[{"id": "2004.00010", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Gautam Kamath, Thomas Steinke", "title": "The Discrete Gaussian for Differential Privacy", "comments": "Improved time analysis, and generalisation to the multivariate case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key tool for building differentially private systems is adding Gaussian\nnoise to the output of a function evaluated on a sensitive dataset.\nUnfortunately, using a continuous distribution presents several practical\nchallenges. First and foremost, finite computers cannot exactly represent\nsamples from continuous distributions, and previous work has demonstrated that\nseemingly innocuous numerical errors can entirely destroy privacy. Moreover,\nwhen the underlying data is itself discrete (e.g., population counts), adding\ncontinuous noise makes the result less interpretable.\n  With these shortcomings in mind, we introduce and analyze the discrete\nGaussian in the context of differential privacy. Specifically, we theoretically\nand experimentally show that adding discrete Gaussian noise provides\nessentially the same privacy and accuracy guarantees as the addition of\ncontinuous Gaussian noise. We also present an simple and efficient algorithm\nfor exact sampling from this distribution. This demonstrates its applicability\nfor privately answering counting queries, or more generally, low-sensitivity\ninteger-valued queries.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:00:00 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 16:47:40 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 19:29:06 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 12:39:15 GMT"}, {"version": "v5", "created": "Mon, 18 Jan 2021 23:30:49 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""], ["Steinke", "Thomas", ""]]}, {"id": "2004.00053", "submitter": "Congzheng Song", "authors": "Congzheng Song and Ananth Raghunathan", "title": "Information Leakage in Embedding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings are functions that map raw input data to low-dimensional vector\nrepresentations, while preserving important semantic information about the\ninputs. Pre-training embeddings on a large amount of unlabeled data and\nfine-tuning them for downstream tasks is now a de facto standard in achieving\nstate of the art learning in many domains.\n  We demonstrate that embeddings, in addition to encoding generic semantics,\noften also present a vector that leaks sensitive information about the input\ndata. We develop three classes of attacks to systematically study information\nthat might be leaked by embeddings. First, embedding vectors can be inverted to\npartially recover some of the input data. As an example, we show that our\nattacks on popular sentence embeddings recover between 50\\%--70\\% of the input\nwords (F1 scores of 0.5--0.7). Second, embeddings may reveal sensitive\nattributes inherent in inputs and independent of the underlying semantic task\nat hand. Attributes such as authorship of text can be easily extracted by\ntraining an inference model on just a handful of labeled embedding vectors.\nThird, embedding models leak moderate amount of membership information for\ninfrequent training data inputs. We extensively evaluate our attacks on various\nstate-of-the-art embedding models in the text domain. We also propose and\nevaluate defenses that can prevent the leakage to some extent at a minor cost\nin utility.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:33:36 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:58:14 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Song", "Congzheng", ""], ["Raghunathan", "Ananth", ""]]}, {"id": "2004.00070", "submitter": "Davide Abati", "authors": "Davide Abati, Jakub Tomczak, Tijmen Blankevoort, Simone Calderara,\n  Rita Cucchiara, Babak Ehteshami Bejnordi", "title": "Conditional Channel Gated Networks for Task-Aware Continual Learning", "comments": "CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks experience catastrophic forgetting when\noptimized on a sequence of learning problems: as they meet the objective of the\ncurrent training examples, their performance on previous tasks drops\ndrastically. In this work, we introduce a novel framework to tackle this\nproblem with conditional computation. We equip each convolutional layer with\ntask-specific gating modules, selecting which filters to apply on the given\ninput. This way, we achieve two appealing properties. Firstly, the execution\npatterns of the gates allow to identify and protect important filters, ensuring\nno loss in the performance of the model for previously learned tasks. Secondly,\nby using a sparsity objective, we can promote the selection of a limited set of\nkernels, allowing to retain sufficient model capacity to digest new\ntasks.Existing solutions require, at test time, awareness of the task to which\neach example belongs to. This knowledge, however, may not be available in many\npractical scenarios. Therefore, we additionally introduce a task classifier\nthat predicts the task label of each example, to deal with settings in which a\ntask oracle is not available. We validate our proposal on four continual\nlearning datasets. Results show that our model consistently outperforms\nexisting methods both in the presence and the absence of a task oracle.\nNotably, on Split SVHN and Imagenet-50 datasets, our model yields up to 23.98%\nand 17.42% improvement in accuracy w.r.t. competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:35:07 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Abati", "Davide", ""], ["Tomczak", "Jakub", ""], ["Blankevoort", "Tijmen", ""], ["Calderara", "Simone", ""], ["Cucchiara", "Rita", ""], ["Bejnordi", "Babak Ehteshami", ""]]}, {"id": "2004.00100", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Saayan Mitra, Somdeb Sarkhel, Viswanathan Swaminathan", "title": "Optimal Bidding Strategy without Exploration in Real-time Bidding", "comments": "SIAM SDM 2020. Added supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing utility with a budget constraint is the primary goal for\nadvertisers in real-time bidding (RTB) systems. The policy maximizing the\nutility is referred to as the optimal bidding strategy. Earlier works on\noptimal bidding strategy apply model-based batch reinforcement learning methods\nwhich can not generalize to unknown budget and time constraint. Further, the\nadvertiser observes a censored market price which makes direct evaluation\ninfeasible on batch test datasets. Previous works ignore the losing auctions to\nalleviate the difficulty with censored states; thus significantly modifying the\ntest distribution. We address the challenge of lacking a clear evaluation\nprocedure as well as the error propagated through batch reinforcement learning\nmethods in RTB systems. We exploit two conditional independence structures in\nthe sequential bidding process that allow us to propose a novel practical\nframework using the maximum entropy principle to imitate the behavior of the\ntrue distribution observed in real-time traffic. Moreover, the framework allows\nus to train a model that can generalize to the unseen budget conditions than\nlimit only to those observed in history. We compare our methods on two\nreal-world RTB datasets with several baselines and demonstrate significantly\nimproved performance under various budget settings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:43:28 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ghosh", "Aritra", ""], ["Mitra", "Saayan", ""], ["Sarkhel", "Somdeb", ""], ["Swaminathan", "Viswanathan", ""]]}, {"id": "2004.00101", "submitter": "Hye Won Chung", "authors": "Doyeon Kim and Hye Won Chung", "title": "Crowdsourced Labeling for Worker-Task Specialization Model", "comments": "To appear at IEEE International Symposium on Information Theory\n  (ISIT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider crowdsourced labeling under a $d$-type worker-task specialization\nmodel, where each worker and task is associated with one particular type among\na finite set of types and a worker provides a more reliable answer to tasks of\nthe matched type than to tasks of unmatched types. We design an inference\nalgorithm that recovers binary task labels (up to any given recovery accuracy)\nby using worker clustering, worker skill estimation and weighted majority\nvoting. The designed inference algorithm does not require any information about\nworker/task types, and achieves any targeted recovery accuracy with the best\nknown performance (minimum number of queries per task).\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:27:03 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 06:55:56 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kim", "Doyeon", ""], ["Chung", "Hye Won", ""]]}, {"id": "2004.00115", "submitter": "Hartmut Maennel", "authors": "Hartmut Maennel", "title": "Exact marginal inference in Latent Dirichlet Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume we have potential \"causes\" $z\\in Z$, which produce \"events\" $w$ with\nknown probabilities $\\beta(w|z)$. We observe $w_1,w_2,...,w_n$, what can we say\nabout the distribution of the causes? A Bayesian estimate will assume a prior\non distributions on $Z$ (we assume a Dirichlet prior) and calculate a\nposterior. An average over that posterior then gives a distribution on $Z$,\nwhich estimates how much each cause $z$ contributed to our observations. This\nis the setting of Latent Dirichlet Allocation, which can be applied e.g. to\ntopics \"producing\" words in a document. In this setting usually the number of\nobserved words is large, but the number of potential topics is small. We are\nhere interested in applications with many potential \"causes\" (e.g. locations on\nthe globe), but only a few observations. We show that the exact Bayesian\nestimate can be computed in linear time (and constant space) in $|Z|$ for a\ngiven upper bound on $n$ with a surprisingly simple formula. We generalize this\nalgorithm to the case of sparse probabilities $\\beta(w|z)$, in which we only\nneed to assume that the tree width of an \"interaction graph\" on the\nobservations is limited. On the other hand we also show that without such\nlimitation the problem is NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 21:14:59 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Maennel", "Hartmut", ""]]}, {"id": "2004.00150", "submitter": "Mohammed Ibrahim", "authors": "Mohammed Ibrahim, Susan Gauch, Omar Salman, Mohammed Alqahatani", "title": "Enriching Consumer Health Vocabulary Using Enhanced GloVe Word Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-Access and Collaborative Consumer Health Vocabulary (OAC CHV, or CHV for\nshort), is a collection of medical terms written in plain English. It provides\na list of simple, easy, and clear terms that laymen prefer to use rather than\nan equivalent professional medical term. The National Library of Medicine (NLM)\nhas integrated and mapped the CHV terms to their Unified Medical Language\nSystem (UMLS). These CHV terms mapped to 56000 professional concepts on the\nUMLS. We found that about 48% of these laymen's terms are still jargon and\nmatched with the professional terms on the UMLS. In this paper, we present an\nenhanced word embedding technique that generates new CHV terms from a\nconsumer-generated text. We downloaded our corpus from a healthcare social\nmedia and evaluated our new method based on iterative feedback to word\nembedding using ground truth built from the existing CHV terms. Our feedback\nalgorithm outperformed unmodified GLoVe and new CHV terms have been detected.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 22:50:24 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 18:02:10 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ibrahim", "Mohammed", ""], ["Gauch", "Susan", ""], ["Salman", "Omar", ""], ["Alqahatani", "Mohammed", ""]]}, {"id": "2004.00163", "submitter": "Zhekun Luo", "authors": "Zhekun Luo, Devin Guillory, Baifeng Shi, Wei Ke, Fang Wan, Trevor\n  Darrell, Huijuan Xu", "title": "Weakly-Supervised Action Localization with Expectation-Maximization\n  Multi-Instance Learning", "comments": "Accepted at European Conference on Computer Vision (ECCV), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly-supervised action localization requires training a model to localize\nthe action segments in the video given only video level action label. It can be\nsolved under the Multiple Instance Learning (MIL) framework, where a bag\n(video) contains multiple instances (action segments). Since only the bag's\nlabel is known, the main challenge is assigning which key instances within the\nbag to trigger the bag's label. Most previous models use attention-based\napproaches applying attentions to generate the bag's representation from\ninstances, and then train it via the bag's classification. These models,\nhowever, implicitly violate the MIL assumption that instances in negative bags\nshould be uniformly negative. In this work, we explicitly model the key\ninstances assignment as a hidden variable and adopt an Expectation-Maximization\n(EM) framework. We derive two pseudo-label generation schemes to model the E\nand M process and iteratively optimize the likelihood lower bound. We show that\nour EM-MIL approach more accurately models both the learning objective and the\nMIL assumptions. It achieves state-of-the-art performance on two standard\nbenchmarks, THUMOS14 and ActivityNet1.2.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 23:36:04 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 19:26:17 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Luo", "Zhekun", ""], ["Guillory", "Devin", ""], ["Shi", "Baifeng", ""], ["Ke", "Wei", ""], ["Wan", "Fang", ""], ["Darrell", "Trevor", ""], ["Xu", "Huijuan", ""]]}, {"id": "2004.00179", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Min Zhang and Shao-Bo Lin", "title": "Fully-Corrective Gradient Boosting with Squared Hinge: Fast Learning\n  Rates and Early Stopping", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a well-known method for improving the accuracy of weak learners\nin machine learning. However, its theoretical generalization guarantee is\nmissing in literature. In this paper, we propose an efficient boosting method\nwith theoretical generalization guarantees for binary classification. Three key\ningredients of the proposed boosting method are: a) the\n\\textit{fully-corrective greedy} (FCG) update in the boosting procedure, b) a\ndifferentiable \\textit{squared hinge} (also called \\textit{truncated\nquadratic}) function as the loss function, and c) an efficient alternating\ndirection method of multipliers (ADMM) algorithm for the associated FCG\noptimization. The used squared hinge loss not only inherits the robustness of\nthe well-known hinge loss for classification with outliers, but also brings\nsome benefits for computational implementation and theoretical justification.\nUnder some sparseness assumption, we derive a fast learning rate of the order\n${\\cal O}((m/\\log m)^{-1/4})$ for the proposed boosting method, which can be\nfurther improved to ${\\cal O}((m/\\log m)^{-1/2})$ if certain additional noise\nassumption is imposed, where $m$ is the size of sample set. Both derived\nlearning rates are the best ones among the existing generalization results of\nboosting-type methods for classification. Moreover, an efficient early stopping\nscheme is provided for the proposed method. A series of toy simulations and\nreal data experiments are conducted to verify the developed theories and\ndemonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 00:39:24 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zeng", "Jinshan", ""], ["Zhang", "Min", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "2004.00184", "submitter": "Michel Besserve", "authors": "Michel Besserve, R\\'emy Sun, Dominik Janzing and Bernhard Sch\\\"olkopf", "title": "A theory of independent mechanisms for extrapolation in generative\n  models", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models reproduce complex empirical data but cannot\nextrapolate to novel environments. An intuitive idea to promote extrapolation\ncapabilities is to enforce the architecture to have the modular structure of a\ncausal graphical model, where one can intervene on each module independently of\nthe others in the graph. We develop a framework to formalize this intuition,\nusing the principle of Independent Causal Mechanisms, and show how\nover-parameterization of generative neural networks can hinder extrapolation\ncapabilities. Our experiments on the generation of human faces shows successive\nlayers of a generator architecture implement independent mechanisms to some\nextent, allowing meaningful extrapolations. Finally, we illustrate that\nindependence of mechanisms may be enforced during training to improve\nextrapolation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 01:01:43 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Besserve", "Michel", ""], ["Sun", "R\u00e9my", ""], ["Janzing", "Dominik", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2004.00198", "submitter": "Yanyao Shen", "authors": "Yanyao Shen, Hsiang-fu Yu, Sujay Sanghavi, Inderjit Dhillon", "title": "Extreme Multi-label Classification from Aggregated Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMC) is the problem of finding the\nrelevant labels for an input, from a very large universe of possible labels. We\nconsider XMC in the setting where labels are available only for groups of\nsamples - but not for individual ones. Current XMC approaches are not built for\nsuch multi-instance multi-label (MIML) training data, and MIML approaches do\nnot scale to XMC sizes. We develop a new and scalable algorithm to impute\nindividual-sample labels from the group labels; this can be paired with any\nexisting XMC method to solve the aggregated label problem. We characterize the\nstatistical properties of our algorithm under mild assumptions, and provide a\nnew end-to-end framework for MIML as an extension. Experiments on both\naggregated label XMC and MIML tasks show the advantages over existing\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:13:09 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Shen", "Yanyao", ""], ["Yu", "Hsiang-fu", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2004.00201", "submitter": "Jianbin Lin Lin", "authors": "Jianbin Lin, Zhiqiang Zhang, Jun Zhou, Xiaolong Li, Jingli Fang,\n  Yanming Fang, Quan Yu, Yuan Qi", "title": "NetDP: An Industrial-Scale Distributed Network Representation Framework\n  for Default Prediction in Ant Credit Pay", "comments": "2018 IEEE International Conference on Big Data (Big Data)", "journal-ref": null, "doi": "10.1109/BigData.2018.8622169", "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Credit Pay is a consumer credit service in Ant Financial Service Group.\nSimilar to credit card, loan default is one of the major risks of this credit\nproduct. Hence, effective algorithm for default prediction is the key to losses\nreduction and profits increment for the company. However, the challenges facing\nin our scenario are different from those in conventional credit card service.\nThe first one is scalability. The huge volume of users and their behaviors in\nAnt Financial requires the ability to process industrial-scale data and perform\nmodel training efficiently. The second challenges is the cold-start problem.\nDifferent from the manual review for credit card application in conventional\nbanks, the credit limit of Ant Credit Pay is automatically offered to users\nbased on the knowledge learned from big data. However, default prediction for\nnew users is suffered from lack of enough credit behaviors. It requires that\nthe proposal should leverage other new data source to alleviate the cold-start\nproblem. Considering the above challenges and the special scenario in Ant\nFinancial, we try to incorporate default prediction with network information to\nalleviate the cold-start problem. In this paper, we propose an industrial-scale\ndistributed network representation framework, termed NetDP, for default\nprediction in Ant Credit Pay. The proposal explores network information\ngenerated by various interaction between users, and blends unsupervised and\nsupervised network representation in a unified framework for default prediction\nproblem. Moreover, we present a parameter-server-based distributed implement of\nour proposal to handle the scalability challenge. Experimental results\ndemonstrate the effectiveness of our proposal, especially in cold-start\nproblem, as well as the efficiency for industrial-scale dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:22:33 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lin", "Jianbin", ""], ["Zhang", "Zhiqiang", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Fang", "Jingli", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""], ["Qi", "Yuan", ""]]}, {"id": "2004.00204", "submitter": "Thi Kim Phung Lai", "authors": "Phung Lai, NhatHai Phan, Han Hu, Anuja Badeti, David Newman, Dejing\n  Dou", "title": "Ontology-based Interpretable Machine Learning for Textual Data", "comments": "Accepted by IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel interpreting framework that learns an\ninterpretable model based on an ontology-based sampling technique to explain\nagnostic prediction models. Different from existing approaches, our algorithm\nconsiders contextual correlation among words, described in domain knowledge\nontologies, to generate semantic explanations. To narrow down the search space\nfor explanations, which is a major problem of long and complicated text data,\nwe design a learnable anchor algorithm, to better extract explanations locally.\nA set of regulations is further introduced, regarding combining learned\ninterpretable representations with anchors to generate comprehensible semantic\nexplanations. An extensive experiment conducted on two real-world datasets\nshows that our approach generates more precise and insightful explanations\ncompared with baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:51:57 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lai", "Phung", ""], ["Phan", "NhatHai", ""], ["Hu", "Han", ""], ["Badeti", "Anuja", ""], ["Newman", "David", ""], ["Dou", "Dejing", ""]]}, {"id": "2004.00225", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, Tom Goldstein", "title": "MetaPoison: Practical General-purpose Clean-label Data Poisoning", "comments": "Conference paper at NeurIPS 2020. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning -- the process by which an attacker takes control of a model\nby making imperceptible changes to a subset of the training data -- is an\nemerging threat in the context of neural networks. Existing attacks for data\npoisoning neural networks have relied on hand-crafted heuristics, because\nsolving the poisoning problem directly via bilevel optimization is generally\nthought of as intractable for deep models. We propose MetaPoison, a first-order\nmethod that approximates the bilevel problem via meta-learning and crafts\npoisons that fool neural networks. MetaPoison is effective: it outperforms\nprevious clean-label poisoning methods by a large margin. MetaPoison is robust:\npoisoned data made for one model transfer to a variety of victim models with\nunknown training settings and architectures. MetaPoison is general-purpose, it\nworks not only in fine-tuning scenarios, but also for end-to-end training from\nscratch, which till now hasn't been feasible for clean-label attacks with deep\nnets. MetaPoison can achieve arbitrary adversary goals -- like using poisons of\none class to make a target image don the label of another arbitrarily chosen\nclass. Finally, MetaPoison works in the real-world. We demonstrate for the\nfirst time successful data poisoning of models trained on the black-box Google\nCloud AutoML API. Code and premade poisons are provided at\nhttps://github.com/wronnyhuang/metapoison\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 04:23:20 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 02:40:40 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Huang", "W. Ronny", ""], ["Geiping", "Jonas", ""], ["Fowl", "Liam", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "2004.00245", "submitter": "Shao-Bo Lin", "authors": "Zhi Han, Siquan Yu, Shao-Bo Lin, Ding-Xuan Zhou", "title": "Depth Selection for Deep ReLU Nets in Feature Extraction and\n  Generalization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is recognized to be capable of discovering deep features for\nrepresentation learning and pattern recognition without requiring elegant\nfeature engineering techniques by taking advantage of human ingenuity and prior\nknowledge. Thus it has triggered enormous research activities in machine\nlearning and pattern recognition. One of the most important challenge of deep\nlearning is to figure out relations between a feature and the depth of deep\nneural networks (deep nets for short) to reflect the necessity of depth. Our\npurpose is to quantify this feature-depth correspondence in feature extraction\nand generalization. We present the adaptivity of features to depths and\nvice-verse via showing a depth-parameter trade-off in extracting both single\nfeature and composite features. Based on these results, we prove that\nimplementing the classical empirical risk minimization on deep nets can achieve\nthe optimal generalization performance for numerous learning tasks. Our\ntheoretical results are verified by a series of numerical experiments including\ntoy simulations and a real application of earthquake seismic intensity\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 06:03:01 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Han", "Zhi", ""], ["Yu", "Siquan", ""], ["Lin", "Shao-Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "2004.00251", "submitter": "Hong-Gyu Jung", "authors": "Jin-Woo Seo, Hong-Gyu Jung, Seong-Whan Lee", "title": "Self-Augmentation: Generalizing Deep Networks to Unseen Classes for\n  Few-Shot Learning", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": "10.1016/j.neunet.2021.02.007", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning aims to classify unseen classes with a few training\nexamples. While recent works have shown that standard mini-batch training with\na carefully designed training strategy can improve generalization ability for\nunseen classes, well-known problems in deep networks such as memorizing\ntraining statistics have been less explored for few-shot learning. To tackle\nthis issue, we propose self-augmentation that consolidates self-mix and\nself-distillation. Specifically, we exploit a regional dropout technique called\nself-mix, in which a patch of an image is substituted into other values in the\nsame image. Then, we employ a backbone network that has auxiliary branches with\nits own classifier to enforce knowledge sharing. Lastly, we present a local\nrepresentation learner to further exploit a few training examples for unseen\nclasses. Experimental results show that the proposed method outperforms the\nstate-of-the-art methods for prevalent few-shot benchmarks and improves the\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 06:39:08 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 04:53:01 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 08:37:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Seo", "Jin-Woo", ""], ["Jung", "Hong-Gyu", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2004.00273", "submitter": "Yu Wang", "authors": "Yu Wang, Nima Roohi, Matthew West, Mahesh Viswanathan, and Geir E.\n  Dullerud", "title": "Statistically Model Checking PCTL Specifications on Markov Decision\n  Processes via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Computation Tree Logic (PCTL) is frequently used to formally\nspecify control objectives such as probabilistic reachability and safety. In\nthis work, we focus on model checking PCTL specifications statistically on\nMarkov Decision Processes (MDPs) by sampling, e.g., checking whether there\nexists a feasible policy such that the probability of reaching certain goal\nstates is greater than a threshold. We use reinforcement learning to search for\nsuch a feasible policy for PCTL specifications, and then develop a statistical\nmodel checking (SMC) method with provable guarantees on its error.\nSpecifically, we first use upper-confidence-bound (UCB) based Q-learning to\ndesign an SMC algorithm for bounded-time PCTL specifications, and then extend\nthis algorithm to unbounded-time specifications by identifying a proper\ntruncation time by checking the PCTL specification and its negation at the same\ntime. Finally, we evaluate the proposed method on case studies.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:10:25 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 02:21:22 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Yu", ""], ["Roohi", "Nima", ""], ["West", "Matthew", ""], ["Viswanathan", "Mahesh", ""], ["Dullerud", "Geir E.", ""]]}, {"id": "2004.00275", "submitter": "Yu Wang", "authors": "Yu Wang, Hussein Sibai, Sayan Mitra and Geir E. Dullerud", "title": "Differential Privacy for Sequential Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the differential privacy of sequential statistical inference and\nlearning algorithms that are characterized by random termination time. Using\nthe two examples: sequential probability ratio test and sequential empirical\nrisk minimization, we show that the number of steps such algorithms execute\nbefore termination can jeopardize the differential privacy of the input data in\na similar fashion as their outputs, and it is impossible to use the usual\nLaplace mechanism to achieve standard differentially private in these examples.\nTo remedy this, we propose a notion of weak differential privacy and\ndemonstrate its equivalence to the standard case for large i.i.d. samples. We\nshow that using the Laplace mechanism, weak differential privacy can be\nachieved for both the sequential probability ratio test and the sequential\nempirical risk minimization with proper performance guarantees. Finally, we\nprovide preliminary experimental results on the Breast Cancer Wisconsin\n(Diagnostic) and Landsat Satellite Data Sets from the UCI repository.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:14:23 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Wang", "Yu", ""], ["Sibai", "Hussein", ""], ["Mitra", "Sayan", ""], ["Dullerud", "Geir E.", ""]]}, {"id": "2004.00281", "submitter": "Michail Tsagris", "authors": "Michail Tsagris, Zacharias Papadovasilakis, Kleanthi Lakiotaki and\n  Ioannis Tsamardinos", "title": "A generalised OMP algorithm for feature selection with application to\n  gene expression data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection for predictive analytics is the problem of identifying a\nminimal-size subset of features that is maximally predictive of an outcome of\ninterest. To apply to molecular data, feature selection algorithms need to be\nscalable to tens of thousands of available features. In this paper, we propose\ngOMP, a highly-scalable generalisation of the Orthogonal Matching Pursuit\nfeature selection algorithm to several directions: (a) different types of\noutcomes, such as continuous, binary, nominal, and time-to-event, (b) different\ntypes of predictive models (e.g., linear least squares, logistic regression),\n(c) different types of predictive features (continuous, categorical), and (d)\ndifferent, statistical-based stopping criteria. We compare the proposed\nalgorithm against LASSO, a prototypical, widely used algorithm for\nhigh-dimensional data. On dozens of simulated datasets, as well as, real gene\nexpression datasets, gOMP is on par, or outperforms LASSO for case-control\nbinary classification, quantified outcomes (regression), and (censored)\nsurvival times (time-to-event) analysis. gOMP has also several theoretical\nadvantages that are discussed. While gOMP is based on quite simple and basic\nstatistical ideas, easy to implement and to generalize, we also show in an\nextensive evaluation that it is also quite effective in bioinformatics analysis\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:33:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Tsagris", "Michail", ""], ["Papadovasilakis", "Zacharias", ""], ["Lakiotaki", "Kleanthi", ""], ["Tsamardinos", "Ioannis", ""]]}, {"id": "2004.00315", "submitter": "Linjun Zhou", "authors": "Linjun Zhou, Peng Cui, Xu Jia, Shiqiang Yang, Qi Tian", "title": "Learning to Select Base Classes for Few-shot Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning has attracted intensive research attention in recent years.\nMany methods have been proposed to generalize a model learned from provided\nbase classes to novel classes, but no previous work studies how to select base\nclasses, or even whether different base classes will result in different\ngeneralization performance of the learned model. In this paper, we utilize a\nsimple yet effective measure, the Similarity Ratio, as an indicator for the\ngeneralization performance of a few-shot model. We then formulate the base\nclass selection problem as a submodular optimization problem over Similarity\nRatio. We further provide theoretical analysis on the optimization lower bound\nof different optimization methods, which could be used to identify the most\nappropriate algorithm for different experimental settings. The extensive\nexperiments on ImageNet, Caltech256 and CUB-200-2011 demonstrate that our\nproposed method is effective in selecting a better base dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:55:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhou", "Linjun", ""], ["Cui", "Peng", ""], ["Jia", "Xu", ""], ["Yang", "Shiqiang", ""], ["Tian", "Qi", ""]]}, {"id": "2004.00345", "submitter": "Sergei Popov", "authors": "Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin, Sergei Popov,\n  Artem Babenko", "title": "Editable Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  These days deep neural networks are ubiquitously used in a wide range of\ntasks, from image classification and machine translation to face identification\nand self-driving cars. In many applications, a single model error can lead to\ndevastating financial, reputational and even life-threatening consequences.\nTherefore, it is crucially important to correct model mistakes quickly as they\nappear. In this work, we investigate the problem of neural network editing $-$\nhow one can efficiently patch a mistake of the model on a particular sample,\nwithout influencing the model behavior on other samples. Namely, we propose\nEditable Training, a model-agnostic training technique that encourages fast\nediting of the trained model. We empirically demonstrate the effectiveness of\nthis method on large-scale image classification and machine translation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:26:27 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 08:00:15 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Sinitsin", "Anton", ""], ["Plokhotnyuk", "Vsevolod", ""], ["Pyrkin", "Dmitriy", ""], ["Popov", "Sergei", ""], ["Babenko", "Artem", ""]]}, {"id": "2004.00353", "submitter": "Ricky T. Q. Chen", "authors": "Yucen Luo, Alex Beatson, Mohammad Norouzi, Jun Zhu, David Duvenaud,\n  Ryan P. Adams, and Ricky T. Q. Chen", "title": "SUMO: Unbiased Estimation of Log Marginal Probability for Latent\n  Variable Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard variational lower bounds used to train latent variable models\nproduce biased estimates of most quantities of interest. We introduce an\nunbiased estimator of the log marginal likelihood and its gradients for latent\nvariable models based on randomized truncation of infinite series. If\nparameterized by an encoder-decoder architecture, the parameters of the encoder\ncan be optimized to minimize its variance of this estimator. We show that\nmodels trained using our estimator give better test-set likelihoods than a\nstandard importance-sampling based approach for the same average computational\ncost. This estimator also allows use of latent variable models for tasks where\nunbiased estimators, rather than marginal likelihood lower bounds, are\npreferred, such as minimizing reverse KL divergences and estimating score\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:49:30 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 19:42:39 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Luo", "Yucen", ""], ["Beatson", "Alex", ""], ["Norouzi", "Mohammad", ""], ["Zhu", "Jun", ""], ["Duvenaud", "David", ""], ["Adams", "Ryan P.", ""], ["Chen", "Ricky T. Q.", ""]]}, {"id": "2004.00361", "submitter": "Jonathan Daniel Smith", "authors": "Jonathan D. Smith, Kamyar Azizzadenesheli and Zachary E. Ross", "title": "EikoNet: Solving the Eikonal equation with Deep Neural Networks", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.geo-ph physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent deep learning revolution has created an enormous opportunity for\naccelerating compute capabilities in the context of physics-based simulations.\nHere, we propose EikoNet, a deep learning approach to solving the Eikonal\nequation, which characterizes the first-arrival-time field in heterogeneous 3D\nvelocity structures. Our grid-free approach allows for rapid determination of\nthe travel time between any two points within a continuous 3D domain. These\ntravel time solutions are allowed to violate the differential equation - which\ncasts the problem as one of optimization - with the goal of finding network\nparameters that minimize the degree to which the equation is violated. In doing\nso, the method exploits the differentiability of neural networks to calculate\nthe spatial gradients analytically, meaning the network can be trained on its\nown without ever needing solutions from a finite difference algorithm. EikoNet\nis rigorously tested on several velocity models and sampling methods to\ndemonstrate robustness and versatility. Training and inference are highly\nparallelized, making the approach well-suited for GPUs. EikoNet has low memory\noverhead, and further avoids the need for travel-time lookup tables. The\ndeveloped approach has important applications to earthquake hypocenter\ninversion, ray multi-pathing, and tomographic modeling, as well as to other\nfields beyond seismology where ray tracing is essential.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 02:31:53 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 23:04:36 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 15:43:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Smith", "Jonathan D.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Ross", "Zachary E.", ""]]}, {"id": "2004.00362", "submitter": "Kisor Sahu Dr.", "authors": "Ajay K. Gogineni, S. Swayamjyoti, Devadatta Sahoo, Kisor K. Sahu, Raj\n  kishore", "title": "Multi-Class classification of vulnerabilities in Smart Contracts using\n  AWD-LSTM, with pre-trained encoder inspired from natural language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability detection and safety of smart contracts are of paramount\nimportance because of their immutable nature. Symbolic tools like OYENTE and\nMAIAN are typically used for vulnerability prediction in smart contracts. As\nthese tools are computationally expensive, they are typically used to detect\nvulnerabilities until some predefined invocation depth. These tools require\nmore search time as the invocation depth increases. Since the number of smart\ncontracts is increasing exponentially, it is difficult to analyze the contracts\nusing these traditional tools. Recently a machine learning technique called\nLong Short Term Memory (LSTM) has been used for binary classification, i.e., to\npredict whether a smart contract is vulnerable or not. This technique requires\nnearly constant search time as the invocation depth increases. In the present\narticle, we have shown a multi-class classification, where we classify a smart\ncontract in Suicidal, Prodigal, Greedy, or Normal categories. We used Average\nStochastic Gradient Descent Weight-Dropped LSTM (AWD-LSTM), which is a variant\nof LSTM, to perform classification. We reduced the class imbalance (a large\nnumber of normal contracts as compared to other categories) by considering only\nthe distinct opcode combination for normal contracts. We have achieved a\nweighted average Fbeta score of 90.0%. Hence, such techniques can be used to\nanalyze a large number of smart contracts and help to improve the security of\nthese contracts.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 20:48:09 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gogineni", "Ajay K.", ""], ["Swayamjyoti", "S.", ""], ["Sahoo", "Devadatta", ""], ["Sahu", "Kisor K.", ""], ["kishore", "Raj", ""]]}, {"id": "2004.00363", "submitter": "Paul Ferrand", "authors": "Paul Ferrand, Alexis Decurninge, Maxime Guillaud", "title": "DNN-based Localization from Channel Estimates: Feature Design and\n  Experimental Results", "comments": "Submitted to Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of deep neural networks (DNNs) in the context of channel\nstate information (CSI)-based localization for Massive MIMO cellular systems.\nWe discuss the practical impairments that are likely to be present in practical\nCSI estimates, and introduce a principled approach to feature design for\nCSI-based DNN applications based on the objective of making the features\ninvariant to the considered impairments. We demonstrate the efficiency of this\napproach by applying it to a dataset constituted of geo-tagged CSI measured in\nan outdoors campus environment, and training a DNN to estimate the position of\nthe UE on the basis of the CSI. We provide an experimental evaluation of\nseveral aspects of that learning approach, including localization accuracy,\ngeneralization capability, and data aging.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 15:20:15 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:15:42 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ferrand", "Paul", ""], ["Decurninge", "Alexis", ""], ["Guillaud", "Maxime", ""]]}, {"id": "2004.00378", "submitter": "Weiheng Jiang", "authors": "Weiheng Jiang, Xiaogang Wu, Bolin Chen, Wenjiang Feng, Yi Jin", "title": "Time-Frequency Analysis based Blind Modulation Classification for\n  Multiple-Antenna Systems", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Blind modulation classification is an important step to implement cognitive\nradio networks. The multiple-input multiple-output (MIMO) technique is widely\nused in military and civil communication systems. Due to the lack of prior\ninformation about channel parameters and the overlapping of signals in the MIMO\nsystems, the traditional likelihood-based and feature-based approaches cannot\nbe applied in these scenarios directly. Hence, in this paper, to resolve the\nproblem of blind modulation classification in MIMO systems, the time-frequency\nanalysis method based on the windowed short-time Fourier transform is used to\nanalyse the time-frequency characteristics of time-domain modulated signals.\nThen the extracted time-frequency characteristics are converted into RGB\nspectrogram images, and the convolutional neural network based on transfer\nlearning is applied to classify the modulation types according to the RGB\nspectrogram images. Finally, a decision fusion module is used to fuse the\nclassification results of all the receive antennas. Through simulations, we\nanalyse the classification performance at different signal-to-noise ratios\n(SNRs), the results indicate that, for the single-input single-output (SISO)\nnetwork, our proposed scheme can achieve 92.37% and 99.12% average\nclassification accuracy at SNRs of -4 dB and 10 dB, respectively. For the MIMO\nnetwork, our scheme achieves 80.42% and 87.92% average classification accuracy\nat -4 dB and 10 dB, respectively. This outperforms the existing classification\nmethods based on baseband signals.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:27:29 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Jiang", "Weiheng", ""], ["Wu", "Xiaogang", ""], ["Chen", "Bolin", ""], ["Feng", "Wenjiang", ""], ["Jin", "Yi", ""]]}, {"id": "2004.00407", "submitter": "Heeyoung Kwak", "authors": "Heeyoung Kwak, Minwoo Lee, Seunghyun Yoon, Jooyoung Chang, Sangmin\n  Park, Kyomin Jung", "title": "Drug-disease Graph: Predicting Adverse Drug Reaction Signals via Graph\n  Neural Network with Clinical Data", "comments": "To appear at PAKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse Drug Reaction (ADR) is a significant public health concern\nworld-wide. Numerous graph-based methods have been applied to biomedical graphs\nfor predicting ADRs in pre-marketing phases. ADR detection in post-market\nsurveillance is no less important than pre-marketing assessment, and ADR\ndetection with large-scale clinical data have attracted much attention in\nrecent years. However, there are not many studies considering graph structures\nfrom clinical data for detecting an ADR signal, which is a pair of a\nprescription and a diagnosis that might be a potential ADR. In this study, we\ndevelop a novel graph-based framework for ADR signal detection using healthcare\nclaims data. We construct a Drug-disease graph with nodes representing the\nmedical codes. The edges are given as the relationships between two codes,\ncomputed using the data. We apply Graph Neural Network to predict ADR signals,\nusing labels from the Side Effect Resource database. The model shows improved\nAUROC and AUPRC performance of 0.795 and 0.775, compared to other algorithms,\nshowing that it successfully learns node representations expressive of those\nrelationships. Furthermore, our model predicts ADR pairs that do not exist in\nthe established ADR database, showing its capability to supplement the ADR\ndatabase.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:01:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kwak", "Heeyoung", ""], ["Lee", "Minwoo", ""], ["Yoon", "Seunghyun", ""], ["Chang", "Jooyoung", ""], ["Park", "Sangmin", ""], ["Jung", "Kyomin", ""]]}, {"id": "2004.00410", "submitter": "Samuel Harford", "authors": "Samuel Harford, Fazle Karim and Houshang Darabi", "title": "Adversarial Attacks on Multivariate Time Series", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.10755", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification models for the multivariate time series have gained\nsignificant importance in the research community, but not much research has\nbeen done on generating adversarial samples for these models. Such samples of\nadversaries could become a security concern. In this paper, we propose\ntransforming the existing adversarial transformation network (ATN) on a\ndistilled model to attack various multivariate time series classification\nmodels. The proposed attack on the classification model utilizes a distilled\nmodel as a surrogate that mimics the behavior of the attacked classical\nmultivariate time series classification models. The proposed methodology is\ntested onto 1-Nearest Neighbor Dynamic Time Warping (1-NN DTW) and a Fully\nConvolutional Network (FCN), all of which are trained on 18 University of East\nAnglia (UEA) and University of California Riverside (UCR) datasets. We show\nboth models were susceptible to attacks on all 18 datasets. To the best of our\nknowledge, adversarial attacks have only been conducted in the domain of\nunivariate time series and have not been conducted on multivariate time series.\nsuch an attack on time series classification models has never been done before.\nAdditionally, we recommend future researchers that develop time series\nclassification models to incorporating adversarial data samples into their\ntraining data sets to improve resilience on adversarial samples and to consider\nmodel robustness as an evaluative metric.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:15:41 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Harford", "Samuel", ""], ["Karim", "Fazle", ""], ["Darabi", "Houshang", ""]]}, {"id": "2004.00412", "submitter": "Wenjie Zheng", "authors": "Wenjie Zheng", "title": "Total Variation Regularization for Compartmental Epidemic Models with\n  Time-Varying Dynamics", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compartmental epidemic models are among the most popular ones in\nepidemiology. For the parameters (e.g., the transmission rate) characterizing\nthese models, the majority of researchers simplify them as constants, while\nsome others manage to detect their continuous variations. In this paper, we aim\nat capturing, on the other hand, discontinuous variations, which better\ndescribe the impact of many noteworthy events, such as city lockdowns, the\nopening of field hospitals, and the mutation of the virus, whose effect should\nbe instant. To achieve this, we balance the model's likelihood by total\nvariation, which regulates the temporal variations of the model parameters. To\ninfer these parameters, instead of using Monte Carlo methods, we design a novel\nyet straightforward optimization algorithm, dubbed Iterated Nelder--Mead, which\nrepeatedly applies the Nelder--Mead algorithm. Experiments conducted on the\nsimulated data demonstrate that our approach can reproduce these\ndiscontinuities and precisely depict the epidemics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:06:10 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 03:39:13 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zheng", "Wenjie", ""]]}, {"id": "2004.00413", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato, Sarunas Girdzijauskas", "title": "Gossip and Attend: Context-Sensitive Graph Representation Learning", "comments": "In Proc. of the 14th AAAI International Conference on Web and Social\n  Media, ICWSM 2020. arXiv admin note: text overlap with arXiv:2001.10394", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning (GRL) is a powerful technique for learning\nlow-dimensional vector representation of high-dimensional and often sparse\ngraphs. Most studies explore the structure and metadata associated with the\ngraph using random walks and employ an unsupervised or semi-supervised learning\nschemes. Learning in these methods is context-free, resulting in only a single\nrepresentation per node. Recently studies have argued on the adequacy of a\nsingle representation and proposed context-sensitive approaches, which are\ncapable of extracting multiple node representations for different contexts.\nThis proved to be highly effective in applications such as link prediction and\nranking.\n  However, most of these methods rely on additional textual features that\nrequire complex and expensive RNNs or CNNs to capture high-level features or\nrely on a community detection algorithm to identify multiple contexts of a\nnode.\n  In this study we show that in-order to extract high-quality context-sensitive\nnode representations it is not needed to rely on supplementary node features,\nnor to employ computationally heavy and complex models. We propose GOAT, a\ncontext-sensitive algorithm inspired by gossip communication and a mutual\nattention mechanism simply over the structure of the graph. We show the\nefficacy of GOAT using 6 real-world datasets on link prediction and node\nclustering tasks and compare it against 12 popular and state-of-the-art (SOTA)\nbaselines. GOAT consistently outperforms them and achieves up to 12% and 19%\ngain over the best performing methods on link prediction and clustering tasks,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:23:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2004.00422", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Yisong Yue, Bistra Dilkina", "title": "A General Large Neighborhood Search Framework for Solving Integer Linear\n  Programs", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a strategy for data-driven algorithm design for\nlarge-scale combinatorial optimization problems that can leverage existing\nstate-of-the-art solvers in general purpose ways. The goal is to arrive at new\napproaches that can reliably outperform existing solvers in wall-clock time. We\nfocus on solving integer programs, and ground our approach in the large\nneighborhood search (LNS) paradigm, which iteratively chooses a subset of\nvariables to optimize while leaving the remainder fixed. The appeal of LNS is\nthat it can easily use any existing solver as a subroutine, and thus can\ninherit the benefits of carefully engineered heuristic or complete approaches\nand their software implementations. We show that one can learn a good\nneighborhood selector using imitation and reinforcement learning techniques.\nThrough an extensive empirical validation in bounded-time optimization, we\ndemonstrate that our LNS framework can significantly outperform compared to\nstate-of-the-art commercial solvers such as Gurobi.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 23:08:14 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:19:57 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 22:21:18 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Yue", "Yisong", ""], ["Dilkina", "Bistra", ""]]}, {"id": "2004.00426", "submitter": "Grzegorz Dudek", "authors": "Pawe{\\l} Pe{\\l}ka, Grzegorz Dudek", "title": "Ensemble Forecasting of Monthly Electricity Demand using Pattern\n  Similarity-based Methods", "comments": "12 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2003.01475", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents ensemble forecasting of monthly electricity demand using\npattern similarity-based forecasting methods (PSFMs). PSFMs applied in this\nstudy include $k$-nearest neighbor model, fuzzy neighborhood model, kernel\nregression model, and general regression neural network. An integral part of\nPSFMs is a time series representation using patterns of time series sequences.\nPattern representation ensures the input and output data unification through\nfiltering a trend and equalizing variance. Two types of ensembles are created:\nheterogeneous and homogeneous. The former consists of different type base\nmodels, while the latter consists of a single-type base model. Five strategies\nare used for controlling a diversity of members in a homogeneous approach. The\ndiversity is generated using different subsets of training data, different\nsubsets of features, randomly disrupted input and output variables, and\nrandomly disrupted model parameters. An empirical illustration applies the\nensemble models as well as individual PSFMs for comparison to the monthly\nelectricity demand forecasting for 35 European countries.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 17:26:58 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Pe\u0142ka", "Pawe\u0142", ""], ["Dudek", "Grzegorz", ""]]}, {"id": "2004.00430", "submitter": "Vithya Yogarajan", "authors": "Vithya Yogarajan, Jacob Montiel, Tony Smith, Bernhard Pfahringer", "title": "Seeing The Whole Patient: Using Multi-Label Medical Text Classification\n  Techniques to Enhance Predictions of Medical Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based multi-label medical text classifications can be used\nto enhance the understanding of the human body and aid the need for patient\ncare. We present a broad study on clinical natural language processing\ntechniques to maximise a feature representing text when predicting medical\ncodes on patients with multi-morbidity. We present results of multi-label\nmedical text classification problems with 18, 50 and 155 labels. We compare\nseveral variations to embeddings, text tagging, and pre-processing. For\nimbalanced data we show that labels which occur infrequently, benefit the most\nfrom additional features incorporated in embeddings. We also show that high\ndimensional embeddings pre-trained using health-related data present a\nsignificant improvement in a multi-label setting, similarly to the way they\nimprove performance for binary classification. High dimensional embeddings from\nthis research are made available for public use.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:19:30 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yogarajan", "Vithya", ""], ["Montiel", "Jacob", ""], ["Smith", "Tony", ""], ["Pfahringer", "Bernhard", ""]]}, {"id": "2004.00431", "submitter": "Jaehyung Kim", "authors": "Jaehyung Kim, Jongheon Jeong, Jinwoo Shin", "title": "M2m: Imbalanced Classification via Major-to-minor Translation", "comments": "12 pages; CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most real-world scenarios, labeled training datasets are highly\nclass-imbalanced, where deep neural networks suffer from generalizing to a\nbalanced testing criterion. In this paper, we explore a novel yet simple way to\nalleviate this issue by augmenting less-frequent classes via translating\nsamples (e.g., images) from more-frequent classes. This simple approach enables\na classifier to learn more generalizable features of minority classes, by\ntransferring and leveraging the diversity of the majority information. Our\nexperimental results on a variety of class-imbalanced datasets show that the\nproposed method improves the generalization on minority classes significantly\ncompared to other existing re-sampling or re-weighting methods. The performance\nof our method even surpasses those of previous state-of-the-art methods for the\nimbalanced classification.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:21:17 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 10:48:34 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kim", "Jaehyung", ""], ["Jeong", "Jongheon", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2004.00433", "submitter": "Mohammad Braei", "authors": "Mohammad Braei and Sebastian Wagner", "title": "Anomaly Detection in Univariate Time-series: A Survey on the\n  State-of-the-Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Anomaly detection for time-series data has been an important research field\nfor a long time. Seminal work on anomaly detection methods has been focussing\non statistical approaches. In recent years an increasing number of machine\nlearning algorithms have been developed to detect anomalies on time-series.\nSubsequently, researchers tried to improve these techniques using (deep) neural\nnetworks. In the light of the increasing number of anomaly detection methods,\nthe body of research lacks a broad comparative evaluation of statistical,\nmachine learning and deep learning methods. This paper studies 20 univariate\nanomaly detection methods from the all three categories. The evaluation is\nconducted on publicly available datasets, which serve as benchmarks for\ntime-series anomaly detection. By analyzing the accuracy of each method as well\nas the computation time of the algorithms, we provide a thorough insight about\nthe performance of these anomaly detection approaches, alongside some general\nnotion of which method is suited for a certain type of data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:22:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Braei", "Mohammad", ""], ["Wagner", "Sebastian", ""]]}, {"id": "2004.00436", "submitter": "Sherif Abdelkarim Mr.", "authors": "Sherif Abdelkarim, Aniket Agarwal, Panos Achlioptas, Jun Chen, Jiaji\n  Huang, Boyang Li, Kenneth Church, Mohamed Elhoseiny", "title": "Long Tail Visual Relationship Recognition with Hubless Regularized\n  Relmix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several approaches have been proposed in recent literature to alleviate the\nlong-tail problem, mostly in the object classification task. We propose to\nstudy the task of Long-Tail Visual Relationship Recognition (LTVRR), which aims\nat generalizing on the structured long-tail distribution of visual\nrelationships (e.g., \"rabbit grazing on grass\"). In this setup, subject,\nrelation, and object classes individually follow a long-tail distribution. We\nfirst introduce two large-scale long-tail visual relationship recognition\nbenchmarks to study this task, dubbed as VG8K-LT (5330 objects, 2000\nrelationships) and GQA-LT (1703 objects, 310 relations). VG8K-LT and GQA-LT are\nbuilt upon the widely used Visual Genome and GQA datasets. In contrast to\nexisting benchmarks, some classes appear at a very low frequency ($1-14$\nexamples). We use these benchmarks to study the performance of several\nstate-of-the-art long-tail models on LTVRR setup. We developed a\nvisiolinguistic hubless (ViLHub) loss that consistently encourages visual\nclassifiers to be more predictive of tail classes while being accurate on the\nhead. We also propose relationship Mixup augmentation, dubbed as RelMix, to\nimprove performance on the tail on VG8K-LT and GQA-LT benchmarks with the best\nperformance achieved when combined with ViLHub loss. Benchmarks and code will\nbe made available.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 19:03:29 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 20:13:01 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 21:36:30 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 09:53:50 GMT"}, {"version": "v5", "created": "Wed, 24 Feb 2021 02:52:17 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Abdelkarim", "Sherif", ""], ["Agarwal", "Aniket", ""], ["Achlioptas", "Panos", ""], ["Chen", "Jun", ""], ["Huang", "Jiaji", ""], ["Li", "Boyang", ""], ["Church", "Kenneth", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "2004.00438", "submitter": "Lucas Baier", "authors": "Lucas Baier (1), Marcel Hofmann (2), Niklas K\\\"uhl (1), Marisa Mohr (2\n  and 3) and Gerhard Satzger (1) ((1) Karlsruhe Institute of Technology,\n  Karlsruhe, Germany, (2) inovex GmbH, Karlsruhe, Germany (3) University of\n  L\\\"ubeck, L\\\"ubeck, Germany)", "title": "Handling Concept Drifts in Regression Problems -- the Error Intersection\n  Approach", "comments": null, "journal-ref": null, "doi": "10.30844/wi_2020_c1-baier", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are omnipresent for predictions on big data. One\nchallenge of deployed models is the change of the data over time, a phenomenon\ncalled concept drift. If not handled correctly, a concept drift can lead to\nsignificant mispredictions. We explore a novel approach for concept drift\nhandling, which depicts a strategy to switch between the application of simple\nand complex machine learning models for regression tasks. We assume that the\napproach plays out the individual strengths of each model, switching to the\nsimpler model if a drift occurs and switching back to the complex model for\ntypical situations. We instantiate the approach on a real-world data set of\ntaxi demand in New York City, which is prone to multiple drifts, e.g. the\nweather phenomena of blizzards, resulting in a sudden decrease of taxi demand.\nWe are able to show that our suggested approach outperforms all regarded\nbaselines significantly.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:30:05 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Baier", "Lucas", "", "2\n  and 3"], ["Hofmann", "Marcel", "", "2\n  and 3"], ["K\u00fchl", "Niklas", "", "2\n  and 3"], ["Mohr", "Marisa", "", "2\n  and 3"], ["Satzger", "Gerhard", ""]]}, {"id": "2004.00464", "submitter": "Oliver D\\\"urr", "authors": "Beate Sick, Torsten Hothorn, Oliver D\\\"urr", "title": "Deep transformation models: Tackling complex regression problems with\n  neural network based transformation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep transformation model for probabilistic regression. Deep\nlearning is known for outstandingly accurate predictions on complex data but in\nregression tasks, it is predominantly used to just predict a single number.\nThis ignores the non-deterministic character of most tasks. Especially if\ncrucial decisions are based on the predictions, like in medical applications,\nit is essential to quantify the prediction uncertainty. The presented deep\nlearning transformation model estimates the whole conditional probability\ndistribution, which is the most thorough way to capture uncertainty about the\noutcome. We combine ideas from a statistical transformation model (most likely\ntransformation) with recent transformation models from deep learning\n(normalizing flows) to predict complex outcome distributions. The core of the\nmethod is a parameterized transformation function which can be trained with the\nusual maximum likelihood framework using gradient descent. The method can be\ncombined with existing deep learning architectures. For small machine learning\nbenchmark datasets, we report state of the art performance for most dataset and\npartly even outperform it. Our method works for complex input data, which we\ndemonstrate by employing a CNN architecture on image data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:23:12 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Sick", "Beate", ""], ["Hothorn", "Torsten", ""], ["D\u00fcrr", "Oliver", ""]]}, {"id": "2004.00478", "submitter": "Reda Marzouk", "authors": "Reda Marzouk and Colin de la Higuera", "title": "Distance and Equivalence between Finite State Machines and Recurrent\n  Neural Networks: Computational results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need of interpreting Deep Learning (DL) models has led, during the past\nyears, to a proliferation of works concerned by this issue. Among strategies\nwhich aim at shedding some light on how information is represented internally\nin DL models, one consists in extracting symbolic rule-based machines from\nconnectionist models that are supposed to approximate well their behaviour. In\norder to better understand how reasonable these approximation strategies are,\nwe need to know the computational complexity of measuring the quality of\napproximation. In this article, we will prove some computational results\nrelated to the problem of extracting Finite State Machine (FSM) based models\nfrom trained RNN Language models. More precisely, we'll show the following: (a)\nFor general weighted RNN-LMs with a single hidden layer and a ReLu activation:\n- The equivalence problem of a PDFA/PFA/WFA and a weighted first-order RNN-LM\nis undecidable; - As a corollary, the distance problem between languages\ngenerated by PDFA/PFA/WFA and that of a weighted RNN-LM is not recursive; -The\nintersection between a DFA and the cut language of a weighted RNN-LM is\nundecidable; - The equivalence of a PDFA/PFA/WFA and weighted RNN-LM in a\nfinite support is EXP-Hard; (b) For consistent weight RNN-LMs with any\ncomputable activation function: - The Tcheybechev distance approximation is\ndecidable; - The Tcheybechev distance approximation in a finite support is\nNP-Hard. Moreover, our reduction technique from 3-SAT makes this latter fact\neasily generalizable to other RNN architectures (e.g. LSTMs/RNNs), and RNNs\nwith finite precision.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:48:59 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Marzouk", "Reda", ""], ["de la Higuera", "Colin", ""]]}, {"id": "2004.00480", "submitter": "Amir Mosavi Prof", "authors": "Sultan Noman Qasem and Amir Mosavi", "title": "Novel Meta-Heuristic Model for Discrimination between Iron Deficiency\n  Anemia and B-Thalassemia with CBC Indices Based on Dynamic Harmony Search", "comments": "10pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent decades, attention has been directed at anemia classification for\nvarious medical purposes, such as thalassemia screening and predicting iron\ndeficiency anemia (IDA). In this study, a new method has been successfully\ntested for discrimination between IDA and \\b{eta}-thalassemia trait\n(\\b{eta}-TT). The method is based on a Dynamic Harmony Search (DHS). Complete\nblood count (CBC), a fast and inexpensive laboratory test, is used as the input\nof the system. Other models, such as a genetic programming method called\nstructured representation on genetic algorithm in non-linear function fitting\n(STROGANOFF), an artificial neural network (ANN), an adaptive neuro-fuzzy\ninference system (ANFIS), a support vector machine (SVM), k-nearest neighbor\n(KNN), and certain traditional methods, are compared with the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:37:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Qasem", "Sultan Noman", ""], ["Mosavi", "Amir", ""]]}, {"id": "2004.00500", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, Wen Sun, J. Andrew Bagnell", "title": "Exploration in Action Space", "comments": "Presented at RSS 2018 in Learning and Inference in Robotics:\n  Integrating Structure, Priors and Models workshop. arXiv admin note: text\n  overlap with arXiv:1901.11503", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter space exploration methods with black-box optimization have recently\nbeen shown to outperform state-of-the-art approaches in continuous control\nreinforcement learning domains. In this paper, we examine reasons why these\nmethods work better and the situations in which they are worse than traditional\naction space exploration methods. Through a simple theoretical analysis, we\nshow that when the parametric complexity required to solve the reinforcement\nlearning problem is greater than the product of action space dimensionality and\nhorizon length, exploration in action space is preferred. This is also shown\nempirically by comparing simple exploration methods on several toy problems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 01:27:22 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Vemula", "Anirudh", ""], ["Sun", "Wen", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "2004.00505", "submitter": "Eoin Brophy", "authors": "Eoin Brophy, Willie Muehlhausen, Alan F. Smeaton, Tomas E. Ward", "title": "Optimised Convolutional Neural Networks for Heart Rate Estimation and\n  Human Activity Recognition in Wrist Worn Sensing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wrist-worn smart devices are providing increased insights into human health,\nbehaviour and performance through sophisticated analytics. However, battery\nlife, device cost and sensor performance in the face of movement-related\nartefact present challenges which must be further addressed to see effective\napplications and wider adoption through commoditisation of the technology. We\naddress these challenges by demonstrating, through using a simple optical\nmeasurement, photoplethysmography (PPG) used conventionally for heart rate\ndetection in wrist-worn sensors, that we can provide improved heart rate and\nhuman activity recognition (HAR) simultaneously at low sample rates, without an\ninertial measurement unit. This simplifies hardware design and reduces costs\nand power budgets. We apply two deep learning pipelines, one for human activity\nrecognition and one for heart rate estimation. HAR is achieved through the\napplication of a visual classification approach, capable of robust performance\nat low sample rates. Here, transfer learning is leveraged to retrain a\nconvolutional neural network (CNN) to distinguish characteristics of the PPG\nduring different human activities. For heart rate estimation we use a CNN\nadopted for regression which maps noisy optical signals to heart rate\nestimates. In both cases, comparisons are made with leading conventional\napproaches. Our results demonstrate a low sampling frequency can achieve good\nperformance without significant degradation of accuracy. 5 Hz and 10 Hz were\nshown to have 80.2% and 83.0% classification accuracy for HAR respectively.\nThese same sampling frequencies also yielded a robust heart rate estimation\nwhich was comparative with that achieved at the more energy-intensive rate of\n256 Hz.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:44:58 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Brophy", "Eoin", ""], ["Muehlhausen", "Willie", ""], ["Smeaton", "Alan F.", ""], ["Ward", "Tomas E.", ""]]}, {"id": "2004.00507", "submitter": "Changyang She", "authors": "Rui Dong, Changyang She, Wibowo Hardjawana, Yonghui Li, and Branka\n  Vucetic", "title": "Deep Learning for Radio Resource Allocation with Diverse\n  Quality-of-Service Requirements in 5G", "comments": "The manuscript has been submitted to IEEE TWC. It is in the second\n  round of review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accommodate diverse Quality-of-Service (QoS) requirements in the 5th\ngeneration cellular networks, base stations need real-time optimization of\nradio resources in time-varying network conditions. This brings high computing\noverheads and long processing delays. In this work, we develop a deep learning\nframework to approximate the optimal resource allocation policy that minimizes\nthe total power consumption of a base station by optimizing bandwidth and\ntransmit power allocation. We find that a fully-connected neural network (NN)\ncannot fully guarantee the QoS requirements due to the approximation errors and\nquantization errors of the numbers of subcarriers. To tackle this problem, we\npropose a cascaded structure of NNs, where the first NN approximates the\noptimal bandwidth allocation, and the second NN outputs the transmit power\nrequired to satisfy the QoS requirement with given bandwidth allocation.\nConsidering that the distribution of wireless channels and the types of\nservices in the wireless networks are non-stationary, we apply deep transfer\nlearning to update NNs in non-stationary wireless networks. Simulation results\nvalidate that the cascaded NNs outperform the fully connected NN in terms of\nQoS guarantee. In addition, deep transfer learning can reduce the number of\ntraining samples required to train the NNs remarkably.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 04:48:22 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Dong", "Rui", ""], ["She", "Changyang", ""], ["Hardjawana", "Wibowo", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "2004.00508", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek, Pawe{\\l} Pe{\\l}ka, Slawek Smyl", "title": "A Hybrid Residual Dilated LSTM end Exponential Smoothing Model for\n  Mid-Term Electric Load Forecasting", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a hybrid and hierarchical deep learning model for mid-term\nload forecasting. The model combines exponential smoothing (ETS), advanced Long\nShort-Term Memory (LSTM) and ensembling. ETS extracts dynamically the main\ncomponents of each individual time series and enables the model to learn their\nrepresentation. Multi-layer LSTM is equipped with dilated recurrent skip\nconnections and a spatial shortcut path from lower layers to allow the model to\nbetter capture long-term seasonal relationships and ensure more efficient\ntraining. A common learning procedure for LSTM and ETS, with a penalized\npinball loss, leads to simultaneous optimization of data representation and\nforecasting performance. In addition, ensembling at three levels ensures a\npowerful regularization. A simulation study performed on the monthly\nelectricity demand time series for 35 European countries confirmed the high\nperformance of the proposed model and its competitiveness with classical models\nsuch as ARIMA and ETS as well as state-of-the-art models based on machine\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 10:53:50 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Dudek", "Grzegorz", ""], ["Pe\u0142ka", "Pawe\u0142", ""], ["Smyl", "Slawek", ""]]}, {"id": "2004.00530", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, Bo Dai, and Jiayu Zhou", "title": "Learning Sparse Rewarded Tasks from Sub-Optimal Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) has demonstrated its superiority\non many complex sequential decision-making problems. However, heavy dependence\non dense rewards and high sample-complexity impedes the wide adoption of these\nmethods in real-world scenarios. On the other hand, imitation learning (IL)\nlearns effectively in sparse-rewarded tasks by leveraging the existing expert\ndemonstrations. In practice, collecting a sufficient amount of expert\ndemonstrations can be prohibitively expensive, and the quality of\ndemonstrations typically limits the performance of the learning policy. In this\nwork, we propose Self-Adaptive Imitation Learning (SAIL) that can achieve\n(near) optimal performance given only a limited number of sub-optimal\ndemonstrations for highly challenging sparse reward tasks. SAIL bridges the\nadvantages of IL and RL to reduce the sample complexity substantially, by\neffectively exploiting sup-optimal demonstrations and efficiently exploring the\nenvironment to surpass the demonstrated performance. Extensive empirical\nresults show that not only does SAIL significantly improve the\nsample-efficiency but also leads to much better final performance across\ndifferent continuous control tasks, comparing to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:57:15 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Dai", "Bo", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2004.00540", "submitter": "Tomas Kulvicius", "authors": "Tomas Kulvicius, Sebastian Herzog, Minija Tamosiunaite and Florentin\n  W\\\"org\\\"otter", "title": "Generation of Paths in a Maze using a Deep Network without Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory- or path-planning is a fundamental issue in a wide variety of\napplications. Here we show that it is possible to solve path planning for\nmultiple start- and end-points highly efficiently with a network that consists\nonly of max pooling layers, for which no network training is needed. Different\nfrom competing approaches, very large mazes containing more than half a billion\nnodes with dense obstacle configuration and several thousand path end-points\ncan this way be solved in very short time on parallel hardware.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:08:45 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kulvicius", "Tomas", ""], ["Herzog", "Sebastian", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.00557", "submitter": "Lev Reyzin", "authors": "Lev Reyzin", "title": "Statistical Queries and Statistical Algorithms: Foundations and\n  Applications", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a survey of the foundations of statistical queries and their many\napplications to other areas. We introduce the model, give the main definitions,\nand we explore the fundamental theory statistical queries and how how it\nconnects to various notions of learnability. We also give a detailed summary of\nsome of the applications of statistical queries to other areas, including to\noptimization, to evolvability, and to differential privacy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:37:10 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 14:32:38 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Reyzin", "Lev", ""]]}, {"id": "2004.00558", "submitter": "Mariana Souza", "authors": "Mariana A. Souza, Robert Sabourin, George D. C. Cavalcanti and Rafael\n  M. O. Cruz", "title": "Multi-label learning for dynamic model type recommendation", "comments": "Paper accepted to the 2020 International Joint Conference on Neural\n  Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic selection techniques aim at selecting the local experts around each\ntest sample in particular for performing its classification. While generating\nthe classifier on a local scope may make it easier for singling out the locally\ncompetent ones, as in the online local pool (OLP) technique, using the same\nbase-classifier model in uneven distributions may restrict the local level of\ncompetence, since each region may have a data distribution that favors one\nmodel over the others. Thus, we propose in this work a problem-independent\ndynamic base-classifier model recommendation for the OLP technique, which uses\ninformation regarding the behavior of a portfolio of models over the samples of\ndifferent problems to recommend one (or several) of them on a per-instance\nmanner. Our proposed framework builds a multi-label meta-classifier responsible\nfor recommending a set of relevant model types based on the local data\ncomplexity of the region surrounding each test sample. The OLP technique then\nproduces a local pool with the model that yields the highest probability score\nof the meta-classifier. Experimental results show that different data\ndistributions favored different model types on a local scope. Moreover, based\non the performance of an ideal model type selector, it was observed that there\nis a clear advantage in choosing a relevant model type for each test instance.\nOverall, the proposed model type recommender system yielded a statistically\nsimilar performance to the original OLP with fixed base-classifier model. Given\nthe novelty of the approach and the gap in performance between the proposed\nframework and the ideal selector, we regard this as a promising research\ndirection. Code available at\ngithub.com/marianaasouza/dynamic-model-recommender.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:42:12 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Souza", "Mariana A.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""], ["Cruz", "Rafael M. O.", ""]]}, {"id": "2004.00566", "submitter": "Xun Xian", "authors": "Xun Xian, Xinran Wang, Jie Ding, Reza Ghanadan", "title": "Assisted Learning: A Framework for Multi-Organization Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasing number of AI scenarios, collaborations among different\norganizations or agents (e.g., human and robots, mobile units) are often\nessential to accomplish an organization-specific mission. However, to avoid\nleaking useful and possibly proprietary information, organizations typically\nenforce stringent security constraints on sharing modeling algorithms and data,\nwhich significantly limits collaborations. In this work, we introduce the\nAssisted Learning framework for organizations to assist each other in\nsupervised learning tasks without revealing any organization's algorithm, data,\nor even task. An organization seeks assistance by broadcasting task-specific\nbut nonsensitive statistics and incorporating others' feedback in one or more\niterations to eventually improve its predictive performance. Theoretical and\nexperimental studies, including real-world medical benchmarks, show that\nAssisted Learning can often achieve near-oracle learning performance as if data\nand training processes were centralized.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:54:49 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 23:22:35 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 02:34:01 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 19:04:24 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 06:35:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xian", "Xun", ""], ["Wang", "Xinran", ""], ["Ding", "Jie", ""], ["Ghanadan", "Reza", ""]]}, {"id": "2004.00567", "submitter": "Marco Pleines", "authors": "Marco Pleines, Jenia Jitsev, Mike Preuss, and Frank Zimmer", "title": "Obstacle Tower Without Human Demonstrations: How Far a Deep Feed-Forward\n  Network Goes with Reinforcement Learning", "comments": "8 pages, 9 figures, 2 tables, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Obstacle Tower Challenge is the task to master a procedurally generated\nchain of levels that subsequently get harder to complete. Whereas the most top\nperforming entries of last year's competition used human demonstrations or\nreward shaping to learn how to cope with the challenge, we present an approach\nthat performed competitively (placed 7th) but starts completely from scratch by\nmeans of Deep Reinforcement Learning with a relatively simple feed-forward deep\nnetwork structure. We especially look at the generalization performance of the\ntaken approach concerning different seeds and various visual themes that have\nbecome available after the competition, and investigate where the agent fails\nand why. Note that our approach does not possess a short-term memory like\nemploying recurrent hidden states. With this work, we hope to contribute to a\nbetter understanding of what is possible with a relatively simple, flexible\nsolution that can be applied to learning in environments featuring complex 3D\nvisual input where the abstract task structure itself is still fairly simple.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:55:51 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:07:52 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pleines", "Marco", ""], ["Jitsev", "Jenia", ""], ["Preuss", "Mike", ""], ["Zimmer", "Frank", ""]]}, {"id": "2004.00568", "submitter": "Tomas Kulvicius", "authors": "Tomas Kulvicius, Sebastian Herzog, Timo L\\\"uddecke, Minija\n  Tamosiunaite and Florentin W\\\"org\\\"otter", "title": "One-shot path planning for multi-agent systems using fully convolutional\n  neural network", "comments": null, "journal-ref": "The 3rd International Symposium on Swarm Behavior and Bioinspired\n  Robotics (SWARM 2019), November 20-22, Okinawa, Japan", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning plays a crucial role in robot action execution, since a path or\na motion trajectory for a particular action has to be defined first before the\naction can be executed. Most of the current approaches are iterative methods\nwhere the trajectory is generated iteratively by predicting the next state\nbased on the current state. Moreover, in case of multi-agent systems, paths are\nplanned for each agent separately. In contrast to that, we propose a novel\nmethod by utilising fully convolutional neural network, which allows generation\nof complete paths, even for more than one agent, in one-shot, i.e., with a\nsingle prediction step. We demonstrate that our method is able to successfully\ngenerate optimal or close to optimal paths in more than 98\\% of the cases for\nsingle path predictions. Moreover, we show that although the network has never\nbeen trained on multi-path planning it is also able to generate optimal or\nclose to optimal paths in 85.7\\% and 65.4\\% of the cases when generating two\nand three paths, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:56:39 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kulvicius", "Tomas", ""], ["Herzog", "Sebastian", ""], ["L\u00fcddecke", "Timo", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.00570", "submitter": "Brendon G. Anderson", "authors": "Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi", "title": "Tightened Convex Relaxations for Neural Network Robustness Certification", "comments": "Proceedings of the 59th IEEE Conference on Decision and Control, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of certifying the robustness of neural\nnetworks to perturbed and adversarial input data. Such certification is\nimperative for the application of neural networks in safety-critical\ndecision-making and control systems. Certification techniques using convex\noptimization have been proposed, but they often suffer from relaxation errors\nthat void the certificate. Our work exploits the structure of ReLU networks to\nimprove relaxation errors through a novel partition-based certification\nprocedure. The proposed method is proven to tighten existing linear programming\nrelaxations, and asymptotically achieves zero relaxation error as the partition\nis made finer. We develop a finite partition that attains zero relaxation error\nand use the result to derive a tractable partitioning scheme that minimizes the\nworst-case relaxation error. Experiments using real data show that the\npartitioning procedure is able to issue robustness certificates in cases where\nprior methods fail. Consequently, partition-based certification procedures are\nfound to provide an intuitive, effective, and theoretically justified method\nfor tightening existing convex relaxation techniques.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:59:21 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 00:04:58 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Anderson", "Brendon G.", ""], ["Ma", "Ziye", ""], ["Li", "Jingqi", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2004.00574", "submitter": "Henning Lange", "authors": "Henning Lange, Steven L. Brunton, Nathan Kutz", "title": "From Fourier to Koopman: Spectral Methods for Long-term Time Series\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose spectral methods for long-term forecasting of temporal signals\nstemming from linear and nonlinear quasi-periodic dynamical systems. For linear\nsignals, we introduce an algorithm with similarities to the Fourier transform\nbut which does not rely on periodicity assumptions, allowing for forecasting\ngiven potentially arbitrary sampling intervals. We then extend this algorithm\nto handle nonlinearities by leveraging Koopman theory. The resulting algorithm\nperforms a spectral decomposition in a nonlinear, data-dependent basis. The\noptimization objective for both algorithms is highly non-convex. However,\nexpressing the objective in the frequency domain allows us to compute global\noptima of the error surface in a scalable and efficient manner, partially by\nexploiting the computational properties of the Fast Fourier Transform. Because\nof their close relation to Bayesian Spectral Analysis, uncertainty\nquantification metrics are a natural byproduct of the spectral forecasting\nmethods. We extensively benchmark these algorithms against other leading\nforecasting methods on a range of synthetic experiments as well as in the\ncontext of real-world power systems and fluid flows.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:04:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lange", "Henning", ""], ["Brunton", "Steven L.", ""], ["Kutz", "Nathan", ""]]}, {"id": "2004.00601", "submitter": "Eduardo C. Garrido-Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an, Daniel Hern\\'andez-Lobato", "title": "Parallel Predictive Entropy Search for Multi-objective Bayesian\n  Optimization with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems often involve the optimization of several objectives\nunder multiple constraints. An example is the hyper-parameter tuning problem of\nmachine learning algorithms. In particular, the minimization of the estimation\nof the generalization error of a deep neural network and at the same time the\nminimization of its prediction time. We may also consider as a constraint that\nthe deep neural network must be implemented in a chip with an area below some\nsize. Here, both the objectives and the constraint are black boxes, i.e.,\nfunctions whose analytical expressions are unknown and are expensive to\nevaluate. Bayesian optimization (BO) methodologies have given state-of-the-art\nresults for the optimization of black-boxes. Nevertheless, most BO methods are\nsequential and evaluate the objectives and the constraints at just one input\nlocation, iteratively. Sometimes, however, we may have resources to evaluate\nseveral configurations in parallel. Notwithstanding, no parallel BO method has\nbeen proposed to deal with the optimization of multiple objectives under\nseveral constraints. If the expensive evaluations can be carried out in\nparallel (as when a cluster of computers is available), sequential evaluations\nresult in a waste of resources. This article introduces PPESMOC, Parallel\nPredictive Entropy Search for Multi-objective Bayesian Optimization with\nConstraints, an information-based batch method for the simultaneous\noptimization of multiple expensive-to-evaluate black-box functions under the\npresence of several constraints. Iteratively, PPESMOC selects a batch of input\nlocations at which to evaluate the black-boxes so as to maximally reduce the\nentropy of the Pareto set of the optimization problem. We present empirical\nevidence in the form of synthetic, benchmark and real-world experiments that\nillustrate the effectiveness of PPESMOC.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:37:58 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:29:30 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2004.00623", "submitter": "Filip Tronarp", "authors": "Filip Tronarp, Simo Sarkka, Philipp Hennig", "title": "Bayesian ODE Solvers: The Maximum A Posteriori Estimate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been established that the numerical solution of ordinary\ndifferential equations can be posed as a nonlinear Bayesian inference problem,\nwhich can be approximately solved via Gaussian filtering and smoothing,\nwhenever a Gauss--Markov prior is used. In this paper the class of $\\nu$ times\ndifferentiable linear time invariant Gauss--Markov priors is considered. A\ntaxonomy of Gaussian estimators is established, with the maximum a posteriori\nestimate at the top of the hierarchy, which can be computed with the iterated\nextended Kalman smoother. The remaining three classes are termed explicit,\nsemi-implicit, and implicit, which are in similarity with the classical notions\ncorresponding to conditions on the vector field, under which the filter update\nproduces a local maximum a posteriori estimate. The maximum a posteriori\nestimate corresponds to an optimal interpolant in the reproducing Hilbert space\nassociated with the prior, which in the present case is equivalent to a Sobolev\nspace of smoothness $\\nu+1$. Consequently, using methods from scattered data\napproximation and nonlinear analysis in Sobolev spaces, it is shown that the\nmaximum a posteriori estimate converges to the true solution at a polynomial\nrate in the fill-distance (maximum step size) subject to mild conditions on the\nvector field. The methodology developed provides a novel and more natural\napproach to study the convergence of these estimators than classical methods of\nconvergence analysis. The methods and theoretical results are demonstrated in\nnumerical examples.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:39:59 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 16:12:21 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Tronarp", "Filip", ""], ["Sarkka", "Simo", ""], ["Hennig", "Philipp", ""]]}, {"id": "2004.00642", "submitter": "Paul Henderson", "authors": "Titas Anciukevicius, Christoph H. Lampert, Paul Henderson", "title": "Object-Centric Image Generation with Factored Depths, Locations, and\n  Appearances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model of images that explicitly reasons over the set\nof objects they show. Our model learns a structured latent representation that\nseparates objects from each other and from the background; unlike prior works,\nit explicitly represents the 2D position and depth of each object, as well as\nan embedding of its segmentation mask and appearance. The model can be trained\nfrom images alone in a purely unsupervised fashion without the need for object\nmasks or depth information. Moreover, it always generates complete objects,\neven though a significant fraction of training images contain occlusions.\nFinally, we show that our model can infer decompositions of novel images into\ntheir constituent objects, including accurate prediction of depth ordering and\nsegmentation of occluded parts.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:00:11 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Anciukevicius", "Titas", ""], ["Lampert", "Christoph H.", ""], ["Henderson", "Paul", ""]]}, {"id": "2004.00658", "submitter": "Lukas Pfannschmidt", "authors": "Lukas Pfannschmidt, Barbara Hammer", "title": "Sequential Feature Classification in the Context of Redundancies", "comments": "Added new experiment and footnote to reproducable results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of all-relevant feature selection is concerned with finding a\nrelevant feature set with preserved redundancies. There exist several\napproximations to solve this problem but only one could give a distinction\nbetween strong and weak relevance. This approach was limited to the case of\nlinear problems. In this work, we present a new solution for this distinction\nin the non-linear case through the use of random forest models and statistical\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:20:51 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 23:09:13 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Pfannschmidt", "Lukas", ""], ["Hammer", "Barbara", ""]]}, {"id": "2004.00663", "submitter": "Tolga Birdal", "authors": "Tolga Birdal, Michael Arbel, Umut \\c{S}im\\c{s}ekli, and Leonidas\n  Guibas", "title": "Synchronizing Probability Measures on Rotations via Optimal Transport", "comments": "Accepted for publication at CVPR 2020, includes supplementary\n  material. Project website: https://github.com/SynchInVision/probsync", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new paradigm, $\\textit{measure synchronization}$, for\nsynchronizing graphs with measure-valued edges. We formulate this problem as\nmaximization of the cycle-consistency in the space of probability measures over\nrelative rotations. In particular, we aim at estimating marginal distributions\nof absolute orientations by synchronizing the $\\textit{conditional}$ ones,\nwhich are defined on the Riemannian manifold of quaternions. Such graph\noptimization on distributions-on-manifolds enables a natural treatment of\nmultimodal hypotheses, ambiguities and uncertainties arising in many computer\nvision applications such as SLAM, SfM, and object pose estimation. We first\nformally define the problem as a generalization of the classical rotation graph\nsynchronization, where in our case the vertices denote probability measures\nover rotations. We then measure the quality of the synchronization by using\nSinkhorn divergences, which reduces to other popular metrics such as\nWasserstein distance or the maximum mean discrepancy as limit cases. We propose\na nonparametric Riemannian particle optimization approach to solve the problem.\nEven though the problem is non-convex, by drawing a connection to the recently\nproposed sparse optimization methods, we show that the proposed algorithm\nconverges to the global optimum in a special case of the problem under certain\nconditions. Our qualitative and quantitative experiments show the validity of\nour approach and we bring in new perspectives to the study of synchronization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:44:18 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Birdal", "Tolga", ""], ["Arbel", "Michael", ""], ["\u015eim\u015fekli", "Umut", ""], ["Guibas", "Leonidas", ""]]}, {"id": "2004.00667", "submitter": "Gecheng Chen", "authors": "Gecheng Chen, Rui Tuo", "title": "Projection Pursuit Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary goal of computer experiments is to reconstruct the function given\nby the computer code via scattered evaluations. Traditional isotropic Gaussian\nprocess models suffer from the curse of dimensionality, when the input\ndimension is high. Gaussian process models with additive correlation functions\nare scalable to dimensionality, but they are very restrictive as they only work\nfor additive functions. In this work, we consider a projection pursuit model,\nin which the nonparametric part is driven by an additive Gaussian process\nregression. The dimension of the additive function is chosen to be higher than\nthe original input dimension. We show that this dimension expansion can help\napproximate more complex functions. A gradient descent algorithm is proposed to\nmaximize the likelihood function. Simulation studies show that the proposed\nmethod outperforms the traditional Gaussian process models.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 19:12:01 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Chen", "Gecheng", ""], ["Tuo", "Rui", ""]]}, {"id": "2004.00668", "submitter": "Ian Covert", "authors": "Ian Covert, Scott Lundberg, Su-In Lee", "title": "Understanding Global Feature Contributions With Additive Importance\n  Measures", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the inner workings of complex machine learning models is a\nlong-standing problem and most recent research has focused on local\ninterpretability. To assess the role of individual input features in a global\nsense, we explore the perspective of defining feature importance through the\npredictive power associated with each feature. We introduce two notions of\npredictive power (model-based and universal) and formalize this approach with a\nframework of additive importance measures, which unifies numerous methods in\nthe literature. We then propose SAGE, a model-agnostic method that quantifies\npredictive power while accounting for feature interactions. Our experiments\nshow that SAGE can be calculated efficiently and that it assigns more accurate\nimportance values than other methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 19:17:58 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 06:46:04 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Covert", "Ian", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "2004.00715", "submitter": "JInglai Li", "authors": "Ziqiao Ao and Jinglai Li", "title": "An approximate KLD based experimental design for models with intractable\n  likelihoods", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection is a critical step in statistical inference and data science,\nand the goal of statistical experimental design (ED) is to find the data\ncollection setup that can provide most information for the inference. In this\nwork we consider a special type of ED problems where the likelihoods are not\navailable in a closed form. In this case, the popular information-theoretic\nKullback-Leibler divergence (KLD) based design criterion can not be used\ndirectly, as it requires to evaluate the likelihood function. To address the\nissue, we derive a new utility function, which is a lower bound of the original\nKLD utility. This lower bound is expressed in terms of the summation of two or\nmore entropies in the data space, and thus can be evaluated efficiently via\nentropy estimation methods. We provide several numerical examples to\ndemonstrate the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 21:18:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:48:28 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ao", "Ziqiao", ""], ["Li", "Jinglai", ""]]}, {"id": "2004.00762", "submitter": "Michael Iuzzolino", "authors": "Michael L. Iuzzolino, Tetsumichi Umada, Nisar R. Ahmed, and Danielle\n  A. Szafir", "title": "In Automation We Trust: Investigating the Role of Uncertainty in Active\n  Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how different active learning (AL) query policies coupled with\nclassification uncertainty visualizations affect analyst trust in automated\nclassification systems. A current standard policy for AL is to query the oracle\n(e.g., the analyst) to refine labels for datapoints where the classifier has\nthe highest uncertainty. This is an optimal policy for the automation system as\nit yields maximal information gain. However, model-centric policies neglect the\neffects of this uncertainty on the human component of the system and the\nconsequent manner in which the human will interact with the system\npost-training. In this paper, we present an empirical study evaluating how AL\nquery policies and visualizations lending transparency to classification\ninfluence trust in automated classification of image data. We found that query\npolicy significantly influences an analyst's trust in an image classification\nsystem, and we use these results to propose a set of oracle query policies and\nvisualizations for use during AL training phases that can influence analyst\ntrust in classification.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 00:52:49 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Iuzzolino", "Michael L.", ""], ["Umada", "Tetsumichi", ""], ["Ahmed", "Nisar R.", ""], ["Szafir", "Danielle A.", ""]]}, {"id": "2004.00857", "submitter": "Manuel Schneckenreither", "authors": "Manuel Schneckenreither", "title": "Average Reward Adjusted Discounted Reinforcement Learning:\n  Near-Blackwell-Optimal Policies for Real-World Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although in recent years reinforcement learning has become very popular the\nnumber of successful applications to different kinds of operations research\nproblems is rather scarce. Reinforcement learning is based on the well-studied\ndynamic programming technique and thus also aims at finding the best stationary\npolicy for a given Markov Decision Process, but in contrast does not require\nany model knowledge. The policy is assessed solely on consecutive states (or\nstate-action pairs), which are observed while an agent explores the solution\nspace. The contributions of this paper are manifold. First we provide deep\ntheoretical insights to the widely applied standard discounted reinforcement\nlearning framework, which give rise to the understanding of why these\nalgorithms are inappropriate when permanently provided with non-zero rewards,\nsuch as costs or profit. Second, we establish a novel near-Blackwell-optimal\nreinforcement learning algorithm. In contrary to former method it assesses the\naverage reward per step separately and thus prevents the incautious combination\nof different types of state values. Thereby, the Laurent Series expansion of\nthe discounted state values forms the foundation for this development and also\nprovides the connection between the two approaches. Finally, we prove the\nviability of our algorithm on a challenging problem set, which includes a\nwell-studied M/M/1 admission control queuing system. In contrast to standard\ndiscounted reinforcement learning our algorithm infers the optimal policy on\nall tested problems. The insights are that in the operations research domain\nmachine learning techniques have to be adapted and advanced to successfully\napply these methods in our settings.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:05:18 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Schneckenreither", "Manuel", ""]]}, {"id": "2004.00891", "submitter": "Mattes Mollenhauer", "authors": "Mattes Mollenhauer, Stefan Klus, Christof Sch\\\"utte, P\\'eter Koltai", "title": "Kernel autocovariance operators of stationary processes: Estimation and\n  convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider autocovariance operators of a stationary stochastic process on a\nPolish space that is embedded into a reproducing kernel Hilbert space. We\ninvestigate how empirical estimates of these operators converge along\nrealizations of the process under various conditions. In particular, we examine\nergodic and strongly mixing processes and prove several asymptotic results as\nwell as finite sample error bounds with a detailed analysis for the Gaussian\nkernel. We provide applications of our theory in terms of consistency results\nfor kernel PCA with dependent data and the conditional mean embedding of\ntransition probabilities. Finally, we use our approach to examine the\nnonparametric estimation of Markov transition operators and highlight how our\ntheory can give a consistency analysis for a large family of spectral analysis\nmethods including kernel-based dynamic mode decomposition.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 09:17:32 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Mollenhauer", "Mattes", ""], ["Klus", "Stefan", ""], ["Sch\u00fctte", "Christof", ""], ["Koltai", "P\u00e9ter", ""]]}, {"id": "2004.00909", "submitter": "Ankit Dhall", "authors": "Ankit Dhall", "title": "Learning Representations For Images With Hierarchical Labels", "comments": "Master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has been studied extensively but there has been limited\nwork in the direction of using non-conventional, external guidance other than\ntraditional image-label pairs to train such models. In this thesis we present a\nset of methods to leverage information about the semantic hierarchy induced by\nclass labels. In the first part of the thesis, we inject label-hierarchy\nknowledge to an arbitrary classifier and empirically show that availability of\nsuch external semantic information in conjunction with the visual semantics\nfrom images boosts overall performance. Taking a step further in this\ndirection, we model more explicitly the label-label and label-image\ninteractions by using order-preserving embedding-based models, prevalent in\nnatural language, and tailor them to the domain of computer vision to perform\nimage classification. Although, contrasting in nature, both the CNN-classifiers\ninjected with hierarchical information, and the embedding-based models\noutperform a hierarchy-agnostic model on the newly presented, real-world ETH\nEntomological Collection image dataset\nhttps://www.research-collection.ethz.ch/handle/20.500.11850/365379.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 09:56:03 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 17:51:39 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dhall", "Ankit", ""]]}, {"id": "2004.00974", "submitter": "Sourya Dey", "authors": "Sourya Dey, Saikrishna C. Kanala, Keith M. Chugg, Peter A. Beerel", "title": "Deep-n-Cheap: An Automated Search Framework for Low Complexity Deep\n  Learning", "comments": "Accepted as a conference paper at ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep-n-Cheap -- an open-source AutoML framework to search for deep\nlearning models. This search includes both architecture and training\nhyperparameters, and supports convolutional neural networks and multi-layer\nperceptrons. Our framework is targeted for deployment on both benchmark and\ncustom datasets, and as a result, offers a greater degree of search space\ncustomizability as compared to a more limited search over only pre-existing\nmodels from literature. We also introduce the technique of 'search transfer',\nwhich demonstrates the generalization capabilities of the models found by our\nframework to multiple datasets.\n  Deep-n-Cheap includes a user-customizable complexity penalty which trades off\nperformance with training time or number of parameters. Specifically, our\nframework results in models offering performance comparable to state-of-the-art\nwhile taking 1-2 orders of magnitude less time to train than models from other\nAutoML and model search frameworks. Additionally, this work investigates and\ndevelops various insights regarding the search process. In particular, we show\nthe superiority of a greedy strategy and justify our choice of Bayesian\noptimization as the primary search methodology over random / grid search.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 13:00:21 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 01:29:44 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 21:24:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Dey", "Sourya", ""], ["Kanala", "Saikrishna C.", ""], ["Chugg", "Keith M.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2004.00979", "submitter": "G\\\"unter Klambauer", "authors": "Markus Hofmarcher, Andreas Mayr, Elisabeth Rumetshofer, Peter Ruch,\n  Philipp Renz, Johannes Schimunek, Philipp Seidl, Andreu Vall, Michael\n  Widrich, Sepp Hochreiter, G\\\"unter Klambauer", "title": "Large-scale ligand-based virtual screening for SARS-CoV-2 inhibitors\n  using deep neural networks", "comments": "Additional results added. Various corrections to formulations and\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the current severe acute respiratory syndrome coronavirus 2\n(SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs.\nWe conducted a large-scale virtual screening for small molecules that are\npotential CoV-2 inhibitors. To this end, we utilized \"ChemAI\", a deep neural\nnetwork trained on more than 220M data points across 3.6M molecules from three\npublic drug-discovery databases. With ChemAI, we screened and ranked one\nbillion molecules from the ZINC database for favourable effects against CoV-2.\nWe then reduced the result to the 30,000 top-ranked compounds, which are\nreadily accessible and purchasable via the ZINC database. Additionally, we\nscreened the DrugBank using ChemAI to allow for drug repurposing, which would\nbe a fast way towards a therapy. We provide these top-ranked compounds of ZINC\nand DrugBank as a library for further screening with bioassays at\nhttps://github.com/ml-jku/sars-cov-inhibitors-chemai.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:24:09 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 09:10:24 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 15:58:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Hofmarcher", "Markus", ""], ["Mayr", "Andreas", ""], ["Rumetshofer", "Elisabeth", ""], ["Ruch", "Peter", ""], ["Renz", "Philipp", ""], ["Schimunek", "Johannes", ""], ["Seidl", "Philipp", ""], ["Vall", "Andreu", ""], ["Widrich", "Michael", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "2004.00994", "submitter": "Uri Shaham", "authors": "Uri Shaham, Tom Zahavy, Cesar Caraballo, Shiwani Mahajan, Daisy\n  Massey, Harlan Krumholz", "title": "Learning to Ask Medical Questions using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reinforcement learning-based approach for adaptive and\niterative feature selection. Given a masked vector of input features, a\nreinforcement learning agent iteratively selects certain features to be\nunmasked, and uses them to predict an outcome when it is sufficiently\nconfident. The algorithm makes use of a novel environment setting,\ncorresponding to a non-stationary Markov Decision Process. A key component of\nour approach is a guesser network, trained to predict the outcome from the\nselected features and parametrizing the reward function. Applying our method to\na national survey dataset, we show that it not only outperforms strong\nbaselines when requiring the prediction to be made based on a small number of\ninput features, but is also highly more interpretable. Our code is publicly\navailable at \\url{https://github.com/ushaham/adaptiveFS}.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:21:46 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 08:13:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Shaham", "Uri", ""], ["Zahavy", "Tom", ""], ["Caraballo", "Cesar", ""], ["Mahajan", "Shiwani", ""], ["Massey", "Daisy", ""], ["Krumholz", "Harlan", ""]]}, {"id": "2004.01022", "submitter": "Adarsh Barik", "authors": "Adarsh Barik, Jean Honorio", "title": "Provable Sample Complexity Guarantees for Learning of Continuous-Action\n  Graphical Games with Nonparametric Utilities", "comments": "arXiv admin note: text overlap with arXiv:1911.04225", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning the exact structure of\ncontinuous-action games with non-parametric utility functions. We propose an\n$\\ell_1$ regularized method which encourages sparsity of the coefficients of\nthe Fourier transform of the recovered utilities. Our method works by accessing\nvery few Nash equilibria and their noisy utilities. Under certain technical\nconditions, our method also recovers the exact structure of these utility\nfunctions, and thus, the exact structure of the game. Furthermore, our method\nonly needs a logarithmic number of samples in terms of the number of players\nand runs in polynomial time. We follow the primal-dual witness framework to\nprovide provable theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:32:27 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "2004.01024", "submitter": "Hansheng Xue", "authors": "Hansheng Xue, Luwei Yang, Wen Jiang, Yi Wei, Yi Hu, and Yu Lin", "title": "Modeling Dynamic Heterogeneous Network for Link Prediction using\n  Hierarchical Attention with Temporal RNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding aims to learn low-dimensional representations of nodes\nwhile capturing structure information of networks. It has achieved great\nsuccess on many tasks of network analysis such as link prediction and node\nclassification. Most of existing network embedding algorithms focus on how to\nlearn static homogeneous networks effectively. However, networks in the real\nworld are more complex, e.g., networks may consist of several types of nodes\nand edges (called heterogeneous information) and may vary over time in terms of\ndynamic nodes and edges (called evolutionary patterns). Limited work has been\ndone for network embedding of dynamic heterogeneous networks as it is\nchallenging to learn both evolutionary and heterogeneous information\nsimultaneously. In this paper, we propose a novel dynamic heterogeneous network\nembedding method, termed as DyHATR, which uses hierarchical attention to learn\nheterogeneous information and incorporates recurrent neural networks with\ntemporal attention to capture evolutionary patterns. We benchmark our method on\nfour real-world datasets for the task of link prediction. Experimental results\nshow that DyHATR significantly outperforms several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:16:47 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Xue", "Hansheng", ""], ["Yang", "Luwei", ""], ["Jiang", "Wen", ""], ["Wei", "Yi", ""], ["Hu", "Yi", ""], ["Lin", "Yu", ""]]}, {"id": "2004.01025", "submitter": "Suriya Gunasekar", "authors": "Suriya Gunasekar, Blake Woodworth, Nathan Srebro", "title": "Mirrorless Mirror Descent: A Natural Derivation of Mirror Descent", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a primal only derivation of Mirror Descent as a \"partial\"\ndiscretization of gradient flow on a Riemannian manifold where the metric\ntensor is the Hessian of the Mirror Descent potential. We contrast this\ndiscretization to Natural Gradient Descent, which is obtained by a \"full\"\nforward Euler discretization. This view helps shed light on the relationship\nbetween the methods and allows generalizing Mirror Descent to general\nRiemannian geometries, even when the metric tensor is {\\em not} a Hessian, and\nthus there is no \"dual.\"\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 14:31:04 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:49:21 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 00:33:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gunasekar", "Suriya", ""], ["Woodworth", "Blake", ""], ["Srebro", "Nathan", ""]]}, {"id": "2004.01028", "submitter": "Christos Fotis", "authors": "C. Fotis, N. Meimetis, A. Sardis and L.G. Alexopoulos", "title": "DeepSIBA: Chemical Structure-based Inference of Biological Alterations", "comments": "Article: 19 pages, Electronic Supplementary Information (included):\n  16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting whether a chemical structure shares a desired biological effect\ncan have a significant impact for in-silico compound screening in early drug\ndiscovery. In this study, we developed a deep learning model where compound\nstructures are represented as graphs and then linked to their biological\nfootprint. To make this complex problem computationally tractable, compound\ndifferences were mapped to biological effect alterations using Siamese Graph\nConvolutional Neural Networks. The proposed model was able to learn new\nrepresentations from chemical structures and identify structurally dissimilar\ncompounds that affect similar biological processes with high precision.\nAdditionally, by utilizing deep ensembles to estimate uncertainty, we were able\nto provide reliable and accurate predictions for chemical structures that are\nvery different from the ones used during training. Finally, we present a novel\ninference approach, where the trained models are used to estimate the signaling\npathways affected by a compound perturbation in a specific cell line, using\nonly its chemical structure as input. As a use case, this approach was used to\ninfer signaling pathways affected by FDA-approved anticancer drugs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:29:45 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Fotis", "C.", ""], ["Meimetis", "N.", ""], ["Sardis", "A.", ""], ["Alexopoulos", "L. G.", ""]]}, {"id": "2004.01077", "submitter": "Daniel Becking", "authors": "Arturo Marban, Daniel Becking, Simon Wiedemann and Wojciech Samek", "title": "Learning Sparse & Ternary Neural Networks with Entropy-Constrained\n  Trained Ternarization (EC2T)", "comments": "Proceedings of the CVPR'20 Joint Workshop on Efficient Deep Learning\n  in Computer Vision. Code is available at\n  https://github.com/d-becking/efficientCNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have shown remarkable success in a variety of\nmachine learning applications. The capacity of these models (i.e., number of\nparameters), endows them with expressive power and allows them to reach the\ndesired performance. In recent years, there is an increasing interest in\ndeploying DNNs to resource-constrained devices (i.e., mobile devices) with\nlimited energy, memory, and computational budget. To address this problem, we\npropose Entropy-Constrained Trained Ternarization (EC2T), a general framework\nto create sparse and ternary neural networks which are efficient in terms of\nstorage (e.g., at most two binary-masks and two full-precision values are\nrequired to save a weight matrix) and computation (e.g., MAC operations are\nreduced to a few accumulations plus two multiplications). This approach\nconsists of two steps. First, a super-network is created by scaling the\ndimensions of a pre-trained model (i.e., its width and depth). Subsequently,\nthis super-network is simultaneously pruned (using an entropy constraint) and\nquantized (that is, ternary values are assigned layer-wise) in a training\nprocess, resulting in a sparse and ternary network representation. We validate\nthe proposed approach in CIFAR-10, CIFAR-100, and ImageNet datasets, showing\nits effectiveness in image classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:38:00 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 09:37:47 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Marban", "Arturo", ""], ["Becking", "Daniel", ""], ["Wiedemann", "Simon", ""], ["Samek", "Wojciech", ""]]}, {"id": "2004.01097", "submitter": "Ivana Kaji\\'c", "authors": "Ivana Kaji\\'c, Eser Ayg\\\"un and Doina Precup", "title": "Learning to cooperate: Emergent communication in multi-agent navigation", "comments": "Accepted to CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent communication in artificial agents has been studied to understand\nlanguage evolution, as well as to develop artificial systems that learn to\ncommunicate with humans. We show that agents performing a cooperative\nnavigation task in various gridworld environments learn an interpretable\ncommunication protocol that enables them to efficiently, and in many cases,\noptimally, solve the task. An analysis of the agents' policies reveals that\nemergent signals spatially cluster the state space, with signals referring to\nspecific locations and spatial directions such as \"left\", \"up\", or \"upper left\nroom\". Using populations of agents, we show that the emergent protocol has\nbasic compositional structure, thus exhibiting a core property of natural\nlanguage.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:03:17 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:13:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kaji\u0107", "Ivana", ""], ["Ayg\u00fcn", "Eser", ""], ["Precup", "Doina", ""]]}, {"id": "2004.01123", "submitter": "Sergey Kovalchuk", "authors": "Anastasia A. Funkner, Aleksey N. Yakovlev, Sergey V. Kovalchuk", "title": "Surrogate-assisted performance tuning of knowledge discovery algorithms:\n  application to clinical pathway evolutionary modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an approach for surrogate-assisted tuning of knowledge\ndiscovery algorithms. The approach is based on the prediction of both the\nquality and performance of the target algorithm. The prediction is furtherly\nused as objectives for the optimization and tuning of the algorithm. The\napproach is investigated using clinical pathways (CP) discovery problem\nresolved using the evolutionary-based clustering of electronic health records\n(EHR). Target algorithm and the proposed approach were applied to the discovery\nof CPs for Acute Coronary Syndrome patients in 3434 EHRs of patients treated in\nAlmazov National Medical Research Center (Saint Petersburg, Russia). The study\ninvestigates the possible acquisition of interpretable clusters of typical CPs\nwithin a single disease. It shows how the approach could be used to improve\ncomplex data-driven analytical knowledge discovery algorithms. The study of the\nresults includes the feature importance of the best surrogate model and\ndiscover how the parameters of input data influence the predictions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:49:43 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Funkner", "Anastasia A.", ""], ["Yakovlev", "Aleksey N.", ""], ["Kovalchuk", "Sergey V.", ""]]}, {"id": "2004.01136", "submitter": "Mengyue Yang", "authors": "Mengyue Yang, Qingyang Li, Zhiwei Qin, Jieping Ye", "title": "Hierarchical Adaptive Contextual Bandits for Resource Constraint based\n  Recommendation", "comments": "Accepted for publication at WWW (The Web Conference) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380115", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual multi-armed bandit (MAB) achieves cutting-edge performance on a\nvariety of problems. When it comes to real-world scenarios such as\nrecommendation system and online advertising, however, it is essential to\nconsider the resource consumption of exploration. In practice, there is\ntypically non-zero cost associated with executing a recommendation (arm) in the\nenvironment, and hence, the policy should be learned with a fixed exploration\ncost constraint. It is challenging to learn a global optimal policy directly,\nsince it is a NP-hard problem and significantly complicates the exploration and\nexploitation trade-off of bandit algorithms. Existing approaches focus on\nsolving the problems by adopting the greedy policy which estimates the expected\nrewards and costs and uses a greedy selection based on each arm's expected\nreward/cost ratio using historical observation until the exploration resource\nis exhausted. However, existing methods are hard to extend to infinite time\nhorizon, since the learning process will be terminated when there is no more\nresource. In this paper, we propose a hierarchical adaptive contextual bandit\nmethod (HATCH) to conduct the policy learning of contextual bandits with a\nbudget constraint. HATCH adopts an adaptive method to allocate the exploration\nresource based on the remaining resource/time and the estimation of reward\ndistribution among different user contexts. In addition, we utilize full of\ncontextual feature information to find the best personalized recommendation.\nFinally, in order to prove the theoretical guarantee, we present a regret bound\nanalysis and prove that HATCH achieves a regret bound as low as $O(\\sqrt{T})$.\nThe experimental results demonstrate the effectiveness and efficiency of the\nproposed method on both synthetic data sets and the real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:04:52 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 16:56:29 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yang", "Mengyue", ""], ["Li", "Qingyang", ""], ["Qin", "Zhiwei", ""], ["Ye", "Jieping", ""]]}, {"id": "2004.01141", "submitter": "Simon Lindst{\\aa}hl", "authors": "Simon Lindst{\\aa}hl, Alexandre Proutiere, Andreas Johnsson", "title": "Predictive Bandits", "comments": "10 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a new class of stochastic bandit problems, referred to\nas predictive bandits. In each round, the decision maker first decides whether\nto gather information about the rewards of particular arms (so that their\nrewards in this round can be predicted). These measurements are costly, and may\nbe corrupted by noise. The decision maker then selects an arm to be actually\nplayed in the round. Predictive bandits find applications in many areas; e.g.\nthey can be applied to channel selection problems in radio communication\nsystems. In this paper, we provide the first theoretical results about\npredictive bandits, and focus on scenarios where the decision maker is allowed\nto measure at most one arm per round. We derive asymptotic instance-specific\nregret lower bounds for these problems, and develop algorithms whose regret\nmatch these fundamental limits. We illustrate the performance of our algorithms\nthrough numerical experiments. In particular, we highlight the gains that can\nbe achieved by using reward predictions, and investigate the impact of the\nnoise in the corresponding measurements.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:12:33 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Lindst\u00e5hl", "Simon", ""], ["Proutiere", "Alexandre", ""], ["Johnsson", "Andreas", ""]]}, {"id": "2004.01143", "submitter": "Ping Li", "authors": "Xiaoyun Li, Jie Gui, Ping Li", "title": "Randomized Kernel Multi-view Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many artificial intelligence and computer vision systems, the same object\ncan be observed at distinct viewpoints or by diverse sensors, which raises the\nchallenges for recognizing objects from different, even heterogeneous views.\nMulti-view discriminant analysis (MvDA) is an effective multi-view subspace\nlearning method, which finds a discriminant common subspace by jointly learning\nmultiple view-specific linear projections for object recognition from multiple\nviews, in a non-pairwise way. In this paper, we propose the kernel version of\nmulti-view discriminant analysis, called kernel multi-view discriminant\nanalysis (KMvDA). To overcome the well-known computational bottleneck of kernel\nmethods, we also study the performance of using random Fourier features (RFF)\nto approximate Gaussian kernels in KMvDA, for large scale learning. Theoretical\nanalysis on stability of this approximation is developed. We also conduct\nexperiments on several popular multi-view datasets to illustrate the\neffectiveness of our proposed strategy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:15:32 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Li", "Xiaoyun", ""], ["Gui", "Jie", ""], ["Li", "Ping", ""]]}, {"id": "2004.01144", "submitter": "Yingqi Gu", "authors": "Yingqi Gu, Akshay Zalkikar, Lara Kelly, Kieran Daly, Tomas E. Ward", "title": "Predicting Injectable Medication Adherence via a Smart Sharps Bin and\n  Machine Learning", "comments": "This paper has been accepted by IEEE IoT World Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medication non-adherence is a widespread problem affecting over 50% of people\nwho have chronic illness and need chronic treatment. Non-adherence exacerbates\nhealth risks and drives significant increases in treatment costs. In order to\naddress these challenges, the importance of predicting patients' adherence has\nbeen recognised. In other words, it is important to improve the efficiency of\ninterventions of the current healthcare system by prioritizing resources to the\npatients who are most likely to be non-adherent. Our objective in this work is\nto make predictions regarding individual patients' behaviour in terms of taking\ntheir medication on time during their next scheduled medication opportunity. We\ndo this by leveraging a number of machine learning models. In particular, we\ndemonstrate the use of a connected IoT device; a \"Smart Sharps Bin\", invented\nby HealthBeacon Ltd.; to monitor and track injection disposal of patients in\ntheir home environment. Using extensive data collected from these devices, five\nmachine learning models, namely Extra Trees Classifier, Random Forest, XGBoost,\nGradient Boosting and Multilayer Perception were trained and evaluated on a\nlarge dataset comprising 165,223 historic injection disposal records collected\nfrom 5,915 HealthBeacon units over the course of 3 years. The testing work was\nconducted on real-time data generated by the smart device over a time period\nafter the model training was complete, i.e. true future data. The proposed\nmachine learning approach demonstrated very good predictive performance\nexhibiting an Area Under the Receiver Operating Characteristic Curve (ROC AUC)\nof 0.86.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:16:51 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Gu", "Yingqi", ""], ["Zalkikar", "Akshay", ""], ["Kelly", "Lara", ""], ["Daly", "Kieran", ""], ["Ward", "Tomas E.", ""]]}, {"id": "2004.01157", "submitter": "Jaron Jia Rong Lee", "authors": "Jaron J. R. Lee, Ilya Shpitser", "title": "Identification Methods With Arbitrary Interventional Distributions as\n  Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference quantifies cause-effect relationships by estimating\ncounterfactual parameters from data. This entails using \\emph{identification\ntheory} to establish a link between counterfactual parameters of interest and\ndistributions from which data is available. A line of work characterized\nnon-parametric identification for a wide variety of causal parameters in terms\nof the \\emph{observed data distribution}. More recently, identification results\nhave been extended to settings where experimental data from interventional\ndistributions is also available. In this paper, we use Single World\nIntervention Graphs and a nested factorization of models associated with mixed\ngraphs to give a very simple view of existing identification theory for\nexperimental data. We use this view to yield general identification algorithms\nfor settings where the input distributions consist of an arbitrary set of\nobservational and experimental distributions, including marginal and\nconditional distributions. We show that for problems where inputs are\ninterventional marginal distributions of a certain type (ancestral marginals),\nour algorithm is complete.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:27:18 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 16:43:19 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lee", "Jaron J. R.", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2004.01181", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Simon Alford, Vijay Gadepally, Michael Jones, Lauren\n  Milechin, Albert Reuther, Ryan Robinett, Sid Samsi", "title": "GraphChallenge.org Sparse Deep Neural Network Performance", "comments": "7 pages, 7 figures, 80 references, to be submitted to IEEE HPEC 2020.\n  This work reports new updated results on prior work reported in\n  arXiv:1909.05631. arXiv admin note: substantial text overlap with\n  arXiv:1807.03165, arXiv:1708.02937. arXiv admin note: text overlap with\n  arXiv:2003.09269", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286253", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to\ndeveloping new solutions for analyzing graphs and sparse data. Sparse AI\nanalytics present unique scalability difficulties. The Sparse Deep Neural\nNetwork (DNN) Challenge draws upon prior challenges from machine learning, high\nperformance computing, and visual analytics to create a challenge that is\nreflective of emerging sparse AI systems. The sparse DNN challenge is based on\na mathematically well-defined DNN inference computation and can be implemented\nin any programming environment. In 2019 several sparse DNN challenge\nsubmissions were received from a wide range of authors and organizations. This\npaper presents a performance analysis of the best performers of these\nsubmissions. These submissions show that their state-of-the-art sparse DNN\nexecution time, $T_{\\rm DNN}$, is a strong function of the number of DNN\noperations performed, $N_{\\rm op}$. The sparse DNN challenge provides a clear\npicture of current sparse DNN systems and underscores the need for new\ninnovations to achieve high performance on very large sparse DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 00:29:12 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 02:38:52 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kepner", "Jeremy", ""], ["Alford", "Simon", ""], ["Gadepally", "Vijay", ""], ["Jones", "Michael", ""], ["Milechin", "Lauren", ""], ["Reuther", "Albert", ""], ["Robinett", "Ryan", ""], ["Samsi", "Sid", ""]]}, {"id": "2004.01190", "submitter": "Gadi Naveh", "authors": "Gadi Naveh, Oded Ben-David, Haim Sompolinsky and Zohar Ringel", "title": "Predicting the outputs of finite networks trained with noisy gradients", "comments": "8 pages + appendix, 7 figures overall", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of works studied wide deep neural networks (DNNs) by\napproximating them as Gaussian Processes (GPs). A DNN trained with gradient\nflow was shown to map to a GP governed by the Neural Tangent Kernel (NTK),\nwhereas earlier works showed that a DNN with an i.i.d. prior over its weights\nmaps to the so-called Neural Network Gaussian Process (NNGP). Here we consider\na DNN training protocol, involving noise, weight decay and finite width, whose\noutcome corresponds to a certain non-Gaussian stochastic process. An analytical\nframework is then introduced to analyze this non-Gaussian process, whose\ndeviation from a GP is controlled by the finite width. Our contribution is\nthree-fold: (i) In the infinite width limit, we establish a correspondence\nbetween DNNs trained with noisy gradients and the NNGP, not the NTK. (ii) We\nprovide a general analytical form for the finite width correction (FWC) for\nDNNs with arbitrary activation functions and depth and use it to predict the\noutputs of empirical finite networks with high accuracy. Analyzing the FWC\nbehavior as a function of $n$, the training set size, we find that it is\nnegligible for both the very small $n$ regime, and, surprisingly, for the large\n$n$ regime (where the GP error scales as $O(1/n)$). (iii) We flesh-out\nalgebraically how these FWCs can improve the performance of finite\nconvolutional neural networks (CNNs) relative to their GP counterparts on image\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:00:01 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 10:17:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Naveh", "Gadi", ""], ["Ben-David", "Oded", ""], ["Sompolinsky", "Haim", ""], ["Ringel", "Zohar", ""]]}, {"id": "2004.01215", "submitter": "Inkit Padhi", "authors": "Vijil Chenthamarakshan, Payel Das, Samuel C. Hoffman, Hendrik\n  Strobelt, Inkit Padhi, Kar Wai Lim, Benjamin Hoover, Matteo Manica, Jannis\n  Born, Teodoro Laino, Aleksandra Mojsilovic", "title": "CogMol: Target-Specific and Selective Drug Design for COVID-19 Using\n  Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel nature of SARS-CoV-2 calls for the development of efficient de novo\ndrug design approaches. In this study, we propose an end-to-end framework,\nnamed CogMol (Controlled Generation of Molecules), for designing new drug-like\nsmall molecules targeting novel viral proteins with high affinity and\noff-target selectivity. CogMol combines adaptive pre-training of a molecular\nSMILES Variational Autoencoder (VAE) and an efficient multi-attribute\ncontrolled sampling scheme that uses guidance from attribute predictors trained\non latent features. To generate novel and optimal drug-like molecules for\nunseen viral targets, CogMol leverages a protein-molecule binding affinity\npredictor that is trained using SMILES VAE embeddings and protein sequence\nembeddings learned unsupervised from a large corpus. CogMol framework is\napplied to three SARS-CoV-2 target proteins: main protease, receptor-binding\ndomain of the spike protein, and non-structural protein 9 replicase. The\ngenerated candidates are novel at both molecular and chemical scaffold levels\nwhen compared to the training data. CogMol also includes insilico screening for\nassessing toxicity of parent molecules and their metabolites with a multi-task\ntoxicity classifier, synthetic feasibility with a chemical retrosynthesis\npredictor, and target structure binding with docking simulations. Docking\nreveals favorable binding of generated molecules to the target protein\nstructure, where 87-95 % of high affinity molecules showed docking free energy\n< -6 kcal/mol. When compared to approved drugs, the majority of designed\ncompounds show low parent molecule and metabolite toxicity and high synthetic\nfeasibility. In summary, CogMol handles multi-constraint design of\nsynthesizable, low-toxic, drug-like molecules with high target specificity and\nselectivity, and does not need target-dependent fine-tuning of the framework or\ntarget structure information.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:17:20 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 00:16:56 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chenthamarakshan", "Vijil", ""], ["Das", "Payel", ""], ["Hoffman", "Samuel C.", ""], ["Strobelt", "Hendrik", ""], ["Padhi", "Inkit", ""], ["Lim", "Kar Wai", ""], ["Hoover", "Benjamin", ""], ["Manica", "Matteo", ""], ["Born", "Jannis", ""], ["Laino", "Teodoro", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "2004.01221", "submitter": "Sriram Ganapathy", "authors": "Bharat Padi, Anand Mohan and Sriram Ganapathy", "title": "Towards Relevance and Sequence Modeling in Language Recognition", "comments": "https://github.com/iiscleap/lre-relevance-weighting Accepted to IEEE\n  Transactions on Audio, Speech and Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of automatic language identification (LID) involving multiple\ndialects of the same language family in the presence of noise is a challenging\nproblem. In these scenarios, the identity of the language/dialect may be\nreliably present only in parts of the temporal sequence of the speech signal.\nThe conventional approaches to LID (and for speaker recognition) ignore the\nsequence information by extracting long-term statistical summary of the\nrecording assuming an independence of the feature frames. In this paper, we\npropose a neural network framework utilizing short-sequence information in\nlanguage recognition. In particular, a new model is proposed for incorporating\nrelevance in language recognition, where parts of speech data are weighted more\nbased on their relevance for the language recognition task. This relevance\nweighting is achieved using the bidirectional long short-term memory (BLSTM)\nnetwork with attention modeling. We explore two approaches, the first approach\nuses segment level i-vector/x-vector representations that are aggregated in the\nneural model and the second approach where the acoustic features are directly\nmodeled in an end-to-end neural model. Experiments are performed using the\nlanguage recognition task in NIST LRE 2017 Challenge using clean, noisy and\nmulti-speaker speech data as well as in the RATS language recognition corpus.\nIn these experiments on noisy LRE tasks as well as the RATS dataset, the\nproposed approach yields significant improvements over the conventional\ni-vector/x-vector based language recognition approaches as well as with other\nprevious models incorporating sequence information.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:31:18 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Padi", "Bharat", ""], ["Mohan", "Anand", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2004.01258", "submitter": "Ying-Cheng Lai", "authors": "Huawei Fan, Junjie Jiang, Chun Zhang, Xingang Wang, and Ying-Cheng Lai", "title": "Long-term prediction of chaotic systems with recurrent neural networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing systems, a class of recurrent neural networks, have\nrecently been exploited for model-free, data-based prediction of the state\nevolution of a variety of chaotic dynamical systems. The prediction horizon\ndemonstrated has been about half dozen Lyapunov time. Is it possible to\nsignificantly extend the prediction time beyond what has been achieved so far?\nWe articulate a scheme incorporating time-dependent but sparse data inputs into\nreservoir computing and demonstrate that such rare \"updates\" of the actual\nstate practically enable an arbitrarily long prediction horizon for a variety\nof chaotic systems. A physical understanding based on the theory of temporal\nsynchronization is developed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 18:59:44 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fan", "Huawei", ""], ["Jiang", "Junjie", ""], ["Zhang", "Chun", ""], ["Wang", "Xingang", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "2004.01275", "submitter": "Usama Masood", "authors": "Ali Imran, Iryna Posokhova, Haneya N. Qureshi, Usama Masood, Muhammad\n  Sajid Riaz, Kamran Ali, Charles N. John, MD Iftikhar Hussain, Muhammad Nabeel", "title": "AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough\n  Samples via an App", "comments": "Accepted in Informatics in Medicine Unlocked 2020", "journal-ref": "Informatics in Medicine Unlocked, vol. 20, p. 100378, 2020", "doi": "10.1016/j.imu.2020.100378", "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The inability to test at scale has become humanity's Achille's\nheel in the ongoing war against the COVID-19 pandemic. A scalable screening\ntool would be a game changer. Building on the prior work on cough-based\ndiagnosis of respiratory diseases, we propose, develop and test an Artificial\nIntelligence (AI)-powered screening solution for COVID-19 infection that is\ndeployable via a smartphone app. The app, named AI4COVID-19 records and sends\nthree 3-second cough sounds to an AI engine running in the cloud, and returns a\nresult within two minutes. Methods: Cough is a symptom of over thirty\nnon-COVID-19 related medical conditions. This makes the diagnosis of a COVID-19\ninfection by cough alone an extremely challenging multidisciplinary problem. We\naddress this problem by investigating the distinctness of pathomorphological\nalterations in the respiratory system induced by COVID-19 infection when\ncompared to other respiratory infections. To overcome the COVID-19 cough\ntraining data shortage we exploit transfer learning. To reduce the misdiagnosis\nrisk stemming from the complex dimensionality of the problem, we leverage a\nmulti-pronged mediator centered risk-averse AI architecture. Results: Results\nshow AI4COVID-19 can distinguish among COVID-19 coughs and several types of\nnon-COVID-19 coughs. The accuracy is promising enough to encourage a\nlarge-scale collection of labeled cough data to gauge the generalization\ncapability of AI4COVID-19. AI4COVID-19 is not a clinical grade testing tool.\nInstead, it offers a screening tool deployable anytime, anywhere, by anyone. It\ncan also be a clinical decision assistance tool used to channel\nclinical-testing and treatment to those who need it the most, thereby saving\nmore lives.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 21:39:34 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 02:06:26 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 04:59:39 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 05:55:56 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 22:53:50 GMT"}, {"version": "v6", "created": "Sun, 27 Sep 2020 21:32:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Imran", "Ali", ""], ["Posokhova", "Iryna", ""], ["Qureshi", "Haneya N.", ""], ["Masood", "Usama", ""], ["Riaz", "Muhammad Sajid", ""], ["Ali", "Kamran", ""], ["John", "Charles N.", ""], ["Hussain", "MD Iftikhar", ""], ["Nabeel", "Muhammad", ""]]}, {"id": "2004.01293", "submitter": "William Underwood", "authors": "William George Underwood, Andrew Elliott, Mihai Cucuringu", "title": "Motif-Based Spectral Clustering of Weighted Directed Networks", "comments": "38 pages, 20 figures", "journal-ref": "Applied Network Science 5, 62 (2020)", "doi": "10.1007/s41109-020-00293-z", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an essential technique for network analysis, with applications\nin a diverse range of fields. Although spectral clustering is a popular and\neffective method, it fails to consider higher-order structure and can perform\npoorly on directed networks. One approach is to capture and cluster\nhigher-order structures using motif adjacency matrices. However, current\nformulations fail to take edge weights into account, and thus are somewhat\nlimited when weight is a key component of the network under study.\n  We address these shortcomings by exploring motif-based weighted spectral\nclustering methods. We present new and computationally useful matrix formulae\nfor motif adjacency matrices on weighted networks, which can be used to\nconstruct efficient algorithms for any anchored or non-anchored motif on three\nnodes. In a very sparse regime, our proposed method can handle graphs with a\nmillion nodes and tens of millions of edges. We further use our framework to\nconstruct a motif-based approach for clustering bipartite networks.\n  We provide comprehensive experimental results, demonstrating (i) the\nscalability of our approach, (ii) advantages of higher-order clustering on\nsynthetic examples, and (iii) the effectiveness of our techniques on a variety\nof real world data sets; and compare against several techniques from the\nliterature. We conclude that motif-based spectral clustering is a valuable tool\nfor analysis of directed and bipartite weighted networks, which is also\nscalable and easy to implement.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 22:45:28 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:25:01 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Underwood", "William George", ""], ["Elliott", "Andrew", ""], ["Cucuringu", "Mihai", ""]]}, {"id": "2004.01299", "submitter": "Ping Li", "authors": "Xiaoyun Li, Chengxi Wu, Ping Li", "title": "IVFS: Simple and Efficient Feature Selection for High Dimensional\n  Topology Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important tool to deal with high dimensional data. In\nunsupervised case, many popular algorithms aim at maintaining the structure of\nthe original data. In this paper, we propose a simple and effective feature\nselection algorithm to enhance sample similarity preservation through a new\nperspective, topology preservation, which is represented by persistent diagrams\nfrom the context of computational topology. This method is designed upon a\nunified feature selection framework called IVFS, which is inspired by random\nsubset method. The scheme is flexible and can handle cases where the problem is\nanalytically intractable. The proposed algorithm is able to well preserve the\npairwise distances, as well as topological patterns, of the full data. We\ndemonstrate that our algorithm can provide satisfactory performance under a\nsharp sub-sampling rate, which supports efficient implementation of our\nproposed method to large scale datasets. Extensive experiments validate the\neffectiveness of the proposed feature selection scheme.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:05:00 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Li", "Xiaoyun", ""], ["Wu", "Chengxi", ""], ["Li", "Ping", ""]]}, {"id": "2004.01305", "submitter": "Ping Li", "authors": "Peng Yang and Ping Li", "title": "Distributed Primal-Dual Optimization for Online Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional online multi-task learning algorithms suffer from two critical\nlimitations: 1) Heavy communication caused by delivering high velocity of\nsequential data to a central machine; 2) Expensive runtime complexity for\nbuilding task relatedness. To address these issues, in this paper we consider a\nsetting where multiple tasks are geographically located in different places,\nwhere one task can synchronize data with others to leverage knowledge of\nrelated tasks. Specifically, we propose an adaptive primal-dual algorithm,\nwhich not only captures task-specific noise in adversarial learning but also\ncarries out a projection-free update with runtime efficiency. Moreover, our\nmodel is well-suited to decentralized periodic-connected tasks as it allows the\nenergy-starved or bandwidth-constraint tasks to postpone the update.\nTheoretical results demonstrate the convergence guarantee of our distributed\nalgorithm with an optimal regret. Empirical results confirm that the proposed\nmodel is highly effective on various real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:36:07 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Yang", "Peng", ""], ["Li", "Ping", ""]]}, {"id": "2004.01339", "submitter": "Tianshu Chu", "authors": "Tianshu Chu, Sandeep Chinchali, Sachin Katti", "title": "Multi-agent Reinforcement Learning for Networked System Control", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers multi-agent reinforcement learning (MARL) in networked\nsystem control. Specifically, each agent learns a decentralized control policy\nbased on local observations and messages from connected neighbors. We formulate\nsuch a networked MARL (NMARL) problem as a spatiotemporal Markov decision\nprocess and introduce a spatial discount factor to stabilize the training of\neach local agent. Further, we propose a new differentiable communication\nprotocol, called NeurComm, to reduce information loss and non-stationarity in\nNMARL. Based on experiments in realistic NMARL scenarios of adaptive traffic\nsignal control and cooperative adaptive cruise control, an appropriate spatial\ndiscount factor effectively enhances the learning curves of non-communicative\nMARL algorithms, while NeurComm outperforms existing communication protocols in\nboth learning efficiency and control performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 02:21:07 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:54:46 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Chu", "Tianshu", ""], ["Chinchali", "Sandeep", ""], ["Katti", "Sachin", ""]]}, {"id": "2004.01358", "submitter": "Wenjing Fang", "authors": "Wenjing Fang, Jun Zhou, Xiaolong Li, and Kenny Q. Zhu", "title": "Unpack Local Model Interpretation for GBDT", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A gradient boosting decision tree (GBDT), which aggregates a collection of\nsingle weak learners (i.e. decision trees), is widely used for data mining\ntasks. Because GBDT inherits the good performance from its ensemble essence,\nmuch attention has been drawn to the optimization of this model. With its\npopularization, an increasing need for model interpretation arises. Besides the\ncommonly used feature importance as a global interpretation, feature\ncontribution is a local measure that reveals the relationship between a\nspecific instance and the related output. This work focuses on the local\ninterpretation and proposes an unified computation mechanism to get the\ninstance-level feature contributions for GBDT in any version. Practicality of\nthis mechanism is validated by the listed experiments as well as applications\nin real industry scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 03:25:07 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fang", "Wenjing", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2004.01375", "submitter": "Tingyi Wanyan", "authors": "Tingyi Wanyan, Chenwei Zhang, Ariful Azad, Xiaomin Liang, Daifeng Li,\n  Ying Ding", "title": "Attribute2vec: Deep Network Embedding Through Multi-Filtering GCN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-filtering Graph Convolution Neural Network (GCN) framework\nfor network embedding task. It uses multiple local GCN filters to do feature\nextraction in every propagation layer. We show this approach could capture\ndifferent important aspects of node features against the existing attribute\nembedding based method. We also show that with multi-filtering GCN approach, we\ncan achieve significant improvement against baseline methods when training data\nis limited. We also perform many empirical experiments and demonstrate the\nbenefit of using multiple filters against single filter as well as most current\nexisting network embedding methods for both the link prediction and node\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:06:16 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wanyan", "Tingyi", ""], ["Zhang", "Chenwei", ""], ["Azad", "Ariful", ""], ["Liang", "Xiaomin", ""], ["Li", "Daifeng", ""], ["Ding", "Ying", ""]]}, {"id": "2004.01376", "submitter": "Matthew Engelhard", "authors": "Matthew Engelhard, Samuel Berchuck, Joshua D'Arcy, Ricardo Henao", "title": "Neural Conditional Event Time Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event time models predict occurrence times of an event of interest based on\nknown features. Recent work has demonstrated that neural networks achieve\nstate-of-the-art event time predictions in a variety of settings. However,\nstandard event time models suppose that the event occurs, eventually, in all\ncases. Consequently, no distinction is made between a) the probability of event\noccurrence, and b) the predicted time of occurrence. This distinction is\ncritical when predicting medical diagnoses, equipment defects, social media\nposts, and other events that or may not occur, and for which the features\naffecting a) may be different from those affecting b). In this work, we develop\na conditional event time model that distinguishes between these components,\nimplement it as a neural network with a binary stochastic layer representing\nfinite event occurrence, and show how it may be learned from right-censored\nevent times via maximum likelihood estimation. Results demonstrate superior\nevent occurrence and event time predictions on synthetic data, medical events\n(MIMIC-III), and social media posts (Reddit), comprising 21 total prediction\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:08:13 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Engelhard", "Matthew", ""], ["Berchuck", "Samuel", ""], ["D'Arcy", "Joshua", ""], ["Henao", "Ricardo", ""]]}, {"id": "2004.01377", "submitter": "Da Li", "authors": "Da Li, Yongxin Yang, Yi-Zhe Song and Timothy Hospedales", "title": "Sequential Learning for Domain Generalization", "comments": "tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a sequential learning framework for Domain\nGeneralization (DG), the problem of training a model that is robust to domain\nshift by design. Various DG approaches have been proposed with different\nmotivating intuitions, but they typically optimize for a single step of domain\ngeneralization -- training on one set of domains and generalizing to one other.\nOur sequential learning is inspired by the idea lifelong learning, where\naccumulated experience means that learning the $n^{th}$ thing becomes easier\nthan the $1^{st}$ thing. In DG this means encountering a sequence of domains\nand at each step training to maximise performance on the next domain. The\nperformance at domain $n$ then depends on the previous $n-1$ learning problems.\nThus backpropagating through the sequence means optimizing performance not just\nfor the next domain, but all following domains. Training on all such sequences\nof domains provides dramatically more `practice' for a base DG learner compared\nto existing approaches, thus improving performance on a true testing domain.\nThis strategy can be instantiated for different base DG algorithms, but we\nfocus on its application to the recently proposed Meta-Learning Domain\ngeneralization (MLDG). We show that for MLDG it leads to a simple to implement\nand fast algorithm that provides consistent performance improvement on a\nvariety of DG benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:10:33 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Li", "Da", ""], ["Yang", "Yongxin", ""], ["Song", "Yi-Zhe", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2004.01395", "submitter": "Binxin Ru", "authors": "Binxin Ru, Pedro Esperanca, Fabio Carlucci", "title": "Neural Architecture Generator Optimization", "comments": "20 pages, 9 figures, neural architecture search, Thirty-fourth\n  Conference on Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) was first proposed to achieve\nstate-of-the-art performance through the discovery of new architecture\npatterns, without human intervention. An over-reliance on expert knowledge in\nthe search space design has however led to increased performance (local optima)\nwithout significant architectural breakthroughs, thus preventing truly novel\nsolutions from being reached. In this work we 1) are the first to investigate\ncasting NAS as a problem of finding the optimal network generator and 2) we\npropose a new, hierarchical and graph-based search space capable of\nrepresenting an extremely large variety of network types, yet only requiring\nfew continuous hyper-parameters. This greatly reduces the dimensionality of the\nproblem, enabling the effective use of Bayesian Optimisation as a search\nstrategy. At the same time, we expand the range of valid architectures,\nmotivating a multi-objective learning approach. We demonstrate the\neffectiveness of this strategy on six benchmark datasets and show that our\nsearch space generates extremely lightweight yet highly competitive models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 06:38:07 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:22:40 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 16:28:40 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ru", "Binxin", ""], ["Esperanca", "Pedro", ""], ["Carlucci", "Fabio", ""]]}, {"id": "2004.01442", "submitter": "Laurent Condat", "authors": "Grigory Malinovsky, Dmitry Kovalev, Elnur Gasanov, Laurent Condat,\n  Peter Richt\\'arik", "title": "From Local SGD to Local Fixed-Point Methods for Federated Learning", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms for solving optimization problems or finding saddle points of\nconvex-concave functions are fixed-point algorithms. In this work we consider\nthe generic problem of finding a fixed point of an average of operators, or an\napproximation thereof, in a distributed setting. Our work is motivated by the\nneeds of federated learning. In this context, each local operator models the\ncomputations done locally on a mobile device. We investigate two strategies to\nachieve such a consensus: one based on a fixed number of local steps, and the\nother based on randomized computations. In both cases, the goal is to limit\ncommunication of the locally-computed variables, which is often the bottleneck\nin distributed frameworks. We perform convergence analysis of both methods and\nconduct a number of experiments highlighting the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 09:24:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:42:08 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Malinovsky", "Grigory", ""], ["Kovalev", "Dmitry", ""], ["Gasanov", "Elnur", ""], ["Condat", "Laurent", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2004.01454", "submitter": "Yuxuan Song", "authors": "Yuxuan Song, Minkai Xu, Lantao Yu, Hao Zhou, Shuo Shao, Yong Yu", "title": "Infomax Neural Joint Source-Channel Coding via Adversarial Bit Flip", "comments": "AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Shannon theory states that it is asymptotically optimal to separate\nthe source and channel coding as two independent processes, in many practical\ncommunication scenarios this decomposition is limited by the finite bit-length\nand computational power for decoding. Recently, neural joint source-channel\ncoding (NECST) is proposed to sidestep this problem. While it leverages the\nadvancements of amortized inference and deep learning to improve the encoding\nand decoding process, it still cannot always achieve compelling results in\nterms of compression and error correction performance due to the limited\nrobustness of its learned coding networks. In this paper, motivated by the\ninherent connections between neural joint source-channel coding and discrete\nrepresentation learning, we propose a novel regularization method called\nInfomax Adversarial-Bit-Flip (IABF) to improve the stability and robustness of\nthe neural joint source-channel coding scheme. More specifically, on the\nencoder side, we propose to explicitly maximize the mutual information between\nthe codeword and data; while on the decoder side, the amortized reconstruction\nis regularized within an adversarial framework. Extensive experiments conducted\non various real-world datasets evidence that our IABF can achieve\nstate-of-the-art performances on both compression and error correction\nbenchmarks and outperform the baselines by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 10:00:02 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Song", "Yuxuan", ""], ["Xu", "Minkai", ""], ["Yu", "Lantao", ""], ["Zhou", "Hao", ""], ["Shao", "Shuo", ""], ["Yu", "Yong", ""]]}, {"id": "2004.01468", "submitter": "Rayyan Ahmad Khan", "authors": "Rayyan Ahmad Khan, Muhammad Umer Anwaar and Martin Kleinsteuber", "title": "Epitomic Variational Graph Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a widely used generative model for learning\nlatent representations. Burda et al. in their seminal paper showed that\nlearning capacity of VAE is limited by over-pruning. It is a phenomenon where a\nsignificant number of latent variables fail to capture any information about\nthe input data and the corresponding hidden units become inactive. This\nadversely affects learning diverse and interpretable latent representations. As\nvariational graph autoencoder (VGAE) extends VAE for graph-structured data, it\ninherits the over-pruning problem. In this paper, we adopt a model based\napproach and propose epitomic VGAE (EVGAE),a generative variational framework\nfor graph datasets which successfully mitigates the over-pruning problem and\nalso boosts the generative ability of VGAE. We consider EVGAE to consist of\nmultiple sparse VGAE models, called epitomes, that are groups of latent\nvariables sharing the latent space. This approach aids in increasing active\nunits as epitomes compete to learn better representation of the graph data. We\nverify our claims via experiments on three benchmark datasets. Our experiments\nshow that EVGAE has a better generative ability than VGAE. Moreover, EVGAE\noutperforms VGAE on link prediction task in citation networks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 11:05:17 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 10:11:12 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 13:10:50 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Khan", "Rayyan Ahmad", ""], ["Anwaar", "Muhammad Umer", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "2004.01495", "submitter": "Usama Masood", "authors": "Charles Bales, Muhammad Nabeel, Charles N. John, Usama Masood, Haneya\n  N. Qureshi, Hasan Farooq, Iryna Posokhova, Ali Imran", "title": "Can Machine Learning Be Used to Recognize and Diagnose Coughs?", "comments": "Accepted in IEEE International Conference on E-Health and\n  Bioengineering - EHB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging wireless technologies, such as 5G and beyond, are bringing new use\ncases to the forefront, one of the most prominent being machine learning\nempowered health care. One of the notable modern medical concerns that impose\nan immense worldwide health burden are respiratory infections. Since cough is\nan essential symptom of many respiratory infections, an automated system to\nscreen for respiratory diseases based on raw cough data would have a multitude\nof beneficial research and medical applications. In literature, machine\nlearning has already been successfully used to detect cough events in\ncontrolled environments. In this paper, we present a low complexity, automated\nrecognition and diagnostic tool for screening respiratory infections that\nutilizes Convolutional Neural Networks (CNNs) to detect cough within\nenvironment audio and diagnose three potential illnesses (i.e., bronchitis,\nbronchiolitis and pertussis) based on their unique cough audio features. Both\nproposed detection and diagnosis models achieve an accuracy of over 89%, while\nalso remaining computationally efficient. Results show that the proposed system\nis successfully able to detect and separate cough events from background noise.\nMoreover, the proposed single diagnosis model is capable of distinguishing\nbetween different illnesses without the need of separate models.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 20:14:36 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 13:41:37 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 04:00:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bales", "Charles", ""], ["Nabeel", "Muhammad", ""], ["John", "Charles N.", ""], ["Masood", "Usama", ""], ["Qureshi", "Haneya N.", ""], ["Farooq", "Hasan", ""], ["Posokhova", "Iryna", ""], ["Imran", "Ali", ""]]}, {"id": "2004.01498", "submitter": "Ye-Sheen Lim", "authors": "Ye-Sheen Lim, Denise Gorse", "title": "Deep Probabilistic Modelling of Price Movements for High-Frequency\n  Trading", "comments": "8 pages, 2 columns, IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep recurrent architecture for the probabilistic\nmodelling of high-frequency market prices, important for the risk management of\nautomated trading systems. Our proposed architecture incorporates probabilistic\nmixture models into deep recurrent neural networks. The resulting deep mixture\nmodels simultaneously address several practical challenges important in the\ndevelopment of automated high-frequency trading strategies that were previously\nneglected in the literature: 1) probabilistic forecasting of the price\nmovements; 2) single objective prediction of both the direction and size of the\nprice movements. We train our models on high-frequency Bitcoin market data and\nevaluate them against benchmark models obtained from the literature. We show\nthat our model outperforms the benchmark models in both a metric-based test and\nin a simulated trading scenario\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:25:40 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lim", "Ye-Sheen", ""], ["Gorse", "Denise", ""]]}, {"id": "2004.01499", "submitter": "Ye-Sheen Lim", "authors": "Ye-Sheen Lim, Denise Gorse", "title": "Deep Recurrent Modelling of Stationary Bitcoin Price Formation Using the\n  Order Flow", "comments": "10 pages, The 19th International Conference on Artificial\n  Intelligence and Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep recurrent model based on the order flow for\nthe stationary modelling of the high-frequency directional prices movements.\nThe order flow is the microsecond stream of orders arriving at the exchange,\ndriving the formation of prices seen on the price chart of a stock or currency.\nTo test the stationarity of our proposed model we train our model on data\nbefore the 2017 Bitcoin bubble period and test our model during and after the\nbubble. We show that without any retraining, the proposed model is temporally\nstable even as Bitcoin trading shifts into an extremely volatile \"bubble\ntrouble\" period. The significance of the result is shown by benchmarking\nagainst existing state-of-the-art models in the literature for modelling price\nformation using deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:13:04 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lim", "Ye-Sheen", ""], ["Gorse", "Denise", ""]]}, {"id": "2004.01504", "submitter": "Philip Ndikum", "authors": "Philip Ndikum", "title": "Machine Learning Algorithms for Financial Asset Price Forecasting", "comments": "16 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research paper explores the performance of Machine Learning (ML)\nalgorithms and techniques that can be used for financial asset price\nforecasting. The prediction and forecasting of asset prices and returns remains\none of the most challenging and exciting problems for quantitative finance and\npractitioners alike. The massive increase in data generated and captured in\nrecent years presents an opportunity to leverage Machine Learning algorithms.\nThis study directly compares and contrasts state-of-the-art implementations of\nmodern Machine Learning algorithms on high performance computing (HPC)\ninfrastructures versus the traditional and highly popular Capital Asset Pricing\nModel (CAPM) on U.S equities data. The implemented Machine Learning models -\ntrained on time series data for an entire stock universe (in addition to\nexogenous macroeconomic variables) significantly outperform the CAPM on\nout-of-sample (OOS) test data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:14:18 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ndikum", "Philip", ""]]}, {"id": "2004.01509", "submitter": "Amir Mosavi Prof", "authors": "Amir Mosavi, Pedram Ghamisi, Yaser Faghan, Puhong Duan", "title": "Comprehensive Review of Deep Reinforcement Learning Methods and\n  Applications in Economics", "comments": "42 pages, 26 figures", "journal-ref": null, "doi": "10.20944/preprints202003.0309.v1", "report-no": null, "categories": "q-fin.ST cs.LG econ.GN q-fin.EC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity of deep reinforcement learning (DRL) methods in economics have\nbeen exponentially increased. DRL through a wide range of capabilities from\nreinforcement learning (RL) and deep learning (DL) for handling sophisticated\ndynamic business environments offers vast opportunities. DRL is characterized\nby scalability with the potential to be applied to high-dimensional problems in\nconjunction with noisy and nonlinear patterns of economic data. In this work,\nwe first consider a brief review of DL, RL, and deep RL methods in diverse\napplications in economics providing an in-depth insight into the state of the\nart. Furthermore, the architecture of DRL applied to economic applications is\ninvestigated in order to highlight the complexity, robustness, accuracy,\nperformance, computational tasks, risk constraints, and profitability. The\nsurvey results indicate that DRL can provide better performance and higher\naccuracy as compared to the traditional algorithms while facing real economic\nproblems at the presence of risk parameters and the ever-increasing\nuncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 14:07:59 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Mosavi", "Amir", ""], ["Ghamisi", "Pedram", ""], ["Faghan", "Yaser", ""], ["Duan", "Puhong", ""]]}, {"id": "2004.01546", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Sridha Sridharan, Mitchell McLaren, Darshana\n  Priyasad, Simon Denman, Clinton Fookes", "title": "Temporarily-Aware Context Modelling using Generative Adversarial\n  Networks for Speech Activity Detection", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing,\n  2020", "doi": "10.1109/TASLP.2020.2982297", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework for Speech Activity Detection (SAD).\nInspired by the recent success of multi-task learning approaches in the speech\nprocessing domain, we propose a novel joint learning framework for SAD. We\nutilise generative adversarial networks to automatically learn a loss function\nfor joint prediction of the frame-wise speech/ non-speech classifications\ntogether with the next audio segment. In order to exploit the temporal\nrelationships within the input signal, we propose a temporal discriminator\nwhich aims to ensure that the predicted signal is temporally consistent. We\nevaluate the proposed framework on multiple public benchmarks, including NIST\nOpenSAT' 17, AMI Meeting and HAVIC, where we demonstrate its capability to\noutperform state-of-the-art SAD approaches. Furthermore, our cross-database\nevaluations demonstrate the robustness of the proposed approach across\ndifferent languages, accents, and acoustic environments.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:33:13 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fernando", "Tharindu", ""], ["Sridharan", "Sridha", ""], ["McLaren", "Mitchell", ""], ["Priyasad", "Darshana", ""], ["Denman", "Simon", ""], ["Fookes", "Clinton", ""]]}, {"id": "2004.01570", "submitter": "Vincent Margot", "authors": "Vincent Margot, George Luta", "title": "A new method to compare the interpretability of rule-based algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is becoming increasingly important for predictive model\nanalysis. Unfortunately, as remarked by many authors, there is still no\nconsensus regarding this notion. The goal of this article is to propose a\ndefinition of the notion of interpretability that allows comparisons of\nrule-based algorithms. This definition consists of three terms, each one being\nquantitatively measured with a simple formula: predictivity, stability and\nsimplicity. While predictivity has been extensively studied to measure the\naccuracy of predictive algorithms, stability is based on the Dice-Sorensen\nindex for comparing two sets of rules generated by an algorithm using two\nindependent samples. The simplicity is based on the sum of the length of the\nrules derived from the predictive model. The new measure for the\ninterpretability of a rule-based algorithm is a weighted sum of the three terms\nmentioned above. We use the new measure to compare the interpretability of\nseveral rule-based algorithms, specifically CART, RuleFit, Node Harvest,\nCovering algorithm and SIRUS for the regression case, and CART, PART and RIPPER\nfor the classification case\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:50:27 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 07:39:24 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 10:49:32 GMT"}, {"version": "v4", "created": "Fri, 22 Jan 2021 08:04:26 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Margot", "Vincent", ""], ["Luta", "George", ""]]}, {"id": "2004.01571", "submitter": "Antoine Baker", "authors": "Antoine Baker, Benjamin Aubin, Florent Krzakala, Lenka Zdeborov\\'a", "title": "TRAMP: Compositional Inference with TRee Approximate Message Passing", "comments": "Source code available at https://github.com/sphinxteam/tramp. For\n  some examples, see https://github.com/benjaminaubin/tramp_examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG eess.SP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce tramp, standing for TRee Approximate Message Passing, a python\npackage for compositional inference in high-dimensional tree-structured models.\nThe package provides an unifying framework to study several approximate message\npassing algorithms previously derived for a variety of machine learning tasks\nsuch as generalized linear models, inference in multi-layer networks, matrix\nfactorization, and reconstruction using non-separable penalties. For some\nmodels, the asymptotic performance of the algorithm can be theoretically\npredicted by the state evolution, and the measurements entropy estimated by the\nfree entropy formalism. The implementation is modular by design: each module,\nwhich implements a factor, can be composed at will with other modules to solve\ncomplex inference tasks. The user only needs to declare the factor graph of the\nmodel: the inference algorithm, state evolution and entropy estimation are\nfully automated.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:51:10 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 11:27:59 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Baker", "Antoine", ""], ["Aubin", "Benjamin", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2004.01574", "submitter": "Babacar Mbaye Ndiaye", "authors": "Babacar Mbaye Ndiaye, Lena Tendeng, Diaraf Seck", "title": "Analysis of the COVID-19 pandemic by SIR model and machine learning\n  technics for forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a trial in which we propose SIR model and machine learning tools\nto analyze the coronavirus pandemic in the real world. Based on the public data\nfrom \\cite{datahub}, we estimate main key pandemic parameters and make\npredictions on the inflection point and possible ending time for the real world\nand specifically for Senegal. The coronavirus disease 2019, by World Health\nOrganization, rapidly spread out in the whole China and then in the whole\nworld. Under optimistic estimation, the pandemic in some countries will end\nsoon, while for most part of countries in the world (US, Italy, etc.), the hit\nof anti-pandemic will be no later than the end of April.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:56:54 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ndiaye", "Babacar Mbaye", ""], ["Tendeng", "Lena", ""], ["Seck", "Diaraf", ""]]}, {"id": "2004.01580", "submitter": "Wen-Hao Chiang", "authors": "Wen-Hao Chiang and George Mohler", "title": "Hawkes Process Multi-armed Bandits for Disaster Search and Rescue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for integrating Hawkes processes with\nmulti-armed bandit algorithms to solve spatio-temporal event forecasting and\ndetection problems when data may be undersampled or spatially biased. In\nparticular, we introduce an upper confidence bound algorithm using Bayesian\nspatial Hawkes process estimation for balancing the tradeoff between exploiting\ngeographic regions where data has been collected and exploring geographic\nregions where data is unobserved. We first validate our model using simulated\ndata and then apply it to the problem of disaster search and rescue using calls\nfor service data from hurricane Harvey in 2017. Our model outperforms the state\nof the art baseline spatial MAB algorithms in terms of cumulative reward and\nseveral other ranking evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:05:09 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Chiang", "Wen-Hao", ""], ["Mohler", "George", ""]]}, {"id": "2004.01584", "submitter": "Aristeidis Panos", "authors": "Constantinos Daskalakis, Petros Dellaportas, Aristeidis Panos", "title": "Scalable Gaussian Processes, with Guarantees: Kernel Approximations and\n  Deep Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide approximation guarantees for a linear-time inferential framework\nfor Gaussian processes, using two low-rank kernel approximations based on\nrandom Fourier features and truncation of Mercer expansions. In particular, we\nbound the Kullback-Leibler divergence between the idealized Gaussian process\nand the one resulting from a low-rank approximation to its kernel.\nAdditionally, we present strong evidence that these two approximations,\nenhanced by an initial automatic feature extraction through deep neural\nnetworks, outperform a broad range of state-of-the-art methods in terms of time\nefficiency, negative log-predictive density, and root mean squared error.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:15:10 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:15:32 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 21:59:40 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 23:01:20 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dellaportas", "Petros", ""], ["Panos", "Aristeidis", ""]]}, {"id": "2004.01602", "submitter": "David F. Nettleton", "authors": "David F. Nettleton, Dimitrios Katsantonis, Argyris Kalaitzidis, Natasa\n  Sarafijanovic-Djukic, Pau Puigdollers and Roberto Confalonieri", "title": "Predicting rice blast disease: machine learning versus process based\n  models", "comments": null, "journal-ref": "BMC Bioinformatics volume 20, Article number: 514 (2019)", "doi": "10.1186/s12859-019-3065-1", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rice is the second most important cereal crop worldwide, and the first in\nterms of number of people who depend on it as a major staple food. Rice blast\ndisease is the most important biotic constraint of rice cultivation causing\neach year millions of dollars of losses. Despite the efforts for breeding new\nresistant varieties, agricultural practices and chemical control are still the\nmost important methods for disease management. Thus, rice blast forecasting is\na primary tool to support rice growers in controlling the disease. In this\nstudy, we compared four models for predicting rice blast disease, two\noperational process-based models (Yoshino and WARM) and two approaches based on\nmachine learning algorithms (M5Rules and RNN), the former inducing a rule-based\nmodel and the latter building a neural network. In situ telemetry is important\nto obtain quality in-field data for predictive models and this was a key aspect\nof the RICE-GUARD project on which this study is based. According to the\nauthors, this is the first time process-based and machine learning modelling\napproaches for supporting plant disease management are compared.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:48:14 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Nettleton", "David F.", ""], ["Katsantonis", "Dimitrios", ""], ["Kalaitzidis", "Argyris", ""], ["Sarafijanovic-Djukic", "Natasa", ""], ["Puigdollers", "Pau", ""], ["Confalonieri", "Roberto", ""]]}, {"id": "2004.01603", "submitter": "Kieran Woodward Mr", "authors": "Kieran Woodward, Eiman Kanjo, David J. Brown and T.M. McGinnity", "title": "On-Device Transfer Learning for Personalising Psychological Stress\n  Modelling using a Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress is a growing concern in modern society adversely impacting the wider\npopulation more than ever before. The accurate inference of stress may result\nin the possibility for personalised interventions. However, individual\ndifferences between people limits the generalisability of machine learning\nmodels to infer emotions as people's physiology when experiencing the same\nemotions widely varies. In addition, it is time consuming and extremely\nchallenging to collect large datasets of individuals' emotions as it relies on\nusers labelling sensor data in real-time for extended periods. We propose the\ndevelopment of a personalised, cross-domain 1D CNN by utilising transfer\nlearning from an initial base model trained using data from 20 participants\ncompleting a controlled stressor experiment. By utilising physiological sensors\n(HR, HRV EDA) embedded within edge computing interfaces that additionally\ncontain a labelling technique, it is possible to collect a small real-world\npersonal dataset that can be used for on-device transfer learning to improve\nmodel personalisation and cross-domain performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:48:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Woodward", "Kieran", ""], ["Kanjo", "Eiman", ""], ["Brown", "David J.", ""], ["McGinnity", "T. M.", ""]]}, {"id": "2004.01608", "submitter": "Paulo Roberto de Oliveira da Costa", "authors": "Paulo R. de O. da Costa, Jason Rhuggenaath, Yingqian Zhang, Alp Akcay", "title": "Learning 2-opt Heuristics for the Traveling Salesman Problem via Deep\n  Reinforcement Learning", "comments": "To appear in Proceedings Machine Learning Research - ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works using deep learning to solve the Traveling Salesman Problem\n(TSP) have focused on learning construction heuristics. Such approaches find\nTSP solutions of good quality but require additional procedures such as beam\nsearch and sampling to improve solutions and achieve state-of-the-art\nperformance. However, few studies have focused on improvement heuristics, where\na given solution is improved until reaching a near-optimal one. In this work,\nwe propose to learn a local search heuristic based on 2-opt operators via deep\nreinforcement learning. We propose a policy gradient algorithm to learn a\nstochastic policy that selects 2-opt operations given a current solution.\nMoreover, we introduce a policy neural network that leverages a pointing\nattention mechanism, which unlike previous works, can be easily extended to\nmore general k-opt moves. Our results show that the learned policies can\nimprove even over random initial solutions and approach near-optimal solutions\nat a faster rate than previous state-of-the-art deep learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:51:54 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 09:50:53 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 16:20:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Rhuggenaath", "Jason", ""], ["Zhang", "Yingqian", ""], ["Akcay", "Alp", ""]]}, {"id": "2004.01623", "submitter": "Philipp Bach", "authors": "Philipp Bach, Sven Klaassen, Jannis Kueck, Martin Spindler", "title": "Uniform Inference in High-Dimensional Generalized Additive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for uniform valid confidence bands of a nonparametric\ncomponent $f_1$ in the general additive model $Y=f_1(X_1)+\\ldots + f_p(X_p) +\n\\varepsilon$ in a high-dimensional setting. We employ sieve estimation and\nembed it in a high-dimensional Z-estimation framework allowing us to construct\nuniformly valid confidence bands for the first component $f_1$. As usual in\nhigh-dimensional settings where the number of regressors $p$ may increase with\nsample, a sparsity assumption is critical for the analysis. We also run\nsimulations studies which show that our proposed method gives reliable results\nconcerning the estimation properties and coverage properties even in small\nsamples. Finally, we illustrate our procedure with an empirical application\ndemonstrating the implementation and the use of the proposed method in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 15:30:29 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bach", "Philipp", ""], ["Klaassen", "Sven", ""], ["Kueck", "Jannis", ""], ["Spindler", "Martin", ""]]}, {"id": "2004.01628", "submitter": "Adrian-Catalin Florea", "authors": "Adrian-Catalin Florea, Razvan Andonie", "title": "Weighted Random Search for Hyperparameter Optimization", "comments": "14 pages, 5 figures, journal paper", "journal-ref": "INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS & CONTROL, Vol\n  14, Nr. 2 (2019)", "doi": "10.15837/ijccc.2019.2.3514", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an improved version of Random Search (RS), used here for\nhyperparameter optimization of machine learning algorithms. Unlike the standard\nRS, which generates for each trial new values for all hyperparameters, we\ngenerate new values for each hyperparameter with a probability of change. The\nintuition behind our approach is that a value that already triggered a good\nresult is a good candidate for the next step, and should be tested in new\ncombinations of hyperparameter values. Within the same computational budget,\nour method yields better results than the standard RS. Our theoretical results\nprove this statement. We test our method on a variation of one of the most\ncommonly used objective function for this class of problems (the Grievank\nfunction) and for the hyperparameter optimization of a deep learning CNN\narchitecture. Our results can be generalized to any optimization problem\ndefined on a discrete domain.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 15:41:22 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Florea", "Adrian-Catalin", ""], ["Andonie", "Razvan", ""]]}, {"id": "2004.01646", "submitter": "Bo Peng", "authors": "Bo Peng, Zhiyun Ren, Srinivasan Parthasarathy and Xia Ning", "title": "M2: Mixed Models with Preferences, Popularities and Transitions for\n  Next-Basket Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-basket recommendation considers the problem of recommending a set of\nitems into the next basket that users will purchase as a whole. In this paper,\nwe develop a novel mixed model with preferences, popularities and transitions\n(M2) for next-basket recommendation. This method explicitly models three\nimportant factors in next-basket generation process: 1) users' general\npreferences, 2) items' global popularities and 3) transition patterns among\nitems. We also propose a simple encoder-decoder based framework (ed-Trans) to\nbetter model the transition patterns among items. We compared M2 with 5\nstate-of-the-art next-basket recommendation methods on 4 public benchmark\ndatasets. Our experimental results demonstrate that M2 significantly\noutperforms the state-of-the-art methods on all the datasets, with an\nimprovement as much as 19.0% at recall@5. We also compared M2 with these\nbaseline methods in recommending the second next and third next baskets. Our\nexperimental results demonstrate that M2 could consistently outperform the\nbaseline methods in all these tasks, with an improvement as much as 14.4% at\nrecall@5. In addition, we conducted a comprehensive ablation study to verify\nthe effects of the different factors. The results show that learning all the\nfactors together could significantly improve the recommendation performance\ncompared to learning each of them alone. The results also show that ed-Trans in\nlearning item transitions among baskets could outperform recurrent neural\nnetwork-based methods on the benchmark datasets, with an improvement as much as\n20.4% at recall@5. We also have a thorough discussion on various experimental\nprotocols and evaluation metrics for next-basket recommendation evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:11:26 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 15:32:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Peng", "Bo", ""], ["Ren", "Zhiyun", ""], ["Parthasarathy", "Srinivasan", ""], ["Ning", "Xia", ""]]}, {"id": "2004.01653", "submitter": "Antoine Ledent", "authors": "Antoine Ledent, Rodrigo Alves, and Marius Kloft", "title": "Orthogonal Inductive Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose orthogonal inductive matrix completion (OMIC), an interpretable\napproach to inductive matrix completion based on a sum of multiple orthonormal\nside information terms, together with nuclear-norm regularization. The approach\nallows us to inject prior knowledge about the eigenvectors of the ground truth\nmatrix. We optimize the approach by a provably converging algorithm, which\noptimizes all components of the model simultaneously. Our method enjoys\ndistribution-free learning guarantees that improve with the quality of the\ninjected knowledge. As a special case of our general framework, we study a\nmodel consisting of a sum of user and item biases (generic behavior), a\nnon-inductive term (specific behavior), and (optionally) an inductive term\nusing side information. Our theoretical analysis shows that\n$\\epsilon$-recovering a ground truth matrix in $\\mathbb{R}^{m\\times n}$\nrequires at most $O\\left( \\frac{n+m+(\\sqrt{n}+\\sqrt{m})\n\\sqrt{mnr}C}{\\epsilon^2}\\right)$ entries, where $r$ (resp. $C$) is the rank\n(resp. maximum entry) of the bias-free part of the ground truth matrix. We\nanalyse the performance of OMIC on several synthetic and real datasets. On\nsynthetic datasets with a sliding scale of user bias relevance, we show that\nOMIC better adapts to different regimes than other methods. On real-life\ndatasets containing user/items recommendations and relevant side information,\nwe find that OMIC surpasses the state-of-the-art, with the added benefit of\ngreater interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:21:23 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 17:41:31 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 10:25:31 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 20:43:50 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Ledent", "Antoine", ""], ["Alves", "Rodrigo", ""], ["Kloft", "Marius", ""]]}, {"id": "2004.01655", "submitter": "Marjan Ghazvininejad", "authors": "Marjan Ghazvininejad, Vladimir Karpukhin, Luke Zettlemoyer, Omer Levy", "title": "Aligned Cross Entropy for Non-Autoregressive Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive machine translation models significantly speed up decoding\nby allowing for parallel prediction of the entire target sequence. However,\nmodeling word order is more challenging due to the lack of autoregressive\nfactors in the model. This difficultly is compounded during training with cross\nentropy loss, which can highly penalize small shifts in word order. In this\npaper, we propose aligned cross entropy (AXE) as an alternative loss function\nfor training of non-autoregressive models. AXE uses a differentiable dynamic\nprogram to assign loss based on the best possible monotonic alignment between\ntarget tokens and model predictions. AXE-based training of conditional masked\nlanguage models (CMLMs) substantially improves performance on major WMT\nbenchmarks, while setting a new state of the art for non-autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:24:47 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ghazvininejad", "Marjan", ""], ["Karpukhin", "Vladimir", ""], ["Zettlemoyer", "Luke", ""], ["Levy", "Omer", ""]]}, {"id": "2004.01704", "submitter": "Qiwei Ye", "authors": "Yuxuan Song, Qiwei Ye, Minkai Xu, Tie-Yan Liu", "title": "Discriminator Contrastive Divergence: Semi-Amortized Generative Modeling\n  by Exploring Energy of the Discriminator", "comments": "17 pages, 9 figures, pre-submmited to cvpr2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown great promise in modeling\nhigh dimensional data. The learning objective of GANs usually minimizes some\nmeasure discrepancy, \\textit{e.g.}, $f$-divergence~($f$-GANs) or Integral\nProbability Metric~(Wasserstein GANs). With $f$-divergence as the objective\nfunction, the discriminator essentially estimates the density ratio, and the\nestimated ratio proves useful in further improving the sample quality of the\ngenerator. However, how to leverage the information contained in the\ndiscriminator of Wasserstein GANs (WGAN) is less explored. In this paper, we\nintroduce the Discriminator Contrastive Divergence, which is well motivated by\nthe property of WGAN's discriminator and the relationship between WGAN and\nenergy-based model. Compared to standard GANs, where the generator is directly\nutilized to obtain new samples, our method proposes a semi-amortized generation\nprocedure where the samples are produced with the generator's output as an\ninitial state. Then several steps of Langevin dynamics are conducted using the\ngradient of the discriminator. We demonstrate the benefits of significant\nimproved generation on both synthetic data and several real-world image\ngeneration benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 01:50:16 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Song", "Yuxuan", ""], ["Ye", "Qiwei", ""], ["Xu", "Minkai", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2004.01732", "submitter": "Kai Shu", "authors": "Kai Shu, Guoqing Zheng, Yichuan Li, Subhabrata Mukherjee, Ahmed Hassan\n  Awadallah, Scott Ruston, Huan Liu", "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News", "comments": "17 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 18:26:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Shu", "Kai", ""], ["Zheng", "Guoqing", ""], ["Li", "Yichuan", ""], ["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed Hassan", ""], ["Ruston", "Scott", ""], ["Liu", "Huan", ""]]}, {"id": "2004.01735", "submitter": "Yuhong Guo", "authors": "Kevin Hua, Yuhong Guo", "title": "Unsupervised Domain Adaptation with Progressive Domain Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to exploit a label-rich source domain for learning\nclassifiers in a different label-scarce target domain. It is particularly\nchallenging when there are significant divergences between the two domains. In\nthe paper, we propose a novel unsupervised domain adaptation method based on\nprogressive domain augmentation. The proposed method generates virtual\nintermediate domains via domain interpolation, progressively augments the\nsource domain and bridges the source-target domain divergence by conducting\nmultiple subspace alignment on the Grassmann manifold. We conduct experiments\non multiple domain adaptation tasks and the results shows the proposed method\nachieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 18:45:39 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:45:24 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hua", "Kevin", ""], ["Guo", "Yuhong", ""]]}, {"id": "2004.01739", "submitter": "Daron Anderson", "authors": "Daron Anderson and Douglas Leith", "title": "Universal Algorithms: Beyond the Simplex", "comments": "1 figure, 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bulk of universal algorithms in the online convex optimisation literature\nare variants of the Hedge (exponential weights) algorithm on the simplex. While\nthese algorithms extend to polytope domains by assigning weights to the\nvertices, this process is computationally unfeasible for many important classes\nof polytopes where the number $V$ of vertices depends exponentially on the\ndimension $d$. In this paper we show the Subgradient algorithm is universal,\nmeaning it has $O(\\sqrt N)$ regret in the antagonistic setting and $O(1)$\npseudo-regret in the i.i.d setting, with two main advantages over Hedge: (1)\nThe update step is more efficient as the action vectors have length only $d$\nrather than $V$; and (2) Subgradient gives better performance if the cost\nvectors satisfy Euclidean rather than sup-norm bounds. This paper extends the\nauthors' recent results for Subgradient on the simplex. We also prove the same\n$O(\\sqrt N)$ and $O(1)$ bounds when the domain is the unit ball. To the\nauthors' knowledge this is the first instance of these bounds on a domain other\nthan a polytope.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 19:00:42 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Anderson", "Daron", ""], ["Leith", "Douglas", ""]]}, {"id": "2004.01743", "submitter": "Zitao Chen", "authors": "Zitao Chen, Niranjhana Narayanan, Bo Fang, Guanpeng Li, Karthik\n  Pattabiraman and Nathan DeBardeleben", "title": "TensorFI: A Flexible Fault Injection Framework for TensorFlow\n  Applications", "comments": "A preliminary version of this work was published in a workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) has seen increasing adoption in safety-critical\ndomains (e.g., autonomous vehicles), the reliability of ML systems has also\ngrown in importance. While prior studies have proposed techniques to enable\nefficient error-resilience techniques (e.g., selective instruction\nduplication), a fundamental requirement for realizing these techniques is a\ndetailed understanding of the application's resilience.\n  In this work, we present TensorFI, a high-level fault injection (FI)\nframework for TensorFlow-based applications. TensorFI is able to inject both\nhardware and software faults in general TensorFlow programs. TensorFI is a\nconfigurable FI tool that is flexible, easy to use, and portable. It can be\nintegrated into existing TensorFlow programs to assess their resilience for\ndifferent fault types (e.g., faults in particular operators). We use TensorFI\nto evaluate the resilience of 12 ML programs, including DNNs used in the\nautonomous vehicle domain. Our tool is publicly available at\nhttps://github.com/DependableSystemsLab/TensorFI.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 19:26:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chen", "Zitao", ""], ["Narayanan", "Niranjhana", ""], ["Fang", "Bo", ""], ["Li", "Guanpeng", ""], ["Pattabiraman", "Karthik", ""], ["DeBardeleben", "Nathan", ""]]}, {"id": "2004.01764", "submitter": "Nathaniel Bastian PhD", "authors": "Kathleen Kerwin and Nathaniel D. Bastian", "title": "Stacked Generalizations in Imbalanced Fraud Data Sets using Resampling\n  Methods", "comments": "19 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study uses stacked generalization, which is a two-step process of\ncombining machine learning methods, called meta or super learners, for\nimproving the performance of algorithms in step one (by minimizing the error\nrate of each individual algorithm to reduce its bias in the learning set) and\nthen in step two inputting the results into the meta learner with its stacked\nblended output (demonstrating improved performance with the weakest algorithms\nlearning better). The method is essentially an enhanced cross-validation\nstrategy. Although the process uses great computational resources, the\nresulting performance metrics on resampled fraud data show that increased\nsystem cost can be justified. A fundamental key to fraud data is that it is\ninherently not systematic and, as of yet, the optimal resampling methodology\nhas not been identified. Building a test harness that accounts for all\npermutations of algorithm sample set pairs demonstrates that the complex,\nintrinsic data structures are all thoroughly tested. Using a comparative\nanalysis on fraud data that applies stacked generalizations provides useful\ninsight needed to find the optimal mathematical formula to be used for\nimbalanced fraud data sets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:38:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kerwin", "Kathleen", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2004.01819", "submitter": "Rifat Zahan", "authors": "Rifat Zahan, Ian McQuillan and Nathaniel D. Osgood", "title": "DNA Methylation Data to Predict Suicidal and Non-Suicidal Deaths: A\n  Machine Learning Approach", "comments": null, "journal-ref": "In 2018 IEEE International Conference on Healthcare Informatics\n  (ICHI) (pp. 363-365). IEEE (2018, June)", "doi": "10.1109/ICHI.2018.00057", "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this study is to predict suicidal and non-suicidal deaths\nfrom DNA methylation data using a modern machine learning algorithm. We used\nsupport vector machines to classify existing secondary data consisting of\nnormalized values of methylated DNA probe intensities from tissues of two\ncortical brain regions to distinguish suicide cases from control cases. Before\nclassification, we employed Principal component analysis (PCA) and\nt-distributed Stochastic Neighbor Embedding (t-SNE) to reduce the dimension of\nthe data. In comparison to PCA, the modern data visualization method t-SNE\nperforms better in dimensionality reduction. t-SNE accounts for the possible\nnon-linear patterns in low-dimensional data. We applied four-fold\ncross-validation in which the resulting output from t-SNE was used as training\ndata for the Support Vector Machine (SVM). Despite the use of cross-validation,\nthe nominally perfect prediction of suicidal deaths for BA11 data suggests\npossible over-fitting of the model. The study also may have suffered from\n'spectrum bias' since the individuals were only studied from two extreme\nscenarios. This research constitutes a baseline study for classifying suicidal\nand non-suicidal deaths from DNA methylation data. Future studies with larger\nsample size, while possibly incorporating methylation data from living\nindividuals, may reduce the bias and improve the accuracy of the results.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 00:34:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zahan", "Rifat", ""], ["McQuillan", "Ian", ""], ["Osgood", "Nathaniel D.", ""]]}, {"id": "2004.01822", "submitter": "Casey Chu", "authors": "Casey Chu, Kentaro Minami, Kenji Fukumizu", "title": "The equivalence between Stein variational gradient descent and black-box\n  variational inference", "comments": "ICLR 2020, Workshop on Integration of Deep Neural Models and\n  Differential Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize an equivalence between two popular methods for Bayesian\ninference: Stein variational gradient descent (SVGD) and black-box variational\ninference (BBVI). In particular, we show that BBVI corresponds precisely to\nSVGD when the kernel is the neural tangent kernel. Furthermore, we interpret\nSVGD and BBVI as kernel gradient flows; we do this by leveraging the recent\nperspective that views SVGD as a gradient flow in the space of probability\ndistributions and showing that BBVI naturally motivates a Riemannian structure\non that space. We observe that kernel gradient flow also describes dynamics\nfound in the training of generative adversarial networks (GANs). This work\nthereby unifies several existing techniques in variational inference and\ngenerative modeling and identifies the kernel as a fundamental object governing\nthe behavior of these algorithms, motivating deeper analysis of its properties.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 00:39:12 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chu", "Casey", ""], ["Minami", "Kentaro", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2004.01832", "submitter": "Avery Ma", "authors": "Avery Ma, Fartash Faghri, Nicolas Papernot, Amir-massoud Farahmand", "title": "SOAR: Second-Order Adversarial Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a common approach to improving the robustness of deep\nneural networks against adversarial examples. In this work, we propose a novel\nregularization approach as an alternative. To derive the regularizer, we\nformulate the adversarial robustness problem under the robust optimization\nframework and approximate the loss function using a second-order Taylor series\nexpansion. Our proposed second-order adversarial regularizer (SOAR) is an upper\nbound based on the Taylor approximation of the inner-max in the robust\noptimization objective. We empirically show that the proposed method\nsignificantly improves the robustness of networks against the $\\ell_\\infty$ and\n$\\ell_2$ bounded perturbations generated using cross-entropy-based PGD on\nCIFAR-10 and SVHN.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 01:35:07 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 22:52:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ma", "Avery", ""], ["Faghri", "Fartash", ""], ["Papernot", "Nicolas", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2004.01840", "submitter": "Pragya Sur", "authors": "Cynthia Dwork, Christina Ilvento, Guy N. Rothblum, Pragya Sur", "title": "Abstracting Fairness: Oracles, Metrics, and Interpretability", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well understood that classification algorithms, for example, for\ndeciding on loan applications, cannot be evaluated for fairness without taking\ncontext into account. We examine what can be learned from a fairness oracle\nequipped with an underlying understanding of ``true'' fairness. The oracle\ntakes as input a (context, classifier) pair satisfying an arbitrary fairness\ndefinition, and accepts or rejects the pair according to whether the classifier\nsatisfies the underlying fairness truth. Our principal conceptual result is an\nextraction procedure that learns the underlying truth; moreover, the procedure\ncan learn an approximation to this truth given access to a weak form of the\noracle. Since every ``truly fair'' classifier induces a coarse metric, in which\nthose receiving the same decision are at distance zero from one another and\nthose receiving different decisions are at distance one, this extraction\nprocess provides the basis for ensuring a rough form of metric fairness, also\nknown as individual fairness. Our principal technical result is a higher\nfidelity extractor under a mild technical constraint on the weak oracle's\nconception of fairness. Our framework permits the scenario in which many\nclassifiers, with differing outcomes, may all be considered fair. Our results\nhave implications for interpretablity -- a highly desired but poorly defined\nproperty of classification systems that endeavors to permit a human arbiter to\nreject classifiers deemed to be ``unfair'' or illegitimately derived.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 03:14:53 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dwork", "Cynthia", ""], ["Ilvento", "Christina", ""], ["Rothblum", "Guy N.", ""], ["Sur", "Pragya", ""]]}, {"id": "2004.01857", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Milad Sikaroudi, H.R. Tizhoosh, Fakhri Karray, Mark\n  Crowley", "title": "Weighted Fisher Discriminant Analysis in the Input and Feature Spaces", "comments": "Accepted (to appear) in International Conference on Image Analysis\n  and Recognition (ICIAR) 2020, Springer", "journal-ref": "International Conference on Image Analysis and Recognition, vol 2,\n  pp. 3-15. Springer, Cham, 2020", "doi": "10.1007/978-3-030-50516-5_1", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher Discriminant Analysis (FDA) is a subspace learning method which\nminimizes and maximizes the intra- and inter-class scatters of data,\nrespectively. Although, in FDA, all the pairs of classes are treated the same\nway, some classes are closer than the others. Weighted FDA assigns weights to\nthe pairs of classes to address this shortcoming of FDA. In this paper, we\npropose a cosine-weighted FDA as well as an automatically weighted FDA in which\nweights are found automatically. We also propose a weighted FDA in the feature\nspace to establish a weighted kernel FDA for both existing and newly proposed\nweights. Our experiments on the ORL face recognition dataset show the\neffectiveness of the proposed weighting schemes.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:17:53 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Sikaroudi", "Milad", ""], ["Tizhoosh", "H. R.", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.01864", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Theoretical Insights into the Use of Structural Similarity Index In\n  Generative Models and Inferential Autoencoders", "comments": "Accepted (to appear) in International Conference on Image Analysis\n  and Recognition (ICIAR) 2020, Springer", "journal-ref": "International Conference on Image Analysis and Recognition, vol 2,\n  pp. 112-117. Springer, Cham, 2020", "doi": "10.1007/978-3-030-50516-5_10", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models and inferential autoencoders mostly make use of $\\ell_2$\nnorm in their optimization objectives. In order to generate perceptually better\nimages, this short paper theoretically discusses how to use Structural\nSimilarity Index (SSIM) in generative models and inferential autoencoders. We\nfirst review SSIM, SSIM distance metrics, and SSIM kernel. We show that the\nSSIM kernel is a universal kernel and thus can be used in unconditional and\nconditional generated moment matching networks. Then, we explain how to use\nSSIM distance in variational and adversarial autoencoders and unconditional and\nconditional Generative Adversarial Networks (GANs). Finally, we propose to use\nSSIM distance rather than $\\ell_2$ norm in least squares GAN.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:39:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.01875", "submitter": "Nadir Murru", "authors": "Nadir Murru, Rosaria Rossini", "title": "A Bayesian approach for initialization of weights in backpropagation\n  neural net with application to character recognition", "comments": null, "journal-ref": "Neurocomputing, Vol. 193, 92-105, 2016", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence rate of training algorithms for neural networks is heavily\naffected by initialization of weights. In this paper, an original algorithm for\ninitialization of weights in backpropagation neural net is presented with\napplication to character recognition. The initialization method is mainly based\non a customization of the Kalman filter, translating it into Bayesian\nstatistics terms. A metrological approach is used in this context considering\nweights as measurements modeled by mutually dependent normal random variables.\nThe algorithm performance is demonstrated by reporting and discussing results\nof simulation trials. Results are compared with random weights initialization\nand other methods. The proposed method shows an improved convergence rate for\nthe backpropagation training algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 06:42:07 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Murru", "Nadir", ""], ["Rossini", "Rosaria", ""]]}, {"id": "2004.01899", "submitter": "Xuefei Ning", "authors": "Xuefei Ning, Yin Zheng, Tianchen Zhao, Yu Wang, and Huazhong Yang", "title": "A Generic Graph-based Neural Architecture Encoding Scheme for\n  Predictor-based NAS", "comments": "14 pages main text; 10 pages appendix", "journal-ref": "ECCV 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel Graph-based neural ArchiTecture Encoding Scheme,\na.k.a. GATES, to improve the predictor-based neural architecture search.\nSpecifically, different from existing graph-based schemes, GATES models the\noperations as the transformation of the propagating information, which mimics\nthe actual data processing of neural architecture. GATES is a more reasonable\nmodeling of the neural architectures, and can encode architectures from both\nthe \"operation on node\" and \"operation on edge\" cell search spaces\nconsistently. Experimental results on various search spaces confirm GATES's\neffectiveness in improving the performance predictor. Furthermore, equipped\nwith the improved performance predictor, the sample efficiency of the\npredictor-based neural architecture search (NAS) flow is boosted. Codes are\navailable at https://github.com/walkerning/aw_nas.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 09:54:49 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 03:19:33 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 01:06:51 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ning", "Xuefei", ""], ["Zheng", "Yin", ""], ["Zhao", "Tianchen", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2004.01902", "submitter": "Nicolas Boull\\'e", "authors": "Nicolas Boull\\'e, Yuji Nakatsukasa, Alex Townsend", "title": "Rational neural networks", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider neural networks with rational activation functions. The choice of\nthe nonlinear activation function in deep learning architectures is crucial and\nheavily impacts the performance of a neural network. We establish optimal\nbounds in terms of network complexity and prove that rational neural networks\napproximate smooth functions more efficiently than ReLU networks with\nexponentially smaller depth. The flexibility and smoothness of rational\nactivation functions make them an attractive alternative to ReLU, as we\ndemonstrate with numerical experiments.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 10:36:11 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:16:55 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Boull\u00e9", "Nicolas", ""], ["Nakatsukasa", "Yuji", ""], ["Townsend", "Alex", ""]]}, {"id": "2004.01942", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Elsa Rizk, Ali H. Sayed", "title": "Tracking Performance of Online Stochastic Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilization of online stochastic algorithms is popular in large-scale\nlearning settings due to their ability to compute updates on the fly, without\nthe need to store and process data in large batches. When a constant step-size\nis used, these algorithms also have the ability to adapt to drifts in problem\nparameters, such as data or model properties, and track the optimal solution\nwith reasonable accuracy. Building on analogies with the study of adaptive\nfilters, we establish a link between steady-state performance derived under\nstationarity assumptions and the tracking performance of online learners under\nrandom walk models. The link allows us to infer the tracking performance from\nsteady-state expressions directly and almost by inspection.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 14:16:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Vlaski", "Stefan", ""], ["Rizk", "Elsa", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2004.02043", "submitter": "Olivier Bernard", "authors": "Sarah Leclerc, Erik Smistad, Andreas {\\O}stvik, Frederic Cervenansky,\n  Florian Espinosa, Torvald Espeland, Erik Andreas Rye Berg, Thomas Grenier,\n  Carole Lartizien, Pierre-Marc Jodoin, Lasse Lovstakken, Olivier Bernard", "title": "LU-Net: a multi-task network to improve the robustness of segmentation\n  of left ventriclular structures by deep learning in 2D echocardiography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of cardiac structures is one of the fundamental steps to\nestimate volumetric indices of the heart. This step is still performed\nsemi-automatically in clinical routine, and is thus prone to inter- and\nintra-observer variability. Recent studies have shown that deep learning has\nthe potential to perform fully automatic segmentation. However, the current\nbest solutions still suffer from a lack of robustness. In this work, we\nintroduce an end-to-end multi-task network designed to improve the overall\naccuracy of cardiac segmentation while enhancing the estimation of clinical\nindices and reducing the number of outliers. Results obtained on a large open\naccess dataset show that our method outperforms the current best performing\ndeep learning solution and achieved an overall segmentation accuracy lower than\nthe intra-observer variability for the epicardial border (i.e. on average a\nmean absolute error of 1.5mm and a Hausdorff distance of 5.1mm) with 11% of\noutliers. Moreover, we demonstrate that our method can closely reproduce the\nexpert analysis for the end-diastolic and end-systolic left ventricular\nvolumes, with a mean correlation of 0.96 and a mean absolute error of 7.6ml.\nConcerning the ejection fraction of the left ventricle, results are more\ncontrasted with a mean correlation coefficient of 0.83 and an absolute mean\nerror of 5.0%, producing scores that are slightly below the intra-observer\nmargin. Based on this observation, areas for improvement are suggested.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 23:07:53 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Leclerc", "Sarah", ""], ["Smistad", "Erik", ""], ["\u00d8stvik", "Andreas", ""], ["Cervenansky", "Frederic", ""], ["Espinosa", "Florian", ""], ["Espeland", "Torvald", ""], ["Berg", "Erik Andreas Rye", ""], ["Grenier", "Thomas", ""], ["Lartizien", "Carole", ""], ["Jodoin", "Pierre-Marc", ""], ["Lovstakken", "Lasse", ""], ["Bernard", "Olivier", ""]]}, {"id": "2004.02046", "submitter": "Ivan Brugere", "authors": "Ivan Brugere, Tanya Y. Berger-Wolf", "title": "Inferring Network Structure From Data", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.05207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are complex models for underlying data in many application domains.\nIn most instances, raw data is not natively in the form of a network, but\nderived from sensors, logs, images, or other data. Yet, the impact of the\nvarious choices in translating this data to a network have been largely\nunexamined. In this work, we propose a network model selection methodology that\nfocuses on evaluating a network's utility for varying tasks, together with an\nefficiency measure which selects the most parsimonious model. We demonstrate\nthat this network definition matters in several ways for modeling the behavior\nof the underlying system.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 23:30:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Brugere", "Ivan", ""], ["Berger-Wolf", "Tanya Y.", ""]]}, {"id": "2004.02088", "submitter": "Chunyuan Li", "authors": "Yang Zhao, Chunyuan Li, Ping Yu, Jianfeng Gao, Changyou Chen", "title": "Feature Quantization Improves GAN Training", "comments": "The first two authors contributed equally to this manuscript. ICML\n  2020. Code: https://github.com/YangNaruto/FQ-GAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instability in GAN training has been a long-standing problem despite\nremarkable research efforts. We identify that instability issues stem from\ndifficulties of performing feature matching with mini-batch statistics, due to\na fragile balance between the fixed target distribution and the progressively\ngenerated distribution. In this work, we propose Feature Quantization (FQ) for\nthe discriminator, to embed both true and fake data samples into a shared\ndiscrete space. The quantized values of FQ are constructed as an evolving\ndictionary, which is consistent with feature statistics of the recent\ndistribution history. Hence, FQ implicitly enables robust feature matching in a\ncompact space. Our method can be easily plugged into existing GAN models, with\nlittle computational overhead in training. We apply FQ to 3 representative GAN\nmodels on 9 benchmarks: BigGAN for image generation, StyleGAN for face\nsynthesis, and U-GAT-IT for unsupervised image-to-image translation. Extensive\nexperimental results show that the proposed FQ-GAN can improve the FID scores\nof baseline methods by a large margin on a variety of tasks, achieving new\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 04:06:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 00:06:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Zhao", "Yang", ""], ["Li", "Chunyuan", ""], ["Yu", "Ping", ""], ["Gao", "Jianfeng", ""], ["Chen", "Changyou", ""]]}, {"id": "2004.02094", "submitter": "Neda Tavakoli", "authors": "Neda Tavakoli", "title": "Locality Sensitive Hashing-based Sequence Alignment Using Deep\n  Bidirectional LSTM Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Long Short-Term Memory (LSTM) is a special kind of Recurrent\nNeural Network (RNN) architecture which is designed to model sequences and\ntheir long-range dependencies more precisely than RNNs. This paper proposes to\nuse deep bidirectional LSTM for sequence modeling as an approach to perform\nlocality-sensitive hashing (LSH)-based sequence alignment. In particular, we\nuse the deep bidirectional LSTM to learn features of LSH. The obtained LSH is\nthen can be utilized to perform sequence alignment. We demonstrate the\nfeasibility of the modeling sequences using the proposed LSTM-based model by\naligning the short read queries over the reference genome. We use the human\nreference genome as our training dataset, in addition to a set of short reads\ngenerated using Illumina sequencing technology. The ultimate goal is to align\nquery sequences into a reference genome. We first decompose the reference\ngenome into multiple sequences. These sequences are then fed into the\nbidirectional LSTM model and then mapped into fixed-length vectors. These\nvectors are what we call the trained LSH, which can then be used for sequence\nalignment. The case study shows that using the introduced LSTM-based model, we\nachieve higher accuracy with the number of epochs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 05:13:06 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Tavakoli", "Neda", ""]]}, {"id": "2004.02113", "submitter": "Gwenaelle Cunha Sergio", "authors": "Gwenaelle Cunha Sergio and Minho Lee", "title": "Emotional Video to Audio Transformation Using Deep Recurrent Neural\n  Networks and a Neuro-Fuzzy System", "comments": "Published (https://www.hindawi.com/journals/mpe/2020/8478527/)", "journal-ref": "Mathematical Problems in Engineering 2020 (2020) 1-15", "doi": "10.1155/2020/8478527", "report-no": null, "categories": "cs.SD cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating music with emotion similar to that of an input video is a very\nrelevant issue nowadays. Video content creators and automatic movie directors\nbenefit from maintaining their viewers engaged, which can be facilitated by\nproducing novel material eliciting stronger emotions in them. Moreover, there's\ncurrently a demand for more empathetic computers to aid humans in applications\nsuch as augmenting the perception ability of visually and/or hearing impaired\npeople. Current approaches overlook the video's emotional characteristics in\nthe music generation step, only consider static images instead of videos, are\nunable to generate novel music, and require a high level of human effort and\nskills. In this study, we propose a novel hybrid deep neural network that uses\nan Adaptive Neuro-Fuzzy Inference System to predict a video's emotion from its\nvisual features and a deep Long Short-Term Memory Recurrent Neural Network to\ngenerate its corresponding audio signals with similar emotional inkling. The\nformer is able to appropriately model emotions due to its fuzzy properties, and\nthe latter is able to model data with dynamic time properties well due to the\navailability of the previous hidden state information. The novelty of our\nproposed method lies in the extraction of visual emotional features in order to\ntransform them into audio signals with corresponding emotional aspects for\nusers. Quantitative experiments show low mean absolute errors of 0.217 and\n0.255 in the Lindsey and DEAP datasets respectively, and similar global\nfeatures in the spectrograms. This indicates that our model is able to\nappropriately perform domain transformation between visual and audio features.\nBased on experimental results, our model can effectively generate audio that\nmatches the scene eliciting a similar emotion from the viewer in both datasets,\nand music generated by our model is also chosen more often.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 07:18:28 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sergio", "Gwenaelle Cunha", ""], ["Lee", "Minho", ""]]}, {"id": "2004.02131", "submitter": "Wei Ye", "authors": "Wei Ye, Omid Askarisichani, Alex Jones, Ambuj Singh", "title": "DeepMap: Learning Deep Representations for Graph Classification", "comments": "arXiv admin note: text overlap with arXiv:2002.09846", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph-structured data arise in many scenarios. A fundamental problem is to\nquantify the similarities of graphs for tasks such as classification. Graph\nkernels are positive-semidefinite functions that decompose graphs into\nsubstructures and compare them. One problem in the effective implementation of\nthis idea is that the substructures are not independent, which leads to\nhigh-dimensional feature space. In addition, graph kernels cannot capture the\nhigh-order complex interactions between vertices. To mitigate these two\nproblems, we propose a framework called DeepMap to learn deep representations\nfor graph feature maps. The learnt deep representation for a graph is a dense\nand low-dimensional vector that captures complex high-order interactions in a\nvertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to\narbitrary graphs by aligning vertices across graphs and building the receptive\nfield for each vertex. We empirically validate DeepMap on various graph\nclassification benchmarks and demonstrate that it achieves state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 08:49:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ye", "Wei", ""], ["Askarisichani", "Omid", ""], ["Jones", "Alex", ""], ["Singh", "Ambuj", ""]]}, {"id": "2004.02137", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Anomaly Detection and Prototype Selection Using Polyhedron Curvature", "comments": "Accepted (to appear) in Canadian Conference on Artificial\n  Intelligence (Canadian AI conference) 2020, Springer. This version includes\n  supplementary material for derivation of an equation", "journal-ref": "Canadian Conference on Artificial Intelligence, pp. 238-250.\n  Springer, Cham, 2020", "doi": "10.1007/978-3-030-47358-7_23", "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to anomaly detection called Curvature Anomaly\nDetection (CAD) and Kernel CAD based on the idea of polyhedron curvature. Using\nthe nearest neighbors for a point, we consider every data point as the vertex\nof a polyhedron where the more anomalous point has more curvature. We also\npropose inverse CAD (iCAD) and Kernel iCAD for instance ranking and prototype\nselection by looking at CAD from an opposite perspective. We define the concept\nof anomaly landscape and anomaly path and we demonstrate an application for it\nwhich is image denoising. The proposed methods are straightforward and easy to\nimplement. Our experiments on different benchmarks show that the proposed\nmethods are effective for anomaly detection and prototype selection.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 09:50:13 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.02164", "submitter": "Tianchen Zhao", "authors": "Xuefei Ning, Tianchen Zhao, Wenshuo Li, Peng Lei, Yu Wang, Huazhong\n  Yang", "title": "DSA: More Efficient Budgeted Pruning via Differentiable Sparsity\n  Allocation", "comments": "The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Budgeted pruning is the problem of pruning under resource constraints. In\nbudgeted pruning, how to distribute the resources across layers (i.e., sparsity\nallocation) is the key problem. Traditional methods solve it by discretely\nsearching for the layer-wise pruning ratios, which lacks efficiency. In this\npaper, we propose Differentiable Sparsity Allocation (DSA), an efficient\nend-to-end budgeted pruning flow. Utilizing a novel differentiable pruning\nprocess, DSA finds the layer-wise pruning ratios with gradient-based\noptimization. It allocates sparsity in continuous space, which is more\nefficient than methods based on discrete evaluation and search. Furthermore,\nDSA could work in a pruning-from-scratch manner, whereas traditional budgeted\npruning methods are applied to pre-trained models. Experimental results on\nCIFAR-10 and ImageNet show that DSA could achieve superior performance than\ncurrent iterative budgeted pruning methods, and shorten the time cost of the\noverall pruning process by at least 1.5x in the meantime.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 11:28:39 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 11:23:05 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 11:05:53 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 08:13:41 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2020 15:26:14 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ning", "Xuefei", ""], ["Zhao", "Tianchen", ""], ["Li", "Wenshuo", ""], ["Lei", "Peng", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2004.02172", "submitter": "Eniko Sz\\'ekely", "authors": "Suddhasattwa Das, Dimitrios Giannakis, Enik\\H{o} Sz\\'ekely", "title": "An information-geometric approach to feature extraction and moment\n  reconstruction in dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dimension reduction framework for feature extraction and moment\nreconstruction in dynamical systems that operates on spaces of probability\nmeasures induced by observables of the system rather than directly in the\noriginal data space of the observables themselves as in more conventional\nmethods. Our approach is based on the fact that orbits of a dynamical system\ninduce probability measures over the measurable space defined by (partial)\nobservations of the system. We equip the space of these probability measures\nwith a divergence, i.e., a distance between probability distributions, and use\nthis divergence to define a kernel integral operator. The eigenfunctions of\nthis operator create an orthonormal basis of functions that capture different\ntimescales of the dynamical system. One of our main results shows that the\nevolution of the moments of the dynamics-dependent probability measures can be\nrelated to a time-averaging operator on the original dynamical system. Using\nthis result, we show that the moments can be expanded in the eigenfunction\nbasis, thus opening up the avenue for nonparametric forecasting of the moments.\nIf the collection of probability measures is itself a manifold, we can in\naddition equip the statistical manifold with the Riemannian metric and use\ntechniques from information geometry. We present applications to ergodic\ndynamical systems on the 2-torus and the Lorenz 63 system, and show on a\nreal-world example that a small number of eigenvectors is sufficient to\nreconstruct the moments (here the first four moments) of an atmospheric time\nseries, i.e., the realtime multivariate Madden-Julian oscillation index.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:07:21 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Das", "Suddhasattwa", ""], ["Giannakis", "Dimitrios", ""], ["Sz\u00e9kely", "Enik\u0151", ""]]}, {"id": "2004.02173", "submitter": "Wentong Liao", "authors": "Tongxin Hu, Vasileios Iosifidis, Wentong Liao, Hang Zhang, Michael\n  YingYang, Eirini Ntoutsi, and Bodo Rosenhahn", "title": "FairNN- Conjoint Learning of Fair Representations for Fair Decisions", "comments": "Code will be available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose FairNN a neural network that performs joint feature\nrepresentation and classification for fairness-aware learning. Our approach\noptimizes a multi-objective loss function in which (a) learns a fair\nrepresentation by suppressing protected attributes (b) maintains the\ninformation content by minimizing a reconstruction loss and (c) allows for\nsolving a classification task in a fair manner by minimizing the classification\nerror and respecting the equalized odds-based fairness regularized. Our\nexperiments on a variety of datasets demonstrate that such a joint approach is\nsuperior to separate treatment of unfairness in representation learning or\nsupervised learning. Additionally, our regularizers can be adaptively weighted\nto balance the different components of the loss function, thus allowing for a\nvery general framework for conjoint fair representation learning and decision\nmaking.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:08:30 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 20:00:16 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Hu", "Tongxin", ""], ["Iosifidis", "Vasileios", ""], ["Liao", "Wentong", ""], ["Zhang", "Hang", ""], ["YingYang", "Michael", ""], ["Ntoutsi", "Eirini", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2004.02182", "submitter": "Pourya Shamsolmoali", "authors": "Pourya Shamsolmoali, Masoumeh Zareapoor, Linlin Shen, Abdul Hamid\n  Sadka, Jie Yang", "title": "Imbalanced Data Learning by Minority Class Augmentation using Capsule\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The fact that image datasets are often imbalanced poses an intense challenge\nfor deep learning techniques. In this paper, we propose a method to restore the\nbalance in imbalanced images, by coalescing two concurrent methods, generative\nadversarial networks (GANs) and capsule network. In our model, generative and\ndiscriminative networks play a novel competitive game, in which the generator\ngenerates samples towards specific classes from multivariate probabilities\ndistribution. The discriminator of our model is designed in a way that while\nrecognizing the real and fake samples, it is also requires to assign classes to\nthe inputs. Since GAN approaches require fully observed data during training,\nwhen the training samples are imbalanced, the approaches might generate similar\nsamples which leading to data overfitting. This problem is addressed by\nproviding all the available information from both the class components jointly\nin the adversarial training. It improves learning from imbalanced data by\nincorporating the majority distribution structure in the generation of new\nminority samples. Furthermore, the generator is trained with feature matching\nloss function to improve the training convergence. In addition, prevents\ngeneration of outliers and does not affect majority class space. The\nevaluations show the effectiveness of our proposed methodology; in particular,\nthe coalescing of capsule-GAN is effective at recognizing highly overlapping\nclasses with much fewer parameters compared with the convolutional-GAN.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:36:06 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 04:25:36 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 07:47:38 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Shamsolmoali", "Pourya", ""], ["Zareapoor", "Masoumeh", ""], ["Shen", "Linlin", ""], ["Sadka", "Abdul Hamid", ""], ["Yang", "Jie", ""]]}, {"id": "2004.02235", "submitter": "Dvir Samuel", "authors": "Dvir Samuel, Yuval Atzmon and Gal Chechik", "title": "From Generalized zero-shot learning to long-tail with class descriptors", "comments": "Accepted to WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data is predominantly unbalanced and long-tailed, but deep models\nstruggle to recognize rare classes in the presence of frequent classes. Often,\nclasses can be accompanied by side information like textual descriptions, but\nit is not fully clear how to use them for learning with unbalanced long-tail\ndata. Such descriptions have been mostly used in (Generalized) Zero-shot\nlearning (ZSL), suggesting that ZSL with class descriptions may also be useful\nfor long-tail distributions. We describe DRAGON, a late-fusion architecture for\nlong-tail learning with class descriptors. It learns to (1) correct the bias\ntowards head classes on a sample-by-sample basis; and (2) fuse information from\nclass-descriptions to improve the tail-class accuracy. We also introduce new\nbenchmarks CUB-LT, SUN-LT, AWA-LT for long-tail learning with\nclass-descriptions, building on existing learning-with-attributes datasets and\na version of Imagenet-LT with class descriptors. DRAGON outperforms\nstate-of-the-art models on the new benchmark. It is also a new SoTA on existing\nbenchmarks for GFSL with class descriptors (GFSL-d) and standard (vision-only)\nlong-tailed learning ImageNet-LT, CIFAR-10, 100, and Places365.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 15:51:31 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 21:41:26 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:12:28 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 15:17:56 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Samuel", "Dvir", ""], ["Atzmon", "Yuval", ""], ["Chechik", "Gal", ""]]}, {"id": "2004.02273", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Nicola Landro", "title": "Dynamic Decision Boundary for One-class Classifiers applied to\n  non-uniformly Sampled Data", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A typical issue in Pattern Recognition is the non-uniformly sampled data,\nwhich modifies the general performance and capability of machine learning\nalgorithms to make accurate predictions. Generally, the data is considered\nnon-uniformly sampled when in a specific area of data space, they are not\nenough, leading us to misclassification problems. This issue cut down the goal\nof the one-class classifiers decreasing their performance. In this paper, we\npropose a one-class classifier based on the minimum spanning tree with a\ndynamic decision boundary (OCdmst) to make good prediction also in the case we\nhave non-uniformly sampled data. To prove the effectiveness and robustness of\nour approach we compare with the most recent one-class classifier reaching the\nstate-of-the-art in most of them.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:29:36 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Landro", "Nicola", ""]]}, {"id": "2004.02274", "submitter": "Ala'eddin Masadeh", "authors": "Ala'eddin Masadeh, Zhengdao Wang, Ahmed E. Kamal", "title": "Reinforcement Learning Architectures: SAC, TAC, and ESAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trend is to implement intelligent agents capable of analyzing available\ninformation and utilize it efficiently. This work presents a number of\nreinforcement learning (RL) architectures; one of them is designed for\nintelligent agents. The proposed architectures are called selector-actor-critic\n(SAC), tuner-actor-critic (TAC), and estimator-selector-actor-critic (ESAC).\nThese architectures are improved models of a well known architecture in RL\ncalled actor-critic (AC). In AC, an actor optimizes the used policy, while a\ncritic estimates a value function and evaluate the optimized policy by the\nactor. SAC is an architecture equipped with an actor, a critic, and a selector.\nThe selector determines the most promising action at the current state based on\nthe last estimate from the critic. TAC consists of a tuner, a model-learner, an\nactor, and a critic. After receiving the approximated value of the current\nstate-action pair from the critic and the learned model from the model-learner,\nthe tuner uses the Bellman equation to tune the value of the current\nstate-action pair. ESAC is proposed to implement intelligent agents based on\ntwo ideas, which are lookahead and intuition. Lookahead appears in estimating\nthe values of the available actions at the next state, while the intuition\nappears in maximizing the probability of selecting the most promising action.\nThe newly added elements are an underlying model learner, an estimator, and a\nselector. The model learner is used to approximate the underlying model. The\nestimator uses the approximated value function, the learned underlying model,\nand the Bellman equation to estimate the values of all actions at the next\nstate. The selector is used to determine the most promising action at the next\nstate, which will be used by the actor to optimize the used policy. Finally,\nthe results show the superiority of ESAC compared with the other architectures.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:31:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Masadeh", "Ala'eddin", ""], ["Wang", "Zhengdao", ""], ["Kamal", "Ahmed E.", ""]]}, {"id": "2004.02290", "submitter": "Jude Tchaye-Kondi", "authors": "Jude Tchaye-Kondi, Yanlong Zhai, Liehuang Zhu", "title": "A new hashing based nearest neighbors selection technique for big\n  datasets", "comments": "8 pages,6 figures", "journal-ref": null, "doi": "10.5121/csit.2021.110708", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KNN has the reputation to be the word simplest but efficient supervised\nlearning algorithm used for either classification or regression. KNN prediction\nefficiency highly depends on the size of its training data but when this\ntraining data grows KNN suffers from slowness in making decisions since it\nneeds to search nearest neighbors within the entire dataset at each decision\nmaking. This paper proposes a new technique that enables the selection of\nnearest neighbors directly in the neighborhood of a given observation. The\nproposed approach consists of dividing the data space into subcells of a\nvirtual grid built on top of data space. The mapping between the data points\nand subcells is performed using hashing. When it comes to select the nearest\nneighbors of a given observation, we firstly identify the cell the observation\nbelongs by using hashing, and then we look for nearest neighbors from that\ncentral cell and cells around it layer by layer. From our experiment\nperformance analysis on publicly available datasets, our algorithm outperforms\nthe original KNN in time efficiency with a prediction quality as good as that\nof KNN it also offers competitive performance with solutions like KDtree\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:36:00 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 03:26:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tchaye-Kondi", "Jude", ""], ["Zhai", "Yanlong", ""], ["Zhu", "Liehuang", ""]]}, {"id": "2004.02319", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "ReRe: A Lightweight Real-time Ready-to-Go Anomaly Detection Approach for\n  Time Series", "comments": "10 pages, 9 figures, COMPSAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is an active research topic in many different fields such\nas intrusion detection, network monitoring, system health monitoring, IoT\nhealthcare, etc. However, many existing anomaly detection approaches require\neither human intervention or domain knowledge, and may suffer from high\ncomputation complexity, consequently hindering their applicability in\nreal-world scenarios. Therefore, a lightweight and ready-to-go approach that is\nable to detect anomalies in real-time is highly sought-after. Such an approach\ncould be easily and immediately applied to perform time series anomaly\ndetection on any commodity machine. The approach could provide timely anomaly\nalerts and by that enable appropriate countermeasures to be undertaken as early\nas possible. With these goals in mind, this paper introduces ReRe, which is a\nReal-time Ready-to-go proactive Anomaly Detection algorithm for streaming time\nseries. ReRe employs two lightweight Long Short-Term Memory (LSTM) models to\npredict and jointly determine whether or not an upcoming data point is\nanomalous based on short-term historical data points and two long-term\nself-adaptive thresholds. Experiments based on real-world time-series datasets\ndemonstrate the good performance of ReRe in real-time anomaly detection without\nrequiring human intervention or domain knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:26:24 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:12:51 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2004.02322", "submitter": "Kadierdan Kaheman", "authors": "Kadierdan Kaheman, J.Nathan Kutz, Steven L. Brunton", "title": "SINDy-PI: A Robust Algorithm for Parallel Implicit Sparse Identification\n  of Nonlinear Dynamics", "comments": "25 pages, 9 figures, 5 tables", "journal-ref": null, "doi": "10.1098/rspa.2020.0279", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately modeling the nonlinear dynamics of a system from measurement data\nis a challenging yet vital topic. The sparse identification of nonlinear\ndynamics (SINDy) algorithm is one approach to discover dynamical systems models\nfrom data. Although extensions have been developed to identify implicit\ndynamics, or dynamics described by rational functions, these extensions are\nextremely sensitive to noise. In this work, we develop SINDy-PI (parallel,\nimplicit), a robust variant of the SINDy algorithm to identify implicit\ndynamics and rational nonlinearities. The SINDy-PI framework includes multiple\noptimization algorithms and a principled approach to model selection. We\ndemonstrate the ability of this algorithm to learn implicit ordinary and\npartial differential equations and conservation laws from limited and noisy\ndata. In particular, we show that the proposed approach is several orders of\nmagnitude more noise robust than previous approaches, and may be used to\nidentify a class of complex ODE and PDE dynamics that were previously\nunattainable with SINDy, including for the double pendulum dynamics and the\nBelousov Zhabotinsky (BZ) reaction.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:35:53 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 23:33:14 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kaheman", "Kadierdan", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "2004.02326", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier and Vladimir Makarenkov", "title": "XtracTree for Regulator Validation of Bagging Methods Used in Retail\n  Banking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap aggregation, known as bagging, is one of the most popular ensemble\nmethods used in machine learning (ML). An ensemble method is a supervised ML\nmethod that combines multiple hypotheses to form a single hypothesis used for\nprediction. A bagging algorithm combines multiple classifiers modelled on\ndifferent sub-samples of the same data set to build one large classifier. Large\nretail banks are nowadays using the power of ML algorithms, including decision\ntrees and random forests, to optimize the retail banking activities. However,\nAI bank researchers face a strong challenge from their own model validation\ndepartment as well as from national financial regulators. Each proposed ML\nmodel has to be validated and clear rules for every algorithm-based decision\nhave to be established. In this context, we propose XtracTree, an algorithm\nthat is capable of effectively converting an ML bagging classifier, such as a\ndecision tree or a random forest, into simple \"if-then\" rules satisfying the\nrequirements of model validation. Our algorithm is also capable of highlighting\nthe decision path for each individual sample or a group of samples, addressing\nany concern from the regulators regarding ML \"black-box\". We use a public loan\ndata set from Kaggle to illustrate the usefulness of our approach. Our\nexperiments indicate that, using XtracTree, we are able to ensure a better\nunderstanding for our model, leading to an easier model validation by national\nfinancial regulators and the internal model validation department.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:57:06 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:32:03 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Charlier", "Jeremy", ""], ["Makarenkov", "Vladimir", ""]]}, {"id": "2004.02328", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker", "title": "Asymptotic normality of robust risk minimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates asymptotic properties of a class of algorithms that\ncan be viewed as robust analogues of the classical empirical risk minimization.\nThese strategies are based on replacing the usual empirical average by a robust\nproxy of the mean, such as the (version of) the median-of-means estimator. It\nis well known by now that the excess risk of resulting estimators often\nconverges to 0 at optimal rates under much weaker assumptions than those\nrequired by their \"classical\" counterparts. However, much less is known about\nthe asymptotic properties of the estimators themselves, for instance, whether\nrobust analogues of the maximum likelihood estimators are asymptotically\nefficient. We make a step towards answering these questions and show that for a\nwide class of parametric problems, minimizers of the appropriately defined\nrobust proxy of the risk converge to the minimizers of the true risk at the\nsame rate, and often have the same asymptotic variance, as the estimators\nobtained by minimizing the usual empirical risk. Moreover, our results show\nthat robust algorithms based on the so-called \"min-max\" type procedures in many\ncases provably outperform, is the asymptotic sense, algorithms based on direct\nrisk minimization.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 22:03:03 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 05:37:18 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 21:26:39 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Minsker", "Stanislav", ""]]}, {"id": "2004.02334", "submitter": "Thamme Gowda", "authors": "Thamme Gowda, Jonathan May", "title": "Finding the Optimal Vocabulary Size for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.352", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We cast neural machine translation (NMT) as a classification task in an\nautoregressive setting and analyze the limitations of both classification and\nautoregression components. Classifiers are known to perform better with\nbalanced class distributions during training. Since the Zipfian nature of\nlanguages causes imbalanced classes, we explore its effect on NMT. We analyze\nthe effect of various vocabulary sizes on NMT performance on multiple languages\nwith many data sizes, and reveal an explanation for why certain vocabulary\nsizes are better than others.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 22:17:34 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:19:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gowda", "Thamme", ""], ["May", "Jonathan", ""]]}, {"id": "2004.02336", "submitter": "He Li", "authors": "Xi Chen and Jason D. Lee and He Li and Yun Yang", "title": "Distributed Estimation for Principal Component Analysis: an Enlarged\n  Eigenspace Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing size of modern data sets brings many challenges to the existing\nstatistical estimation approaches, which calls for new distributed\nmethodologies. This paper studies distributed estimation for a fundamental\nstatistical machine learning problem, principal component analysis (PCA).\nDespite the massive literature on top eigenvector estimation, much less is\npresented for the top-$L$-dim ($L>1$) eigenspace estimation, especially in a\ndistributed manner. We propose a novel multi-round algorithm for constructing\ntop-$L$-dim eigenspace for distributed data. Our algorithm takes advantage of\nshift-and-invert preconditioning and convex optimization. Our estimator is\ncommunication-efficient and achieves a fast convergence rate. In contrast to\nthe existing divide-and-conquer algorithm, our approach has no restriction on\nthe number of machines. Theoretically, the traditional Davis-Kahan theorem\nrequires the explicit eigengap assumption to estimate the top-$L$-dim\neigenspace. To abandon this eigengap assumption, we consider a new route in our\nanalysis: instead of exactly identifying the top-$L$-dim eigenspace, we show\nthat our estimator is able to cover the targeted top-$L$-dim population\neigenspace. Our distributed algorithm can be applied to a wide range of\nstatistical problems based on PCA, such as principal component regression and\nsingle index model. Finally, We provide simulation studies to demonstrate the\nperformance of the proposed distributed estimator.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 22:28:08 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 19:43:28 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 02:24:02 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Chen", "Xi", ""], ["Lee", "Jason D.", ""], ["Li", "He", ""], ["Yang", "Yun", ""]]}, {"id": "2004.02353", "submitter": "Jie Chen", "authors": "Jie Chen, Joel Vaughan, Vijayan N. Nair, Agus Sudjianto", "title": "Adaptive Explainable Neural Networks (AxNNs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning techniques have been successfully applied in several\nfields, the black-box nature of the models presents challenges for interpreting\nand explaining the results. We develop a new framework called Adaptive\nExplainable Neural Networks (AxNN) for achieving the dual goals of good\npredictive performance and model interpretability. For predictive performance,\nwe build a structured neural network made up of ensembles of generalized\nadditive model networks and additive index models (through explainable neural\nnetworks) using a two-stage process. This can be done using either a boosting\nor a stacking ensemble. For interpretability, we show how to decompose the\nresults of AxNN into main effects and higher-order interaction effects. The\ncomputations are inherited from Google's open source tool AdaNet and can be\nefficiently accelerated by training with distributed computing. The results are\nillustrated on simulated and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:40:57 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 06:18:04 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Jie", ""], ["Vaughan", "Joel", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2004.02359", "submitter": "Ranadeep Daw", "authors": "Ranadeep Daw, Zhuoqiong He", "title": "Deep Neural Network in Cusp Catastrophe Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophe theory was originally proposed to study dynamical systems that\nexhibit sudden shifts in behavior arising from small changes in input. These\nmodels can generate reasonable explanation behind abrupt jumps in nonlinear\ndynamic models. Among the different catastrophe models, the Cusp Catastrophe\nmodel attracted the most attention due to it's relatively simpler dynamics and\nrich domain of application. Due to the complex behavior of the response, the\nparameter space becomes highly non-convex and hence it becomes very hard to\noptimize to figure out the generating parameters. Instead of solving for these\ngenerating parameters, we demonstrated how a Machine learning model can be\ntrained to learn the dynamics of the Cusp catastrophe models, without ever\nreally solving for the generating model parameters. Simulation studies and\napplication on a few famous datasets are used to validate our approach. To our\nknowledge, this is the first paper of such kind where a neural network based\napproach has been applied in Cusp Catastrophe model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 00:25:41 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 02:30:54 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Daw", "Ranadeep", ""], ["He", "Zhuoqiong", ""]]}, {"id": "2004.02360", "submitter": "Zezhong Zhang", "authors": "Zezhong Zhang, Keyu Nie and Ted Tao Yuan", "title": "Moving Metric Detection and Alerting System at eBay", "comments": "The work is oral presented on the AAAI-20 Workshop on Cloud\n  Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At eBay, there are thousands of product health metrics for different domain\nteams to monitor. We built a two-phase alerting system to notify users with\nactionable alerts based on anomaly detection and alert retrieval. In the first\nphase, we developed an efficient anomaly detection algorithm, called Moving\nMetric Detector (MMD), to identify potential alerts among metrics with\ndistribution agnostic criteria. In the second alert retrieval phase, we built\nadditional logic with feedbacks to select valid actionable alerts with\npoint-wise ranking model and business rules. Compared with other trend and\nseasonality decomposition methods, our decomposer is faster and better to\ndetect anomalies in unsupervised cases. Our two-phase approach dramatically\nimproves alert precision and avoids alert spamming in eBay production.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 00:28:39 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Zezhong", ""], ["Nie", "Keyu", ""], ["Yuan", "Ted Tao", ""]]}, {"id": "2004.02380", "submitter": "Philippe Morere", "authors": "Philippe Morere and Fabio Ramos", "title": "Intrinsic Exploration as Multi-Objective RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic motivation enables reinforcement learning (RL) agents to explore\nwhen rewards are very sparse, where traditional exploration heuristics such as\nBoltzmann or e-greedy would typically fail. However, intrinsic exploration is\ngenerally handled in an ad-hoc manner, where exploration is not treated as a\ncore objective of the learning process; this weak formulation leads to\nsub-optimal exploration performance. To overcome this problem, we propose a\nframework based on multi-objective RL where both exploration and exploitation\nare being optimized as separate objectives. This formulation brings the balance\nbetween exploration and exploitation at a policy level, resulting in advantages\nover traditional methods. This also allows for controlling exploration while\nlearning, at no extra cost. Such strategies achieve a degree of control over\nagent exploration that was previously unattainable with classic or intrinsic\nrewards. We demonstrate scalability to continuous state-action spaces by\npresenting a method (EMU-Q) based on our framework, guiding exploration towards\nregions of higher value-function uncertainty. EMU-Q is experimentally shown to\noutperform classic exploration techniques and other intrinsic RL methods on a\ncontinuous control benchmark and on a robotic manipulator.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 02:37:29 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Morere", "Philippe", ""], ["Ramos", "Fabio", ""]]}, {"id": "2004.02382", "submitter": "Raed Al Kontar", "authors": "Moyan Li, Raed Kontar", "title": "On Negative Transfer and Structure of Latent Functions in Multi-output\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-output Gaussian process ($\\mathcal{MGP}$) is based on the\nassumption that outputs share commonalities, however, if this assumption does\nnot hold negative transfer will lead to decreased performance relative to\nlearning outputs independently or in subsets. In this article, we first define\nnegative transfer in the context of an $\\mathcal{MGP}$ and then derive\nnecessary conditions for an $\\mathcal{MGP}$ model to avoid negative transfer.\nSpecifically, under the convolution construction, we show that avoiding\nnegative transfer is mainly dependent on having a sufficient number of latent\nfunctions $Q$ regardless of the flexibility of the kernel or inference\nprocedure used. However, a slight increase in $Q$ leads to a large increase in\nthe number of parameters to be estimated. To this end, we propose two latent\nstructures that scale to arbitrarily large datasets, can avoid negative\ntransfer and allow any kernel or sparse approximations to be used within. These\nstructures also allow regularization which can provide consistent and automatic\nselection of related outputs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 02:47:30 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Li", "Moyan", ""], ["Kontar", "Raed", ""]]}, {"id": "2004.02391", "submitter": "Xinglei Wang", "authors": "Xinglei Wang, Xuefeng Guan, Jun Cao, Na Zhang, Huayi Wu", "title": "Forecast Network-Wide Traffic States for Multiple Steps Ahead: A Deep\n  Learning Approach Considering Dynamic Non-Local Spatial Correlation and\n  Non-Stationary Temporal Dependency", "comments": "29 pages, 16 figures, 3 tables", "journal-ref": "Transportation research part C: emerging technologies. 119 (2020):\n  102763", "doi": "10.1016/j.trc.2020.102763", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining accurate information about future traffic flows of all links in a\ntraffic network is of great importance for traffic management and control\napplications. This research studies two particular problems in traffic\nforecasting: (1) capture the dynamic and non-local spatial correlation between\ntraffic links and (2) model the dynamics of temporal dependency for accurate\nmultiple steps ahead predictions. To address these issues, we propose a deep\nlearning framework named Spatial-Temporal Sequence to Sequence model\n(STSeq2Seq). This model builds on sequence to sequence (seq2seq) architecture\nto capture temporal feature and relies on graph convolution for aggregating\nspatial information. Moreover, STSeq2Seq defines and constructs pattern-aware\nadjacency matrices (PAMs) based on pair-wise similarity of the recent traffic\npatterns on traffic links and integrate it into graph convolution operation. It\nalso deploys a novel seq2sesq architecture which couples a convolutional\nencoder and a recurrent decoder with attention mechanism for dynamic modeling\nof long-range dependence between different time steps. We conduct extensive\nexperiments using two publicly-available large-scale traffic datasets and\ncompare STSeq2Seq with other baseline models. The numerical results demonstrate\nthat the proposed model achieves state-of-the-art forecasting performance in\nterms of various error measures. The ablation study verifies the effectiveness\nof PAMs in capturing dynamic non-local spatial correlation and the superiority\nof proposed seq2seq architecture in modeling non-stationary temporal dependency\nfor multiple steps ahead prediction. Furthermore, qualitative analysis is\nconducted on PAMs as well as the attention weights for model interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 03:40:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wang", "Xinglei", ""], ["Guan", "Xuefeng", ""], ["Cao", "Jun", ""], ["Zhang", "Na", ""], ["Wu", "Huayi", ""]]}, {"id": "2004.02396", "submitter": "Jun Chen", "authors": "Jun Chen, Liang Liu, Yong Liu, Xianfang Zeng", "title": "A Learning Framework for n-bit Quantized Neural Networks toward FPGAs", "comments": "This paper has been accepted for publication in the IEEE Transactions\n  on Neural Networks and Learning Systems", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems 2020", "doi": "10.1109/TNNLS.2020.2980041", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantized neural network (QNN) is an efficient approach for network\ncompression and can be widely used in the implementation of FPGAs. This paper\nproposes a novel learning framework for n-bit QNNs, whose weights are\nconstrained to the power of two. To solve the gradient vanishing problem, we\npropose a reconstructed gradient function for QNNs in back-propagation\nalgorithm that can directly get the real gradient rather than estimating an\napproximate gradient of the expected loss. We also propose a novel QNN\nstructure named n-BQ-NN, which uses shift operation to replace the multiply\noperation and is more suitable for the inference on FPGAs. Furthermore, we also\ndesign a shift vector processing element (SVPE) array to replace all 16-bit\nmultiplications with SHIFT operations in convolution operation on FPGAs. We\nalso carry out comparable experiments to evaluate our framework. The\nexperimental results show that the quantized models of ResNet, DenseNet and\nAlexNet through our learning framework can achieve almost the same accuracies\nwith the original full-precision models. Moreover, when using our learning\nframework to train our n-BQ-NN from scratch, it can achieve state-of-the-art\nresults compared with typical low-precision QNNs. Experiments on Xilinx ZCU102\nplatform show that our n-BQ-NN with our SVPE can execute 2.9 times faster than\nwith the vector processing element (VPE) in inference. As the SHIFT operation\nin our SVPE array will not consume Digital Signal Processings (DSPs) resources\non FPGAs, the experiments have shown that the use of SVPE array also reduces\naverage energy consumption to 68.7% of the VPE array with 16-bit.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 04:21:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chen", "Jun", ""], ["Liu", "Liang", ""], ["Liu", "Yong", ""], ["Zeng", "Xianfang", ""]]}, {"id": "2004.02401", "submitter": "Wei Peng", "authors": "Choon Meng Lee, Jianfeng Liu, Wei Peng", "title": "Applying Cyclical Learning Rate to Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In training deep learning networks, the optimizer and related learning rate\nare often used without much thought or with minimal tuning, even though it is\ncrucial in ensuring a fast convergence to a good quality minimum of the loss\nfunction that can also generalize well on the test dataset. Drawing inspiration\nfrom the successful application of cyclical learning rate policy for computer\nvision related convolutional networks and datasets, we explore how cyclical\nlearning rate can be applied to train transformer-based neural networks for\nneural machine translation. From our carefully designed experiments, we show\nthat the choice of optimizers and the associated cyclical learning rate policy\ncan have a significant impact on the performance. In addition, we establish\nguidelines when applying cyclical learning rates to neural machine translation\ntasks. Thus with our work, we hope to raise awareness of the importance of\nselecting the right optimizers and the accompanying learning rate policy, at\nthe same time, encourage further research into easy-to-use learning rate\npolicies.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 04:45:49 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lee", "Choon Meng", ""], ["Liu", "Jianfeng", ""], ["Peng", "Wei", ""]]}, {"id": "2004.02423", "submitter": "Darren Yates", "authors": "Darren Yates and Md Zahidul Islam", "title": "FastForest: Increasing Random Forest Processing Speed While Maintaining\n  Accuracy", "comments": "20 pages, 10 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forest remains one of Data Mining's most enduring ensemble algorithms,\nachieving well-documented levels of accuracy and processing speed, as well as\nregularly appearing in new research. However, with data mining now reaching the\ndomain of hardware-constrained devices such as smartphones and Internet of\nThings (IoT) devices, there is continued need for further research into\nalgorithm efficiency to deliver greater processing speed without sacrificing\naccuracy. Our proposed FastForest algorithm delivers an average 24% increase in\nprocessing speed compared with Random Forest whilst maintaining (and frequently\nexceeding) it on classification accuracy over tests involving 45 datasets.\nFastForest achieves this result through a combination of three optimising\ncomponents - Subsample Aggregating ('Subbagging'), Logarithmic Split-Point\nSampling and Dynamic Restricted Subspacing. Moreover, detailed testing of\nSubbagging sizes has found an optimal scalar delivering a positive mix of\nprocessing performance and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 06:37:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yates", "Darren", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "2004.02425", "submitter": "Kirankumar Shiragur", "authors": "Nima Anari, Moses Charikar, Kirankumar Shiragur, Aaron Sidford", "title": "The Bethe and Sinkhorn Permanents of Low Rank Matrices and Implications\n  for Profile Maximum Likelihood", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of computing the likelihood of the\nprofile of a discrete distribution, i.e., the probability of observing the\nmultiset of element frequencies, and computing a profile maximum likelihood\n(PML) distribution, i.e., a distribution with the maximum profile likelihood.\nFor each problem we provide polynomial time algorithms that given $n$ i.i.d.\\\nsamples from a discrete distribution, achieve an approximation factor of\n$\\exp\\left(-O(\\sqrt{n} \\log n) \\right)$, improving upon the previous best-known\nbound achievable in polynomial time of $\\exp(-O(n^{2/3} \\log n))$ (Charikar,\nShiragur and Sidford, 2019). Through the work of Acharya, Das, Orlitsky and\nSuresh (2016), this implies a polynomial time universal estimator for symmetric\nproperties of discrete distributions in a broader range of error parameter.\n  We achieve these results by providing new bounds on the quality of\napproximation of the Bethe and Sinkhorn permanents (Vontobel, 2012 and 2014).\nWe show that each of these are $\\exp(O(k \\log(N/k)))$ approximations to the\npermanent of $N \\times N$ matrices with non-negative rank at most $k$,\nimproving upon the previous known bounds of $\\exp(O(N))$. To obtain our results\non PML, we exploit the fact that the PML objective is proportional to the\npermanent of a certain Vandermonde matrix with $\\sqrt{n}$ distinct columns,\ni.e. with non-negative rank at most $\\sqrt{n}$. As a by-product of our work we\nestablish a surprising connection between the convex relaxation in prior work\n(CSS19) and the well-studied Bethe and Sinkhorn approximations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 06:40:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Anari", "Nima", ""], ["Charikar", "Moses", ""], ["Shiragur", "Kirankumar", ""], ["Sidford", "Aaron", ""]]}, {"id": "2004.02435", "submitter": "Mahesh Subedar", "authors": "Shashank Bujimalla, Mahesh Subedar, Omesh Tickoo", "title": "B-SCST: Bayesian Self-Critical Sequence Training for Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian deep neural networks (DNNs) can provide a mathematically grounded\nframework to quantify uncertainty in predictions from image captioning models.\nWe propose a Bayesian variant of policy-gradient based reinforcement learning\ntraining technique for image captioning models to directly optimize\nnon-differentiable image captioning quality metrics such as CIDEr-D. We extend\nthe well-known Self-Critical Sequence Training (SCST) approach for image\ncaptioning models by incorporating Bayesian inference, and refer to it as\nB-SCST. The \"baseline\" for the policy-gradients in B-SCST is generated by\naveraging predictive quality metrics (CIDEr-D) of the captions drawn from the\ndistribution obtained using a Bayesian DNN model. We infer this predictive\ndistribution using Monte Carlo (MC) dropout approximate variational inference.\nWe show that B-SCST improves CIDEr-D scores on Flickr30k, MS COCO and VizWiz\nimage captioning datasets, compared to the SCST approach. We also provide a\nstudy of uncertainty quantification for the predicted captions, and demonstrate\nthat it correlates well with the CIDEr-D scores. To our knowledge, this is the\nfirst such analysis, and it can improve the interpretability of image\ncaptioning model outputs, which is critical for practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:07:41 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:37:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bujimalla", "Shashank", ""], ["Subedar", "Mahesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "2004.02441", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Pratik Chaudhari, Jonas Mueller, Alexander J. Smola", "title": "TraDE: Transformers for Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TraDE, a self-attention-based architecture for auto-regressive\ndensity estimation with continuous and discrete valued data. Our model is\ntrained using a penalized maximum likelihood objective, which ensures that\nsamples from the density estimate resemble the training data distribution. The\nuse of self-attention means that the model need not retain conditional\nsufficient statistics during the auto-regressive process beyond what is needed\nfor each covariate. On standard tabular and image data benchmarks, TraDE\nproduces significantly better density estimates than existing approaches such\nas normalizing flow estimators and recurrent auto-regressive models. However\nlog-likelihood on held-out data only partially reflects how useful these\nestimates are in real-world applications. In order to systematically evaluate\ndensity estimators, we present a suite of tasks such as regression using\ngenerated samples, out-of-distribution detection, and robustness to noise in\nthe training data and demonstrate that TraDE works well in these scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:32:51 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 20:22:00 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Fakoor", "Rasool", ""], ["Chaudhari", "Pratik", ""], ["Mueller", "Jonas", ""], ["Smola", "Alexander J.", ""]]}, {"id": "2004.02551", "submitter": "Guillaume Tauzin", "authors": "Guillaume Tauzin, Umberto Lupo, Lewis Tunstall, Julian Burella\n  P\\'erez, Matteo Caorsi, Wojciech Reise, Anibal Medina-Mardones, Alberto\n  Dassatti and Kathryn Hess", "title": "giotto-tda: A Topological Data Analysis Toolkit for Machine Learning and\n  Data Exploration", "comments": "7 pages, 2 figures", "journal-ref": "NeurIPS 2020 workshop \"Topological Data Analysis and beyond\"\n  (https://openreview.net/forum?id=fjQtZJOCTXf); JMLR 22\n  (https://www.jmlr.org/papers/v22/20-325.html)", "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce giotto-tda, a Python library that integrates high-performance\ntopological data analysis with machine learning via a scikit-learn-compatible\nAPI and state-of-the-art C++ implementations. The library's ability to handle\nvarious types of data is rooted in a wide range of preprocessing techniques,\nand its strong focus on data exploration and interpretability is aided by an\nintuitive plotting API. Source code, binaries, examples, and documentation can\nbe found at https://github.com/giotto-ai/giotto-tda.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 10:53:57 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 19:05:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Tauzin", "Guillaume", ""], ["Lupo", "Umberto", ""], ["Tunstall", "Lewis", ""], ["P\u00e9rez", "Julian Burella", ""], ["Caorsi", "Matteo", ""], ["Reise", "Wojciech", ""], ["Medina-Mardones", "Anibal", ""], ["Dassatti", "Alberto", ""], ["Hess", "Kathryn", ""]]}, {"id": "2004.02561", "submitter": "Tom Vander Aa", "authors": "Tom Vander Aa, Xiangju Qin, Paul Blomstedt, Roel Wuyts, Wilfried\n  Verachtert, Samuel Kaski", "title": "A High-Performance Implementation of Bayesian Matrix Factorization with\n  Limited Communication", "comments": "European Commission Project: EPEEC - European joint Effort toward a\n  Highly Productive Programming Environment for Heterogeneous Exascale\n  Computing (EC-H2020-80151)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is a very common machine learning technique in\nrecommender systems. Bayesian Matrix Factorization (BMF) algorithms would be\nattractive because of their ability to quantify uncertainty in their\npredictions and avoid over-fitting, combined with high prediction accuracy.\nHowever, they have not been widely used on large-scale data because of their\nprohibitive computational cost. In recent work, efforts have been made to\nreduce the cost, both by improving the scalability of the BMF algorithm as well\nas its implementation, but so far mainly separately. In this paper we show that\nthe state-of-the-art of both approaches to scalability can be combined. We\ncombine the recent highly-scalable Posterior Propagation algorithm for BMF,\nwhich parallelizes computation of blocks of the matrix, with a distributed BMF\nimplementation that users asynchronous communication within each block. We show\nthat the combination of the two methods gives substantial improvements in the\nscalability of BMF on web-scale datasets, when the goal is to reduce the\nwall-clock time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:16:30 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 07:41:19 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Aa", "Tom Vander", ""], ["Qin", "Xiangju", ""], ["Blomstedt", "Paul", ""], ["Wuyts", "Roel", ""], ["Verachtert", "Wilfried", ""], ["Kaski", "Samuel", ""]]}, {"id": "2004.02569", "submitter": "Jyri Kimari", "authors": "Jussi M\\\"a\\\"att\\\"a, Viacheslav Bazaliy, Jyri Kimari, Flyura\n  Djurabekova, Kai Nordlund, Teemu Roos", "title": "Gradient-Based Training and Pruning of Radial Basis Function Networks\n  with an Application in Materials Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications, especially in physics and other sciences, call for easily\ninterpretable and robust machine learning techniques. We propose a fully\ngradient-based technique for training radial basis function networks with an\nefficient and scalable open-source implementation. We derive novel closed-form\noptimization criteria for pruning the models for continuous as well as binary\ndata which arise in a challenging real-world material physics problem. The\npruned models are optimized to provide compact and interpretable versions of\nlarger models based on informed assumptions about the data distribution.\nVisualizations of the pruned models provide insight into the atomic\nconfigurations that determine atom-level migration processes in solid matter;\nthese results may inform future research on designing more suitable descriptors\nfor use with machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:32:37 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["M\u00e4\u00e4tt\u00e4", "Jussi", ""], ["Bazaliy", "Viacheslav", ""], ["Kimari", "Jyri", ""], ["Djurabekova", "Flyura", ""], ["Nordlund", "Kai", ""], ["Roos", "Teemu", ""]]}, {"id": "2004.02581", "submitter": "Najmeh Abiri", "authors": "Najmeh Abiri and Mattias Ohlsson", "title": "Variational auto-encoders with Student's t-prior", "comments": null, "journal-ref": "ESANN 2019 Proceedings, 27th European Symposium on Artificial\n  Neural Networks, Computational Intelligence and Machine Learning: Bruges\n  April 2019, Bruges: ESANN , 2019, p. 415-420", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a new structure for the variational auto-encoders (VAEs) prior,\nwith the weakly informative multivariate Student's t-distribution. In the\nproposed model all distribution parameters are trained, thereby allowing for a\nmore robust approximation of the underlying data distribution. We used\nFashion-MNIST data in two experiments to compare the proposed VAEs with the\nstandard Gaussian priors. Both experiments showed a better reconstruction of\nthe images with VAEs using Student's t-prior distribution.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:54:20 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Abiri", "Najmeh", ""], ["Ohlsson", "Mattias", ""]]}, {"id": "2004.02584", "submitter": "Najmeh Abiri", "authors": "Najmeh Abiri, Bj\\\"orn Linse, Patrik Ed\\'en and Mattias Ohlsson", "title": "Establishing strong imputation performance of a denoising autoencoder in\n  a wide range of missing data problems", "comments": null, "journal-ref": "Neurocomputing Volume 365, 6 November 2019, Pages 137-146", "doi": "10.1016/j.neucom.2019.07.065", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Dealing with missing data in data analysis is inevitable. Although powerful\nimputation methods that address this problem exist, there is still much room\nfor improvement. In this study, we examined single imputation based on deep\nautoencoders, motivated by the apparent success of deep learning to efficiently\nextract useful dataset features. We have developed a consistent framework for\nboth training and imputation. Moreover, we benchmarked the results against\nstate-of-the-art imputation methods on different data sizes and\ncharacteristics. The work was not limited to the one-type variable dataset; we\nalso imputed missing data with multi-type variables, e.g., a combination of\nbinary, categorical, and continuous attributes. To evaluate the imputation\nmethods, we randomly corrupted the complete data, with varying degrees of\ncorruption, and then compared the imputed and original values. In all\nexperiments, the developed autoencoder obtained the smallest error for all\nranges of initial data corruption.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:00:30 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Abiri", "Najmeh", ""], ["Linse", "Bj\u00f6rn", ""], ["Ed\u00e9n", "Patrik", ""], ["Ohlsson", "Mattias", ""]]}, {"id": "2004.02593", "submitter": "Floris Geerts", "authors": "Floris Geerts, Filip Mazowiecki and Guillermo A. P\\'erez", "title": "Let's Agree to Degree: Comparing Graph Convolutional Networks in the\n  Message-Passing Framework", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we cast neural networks defined on graphs as message-passing\nneural networks (MPNNs) in order to study the distinguishing power of different\nclasses of such models. We are interested in whether certain architectures are\nable to tell vertices apart based on the feature labels given as input with the\ngraph. We consider two variants of MPNNS: anonymous MPNNs whose message\nfunctions depend only on the labels of vertices involved; and degree-aware\nMPNNs in which message functions can additionally use information regarding the\ndegree of vertices. The former class covers a popular formalisms for computing\nfunctions on graphs: graph neural networks (GNN). The latter covers the\nso-called graph convolutional networks (GCNs), a recently introduced variant of\nGNNs by Kipf and Welling. We obtain lower and upper bounds on the\ndistinguishing power of MPNNs in terms of the distinguishing power of the\nWeisfeiler-Lehman (WL) algorithm. Our results imply that (i) the distinguishing\npower of GCNs is bounded by the WL algorithm, but that they are one step ahead;\n(ii) the WL algorithm cannot be simulated by \"plain vanilla\" GCNs but the\naddition of a trade-off parameter between features of the vertex and those of\nits neighbours (as proposed by Kipf and Welling themselves) resolves this\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:14:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Geerts", "Floris", ""], ["Mazowiecki", "Filip", ""], ["P\u00e9rez", "Guillermo A.", ""]]}, {"id": "2004.02607", "submitter": "Tomas Kulvicius", "authors": "Tomas Kulvicius, Irene Markelic, Minija Tamosiunaite and Florentin\n  W\\\"org\\\"otter", "title": "Semantic Image Search for Robotic Applications", "comments": null, "journal-ref": "22nd International Workshop on Robotics in Alpe-Adria-Danube\n  Region (RAAD 2013), September 11-13, 2013, Portoroz, Slovenia", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization in robotics is one of the most important problems. New\ngeneralization approaches use internet databases in order to solve new tasks.\nModern search engines can return a large amount of information according to a\nquery within milliseconds. However, not all of the returned information is task\nrelevant, partly due to the problem of polysemes. Here we specifically address\nthe problem of object generalization by using image search. We suggest a\nbi-modal solution, combining visual and textual information, based on the\nobservation that humans use additional linguistic cues to demarcate intended\nword meaning. We evaluate the quality of our approach by comparing it to human\nlabelled data and find that, on average, our approach leads to improved results\nin comparison to Google searches, and that it can treat the problem of\npolysemes.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:09:06 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kulvicius", "Tomas", ""], ["Markelic", "Irene", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.02621", "submitter": "Mustafa Abdool", "authors": "Mustafa Abdool, Malay Haldar, Prashant Ramanathan, Tyler Sax, Lanbo\n  Zhang, Aamir Mansawala, Shulin Yang, Thomas Legrand", "title": "Managing Diversity in Airbnb Search", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the long-standing questions in search systems is the role of diversity\nin results. From a product perspective, showing diverse results provides the\nuser with more choice and should lead to an improved experience. However, this\nintuition is at odds with common machine learning approaches to ranking which\ndirectly optimize the relevance of each individual item without a holistic view\nof the result set. In this paper, we describe our journey in tackling the\nproblem of diversity for Airbnb search, starting from heuristic based\napproaches and concluding with a novel deep learning solution that produces an\nembedding of the entire query context by leveraging Recurrent Neural Networks\n(RNNs). We hope our lessons learned will prove useful to others and motivate\nfurther research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:54:45 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Abdool", "Mustafa", ""], ["Haldar", "Malay", ""], ["Ramanathan", "Prashant", ""], ["Sax", "Tyler", ""], ["Zhang", "Lanbo", ""], ["Mansawala", "Aamir", ""], ["Yang", "Shulin", ""], ["Legrand", "Thomas", ""]]}, {"id": "2004.02625", "submitter": "Amir Mosavi Prof", "authors": "Dangquan Zhang, Muhammad Aqeel Ashraf, Zhenling Liu, Wan-Xi Peng,\n  Mohammad Javad Golkar, Amir Mosavi", "title": "Dynamic Modeling and Adaptive Controlling in GPS-Intelligent Buoy (GIB)\n  Systems Based on Neural-Fuzzy Networks", "comments": "32 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.adhoc.2020.102149", "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, various relations and criteria have been presented to establish a\nproper relationship between control systems and control the Global Positioning\nSystem (GPS)-intelligent buoy system. Given the importance of controlling the\nposition of buoys and the construction of intelligent systems, in this paper,\ndynamic system modeling is applied to position marine buoys through the\nimproved neural network with a backstepping technique. This study aims at\ndeveloping a novel controller based on an adaptive fuzzy neural network to\noptimally track the dynamically positioned vehicle on the water with\nunavailable velocities and unidentified control parameters. In order to model\nthe network with the proposed technique, uncertainties and the unwanted\ndisturbances are studied in the neural network. The presented study aims at\ndeveloping a neural controlling which applies the vectorial back-stepping\ntechnique to the surface ships, which have been dynamically positioned with\nundetermined disturbances and ambivalences. Moreover, the objective function is\nto minimize the output error for the neural network (NN) based on the\nclosed-loop system. The most important feature of the proposed model for the\npositioning buoys is its independence from comparative knowledge or information\non the dynamics and the unwanted disturbances of ships. The numerical and\nobtained consequences demonstrate that the control system can adjust the routes\nand the position of the buoys to the desired objective with relatively few\nposition errors.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:28:53 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Dangquan", ""], ["Ashraf", "Muhammad Aqeel", ""], ["Liu", "Zhenling", ""], ["Peng", "Wan-Xi", ""], ["Golkar", "Mohammad Javad", ""], ["Mosavi", "Amir", ""]]}, {"id": "2004.02635", "submitter": "Laurent Condat", "authors": "Adil Salim, Laurent Condat, Konstantin Mishchenko, Peter Richt\\'arik", "title": "Dualize, Split, Randomize: Fast Nonsmooth Optimization Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new primal-dual algorithms to minimize the sum of three convex\nfunctions, each having its own oracle. Namely, the first one is differentiable,\nsmooth and possibly stochastic, the second is proximable, and the last one is a\ncomposition of a proximable function with a linear map. By leveraging variance\nreduction, we prove convergence to an exact solution with sublinear or linear\nrates, depending on strong convexity properties. The proposed theory is simple\nand unified by the umbrella of stochastic Davis-Yin splitting, which we first\ndesign in this work. Our theory covers several settings that are not tackled by\nany existing algorithm; we illustrate their importance with real-world\napplications and we show the efficiency of our algorithms by numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 10:48:01 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:18:31 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Salim", "Adil", ""], ["Condat", "Laurent", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2004.02653", "submitter": "Fabio Sigrist", "authors": "Fabio Sigrist", "title": "Gaussian Process Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel way to combine boosting with Gaussian process and mixed\neffects models. This allows for relaxing, first, the linearity assumption for\nthe mean function in Gaussian process and grouped random effects models in a\nflexible non-parametric way and, second, the independence assumption made in\nmost boosting algorithms. The former is advantageous for predictive accuracy\nand for avoiding model misspecifications. The latter is important for more\nefficient learning of the mean function and for obtaining probabilistic\npredictions. In addition, we present an extension that scales to large data\nusing a Vecchia approximation for the Gaussian process model relying on novel\nresults for covariance parameter inference. We obtain increased predictive\naccuracy compared to existing approaches on several simulated and real-world\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:19:54 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 20:00:36 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 12:06:59 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sigrist", "Fabio", ""]]}, {"id": "2004.02687", "submitter": "Alex Glushkovsky", "authors": "Alex Glushkovsky", "title": "AI Giving Back to Statistics? Discovery of the Coordinate System of\n  Univariate Distributions by Beta Variational Autoencoder", "comments": "12 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributions are fundamental statistical elements that play essential\ntheoretical and practical roles. The article discusses experiences of training\nneural networks to classify univariate empirical distributions and to represent\nthem on the two-dimensional latent space forcing disentanglement based on the\ninputs of cumulative distribution functions (CDF). The latent space\nrepresentation has been performed using an unsupervised beta variational\nautoencoder (beta-VAE). It separates distributions of different shapes while\noverlapping similar ones and empirically realises relationships between\ndistributions that are known theoretically. The synthetic experiment of\ngenerated univariate continuous and discrete (Bernoulli) distributions with\nvarying sample sizes and parameters has been performed to support the study.\nThe representation on the latent two-dimensional coordinate system can be seen\nas an additional metadata of the real-world data that disentangles important\ndistribution characteristics, such as shape of the CDF, classification\nprobabilities of underlying theoretical distributions and their parameters,\ninformation entropy, and skewness. Entropy changes, providing an \"arrow of\ntime\", determine dynamic trajectories along representations of distributions on\nthe latent space. In addition, post beta-VAE unsupervised segmentation of the\nlatent space based on weight-of-evidence (WOE) of posterior versus standard\nisotopic two-dimensional normal densities has been applied detecting the\npresence of assignable causes that distinguish exceptional CDF inputs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:11:13 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Glushkovsky", "Alex", ""]]}, {"id": "2004.02689", "submitter": "Junan Zhu", "authors": "Junan Zhu, Kristina Rivera, Dror Baron", "title": "Noisy Pooled PCR for Virus Testing", "comments": "5 pages, 3 figures; we welcome new collaborators to reach out and\n  help improve this work!", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.IT eess.SP math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast testing can help mitigate the coronavirus disease 2019 (COVID-19)\npandemic. Despite their accuracy for single sample analysis, infectious\ndiseases diagnostic tools, like RT-PCR, require substantial resources to test\nlarge populations. We develop a scalable approach for determining the viral\nstatus of pooled patient samples. Our approach converts group testing to a\nlinear inverse problem, where false positives and negatives are interpreted as\ngenerated by a noisy communication channel, and a message passing algorithm\nestimates the illness status of patients. Numerical results reveal that our\napproach estimates patient illness using fewer pooled measurements than\nexisting noisy group testing algorithms. Our approach can easily be extended to\nvarious applications, including where false negatives must be minimized.\nFinally, in a Utopian world we would have collaborated with RT-PCR experts; it\nis difficult to form such connections during a pandemic. We welcome new\ncollaborators to reach out and help improve this work!\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:12:20 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zhu", "Junan", ""], ["Rivera", "Kristina", ""], ["Baron", "Dror", ""]]}, {"id": "2004.02718", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Kiryung Lee", "title": "Low-Rank Matrix Estimation From Rank-One Projections by Unlifted Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an estimator with a convex formulation for recovery of low-rank\nmatrices from rank-one projections. Using initial estimates of the factors of\nthe target $d_1\\times d_2$ matrix of rank-$r$, the estimator admits a practical\nsubgradient method operating in a space of dimension $r(d_1+d_2)$. This\nproperty makes the estimator significantly more scalable than the convex\nestimators based on lifting and semidefinite programming. Furthermore, we\npresent a streamlined analysis for exact recovery under the real Gaussian\nmeasurement model, as well as the partially derandomized measurement model by\nusing the spherical $t$-design. We show that under both models the estimator\nsucceeds, with high probability, if the number of measurements exceeds $r^2\n(d_1+d_2)$ up to some logarithmic factors. This sample complexity improves on\nthe existing results for nonconvex iterative algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:57:54 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 19:23:16 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bahmani", "Sohail", ""], ["Lee", "Kiryung", ""]]}, {"id": "2004.02755", "submitter": "Dingkang Wang", "authors": "Dingkang Wang, Lucas Magee, Bing-Xing Huo, Samik Banerjee, Xu Li,\n  Jaikishan Jayakumar, Meng Kuan Lin, Keerthi Ram, Suyi Wang, Yusu Wang, Partha\n  P. Mitra", "title": "Detection and skeletonization of single neurons and tracer injections\n  using topological methods", "comments": "20 pages (14 pages main-text and 6 pages supplementary information).\n  5 main-text figures. 5 supplementary figures. 2 supplementary tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neuroscientific data analysis has traditionally relied on linear algebra and\nstochastic process theory. However, the tree-like shapes of neurons cannot be\ndescribed easily as points in a vector space (the subtraction of two neuronal\nshapes is not a meaningful operation), and methods from computational topology\nare better suited to their analysis. Here we introduce methods from Discrete\nMorse (DM) Theory to extract the tree-skeletons of individual neurons from\nvolumetric brain image data, and to summarize collections of neurons labelled\nby tracer injections. Since individual neurons are topologically trees, it is\nsensible to summarize the collection of neurons using a consensus tree-shape\nthat provides a richer information summary than the traditional regional\n'connectivity matrix' approach. The conceptually elegant DM approach lacks\nhand-tuned parameters and captures global properties of the data as opposed to\nprevious approaches which are inherently local. For individual skeletonization\nof sparsely labelled neurons we obtain substantial performance gains over\nstate-of-the-art non-topological methods (over 10% improvements in precision\nand faster proofreading). The consensus-tree summary of tracer injections\nincorporates the regional connectivity matrix information, but in addition\ncaptures the collective collateral branching patterns of the set of neurons\nconnected to the injection site, and provides a bridge between single-neuron\nmorphology and tracer-injection data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 20:58:38 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Dingkang", ""], ["Magee", "Lucas", ""], ["Huo", "Bing-Xing", ""], ["Banerjee", "Samik", ""], ["Li", "Xu", ""], ["Jayakumar", "Jaikishan", ""], ["Lin", "Meng Kuan", ""], ["Ram", "Keerthi", ""], ["Wang", "Suyi", ""], ["Wang", "Yusu", ""], ["Mitra", "Partha P.", ""]]}, {"id": "2004.02757", "submitter": "Yuanhan Mo", "authors": "Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao\n  Teng and Wenjia Bai and Yike Guo", "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep learning requires a large amount of training samples with\nannotations (e.g. label class for classification task, pixel- or voxel-wised\nlabel map for segmentation tasks), which are expensive and time-consuming to\nobtain. During the training of a deep neural network, the annotated samples are\nfed into the network in a mini-batch way, where they are often regarded of\nequal importance. However, some of the samples may become less informative\nduring training, as the magnitude of the gradient start to vanish for these\nsamples. In the meantime, other samples of higher utility or hardness may be\nmore demanded for the training process to proceed and require more\nexploitation. To address the challenges of expensive annotations and loss of\nsample informativeness, here we propose a novel training framework which\nadaptively selects informative samples that are fed to the training process.\nThe adaptive selection or sampling is performed based on a hardness-aware\nstrategy in the latent space constructed by a generative model. To evaluate the\nproposed training framework, we perform experiments on three different\ndatasets, including MNIST and CIFAR-10 for image classification task and a\nmedical image dataset IVUS for biophysical simulation task. On all three\ndatasets, the proposed framework outperforms a random sampling method, which\ndemonstrates the effectiveness of proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 22:17:02 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 18:25:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mo", "Yuanhan", ""], ["Wang", "Shuo", ""], ["Dai", "Chengliang", ""], ["Zhou", "Rui", ""], ["Teng", "Zhongzhao", ""], ["Bai", "Wenjia", ""], ["Guo", "Yike", ""]]}, {"id": "2004.02758", "submitter": "Anthony Griffin", "authors": "Farah Sarwar, Anthony Griffin, Saeed Ur Rehman, and Timotius Pasang", "title": "Towards Detection of Sheep Onboard a UAV", "comments": "This was accepted for publication and presentation at the Embedded AI\n  for Real-time Machine Vision 2019 in conjunction with the British Machine\n  Vision Conference (BMVC) 2019. It was presented on 12 September 2019 in\n  Cardiff, Wales. 10 pages, 3 figures, and 1 table, note that this is a\n  web-friendly format as used at BMVC, so the pages are about A5 size (but not\n  exactly!)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the task of detecting sheep onboard an unmanned\naerial vehicle (UAV) flying at an altitude of 80 m. At this height, the sheep\nare relatively small, only about 15 pixels across. Although deep learning\nstrategies have gained enormous popularity in the last decade and are now\nextensively used for object detection in many fields, state-of-the-art\ndetectors perform poorly in the case of smaller objects. We develop a novel\ndataset of UAV imagery of sheep and consider a variety of object detectors to\ndetermine which is the most suitable for our task in terms of both accuracy and\nspeed. Our findings indicate that a UNet detector using the weighted Hausdorff\ndistance as a loss function during training is an excellent option for\ndetection of sheep onboard a UAV.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:40:48 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sarwar", "Farah", ""], ["Griffin", "Anthony", ""], ["Rehman", "Saeed Ur", ""], ["Pasang", "Timotius", ""]]}, {"id": "2004.02766", "submitter": "Tyler Westenbroek", "authors": "Tyler Westenbroek, Eric Mazumdar, David Fridovich-Keil, Valmik Prabhu,\n  Claire J. Tomlin and S. Shankar Sastry", "title": "Technical Report: Adaptive Control for Linearizable Systems Using\n  On-Policy Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a framework for adaptively learning a feedback\nlinearization-based tracking controller for an unknown system using\ndiscrete-time model-free policy-gradient parameter update rules. The primary\nadvantage of the scheme over standard model-reference adaptive control\ntechniques is that it does not require the learned inverse model to be\ninvertible at all instances of time. This enables the use of general function\napproximators to approximate the linearizing controller for the system without\nhaving to worry about singularities. However, the discrete-time and stochastic\nnature of these algorithms precludes the direct application of standard\nmachinery from the adaptive control literature to provide deterministic\nstability proofs for the system. Nevertheless, we leverage these techniques\nalongside tools from the stochastic approximation literature to demonstrate\nthat with high probability the tracking and parameter errors concentrate near\nzero when a certain persistence of excitation condition is satisfied. A\nsimulated example of a double pendulum demonstrates the utility of the proposed\ntheory. 1\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:50:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Westenbroek", "Tyler", ""], ["Mazumdar", "Eric", ""], ["Fridovich-Keil", "David", ""], ["Prabhu", "Valmik", ""], ["Tomlin", "Claire J.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "2004.02769", "submitter": "Luis Miguel L\\'opez-Ramos", "authors": "Luis Miguel Lopez-Ramos, Baltasar Beferull-Lozano", "title": "Online Hyperparameter Search Interleaved with Proximal Parameter Updates", "comments": "6 pages, 3 figures, 1 algorithm; Submitted to the European Signal\n  Processing Conference (EUSIPCO) 2020 (Amsterdam)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a clear need for efficient algorithms to tune hyperparameters for\nstatistical learning schemes, since the commonly applied search methods (such\nas grid search with N-fold cross-validation) are inefficient and/or\napproximate. Previously existing algorithms that efficiently search for\nhyperparameters relying on the smoothness of the cost function cannot be\napplied in problems such as Lasso regression.\n  In this contribution, we develop a hyperparameter optimization method that\nrelies on the structure of proximal gradient methods and does not require a\nsmooth cost function. Such a method is applied to Leave-one-out (LOO)-validated\nLasso and Group Lasso to yield efficient, data-driven, hyperparameter\noptimization algorithms.\n  Numerical experiments corroborate the convergence of the proposed method to a\nlocal optimum of the LOO validation error curve, and the efficiency of its\napproximations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:54:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lopez-Ramos", "Luis Miguel", ""], ["Beferull-Lozano", "Baltasar", ""]]}, {"id": "2004.02772", "submitter": "Haomiao Meng", "authors": "Haomiao Meng, Ying-Qi Zhao, Haoda Fu, Xingye Qiao", "title": "Near-optimal Individualized Treatment Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individualized treatment recommendation (ITR) is an important analytic\nframework for precision medicine. The goal is to assign proper treatments to\npatients based on their individual characteristics. From the machine learning\nperspective, the solution to an ITR problem can be formulated as a weighted\nclassification problem to maximize the average benefit that patients receive\nfrom the recommended treatments. Several methods have been proposed for ITR in\nboth binary and multicategory treatment setups. In practice, one may prefer a\nmore flexible recommendation with multiple treatment options. This motivates us\nto develop methods to obtain a set of near-optimal individualized treatment\nrecommendations alternative to each other, called alternative individualized\ntreatment recommendations (A-ITR). We propose two methods to estimate the\noptimal A-ITR within the outcome weighted learning (OWL) framework. We show the\nconsistency of these methods and obtain an upper bound for the risk between the\ntheoretically optimal recommendation and the estimated one. We also conduct\nsimulation studies, and apply our methods to a real data set for Type 2\ndiabetic patients with injectable antidiabetic treatments. These numerical\nstudies have shown the usefulness of the proposed A-ITR framework. We develop a\nR package aitr which can be found at https://github.com/menghaomiao/aitr.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:59:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Meng", "Haomiao", ""], ["Zhao", "Ying-Qi", ""], ["Fu", "Haoda", ""], ["Qiao", "Xingye", ""]]}, {"id": "2004.02778", "submitter": "Nathan Kallus", "authors": "Nathan Kallus", "title": "Comment: Entropy Learning for Dynamic Treatment Regimes", "comments": null, "journal-ref": "Statistica Sinica 29.4 (2019): 1697-1705", "doi": "10.5705/ss.202019.0115", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I congratulate Profs. Binyan Jiang, Rui Song, Jialiang Li, and Donglin Zeng\n(JSLZ) for an exciting development in conducting inferences on optimal dynamic\ntreatment regimes (DTRs) learned via empirical risk minimization using the\nentropy loss as a surrogate. JSLZ's approach leverages a\nrejection-and-importance-sampling estimate of the value of a given decision\nrule based on inverse probability weighting (IPW) and its interpretation as a\nweighted (or cost-sensitive) classification. Their use of smooth classification\nsurrogates enables their careful approach to analyzing asymptotic\ndistributions. However, even for evaluation purposes, the IPW estimate is\nproblematic as it leads to weights that discard most of the data and are\nextremely variable on whatever remains. In this comment, I discuss an\noptimization-based alternative to evaluating DTRs, review several connections,\nand suggest directions forward. This extends the balanced policy evaluation\napproach of Kallus (2018a) to the longitudinal setting.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:11:05 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kallus", "Nathan", ""]]}, {"id": "2004.02786", "submitter": "Jeffrey Ede BSc MPhys", "authors": "Jeffrey M. Ede", "title": "Adaptive Partial Scanning Transmission Electron Microscopy with\n  Reinforcement Learning", "comments": "13 pages, 3 figures + 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compressed sensing can decrease scanning transmission electron microscopy\nelectron dose and scan time with minimal information loss. Traditionally,\nsparse scans used in compressed sensing sample a static set of probing\nlocations. However, dynamic scans that adapt to specimens are expected to be\nable to match or surpass the performance of static scans as static scans are a\nsubset of possible dynamic scans. Thus, we present a prototype for a contiguous\nsparse scan system that piecewise adapts scan paths to specimens as they are\nscanned. Sampling directions for scan segments are chosen by a recurrent neural\nnetwork based on previously observed scan segments. The recurrent neural\nnetwork is trained by reinforcement learning to cooperate with a feedforward\nconvolutional neural network that completes the sparse scans. This paper\npresents our learning policy, experiments, and example partial scans, and\ndiscusses future research directions. Source code, pretrained models, and\ntraining data is openly accessible at\nhttps://github.com/Jeffrey-Ede/adaptive-scans\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:25:38 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 13:05:52 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 16:06:00 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 14:26:08 GMT"}, {"version": "v5", "created": "Mon, 1 Mar 2021 11:11:30 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 12:15:56 GMT"}, {"version": "v7", "created": "Mon, 8 Mar 2021 18:09:48 GMT"}, {"version": "v8", "created": "Thu, 11 Mar 2021 16:55:09 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ede", "Jeffrey M.", ""]]}, {"id": "2004.02805", "submitter": "Weiya Fan", "authors": "Rui Nie (2), Huan Yang (1), Hejuan Peng (2), Wenbin Luo (2), Weiya Fan\n  (2), Jie Zhang (2), Jing Liao (2), Fang Huang (2), Yufeng Xiao (1) ((1)\n  Depatment of Gastroenterology, Second Affiliated Hospital, Army Medical\n  University (Third Military Medical University), Chongqing, China. (2)\n  Chongqing Jinshan Science & Technology (Group) Co., Ltd., Chongqing, China.)", "title": "Application of Structural Similarity Analysis of Visually Salient Areas\n  and Hierarchical Clustering in the Screening of Similar Wireless Capsule\n  Endoscopic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small intestinal capsule endoscopy is the mainstream method for inspecting\nsmall intestinal lesions,but a single small intestinal capsule endoscopy will\nproduce 60,000 - 120,000 images, the majority of which are similar and have no\ndiagnostic value. It takes 2 - 3 hours for doctors to identify lesions from\nthese images. This is time-consuming and increase the probability of\nmisdiagnosis and missed diagnosis since doctors are likely to experience visual\nfatigue while focusing on a large number of similar images for an extended\nperiod of time.In order to solve these problems, we proposed a similar wireless\ncapsule endoscope (WCE) image screening method based on structural similarity\nanalysis and the hierarchical clustering of visually salient sub-image blocks.\nThe similarity clustering of images was automatically identified by\nhierarchical clustering based on the hue,saturation,value (HSV) spatial color\ncharacteristics of the images,and the keyframe images were extracted based on\nthe structural similarity of the visually salient sub-image blocks, in order to\naccurately identify and screen out similar small intestinal capsule endoscopic\nimages. Subsequently, the proposed method was applied to the capsule endoscope\nimaging workstation. After screening out similar images in the complete data\ngathered by the Type I OMOM Small Intestinal Capsule Endoscope from 52 cases\ncovering 17 common types of small intestinal lesions, we obtained a lesion\nrecall of 100% and an average similar image reduction ratio of 76%. With\nsimilar images screened out, the average play time of the OMOM image\nworkstation was 18 minutes, which greatly reduced the time spent by doctors\nviewing the images.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:03:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nie", "Rui", ""], ["Yang", "Huan", ""], ["Peng", "Hejuan", ""], ["Luo", "Wenbin", ""], ["Fan", "Weiya", ""], ["Zhang", "Jie", ""], ["Liao", "Jing", ""], ["Huang", "Fang", ""], ["Xiao", "Yufeng", ""]]}, {"id": "2004.02823", "submitter": "Lingjiong Zhu", "authors": "Yuanhan Hu, Xiaoyu Wang, Xuefeng Gao, Mert Gurbuzbalaban, Lingjiong\n  Zhu", "title": "Non-Convex Optimization via Non-Reversible Stochastic Gradient Langevin\n  Dynamics", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Langevin Dynamics (SGLD) is a powerful algorithm for\noptimizing a non-convex objective, where a controlled and properly scaled\nGaussian noise is added to the stochastic gradients to steer the iterates\ntowards a global minimum. SGLD is based on the overdamped Langevin diffusion\nwhich is reversible in time. By adding an anti-symmetric matrix to the drift\nterm of the overdamped Langevin diffusion, one gets a non-reversible diffusion\nthat converges to the same stationary distribution with a faster convergence\nrate. In this paper, we study the non reversible Stochastic Gradient Langevin\nDynamics (NSGLD) which is based on discretization of the non-reversible\nLangevin diffusion. We provide finite-time performance bounds for the global\nconvergence of NSGLD for solving stochastic non-convex optimization problems.\nOur results lead to non-asymptotic guarantees for both population and empirical\nrisk minimization problems. Numerical experiments for Bayesian independent\ncomponent analysis and neural network models show that NSGLD can outperform\nSGLD with proper choices of the anti-symmetric matrix.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:11:03 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 20:49:37 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Hu", "Yuanhan", ""], ["Wang", "Xiaoyu", ""], ["Gao", "Xuefeng", ""], ["Gurbuzbalaban", "Mert", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "2004.02830", "submitter": "Artem Zholus", "authors": "Artem Zholus and Evgeny Putin", "title": "Continuous Histogram Loss: Beyond Neural Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity learning has gained a lot of attention from researches in recent\nyears and tons of successful approaches have been recently proposed. However,\nthe majority of the state-of-the-art similarity learning methods consider only\na binary similarity. In this paper we introduce a new loss function called\nContinuous Histogram Loss (CHL) which generalizes recently proposed Histogram\nloss to multiple-valued similarities, i.e. allowing the acceptable values of\nsimilarity to be continuously distributed within some range. The novel loss\nfunction is computed by aggregating pairwise distances and similarities into 2D\nhistograms in a differentiable manner and then computing the probability of\ncondition that pairwise distances will not decrease as the similarities\nincrease. The novel loss is capable of solving a wider range of tasks including\nsimilarity learning, representation learning and data visualization.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:20:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zholus", "Artem", ""], ["Putin", "Evgeny", ""]]}, {"id": "2004.02842", "submitter": "Maoying Qiao", "authors": "Maoying Qiao, Jun Yu, Wei Bian, Dacheng Tao", "title": "Detecting Communities in Heterogeneous Multi-Relational Networks:A\n  Message Passing based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community is a common characteristic of networks including social networks,\nbiological networks, computer and information networks, to name a few.\nCommunity detection is a basic step for exploring and analysing these network\ndata. Typically, homogenous network is a type of networks which consists of\nonly one type of objects with one type of links connecting them. There has been\na large body of developments in models and algorithms to detect communities\nover it. However, real-world networks naturally exhibit heterogeneous qualities\nappearing as multiple types of objects with multi-relational links connecting\nthem. Those heterogeneous information could facilitate the community detection\nfor its constituent homogeneous networks, but has not been fully explored. In\nthis paper, we exploit heterogeneous multi-relational networks (HMRNet) and\npropose an efficient message passing based algorithm to simultaneously detect\ncommunities for all homogeneous networks. Specifically, an HMRNet is\nreorganized into a hierarchical structure with homogeneous networks as its\nlayers and heterogeneous links connecting them. To detect communities in such\nan HMRNet, the problem is formulated as a maximum a posterior (MAP) over a\nfactor graph. Finally a message passing based algorithm is derived to find a\nbest solution of the MAP problem. Evaluation on both synthetic and real-world\nnetworks confirms the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:36:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Qiao", "Maoying", ""], ["Yu", "Jun", ""], ["Bian", "Wei", ""], ["Tao", "Dacheng", ""]]}, {"id": "2004.02860", "submitter": "Lisa Lee", "authors": "Lisa Lee, Benjamin Eysenbach, Ruslan Salakhutdinov, Shixiang Shane Gu,\n  Chelsea Finn", "title": "Weakly-Supervised Reinforcement Learning for Controllable Behavior", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a powerful framework for learning to take\nactions to solve tasks. However, in many settings, an agent must winnow down\nthe inconceivably large space of all possible tasks to the single task that it\nis currently being asked to solve. Can we instead constrain the space of tasks\nto those that are semantically meaningful? In this work, we introduce a\nframework for using weak supervision to automatically disentangle this\nsemantically meaningful subspace of tasks from the enormous space of\nnonsensical \"chaff\" tasks. We show that this learned subspace enables efficient\nexploration and provides a representation that captures distance between\nstates. On a variety of challenging, vision-based continuous control problems,\nour approach leads to substantial performance gains, particularly as the\ncomplexity of the environment grows.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:50:28 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 02:03:28 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Lee", "Lisa", ""], ["Eysenbach", "Benjamin", ""], ["Salakhutdinov", "Ruslan", ""], ["Gu", "Shixiang Shane", ""], ["Finn", "Chelsea", ""]]}, {"id": "2004.02863", "submitter": "SeongMin Kye", "authors": "Seong Min Kye, Youngmoon Jung, Hae Beom Lee, Sung Ju Hwang, Hoirin Kim", "title": "Meta-Learning for Short Utterance Speaker Recognition with Imbalance\n  Length Pairs", "comments": "Accepted to Interspeech 2020. The codes are available at\n  https://github.com/seongmin-kye/meta-SR", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical settings, a speaker recognition system needs to identify a\nspeaker given a short utterance, while the enrollment utterance may be\nrelatively long. However, existing speaker recognition models perform poorly\nwith such short utterances. To solve this problem, we introduce a meta-learning\nframework for imbalance length pairs. Specifically, we use a Prototypical\nNetworks and train it with a support set of long utterances and a query set of\nshort utterances of varying lengths. Further, since optimizing only for the\nclasses in the given episode may be insufficient for learning discriminative\nembeddings for unseen classes, we additionally enforce the model to classify\nboth the support and the query set against the entire set of classes in the\ntraining set. By combining these two learning schemes, our model outperforms\nexisting state-of-the-art speaker verification models learned with a standard\nsupervised learning framework on short utterance (1-2 seconds) on the VoxCeleb\ndatasets. We also validate our proposed model for unseen speaker\nidentification, on which it also achieves significant performance gains over\nthe existing approaches. The codes are available at\nhttps://github.com/seongmin-kye/meta-SR.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:53:14 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 06:55:10 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 10:56:47 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 04:07:46 GMT"}, {"version": "v5", "created": "Tue, 11 Aug 2020 02:21:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kye", "Seong Min", ""], ["Jung", "Youngmoon", ""], ["Lee", "Hae Beom", ""], ["Hwang", "Sung Ju", ""], ["Kim", "Hoirin", ""]]}, {"id": "2004.02881", "submitter": "Luciano Melodia", "authors": "Luciano Melodia, Richard Lenz", "title": "Estimate of the Neural Network Dimension using Algebraic Topology and\n  Lie Theory", "comments": "The title of this article was formerly \"Parameterization of Neural\n  Networks with Connected Abelian Lie Groups as Data Manifold\"", "journal-ref": "Img.Mine.Theo.Appl.VII 2021 (15-29)", "doi": "10.1007/978-3-030-68821-9_2", "report-no": null, "categories": "stat.ML cs.CG cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an approach to determine the smallest possible\nnumber of neurons in a layer of a neural network in such a way that the\ntopology of the input space can be learned sufficiently well. We introduce a\ngeneral procedure based on persistent homology to investigate topological\ninvariants of the manifold on which we suspect the data set. We specify the\nrequired dimensions precisely, assuming that there is a smooth manifold on or\nnear which the data are located. Furthermore, we require that this space is\nconnected and has a commutative group structure in the mathematical sense.\nThese assumptions allow us to derive a decomposition of the underlying space\nwhose topology is well known. We use the representatives of the $k$-dimensional\nhomology groups from the persistence landscape to determine an integer\ndimension for this decomposition. This number is the dimension of the embedding\nthat is capable of capturing the topology of the data manifold. We derive the\ntheory and validate it experimentally on toy data sets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:15:05 GMT"}, {"version": "v10", "created": "Sun, 13 Dec 2020 14:36:48 GMT"}, {"version": "v11", "created": "Thu, 31 Dec 2020 07:27:13 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 09:32:13 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 13:09:50 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2020 08:58:54 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 06:17:04 GMT"}, {"version": "v6", "created": "Wed, 28 Oct 2020 08:45:41 GMT"}, {"version": "v7", "created": "Tue, 3 Nov 2020 15:02:55 GMT"}, {"version": "v8", "created": "Tue, 10 Nov 2020 14:29:01 GMT"}, {"version": "v9", "created": "Mon, 16 Nov 2020 09:14:42 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Melodia", "Luciano", ""], ["Lenz", "Richard", ""]]}, {"id": "2004.02919", "submitter": "John Burden", "authors": "John Burden and Daniel Kudenko", "title": "Uniform State Abstraction For Reinforcement Learning", "comments": "8 Pages, 2 figures, Accepted for publication in the European\n  Conference of Artificial Intelligence (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential Based Reward Shaping combined with a potential function based on\nappropriately defined abstract knowledge has been shown to significantly\nimprove learning speed in Reinforcement Learning. MultiGrid Reinforcement\nLearning (MRL) has further shown that such abstract knowledge in the form of a\npotential function can be learned almost solely from agent interaction with the\nenvironment. However, we show that MRL faces the problem of not extending well\nto work with Deep Learning. In this paper we extend and improve MRL to take\nadvantage of modern Deep Learning algorithms such as Deep Q-Networks (DQN). We\nshow that DQN augmented with our approach perform significantly better on\ncontinuous control tasks than its Vanilla counterpart and DQN augmented with\nMRL.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:13:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Burden", "John", ""], ["Kudenko", "Daniel", ""]]}, {"id": "2004.02942", "submitter": "Rhys Compton", "authors": "Rhys Compton, Eibe Frank, Panos Patros, Abigail Koay", "title": "Embedding Java Classes with code2vec: Improvements from Variable\n  Obfuscation", "comments": "In 17th International Conference on Mining Software Repositories\n  (MSR) 2020, Seoul, Republic of Korea. 11 pages", "journal-ref": null, "doi": "10.1145/3379597.3387445", "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic source code analysis in key areas of software engineering, such as\ncode security, can benefit from Machine Learning (ML). However, many standard\nML approaches require a numeric representation of data and cannot be applied\ndirectly to source code. Thus, to enable ML, we need to embed source code into\nnumeric feature vectors while maintaining the semantics of the code as much as\npossible. code2vec is a recently released embedding approach that uses the\nproxy task of method name prediction to map Java methods to feature vectors.\nHowever, experimentation with code2vec shows that it learns to rely on variable\nnames for prediction, causing it to be easily fooled by typos or adversarial\nattacks. Moreover, it is only able to embed individual Java methods and cannot\nembed an entire collection of methods such as those present in a typical Java\nclass, making it difficult to perform predictions at the class level (e.g., for\nthe identification of malicious Java classes). Both shortcomings are addressed\nin the research presented in this paper. We investigate the effect of\nobfuscating variable names during the training of a code2vec model to force it\nto rely on the structure of the code rather than specific names and consider a\nsimple approach to creating class-level embeddings by aggregating sets of\nmethod embeddings. Our results, obtained on a challenging new collection of\nsource-code classification problems, indicate that obfuscating variable names\nproduces an embedding model that is both impervious to variable naming and more\naccurately reflects code semantics. The datasets, models, and code are shared\nfor further ML research on source code.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:05:18 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Compton", "Rhys", ""], ["Frank", "Eibe", ""], ["Patros", "Panos", ""], ["Koay", "Abigail", ""]]}, {"id": "2004.02958", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Dominique Mercier, Andreas Dengel, Sheraz Ahmed", "title": "TSInsight: A local-global attribution framework for interpretability in\n  time-series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise in the employment of deep learning methods in safety-critical\nscenarios, interpretability is more essential than ever before. Although many\ndifferent directions regarding interpretability have been explored for visual\nmodalities, time-series data has been neglected with only a handful of methods\ntested due to their poor intelligibility. We approach the problem of\ninterpretability in a novel way by proposing TSInsight where we attach an\nauto-encoder to the classifier with a sparsity-inducing norm on its output and\nfine-tune it based on the gradients from the classifier and a reconstruction\npenalty. TSInsight learns to preserve features that are important for\nprediction by the classifier and suppresses those that are irrelevant i.e.\nserves as a feature attribution method to boost interpretability. In contrast\nto most other attribution frameworks, TSInsight is capable of generating both\ninstance-based and model-based explanations. We evaluated TSInsight along with\n9 other commonly used attribution methods on 8 different time-series datasets\nto validate its efficacy. Evaluation results show that TSInsight naturally\nachieves output space contraction, therefore, is an effective tool for the\ninterpretability of deep time-series models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:34:25 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2004.02965", "submitter": "Yi Ding", "authors": "Yi Ding, Neethu Robinson, Qiuhao Zeng, Duo Chen, Aung Aung Phyo Wai,\n  Tih-Shih Lee, Cuntai Guan", "title": "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "comments": "Authors information updated only. Accepted to be published in: 2020\n  International Joint Conference on Neural Networks (IJCNN), Glasgow, July\n  19--24, 2020, part of 2020 IEEE World Congress on Computational Intelligence\n  (IEEE WCCI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning framework, TSception, for emotion\ndetection from electroencephalogram (EEG). TSception consists of temporal and\nspatial convolutional layers, which learn discriminative representations in the\ntime and channel domains simultaneously. The temporal learner consists of\nmulti-scale 1D convolutional kernels whose lengths are related to the sampling\nrate of the EEG signal, which learns multiple temporal and frequency\nrepresentations. The spatial learner takes advantage of the asymmetry property\nof emotion responses at the frontal brain area to learn the discriminative\nrepresentations from the left and right hemispheres of the brain. In our study,\na system is designed to study the emotional arousal in an immersive virtual\nreality (VR) environment. EEG data were collected from 18 healthy subjects\nusing this system to evaluate the performance of the proposed deep learning\nnetwork for the classification of low and high emotional arousal states. The\nproposed method is compared with SVM, EEGNet, and LSTM. TSception achieves a\nhigh classification accuracy of 86.03%, which outperforms the prior methods\nsignificantly (p<0.05). The code is available at\nhttps://github.com/deepBrains/TSception\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:10:07 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 01:39:59 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ding", "Yi", ""], ["Robinson", "Neethu", ""], ["Zeng", "Qiuhao", ""], ["Chen", "Duo", ""], ["Wai", "Aung Aung Phyo", ""], ["Lee", "Tih-Shih", ""], ["Guan", "Cuntai", ""]]}, {"id": "2004.02967", "submitter": "Hanxiao Liu", "authors": "Hanxiao Liu, Andrew Brock, Karen Simonyan, Quoc V. Le", "title": "Evolving Normalization-Activation Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers and activation functions are fundamental components in\ndeep networks and typically co-locate with each other. Here we propose to\ndesign them using an automated approach. Instead of designing them separately,\nwe unify them into a single tensor-to-tensor computation graph, and evolve its\nstructure starting from basic mathematical functions. Examples of such\nmathematical functions are addition, multiplication and statistical moments.\nThe use of low-level mathematical functions, in contrast to the use of\nhigh-level modules in mainstream NAS, leads to a highly sparse and large search\nspace which can be challenging for search methods. To address the challenge, we\ndevelop efficient rejection protocols to quickly filter out candidate layers\nthat do not work well. We also use multi-objective evolution to optimize each\nlayer's performance across many architectures to prevent overfitting. Our\nmethod leads to the discovery of EvoNorms, a set of new\nnormalization-activation layers with novel, and sometimes surprising structures\nthat go beyond existing design patterns. For example, some EvoNorms do not\nassume that normalization and activation functions must be applied\nsequentially, nor need to center the feature maps, nor require explicit\nactivation functions. Our experiments show that EvoNorms work well on image\nclassification models including ResNets, MobileNets and EfficientNets but also\ntransfer well to Mask R-CNN with FPN/SpineNet for instance segmentation and to\nBigGAN for image synthesis, outperforming BatchNorm and GroupNorm based layers\nin many cases.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:52:48 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 02:58:37 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 16:29:08 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 22:59:31 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 04:42:59 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Liu", "Hanxiao", ""], ["Brock", "Andrew", ""], ["Simonyan", "Karen", ""], ["Le", "Quoc V.", ""]]}, {"id": "2004.02988", "submitter": "Gustavo A Valencia-Zapata", "authors": "Gustavo A. Valencia-Zapata, Carolina Gonzalez-Canas, Michael G.\n  Zentner, Okan Ersoy, and Gerhard Klimeck", "title": "Probabilistic Diagnostic Tests for Degradation Problems in Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Several studies point out different causes of performance degradation in\nsupervised machine learning. Problems such as class imbalance, overlapping,\nsmall-disjuncts, noisy labels, and sparseness limit accuracy in classification\nalgorithms. Even though a number of approaches either in the form of a\nmethodology or an algorithm try to minimize performance degradation, they have\nbeen isolated efforts with limited scope. Most of these approaches focus on\nremediation of one among many problems, with experimental results coming from\nfew datasets and classification algorithms, insufficient measures of prediction\npower, and lack of statistical validation for testing the real benefit of the\nproposed approach. This paper consists of two main parts: In the first part, a\nnovel probabilistic diagnostic model based on identifying signs and symptoms of\neach problem is presented. Thereby, early and correct diagnosis of these\nproblems is to be achieved in order to select not only the most convenient\nremediation treatment but also unbiased performance metrics. Secondly, the\nbehavior and performance of several supervised algorithms are studied when\ntraining sets have such problems. Therefore, prediction of success for\ntreatments can be estimated across classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:32:35 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 19:12:24 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Valencia-Zapata", "Gustavo A.", ""], ["Gonzalez-Canas", "Carolina", ""], ["Zentner", "Michael G.", ""], ["Ersoy", "Okan", ""], ["Klimeck", "Gerhard", ""]]}, {"id": "2004.03019", "submitter": "Ding Zhou", "authors": "Ding Zhou, Yuanjun Gao, Liam Paninski", "title": "Disentangled Sticky Hierarchical Dirichlet Process Hidden Markov Model", "comments": null, "journal-ref": "ECML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) has been\nused widely as a natural Bayesian nonparametric extension of the classical\nHidden Markov Model for learning from sequential and time-series data. A sticky\nextension of the HDP-HMM has been proposed to strengthen the self-persistence\nprobability in the HDP-HMM. However, the sticky HDP-HMM entangles the strength\nof the self-persistence prior and transition prior together, limiting its\nexpressiveness. Here, we propose a more general model: the disentangled sticky\nHDP-HMM (DS-HDP-HMM). We develop novel Gibbs sampling algorithms for efficient\ninference in this model. We show that the disentangled sticky HDP-HMM\noutperforms the sticky HDP-HMM and HDP-HMM on both synthetic and real data, and\napply the new approach to analyze neural data and segment behavioral video\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:10:09 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 00:33:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Ding", ""], ["Gao", "Yuanjun", ""], ["Paninski", "Liam", ""]]}, {"id": "2004.03040", "submitter": "Christopher Thiele", "authors": "Christopher Thiele, Mauricio Araya-Polo, Detlef Hohl", "title": "Deep Neural Network Learning with Second-Order Optimizers -- a Practical\n  Study with a Stochastic Quasi-Gauss-Newton Method", "comments": "8 pages, 3 figures; added reference to code, fixed formatting of\n  title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training in supervised deep learning is computationally demanding, and the\nconvergence behavior is usually not fully understood. We introduce and study a\nsecond-order stochastic quasi-Gauss-Newton (SQGN) optimization method that\ncombines ideas from stochastic quasi-Newton methods, Gauss-Newton methods, and\nvariance reduction to address this problem. SQGN provides excellent accuracy\nwithout the need for experimenting with many hyper-parameter configurations,\nwhich is often computationally prohibitive given the number of combinations and\nthe cost of each training process. We discuss the implementation of SQGN with\nTensorFlow, and we compare its convergence and computational performance to\nselected first-order methods using the MNIST benchmark and a large-scale\nseismic tomography application from Earth science.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 23:41:41 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:28:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Thiele", "Christopher", ""], ["Araya-Polo", "Mauricio", ""], ["Hohl", "Detlef", ""]]}, {"id": "2004.03045", "submitter": "Jeong-Yoon Lee", "authors": "Jing Pan, Vincent Pham, Mohan Dorairaj, Huigang Chen, Jeong-Yoon Lee\n  (Uber Technologies, San Francisco, CA, USA)", "title": "Adversarial Validation Approach to Concept Drift Problem in User\n  Targeting Automation Systems at Uber", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In user targeting automation systems, concept drift in input data is one of\nthe main challenges. It deteriorates model performance on new data over time.\nPrevious research on concept drift mostly proposed model retraining after\nobserving performance decreases. However, this approach is suboptimal because\nthe system fixes the problem only after suffering from poor performance on new\ndata. Here, we introduce an adversarial validation approach to concept drift\nproblems in user targeting automation systems. With our approach, the system\ndetects concept drift in new data before making inference, trains a model, and\nproduces predictions adapted to the new data. We show that our approach\naddresses concept drift effectively with the AutoML3 Lifelong Machine Learning\nchallenge data as well as in Uber's internal user targeting automation system,\nMaLTA.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:01:34 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 06:23:09 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Pan", "Jing", "", "Uber Technologies, San Francisco, CA, USA"], ["Pham", "Vincent", "", "Uber Technologies, San Francisco, CA, USA"], ["Dorairaj", "Mohan", "", "Uber Technologies, San Francisco, CA, USA"], ["Chen", "Huigang", "", "Uber Technologies, San Francisco, CA, USA"], ["Lee", "Jeong-Yoon", "", "Uber Technologies, San Francisco, CA, USA"]]}, {"id": "2004.03083", "submitter": "Yadi Wei", "authors": "Yadi Wei, Rishit Sheth, Roni Khardon", "title": "Direct loss minimization algorithms for sparse Gaussian processes", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides a thorough investigation of Direct loss minimization\n(DLM), which optimizes the posterior to minimize predictive loss, in sparse\nGaussian processes. For the conjugate case, we consider DLM for log-loss and\nDLM for square loss showing a significant performance improvement in both\ncases. The application of DLM in non-conjugate cases is more complex because\nthe logarithm of expectation in the log-loss DLM objective is often intractable\nand simple sampling leads to biased estimates of gradients. The paper makes two\ntechnical contributions to address this. First, a new method using product\nsampling is proposed, which gives unbiased estimates of gradients (uPS) for the\nobjective function. Second, a theoretical analysis of biased Monte Carlo\nestimates (bMC) shows that stochastic gradient descent converges despite the\nbiased gradients. Experiments demonstrate empirical success of DLM. A\ncomparison of the sampling methods shows that, while uPS is potentially more\nsample-efficient, bMC provides a better tradeoff in terms of convergence time\nand computational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 02:31:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:30:10 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 18:36:12 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wei", "Yadi", ""], ["Sheth", "Rishit", ""], ["Khardon", "Roni", ""]]}, {"id": "2004.03104", "submitter": "Qinghai Zheng", "authors": "Qinghai Zheng, Jihua Zhu, Haoyu Tang, Xinyuan Liu, Zhongyu Li, and\n  Huimin Lu", "title": "Generalized Label Enhancement with Sample Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, label distribution learning (LDL) has drawn much attention in\nmachine learning, where LDL model is learned from labelel instances. Different\nfrom single-label and multi-label annotations, label distributions describe the\ninstance by multiple labels with different intensities and accommodate to more\ngeneral scenes. Since most existing machine learning datasets merely provide\nlogical labels, label distributions are unavailable in many real-world\napplications. To handle this problem, we propose two novel label enhancement\nmethods, i.e., Label Enhancement with Sample Correlations (LESC) and\ngeneralized Label Enhancement with Sample Correlations (gLESC). More\nspecifically, LESC employs a low-rank representation of samples in the feature\nspace, and gLESC leverages a tensor multi-rank minimization to further\ninvestigate the sample correlations in both the feature space and label space.\nBenefitting from the sample correlations, the proposed methods can boost the\nperformance of label enhancement. Extensive experiments on 14 benchmark\ndatasets demonstrate the effectiveness and superiority of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:32:36 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:17:26 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 02:47:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zheng", "Qinghai", ""], ["Zhu", "Jihua", ""], ["Tang", "Haoyu", ""], ["Liu", "Xinyuan", ""], ["Li", "Zhongyu", ""], ["Lu", "Huimin", ""]]}, {"id": "2004.03106", "submitter": "Qinghai Zheng", "authors": "Qinghai Zheng, Jihua Zhu, Zhongyu Li, Shanmin Pang, Jun Wang, Lei Chen", "title": "Consistent and Complementary Graph Regularized Multi-view Subspace\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the problem of multi-view clustering, where multiple\nviews contain consistent information and each view also includes complementary\ninformation. Exploration of all information is crucial for good multi-view\nclustering. However, most traditional methods blindly or crudely combine\nmultiple views for clustering and are unable to fully exploit the valuable\ninformation. Therefore, we propose a method that involves consistent and\ncomplementary graph-regularized multi-view subspace clustering (GRMSC), which\nsimultaneously integrates a consistent graph regularizer with a complementary\ngraph regularizer into the objective function. In particular, the consistent\ngraph regularizer learns the intrinsic affinity relationship of data points\nshared by all views. The complementary graph regularizer investigates the\nspecific information of multiple views. It is noteworthy that the consistent\nand complementary regularizers are formulated by two different graphs\nconstructed from the first-order proximity and second-order proximity of\nmultiple views, respectively. The objective function is optimized by the\naugmented Lagrangian multiplier method in order to achieve multi-view\nclustering. Extensive experiments on six benchmark datasets serve to validate\nthe effectiveness of the proposed method over other state-of-the-art multi-view\nclustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:48:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zheng", "Qinghai", ""], ["Zhu", "Jihua", ""], ["Li", "Zhongyu", ""], ["Pang", "Shanmin", ""], ["Wang", "Jun", ""], ["Chen", "Lei", ""]]}, {"id": "2004.03112", "submitter": "Maoying Qiao", "authors": "Maoying Qiao, Tongliang Liu, Jun Yu, Wei Bian, Dacheng Tao", "title": "Repulsive Mixture Models of Exponential Family PCA for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixture extension of exponential family principal component analysis\n(EPCA) was designed to encode much more structural information about data\ndistribution than the traditional EPCA does. For example, due to the linearity\nof EPCA's essential form, nonlinear cluster structures cannot be easily\nhandled, but they are explicitly modeled by the mixing extensions. However, the\ntraditional mixture of local EPCAs has the problem of model redundancy, i.e.,\noverlaps among mixing components, which may cause ambiguity for data\nclustering. To alleviate this problem, in this paper, a\nrepulsiveness-encouraging prior is introduced among mixing components and a\ndiversified EPCA mixture (DEPCAM) model is developed in the Bayesian framework.\nSpecifically, a determinantal point process (DPP) is exploited as a\ndiversity-encouraging prior distribution over the joint local EPCAs. As\nrequired, a matrix-valued measure for L-ensemble kernel is designed, within\nwhich, $\\ell_1$ constraints are imposed to facilitate selecting effective PCs\nof local EPCAs, and angular based similarity measure are proposed. An efficient\nvariational EM algorithm is derived to perform parameter learning and hidden\nvariable inference. Experimental results on both synthetic and real-world\ndatasets confirm the effectiveness of the proposed method in terms of model\nparsimony and generalization ability on unseen test data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 04:07:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Qiao", "Maoying", ""], ["Liu", "Tongliang", ""], ["Yu", "Jun", ""], ["Bian", "Wei", ""], ["Tao", "Dacheng", ""]]}, {"id": "2004.03133", "submitter": "Seungjae Shin", "authors": "Seungjae Shin, Kyungwoo Song, JoonHo Jang, Hyemi Kim, Weonyoung Joo,\n  Il-Chul Moon", "title": "Neutralizing Gender Bias in Word Embedding with Latent Disentanglement\n  and Counterfactual Generation", "comments": "Findings of EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research demonstrates that word embeddings, trained on the\nhuman-generated corpus, have strong gender biases in embedding spaces, and\nthese biases can result in the discriminative results from the various\ndownstream tasks. Whereas the previous methods project word embeddings into a\nlinear subspace for debiasing, we introduce a \\textit{Latent Disentanglement}\nmethod with a siamese auto-encoder structure with an adapted gradient reversal\nlayer. Our structure enables the separation of the semantic latent information\nand gender latent information of given word into the disjoint latent\ndimensions. Afterwards, we introduce a \\textit{Counterfactual Generation} to\nconvert the gender information of words, so the original and the modified\nembeddings can produce a gender-neutralized word embedding after geometric\nalignment regularization, without loss of semantic information. From the\nvarious quantitative and qualitative debiasing experiments, our method shows to\nbe better than existing debiasing methods in debiasing word embeddings. In\naddition, Our method shows the ability to preserve semantic information during\ndebiasing by minimizing the semantic information losses for extrinsic NLP\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 05:16:48 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 05:06:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Shin", "Seungjae", ""], ["Song", "Kyungwoo", ""], ["Jang", "JoonHo", ""], ["Kim", "Hyemi", ""], ["Joo", "Weonyoung", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2004.03139", "submitter": "Yeganeh Marghi", "authors": "Yeganeh M. Marghi, Aziz Kocanaogullari, Murat Akcakaya, Deniz Erdogmus", "title": "Active recursive Bayesian inference using R\\'enyi information measures", "comments": "13 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive Bayesian inference (RBI) provides optimal Bayesian latent variable\nestimates in real-time settings with streaming noisy observations. Active RBI\nattempts to effectively select queries that lead to more informative\nobservations to rapidly reduce uncertainty until a confident decision is made.\nHowever, typically the optimality objectives of inference and query mechanisms\nare not jointly selected. Furthermore, conventional active querying methods\nstagger due to misleading prior information. Motivated by information theoretic\napproaches, we propose an active RBI framework with unified inference and query\nselection steps through Renyi entropy and $\\alpha$-divergence. We also propose\na new objective based on Renyi entropy and its changes called Momentum that\nencourages exploration for misleading prior cases. The proposed active RBI\nframework is applied to the trajectory of the posterior changes in the\nprobability simplex that provides a coordinated active querying and decision\nmaking with specified confidence. Under certain assumptions, we analytically\ndemonstrate that the proposed approach outperforms conventional methods such as\nmutual information by allowing the selections of unlikely events. We present\nempirical and experimental performance evaluations on two applications:\nrestaurant recommendation and brain-computer interface (BCI) typing systems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 05:52:58 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 16:35:34 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Marghi", "Yeganeh M.", ""], ["Kocanaogullari", "Aziz", ""], ["Akcakaya", "Murat", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2004.03168", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas and Katja Hofmann and Pierre-Yves Oudeyer", "title": "Trying AGAIN instead of Trying Longer: Prior Learning for Automatic\n  Curriculum Learning", "comments": "Accepted to the ICLR 2020 workshop Beyond tabula rasa in RL (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in the Deep RL (DRL) community is to train agents able to\ngeneralize over unseen situations, which is often approached by training them\non a diversity of tasks (or environments). A powerful method to foster\ndiversity is to procedurally generate tasks by sampling their parameters from a\nmulti-dimensional distribution, enabling in particular to propose a different\ntask for each training episode. In practice, to get the high diversity of\ntraining tasks necessary for generalization, one has to use complex procedural\ngeneration systems. With such generators, it is hard to get prior knowledge on\nthe subset of tasks that are actually learnable at all (many generated tasks\nmay be unlearnable), what is their relative difficulty and what is the most\nefficient task distribution ordering for training. A typical solution in such\ncases is to rely on some form of Automated Curriculum Learning (ACL) to adapt\nthe sampling distribution. One limit of current approaches is their need to\nexplore the task space to detect progress niches over time, which leads to a\nloss of time. Additionally, we hypothesize that the induced noise in the\ntraining data may impair the performances of brittle DRL learners. We address\nthis problem by proposing a two stage ACL approach where 1) a teacher algorithm\nfirst learns to train a DRL agent with a high-exploration curriculum, and then\n2) distills learned priors from the first run to generate an \"expert\ncurriculum\" to re-train the same agent from scratch. Besides demonstrating 50%\nimprovements on average over the current state of the art, the objective of\nthis work is to give a first example of a new research direction oriented\ntowards refining ACL techniques over multiple learners, which we call Classroom\nTeaching.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:30:27 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2004.03188", "submitter": "Saeed Rahimi Gorji", "authors": "Saeed Rahimi Gorji, Ole-Christoffer Granmo, Sondre Glimsdal, Jonathan\n  Edwards, Morten Goodwin", "title": "Increasing the Inference and Learning Speed of Tsetlin Machines with\n  Clause Indexing", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is a machine learning algorithm founded on the\nclassical Tsetlin Automaton (TA) and game theory. It further leverages frequent\npattern mining and resource allocation principles to extract common patterns in\nthe data, rather than relying on minimizing output error, which is prone to\noverfitting. Unlike the intertwined nature of pattern representation in neural\nnetworks, a TM decomposes problems into self-contained patterns, represented as\nconjunctive clauses. The clause outputs, in turn, are combined into a\nclassification decision through summation and thresholding, akin to a logistic\nregression function, however, with binary weights and a unit step output\nfunction. In this paper, we exploit this hierarchical structure by introducing\na novel algorithm that avoids evaluating the clauses exhaustively. Instead we\nuse a simple look-up table that indexes the clauses on the features that\nfalsify them. In this manner, we can quickly evaluate a large number of clauses\nthrough falsification, simply by iterating through the features and using the\nlook-up table to eliminate those clauses that are falsified. The look-up table\nis further structured so that it facilitates constant time updating, thus\nsupporting use also during learning. We report up to 15 times faster\nclassification and three times faster learning on MNIST and Fashion-MNIST image\nclassification, and IMDb sentiment analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 08:16:07 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Gorji", "Saeed Rahimi", ""], ["Granmo", "Ole-Christoffer", ""], ["Glimsdal", "Sondre", ""], ["Edwards", "Jonathan", ""], ["Goodwin", "Morten", ""]]}, {"id": "2004.03194", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Seong Min Kye, Yeunju Choi, Myunghun Jung, Hoirin Kim", "title": "Improving Multi-Scale Aggregation Using Feature Pyramid Module for\n  Robust Speaker Verification of Variable-Duration Utterances", "comments": "Accepted to Interspeech 2020", "journal-ref": "Proc. Interspeech 2020, pp. 1501-1505", "doi": "10.21437/Interspeech.2020-1025", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the most widely used approach for speaker verification is the deep\nspeaker embedding learning. In this approach, we obtain a speaker embedding\nvector by pooling single-scale features that are extracted from the last layer\nof a speaker feature extractor. Multi-scale aggregation (MSA), which utilizes\nmulti-scale features from different layers of the feature extractor, has\nrecently been introduced and shows superior performance for variable-duration\nutterances. To increase the robustness dealing with utterances of arbitrary\nduration, this paper improves the MSA by using a feature pyramid module. The\nmodule enhances speaker-discriminative information of features from multiple\nlayers via a top-down pathway and lateral connections. We extract speaker\nembeddings using the enhanced features that contain rich speaker information\nwith different time scales. Experiments on the VoxCeleb dataset show that the\nproposed module improves previous MSA methods with a smaller number of\nparameters. It also achieves better performance than state-of-the-art\napproaches for both short and long utterances.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 08:35:05 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 04:28:40 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 09:39:43 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 06:09:29 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Jung", "Youngmoon", ""], ["Kye", "Seong Min", ""], ["Choi", "Yeunju", ""], ["Jung", "Myunghun", ""], ["Kim", "Hoirin", ""]]}, {"id": "2004.03254", "submitter": "Marco Corneli", "authors": "Laurent Vanni, Marco Corneli, Damon Mayaffre, Fr\\'ed\\'eric Precioso", "title": "From text saliency to linguistic objects: learning linguistic\n  interpretable markers with a multi-channels convolutional architecture", "comments": "7 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of effort is currently made to provide methods to analyze and\nunderstand deep neural network impressive performances for tasks such as image\nor text classification. These methods are mainly based on visualizing the\nimportant input features taken into account by the network to build a decision.\nHowever these techniques, let us cite LIME, SHAP, Grad-CAM, or TDS, require\nextra effort to interpret the visualization with respect to expert knowledge.\nIn this paper, we propose a novel approach to inspect the hidden layers of a\nfitted CNN in order to extract interpretable linguistic objects from texts\nexploiting classification process. In particular, we detail a weighted\nextension of the Text Deconvolution Saliency (wTDS) measure which can be used\nto highlight the relevant features used by the CNN to perform the\nclassification task. We empirically demonstrate the efficiency of our approach\non corpora from two different languages: English and French. On all datasets,\nwTDS automatically encodes complex linguistic objects based on co-occurrences\nand possibly on grammatical and syntax analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:46:58 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Vanni", "Laurent", ""], ["Corneli", "Marco", ""], ["Mayaffre", "Damon", ""], ["Precioso", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2004.03260", "submitter": "Danyang Huang", "authors": "Yingqiu Zhu, Yu Chen, Danyang Huang, Bo Zhang and Hansheng Wang", "title": "Automatic, Dynamic, and Nearly Optimal Learning Rate Specification by\n  Local Quadratic Approximation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning tasks, the learning rate determines the update step size in\neach iteration, which plays a critical role in gradient-based optimization.\nHowever, the determination of the appropriate learning rate in practice\ntypically replies on subjective judgement. In this work, we propose a novel\noptimization method based on local quadratic approximation (LQA). In each\nupdate step, given the gradient direction, we locally approximate the loss\nfunction by a standard quadratic function of the learning rate. Then, we\npropose an approximation step to obtain a nearly optimal learning rate in a\ncomputationally efficient way. The proposed LQA method has three important\nfeatures. First, the learning rate is automatically determined in each update\nstep. Second, it is dynamically adjusted according to the current loss function\nvalue and the parameter estimates. Third, with the gradient direction fixed,\nthe proposed method leads to nearly the greatest reduction in terms of the loss\nfunction. Extensive experiments have been conducted to prove the strengths of\nthe proposed LQA method.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:55:12 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zhu", "Yingqiu", ""], ["Chen", "Yu", ""], ["Huang", "Danyang", ""], ["Zhang", "Bo", ""], ["Wang", "Hansheng", ""]]}, {"id": "2004.03264", "submitter": "Geon Heo", "authors": "Geon Heo, Yuji Roh, Seonghyeon Hwang, Dayun Lee, Steven Euijong Whang", "title": "Inspector Gadget: A Data Programming-based Labeling System for\n  Industrial Images", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning for images becomes democratized in the Software 2.0 era,\none of the serious bottlenecks is securing enough labeled data for training.\nThis problem is especially critical in a manufacturing setting where smart\nfactories rely on machine learning for product quality control by analyzing\nindustrial images. Such images are typically large and may only need to be\npartially analyzed where only a small portion is problematic (e.g., identifying\ndefects on a surface). Since manual labeling these images is expensive, weak\nsupervision is an attractive alternative where the idea is to generate weak\nlabels that are not perfect, but can be produced at scale. Data programming is\na recent paradigm in this category where it uses human knowledge in the form of\nlabeling functions and combines them into a generative model. Data programming\nhas been successful in applications based on text or structured data and can\nalso be applied to images usually if one can find a way to convert them into\nstructured data. In this work, we expand the horizon of data programming by\ndirectly applying it to images without this conversion, which is a common\nscenario for industrial applications. We propose Inspector Gadget, an image\nlabeling system that combines crowdsourcing, data augmentation, and data\nprogramming to produce weak labels at scale for image classification. We\nperform experiments on real industrial image datasets and show that Inspector\nGadget obtains better performance than other weak-labeling techniques: Snuba,\nGOGGLES, and self-learning baselines using convolutional neural networks (CNNs)\nwithout pre-training.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:00:29 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 05:45:21 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 04:12:15 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Heo", "Geon", ""], ["Roh", "Yuji", ""], ["Hwang", "Seonghyeon", ""], ["Lee", "Dayun", ""], ["Whang", "Steven Euijong", ""]]}, {"id": "2004.03281", "submitter": "Shaiq Munir Malik", "authors": "Shaiq Munir Malik, Mohbat Tharani, and Murtaza Taj", "title": "Teacher-Class Network: A Neural Network Compression Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the problem of the overwhelming size of Deep Neural Networks (DNN)\nseveral compression schemes have been proposed, one of them is teacher-student.\nTeacher-student tries to transfer knowledge from a complex teacher network to a\nsimple student network. In this paper, we propose a novel method called a\nteacher-class network consisting of a single teacher and multiple student\nnetworks (i.e. class of students). Instead of transferring knowledge to one\nstudent only, the proposed method transfers a chunk of knowledge about the\nentire solution to each student. Our students are not trained for\nproblem-specific logits, they are trained to mimic knowledge (dense\nrepresentation) learned by the teacher network. Thus unlike the logits-based\nsingle student approach, the combined knowledge learned by the class of\nstudents can be used to solve other problems as well. These students can be\ndesigned to satisfy a given budget, e.g. for comparative purposes we kept the\ncollective parameters of all the students less than or equivalent to that of a\nsingle student in the teacher-student approach . These small student networks\nare trained independently, making it possible to train and deploy models on\nmemory deficient devices as well as on parallel processing systems such as data\ncenters. The proposed teacher-class architecture is evaluated on several\nbenchmark datasets including MNIST, FashionMNIST, IMDB Movie Reviews and CAMVid\non multiple tasks including classification, sentiment classification and\nsegmentation. Our approach outperforms the state-of-the-art single student\napproach in terms of accuracy as well as computational cost and in many cases\nit achieves an accuracy equivalent to the teacher network while having 10-30\ntimes fewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:31:20 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 14:50:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Malik", "Shaiq Munir", ""], ["Tharani", "Mohbat", ""], ["Taj", "Murtaza", ""]]}, {"id": "2004.03295", "submitter": "Claudio Lucchese", "authors": "Stefano Calzavara, Claudio Lucchese, Federico Marcuzzi, Salvatore\n  Orlando", "title": "Feature Partitioning for Robust Tree Ensembles and their Certification\n  in Adversarial Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms, however effective, are known to be vulnerable in\nadversarial scenarios where a malicious user may inject manipulated instances.\nIn this work we focus on evasion attacks, where a model is trained in a safe\nenvironment and exposed to attacks at test time. The attacker aims at finding a\nminimal perturbation of a test instance that changes the model outcome.\n  We propose a model-agnostic strategy that builds a robust ensemble by\ntraining its basic models on feature-based partitions of the given dataset. Our\nalgorithm guarantees that the majority of the models in the ensemble cannot be\naffected by the attacker. We experimented the proposed strategy on decision\ntree ensembles, and we also propose an approximate certification method for\ntree ensembles that efficiently assess the minimal accuracy of a forest on a\ngiven dataset avoiding the costly computation of evasion attacks.\n  Experimental evaluation on publicly available datasets shows that proposed\nstrategy outperforms state-of-the-art adversarial learning algorithms against\nevasion attacks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 12:00:40 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Calzavara", "Stefano", ""], ["Lucchese", "Claudio", ""], ["Marcuzzi", "Federico", ""], ["Orlando", "Salvatore", ""]]}, {"id": "2004.03329", "submitter": "Pengtao Xie", "authors": "Xuehai He, Shu Chen, Zeqian Ju, Xiangyu Dong, Hongchao Fang, Sicheng\n  Wang, Yue Yang, Jiaqi Zeng, Ruisi Zhang, Ruoyu Zhang, Meng Zhou, Penghui Zhu,\n  Pengtao Xie", "title": "MedDialog: Two Large-scale Medical Dialogue Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical dialogue systems are promising in assisting in telemedicine to\nincrease access to healthcare services, improve the quality of patient care,\nand reduce medical costs. To facilitate the research and development of medical\ndialogue systems, we build two large-scale medical dialogue datasets:\nMedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing\n0.3 million conversations between patients and doctors and 0.5 million\nutterances. MedDialog-CN is an Chinese dataset containing 1.1 million\nconversations and 4 million utterances. To our best knowledge,\nMedDialog-(EN,CN) are the largest medical dialogue datasets to date. The\ndataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:07:09 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 22:15:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["He", "Xuehai", ""], ["Chen", "Shu", ""], ["Ju", "Zeqian", ""], ["Dong", "Xiangyu", ""], ["Fang", "Hongchao", ""], ["Wang", "Sicheng", ""], ["Yang", "Yue", ""], ["Zeng", "Jiaqi", ""], ["Zhang", "Ruisi", ""], ["Zhang", "Ruoyu", ""], ["Zhou", "Meng", ""], ["Zhu", "Penghui", ""], ["Xie", "Pengtao", ""]]}, {"id": "2004.03332", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski", "title": "Two-Stage Resampling for Convolutional Neural Network Training in the\n  Imbalanced Colorectal Cancer Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data imbalance remains one of the open challenges in the contemporary machine\nlearning. It is especially prevalent in case of medical data, such as\nhistopathological images. Traditional data-level approaches for dealing with\ndata imbalance are ill-suited for image data: oversampling methods such as\nSMOTE and its derivatives lead to creation of unrealistic synthetic\nobservations, whereas undersampling reduces the amount of available data,\ncritical for successful training of convolutional neural networks. To alleviate\nthe problems associated with over- and undersampling we propose a novel\ntwo-stage resampling methodology, in which we initially use the oversampling\ntechniques in the image space to leverage a large amount of data for training\nof a convolutional neural network, and afterwards apply undersampling in the\nfeature space to fine-tune the last layers of the network. Experiments\nconducted on a colorectal cancer image dataset indicate the usefulness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:11:17 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 13:44:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Koziarski", "Micha\u0142", ""]]}, {"id": "2004.03337", "submitter": "Andre G Hochuli", "authors": "Andre G. Hochuli, Alceu S. Britto Jr., Jean P. Barddal, Luiz E. S.\n  Oliveira, Robert Sabourin", "title": "An End-to-End Approach for Recognition of Modern and Historical\n  Handwritten Numeral Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An end-to-end solution for handwritten numeral string recognition is\nproposed, in which the numeral string is considered as composed of objects\nautomatically detected and recognized by a YoLo-based model. The main\ncontribution of this paper is to avoid heuristic-based methods for string\npreprocessing and segmentation, the need for task-oriented classifiers, and\nalso the use of specific constraints related to the string length. A robust\nexperimental protocol based on several numeral string datasets, including one\ncomposed of historical documents, has shown that the proposed method is a\nfeasible end-to-end solution for numeral string recognition. Besides, it\nreduces the complexity of the string recognition task considerably since it\ndrops out classical steps, in special preprocessing, segmentation, and a set of\nclassifiers devoted to strings with a specific length.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 16:51:00 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Hochuli", "Andre G.", ""], ["Britto", "Alceu S.", "Jr."], ["Barddal", "Jean P.", ""], ["Oliveira", "Luiz E. S.", ""], ["Sabourin", "Robert", ""]]}, {"id": "2004.03338", "submitter": "Bo Huang", "authors": "Fenxi Xiao, Jie Zhang, Bo Huang, Xia Wu", "title": "Multiform Fonts-to-Fonts Translation via Style and Content Disentangled\n  Representations of Chinese Character", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper mainly discusses the generation of personalized fonts as the\nproblem of image style transfer. The main purpose of this paper is to design a\nnetwork framework that can extract and recombine the content and style of the\ncharacters. These attempts can be used to synthesize the entire set of fonts\nwith only a small amount of characters. The paper combines various depth\nnetworks such as Convolutional Neural Network, Multi-layer Perceptron and\nResidual Network to find the optimal model to extract the features of the fonts\ncharacter. The result shows that those characters we have generated is very\nclose to real characters, using Structural Similarity index and Peak\nSignal-to-Noise Ratio evaluation criterions.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 04:30:00 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Xiao", "Fenxi", ""], ["Zhang", "Jie", ""], ["Huang", "Bo", ""], ["Wu", "Xia", ""]]}, {"id": "2004.03339", "submitter": "Bo Huang", "authors": "Fenxi Xiao, Bo Huang, Xia Wu", "title": "Automatic Generation of Chinese Handwriting via Fonts Style\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and end-to-end deep Chinese font generation system.\nThis system can generate new style fonts by interpolation of latent\nstyle-related embeding variables that could achieve smooth transition between\ndifferent style. Our method is simpler and more effective than other methods,\nwhich will help to improve the font design efficiency\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 23:34:01 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Xiao", "Fenxi", ""], ["Huang", "Bo", ""], ["Wu", "Xia", ""]]}, {"id": "2004.03375", "submitter": "Dario Sitnik", "authors": "Dario Sitnik and Ivica Kopriva", "title": "Robust Self-Supervised Convolutional Neural Network for Subspace\n  Clustering and Classification", "comments": "15 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insufficient capability of existing subspace clustering methods to handle\ndata coming from nonlinear manifolds, data corruptions, and out-of-sample data\nhinders their applicability to address real-world clustering and classification\nproblems. This paper proposes the robust formulation of the self-supervised\nconvolutional subspace clustering network ($S^2$ConvSCN) that incorporates the\nfully connected (FC) layer and, thus, it is capable for handling out-of-sample\ndata by classifying them using a softmax classifier. $S^2$ConvSCN clusters data\ncoming from nonlinear manifolds by learning the linear self-representation\nmodel in the feature space. Robustness to data corruptions is achieved by using\nthe correntropy induced metric (CIM) of the error. Furthermore, the\nblock-diagonal (BD) structure of the representation matrix is enforced\nexplicitly through BD regularization. In a truly unsupervised training\nenvironment, Robust $S^2$ConvSCN outperforms its baseline version by a\nsignificant amount for both seen and unseen data on four well-known datasets.\nArguably, such an ablation study has not been reported before.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:07:58 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Sitnik", "Dario", ""], ["Kopriva", "Ivica", ""]]}, {"id": "2004.03376", "submitter": "Kaveena Persand", "authors": "Kaveena Persand, Andrew Anderson, David Gregg", "title": "Composition of Saliency Metrics for Channel Pruning with a Myopic Oracle", "comments": null, "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI47803.2020.9308157", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation and memory needed for Convolutional Neural Network (CNN)\ninference can be reduced by pruning weights from the trained network. Pruning\nis guided by a pruning saliency, which heuristically approximates the change in\nthe loss function associated with the removal of specific weights. Many pruning\nsignals have been proposed, but the performance of each heuristic depends on\nthe particular trained network. This leaves the data scientist with a difficult\nchoice. When using any one saliency metric for the entire pruning process, we\nrun the risk of the metric assumptions being invalidated, leading to poor\ndecisions being made by the metric. Ideally we could combine the best aspects\nof different saliency metrics. However, despite an extensive literature review,\nwe are unable to find any prior work on composing different saliency metrics.\nThe chief difficulty lies in combining the numerical output of different\nsaliency metrics, which are not directly comparable.\n  We propose a method to compose several primitive pruning saliencies, to\nexploit the cases where each saliency measure does well. Our experiments show\nthat the composition of saliencies avoids many poor pruning choices identified\nby individual saliencies. In most cases our method finds better selections than\neven the best individual pruning saliency.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 11:29:41 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 12:56:50 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Persand", "Kaveena", ""], ["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}, {"id": "2004.03385", "submitter": "Mat\\'ias  Di Martino", "authors": "J. Matias Di Martino, Fernando Suzacq, Mauricio Delbracio, Qiang Qiu,\n  and Guillermo Sapiro", "title": "Differential 3D Facial Recognition: Adding 3D to Your State-of-the-Art\n  2D Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Active illumination is a prominent complement to enhance 2D face recognition\nand make it more robust, e.g., to spoofing attacks and low-light conditions. In\nthe present work we show that it is possible to adopt active illumination to\nenhance state-of-the-art 2D face recognition approaches with 3D features, while\nbypassing the complicated task of 3D reconstruction. The key idea is to project\nover the test face a high spatial frequency pattern, which allows us to\nsimultaneously recover real 3D information plus a standard 2D facial image.\nTherefore, state-of-the-art 2D face recognition solution can be transparently\napplied, while from the high frequency component of the input image,\ncomplementary 3D facial features are extracted. Experimental results on ND-2006\ndataset show that the proposed ideas can significantly boost face recognition\nperformance and dramatically improve the robustness to spoofing attacks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:17:14 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Di Martino", "J. Matias", ""], ["Suzacq", "Fernando", ""], ["Delbracio", "Mauricio", ""], ["Qiu", "Qiang", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2004.03391", "submitter": "Jarek Duda Dr", "authors": "Jarek Duda", "title": "Exploiting context dependence for image compression with upsampling", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image compression with upsampling encodes information to succeedingly\nincrease image resolution, for example by encoding differences in FUIF and JPEG\nXL. It is useful for progressive decoding, also often can improve compression\nratio - both for lossless compression and e.g. DC coefficients of lossy.\nHowever, the currently used solutions rather do not exploit context dependence\nfor encoding of such upscaling information. This article discusses simple\ninexpensive general techniques for this purpose, which allowed to save on\naverage $0.645$ bits/difference (between $0.138$ and $1.489$) for the last\nupscaling for 48 standard $512\\times 512$ grayscale 8 bit images - compared to\nassumption of fixed Laplace distribution. Using least squares linear regression\nof context to predict center of Laplace distribution gave on average $0.393$\nbits/difference savings. The remaining savings were obtained by additionally\npredicting width of this Laplace distribution, also using just the least\nsquares linear regression.\n  For RGB images, optimization of color transform alone gave mean $\\approx\n4.6\\%$ size reduction comparing to standard YCrCb if using fixed transform,\n$\\approx 6.3\\%$ if optimizing transform individually for each image. Then\nfurther mean $\\approx 10\\%$ reduction was obtained if predicting Laplace\nparameters based on context. The presented simple inexpensive general\nmethodology can be also used for different types of data like DCT coefficients\nin lossy image compression.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:37:04 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 12:51:20 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 07:56:31 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "2004.03398", "submitter": "Berthold Reinwald", "authors": "Shivam Srivastava, Prithviraj Sen, Berthold Reinwald", "title": "Forecasting in multivariate irregularly sampled time series with missing\n  values", "comments": "arXiv admin note: text overlap with arXiv:1905.12374 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse and irregularly sampled multivariate time series are common in\nclinical, climate, financial and many other domains. Most recent approaches\nfocus on classification, regression or forecasting tasks on such data. In\nforecasting, it is necessary to not only forecast the right value but also to\nforecast when that value will occur in the irregular time series. In this work,\nwe present an approach to forecast not only the values but also the time at\nwhich they are expected to occur.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 01:49:46 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Srivastava", "Shivam", ""], ["Sen", "Prithviraj", ""], ["Reinwald", "Berthold", ""]]}, {"id": "2004.03406", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski, Micha{\\l} Wo\\'zniak, Bartosz Krawczyk", "title": "Combined Cleaning and Resampling Algorithm for Multi-Class Imbalanced\n  Data with Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imbalanced data classification is one of the most crucial tasks facing\nmodern data analysis. Especially when combined with other difficulty factors,\nsuch as the presence of noise, overlapping class distributions, and small\ndisjuncts, data imbalance can significantly impact the classification\nperformance. Furthermore, some of the data difficulty factors are known to\naffect the performance of the existing oversampling strategies, in particular\nSMOTE and its derivatives. This effect is especially pronounced in the\nmulti-class setting, in which the mutual imbalance relationships between the\nclasses complicate even further. Despite that, most of the contemporary\nresearch in the area of data imbalance focuses on the binary classification\nproblems, while their more difficult multi-class counterparts are relatively\nunexplored. In this paper, we propose a novel oversampling technique, a\nMulti-Class Combined Cleaning and Resampling (MC-CCR) algorithm. The proposed\nmethod utilizes an energy-based approach to modeling the regions suitable for\noversampling, less affected by small disjuncts and outliers than SMOTE. It\ncombines it with a simultaneous cleaning operation, the aim of which is to\nreduce the effect of overlapping class distributions on the performance of the\nlearning algorithms. Finally, by incorporating a dedicated strategy of handling\nthe multi-class problems, MC-CCR is less affected by the loss of information\nabout the inter-class relationships than the traditional multi-class\ndecomposition strategies. Based on the results of experimental research carried\nout for many multi-class imbalanced benchmark datasets, the high robust of the\nproposed approach to noise was shown, as well as its high quality compared to\nthe state-of-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:59:35 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Koziarski", "Micha\u0142", ""], ["Wo\u017aniak", "Micha\u0142", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2004.03409", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski", "title": "CSMOUTE: Combined Synthetic Oversampling and Undersampling Technique for\n  Imbalanced Data Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel data-level algorithm for handling data\nimbalance in the classification task, Synthetic Majority Undersampling\nTechnique (SMUTE). SMUTE leverages the concept of interpolation of nearby\ninstances, previously introduced in the oversampling setting in SMOTE.\nFurthermore, we combine both in the Combined Synthetic Oversampling and\nUndersampling Technique (CSMOUTE), which integrates SMOTE oversampling with\nSMUTE undersampling. The results of the conducted experimental study\ndemonstrate the usefulness of both the SMUTE and the CSMOUTE algorithms,\nespecially when combined with more complex classifiers, namely MLP and SVM, and\nwhen applied on datasets consisting of a large number of outliers. This leads\nus to a conclusion that the proposed approach shows promise for further\nextensions accommodating local data characteristics, a direction discussed in\nmore detail in the paper.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:03:43 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 13:39:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Koziarski", "Micha\u0142", ""]]}, {"id": "2004.03424", "submitter": "Joon Sik Kim", "authors": "Joon Sik Kim, Jiahao Chen, Ameet Talwalkar", "title": "FACT: A Diagnostic for Group Fairness Trade-offs", "comments": "Accepted to International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group fairness, a class of fairness notions that measure how different groups\nof individuals are treated differently according to their protected attributes,\nhas been shown to conflict with one another, often with a necessary cost in\nloss of model's predictive performance. We propose a general diagnostic that\nenables systematic characterization of these trade-offs in group fairness. We\nobserve that the majority of group fairness notions can be expressed via the\nfairness-confusion tensor, which is the confusion matrix split according to the\nprotected attribute values. We frame several optimization problems that\ndirectly optimize both accuracy and fairness objectives over the elements of\nthis tensor, which yield a general perspective for understanding multiple\ntrade-offs including group fairness incompatibilities. It also suggests an\nalternate post-processing method for designing fair classifiers. On synthetic\nand real datasets, we demonstrate the use cases of our diagnostic, particularly\non understanding the trade-off landscape between accuracy and fairness.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:15:51 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:55:32 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 17:34:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kim", "Joon Sik", ""], ["Chen", "Jiahao", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2004.03445", "submitter": "Adriano Koshiyama", "authors": "Adriano Koshiyama, Sebastian Flennerhag, Stefano B. Blumberg, Nick\n  Firoozye and Philip Treleaven", "title": "QuantNet: Transferring Learning Across Systematic Trading Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP q-fin.PM q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic financial trading strategies account for over 80% of trade volume\nin equities and a large chunk of the foreign exchange market. In spite of the\navailability of data from multiple markets, current approaches in trading rely\nmainly on learning trading strategies per individual market. In this paper, we\ntake a step towards developing fully end-to-end global trading strategies that\nleverage systematic trends to produce superior market-specific trading\nstrategies. We introduce QuantNet: an architecture that learns market-agnostic\ntrends and use these to learn superior market-specific trading strategies. Each\nmarket-specific model is composed of an encoder-decoder pair. The encoder\ntransforms market-specific data into an abstract latent representation that is\nprocessed by a global model shared by all markets, while the decoder learns a\nmarket-specific trading strategy based on both local and global information\nfrom the market-specific encoder and the global model. QuantNet uses recent\nadvances in transfer and meta-learning, where market-specific parameters are\nfree to specialize on the problem at hand, whilst market-agnostic parameters\nare driven to capture signals from all markets. By integrating over\nidiosyncratic market data we can learn general transferable dynamics, avoiding\nthe problem of overfitting to produce strategies with superior returns. We\nevaluate QuantNet on historical data across 3103 assets in 58 global equity\nmarkets. Against the top performing baseline, QuantNet yielded 51% higher\nSharpe and 69% Calmar ratios. In addition we show the benefits of our approach\nover the non-transfer learning variant, with improvements of 15% and 41% in\nSharpe and Calmar ratios. Code available in appendix.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:48:20 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:46:25 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Koshiyama", "Adriano", ""], ["Flennerhag", "Sebastian", ""], ["Blumberg", "Stefano B.", ""], ["Firoozye", "Nick", ""], ["Treleaven", "Philip", ""]]}, {"id": "2004.03452", "submitter": "Jason Stock", "authors": "Jason Stock, Andy Dolan, and Tom Cavey", "title": "Strategies for Robust Image Classification", "comments": "15 pages, and 39 figure (with Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we evaluate the impact of digitally altered images on the\nperformance of artificial neural networks. We explore factors that negatively\naffect the ability of an image classification model to produce consistent and\naccurate results. A model's ability to classify is negatively influenced by\nalterations to images as a result of digital abnormalities or changes in the\nphysical environment. The focus of this paper is to discover and replicate\nscenarios that modify the appearance of an image and evaluate them on\nstate-of-the-art machine learning models. Our contributions present various\ntraining techniques that enhance a model's ability to generalize and improve\nrobustness against these alterations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 21:22:39 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 16:50:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Stock", "Jason", ""], ["Dolan", "Andy", ""], ["Cavey", "Tom", ""]]}, {"id": "2004.03455", "submitter": "Francesco Sovrano", "authors": "Francesco Sovrano, Monica Palmirani, Fabio Vitali", "title": "Deep Learning Based Multi-Label Text Classification of UNGA Resolutions", "comments": "10 pages, 10 figures, accepted paper at ICEGOV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this research is to produce a useful software for United\nNations (UN), that could help to speed up the process of qualifying the UN\ndocuments following the Sustainable Development Goals (SDGs) in order to\nmonitor the progresses at the world level to fight poverty, discrimination,\nclimate changes. In fact human labeling of UN documents would be a daunting\ntask given the size of the impacted corpus. Thus, automatic labeling must be\nadopted at least as a first step of a multi-phase process to reduce the overall\neffort of cataloguing and classifying. Deep Learning (DL) is nowadays one of\nthe most powerful tools for state-of-the-art (SOTA) AI for this task, but very\noften it comes with the cost of an expensive and error-prone preparation of a\ntraining-set. In the case of multi-label text classification of domain-specific\ntext it seems that we cannot effectively adopt DL without a big-enough\ndomain-specific training-set. In this paper, we show that this is not always\ntrue. In fact we propose a novel method that is able, through statistics like\nTF-IDF, to exploit pre-trained SOTA DL models (such as the Universal Sentence\nEncoder) without any need for traditional transfer learning or any other\nexpensive training procedure. We show the effectiveness of our method in a\nlegal context, by classifying UN Resolutions according to their most related\nSDGs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:54:38 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Sovrano", "Francesco", ""], ["Palmirani", "Monica", ""], ["Vitali", "Fabio", ""]]}, {"id": "2004.03456", "submitter": "Jefferson Oliva PhD", "authors": "Jefferson Tales Oliva and Jo\\~ao Lu\\'is Garcia Rosa", "title": "Binary and Multiclass Classifiers based on Multitaper Spectral Features\n  for Epilepsy Detection", "comments": "19 pages, 6 figures, 10 tables. Obs.: in the text, English editing is\n  required. A new version of this text will be available once we have completed\n  their review", "journal-ref": null, "doi": "10.1016/j.bspc.2021.102469", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is one of the most common neurological disorders that can be\ndiagnosed through electroencephalogram (EEG), in which the following epileptic\nevents can be observed: pre-ictal, ictal, post-ictal, and interictal. In this\npaper, we present a novel method for epilepsy detection into two\ndifferentiation contexts: binary and multiclass classification. For feature\nextraction, a total of 105 measures were extracted from power spectrum,\nspectrogram, and bispectrogram. For classifier building, eight different\nmachine learning algorithms were used. Our method was applied in a widely used\nEEG database. As a result, random forest and backpropagation based on\nmultilayer perceptron algorithms reached the highest accuracy for binary\n(98.75%) and multiclass (96.25%) classification problems, respectively.\nSubsequently, the statistical tests did not find a model that would achieve a\nbetter performance than the other classifiers. In the evaluation based on\nconfusion matrices, it was also not possible to identify a classifier that\nstands out in relation to other models for EEG classification. Even so, our\nresults are promising and competitive with the findings in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:12:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Oliva", "Jefferson Tales", ""], ["Rosa", "Jo\u00e3o Lu\u00eds Garcia", ""]]}, {"id": "2004.03459", "submitter": "Ankit Dhall", "authors": "Ankit Dhall, Anastasia Makarova, Octavian Ganea, Dario Pavllo, Michael\n  Greeff, Andreas Krause", "title": "Hierarchical Image Classification using Entailment Cone Embeddings", "comments": "Accepted in the CVPR 2020 Workshop on Differential Geometry in\n  Computer Vision and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has been studied extensively, but there has been limited\nwork in using unconventional, external guidance other than traditional\nimage-label pairs for training. We present a set of methods for leveraging\ninformation about the semantic hierarchy embedded in class labels. We first\ninject label-hierarchy knowledge into an arbitrary CNN-based classifier and\nempirically show that availability of such external semantic information in\nconjunction with the visual semantics from images boosts overall performance.\nTaking a step further in this direction, we model more explicitly the\nlabel-label and label-image interactions using order-preserving embeddings\ngoverned by both Euclidean and hyperbolic geometries, prevalent in natural\nlanguage, and tailor them to hierarchical image classification and\nrepresentation learning. We empirically validate all the models on the\nhierarchical ETHEC dataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:22:02 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 12:56:07 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dhall", "Ankit", ""], ["Makarova", "Anastasia", ""], ["Ganea", "Octavian", ""], ["Pavllo", "Dario", ""], ["Greeff", "Michael", ""], ["Krause", "Andreas", ""]]}, {"id": "2004.03473", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Maruan Al-Shedivat and Eric Xing and\n  Tom Mitchell", "title": "Learning from Imperfect Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems today are trained on large amounts of\nhuman-annotated data. Data annotation tasks that require a high level of\ncompetency make data acquisition expensive, while the resulting labels are\noften subjective, inconsistent, and may contain a variety of human biases. To\nimprove the data quality, practitioners often need to collect multiple\nannotations per example and aggregate them before training models. Such a\nmulti-stage approach results in redundant annotations and may often produce\nimperfect \"ground truth\" that may limit the potential of training accurate\nmachine learning models. We propose a new end-to-end framework that enables us\nto: (i) merge the aggregation step with model training, thus allowing deep\nlearning systems to learn to predict ground truth estimates directly from the\navailable data, and (ii) model difficulties of examples and learn\nrepresentations of the annotators that allow us to estimate and take into\naccount their competencies. Our approach is general and has many applications,\nincluding training more accurate models on crowdsourced data, ensemble\nlearning, as well as classifier accuracy estimation from unlabeled data. We\nconduct an extensive experimental evaluation of our method on 5 crowdsourcing\ndatasets of varied difficulty and show accuracy gains of up to 25% over the\ncurrent state-of-the-art approaches for aggregating annotations, as well as\nsignificant reductions in the required annotation redundancy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:21:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Al-Shedivat", "Maruan", ""], ["Xing", "Eric", ""], ["Mitchell", "Tom", ""]]}, {"id": "2004.03497", "submitter": "Ali Madani", "authors": "Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata\n  Anand, Raphael R. Eguchi, Po-Ssu Huang, Richard Socher", "title": "ProGen: Language Modeling for Protein Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modeling for protein engineering is key to solving fundamental\nproblems in synthetic biology, medicine, and material science. We pose protein\nengineering as an unsupervised sequence generation problem in order to leverage\nthe exponentially growing set of proteins that lack costly, structural\nannotations. We train a 1.2B-parameter language model, ProGen, on ~280M protein\nsequences conditioned on taxonomic and keyword tags such as molecular function\nand cellular component. This provides ProGen with an unprecedented range of\nevolutionary sequence diversity and allows it to generate with fine-grained\ncontrol as demonstrated by metrics based on primary sequence similarity,\nsecondary structure accuracy, and conformational energy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 04:27:16 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Madani", "Ali", ""], ["McCann", "Bryan", ""], ["Naik", "Nikhil", ""], ["Keskar", "Nitish Shirish", ""], ["Anand", "Namrata", ""], ["Eguchi", "Raphael R.", ""], ["Huang", "Po-Ssu", ""], ["Socher", "Richard", ""]]}, {"id": "2004.03499", "submitter": "Benjamin Van NIekerk", "authors": "Benjamin van Niekerk, Andreas Damianou, Benjamin Rosman", "title": "Online Constrained Model-based Reinforcement Learning", "comments": "Conf. Uncertainty in Artificial Intelligence (UAI). 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying reinforcement learning to robotic systems poses a number of\nchallenging problems. A key requirement is the ability to handle continuous\nstate and action spaces while remaining within a limited time and resource\nbudget. Additionally, for safe operation, the system must make robust decisions\nunder hard constraints. To address these challenges, we propose a model based\napproach that combines Gaussian Process regression and Receding Horizon\nControl. Using sparse spectrum Gaussian Processes, we extend previous work by\nupdating the dynamics model incrementally from a stream of sensory data. This\nresults in an agent that can learn and plan in real-time under non-linear\nconstraints. We test our approach on a cart pole swing-up environment and\ndemonstrate the benefits of online learning on an autonomous racing task. The\nenvironment's dynamics are learned from limited training data and can be reused\nin new task instances without retraining.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:51:34 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["van Niekerk", "Benjamin", ""], ["Damianou", "Andreas", ""], ["Rosman", "Benjamin", ""]]}, {"id": "2004.03515", "submitter": "Lev Reyzin", "authors": "Benjamin Fish, Lev Reyzin", "title": "On the Complexity of Learning from Label Proportions", "comments": "this is an extended and corrected version of an IJCAI 2017 paper, 13\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning with label proportions, which we call LLP\nlearning, the training data is unlabeled, and only the proportions of examples\nreceiving each label are given. The goal is to learn a hypothesis that predicts\nthe proportions of labels on the distribution underlying the sample. This model\nof learning is applicable to a wide variety of settings, including predicting\nthe number of votes for candidates in political elections from polls.\n  In this paper, we formally define this class and resolve foundational\nquestions regarding the computational complexity of LLP and characterize its\nrelationship to PAC learning. Among our results, we show, perhaps surprisingly,\nthat for finite VC classes what can be efficiently LLP learned is a strict\nsubset of what can be leaned efficiently in PAC, under standard complexity\nassumptions. We also show that there exist classes of functions whose\nlearnability in LLP is independent of ZFC, the standard set theoretic axioms.\nThis implies that LLP learning cannot be easily characterized (like PAC by VC\ndimension).\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 16:15:22 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Fish", "Benjamin", ""], ["Reyzin", "Lev", ""]]}, {"id": "2004.03553", "submitter": "Lewis Smith", "authors": "Lewis Smith and Lisa Schut and Yarin Gal and Mark van der Wilk", "title": "Capsule Networks -- A Probabilistic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'Capsule' models try to explicitly represent the poses of objects, enforcing\na linear relationship between an object's pose and that of its constituent\nparts. This modelling assumption should lead to robustness to viewpoint changes\nsince the sub-object/super-object relationships are invariant to the poses of\nthe object. We describe a probabilistic generative model which encodes such\ncapsule assumptions, clearly separating the generative parts of the model from\nthe inference mechanisms. With a variational bound we explore the properties of\nthe generative model independently of the approximate inference scheme, and\ngain insights into failures of the capsule assumptions and inference\namortisation. We experimentally demonstrate the applicability of our unified\nobjective, and demonstrate the use of test time optimisation to solve problems\ninherent to amortised inference in our model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:26:11 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:00:04 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 10:04:41 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Smith", "Lewis", ""], ["Schut", "Lisa", ""], ["Gal", "Yarin", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2004.03569", "submitter": "Emma Jingfei Zhang", "authors": "Biao Cai, Jingfei Zhang, Yongtao Guan", "title": "Latent Network Structure Learning from High Dimensional Multivariate\n  Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the latent network structure from large scale multivariate point\nprocess data is an important task in a wide range of scientific and business\napplications. For instance, we might wish to estimate the neuronal functional\nconnectivity network based on spiking times recorded from a collection of\nneurons. To characterize the complex processes underlying the observed data, we\npropose a new and flexible class of nonstationary Hawkes processes that allow\nboth excitatory and inhibitory effects. We estimate the latent network\nstructure using an efficient sparse least squares estimation approach. Using a\nthinning representation, we establish concentration inequalities for the first\nand second order statistics of the proposed Hawkes process. Such theoretical\nresults enable us to establish the non-asymptotic error bound and the selection\nconsistency of the estimated parameters. Furthermore, we describe a least\nsquares loss based statistic for testing if the background intensity is\nconstant in time. We demonstrate the efficacy of our proposed method through\nsimulation studies and an application to a neuron spike train data set.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:48:01 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 20:07:22 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cai", "Biao", ""], ["Zhang", "Jingfei", ""], ["Guan", "Yongtao", ""]]}, {"id": "2004.03586", "submitter": "Jean-Pierre Briot", "authors": "Jean-Pierre Briot", "title": "From Artificial Neural Networks to Deep Learning for Music Generation --\n  History, Concepts and Trends", "comments": "To appear in the Special Issue on Art, Sound and Design in the Neural\n  Computing and Applications Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current wave of deep learning (the hyper-vitamined return of artificial\nneural networks) applies not only to traditional statistical machine learning\ntasks: prediction and classification (e.g., for weather prediction and pattern\nrecognition), but has already conquered other areas, such as translation. A\ngrowing area of application is the generation of creative content, notably the\ncase of music, the topic of this paper. The motivation is in using the capacity\nof modern deep learning techniques to automatically learn musical styles from\narbitrary musical corpora and then to generate musical samples from the\nestimated distribution, with some degree of control over the generation. This\npaper provides a tutorial on music generation based on deep learning\ntechniques. After a short introduction to the topic illustrated by a recent\nexemple, the paper analyzes some early works from the late 1980s using\nartificial neural networks for music generation and how their pioneering\ncontributions have prefigured current techniques. Then, we introduce some\nconceptual framework to analyze the various concepts and dimensions involved.\nVarious examples of recent systems are introduced and analyzed to illustrate\nthe variety of concerns and of techniques.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:33:56 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 22:33:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Briot", "Jean-Pierre", ""]]}, {"id": "2004.03637", "submitter": "Pola Schw\\\"obel", "authors": "Pola Schw\\\"obel, Frederik Warburg, Martin J{\\o}rgensen, Kristoffer H.\n  Madsen, S{\\o}ren Hauberg", "title": "Probabilistic Spatial Transformers for Bayesian Data Augmentation", "comments": "Submitted to the International Conference on Machine Learning (ICML),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-capacity models require vast amounts of data, and data augmentation is a\ncommon remedy when this resource is limited. Standard augmentation techniques\napply small hand-tuned transformations to existing data, which is a brittle\nprocess that realistically only allows for simple transformations. We propose a\nBayesian interpretation of data augmentation where the transformations are\nmodelled as latent variables to be marginalized, and show how these can be\ninferred variationally in an end-to-end fashion. This allows for significantly\nmore complex transformations than manual tuning, and the marginalization\nimplies a form of test-time data augmentation. The resulting model can be\ninterpreted as a probabilistic extension of spatial transformer networks.\nExperimentally, we demonstrate improvements in accuracy and uncertainty\nquantification in image and time series classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:22:02 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Schw\u00f6bel", "Pola", ""], ["Warburg", "Frederik", ""], ["J\u00f8rgensen", "Martin", ""], ["Madsen", "Kristoffer H.", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2004.03639", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Tianyu Ding, Bo Ji, Guanyi Wang, Jing Tian, Yixin Shi,\n  Sheng Yi, Xiao Tu, Zhihui Zhu", "title": "Orthant Based Proximal Stochastic Gradient Method for\n  $\\ell_1$-Regularized Optimization", "comments": "Accepted by ECML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-inducing regularization problems are ubiquitous in machine learning\napplications, ranging from feature selection to model compression. In this\npaper, we present a novel stochastic method -- Orthant Based Proximal\nStochastic Gradient Method (OBProx-SG) -- to solve perhaps the most popular\ninstance, i.e., the l1-regularized problem. The OBProx-SG method contains two\nsteps: (i) a proximal stochastic gradient step to predict a support cover of\nthe solution; and (ii) an orthant step to aggressively enhance the sparsity\nlevel via orthant face projection. Compared to the state-of-the-art methods,\ne.g., Prox-SG, RDA and Prox-SVRG, the OBProx-SG not only converges to the\nglobal optimal solutions (in convex scenario) or the stationary points (in\nnon-convex scenario), but also promotes the sparsity of the solutions\nsubstantially. Particularly, on a large number of convex problems, OBProx-SG\noutperforms the existing methods comprehensively in the aspect of sparsity\nexploration and objective values. Moreover, the experiments on non-convex deep\nneural networks, e.g., MobileNetV1 and ResNet18, further demonstrate its\nsuperiority by achieving the solutions of much higher sparsity without\nsacrificing generalization accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:23:39 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 04:54:42 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Chen", "Tianyi", ""], ["Ding", "Tianyu", ""], ["Ji", "Bo", ""], ["Wang", "Guanyi", ""], ["Tian", "Jing", ""], ["Shi", "Yixin", ""], ["Yi", "Sheng", ""], ["Tu", "Xiao", ""], ["Zhu", "Zhihui", ""]]}, {"id": "2004.03657", "submitter": "Wei Chen", "authors": "Wei Chen, Kartikeya Bhardwaj, Radu Marculescu", "title": "FedMAX: Mitigating Activation Divergence for Accurate and\n  Communication-Efficient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify a new phenomenon called activation-divergence\nwhich occurs in Federated Learning (FL) due to data heterogeneity (i.e., data\nbeing non-IID) across multiple users. Specifically, we argue that the\nactivation vectors in FL can diverge, even if subsets of users share a few\ncommon classes with data residing on different devices. To address the\nactivation-divergence issue, we introduce a prior based on the principle of\nmaximum entropy; this prior assumes minimal information about the per-device\nactivation vectors and aims at making the activation vectors of same classes as\nsimilar as possible across multiple devices. Our results show that, for both\nIID and non-IID settings, our proposed approach results in better accuracy (due\nto the significantly more similar activation vectors across multiple devices),\nand is more communication-efficient than state-of-the-art approaches in FL.\nFinally, we illustrate the effectiveness of our approach on a few common\nbenchmarks and two large medical datasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:22:58 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 19:57:52 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Wei", ""], ["Bhardwaj", "Kartikeya", ""], ["Marculescu", "Radu", ""]]}, {"id": "2004.03658", "submitter": "Haitian Sun", "authors": "Haitian Sun, Andrew O. Arnold, Tania Bedrax-Weiss, Fernando Pereira,\n  William W. Cohen", "title": "Faithful Embeddings for Knowledge Base Queries", "comments": "Published at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deductive closure of an ideal knowledge base (KB) contains exactly the\nlogical queries that the KB can answer. However, in practice KBs are both\nincomplete and over-specified, failing to answer some queries that have\nreal-world answers. \\emph{Query embedding} (QE) techniques have been recently\nproposed where KB entities and KB queries are represented jointly in an\nembedding space, supporting relaxation and generalization in KB inference.\nHowever, experiments in this paper show that QE systems may disagree with\ndeductive reasoning on answers that do not require generalization or\nrelaxation. We address this problem with a novel QE method that is more\nfaithful to deductive reasoning, and show that this leads to better performance\non complex queries to incomplete KBs. Finally we show that inserting this new\nQE module into a neural question-answering system leads to substantial\nimprovements over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:25:16 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 21:19:36 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 03:46:25 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Sun", "Haitian", ""], ["Arnold", "Andrew O.", ""], ["Bedrax-Weiss", "Tania", ""], ["Pereira", "Fernando", ""], ["Cohen", "William W.", ""]]}, {"id": "2004.03670", "submitter": "Antonio Libri", "authors": "Antonio Libri, Andrea Bartolini, Luca Benini", "title": "pAElla: Edge-AI based Real-Time Malware Detection in Data Centers", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.2986702", "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of Internet-of-Things (IoT) devices for monitoring a wide\nspectrum of applications, along with the challenges of \"big data\" streaming\nsupport they often require for data analysis, is nowadays pushing for an\nincreased attention to the emerging edge computing paradigm. In particular,\nsmart approaches to manage and analyze data directly on the network edge, are\nmore and more investigated, and Artificial Intelligence (AI) powered edge\ncomputing is envisaged to be a promising direction. In this paper, we focus on\nData Centers (DCs) and Supercomputers (SCs), where a new generation of\nhigh-resolution monitoring systems is being deployed, opening new opportunities\nfor analysis like anomaly detection and security, but introducing new\nchallenges for handling the vast amount of data it produces. In detail, we\nreport on a novel lightweight and scalable approach to increase the security of\nDCs/SCs, that involves AI-powered edge computing on high-resolution power\nconsumption. The method -- called pAElla -- targets real-time Malware Detection\n(MD), it runs on an out-of-band IoT-based monitoring system for DCs/SCs, and\ninvolves Power Spectral Density of power measurements, along with AutoEncoders.\nResults are promising, with an F1-score close to 1, and a False Alarm and\nMalware Miss rate close to 0%. We compare our method with State-of-the-Art MD\ntechniques and show that, in the context of DCs/SCs, pAElla can cover a wider\nrange of malware, significantly outperforming SoA approaches in terms of\naccuracy. Moreover, we propose a methodology for online training suitable for\nDCs/SCs in production, and release open dataset and code.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:48:57 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Libri", "Antonio", ""], ["Bartolini", "Andrea", ""], ["Benini", "Luca", ""]]}, {"id": "2004.03683", "submitter": "Brian Williamson", "authors": "Brian D. Williamson, Peter B. Gilbert, Noah R. Simon, Marco Carone", "title": "A unified approach for inference on algorithm-agnostic variable\n  importance", "comments": "55 total pages (31 in the main document, 24 supplementary), 14\n  figures (4 in the main document, 10 supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, it is of interest to assess the relative contribution\nof features (or subsets of features) toward the goal of predicting a response\n-- in other words, to gauge the variable importance of features. Most recent\nwork on variable importance assessment has focused on describing the importance\nof features within the confines of a given prediction algorithm. However, such\nassessment does not necessarily characterize the prediction potential of\nfeatures, and may provide a misleading reflection of the intrinsic value of\nthese features. To address this limitation, we propose a general framework for\nnonparametric inference on interpretable algorithm-agnostic variable\nimportance. We define variable importance as a population-level contrast\nbetween the oracle predictiveness of all available features versus all features\nexcept those under consideration. We propose a nonparametric efficient\nestimation procedure that allows the construction of valid confidence\nintervals, even when machine learning techniques are used. We also outline a\nvalid strategy for testing the null importance hypothesis. Through simulations,\nwe show that our proposal has good operating characteristics, and we illustrate\nits use with data from a study of an antibody against HIV-1 infection.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 20:09:21 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Williamson", "Brian D.", ""], ["Gilbert", "Peter B.", ""], ["Simon", "Noah R.", ""], ["Carone", "Marco", ""]]}, {"id": "2004.03705", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam\n  Chenaghlu, Jianfeng Gao", "title": "Deep Learning Based Text Classification: A Comprehensive Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based models have surpassed classical machine learning based\napproaches in various text classification tasks, including sentiment analysis,\nnews categorization, question answering, and natural language inference. In\nthis paper, we provide a comprehensive review of more than 150 deep learning\nbased models for text classification developed in recent years, and discuss\ntheir technical contributions, similarities, and strengths. We also provide a\nsummary of more than 40 popular datasets widely used for text classification.\nFinally, we provide a quantitative analysis of the performance of different\ndeep learning models on popular benchmarks, and discuss future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 02:00:30 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 20:53:58 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 07:41:46 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Minaee", "Shervin", ""], ["Kalchbrenner", "Nal", ""], ["Cambria", "Erik", ""], ["Nikzad", "Narjes", ""], ["Chenaghlu", "Meysam", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.03712", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Houman Ghaemmaghami, Simon Denman, Sridha\n  Sridharan, Nayyar Hussain, Clinton Fookes", "title": "Heart Sound Segmentation using Bidirectional LSTMs with Attention", "comments": "IEEE Journal of Biomedical and Health Informatics, 25 October 2019", "journal-ref": null, "doi": "10.1109/JBHI.2019.2949516", "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework for the segmentation of phonocardiogram\n(PCG) signals into heart states, exploiting the temporal evolution of the PCG\nas well as considering the salient information that it provides for the\ndetection of the heart state. We propose the use of recurrent neural networks\nand exploit recent advancements in attention based learning to segment the PCG\nsignal. This allows the network to identify the most salient aspects of the\nsignal and disregard uninformative information. The proposed method attains\nstate-of-the-art performance on multiple benchmarks including both human and\nanimal heart recordings. Furthermore, we empirically analyse different feature\ncombinations including envelop features, wavelet and Mel Frequency Cepstral\nCoefficients (MFCC), and provide quantitative measurements that explore the\nimportance of different features in the proposed approach. We demonstrate that\na recurrent neural network coupled with attention mechanisms can effectively\nlearn from irregular and noisy PCG recordings. Our analysis of different\nfeature combinations shows that MFCC features and their derivatives offer the\nbest performance compared to classical wavelet and envelop features. Heart\nsound segmentation is a crucial pre-processing step for many diagnostic\napplications. The proposed method provides a cost effective alternative to\nlabour extensive manual segmentation, and provides a more accurate segmentation\nthan existing methods. As such, it can improve the performance of further\nanalysis including the detection of murmurs and ejection clicks. The proposed\nmethod is also applicable for detection and segmentation of other one\ndimensional biomedical signals.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:09:11 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Fernando", "Tharindu", ""], ["Ghaemmaghami", "Houman", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Hussain", "Nayyar", ""], ["Fookes", "Clinton", ""]]}, {"id": "2004.03722", "submitter": "Lucas May Petry", "authors": "Lucas May Petry, Amilcar Soares, Vania Bogorny, Bruno Brandoli, Stan\n  Matwin", "title": "Challenges in Vessel Behavior and Anomaly Detection: From Classical\n  Machine Learning to Deep Learning", "comments": "This is an extended version of the article Challenges in Vessel\n  Behavior and Anomaly Detection: From Classical Machine Learning to Deep\n  Learning, to be published by Springer in the proceedings of the 33rd Canadian\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global expansion of maritime activities and the development of the\nAutomatic Identification System (AIS) have driven the advances in maritime\nmonitoring systems in the last decade. Monitoring vessel behavior is\nfundamental to safeguard maritime operations, protecting other vessels sailing\nthe ocean and the marine fauna and flora. Given the enormous volume of vessel\ndata continually being generated, real-time analysis of vessel behaviors is\nonly possible because of decision support systems provided with event and\nanomaly detection methods. However, current works on vessel event detection are\nad-hoc methods able to handle only a single or a few predefined types of vessel\nbehavior. Most of the existing approaches do not learn from the data and\nrequire the definition of queries and rules for describing each behavior. In\nthis paper, we discuss challenges and opportunities in classical machine\nlearning and deep learning for vessel event and anomaly detection. We hope to\nmotivate the research of novel methods and tools, since addressing these\nchallenges is an essential step towards actual intelligent maritime monitoring\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 21:25:12 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Petry", "Lucas May", ""], ["Soares", "Amilcar", ""], ["Bogorny", "Vania", ""], ["Brandoli", "Bruno", ""], ["Matwin", "Stan", ""]]}, {"id": "2004.03734", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Francis Ferraro, Tim Oates", "title": "Locality Preserving Loss: Neighbors that Live together, Align together", "comments": null, "journal-ref": "Adapt-NLP 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a locality preserving loss (LPL) that improves the alignment\nbetween vector space embeddings while separating uncorrelated representations.\nGiven two pretrained embedding manifolds, LPL optimizes a model to project an\nembedding and maintain its local neighborhood while aligning one manifold to\nanother. This reduces the overall size of the dataset required to align the two\nin tasks such as cross-lingual word alignment. We show that the LPL-based\nalignment between input vector spaces acts as a regularizer, leading to better\nand consistent accuracy than the baseline, especially when the size of the\ntraining set is small. We demonstrate the effectiveness of LPL optimized\nalignment on semantic text similarity (STS), natural language inference (SNLI),\nmulti-genre language inference (MNLI) and cross-lingual word alignment(CLA)\nshowing consistent improvements, finding up to 16% improvement over our\nbaseline in lower resource settings.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 22:26:09 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 04:56:20 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Ferraro", "Francis", ""], ["Oates", "Tim", ""]]}, {"id": "2004.03797", "submitter": "Jaleh Zand", "authors": "Jaleh Zand and Stephen Roberts", "title": "Mixture Density Conditional Generative Adversarial Network Models\n  (MD-CGAN)", "comments": "Revision includes further expansion of analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have gained significant attention in\nrecent years, with impressive applications highlighted in computer vision in\nparticular. Compared to such examples, however, there have been more limited\napplications of GANs to time series modelling, including forecasting. In this\nwork, we present the Mixture Density Conditional Generative Adversarial Model\n(MD-CGAN), with a focus on time series forecasting. We show that our model is\ncapable of estimating a probabilistic posterior distribution over forecasts and\nthat, in comparison to a set of benchmark methods, the MD-CGAN model performs\nwell, particularly in situations where noise is a significant component of the\nobserved time series. Further, by using a Gaussian mixture model as the output\ndistribution, MD-CGAN offers posterior predictions that are non-Gaussian.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 03:55:30 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 16:09:17 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 03:52:08 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Zand", "Jaleh", ""], ["Roberts", "Stephen", ""]]}, {"id": "2004.03816", "submitter": "Liren Yu", "authors": "Liren Yu, Jiaming Xu, and Xiaojun Lin", "title": "Graph Matching with Partially-Correct Seeds", "comments": "43 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching aims to find the latent vertex correspondence between two\nedge-correlated graphs and has found numerous applications across different\nfields. In this paper, we study a seeded graph matching problem, which assumes\nthat a set of seeds, i.e., pre-mapped vertex-pairs, is given in advance. While\nmost previous work requires all seeds to be correct, we focus on the setting\nwhere the seeds are partially correct. Specifically, consider two correlated\ngraphs whose edges are sampled independently from a parent \\ER graph\n$\\mathcal{G}(n,p)$. A mapping between the vertices of the two graphs is\nprovided as seeds, of which an unknown $\\beta$ fraction is correct. We first\nanalyze a simple algorithm that matches vertices based on the number of common\nseeds in the $1$-hop neighborhoods, and then further propose a new algorithm\nthat uses seeds in the $2$-hop neighborhoods. We establish non-asymptotic\nperformance guarantees of perfect matching for both $1$-hop and $2$-hop\nalgorithms, showing that our new $2$-hop algorithm requires substantially fewer\ncorrect seeds than the $1$-hop algorithm when graphs are sparse. Moreover, by\ncombining our new performance guarantees for the $1$-hop and $2$-hop\nalgorithms, we attain the best-known results (in terms of the required fraction\nof correct seeds) across the entire range of graph sparsity and significantly\nimprove the previous results in\n\\cite{10.14778/2794367.2794371,lubars2018correcting} when $p\\ge n^{-5/6}$. For\ninstance, when $p$ is a constant or $p=n^{-3/4}$, we show that only\n$\\Omega(\\sqrt{n\\log n})$ correct seeds suffice for perfect matching, while the\npreviously best-known results demand $\\Omega(n)$ and $\\Omega(n^{3/4}\\log n)$\ncorrect seeds, respectively. Numerical experiments corroborate our theoretical\nfindings, demonstrating the superiority of our $2$-hop algorithm on a variety\nof synthetic and real graphs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 05:25:52 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 17:32:14 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Yu", "Liren", ""], ["Xu", "Jiaming", ""], ["Lin", "Xiaojun", ""]]}, {"id": "2004.03845", "submitter": "Camille Champion", "authors": "Camille Champion (IMT), Blaz\\`ere M\\'elanie (IMT), Burcelin R\\'emy\n  (I2MC), Loubes Jean-Michel (IMT), Risser Laurent (IMT)", "title": "Robust spectral clustering using LASSO regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster structure detection is a fundamental task for the analysis of graphs,\nin order to understand and to visualize their functional characteristics. Among\nthe different cluster structure detection methods, spectral clustering is\ncurrently one of the most widely used due to its speed and simplicity. Yet,\nthere are few theoretical guarantee to recover the underlying partitions of the\ngraph for general models. This paper therefore presents a variant of spectral\nclustering, called 1-spectral clustering, performed on a new random model\nclosely related to stochastic block model. Its goal is to promote a sparse\neigenbasis solution of a 1 minimization problem revealing the natural structure\nof the graph. The effectiveness and the robustness to small noise perturbations\nof our technique is confirmed through a collection of simulated and real data\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:12:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Champion", "Camille", "", "IMT"], ["M\u00e9lanie", "Blaz\u00e8re", "", "IMT"], ["R\u00e9my", "Burcelin", "", "I2MC"], ["Jean-Michel", "Loubes", "", "IMT"], ["Laurent", "Risser", "", "IMT"]]}, {"id": "2004.03891", "submitter": "Apratim Bhattacharyya", "authors": "Shweta Mahajan, Apratim Bhattacharyya, Mario Fritz, Bernt Schiele,\n  Stefan Roth", "title": "Normalizing Flows with Multi-Scale Autoregressive Priors", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models are an important class of exact inference models\nthat admit efficient inference and sampling for image synthesis. Owing to the\nefficiency constraints on the design of the flow layers, e.g. split coupling\nflow layers in which approximately half the pixels do not undergo further\ntransformations, they have limited expressiveness for modeling long-range data\ndependencies compared to autoregressive models that rely on conditional\npixel-wise generation. In this work, we improve the representational power of\nflow-based models by introducing channel-wise dependencies in their latent\nspace through multi-scale autoregressive priors (mAR). Our mAR prior for models\nwith split coupling flow layers (mAR-SCF) can better capture dependencies in\ncomplex multimodal data. The resulting model achieves state-of-the-art density\nestimation results on MNIST, CIFAR-10, and ImageNet. Furthermore, we show that\nmAR-SCF allows for improved image generation quality, with gains in FID and\nInception scores compared to state-of-the-art flow-based models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 09:07:11 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Mahajan", "Shweta", ""], ["Bhattacharyya", "Apratim", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""], ["Roth", "Stefan", ""]]}, {"id": "2004.03898", "submitter": "Michael Gygli", "authors": "Michael Gygli, Jasper Uijlings, Vittorio Ferrari", "title": "Towards Reusable Network Components by Learning Compatible\n  Representations", "comments": "Preprint; To be presented at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to make a first step towards compatible and hence\nreusable network components. Rather than training networks for different tasks\nindependently, we adapt the training process to produce network components that\nare compatible across tasks. In particular, we split a network into two\ncomponents, a features extractor and a target task head, and propose various\napproaches to accomplish compatibility between them. We systematically analyse\nthese approaches on the task of image classification on standard datasets. We\ndemonstrate that we can produce components which are directly compatible\nwithout any fine-tuning or compromising accuracy on the original tasks.\nAfterwards, we demonstrate the use of compatible components on three\napplications: Unsupervised domain adaptation, transferring classifiers across\nfeature extractors with different architectures, and increasing the\ncomputational efficiency of transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 09:21:37 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:40:59 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 13:31:27 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Gygli", "Michael", ""], ["Uijlings", "Jasper", ""], ["Ferrari", "Vittorio", ""]]}, {"id": "2004.03922", "submitter": "Suchismita Das", "authors": "Suchismita Das and Nikhil R. Pal", "title": "Nonlinear Dimensionality Reduction for Data Visualization: An\n  Unsupervised Fuzzy Rule-based Approach", "comments": null, "journal-ref": "IEEE Transactions on Fuzzy Systems ( Early Access ) 2021", "doi": "10.1109/TFUZZ.2021.3076583", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we propose an unsupervised fuzzy rule-based dimensionality reduction\nmethod primarily for data visualization. It considers the following important\nissues relevant to dimensionality reduction-based data visualization: (i)\npreservation of neighborhood relationships, (ii) handling data on a non-linear\nmanifold, (iii) the capability of predicting projections for new test data\npoints, (iv) interpretability of the system, and (v) the ability to reject test\npoints if required. For this, we use a first-order Takagi-Sugeno type model. We\ngenerate rule antecedents using clusters in the input data. In this context, we\nalso propose a new variant of the Geodesic c-means clustering algorithm. We\nestimate the rule parameters by minimizing an error function that preserves the\ninter-point geodesic distances (distances over the manifold) as Euclidean\ndistances on the projected space. We apply the proposed method on three\nsynthetic and three real-world data sets and visually compare the results with\nfour other standard data visualization methods. The obtained results show that\nthe proposed method behaves desirably and performs better than or comparable to\nthe methods compared with. The proposed method is found to be robust to the\ninitial conditions. The predictability of the proposed method for test points\nis validated by experiments. We also assess the ability of our method to reject\noutput points when it should. Then, we extend this concept to provide a general\nframework for learning an unsupervised fuzzy model for data projection with\ndifferent objective functions. To the best of our knowledge, this is the first\nattempt to manifold learning using unsupervised fuzzy modeling.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 10:33:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Das", "Suchismita", ""], ["Pal", "Nikhil R.", ""]]}, {"id": "2004.03951", "submitter": "Zhongchen Ma", "authors": "Zhongchen Ma and Songcan Chen", "title": "Global Expanding, Local Shrinking: Discriminant Multi-label Learning\n  with Missing Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-label learning, the issue of missing labels brings a major\nchallenge. Many methods attempt to recovery missing labels by exploiting\nlow-rank structure of label matrix. However, these methods just utilize global\nlow-rank label structure, ignore both local low-rank label structures and label\ndiscriminant information to some extent, leaving room for further performance\nimprovement. In this paper, we develop a simple yet effective discriminant\nmulti-label learning (DM2L) method for multi-label learning with missing\nlabels. Specifically, we impose the low-rank structures on all the predictions\nof instances from the same labels (local shrinking of rank), and a maximally\nseparated structure (high-rank structure) on the predictions of instances from\ndifferent labels (global expanding of rank). In this way, these imposed\nlow-rank structures can help modeling both local and global low-rank label\nstructures, while the imposed high-rank structure can help providing more\nunderlying discriminability. Our subsequent theoretical analysis also supports\nthese intuitions. In addition, we provide a nonlinear extension via using\nkernel trick to enhance DM2L and establish a concave-convex objective to learn\nthese models. Compared to the other methods, our method involves the fewest\nassumptions and only one hyper-parameter. Even so, extensive experiments show\nthat our method still outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 11:49:58 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ma", "Zhongchen", ""], ["Chen", "Songcan", ""]]}, {"id": "2004.03990", "submitter": "Erik Thiede", "authors": "Erik Henning Thiede, Truong Son Hy, and Risi Kondor", "title": "The general theory of permutation equivarant neural networks and higher\n  order graph variational encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on symmetric group equivariant neural networks generally only\nconsidered the case where the group acts by permuting the elements of a single\nvector. In this paper we derive formulae for general permutation equivariant\nlayers, including the case where the layer acts on matrices by permuting their\nrows and columns simultaneously. This case arises naturally in graph learning\nand relation learning applications. As a specific case of higher order\npermutation equivariant networks, we present a second order graph variational\nencoder, and show that the latent distribution of equivariant generative models\nmust be exchangeable. We demonstrate the efficacy of this architecture on the\ntasks of link prediction in citation graphs and molecular graph generation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:29:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Thiede", "Erik Henning", ""], ["Hy", "Truong Son", ""], ["Kondor", "Risi", ""]]}, {"id": "2004.03991", "submitter": "Karl Stratos", "authors": "Karl Stratos, Sam Wiseman", "title": "Learning Discrete Structured Representations by Adversarially Maximizing\n  Mutual Information", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose learning discrete structured representations from unlabeled data\nby maximizing the mutual information between a structured latent variable and a\ntarget variable. Calculating mutual information is intractable in this setting.\nOur key technical contribution is an adversarial objective that can be used to\ntractably estimate mutual information assuming only the feasibility of cross\nentropy calculation. We develop a concrete realization of this general\nformulation with Markov distributions over binary encodings. We report critical\nand unexpected findings on practical aspects of the objective such as the\nchoice of variational priors. We apply our model on document hashing and show\nthat it outperforms current best baselines based on discrete and vector\nquantized variational autoencoders. It also yields highly compressed\ninterpretable representations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:31:53 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 18:03:23 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Stratos", "Karl", ""], ["Wiseman", "Sam", ""]]}, {"id": "2004.03994", "submitter": "Rahul Ragesh", "authors": "Rahul Ragesh, Sundararajan Sellamanickam, Vijay Lingam and Arun Iyer", "title": "A Graph Convolutional Network Composition Framework for Semi-supervised\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have gained popularity due to high\nperformance achievable on several downstream tasks including node\nclassification. Several architectural variants of these networks have been\nproposed and investigated with experimental studies in the literature.\nMotivated by a recent work on simplifying GCNs, we study the problem of\ndesigning other variants and propose a framework to compose networks using\nbuilding blocks of GCN. The framework offers flexibility to compose and\nevaluate different networks using feature and/or label propagation networks,\nlinear or non-linear networks, with each composition having different\ncomputational complexity. We conduct a detailed experimental study on several\nbenchmark datasets with many variants and present observations from our\nevaluation. Our empirical experimental results suggest that several newly\ncomposed variants are useful alternatives to consider because they are as\ncompetitive as, or better than the original GCN.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:52:09 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ragesh", "Rahul", ""], ["Sellamanickam", "Sundararajan", ""], ["Lingam", "Vijay", ""], ["Iyer", "Arun", ""]]}, {"id": "2004.04006", "submitter": "Yue Wu", "authors": "Yue Wu, Hao Ni, Terence J. Lyons, and Robin L. Hudson", "title": "Signature features with the visibility transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we put the visibility transformation on a clear theoretical\nfooting and show that this transform is able to embed the effect of the\nabsolute position of the data stream into signature features in a unified and\nefficient way. The generated feature set is particularly useful in pattern\nrecognition tasks, for its simplifying role in allowing the signature feature\nset to accommodate nonlinear functions of absolute and relative values.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:24:13 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 11:18:19 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 09:25:50 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 23:26:58 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wu", "Yue", ""], ["Ni", "Hao", ""], ["Lyons", "Terence J.", ""], ["Hudson", "Robin L.", ""]]}, {"id": "2004.04019", "submitter": "Mauricio Santillana", "authors": "Dianbo Liu, Leonardo Clemente, Canelle Poirier, Xiyu Ding, Matteo\n  Chinazzi, Jessica T Davis, Alessandro Vespignani, Mauricio Santillana", "title": "A machine learning methodology for real-time forecasting of the\n  2019-2020 COVID-19 outbreak using Internet searches, news alerts, and\n  estimates from mechanistic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a timely and novel methodology that combines disease estimates\nfrom mechanistic models with digital traces, via interpretable machine-learning\nmethodologies, to reliably forecast COVID-19 activity in Chinese provinces in\nreal-time. Specifically, our method is able to produce stable and accurate\nforecasts 2 days ahead of current time, and uses as inputs (a) official health\nreports from Chinese Center Disease for Control and Prevention (China CDC), (b)\nCOVID-19-related internet search activity from Baidu, (c) news media activity\nreported by Media Cloud, and (d) daily forecasts of COVID-19 activity from\nGLEAM, an agent-based mechanistic model. Our machine-learning methodology uses\na clustering technique that enables the exploitation of geo-spatial\nsynchronicities of COVID-19 activity across Chinese provinces, and a data\naugmentation technique to deal with the small number of historical disease\nactivity observations, characteristic of emerging outbreaks. Our model's\npredictive power outperforms a collection of baseline models in 27 out of the\n32 Chinese provinces, and could be easily extended to other geographies\ncurrently affected by the COVID-19 outbreak to help decision makers.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:39:32 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Liu", "Dianbo", ""], ["Clemente", "Leonardo", ""], ["Poirier", "Canelle", ""], ["Ding", "Xiyu", ""], ["Chinazzi", "Matteo", ""], ["Davis", "Jessica T", ""], ["Vespignani", "Alessandro", ""], ["Santillana", "Mauricio", ""]]}, {"id": "2004.04030", "submitter": "Ayobami Adewale Mr", "authors": "Ayobami E. Adewale and Amnir Hadachi", "title": "Neural Networks Model for Travel Time Prediction Based on ODTravel Time\n  Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public transportation system commuters are often interested in getting\naccurate travel time information to plan their daily activities. However, this\ninformation is often difficult to predict accurately due to the irregularities\nof road traffic, caused by factors such as weather conditions, road accidents,\nand traffic jams. In this study, two neural network models namely\nmulti-layer(MLP) perceptron and long short-term model(LSTM) are developed for\npredicting link travel time of a busy route with input generated using\nOrigin-Destination travel time matrix derived from a historical GPS dataset.\nThe experiment result showed that both models can make near-accurate\npredictions however, LSTM is more susceptible to noise as time step increases.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 15:01:13 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Adewale", "Ayobami E.", ""], ["Hadachi", "Amnir", ""]]}, {"id": "2004.04054", "submitter": "Astik Biswas", "authors": "A. Biswas, F. de Wet, E. van der Westhuizen, T.R. Niesler", "title": "Semi-supervised acoustic and language model training for English-isiZulu\n  code-switched speech recognition", "comments": "4th Code-Switch workshop, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis of semi-supervised acoustic and language model\ntraining for English-isiZulu code-switched ASR using soap opera speech.\nApproximately 11 hours of untranscribed multilingual speech was transcribed\nautomatically using four bilingual code-switching transcription systems\noperating in English-isiZulu, English-isiXhosa, English-Setswana and\nEnglish-Sesotho. These transcriptions were incorporated into the acoustic and\nlanguage model training sets. Results showed that the TDNN-F acoustic models\nbenefit from the additional semi-supervised data and that even better\nperformance could be achieved by including additional CNN layers. Using these\nCNN-TDNN-F acoustic models, a first iteration of semi-supervised training\nachieved an absolute mixed-language WER reduction of 3.4%, and a further 2.2%\nafter a second iteration. Although the languages in the untranscribed data were\nunknown, the best results were obtained when all automatically transcribed data\nwas used for training and not just the utterances classified as\nEnglish-isiZulu. Despite reducing perplexity, the semi-supervised language\nmodel was not able to improve the ASR performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:27:29 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Biswas", "A.", ""], ["de Wet", "F.", ""], ["van der Westhuizen", "E.", ""], ["Niesler", "T. R.", ""]]}, {"id": "2004.04072", "submitter": "Lam Pham", "authors": "Lam Pham, Huy Phan, Ramaswamy Palaniappan, Alfred Mertins, Ian\n  McLoughlin", "title": "CNN-MoE based framework for classification of respiratory anomalies and\n  lung disease detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents and explores a robust deep learning framework for\nauscultation analysis. This aims to classify anomalies in respiratory cycles\nand detect disease, from respiratory sound recordings. The framework begins\nwith front-end feature extraction that transforms input sound into a\nspectrogram representation. Then, a back-end deep learning network is used to\nclassify the spectrogram features into categories of respiratory anomaly cycles\nor diseases. Experiments, conducted over the ICBHI benchmark dataset of\nrespiratory sounds, confirm three main contributions towards respiratory-sound\nanalysis. Firstly, we carry out an extensive exploration of the effect of\nspectrogram type, spectral-time resolution, overlapped/non-overlapped windows,\nand data augmentation on final prediction accuracy. This leads us to propose a\nnovel deep learning system, built on the proposed framework, which outperforms\ncurrent state-of-the-art methods. Finally, we apply a Teacher-Student scheme to\nachieve a trade-off between model performance and model complexity which\nadditionally helps to increase the potential of the proposed framework for\nbuilding real-time applications.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 21:45:06 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 19:55:28 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Pham", "Lam", ""], ["Phan", "Huy", ""], ["Palaniappan", "Ramaswamy", ""], ["Mertins", "Alfred", ""], ["McLoughlin", "Ian", ""]]}, {"id": "2004.04077", "submitter": "Andrea Cossu", "authors": "Andrea Cossu, Antonio Carta, Davide Bacciu", "title": "Continual Learning with Gated Incremental Memories for sequential data\n  processing", "comments": "Accepted as a conference paper at 2020 International Joint Conference\n  on Neural Networks (IJCNN 2020). Part of 2020 IEEE World Congress on\n  Computational Intelligence (IEEE WCCI 2020)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207550", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn in dynamic, nonstationary environments without\nforgetting previous knowledge, also known as Continual Learning (CL), is a key\nenabler for scalable and trustworthy deployments of adaptive solutions. While\nthe importance of continual learning is largely acknowledged in machine vision\nand reinforcement learning problems, this is mostly under-documented for\nsequence processing tasks. This work proposes a Recurrent Neural Network (RNN)\nmodel for CL that is able to deal with concept drift in input distribution\nwithout forgetting previously acquired knowledge. We also implement and test a\npopular CL approach, Elastic Weight Consolidation (EWC), on top of two\ndifferent types of RNNs. Finally, we compare the performances of our enhanced\narchitecture against EWC and RNNs on a set of standard CL benchmarks, adapted\nto the sequential data processing scenario. Results show the superior\nperformance of our architecture and highlight the need for special solutions\ndesigned to address CL in RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:00:20 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Cossu", "Andrea", ""], ["Carta", "Antonio", ""], ["Bacciu", "Davide", ""]]}, {"id": "2004.04092", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Xiang Gao, Yuan Li, Baolin Peng, Xiujun Li, Yizhe Zhang,\n  Jianfeng Gao", "title": "Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space", "comments": "Accepted in EMNLP 2020; Code: https://github.com/ChunyuanLI/Optimus\n  Demo: http://aka.ms/optimus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trained effectively, the Variational Autoencoder (VAE) can be both a\npowerful generative model and an effective representation learning framework\nfor natural language. In this paper, we propose the first large-scale language\nVAE model, Optimus. A universal latent embedding space for sentences is first\npre-trained on large text corpus, and then fine-tuned for various language\ngeneration and understanding tasks. Compared with GPT-2, Optimus enables guided\nlanguage generation from an abstract level using the latent vectors. Compared\nwith BERT, Optimus can generalize better on low-resource language understanding\ntasks due to the smooth latent space structure. Extensive experimental results\non a wide range of language tasks demonstrate the effectiveness of Optimus. It\nachieves new state-of-the-art on VAE language modeling benchmarks. We hope that\nour first pre-trained big VAE language model itself and results can help the\nNLP community renew the interests of deep generative models in the era of\nlarge-scale pre-training, and make these principled methods more practical.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:20:18 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 19:11:42 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 00:41:43 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 23:33:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Chunyuan", ""], ["Gao", "Xiang", ""], ["Li", "Yuan", ""], ["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Zhang", "Yizhe", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.04093", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Meenu Ajith, Aswathy Rajendra Kurup, and Manel Mart\\'inez-Ram\\'on", "title": "Time accelerated image super-resolution using shallow residual feature\n  representative network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep learning indicate significant progress in the\nfield of single image super-resolution. With the advent of these techniques,\nhigh-resolution image with high peak signal to noise ratio (PSNR) and excellent\nperceptual quality can be reconstructed. The major challenges associated with\nexisting deep convolutional neural networks are their computational complexity\nand time; the increasing depth of the networks, often result in high space\ncomplexity. To alleviate these issues, we developed an innovative shallow\nresidual feature representative network (SRFRN) that uses a bicubic\ninterpolated low-resolution image as input and residual representative units\n(RFR) which include serially stacked residual non-linear convolutions.\nFurthermore, the reconstruction of the high-resolution image is done by\ncombining the output of the RFR units and the residual output from the bicubic\ninterpolated LR image. Finally, multiple experiments have been performed on the\nbenchmark datasets and the proposed model illustrates superior performance for\nhigher scales. Besides, this model also exhibits faster execution time compared\nto all the existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:17:42 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ajith", "Meenu", ""], ["Kurup", "Aswathy Rajendra", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""]]}, {"id": "2004.04095", "submitter": "Yunqi Cai", "authors": "Yunqi Cai, Lantian Li, Dong Wang and Andrew Abel", "title": "Deep Normalization for Speaker Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embedding has demonstrated state-of-the-art performance in\nspeaker recognition tasks. However, one potential issue with this approach is\nthat the speaker vectors derived from deep embedding models tend to be\nnon-Gaussian for each individual speaker, and non-homogeneous for distributions\nof different speakers. These irregular distributions can seriously impact\nspeaker recognition performance, especially with the popular PLDA scoring\nmethod, which assumes homogeneous Gaussian distribution. In this paper, we\nargue that deep speaker vectors require deep normalization, and propose a deep\nnormalization approach based on a novel discriminative normalization flow (DNF)\nmodel. We demonstrate the effectiveness of the proposed approach with\nexperiments using the widely used SITW and CNCeleb corpora. In these\nexperiments, the DNF-based normalization delivered substantial performance\ngains and also showed strong generalization capability in out-of-domain tests.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 09:20:48 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:27:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Yunqi", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Abel", "Andrew", ""]]}, {"id": "2004.04096", "submitter": "Niko Br\\\"ummer", "authors": "Anna Silnova, Niko Br\\\"ummer, Johan Rohdin, Themos Stafylakis,\n  Luk\\'a\\v{s} Burget", "title": "Probabilistic embeddings for speaker diarization", "comments": "Awarded: Jack Godfrey Best Student Paper Award, at Odyssey 2020: The\n  Speaker and Language Recognition Workshop, Tokio", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker embeddings (x-vectors) extracted from very short segments of speech\nhave recently been shown to give competitive performance in speaker\ndiarization. We generalize this recipe by extracting from each speech segment,\nin parallel with the x-vector, also a diagonal precision matrix, thus providing\na path for the propagation of information about the quality of the speech\nsegment into a PLDA scoring backend. These precisions quantify the uncertainty\nabout what the values of the embeddings might have been if they had been\nextracted from high quality speech segments. The proposed probabilistic\nembeddings (x-vectors with precisions) are interfaced with the PLDA model by\ntreating the x-vectors as hidden variables and marginalizing them out. We apply\nthe proposed probabilistic embeddings as input to an agglomerative hierarchical\nclustering (AHC) algorithm to do diarization in the DIHARD'19 evaluation set.\nWe compute the full PLDA likelihood 'by the book' for each clustering\nhypothesis that is considered by AHC. We do joint discriminative training of\nthe PLDA parameters and of the probabilistic x-vector extractor. We demonstrate\naccuracy gains relative to a baseline AHC algorithm, applied to traditional\nxvectors (without uncertainty), and which uses averaging of binary\nlog-likelihood-ratios, rather than by-the-book scoring.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:51:01 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 09:25:25 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 06:16:16 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Silnova", "Anna", ""], ["Br\u00fcmmer", "Niko", ""], ["Rohdin", "Johan", ""], ["Stafylakis", "Themos", ""], ["Burget", "Luk\u00e1\u0161", ""]]}, {"id": "2004.04098", "submitter": "Tsun-An Hsieh", "authors": "Tsun-An Hsieh, Hsin-Min Wang, Xugang Lu, and Yu Tsao", "title": "WaveCRN: An Efficient Convolutional Recurrent Neural Network for\n  End-to-end Speech Enhancement", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3040693", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the simple design pipeline, end-to-end (E2E) neural models for speech\nenhancement (SE) have attracted great interest. In order to improve the\nperformance of the E2E model, the locality and temporal sequential properties\nof speech should be efficiently taken into account when modelling. However, in\nmost current E2E models for SE, these properties are either not fully\nconsidered or are too complex to be realized. In this paper, we propose an\nefficient E2E SE model, termed WaveCRN. In WaveCRN, the speech locality feature\nis captured by a convolutional neural network (CNN), while the temporal\nsequential property of the locality feature is modeled by stacked simple\nrecurrent units (SRU). Unlike a conventional temporal sequential model that\nuses a long short-term memory (LSTM) network, which is difficult to\nparallelize, SRU can be efficiently parallelized in calculation with even fewer\nmodel parameters. In addition, in order to more effectively suppress the noise\ncomponents in the input noisy speech, we derive a novel restricted feature\nmasking (RFM) approach that performs enhancement on the feature maps in the\nhidden layers; this is different from the approach that applies the estimated\nratio mask on the noisy spectral features, which is commonly used in speech\nseparation methods. Experimental results on speech denoising and compressed\nspeech restoration tasks confirm that with the lightweight architecture of SRU\nand the feature-mapping-based RFM, WaveCRN performs comparably with other\nstate-of-the-art approaches with notably reduced model complexity and inference\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:48:05 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 15:40:42 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 07:28:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hsieh", "Tsun-An", ""], ["Wang", "Hsin-Min", ""], ["Lu", "Xugang", ""], ["Tsao", "Yu", ""]]}, {"id": "2004.04104", "submitter": "Hieu Nguyen", "authors": "Nguyen Quang Hieu, Tran The Anh, Nguyen Cong Luong, Dusit Niyato, Dong\n  In Kim, Erik Elmroth", "title": "Resource Management for Blockchain-enabled Federated Learning: A Deep\n  Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-enabled Federated Learning (BFL) enables mobile devices to\ncollaboratively train neural network models required by a Machine Learning\nModel Owner (MLMO) while keeping data on the mobile devices. Then, the model\nupdates are stored in the blockchain in a decentralized and reliable manner.\nHowever, the issue of BFL is that the mobile devices have energy and CPU\nconstraints that may reduce the system lifetime and training efficiency. The\nother issue is that the training latency may increase due to the blockchain\nmining process. To address these issues, the MLMO needs to (i) decide how much\ndata and energy that the mobile devices use for the training and (ii) determine\nthe block generation rate to minimize the system latency, energy consumption,\nand incentive cost while achieving the target accuracy for the model. Under the\nuncertainty of the BFL environment, it is challenging for the MLMO to determine\nthe optimal decisions. We propose to use the Deep Reinforcement Learning (DRL)\nto derive the optimal decisions for the MLMO.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:29:19 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 05:51:28 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Hieu", "Nguyen Quang", ""], ["Anh", "Tran The", ""], ["Luong", "Nguyen Cong", ""], ["Niyato", "Dusit", ""], ["Kim", "Dong In", ""], ["Elmroth", "Erik", ""]]}, {"id": "2004.04116", "submitter": "Lorraine Chambers", "authors": "Lorraine Chambers, Mohamed Medhat Gaber, Zahraa S. Abdallah", "title": "DeepStreamCE: A Streaming Approach to Concept Evolution Detection in\n  Deep Neural Networks", "comments": "Submitted to Journal of Machine Learning, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have experimentally demonstrated superior performance\nover other machine learning approaches in decision-making predictions. However,\none major concern is the closed set nature of the classification decision on\nthe trained classes, which can have serious consequences in safety critical\nsystems. When the deep neural network is in a streaming environment, fast\ninterpretation of this classification is required to determine if the\nclassification result is trusted. Un-trusted classifications can occur when the\ninput data to the deep neural network changes over time. One type of change\nthat can occur is concept evolution, where a new class is introduced that the\ndeep neural network was not trained on. In the majority of deep neural network\narchitectures, the only option is to assign this instance to one of the classes\nit was trained on, which would be incorrect. The aim of this research is to\ndetect the arrival of a new class in the stream. Existing work on interpreting\ndeep neural networks often focuses on neuron activations to provide visual\ninterpretation and feature extraction. Our novel approach, coined DeepStreamCE,\nuses streaming approaches for real-time concept evolution detection in deep\nneural networks. DeepStreamCE applies neuron activation reduction using an\nautoencoder and MCOD stream-based clustering in the offline phase. Both outputs\nare used in the online phase to analyse the neuron activations in the evolving\nstream in order to detect concept evolution occurrence in real time. We\nevaluate DeepStreamCE by training VGG16 convolutional neural networks on\ncombinations of data from the CIFAR-10 dataset, holding out some classes to be\nused as concept evolution. For comparison, we apply the data and VGG16 networks\nto an open-set deep network solution - OpenMax. DeepStreamCE outperforms\nOpenMax when identifying concept evolution for our datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:53:26 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Chambers", "Lorraine", ""], ["Gaber", "Mohamed Medhat", ""], ["Abdallah", "Zahraa S.", ""]]}, {"id": "2004.04120", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Solving the scalarization issues of Advantage-based Reinforcement\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": "10.1016/j.compeleceng.2021.107117", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, some of the issues that arise from the scalarization of the\nmulti-objective optimization problem in the Advantage Actor Critic (A2C)\nreinforcement learning algorithm are investigated. The paper shows how a naive\nscalarization can lead to gradients overlapping. Furthermore, the possibility\nthat the entropy regularization term can be a source of uncontrolled noise is\ndiscussed. With respect to the above issues, a technique to avoid gradient\noverlapping is proposed, while keeping the same loss formulation. Moreover, a\nmethod to avoid the uncontrolled noise, by sampling the actions from\ndistributions with a desired minimum entropy, is investigated. Pilot\nexperiments have been carried out to show how the proposed method speeds up the\ntraining. The proposed approach can be applied to any Advantage-based\nReinforcement Learning algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:03:21 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:58:25 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 14:30:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "2004.04136", "submitter": "Michael Laskin", "authors": "Aravind Srinivas, Michael Laskin, Pieter Abbeel", "title": "CURL: Contrastive Unsupervised Representations for Reinforcement\n  Learning", "comments": "First two authors contributed equally, website:\n  https://mishalaskin.github.io/curl code: https://github.com/MishaLaskin/curl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CURL: Contrastive Unsupervised Representations for Reinforcement\nLearning. CURL extracts high-level features from raw pixels using contrastive\nlearning and performs off-policy control on top of the extracted features. CURL\noutperforms prior pixel-based methods, both model-based and model-free, on\ncomplex tasks in the DeepMind Control Suite and Atari Games showing 1.9x and\n1.2x performance gains at the 100K environment and interaction steps benchmarks\nrespectively. On the DeepMind Control Suite, CURL is the first image-based\nalgorithm to nearly match the sample-efficiency of methods that use state-based\nfeatures. Our code is open-sourced and available at\nhttps://github.com/MishaLaskin/curl.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:40:43 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:54:47 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 16:37:04 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 15:34:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Srinivas", "Aravind", ""], ["Laskin", "Michael", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2004.04141", "submitter": "Leslie Smith", "authors": "Leslie N. Smith, Adam Conovaloff", "title": "Empirical Perspectives on One-Shot Semi-supervised Learning", "comments": "Short paper with interesting results pointing to further\n  investigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest obstacles in the adoption of deep neural networks for new\napplications is that training the network typically requires a large number of\nmanually labeled training samples. We empirically investigate the scenario\nwhere one has access to large amounts of unlabeled data but require labeling\nonly a single prototypical sample per class in order to train a deep network\n(i.e., one-shot semi-supervised learning). Specifically, we investigate the\nrecent results reported in FixMatch for one-shot semi-supervised learning to\nunderstand the factors that affect and impede high accuracies and reliability\nfor one-shot semi-supervised learning of Cifar-10. For example, we discover\nthat one barrier to one-shot semi-supervised learning for high-performance\nimage classification is the unevenness of class accuracy during the training.\nThese results point to solutions that might enable more widespread adoption of\none-shot semi-supervised training methods for new applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:51:06 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Smith", "Leslie N.", ""], ["Conovaloff", "Adam", ""]]}, {"id": "2004.04192", "submitter": "Elijah Cole", "authors": "Elijah Cole, Benjamin Deneu, Titouan Lorieul, Maximilien Servajean,\n  Christophe Botella, Dan Morris, Nebojsa Jojic, Pierre Bonnet, Alexis Joly", "title": "The GeoLifeCLEF 2020 Dataset", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the geographic distribution of species is a key concern in\nconservation. By pairing species occurrences with environmental features,\nresearchers can model the relationship between an environment and the species\nwhich may be found there. To facilitate research in this area, we present the\nGeoLifeCLEF 2020 dataset, which consists of 1.9 million species observations\npaired with high-resolution remote sensing imagery, land cover data, and\naltitude, in addition to traditional low-resolution climate and soil variables.\nWe also discuss the GeoLifeCLEF 2020 competition, which aims to use this\ndataset to advance the state-of-the-art in location-based species\nrecommendation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:30:00 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Cole", "Elijah", ""], ["Deneu", "Benjamin", ""], ["Lorieul", "Titouan", ""], ["Servajean", "Maximilien", ""], ["Botella", "Christophe", ""], ["Morris", "Dan", ""], ["Jojic", "Nebojsa", ""], ["Bonnet", "Pierre", ""], ["Joly", "Alexis", ""]]}, {"id": "2004.04193", "submitter": "Xavier Fontaine", "authors": "Xavier Fontaine, Valentin De Bortoli, and Alain Durmus", "title": "Convergence rates and approximation results for SGD and its\n  continuous-time counterpart", "comments": "94 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a thorough theoretical analysis of Stochastic Gradient\nDescent (SGD) with non-increasing step sizes. First, we show that the recursion\ndefining SGD can be provably approximated by solutions of a time inhomogeneous\nStochastic Differential Equation (SDE) using an appropriate coupling. In the\nspecific case of a batch noise we refine our results using recent advances in\nStein's method. Then, motivated by recent analyses of deterministic and\nstochastic optimization methods by their continuous counterpart, we study the\nlong-time behavior of the continuous processes at hand and establish\nnon-asymptotic bounds. To that purpose, we develop new comparison techniques\nwhich are of independent interest. Adapting these techniques to the discrete\nsetting, we show that the same results hold for the corresponding SGD\nsequences. In our analysis, we notably improve non-asymptotic bounds in the\nconvex setting for SGD under weaker assumptions than the ones considered in\nprevious works. Finally, we also establish finite-time convergence results\nunder various conditions, including relaxations of the famous {\\L}ojasiewicz\ninequality, which can be applied to a class of non-convex functions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:31:34 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 21:39:41 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Fontaine", "Xavier", ""], ["De Bortoli", "Valentin", ""], ["Durmus", "Alain", ""]]}, {"id": "2004.04198", "submitter": "Kenneth McMIllan", "authors": "Kenneth L. McMillan", "title": "Bayesian Interpolants as Explanations for Neural Inferences", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of Craig interpolant, used as a form of explanation in automated\nreasoning, is adapted from logical inference to statistical inference and used\nto explain inferences made by neural networks. The method produces explanations\nthat are at the same time concise, understandable and precise.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:45:06 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["McMillan", "Kenneth L.", ""]]}, {"id": "2004.04221", "submitter": "Lei Xu", "authors": "Lei Xu, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj", "title": "Saliency-based Weighted Multi-label Linear Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new variant of Linear Discriminant Analysis (LDA)\nto solve multi-label classification tasks. The proposed method is based on a\nprobabilistic model for defining the weights of individual samples in a\nweighted multi-label LDA approach. Linear Discriminant Analysis is a classical\nstatistical machine learning method, which aims to find a linear data\ntransformation increasing class discrimination in an optimal discriminant\nsubspace. Traditional LDA sets assumptions related to Gaussian class\ndistributions and single-label data annotations. To employ the LDA technique in\nmulti-label classification problems, we exploit intuitions coming from a\nprobabilistic interpretation of class saliency to redefine the between-class\nand within-class scatter matrices. The saliency-based weights obtained based on\nvarious kinds of affinity encoding prior information are used to reveal the\nprobability of each instance to be salient for each of its classes in the\nmulti-label problem at hand. The proposed Saliency-based weighted Multi-label\nLDA approach is shown to lead to performance improvements in various\nmulti-label classification problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:40:53 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Xu", "Lei", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2004.04249", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi, Mohammad Samragh, Tara Javidi, Farinaz Koushanfar", "title": "GeneCAI: Genetic Evolution for Acquiring Compact AI", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390226", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contemporary big data realm, Deep Neural Networks (DNNs) are evolving\ntowards more complex architectures to achieve higher inference accuracy. Model\ncompression techniques can be leveraged to efficiently deploy such\ncompute-intensive architectures on resource-limited mobile devices. Such\nmethods comprise various hyper-parameters that require per-layer customization\nto ensure high accuracy. Choosing such hyper-parameters is cumbersome as the\npertinent search space grows exponentially with model layers. This paper\nintroduces GeneCAI, a novel optimization method that automatically learns how\nto tune per-layer compression hyper-parameters. We devise a bijective\ntranslation scheme that encodes compressed DNNs to the genotype space. The\noptimality of each genotype is measured using a multi-objective score based on\naccuracy and number of floating point operations. We develop customized genetic\noperations to iteratively evolve the non-dominated solutions towards the\noptimal Pareto front, thus, capturing the optimal trade-off between model\naccuracy and complexity. GeneCAI optimization method is highly scalable and can\nachieve a near-linear performance boost on distributed multi-GPU platforms. Our\nextensive evaluations demonstrate that GeneCAI outperforms existing rule-based\nand reinforcement learning methods in DNN compression by finding models that\nlie on a better accuracy-complexity Pareto curve.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 20:56:37 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 04:35:42 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Samragh", "Mohammad", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2004.04250", "submitter": "Zhao Song", "authors": "Haotian Jiang, Yin Tat Lee, Zhao Song, Sam Chiu-wai Wong", "title": "An Improved Cutting Plane Method for Convex Optimization, Convex-Concave\n  Games and its Applications", "comments": "STOC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Given a separation oracle for a convex set $K \\subset \\mathbb{R}^n$ that is\ncontained in a box of radius $R$, the goal is to either compute a point in $K$\nor prove that $K$ does not contain a ball of radius $\\epsilon$. We propose a\nnew cutting plane algorithm that uses an optimal $O(n \\log (\\kappa))$\nevaluations of the oracle and an additional $O(n^2)$ time per evaluation, where\n$\\kappa = nR/\\epsilon$.\n  $\\bullet$ This improves upon Vaidya's $O( \\text{SO} \\cdot n \\log (\\kappa) +\nn^{\\omega+1} \\log (\\kappa))$ time algorithm [Vaidya, FOCS 1989a] in terms of\npolynomial dependence on $n$, where $\\omega < 2.373$ is the exponent of matrix\nmultiplication and $\\text{SO}$ is the time for oracle evaluation.\n  $\\bullet$ This improves upon Lee-Sidford-Wong's $O( \\text{SO} \\cdot n \\log\n(\\kappa) + n^3 \\log^{O(1)} (\\kappa))$ time algorithm [Lee, Sidford and Wong,\nFOCS 2015] in terms of dependence on $\\kappa$.\n  For many important applications in economics, $\\kappa = \\Omega(\\exp(n))$ and\nthis leads to a significant difference between $\\log(\\kappa)$ and\n$\\mathrm{poly}(\\log (\\kappa))$. We also provide evidence that the $n^2$ time\nper evaluation cannot be improved and thus our running time is optimal.\n  A bottleneck of previous cutting plane methods is to compute leverage scores,\na measure of the relative importance of past constraints. Our result is\nachieved by a novel multi-layered data structure for leverage score\nmaintenance, which is a sophisticated combination of diverse techniques such as\nrandom projection, batched low-rank update, inverse maintenance, polynomial\ninterpolation, and fast rectangular matrix multiplication. Interestingly, our\nmethod requires a combination of different fast rectangular matrix\nmultiplication algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 20:56:40 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jiang", "Haotian", ""], ["Lee", "Yin Tat", ""], ["Song", "Zhao", ""], ["Wong", "Sam Chiu-wai", ""]]}, {"id": "2004.04256", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Adrian Flanagan, Were Oyomno, Alexander Grigorievskiy, Kuan Eeik Tan,\n  Suleiman A. Khan, and Muhammad Ammad-Ud-Din", "title": "Federated Multi-view Matrix Factorization for Personalized\n  Recommendations", "comments": "16 pages, 3 figures, 5 tables, submitted to a conference", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2020. Lecture Notes in Computer Science, Springer, Cham", "doi": "10.1007/978-3-030-67661-2_20", "report-no": "12458", "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the federated multi-view matrix factorization method that\nextends the federated learning framework to matrix factorization with multiple\ndata sources. Our method is able to learn the multi-view model without\ntransferring the user's personal data to a central server. As far as we are\naware this is the first federated model to provide recommendations using\nmulti-view matrix factorization. The model is rigorously evaluated on three\ndatasets on production settings. Empirical validation confirms that federated\nmulti-view matrix factorization outperforms simpler methods that do not take\ninto account the multi-view structure of the data, in addition, it demonstrates\nthe usefulness of the proposed method for the challenging prediction tasks of\ncold-start federated recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 21:07:50 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Flanagan", "Adrian", ""], ["Oyomno", "Were", ""], ["Grigorievskiy", "Alexander", ""], ["Tan", "Kuan Eeik", ""], ["Khan", "Suleiman A.", ""], ["Ammad-Ud-Din", "Muhammad", ""]]}, {"id": "2004.04272", "submitter": "Jingyun Jia", "authors": "Jingyun Jia", "title": "Deep Learning and Open Set Malware Classification: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Internet is growing rapidly these years, the variant of malicious\nsoftware, which often referred to as malware, has become one of the major and\nserious threats to Internet users. The dramatic increase of malware has led to\na research area of not only using cutting edge machine learning techniques\nclassify malware into their known families, moreover, recognize the unknown\nones, which can be related to Open Set Recognition (OSR) problem in machine\nlearning. Recent machine learning works have shed light on Open Set Recognition\n(OSR) from different scenarios. Under the situation of missing unknown training\nsamples, the OSR system should not only correctly classify the known classes,\nbut also recognize the unknown class. This survey provides an overview of\ndifferent deep learning techniques, a discussion of OSR and graph\nrepresentation solutions and an introduction of malware classification systems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 21:36:21 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jia", "Jingyun", ""]]}, {"id": "2004.04292", "submitter": "Mark Koren", "authors": "Mark Koren and Mykel J. Kochenderfer", "title": "Adaptive Stress Testing without Domain Heuristics using Go-Explore", "comments": "Accepted to ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning (RL) has been used as a tool for finding\nfailures in autonomous systems. During execution, the RL agents often rely on\nsome domain-specific heuristic reward to guide them towards finding failures,\nbut constructing such a heuristic may be difficult or infeasible. Without a\nheuristic, the agent may only receive rewards at the time of failure, or even\nrewards that guide it away from failures. For example, some approaches give\nrewards for taking more-likely actions, because we want to find more-likely\nfailures. However, the agent may then learn to only take likely actions, and\nmay not be able to find a failure at all. Consequently, the problem becomes a\nhard-exploration problem, where rewards do not aid exploration. A new\nalgorithm, go-explore (GE), has recently set new records on benchmarks from the\nhard-exploration field. We apply GE to adaptive stress testing (AST), one\nexample of an RL-based falsification approach that provides a way to search for\nthe most-likely failure scenario. We simulate a scenario where an autonomous\nvehicle drives while a pedestrian is crossing the road. We demonstrate that GE\nis able to find failures without domain-specific heuristics, such as the\ndistance between the car and the pedestrian, on scenarios that other RL\ntechniques are unable to solve. Furthermore, inspired by the robustification\nphase of GE, we demonstrate that the backwards algorithm (BA) improves the\nfailures found by other RL techniques.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 22:56:59 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:49:28 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Koren", "Mark", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.04293", "submitter": "Mark Koren", "authors": "Mark Koren, Anthony Corso, and Mykel J. Kochenderfer", "title": "The Adaptive Stress Testing Formulation", "comments": "Presented at the Workshop on Robust Autonomy at RSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validation is a key challenge in the search for safe autonomy. Simulations\nare often either too simple to provide robust validation, or too complex to\ntractably compute. Therefore, approximate validation methods are needed to\ntractably find failures without unsafe simplifications. This paper presents the\ntheory behind one such black-box approach: adaptive stress testing (AST). We\nalso provide three examples of validation problems formulated to work with AST.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 23:04:42 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Koren", "Mark", ""], ["Corso", "Anthony", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.04320", "submitter": "Ka-Ho Chow", "authors": "Ka-Ho Chow, Ling Liu, Mehmet Emre Gursoy, Stacey Truex, Wenqi Wei,\n  Yanzhao Wu", "title": "TOG: Targeted Adversarial Objectness Gradient Attacks on Real-time\n  Object Detection Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of real-time huge data capturing has pushed the deep\nlearning and data analytic computing to the edge systems. Real-time object\nrecognition on the edge is one of the representative deep neural network (DNN)\npowered edge systems for real-world mission-critical applications, such as\nautonomous driving and augmented reality. While DNN powered object detection\nedge systems celebrate many life-enriching opportunities, they also open doors\nfor misuse and abuse. This paper presents three Targeted adversarial Objectness\nGradient attacks, coined as TOG, which can cause the state-of-the-art deep\nobject detection networks to suffer from object-vanishing, object-fabrication,\nand object-mislabeling attacks. We also present a universal objectness gradient\nattack to use adversarial transferability for black-box attacks, which is\neffective on any inputs with negligible attack time cost, low human\nperceptibility, and particularly detrimental to object detection edge systems.\nWe report our experimental measurements using two benchmark datasets (PASCAL\nVOC and MS COCO) on two state-of-the-art detection algorithms (YOLO and SSD).\nThe results demonstrate serious adversarial vulnerabilities and the compelling\nneed for developing robust object detection systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 01:36:23 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Chow", "Ka-Ho", ""], ["Liu", "Ling", ""], ["Gursoy", "Mehmet Emre", ""], ["Truex", "Stacey", ""], ["Wei", "Wenqi", ""], ["Wu", "Yanzhao", ""]]}, {"id": "2004.04333", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Ruxin Wang, Rongxiang Zhu, Yunpeng Cai, Hongyan Wu", "title": "HopGAT: Hop-aware Supervision Graph Attention Networks for Sparsely\n  Labeled Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the cost of labeling nodes, classifying a node in a sparsely labeled\ngraph while maintaining the prediction accuracy deserves attention. The key\npoint is how the algorithm learns sufficient information from more neighbors\nwith different hop distances. This study first proposes a hop-aware attention\nsupervision mechanism for the node classification task. A simulated annealing\nlearning strategy is then adopted to balance two learning tasks, node\nclassification and the hop-aware attention coefficients, along the training\ntimeline. Compared with state-of-the-art models, the experimental results\nproved the superior effectiveness of the proposed Hop-aware Supervision Graph\nAttention Networks (HopGAT) model. Especially, for the protein-protein\ninteraction network, in a 40% labeled graph, the performance loss is only 3.9%,\nfrom 98.5% to 94.6%, compared to the fully labeled graph. Extensive experiments\nalso demonstrate the effectiveness of supervised attention coefficient and\nlearning strategies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 02:27:15 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ji", "Chaojie", ""], ["Wang", "Ruxin", ""], ["Zhu", "Rongxiang", ""], ["Cai", "Yunpeng", ""], ["Wu", "Hongyan", ""]]}, {"id": "2004.04342", "submitter": "Yang Yang", "authors": "Adam Golinski, Reza Pourreza, Yang Yang, Guillaume Sautiere, Taco S\n  Cohen", "title": "Feedback Recurrent Autoencoder for Video Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep generative modeling have enabled efficient modeling\nof high dimensional data distributions and opened up a new horizon for solving\ndata compression problems. Specifically, autoencoder based learned image or\nvideo compression solutions are emerging as strong competitors to traditional\napproaches. In this work, We propose a new network architecture, based on\ncommon and well studied components, for learned video compression operating in\nlow latency mode. Our method yields state of the art MS-SSIM/rate performance\non the high-resolution UVG dataset, among both learned video compression\napproaches and classical video compression methods (H.265 and H.264) in the\nrate range of interest for streaming applications. Additionally, we provide an\nanalysis of existing approaches through the lens of their underlying\nprobabilistic graphical models. Finally, we point out issues with temporal\nconsistency and color shift observed in empirical evaluation, and suggest\ndirections forward to alleviate those.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 02:58:07 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Golinski", "Adam", ""], ["Pourreza", "Reza", ""], ["Yang", "Yang", ""], ["Sautiere", "Guillaume", ""], ["Cohen", "Taco S", ""]]}, {"id": "2004.04362", "submitter": "Chee-Ming Ting PhD", "authors": "Chee-Ming Ting, S. Balqis Samdin, Meini Tang, Hernando Ombao", "title": "Detecting Dynamic Community Structure in Functional Brain Networks\n  Across Individuals: A Multilayer Approach", "comments": "Main paper: 12 pages, 13 figures. Supplemental file: 16 pages.\n  Accepted for IEEE Trans Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.3030047", "report-no": null, "categories": "cs.LG eess.SP physics.soc-ph q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified statistical framework for characterizing community\nstructure of brain functional networks that captures variation across\nindividuals and evolution over time. Existing methods for community detection\nfocus only on single-subject analysis of dynamic networks; while recent\nextensions to multiple-subjects analysis are limited to static networks. To\novercome these limitations, we propose a multi-subject, Markov-switching\nstochastic block model (MSS-SBM) to identify state-related changes in brain\ncommunity organization over a group of individuals. We first formulate a\nmultilayer extension of SBM to describe the time-dependent, multi-subject brain\nnetworks. We develop a novel procedure for fitting the multilayer SBM that\nbuilds on multislice modularity maximization which can uncover a common\ncommunity partition of all layers (subjects) simultaneously. By augmenting with\na dynamic Markov switching process, our proposed method is able to capture a\nset of distinct, recurring temporal states with respect to inter-community\ninteractions over subjects and the change points between them. Simulation shows\naccurate community recovery and tracking of dynamic community regimes over\nmultilayer networks by the MSS-SBM. Application to task fMRI reveals meaningful\nnon-assortative brain community motifs, e.g., core-periphery structure at the\ngroup level, that are associated with language comprehension and motor\nfunctions suggesting their putative role in complex information integration.\nOur approach detected dynamic reconfiguration of modular connectivity elicited\nby varying task demands and identified unique profiles of intra and\ninter-community connectivity across different task conditions. The proposed\nmultilayer network representation provides a principled way of detecting\nsynchronous, dynamic modularity in brain networks across subjects.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 04:23:26 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 06:38:07 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 04:53:23 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 07:59:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ting", "Chee-Ming", ""], ["Samdin", "S. Balqis", ""], ["Tang", "Meini", ""], ["Ombao", "Hernando", ""]]}, {"id": "2004.04373", "submitter": "Onur Avci", "authors": "Onur Avci, Osama Abdeljaber, Serkan Kiranyaz, Mohammed Hussein, Moncef\n  Gabbouj, Daniel J. Inman", "title": "A Review of Vibration-Based Damage Detection in Civil Structures: From\n  Traditional Methods to Machine Learning and Deep Learning Applications", "comments": "51 pages, 45 figures, MSSP (Elsevier) submission", "journal-ref": null, "doi": "10.1016/j.ymssp.2020.107077", "report-no": null, "categories": "eess.SP cs.LG stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring structural damage is extremely important for sustaining and\npreserving the service life of civil structures. While successful monitoring\nprovides resolute and staunch information on the health, serviceability,\nintegrity and safety of structures; maintaining continuous performance of a\nstructure depends highly on monitoring the occurrence, formation and\npropagation of damage. Damage may accumulate on structures due to different\nenvironmental and human-induced factors. Numerous monitoring and detection\napproaches have been developed to provide practical means for early warning\nagainst structural damage or any type of anomaly. Considerable effort has been\nput into vibration-based methods, which utilize the vibration response of the\nmonitored structure to assess its condition and identify structural damage.\nMeanwhile, with emerging computing power and sensing technology in the last\ndecade, Machine Learning (ML) and especially Deep Learning (DL) algorithms have\nbecome more feasible and extensively used in vibration-based structural damage\ndetection with elegant performance and often with rigorous accuracy. While\nthere have been multiple review studies published on vibration-based structural\ndamage detection, there has not been a study where the transition from\ntraditional methods to ML and DL methods are described and discussed. This\npaper aims to fulfill this gap by presenting the highlights of the traditional\nmethods and provide a comprehensive review of the most recent applications of\nML and DL algorithms utilized for vibration-based structural damage detection\nin civil structures.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 05:39:21 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Avci", "Onur", ""], ["Abdeljaber", "Osama", ""], ["Kiranyaz", "Serkan", ""], ["Hussein", "Mohammed", ""], ["Gabbouj", "Moncef", ""], ["Inman", "Daniel J.", ""]]}, {"id": "2004.04386", "submitter": "Felix Dietrich", "authors": "Felix Dietrich, Or Yair, Rotem Mulayoff, Ronen Talmon, and Ioannis G.\n  Kevrekidis", "title": "Spectral Discovery of Jointly Smooth Features for Multimodal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a spectral method for deriving functions that are\njointly smooth on multiple observed manifolds. This allows us to register\nmeasurements of the same phenomenon by heterogeneous sensors, and to reject\nsensor-specific noise. Our method is unsupervised and primarily consists of two\nsteps. First, using kernels, we obtain a subspace spanning smooth functions on\neach separate manifold. Then, we apply a spectral method to the obtained\nsubspaces and discover functions that are jointly smooth on all manifolds. We\nshow analytically that our method is guaranteed to provide a set of orthogonal\nfunctions that are as jointly smooth as possible, ordered by increasing\nDirichlet energy from the smoothest to the least smooth. In addition, we show\nthat the extracted functions can be efficiently extended to unseen data using\nthe Nystr\\\"{o}m method. We demonstrate the proposed method on both simulated\nand real measured data and compare the results to nonlinear variants of the\nseminal Canonical Correlation Analysis (CCA). Particularly, we show superior\nresults for sleep stage identification. In addition, we show how the proposed\nmethod can be leveraged for finding minimal realizations of parameter spaces of\nnonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:04:02 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 16:24:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dietrich", "Felix", ""], ["Yair", "Or", ""], ["Mulayoff", "Rotem", ""], ["Talmon", "Ronen", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "2004.04391", "submitter": "Benjamin Smith", "authors": "Benjamin Smith, Kevin Cant, Gloria Wang", "title": "Anomaly Detection with SDAE", "comments": "9 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a prominent data preprocessing step in learning\napplications for correction and/or removal of faulty data. Automating this data\ntype with the use of autoencoders could increase the quality of the dataset by\nisolating anomalies that were missed through manual or basic statistical\nanalysis. A Simple, Deep, and Supervised Deep Autoencoder were trained and\ncompared for anomaly detection over the ASHRAE building energy dataset. Given\nthe restricted parameters under which the models were trained, the Deep\nAutoencoder perfoms the best, however, the Supervised Deep Autoencoder\noutperforms the other models in total anomalies detected when considerations\nfor the test datasets are given.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:22:08 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Smith", "Benjamin", ""], ["Cant", "Kevin", ""], ["Wang", "Gloria", ""]]}, {"id": "2004.04402", "submitter": "Quentin Duchemin", "authors": "Quentin Duchemin (LAMA)", "title": "Inference in the Stochastic Block Model with a Markovian assignment of\n  the communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the community detection problem in the Stochastic Block Model (SBM)\nwhen the communities of the nodes of the graph are assigned with a Markovian\ndynamic. To recover the partition of the nodes, we adapt the relaxed K-means\nSDP program presented in [11]. We identify the relevant signal-to-noise ratio\n(SNR) in our framework and we prove that the misclassification error decays\nexponentially fast with respect to this SNR. We provide infinity norm\nconsistent estimation of the parameters of our model and we discuss our results\nthrough the prism of classical degree regimes of the SBMs' literature. MSC 2010\nsubject classifications: Primary 68Q32; secondary 68R10, 90C35.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:58:02 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Duchemin", "Quentin", "", "LAMA"]]}, {"id": "2004.04454", "submitter": "Toshinari Morimoto", "authors": "Toshinari Morimoto, Su-Yun Huang", "title": "TensorProjection Layer: A Tensor-Based Dimensionality Reduction Method\n  in CNN", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dimensionality reduction method applied to\ntensor-structured data as a hidden layer (we call it TensorProjection Layer) in\na convolutional neural network. Our proposed method transforms input tensors\ninto ones with a smaller dimension by projection. The directions of projection\nare viewed as training parameters associated with our proposed layer and\ntrained via a supervised learning criterion such as minimization of the\ncross-entropy loss function. We discuss the gradients of the loss function with\nrespect to the parameters associated with our proposed layer. We also implement\nsimple numerical experiments to evaluate the performance of the\nTensorProjection Layer.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:52:49 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Morimoto", "Toshinari", ""], ["Huang", "Su-Yun", ""]]}, {"id": "2004.04464", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi and Yoshinobu Kawahara", "title": "On Anomaly Interpretation via Shapley Values", "comments": "23 pages, 5 figures and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly localization is an essential problem as anomaly detection is. Because\na rigorous localization requires a causal model of a target system, practically\nwe often resort to a relaxed problem of anomaly interpretation, for which we\nare to obtain meaningful attribution of anomaly scores to input features. In\nthis paper, we investigate the use of the Shapley value for anomaly\ninterpretation. We focus on the semi-supervised anomaly detection and newly\npropose a characteristic function, on which the Shapley value is computed,\nspecifically for anomaly scores. The idea of the proposed method is\napproximating the absence of some features by minimizing an anomaly score with\nregard to them. We examine the performance of the proposed method as well as\nother general approaches to computing the Shapley value in interpreting anomaly\nscores. We show the results of experiments on multiple datasets and anomaly\ndetection methods, which indicate the usefulness of the Shapley-based anomaly\ninterpretation toward anomaly localization.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:27:00 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2004.04480", "submitter": "Bruno Sudret", "authors": "S. Marelli, P.-R. Wagner, C. Lataniotis and B. Sudret", "title": "Stochastic spectral embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2020-003", "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing approximations that can accurately mimic the behavior of complex\nmodels at reduced computational costs is an important aspect of uncertainty\nquantification. Despite their flexibility and efficiency, classical surrogate\nmodels such as Kriging or polynomial chaos expansions tend to struggle with\nhighly non-linear, localized or non-stationary computational models. We hereby\npropose a novel sequential adaptive surrogate modeling method based on\nrecursively embedding locally spectral expansions. It is achieved by means of\ndisjoint recursive partitioning of the input domain, which consists in\nsequentially splitting the latter into smaller subdomains, and constructing a\nsimpler local spectral expansions in each, exploiting the trade-off complexity\nvs. locality. The resulting expansion, which we refer to as \"stochastic\nspectral embedding\" (SSE), is a piece-wise continuous approximation of the\nmodel response that shows promising approximation capabilities, and good\nscaling with both the problem dimension and the size of the training set. We\nfinally show how the method compares favorably against state-of-the-art sparse\npolynomial chaos expansions on a set of models with different complexity and\ninput dimension.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 11:00:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:02:44 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Marelli", "S.", ""], ["Wagner", "P. -R.", ""], ["Lataniotis", "C.", ""], ["Sudret", "B.", ""]]}, {"id": "2004.04520", "submitter": "Jun Li", "authors": "Jun Li, Hongfu Liu, Zhiqiang Tao, Handong Zhao, and Yun Fu", "title": "Learnable Subspace Clustering", "comments": "IEEE Transactions on Neural Networks and Learning Systems (accepted\n  with minor revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the large-scale subspace clustering (LSSC) problem with\nmillion data points. Many popular subspace clustering methods cannot directly\nhandle the LSSC problem although they have been considered as state-of-the-art\nmethods for small-scale data points. A basic reason is that these methods often\nchoose all data points as a big dictionary to build huge coding models, which\nresults in a high time and space complexity. In this paper, we develop a\nlearnable subspace clustering paradigm to efficiently solve the LSSC problem.\nThe key idea is to learn a parametric function to partition the\nhigh-dimensional subspaces into their underlying low-dimensional subspaces\ninstead of the expensive costs of the classical coding models. Moreover, we\npropose a unified robust predictive coding machine (RPCM) to learn the\nparametric function, which can be solved by an alternating minimization\nalgorithm. In addition, we provide a bounded contraction analysis of the\nparametric function. To the best of our knowledge, this paper is the first work\nto efficiently cluster millions of data points among the subspace clustering\nmethods. Experiments on million-scale datasets verify that our paradigm\noutperforms the related state-of-the-art methods in both efficiency and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 12:53:28 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Li", "Jun", ""], ["Liu", "Hongfu", ""], ["Tao", "Zhiqiang", ""], ["Zhao", "Handong", ""], ["Fu", "Yun", ""]]}, {"id": "2004.04523", "submitter": "P\\'adraig Cunningham", "authors": "Padraig Cunningham, Sarah Jane Delany", "title": "k-Nearest Neighbour Classifiers: 2nd Edition (with Python examples)", "comments": "22 pages, 15 figures: An updated edition of an older tutorial on kNN", "journal-ref": null, "doi": "10.1145/3459665", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps the most straightforward classifier in the arsenal or machine\nlearning techniques is the Nearest Neighbour Classifier -- classification is\nachieved by identifying the nearest neighbours to a query example and using\nthose neighbours to determine the class of the query. This approach to\nclassification is of particular importance because issues of poor run-time\nperformance is not such a problem these days with the computational power that\nis available. This paper presents an overview of techniques for Nearest\nNeighbour classification focusing on; mechanisms for assessing similarity\n(distance), computational issues in identifying nearest neighbours and\nmechanisms for reducing the dimension of the data.\n  This paper is the second edition of a paper previously published as a\ntechnical report. Sections on similarity measures for time-series, retrieval\nspeed-up and intrinsic dimensionality have been added. An Appendix is included\nproviding access to Python code for the key methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 13:00:05 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 11:07:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cunningham", "Padraig", ""], ["Delany", "Sarah Jane", ""]]}, {"id": "2004.04546", "submitter": "Laetitia Teodorescu", "authors": "Laetitia Teodorescu, Katja Hofmann, and Pierre-Yves Oudeyer", "title": "SpatialSim: Recognizing Spatial Configurations of Objects with Graph\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing precise geometrical configurations of groups of objects is a key\ncapability of human spatial cognition, yet little studied in the deep learning\nliterature so far. In particular, a fundamental problem is how a machine can\nlearn and compare classes of geometric spatial configurations that are\ninvariant to the point of view of an external observer. In this paper we make\ntwo key contributions. First, we propose SpatialSim (Spatial Similarity), a\nnovel geometrical reasoning benchmark, and argue that progress on this\nbenchmark would pave the way towards a general solution to address this\nchallenge in the real world. This benchmark is composed of two tasks:\nIdentification and Comparison, each one instantiated in increasing levels of\ndifficulty. Secondly, we study how relational inductive biases exhibited by\nfully-connected message-passing Graph Neural Networks (MPGNNs) are useful to\nsolve those tasks, and show their advantages over less relational baselines\nsuch as Deep Sets and unstructured models such as Multi-Layer Perceptrons.\nFinally, we highlight the current limits of GNNs in these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:13:20 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 18:16:31 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Teodorescu", "Laetitia", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2004.04552", "submitter": "Ga\\\"el Poux-M\\'edard", "authors": "Ga\\\"el Poux-M\\'edard, Julien Velcin, Sabine Loudcher", "title": "Interactions in information spread: quantification and interpretation\n  using stochastic block models", "comments": "17 pages, 3 figures, submitted to ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most real-world applications, it is seldom the case that a given\nobservable evolves independently of its environment. In social networks, users'\nbehavior results from the people they interact with, news in their feed, or\ntrending topics. In natural language, the meaning of phrases emerges from the\ncombination of words. In general medicine, a diagnosis is established on the\nbasis of the interaction of symptoms. Here, we propose a new model, the\nInteractive Mixed Membership Stochastic Block Model (IMMSBM), which\ninvestigates the role of interactions between entities (hashtags, words, memes,\netc.) and quantifies their importance within the aforementioned corpora. We\nfind that interactions play an important role in those corpora. In inference\ntasks, taking them into account leads to average relative changes with respect\nto non-interactive models of up to 150\\% in the probability of an outcome.\nFurthermore, their role greatly improves the predictive power of the model. Our\nfindings suggest that neglecting interactions when modeling real-world\nphenomena might lead to incorrect conclusions being drawn.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:22:10 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 16:33:48 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Poux-M\u00e9dard", "Ga\u00ebl", ""], ["Velcin", "Julien", ""], ["Loudcher", "Sabine", ""]]}, {"id": "2004.04565", "submitter": "Md Tahmid Rashid", "authors": "Md Tahmid Rashid, Dong Wang", "title": "CovidSens: A Vision on Reliable Social Sensing for COVID-19", "comments": "Artificial Intelligence Review (accepted for publication)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it\nhas becoming inherently important to disseminate accurate and timely\ninformation about the disease. Due to the ubiquity of Internet connectivity and\nsmart devices, social sensing is emerging as a dynamic AI-driven sensing\nparadigm to extract real-time observations from online users. In this paper, we\npropose CovidSens, a vision of social sensing based risk alert systems to\nspontaneously obtain and analyze social data to infer COVID-19 propagation.\nCovidSens can actively help to keep the general public informed about the\nCOVID-19 spread and identify risk-prone areas. The CovidSens concept is\nmotivated by three observations: 1) people actively share their experience of\nCOVID-19 via online social media, 2) official warning channels and news\nagencies are relatively slower than people reporting on social media, and 3)\nonline users are frequently equipped with powerful mobile devices that can\nperform data processing and analytics. We envision unprecedented opportunities\nto leverage posts generated by ordinary people to build real-time sensing and\nanalytic system for gathering and circulating COVID-19 propagation data.\nSpecifically, the vision of CovidSens attempts to answer the questions: How to\ndistill reliable information on COVID-19 with prevailing rumors and\nmisinformation? How to inform the general public about the state of the spread\ntimely and effectively? How to leverage the computational power on edge devices\nto construct fully integrated edge-based social sensing platforms? In this\nvision paper, we discuss the roles of CovidSens and identify potential\nchallenges in developing reliable social sensing based risk alert systems. We\nenvision that approaches originating from multiple disciplines can be effective\nin addressing the challenges. Finally, we outline a few research directions for\nfuture work in CovidSens.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:37:43 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 16:14:33 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 15:16:31 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Rashid", "Md Tahmid", ""], ["Wang", "Dong", ""]]}, {"id": "2004.04571", "submitter": "Anthony Constantinou", "authors": "Anthony Constantinou", "title": "Learning Bayesian Networks that enable full propagation of evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on recent developments in Bayesian network (BN) structure\nlearning under the controversial assumption that the input variables are\ndependent. This assumption can be viewed as a learning constraint geared\ntowards cases where the input variables are known or assumed to be dependent.\nIt addresses the problem of learning multiple disjoint subgraphs that do not\nenable full propagation of evidence. This problem is highly prevalent in cases\nwhere the sample size of the input data is low with respect to the\ndimensionality of the model, which is often the case when working with real\ndata. The paper presents a novel hybrid structure learning algorithm, called\nSaiyanH, that addresses this issue. The results show that this constraint helps\nthe algorithm to estimate the number of true edges with higher accuracy\ncompared to the state-of-the-art. Out of the 13 algorithms investigated, the\nresults rank SaiyanH 4th in reconstructing the true DAG, with accuracy scores\nlower by 8.1% (F1), 10.2% (BSF), and 19.5% (SHD) compared to the top ranked\nalgorithm, and higher by 75.5% (F1), 118% (BSF), and 4.3% (SHD) compared to the\nbottom ranked algorithm. Overall, the results suggest that the proposed\nalgorithm discovers satisfactorily accurate connected DAGs in cases where other\nalgorithms produce multiple disjoint subgraphs that often underfit the true\ngraph.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:44:11 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 14:16:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Constantinou", "Anthony", ""]]}, {"id": "2004.04573", "submitter": "Mark Crowley", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Backprojection for Training Feedforward Neural Networks in the Input and\n  Feature Spaces", "comments": "Accepted (to appear) in International Conference on Image Analysis\n  and Recognition (ICIAR) 2020, Springer", "journal-ref": "International Conference on Image Analysis and Recognition, vol 2,\n  pp. 16-24. Springer, Cham, 2020", "doi": "10.1007/978-3-030-50516-5_2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the tremendous development of neural networks trained by\nbackpropagation, it is a good time to develop other algorithms for training\nneural networks to gain more insights into networks. In this paper, we propose\na new algorithm for training feedforward neural networks which is fairly faster\nthan backpropagation. This method is based on projection and reconstruction\nwhere, at every layer, the projected data and reconstructed labels are forced\nto be similar and the weights are tuned accordingly layer by layer. The\nproposed algorithm can be used for both input and feature spaces, named as\nbackprojection and kernel backprojection, respectively. This algorithm gives an\ninsight to networks with a projection-based perspective. The experiments on\nsynthetic datasets show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 20:53:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.04593", "submitter": "Pawel Kalczynski", "authors": "Pawel Kalczynski, Jack Brimberg and Zvi Drezner", "title": "The Importance of Good Starting Solutions in the Minimum Sum of Squares\n  Clustering Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering problem has many applications in Machine Learning, Operations\nResearch, and Statistics. We propose three algorithms to create starting\nsolutions for improvement algorithms for this problem. We test the algorithms\non 72 instances that were investigated in the literature. Forty eight of them\nare relatively easy to solve and we found the best known solution many times\nfor all of them. Twenty four medium and large size instances are more\nchallenging. We found five new best known solutions and matched the best known\nsolution for 18 of the remaining 19 instances.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:13:41 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kalczynski", "Pawel", ""], ["Brimberg", "Jack", ""], ["Drezner", "Zvi", ""]]}, {"id": "2004.04597", "submitter": "Andres Abeliuk", "authors": "Nazgol Tavabi, Andr\\'es Abeliuk, Negar Mokhberian, Jeremy Abramson,\n  Kristina Lerman", "title": "Challenges in Forecasting Malicious Events from Incomplete Data", "comments": "Accepted in The Fifth Workshop on Computational Methods in Online\n  Misbehavior, Companion Proceedings of The 2020 World Wide Web Conference (WWW\n  '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately predict cyber-attacks would enable organizations to\nmitigate their growing threat and avert the financial losses and disruptions\nthey cause. But how predictable are cyber-attacks? Researchers have attempted\nto combine external data -- ranging from vulnerability disclosures to\ndiscussions on Twitter and the darkweb -- with machine learning algorithms to\nlearn indicators of impending cyber-attacks. However, successful cyber-attacks\nrepresent a tiny fraction of all attempted attacks: the vast majority are\nstopped, or filtered by the security appliances deployed at the target. As we\nshow in this paper, the process of filtering reduces the predictability of\ncyber-attacks. The small number of attacks that do penetrate the target's\ndefenses follow a different generative process compared to the whole data which\nis much harder to learn for predictive models. This could be caused by the fact\nthat the resulting time series also depends on the filtering process in\naddition to all the different factors that the original time series depended\non. We empirically quantify the loss of predictability due to filtering using\nreal-world data from two organizations. Our work identifies the limits to\nforecasting cyber-attacks from highly filtered data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:57:23 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Tavabi", "Nazgol", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Mokhberian", "Negar", ""], ["Abramson", "Jeremy", ""], ["Lerman", "Kristina", ""]]}, {"id": "2004.04618", "submitter": "You Li", "authors": "You Li, Xin Hu, Yuan Zhuang, Zhouzheng Gao, Peng Zhang, Naser\n  El-Sheimy", "title": "Deep Reinforcement Learning (DRL): Another Perspective for Unsupervised\n  Wireless Localization", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2019.2957778", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location is key to spatialize internet-of-things (IoT) data. However, it is\nchallenging to use low-cost IoT devices for robust unsupervised localization\n(i.e., localization without training data that have known location labels).\nThus, this paper proposes a deep reinforcement learning (DRL) based\nunsupervised wireless-localization method. The main contributions are as\nfollows. (1) This paper proposes an approach to model a continuous\nwireless-localization process as a Markov decision process (MDP) and process it\nwithin a DRL framework. (2) To alleviate the challenge of obtaining rewards\nwhen using unlabeled data (e.g., daily-life crowdsourced data), this paper\npresents a reward-setting mechanism, which extracts robust landmark data from\nunlabeled wireless received signal strengths (RSS). (3) To ease requirements\nfor model re-training when using DRL for localization, this paper uses RSS\nmeasurements together with agent location to construct DRL inputs. The proposed\nmethod was tested by using field testing data from multiple Bluetooth 5 smart\near tags in a pasture. Meanwhile, the experimental verification process\nreflected the advantages and challenges for using DRL in wireless localization.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:03:56 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Li", "You", ""], ["Hu", "Xin", ""], ["Zhuang", "Yuan", ""], ["Gao", "Zhouzheng", ""], ["Zhang", "Peng", ""], ["El-Sheimy", "Naser", ""]]}, {"id": "2004.04631", "submitter": "Di Gao", "authors": "Di Gao and Cheng Zhuo", "title": "Private Knowledge Transfer via Model Distillation with Generative\n  Adversarial Networks", "comments": "9 pages, 4 figures, ECAI 2020, the 24th European Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of deep learning applications has to address the growing\nprivacy concerns when using private and sensitive data for training. A\nconventional deep learning model is prone to privacy attacks that can recover\nthe sensitive information of individuals from either model parameters or\naccesses to the target model. Recently, differential privacy that offers\nprovable privacy guarantees has been proposed to train neural networks in a\nprivacy-preserving manner to protect training data. However, many approaches\ntend to provide the worst case privacy guarantees for model publishing,\ninevitably impairing the accuracy of the trained models. In this paper, we\npresent a novel private knowledge transfer strategy, where the private teacher\ntrained on sensitive data is not publicly accessible but teaches a student to\nbe publicly released. In particular, a three-player\n(teacher-student-discriminator) learning framework is proposed to achieve\ntrade-off between utility and privacy, where the student acquires the distilled\nknowledge from the teacher and is trained with the discriminator to generate\nsimilar outputs as the teacher. We then integrate a differential privacy\nprotection mechanism into the learning procedure, which enables a rigorous\nprivacy budget for the training. The framework eventually allows student to be\ntrained with only unlabelled public data and very few epochs, and hence\nprevents the exposure of sensitive training data, while ensuring model utility\nwith a modest privacy budget. The experiments on MNIST, SVHN and CIFAR-10\ndatasets show that our students obtain the accuracy losses w.r.t teachers of\n0.89%, 2.29%, 5.16%, respectively with the privacy bounds of (1.93, 10^-5),\n(5.02, 10^-6), (8.81, 10^-6). When compared with the existing works\n\\cite{papernot2016semi,wang2019private}, the proposed work can achieve 5-82%\naccuracy loss improvement.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:55:01 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Gao", "Di", ""], ["Zhuo", "Cheng", ""]]}, {"id": "2004.04632", "submitter": "Xueyu Zhu", "authors": "Andrew Pensoneault and Xiu Yang and Xueyu Zhu", "title": "Nonnegativity-Enforced Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process (GP) regression is a flexible non-parametric approach to\napproximate complex models. In many cases, these models correspond to processes\nwith bounded physical properties. Standard GP regression typically results in a\nproxy model which is unbounded for all temporal or spacial points, and thus\nleaves the possibility of taking on infeasible values. We propose an approach\nto enforce the physical constraints in a probabilistic way under the GP\nregression framework. In addition, this new approach reduces the variance in\nthe resulting GP model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:43:46 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Pensoneault", "Andrew", ""], ["Yang", "Xiu", ""], ["Zhu", "Xueyu", ""]]}, {"id": "2004.04635", "submitter": "Xin Xin", "authors": "Xin Xin, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M.Jose", "title": "Graph Highway Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Networks (GCN) are widely used in learning graph\nrepresentations due to their effectiveness and efficiency. However, they suffer\nfrom the notorious over-smoothing problem, in which the learned representations\nof densely connected nodes converge to alike vectors when many (>3) graph\nconvolutional layers are stacked. In this paper, we argue that\nthere-normalization trick used in GCN leads to overly homogeneous information\npropagation, which is the source of over-smoothing. To address this problem, we\npropose Graph Highway Networks(GHNet) which utilize gating units to\nautomatically balance the trade-off between homogeneity and heterogeneity in\nthe GCN learning process. The gating units serve as direct highways to maintain\nheterogeneous information from the node itself after feature propagation. This\ndesign enables GHNet to achieve much larger receptive fields per node without\nover-smoothing and thus access to more of the graph connectivity information.\nExperimental results on benchmark datasets demonstrate the superior performance\nof GHNet over GCN and related models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:26:43 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Xin", "Xin", ""], ["Karatzoglou", "Alexandros", ""], ["Arapakis", "Ioannis", ""], ["Jose", "Joemon M.", ""]]}, {"id": "2004.04645", "submitter": "Denis McInerney", "authors": "Denis Jered McInerney, Borna Dabiri, Anne-Sophie Touret, Geoffrey\n  Young, Jan-Willem van de Meent, Byron C. Wallace", "title": "Query-Focused EHR Summarization to Aid Imaging Diagnosis", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 126 (2020) 632-659", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHRs) provide vital contextual information to\nradiologists and other physicians when making a diagnosis. Unfortunately,\nbecause a given patient's record may contain hundreds of notes and reports,\nidentifying relevant information within these in the short time typically\nallotted to a case is very difficult. We propose and evaluate models that\nextract relevant text snippets from patient records to provide a rough case\nsummary intended to aid physicians considering one or more diagnoses. This is\nhard because direct supervision (i.e., physician annotations of snippets\nrelevant to specific diagnoses in medical records) is prohibitively expensive\nto collect at scale. We propose a distantly supervised strategy in which we use\ngroups of International Classification of Diseases (ICD) codes observed in\n'future' records as noisy proxies for 'downstream' diagnoses. Using this we\ntrain a transformer-based neural model to perform extractive summarization\nconditioned on potential diagnoses. This model defines an attention mechanism\nthat is conditioned on potential diagnoses (queries) provided by the diagnosing\nphysician. We train (via distant supervision) and evaluate variants of this\nmodel on EHR data from Brigham and Women's Hospital in Boston and MIMIC-III\n(the latter to facilitate reproducibility). Evaluations performed by\nradiologists demonstrate that these distantly supervised models yield better\nextractive summaries than do unsupervised approaches. Such models may aid\ndiagnosis by identifying sentences in past patient reports that are clinically\nrelevant to a potential diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:32:39 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 04:25:30 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["McInerney", "Denis Jered", ""], ["Dabiri", "Borna", ""], ["Touret", "Anne-Sophie", ""], ["Young", "Geoffrey", ""], ["van de Meent", "Jan-Willem", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2004.04650", "submitter": "Ilija Radosavovic", "authors": "Ilija Radosavovic, Xiaolong Wang, Lerrel Pinto, Jitendra Malik", "title": "State-Only Imitation Learning for Dexterous Manipulation", "comments": "Videos available at https://people.eecs.berkeley.edu/~ilija/soil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous manipulation has been a long-standing challenge in robotics.\nRecently, modern model-free RL has demonstrated impressive results on a number\nof problems. However, complex domains like dexterous manipulation remain a\nchallenge for RL due to the poor sample complexity. To address this, current\napproaches employ expert demonstrations in the form of state-action pairs,\nwhich are difficult to obtain for real-world settings such as learning from\nvideos. In this work, we move toward a more realistic setting and explore\nstate-only imitation learning. To tackle this setting, we train an inverse\ndynamics model and use it to predict actions for state-only demonstrations. The\ninverse dynamics model and the policy are trained jointly. Our method performs\non par with state-action approaches and considerably outperforms RL alone. By\nnot relying on expert actions, we are able to learn from demonstrations with\ndifferent dynamics, morphologies, and objects.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:57:20 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Radosavovic", "Ilija", ""], ["Wang", "Xiaolong", ""], ["Pinto", "Lerrel", ""], ["Malik", "Jitendra", ""]]}, {"id": "2004.04653", "submitter": "Quercus Hernandez Lain", "authors": "Quercus Hern\\'andez, Alberto Badias, David Gonzalez, Francisco\n  Chinesta, and Elias Cueto", "title": "Structure-preserving neural networks", "comments": "19 pages, 11 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109950", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method to learn physical systems from data that employs\nfeedforward neural networks and whose predictions comply with the first and\nsecond principles of thermodynamics. The method employs a minimum amount of\ndata by enforcing the metriplectic structure of dissipative Hamiltonian systems\nin the form of the so-called General Equation for the Non-Equilibrium\nReversible-Irreversible Coupling, GENERIC [M. Grmela and H.C Oettinger (1997).\nDynamics and thermodynamics of complex fluids. I. Development of a general\nformalism. Phys. Rev. E. 56 (6): 6620-6632]. The method does not need to\nenforce any kind of balance equation, and thus no previous knowledge on the\nnature of the system is needed. Conservation of energy and dissipation of\nentropy in the prediction of previously unseen situations arise as a natural\nby-product of the structure of the method. Examples of the performance of the\nmethod are shown that include conservative as well as dissipative systems,\ndiscrete as well as continuous ones.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:41:20 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 15:07:50 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Hern\u00e1ndez", "Quercus", ""], ["Badias", "Alberto", ""], ["Gonzalez", "David", ""], ["Chinesta", "Francisco", ""], ["Cueto", "Elias", ""]]}, {"id": "2004.04668", "submitter": "Neerav Karani", "authors": "Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu", "title": "Test-Time Adaptable Neural Networks for Robust Medical Image\n  Segmentation", "comments": "Published in Medical Image Analysis journal:\n  https://doi.org/10.1016/j.media.2020.101907", "journal-ref": "Medical Image Analysis, Volume 68, 2021, 101907, ISSN 1361-8415.\n  http://www.sciencedirect.com/science/article/pii/S1361841520302711", "doi": "10.1016/j.media.2020.101907", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) work very well for supervised learning\nproblems when the training dataset is representative of the variations expected\nto be encountered at test time. In medical image segmentation, this premise is\nviolated when there is a mismatch between training and test images in terms of\ntheir acquisition details, such as the scanner model or the protocol.\nRemarkable performance degradation of CNNs in this scenario is well documented\nin the literature. To address this problem, we design the segmentation CNN as a\nconcatenation of two sub-networks: a relatively shallow image normalization\nCNN, followed by a deep CNN that segments the normalized image. We train both\nthese sub-networks using a training dataset, consisting of annotated images\nfrom a particular scanner and protocol setting. Now, at test time, we adapt the\nimage normalization sub-network for \\emph{each test image}, guided by an\nimplicit prior on the predicted segmentation labels. We employ an independently\ntrained denoising autoencoder (DAE) in order to model such an implicit prior on\nplausible anatomical segmentation labels. We validate the proposed idea on\nmulti-center Magnetic Resonance imaging datasets of three anatomies: brain,\nheart and prostate. The proposed test-time adaptation consistently provides\nperformance improvement, demonstrating the promise and generality of the\napproach. Being agnostic to the architecture of the deep CNN, the second\nsub-network, the proposed design can be utilized with any segmentation network\nto increase robustness to variations in imaging scanners and protocols. Our\ncode is available at:\n\\url{https://github.com/neerakara/test-time-adaptable-neural-networks-for-domain-generalization}.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:57:27 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 11:01:39 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 12:07:31 GMT"}, {"version": "v4", "created": "Sat, 23 Jan 2021 16:14:08 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Karani", "Neerav", ""], ["Erdil", "Ertunc", ""], ["Chaitanya", "Krishna", ""], ["Konukoglu", "Ender", ""]]}, {"id": "2004.04674", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Milad Sikaroudi, Sobhan Shafiei, H.R. Tizhoosh,\n  Fakhri Karray, Mark Crowley", "title": "Fisher Discriminant Triplet and Contrastive Losses for Training Siamese\n  Networks", "comments": "Accepted (to appear) in International Joint Conference on Neural\n  Networks (IJCNN) 2020, IEEE, in IEEE World Congress on Computational\n  Intelligence (WCCI) 2020", "journal-ref": "International Joint Conference on Neural Networks (IJCNN), IEEE,\n  2020", "doi": "10.1109/IJCNN48605.2020.9206833", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Siamese neural network is a very powerful architecture for both feature\nextraction and metric learning. It usually consists of several networks that\nshare weights. The Siamese concept is topology-agnostic and can use any neural\nnetwork as its backbone. The two most popular loss functions for training these\nnetworks are the triplet and contrastive loss functions. In this paper, we\npropose two novel loss functions, named Fisher Discriminant Triplet (FDT) and\nFisher Discriminant Contrastive (FDC). The former uses anchor-neighbor-distant\ntriplets while the latter utilizes pairs of anchor-neighbor and anchor-distant\nsamples. The FDT and FDC loss functions are designed based on the statistical\nformulation of the Fisher Discriminant Analysis (FDA), which is a linear\nsubspace learning method. Our experiments on the MNIST and two challenging and\npublicly available histopathology datasets show the effectiveness of the\nproposed loss functions.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 09:27:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Sikaroudi", "Milad", ""], ["Shafiei", "Sobhan", ""], ["Tizhoosh", "H. R.", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.04676", "submitter": "David Enthoven", "authors": "David Enthoven and Zaid Al-Ars", "title": "An Overview of Federated Deep Learning Privacy Attacks and Defensive\n  Strategies", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased attention and legislation for data-privacy, collaborative\nmachine learning (ML) algorithms are being developed to ensure the protection\nof private data used for processing. Federated learning (FL) is the most\npopular of these methods, which provides privacy preservation by facilitating\ncollaborative training of a shared model without the need to exchange any\nprivate data with a centralized server. Rather, an abstraction of the data in\nthe form of a machine learning model update is sent. Recent studies showed that\nsuch model updates may still very well leak private information and thus more\nstructured risk assessment is needed. In this paper, we analyze existing\nvulnerabilities of FL and subsequently perform a literature review of the\npossible attack methods targetingFL privacy protection capabilities. These\nattack methods are then categorized by a basic taxonomy. Additionally, we\nprovide a literature study of the most recent defensive strategies and\nalgorithms for FL aimed to overcome these attacks. These defensive strategies\nare categorized by their respective underlying defence principle. The paper\nconcludes that the application of a single defensive strategy is not enough to\nprovide adequate protection to all available attack methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:41:45 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Enthoven", "David", ""], ["Al-Ars", "Zaid", ""]]}, {"id": "2004.04690", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Rongmei Lin, Zhen Liu, James M. Rehg, Liam Paull, Li\n  Xiong, Le Song, Adrian Weller", "title": "Orthogonal Over-Parameterized Training", "comments": "CVPR 2021 Oral (43 Pages, Substantial Update from v3, Typos Fixed\n  from v5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inductive bias of a neural network is largely determined by the\narchitecture and the training algorithm. To achieve good generalization, how to\neffectively train a neural network is of great importance. We propose a novel\northogonal over-parameterized training (OPT) framework that can provably\nminimize the hyperspherical energy which characterizes the diversity of neurons\non a hypersphere. By maintaining the minimum hyperspherical energy during\ntraining, OPT can greatly improve the empirical generalization. Specifically,\nOPT fixes the randomly initialized weights of the neurons and learns an\northogonal transformation that applies to these neurons. We consider multiple\nways to learn such an orthogonal transformation, including unrolling\northogonalization algorithms, applying orthogonal parameterization, and\ndesigning orthogonality-preserving gradient descent. For better scalability, we\npropose the stochastic OPT which performs orthogonal transformation\nstochastically for partial dimensions of neurons. Interestingly, OPT reveals\nthat learning a proper coordinate system for neurons is crucial to\ngeneralization. We provide some insights on why OPT yields better\ngeneralization. Extensive experiments validate the superiority of OPT over the\nstandard training.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:16:38 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:22:30 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 06:18:55 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 11:31:31 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 01:07:38 GMT"}, {"version": "v6", "created": "Sat, 5 Jun 2021 00:31:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Weiyang", ""], ["Lin", "Rongmei", ""], ["Liu", "Zhen", ""], ["Rehg", "James M.", ""], ["Paull", "Liam", ""], ["Xiong", "Li", ""], ["Song", "Le", ""], ["Weller", "Adrian", ""]]}, {"id": "2004.04704", "submitter": "Robert Tillman", "authors": "Robert E. Tillman, Vamsi K. Potluru, Jiahao Chen, Prashant Reddy,\n  Manuela Veloso", "title": "Heuristics for Link Prediction in Multiplex Networks", "comments": null, "journal-ref": "Proceedings of the 24th European Conference on Artificial\n  Intelligence (ECAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction, or the inference of future or missing connections between\nentities, is a well-studied problem in network analysis. A multitude of\nheuristics exist for link prediction in ordinary networks with a single type of\nconnection. However, link prediction in multiplex networks, or networks with\nmultiple types of connections, is not a well understood problem. We propose a\nnovel general framework and three families of heuristics for multiplex network\nlink prediction that are simple, interpretable, and take advantage of the rich\nconnection type correlation structure that exists in many real world networks.\nWe further derive a theoretical threshold for determining when to use a\ndifferent connection type based on the number of links that overlap with an\nErdos-Renyi random graph. Through experiments with simulated and real world\nscientific collaboration, transportation and global trade networks, we\ndemonstrate that the proposed heuristics show increased performance with the\nrichness of connection type correlation structure and significantly outperform\ntheir baseline heuristics for ordinary networks with a single connection type.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:36:18 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Tillman", "Robert E.", ""], ["Potluru", "Vamsi K.", ""], ["Chen", "Jiahao", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.04710", "submitter": "Besher Alhalabi", "authors": "Besher Alhalabi, Mohamed Gaber, Shadi Basurra", "title": "Prune2Edge: A Multi-Phase Pruning Pipelines to Deep Ensemble Learning in\n  IIoT", "comments": "a revised version is going to be submitted to a journal soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recently, with the proliferation of IoT devices, computational nodes in\nmanufacturing systems IIoT(Industrial-Internet-of-things) and the lunch of 5G\nnetworks, there will be millions of connected devices generating a massive\namount of data. In such an environment, the controlling systems need to be\nintelligent enough to deal with a vast amount of data to detect defects in a\nreal-time process. Driven by such a need, artificial intelligence models such\nas deep learning have to be deployed into IIoT systems. However, learning and\nusing deep learning models are computationally expensive, so an IoT device with\nlimited computational power could not run such models. To tackle this issue,\nedge intelligence had emerged as a new paradigm towards running Artificial\nIntelligence models on edge devices. Although a considerable amount of studies\nhave been proposed in this area, the research is still in the early stages. In\nthis paper, we propose a novel edge-based multi-phase pruning pipelines to\nensemble learning on IIoT devices. In the first phase, we generate a diverse\nensemble of pruned models, then we apply integer quantisation, next we prune\nthe generated ensemble using a clustering-based technique. Finally, we choose\nthe best representative from each generated cluster to be deployed to a\ndistributed IoT environment. On CIFAR-100 and CIFAR-10, our proposed approach\nwas able to outperform the predictability levels of a baseline model (up to\n7%), more importantly, the generated learners have small sizes (up to 90%\nreduction in the model size) that minimise the required computational\ncapabilities to make an inference on the resource-constraint devices.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:44:34 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 16:05:23 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Alhalabi", "Besher", ""], ["Gaber", "Mohamed", ""], ["Basurra", "Shadi", ""]]}, {"id": "2004.04715", "submitter": "Justin Khim", "authors": "Justin Khim, Ziyu Xu and Shashank Singh", "title": "Multiclass Classification via Class-Weighted Nearest Neighbors", "comments": "62 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical properties of the k-nearest neighbors algorithm for\nmulticlass classification, with a focus on settings where the number of classes\nmay be large and/or classes may be highly imbalanced. In particular, we\nconsider a variant of the k-nearest neighbor classifier with non-uniform\nclass-weightings, for which we derive upper and minimax lower bounds on\naccuracy, class-weighted risk, and uniform error. Additionally, we show that\nuniform error bounds lead to bounds on the difference between empirical\nconfusion matrix quantities and their population counterparts across a set of\nweights. As a result, we may adjust the class weights to optimize\nclassification metrics such as F1 score or Matthew's Correlation Coefficient\nthat are commonly used in practice, particularly in settings with imbalanced\nclasses. We additionally provide a simple example to instantiate our bounds and\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:50:16 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 00:40:57 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Khim", "Justin", ""], ["Xu", "Ziyu", ""], ["Singh", "Shashank", ""]]}, {"id": "2004.04717", "submitter": "Matthew Dixon", "authors": "Matthew F Dixon", "title": "Industrial Forecasting with Exponentially Smoothed Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series modeling has entered an era of unprecedented growth in the size\nand complexity of data which require new modeling approaches. While many new\ngeneral purpose machine learning approaches have emerged, they remain poorly\nunderstand and irreconcilable with more traditional statistical modeling\napproaches. We present a general class of exponential smoothed recurrent neural\nnetworks (RNNs) which are well suited to modeling non-stationary dynamical\nsystems arising in industrial applications. In particular, we analyze their\ncapacity to characterize the non-linear partial autocorrelation structure of\ntime series and directly capture dynamic effects such as seasonality and\ntrends. Application of exponentially smoothed RNNs to forecasting electricity\nload, weather data, and stock prices highlight the efficacy of exponential\nsmoothing of the hidden state for multi-step time series forecasting. The\nresults also suggest that popular, but more complicated neural network\narchitectures originally designed for speech processing, such as LSTMs and\nGRUs, are likely over-engineered for industrial forecasting and light-weight\nexponentially smoothed architectures, trained in a fraction of the time,\ncapture the salient features while being superior and more robust than simple\nRNNs and ARIMA models. Additionally uncertainty quantification of the\nexponential smoothed recurrent neural networks, provided by Bayesian\nestimation, is shown to provide improved coverage.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:53:49 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 16:54:40 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Dixon", "Matthew F", ""]]}, {"id": "2004.04719", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Chris Junchi Li, Martin J. Wainwright, Peter L. Bartlett,\n  Michael I. Jordan", "title": "On Linear Stochastic Approximation: Fine-grained Polyak-Ruppert and\n  Non-Asymptotic Concentration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertake a precise study of the asymptotic and non-asymptotic properties\nof stochastic approximation procedures with Polyak-Ruppert averaging for\nsolving a linear system $\\bar{A} \\theta = \\bar{b}$. When the matrix $\\bar{A}$\nis Hurwitz, we prove a central limit theorem (CLT) for the averaged iterates\nwith fixed step size and number of iterations going to infinity. The CLT\ncharacterizes the exact asymptotic covariance matrix, which is the sum of the\nclassical Polyak-Ruppert covariance and a correction term that scales with the\nstep size. Under assumptions on the tail of the noise distribution, we prove a\nnon-asymptotic concentration inequality whose main term matches the covariance\nin CLT in any direction, up to universal constants. When the matrix $\\bar{A}$\nis not Hurwitz but only has non-negative real parts in its eigenvalues, we\nprove that the averaged LSA procedure actually achieves an $O(1/T)$ rate in\nmean-squared error. Our results provide a more refined understanding of linear\nstochastic approximation in both the asymptotic and non-asymptotic settings. We\nalso show various applications of the main results, including the study of\nmomentum-based stochastic gradient methods as well as temporal difference\nalgorithms in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:54:18 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Mou", "Wenlong", ""], ["Li", "Chris Junchi", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2004.04729", "submitter": "Temesgen Mehari", "authors": "Simon Wiedemann, Temesgen Mehari, Kevin Kepp, Wojciech Samek", "title": "Dithered backprop: A sparse and quantized backpropagation algorithm for\n  more efficient deep neural network training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are successful but highly computationally expensive\nlearning systems. One of the main sources of time and energy drains is the well\nknown backpropagation (backprop) algorithm, which roughly accounts for 2/3 of\nthe computational complexity of training. In this work we propose a method for\nreducing the computational cost of backprop, which we named dithered backprop.\nIt consists in applying a stochastic quantization scheme to intermediate\nresults of the method. The particular quantisation scheme, called\nnon-subtractive dither (NSD), induces sparsity which can be exploited by\ncomputing efficient sparse matrix multiplications. Experiments on popular image\nclassification tasks show that it induces 92% sparsity on average across a wide\nset of models at no or negligible accuracy drop in comparison to\nstate-of-the-art approaches, thus significantly reducing the computational\ncomplexity of the backward pass. Moreover, we show that our method is fully\ncompatible to state-of-the-art training methods that reduce the bit-precision\nof training down to 8-bits, as such being able to further reduce the\ncomputational requirements. Finally we discuss and show potential benefits of\napplying dithered backprop in a distributed training setting, where both\ncommunication as well as compute efficiency may increase simultaneously with\nthe number of participant nodes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:59:26 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 16:59:09 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Wiedemann", "Simon", ""], ["Mehari", "Temesgen", ""], ["Kepp", "Kevin", ""], ["Samek", "Wojciech", ""]]}, {"id": "2004.04767", "submitter": "Hai Tran-Bach", "authors": "Tengyuan Liang and Hai Tran-Bach", "title": "Mehler's Formula, Branching Process, and Compositional Kernels of Deep\n  Neural Networks", "comments": null, "journal-ref": "Journal of the American Statistical Association (2020)", "doi": "10.1080/01621459.2020.1853547", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize a connection between compositional kernels and branching processes\nvia Mehler's formula to study deep neural networks. This new probabilistic\ninsight provides us a novel perspective on the mathematical role of activation\nfunctions in compositional neural networks. We study the unscaled and rescaled\nlimits of the compositional kernels and explore the different phases of the\nlimiting behavior, as the compositional depth increases. We investigate the\nmemorization capacity of the compositional kernels and neural networks by\ncharacterizing the interplay among compositional depth, sample size,\ndimensionality, and non-linearity of the activation. Explicit formulas on the\neigenvalues of the compositional kernel are provided, which quantify the\ncomplexity of the corresponding reproducing kernel Hilbert space. On the\nmethodological front, we propose a new random features algorithm, which\ncompresses the compositional layers by devising a new activation function.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 18:46:13 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 17:29:34 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Liang", "Tengyuan", ""], ["Tran-Bach", "Hai", ""]]}, {"id": "2004.04795", "submitter": "Sajad Norouzi", "authors": "Sajad Norouzi, David J. Fleet, Mohammad Norouzi", "title": "Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and\n  Data Augmentation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Exemplar VAEs, a family of generative models that bridge the gap\nbetween parametric and non-parametric, exemplar based generative models.\nExemplar VAE is a variant of VAE with a non-parametric prior in the latent\nspace based on a Parzen window estimator. To sample from it, one first draws a\nrandom exemplar from a training set, then stochastically transforms that\nexemplar into a latent code and a new observation. We propose retrieval\naugmented training (RAT) as a way to speed up Exemplar VAE training by using\napproximate nearest neighbor search in the latent space to define a lower bound\non log marginal likelihood. To enhance generalization, model parameters are\nlearned using exemplar leave-one-out and subsampling. Experiments demonstrate\nthe effectiveness of Exemplar VAEs on density estimation and representation\nlearning. Importantly, generative data augmentation using Exemplar VAEs on\npermutation invariant MNIST and Fashion MNIST reduces classification error from\n1.17% to 0.69% and from 8.56% to 8.16%.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 20:21:45 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 21:06:22 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 18:51:11 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Norouzi", "Sajad", ""], ["Fleet", "David J.", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2004.04816", "submitter": "Guanhua Zhang", "authors": "Bing Bai, Guanhua Zhang, Ye Lin, Hao Li, Kun Bai, Bo Luo", "title": "CSRN: Collaborative Sequential Recommendation Networks for News\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, news apps have taken over the popularity of paper-based media,\nproviding a great opportunity for personalization. Recurrent Neural Network\n(RNN)-based sequential recommendation is a popular approach that utilizes\nusers' recent browsing history to predict future items. This approach is\nlimited that it does not consider the societal influences of news consumption,\ni.e., users may follow popular topics that are constantly changing, while\ncertain hot topics might be spreading only among specific groups of people.\nSuch societal impact is difficult to predict given only users' own reading\nhistories. On the other hand, the traditional User-based Collaborative\nFiltering (UserCF) makes recommendations based on the interests of the\n\"neighbors\", which provides the possibility to supplement the weaknesses of\nRNN-based methods. However, conventional UserCF only uses a single similarity\nmetric to model the relationships between users, which is too coarse-grained\nand thus limits the performance. In this paper, we propose a framework of deep\nneural networks to integrate the RNN-based sequential recommendations and the\nkey ideas from UserCF, to develop Collaborative Sequential Recommendation\nNetworks (CSRNs). Firstly, we build a directed co-reading network of users, to\ncapture the fine-grained topic-specific similarities between users in a vector\nspace. Then, the CSRN model encodes users with RNNs, and learns to attend to\nneighbors and summarize what news they are reading at the moment. Finally, news\narticles are recommended according to both the user's own state and the\nsummarized state of the neighbors. Experiments on two public datasets show that\nthe proposed model outperforms the state-of-the-art approaches significantly.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:25:21 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bai", "Bing", ""], ["Zhang", "Guanhua", ""], ["Lin", "Ye", ""], ["Li", "Hao", ""], ["Bai", "Kun", ""], ["Luo", "Bo", ""]]}, {"id": "2004.04843", "submitter": "Sujay Bhatt", "authors": "Sujay Bhatt, Alec Koppel, Vikram Krishnamurthy", "title": "Policy Gradient using Weak Derivatives for Reinforcement Learning", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers policy search in continuous state-action reinforcement\nlearning problems. Typically, one computes search directions using a classic\nexpression for the policy gradient called the Policy Gradient Theorem, which\ndecomposes the gradient of the value function into two factors: the score\nfunction and the Q-function. This paper presents four results:(i) an\nalternative policy gradient theorem using weak (measure-valued) derivatives\ninstead of score-function is established; (ii) the stochastic gradient\nestimates thus derived are shown to be unbiased and to yield algorithms that\nconverge almost surely to stationary points of the non-convex value function of\nthe reinforcement learning problem; (iii) the sample complexity of the\nalgorithm is derived and is shown to be $O(1/\\sqrt(k))$; (iv) finally, the\nexpected variance of the gradient estimates obtained using weak derivatives is\nshown to be lower than those obtained using the popular score-function\napproach. Experiments on OpenAI gym pendulum environment show superior\nperformance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:05:18 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bhatt", "Sujay", ""], ["Koppel", "Alec", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "2004.04866", "submitter": "Mart\\'in Palazzo", "authors": "Martin Palazzo, Patricio Yankilevich, Pierre Beauseroy", "title": "Latent regularization for feature selection using kernel methods in\n  tumor classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transcriptomics of cancer tumors are characterized with tens of thousands\nof gene expression features. Patient prognosis or tumor stage can be assessed\nby machine learning techniques like supervised classification tasks given a\ngene expression profile. Feature selection is a useful approach to select the\nkey genes which helps to classify tumors. In this work we propose a feature\nselection method based on Multiple Kernel Learning that results in a reduced\nsubset of genes and a custom kernel that improves the classification\nperformance when used in support vector classification. During the feature\nselection process this method performs a novel latent regularisation by\nrelaxing the supervised target problem by introducing unsupervised structure\nobtained from the latent space learned by a non linear dimensionality reduction\nmodel. An improvement of the generalization capacity is obtained and assessed\nby the tumor classification performance on new unseen test samples when the\nclassifier is trained with the features selected by the proposed method in\ncomparison with other supervised feature selection approaches.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 00:46:02 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Palazzo", "Martin", ""], ["Yankilevich", "Patricio", ""], ["Beauseroy", "Pierre", ""]]}, {"id": "2004.04894", "submitter": "Zhanhong Zhou", "authors": "Zhanhong Zhou, Xiaolong Zhai, Chung Tin", "title": "Fully Automatic Electrocardiogram Classification System based on\n  Generative Adversarial Network with Auxiliary Classifier", "comments": "Accepted for publication in Expert Systems with Applications", "journal-ref": "Expert Systems with Applications, Volume 174, 2021, 114809, ISSN\n  0957-4174", "doi": "10.1016/j.eswa.2021.114809", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A generative adversarial network (GAN) based fully automatic\nelectrocardiogram (ECG) arrhythmia classification system with high performance\nis presented in this paper. The generator (G) in our GAN is designed to\ngenerate various coupling matrix inputs conditioned on different arrhythmia\nclasses for data augmentation. Our designed discriminator (D) is trained on\nboth real and generated ECG coupling matrix inputs, and is extracted as an\narrhythmia classifier upon completion of training for our GAN. After\nfine-tuning the D by including patient-specific normal beats estimated using an\nunsupervised algorithm, and generated abnormal beats by G that are usually rare\nto obtain, our fully automatic system showed superior overall classification\nperformance for both supraventricular ectopic beats (SVEB or S beats) and\nventricular ectopic beats (VEB or V beats) on the MIT-BIH arrhythmia database.\nIt surpassed several state-of-art automatic classifiers and can perform on\nsimilar levels as some expert-assisted methods. In particular, the F1 score of\nSVEB has been improved by up to 13% over the top-performing automatic systems.\nMoreover, high sensitivity for both SVEB (87%) and VEB (93%) detection has been\nachieved, which is of great value for practical diagnosis. We, therefore,\nsuggest our ACE-GAN (Generative Adversarial Network with Auxiliary Classifier\nfor Electrocardiogram) based automatic system can be a promising and reliable\ntool for high throughput clinical screening practice, without any need of\nmanual intervene or expert assisted labeling.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 03:33:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:08:11 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 06:09:24 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhou", "Zhanhong", ""], ["Zhai", "Xiaolong", ""], ["Tin", "Chung", ""]]}, {"id": "2004.04898", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Liang Li, Wenjing Fang, Jun Zhou, Li Wang, Lei Wang,\n  Shuang Yang, Alex Liu, and Hao Wang", "title": "Secret Sharing based Secure Regressions with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the utilization of the ever expanding amount of data has made a\nhuge impact on web technologies while also causing various types of security\nconcerns. On one hand, potential gains are highly anticipated if different\norganizations could somehow collaboratively share their data for technological\nimprovements. On the other hand, data security concerns may arise for both data\nholders and data providers due to commercial or sociological concerns. To make\na balance between technical improvements and security limitations, we implement\nsecure and scalable protocols for multiple data holders to train linear\nregression and logistic regression models. We build our protocols based on the\nsecret sharing scheme, which is scalable and efficient in applications.\nMoreover, our proposed paradigm can be generalized to any secure multiparty\ntraining scenarios where only matrix summation and matrix multiplications are\nused. We demonstrate our approach by experiments which shows the scalability\nand efficiency of our proposed protocols, and finally present its real-world\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 04:04:06 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chen", "Chaochao", ""], ["Li", "Liang", ""], ["Fang", "Wenjing", ""], ["Zhou", "Jun", ""], ["Wang", "Li", ""], ["Wang", "Lei", ""], ["Yang", "Shuang", ""], ["Liu", "Alex", ""], ["Wang", "Hao", ""]]}, {"id": "2004.04919", "submitter": "R\\'emi Bernhard", "authors": "R\\'emi Bernhard, Pierre-Alain Moellic, Jean-Max Dutertre", "title": "Luring of transferable adversarial perturbations in the black-box\n  paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest for adversarial examples, i.e. maliciously modified\nexamples which fool a classifier, has resulted in many defenses intended to\ndetect them, render them inoffensive or make the model more robust against\nthem. In this paper, we pave the way towards a new approach to improve the\nrobustness of a model against black-box transfer attacks. A removable\nadditional neural network is included in the target model, and is designed to\ninduce the \\textit{luring effect}, which tricks the adversary into choosing\nfalse directions to fool the target model. Training the additional model is\nachieved thanks to a loss function acting on the logits sequence order. Our\ndeception-based method only needs to have access to the predictions of the\ntarget model and does not require a labeled data set. We explain the luring\neffect thanks to the notion of robust and non-robust useful features and\nperform experiments on MNIST, SVHN and CIFAR10 to characterize and evaluate\nthis phenomenon. Additionally, we discuss two simple prediction schemes, and\nverify experimentally that our approach can be used as a defense to efficiently\nthwart an adversary using state-of-the-art attacks and allowed to perform large\nperturbations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 06:48:36 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 08:46:39 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 15:52:41 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Bernhard", "R\u00e9mi", ""], ["Moellic", "Pierre-Alain", ""], ["Dutertre", "Jean-Max", ""]]}, {"id": "2004.04926", "submitter": "TImothee Lacroix", "authors": "Timoth\\'ee Lacroix, Guillaume Obozinski and Nicolas Usunier", "title": "Tensor Decompositions for temporal knowledge base completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms for representation learning and link prediction in relational\ndata have been designed for static data. However, the data they are applied to\nusually evolves with time, such as friend graphs in social networks or user\ninteractions with items in recommender systems. This is also the case for\nknowledge bases, which contain facts such as (US, has president, B. Obama,\n[2009-2017]) that are valid only at certain points in time. For the problem of\nlink prediction under temporal constraints, i.e., answering queries such as\n(US, has president, ?, 2012), we propose a solution inspired by the canonical\ndecomposition of tensors of order 4. We introduce new regularization schemes\nand present an extension of ComplEx (Trouillon et al., 2016) that achieves\nstate-of-the-art performance. Additionally, we propose a new dataset for\nknowledge base completion constructed from Wikidata, larger than previous\nbenchmarks by an order of magnitude, as a new reference for evaluating temporal\nand non-temporal link prediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 07:09:30 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Lacroix", "Timoth\u00e9e", ""], ["Obozinski", "Guillaume", ""], ["Usunier", "Nicolas", ""]]}, {"id": "2004.04931", "submitter": "Asif Iqbal Khan", "authors": "Asif Iqbal Khan, Junaid Latief Shah, Mudasir Bhat", "title": "CoroNet: A deep neural network for detection and diagnosis of COVID-19\n  from chest x-ray images", "comments": "9 pages, 8 Figures and 8 Tables", "journal-ref": "Computer Methods and Programs in Biomedicine 196C (2020) 105581", "doi": "10.1016/j.cmpb.2020.105581", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Objective\n  The novel Coronavirus also called COVID-19 originated in Wuhan, China in\nDecember 2019 and has now spread across the world. It has so far infected\naround 1.8 million people and claimed approximately 114,698 lives overall. As\nthe number of cases are rapidly increasing, most of the countries are facing\nshortage of testing kits and resources. The limited quantity of testing kits\nand increasing number of daily cases encouraged us to come up with a Deep\nLearning model that can aid radiologists and clinicians in detecting COVID-19\ncases using chest X-rays.\n  Methods\n  In this study, we propose CoroNet, a Deep Convolutional Neural Network model\nto automatically detect COVID-19 infection from chest X-ray images. The\nproposed model is based on Xception architecture pre-trained on ImageNet\ndataset and trained end-to-end on a dataset prepared by collecting COVID-19 and\nother chest pneumonia X-ray images from two different publically available\ndatabases.\n  Results and Conclusion\n  CoroNet has been trained and tested on the prepared dataset and the\nexperimental results show that our proposed model achieved an overall accuracy\nof 89.6%, and more importantly the precision and recall rate for COVID-19 cases\nare 93% and 98.2% for 4-class cases (COVID vs Pneumonia bacterial vs pneumonia\nviral vs normal). For 3-class classification (COVID vs Pneumonia vs normal),\nthe proposed model produced a classification accuracy of 95%. The preliminary\nresults of this study look promising which can be further improved as more\ntraining data becomes available. Overall, the proposed model substantially\nadvances the current radiology based methodology and during COVID-19 pandemic,\nit can be very helpful tool for clinical practitioners and radiologists to aid\nthem in diagnosis, quantification and follow-up of COVID-19 cases.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 07:46:07 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 13:48:04 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 07:04:19 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Khan", "Asif Iqbal", ""], ["Shah", "Junaid Latief", ""], ["Bhat", "Mudasir", ""]]}, {"id": "2004.04946", "submitter": "Yuying Liu", "authors": "Yuying Liu, Colin Ponce, Steven L. Brunton, J. Nathan Kutz", "title": "Multiresolution Convolutional Autoencoders", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-resolution convolutional autoencoder (MrCAE) architecture\nthat integrates and leverages three highly successful mathematical\narchitectures: (i) multigrid methods, (ii) convolutional autoencoders and (iii)\ntransfer learning. The method provides an adaptive, hierarchical architecture\nthat capitalizes on a progressive training approach for multiscale\nspatio-temporal data. This framework allows for inputs across multiple scales:\nstarting from a compact (small number of weights) network architecture and\nlow-resolution data, our network progressively deepens and widens itself in a\nprincipled manner to encode new information in the higher resolution data based\non its current performance of reconstruction. Basic transfer learning\ntechniques are applied to ensure information learned from previous training\nsteps can be rapidly transferred to the larger network. As a result, the\nnetwork can dynamically capture different scaled features at different depths\nof the network. The performance gains of this adaptive multiscale architecture\nare illustrated through a sequence of numerical experiments on synthetic\nexamples and real-world spatial-temporal data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 08:31:59 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Liu", "Yuying", ""], ["Ponce", "Colin", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2004.04986", "submitter": "Amit Portnoy", "authors": "Amit Portnoy, Yoav Tirosh, and Danny Hendler", "title": "Towards Federated Learning With Byzantine-Robust Client Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated Learning (FL) is a distributed machine learning paradigm where data\nis distributed among clients who collaboratively train a model in a computation\nprocess coordinated by a central server. By assigning a weight to each client\nbased on the proportion of data instances it possesses, the rate of convergence\nto an accurate joint model can be greatly accelerated. Some previous works\nstudied FL in a Byzantine setting, in which a fraction of the clients may send\narbitrary or even malicious information regarding their model. However, these\nworks either ignore the issue of data unbalancedness altogether or assume that\nclient weights are apriori known to the server, whereas, in practice, it is\nlikely that weights will be reported to the server by the clients themselves\nand therefore cannot be relied upon. We address this issue for the first time\nby proposing a practical weight-truncation-based preprocessing method and\ndemonstrating empirically that it is able to strike a good balance between\nmodel quality and Byzantine robustness. We also establish analytically that our\nmethod can be applied to a randomly selected sample of client weights.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:59:16 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 08:10:10 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Portnoy", "Amit", ""], ["Tirosh", "Yoav", ""], ["Hendler", "Danny", ""]]}, {"id": "2004.05005", "submitter": "Eirini Anthi", "authors": "Eirini Anthi, Lowri Williams, Matilda Rhode, Pete Burnap, Adam\n  Wedgbury", "title": "Adversarial Attacks on Machine Learning Cybersecurity Defences in\n  Industrial Control Systems", "comments": "9 pages. 7 figures. 7 tables. 46 references. Submitted to a special\n  issue Journal of Information Security and Applications, Machine Learning\n  Techniques for Cyber Security: Challenges and Future Trends, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation and application of machine learning based Intrusion\nDetection Systems (IDS) have allowed for more flexibility and efficiency in the\nautomated detection of cyber attacks in Industrial Control Systems (ICS).\nHowever, the introduction of such IDSs has also created an additional attack\nvector; the learning models may also be subject to cyber attacks, otherwise\nreferred to as Adversarial Machine Learning (AML). Such attacks may have severe\nconsequences in ICS systems, as adversaries could potentially bypass the IDS.\nThis could lead to delayed attack detection which may result in infrastructure\ndamages, financial loss, and even loss of life. This paper explores how\nadversarial learning can be used to target supervised models by generating\nadversarial samples using the Jacobian-based Saliency Map attack and exploring\nclassification behaviours. The analysis also includes the exploration of how\nsuch samples can support the robustness of supervised models using adversarial\ntraining. An authentic power system dataset was used to support the experiments\npresented herein. Overall, the classification performance of two widely used\nclassifiers, Random Forest and J48, decreased by 16 and 20 percentage points\nwhen adversarial samples were present. Their performances improved following\nadversarial training, demonstrating their robustness towards such attacks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:05:33 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Anthi", "Eirini", ""], ["Williams", "Lowri", ""], ["Rhode", "Matilda", ""], ["Burnap", "Pete", ""], ["Wedgbury", "Adam", ""]]}, {"id": "2004.05007", "submitter": "Yo Joong Choe", "authors": "Yo Joong Choe, Jiyeon Ham, Kyubyong Park", "title": "An Empirical Study of Invariant Risk Minimization", "comments": "Presented at the ICML 2020 Workshop on Uncertainty and Robustness in\n  Deep Learning. Code at https://github.com/kakaobrain/irm-empirical-study", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Invariant risk minimization (IRM) (Arjovsky et al., 2019) is a recently\nproposed framework designed for learning predictors that are invariant to\nspurious correlations across different training environments. Yet, despite its\ntheoretical justifications, IRM has not been extensively tested across various\nsettings. In an attempt to gain a better understanding of the framework, we\nempirically investigate several research questions using IRMv1, which is the\nfirst practical algorithm proposed to approximately solve IRM. By extending the\nColoredMNIST experiment in different ways, we find that IRMv1 (i) performs\nbetter as the spurious correlation varies more widely between training\nenvironments, (ii) learns an approximately invariant predictor when the\nunderlying relationship is approximately invariant, and (iii) can be extended\nto an analogous setting for text classification.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:23:29 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 09:10:51 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Choe", "Yo Joong", ""], ["Ham", "Jiyeon", ""], ["Park", "Kyubyong", ""]]}, {"id": "2004.05013", "submitter": "Celine Beji", "authors": "C\\'eline Beji, Micha\\\"el Bon, Florian Yger, Jamal Atif", "title": "Estimating Individual Treatment Effects through Causal Populations\n  Identification", "comments": "Accepted (to appear) in ESANN 2020 proceedings, European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning.\n  Bruges (Belgium), 2-4 October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the Individual Treatment Effect from observational data, defined\nas the difference between outcomes with and without treatment or intervention,\nwhile observing just one of both, is a challenging problems in causal learning.\nIn this paper, we formulate this problem as an inference from hidden variables\nand enforce causal constraints based on a model of four exclusive causal\npopulations. We propose a new version of the EM algorithm, coined as\nExpected-Causality-Maximization (ECM) algorithm and provide hints on its\nconvergence under mild conditions. We compare our algorithm to baseline methods\non synthetic and real-world data and discuss its performances.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:51:19 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 12:59:34 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 11:12:37 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Beji", "C\u00e9line", ""], ["Bon", "Micha\u00ebl", ""], ["Yger", "Florian", ""], ["Atif", "Jamal", ""]]}, {"id": "2004.05041", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda and Kiran Rama", "title": "A Modified Bayesian Optimization based Hyper-Parameter Tuning Approach\n  for Extreme Gradient Boosting", "comments": "Pre-review version of the paper submitted to IEEE 2019 Fifteenth\n  International Conference on Information Processing (ICINPRO). The paper is\n  accepted for publication", "journal-ref": null, "doi": "10.1109/ICInPro47689.2019.9092025", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is already reported in the literature that the performance of a machine\nlearning algorithm is greatly impacted by performing proper Hyper-Parameter\noptimization. One of the ways to perform Hyper-Parameter optimization is by\nmanual search but that is time consuming. Some of the common approaches for\nperforming Hyper-Parameter optimization are Grid search Random search and\nBayesian optimization using Hyperopt. In this paper, we propose a brand new\napproach for hyperparameter improvement i.e. Randomized-Hyperopt and then tune\nthe hyperparameters of the XGBoost i.e. the Extreme Gradient Boosting algorithm\non ten datasets by applying Random search, Randomized-Hyperopt, Hyperopt and\nGrid Search. The performances of each of these four techniques were compared by\ntaking both the prediction accuracy and the execution time into consideration.\nWe find that the Randomized-Hyperopt performs better than the other three\nconventional methods for hyper-paramter optimization of XGBoost.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 14:09:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Putatunda", "Sayan", ""], ["Rama", "Kiran", ""]]}, {"id": "2004.05062", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "Joint Learning of Probabilistic and Geometric Shaping for Coded\n  Modulation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a trainable coded modulation scheme that enables joint\noptimization of the bit-wise mutual information (BMI) through probabilistic\nshaping, geometric shaping, bit labeling, and demapping for a specific channel\nmodel and for a wide range of signal-to-noise ratios (SNRs). Compared to\nprobabilistic amplitude shaping (PAS), the proposed approach is not restricted\nto symmetric probability distributions, can be optimized for any channel model,\nand works with any code rate $k/m$, $m$ being the number of bits per channel\nuse and $k$ an integer within the range from $1$ to $m-1$. The proposed scheme\nenables learning of a continuum of constellation geometries and probability\ndistributions determined by the SNR. Additionally, the PAS architecture with\nMaxwell-Boltzmann (MB) as shaping distribution was extended with a neural\nnetwork (NN) that controls the MB shaping of a quadrature amplitude modulation\n(QAM) constellation according to the SNR, enabling learning of a continuum of\nMB distributions for QAM. Simulations were performed to benchmark the\nperformance of the proposed joint probabilistic and geometric shaping scheme on\nadditive white Gaussian noise (AWGN) and mismatched Rayleigh block fading (RBF)\nchannels.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 14:56:32 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 14:16:26 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "2004.05089", "submitter": "Navid Khoshavi", "authors": "Navid Khoshavi, Saman Sargolzaei, Arman Roohi, Connor Broyles, Yu Bi", "title": "Entropy-Based Modeling for Estimating Soft Errors Impact on Binarized\n  Neural Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over past years, the easy accessibility to the large scale datasets has\nsignificantly shifted the paradigm for developing highly accurate prediction\nmodels that are driven from Neural Network (NN). These models can be\npotentially impacted by the radiation-induced transient faults that might lead\nto the gradual downgrade of the long-running expected NN inference accelerator.\nThe crucial observation from our rigorous vulnerability assessment on the NN\ninference accelerator demonstrates that the weights and activation functions\nare unevenly susceptible to both single-event upset (SEU) and multi-bit upset\n(MBU), especially in the first five layers of our selected convolution neural\nnetwork. In this paper, we present the relatively-accurate statistical models\nto delineate the impact of both undertaken SEU and MBU across layers and per\neach layer of the selected NN. These models can be used for evaluating the\nerror-resiliency magnitude of NN topology before adopting them in the\nsafety-critical applications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:10:24 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 14:01:53 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Khoshavi", "Navid", ""], ["Sargolzaei", "Saman", ""], ["Roohi", "Arman", ""], ["Broyles", "Connor", ""], ["Bi", "Yu", ""]]}, {"id": "2004.05094", "submitter": "Michael Murray", "authors": "Michael Murray, Jared Tanner", "title": "Encoder blind combinatorial compressed sensing", "comments": "41 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In its most elementary form, compressed sensing studies the design of\ndecoding algorithms to recover a sufficiently sparse vector or code from a\nlower dimensional linear measurement vector. Typically it is assumed that the\ndecoder has access to the encoder matrix, which in the combinatorial case is\nsparse and binary. In this paper we consider the problem of designing a decoder\nto recover a set of sparse codes from their linear measurements alone, that is\nwithout access to encoder matrix. To this end we study the matrix factorisation\ntask of recovering both the encoder and sparse coding matrices from the\nassociated linear measurement matrix. The contribution of this paper is a\ncomputationally efficient decoding algorithm, Decoder-Expander Based\nFactorisation, with strong performance guarantees. In particular, under mild\nassumptions on the sparse coding matrix and by deploying a novel random encoder\nmatrix, we prove that Decoder-Expander Based Factorisation recovers both the\nencoder and sparse coding matrix at the optimal measurement rate with high\nprobability and from a near optimal number of measurement vectors. In addition,\nour experiments demonstrate the efficacy and computational efficiency of our\nalgorithm in practice. Beyond compressed sensing our results may be of interest\nfor researchers working in areas such as linear sketching, coding theory and\nmatrix compression.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:26:11 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 08:30:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Murray", "Michael", ""], ["Tanner", "Jared", ""]]}, {"id": "2004.05107", "submitter": "Jessica Hamrick", "authors": "Jessica Hamrick and Shakir Mohamed", "title": "Levels of Analysis for Machine Learning", "comments": "Accepted to the workshop on \"Bridging AI and Cognitive Science\" at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is currently involved in some of the most vigorous debates\nit has ever seen. Such debates often seem to go around in circles, reaching no\nconclusion or resolution. This is perhaps unsurprising given that researchers\nin machine learning come to these discussions with very different frames of\nreference, making it challenging for them to align perspectives and find common\nground. As a remedy for this dilemma, we advocate for the adoption of a common\nconceptual framework which can be used to understand, analyze, and discuss\nresearch. We present one such framework which is popular in cognitive science\nand neuroscience and which we believe has great utility in machine learning as\nwell: Marr's levels of analysis. Through a series of case studies, we\ndemonstrate how the levels facilitate an understanding and dissection of\nseveral methods from machine learning. By adopting the levels of analysis in\none's own work, we argue that researchers can be better equipped to engage in\nthe debates necessary to drive forward progress in our field.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:58:44 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Hamrick", "Jessica", ""], ["Mohamed", "Shakir", ""]]}, {"id": "2004.05111", "submitter": "Alexander Neergaard Olesen", "authors": "Alexander Neergaard Olesen, Poul Jennum, Emmanuel Mignot, Helge B. D.\n  Sorensen", "title": "Deep transfer learning for improving single-EEG arousal detection", "comments": "Accepted for presentation at EMBC2020", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9176723", "report-no": null, "categories": "cs.CV eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets in sleep science present challenges for machine learning algorithms\ndue to differences in recording setups across clinics. We investigate two deep\ntransfer learning strategies for overcoming the channel mismatch problem for\ncases where two datasets do not contain exactly the same setup leading to\ndegraded performance in single-EEG models. Specifically, we train a baseline\nmodel on multivariate polysomnography data and subsequently replace the first\ntwo layers to prepare the architecture for single-channel\nelectroencephalography data. Using a fine-tuning strategy, our model yields\nsimilar performance to the baseline model (F1=0.682 and F1=0.694,\nrespectively), and was significantly better than a comparable single-channel\nmodel. Our results are promising for researchers working with small databases\nwho wish to use deep learning models pre-trained on larger databases.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:51:06 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 11:18:28 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Olesen", "Alexander Neergaard", ""], ["Jennum", "Poul", ""], ["Mignot", "Emmanuel", ""], ["Sorensen", "Helge B. D.", ""]]}, {"id": "2004.05113", "submitter": "Naeemul Hassan", "authors": "Fariha Afsana, Muhammad Ashad Kabir, Naeemul Hassan, Manoranjan Paul", "title": "Automatically Assessing Quality of Online Health Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information ecosystem today is overwhelmed by an unprecedented quantity\nof data on versatile topics are with varied quality. However, the quality of\ninformation disseminated in the field of medicine has been questioned as the\nnegative health consequences of health misinformation can be life-threatening.\nThere is currently no generic automated tool for evaluating the quality of\nonline health information spanned over a broad range. To address this gap, in\nthis paper, we applied a data mining approach to automatically assess the\nquality of online health articles based on 10 quality criteria. We have\nprepared a labeled dataset with 53012 features and applied different feature\nselection methods to identify the best feature subset with which our trained\nclassifier achieved an accuracy of 84%-90% varied over 10 criteria. Our\nsemantic analysis of features shows the underpinning associations between the\nselected features & assessment criteria and further rationalize our assessment\napproach. Our findings will help in identifying high-quality health articles\nand thus aiding users in shaping their opinion to make the right choice while\npicking health-related help from online.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 02:57:35 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Afsana", "Fariha", ""], ["Kabir", "Muhammad Ashad", ""], ["Hassan", "Naeemul", ""], ["Paul", "Manoranjan", ""]]}, {"id": "2004.05154", "submitter": "Carlos Esteves", "authors": "Carlos Esteves", "title": "Theoretical Aspects of Group Equivariant Neural Networks", "comments": "Corrected 3D steerable CNNs kernel characterization and other minor\n  fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group equivariant neural networks have been explored in the past few years\nand are interesting from theoretical and practical standpoints. They leverage\nconcepts from group representation theory, non-commutative harmonic analysis\nand differential geometry that do not often appear in machine learning. In\npractice, they have been shown to reduce sample and model complexity, notably\nin challenging tasks where input transformations such as arbitrary rotations\nare present. We begin this work with an exposition of group representation\ntheory and the machinery necessary to define and evaluate integrals and\nconvolutions on groups. Then, we show applications to recent SO(3) and SE(3)\nequivariant networks, namely the Spherical CNNs, Clebsch-Gordan Networks, and\n3D Steerable CNNs. We proceed to discuss two recent theoretical results. The\nfirst, by Kondor and Trivedi (ICML'18), shows that a neural network is group\nequivariant if and only if it has a convolutional structure. The second, by\nCohen et al. (NeurIPS'19), generalizes the first to a larger class of networks,\nwith feature maps as fields on homogeneous spaces.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:57:27 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 02:10:51 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Esteves", "Carlos", ""]]}, {"id": "2004.05167", "submitter": "Meena Jagadeesan", "authors": "Cynthia Dwork, Christina Ilvento, Meena Jagadeesan", "title": "Individual Fairness in Pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well understood that a system built from individually fair components\nmay not itself be individually fair. In this work, we investigate individual\nfairness under pipeline composition. Pipelines differ from ordinary sequential\nor repeated composition in that individuals may drop out at any stage, and\nclassification in subsequent stages may depend on the remaining \"cohort\" of\nindividuals. As an example, a company might hire a team for a new project and\nat a later point promote the highest performer on the team. Unlike other\nrepeated classification settings, where the degree of unfairness degrades\ngracefully over multiple fair steps, the degree of unfairness in pipelines can\nbe arbitrary, even in a pipeline with just two stages.\n  Guided by a panoply of real-world examples, we provide a rigorous framework\nfor evaluating different types of fairness guarantees for pipelines. We show\nthat na\\\"{i}ve auditing is unable to uncover systematic unfairness and that, in\norder to ensure fairness, some form of dependence must exist between the design\nof algorithms at different stages in the pipeline. Finally, we provide\nconstructions that permit flexibility at later stages, meaning that there is no\nneed to lock in the entire pipeline at the time that the early stage is\nconstructed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 00:31:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dwork", "Cynthia", ""], ["Ilvento", "Christina", ""], ["Jagadeesan", "Meena", ""]]}, {"id": "2004.05184", "submitter": "Christian Reilly", "authors": "Oleksandr Ivanov (1), Lisa Wolf (2), Deena Brecher (1), Kevin Masek\n  (3), Erica Lewis (4), Stephen Liu (5), Robert B Dunne (6), Kevin Klauer (7),\n  Kyla Montgomery (1), Yurii Andrieiev (1), Moss McLaughlin (1), and Christian\n  Reilly (1) ((1) Mednition Inc., (2) Emergency Nurses Association, (3) San\n  Mateo Medical Center, (4) El Camino Hospital, (5) Adventist Health, (6)\n  Ascension Health, (7) American Osteopathic Association)", "title": "Improving Emergency Department ESI Acuity Assignment Using Machine\n  Learning and Clinical Natural Language Processing", "comments": "18 pages, 6 tables, 12 supplemental tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective triage is critical to mitigating the effect of increased volume by\naccurately determining patient acuity, need for resources, and establishing\neffective acuity-based patient prioritization. The purpose of this\nretrospective study was to determine whether historical EHR data can be\nextracted and synthesized with clinical natural language processing (C-NLP) and\nthe latest ML algorithms (KATE) to produce highly accurate ESI predictive\nmodels. An ML model (KATE) for the triage process was developed using 166,175\npatient encounters from two participating hospitals. The model was then tested\nagainst a gold set that was derived from a random sample of triage encounters\nat the study sites and correct acuity assignments were recorded by study\nclinicians using the Emergency Severity Index (ESI) standard as a guide. At the\ntwo study sites, KATE predicted accurate ESI acuity assignments 75.9% of the\ntime, compared to nurses (59.8%) and average individual study clinicians\n(75.3%). KATE accuracy was 26.9% higher than the average nurse accuracy\n(p-value < 0.0001). On the boundary between ESI 2 and ESI 3 acuity assignments,\nwhich relates to the risk of decompensation, KATE was 93.2% higher with 80%\naccuracy, compared to triage nurses with 41.4% accuracy (p-value < 0.0001).\nKATE provides a triage acuity assignment substantially more accurate than the\ntriage nurses in this study sample. KATE operates independently of contextual\nfactors, unaffected by the external pressures that can cause under triage and\nmay mitigate the racial and social biases that can negatively affect the\naccuracy of triage assignment. Future research should focus on the impact of\nKATE providing feedback to triage nurses in real time, KATEs impact on\nmortality and morbidity, ED throughput, resource optimization, and nursing\noutcomes.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:18:22 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 15:38:40 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ivanov", "Oleksandr", ""], ["Wolf", "Lisa", ""], ["Brecher", "Deena", ""], ["Masek", "Kevin", ""], ["Lewis", "Erica", ""], ["Liu", "Stephen", ""], ["Dunne", "Robert B", ""], ["Klauer", "Kevin", ""], ["Montgomery", "Kyla", ""], ["Andrieiev", "Yurii", ""], ["McLaughlin", "Moss", ""], ["Reilly", "Christian", ""]]}, {"id": "2004.05198", "submitter": "Michael Schneider", "authors": "Im\\`ene R. Goumiri, Benjamin W. Priest, Michael D. Schneider", "title": "Reinforcement Learning via Gaussian Processes with Neural Network Dual\n  Kernels", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-808440", "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks (DNNs) and Gaussian Processes (GPs) are both\npopularly utilized to solve problems in reinforcement learning, both approaches\nfeature undesirable drawbacks for challenging problems. DNNs learn complex\nnonlinear embeddings, but do not naturally quantify uncertainty and are often\ndata-inefficient to train. GPs infer posterior distributions over functions,\nbut popular kernels exhibit limited expressivity on complex and\nhigh-dimensional data. Fortunately, recently discovered conjugate and neural\ntangent kernel functions encode the behavior of overparameterized neural\nnetworks in the kernel domain. We demonstrate that these kernels can be\nefficiently applied to regression and reinforcement learning problems by\nanalyzing a baseline case study. We apply GPs with neural network dual kernels\nto solve reinforcement learning tasks for the first time. We demonstrate, using\nthe well-understood mountain-car problem, that GPs empowered with dual kernels\nperform at least as well as those using the conventional radial basis function\nkernel. We conjecture that by inheriting the probabilistic rigor of GPs and the\npowerful embedding properties of DNNs, GPs using NN dual kernels will empower\nfuture reinforcement learning models on difficult domains.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 18:36:21 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Goumiri", "Im\u00e8ne R.", ""], ["Priest", "Benjamin W.", ""], ["Schneider", "Michael D.", ""]]}, {"id": "2004.05209", "submitter": "David Carlson", "authors": "Austin Talbot, David Dunson, Kafui Dzirasa, David Carlson", "title": "Supervised Autoencoders Learn Robust Joint Factor Models of Neural\n  Activity", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor models are routinely used for dimensionality reduction in modeling of\ncorrelated, high-dimensional data. We are particularly motivated by\nneuroscience applications collecting high-dimensional `predictors'\ncorresponding to brain activity in different regions along with behavioral\noutcomes. Joint factor models for the predictors and outcomes are natural, but\nmaximum likelihood estimates of these models can struggle in practice when\nthere is model misspecification. We propose an alternative inference strategy\nbased on supervised autoencoders; rather than placing a probability\ndistribution on the latent factors, we define them as an unknown function of\nthe high-dimensional predictors. This mapping function, along with the\nloadings, can be optimized to explain variance in brain activity while\nsimultaneously being predictive of behavior. In practice, the mapping function\ncan range in complexity from linear to more complex forms, such as splines or\nneural networks, with the usual tradeoff between bias and variance. This\napproach yields distinct solutions from a maximum likelihood inference\nstrategy, as we demonstrate by deriving analytic solutions for a linear\nGaussian factor model. Using synthetic data, we show that this function-based\napproach is robust against multiple types of misspecification. We then apply\nthis technique to a neuroscience application resulting in substantial gains in\npredicting behavioral tasks from electrophysiological measurements in multiple\nfactor models.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 19:31:57 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Talbot", "Austin", ""], ["Dunson", "David", ""], ["Dzirasa", "Kafui", ""], ["Carlson", "David", ""]]}, {"id": "2004.05218", "submitter": "Edward Hirst", "authors": "Yang-Hui He, Edward Hirst, Toby Peterken", "title": "Machine-Learning Dessins d'Enfants: Explorations via Modular and\n  Seiberg-Witten Curves", "comments": "60 pages, 197 figures. Acknowledgements updated to reflect thanks to\n  the group at UoAugsburg for highlighting a data analysis problem, that lead\n  authors to identify the dessin d'enfant representation subtlety and use the\n  improved cyclic edge list representation, as in version 3", "journal-ref": "J. Phys. A: Math. Theor. 54 075401 (2021)", "doi": "10.1088/1751-8121/abbc4f", "report-no": null, "categories": "hep-th math.AG math.NT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply machine-learning to the study of dessins d'enfants. Specifically, we\ninvestigate a class of dessins which reside at the intersection of the\ninvestigations of modular subgroups, Seiberg-Witten curves and extremal\nelliptic K3 surfaces. A deep feed-forward neural network with simple structure\nand standard activation functions without prior knowledge of the underlying\nmathematics is established and imposed onto the classification of extension\ndegree over the rationals, known to be a difficult problem. The classifications\nreached 0.92 accuracy with 0.03 standard error relatively quickly. The\nSeiberg-Witten curves for those with rational coefficients are also tabulated.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 20:17:02 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 17:18:10 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 18:52:07 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 13:48:03 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["He", "Yang-Hui", ""], ["Hirst", "Edward", ""], ["Peterken", "Toby", ""]]}, {"id": "2004.05265", "submitter": "Nic Herndon", "authors": "Mark Sokolov, Kehinde Olufowobi and Nic Herndon", "title": "Visual Spoofing in content based spam detection", "comments": null, "journal-ref": null, "doi": "10.1145/3433174.3433605", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the problem of spam classification seems to be solved, there are\nstill vulnerabilities in the current spam filters that could be easily\nexploited. We present one such vulnerability, in which one could replace some\ncharacters with corresponding characters from a different alphabet. These\ncharacters are visually similar, yet have a different Unicode encoding. With\nthis approach spammers can create messages that bypass existing spam filters.\nMoreover, we show that this approach can be used to avoid plagiarism detection,\nand in other applications that use natural language processing for automatic\nanalysis of text documents.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:16:04 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 01:44:32 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sokolov", "Mark", ""], ["Olufowobi", "Kehinde", ""], ["Herndon", "Nic", ""]]}, {"id": "2004.05277", "submitter": "Bubacarr Bah", "authors": "Mhlasakululeka Mvubu, Emmanuel Kabuga, Christian Plitz, Bubacarr Bah,\n  Ronnie Becker, Hans Georg Zimmermann", "title": "On Error Correction Neural Networks for Economic Forecasting", "comments": "13 pages, 4 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are more suitable for learning non-linear\ndependencies in dynamical systems from observed time series data. In practice\nall the external variables driving such systems are not known a priori,\nespecially in economical forecasting. A class of RNNs called Error Correction\nNeural Networks (ECNNs) was designed to compensate for missing input variables.\nIt does this by feeding back in the current step the error made in the previous\nstep. The ECNN is implemented in Python by the computation of the appropriate\ngradients and it is tested on stock market predictions. As expected it out\nperformed the simple RNN and LSTM and other hybrid models which involve a\nde-noising pre-processing step. The intuition for the latter is that de-noising\nmay lead to loss of information.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 01:23:39 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:21:32 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Mvubu", "Mhlasakululeka", ""], ["Kabuga", "Emmanuel", ""], ["Plitz", "Christian", ""], ["Bah", "Bubacarr", ""], ["Becker", "Ronnie", ""], ["Zimmermann", "Hans Georg", ""]]}, {"id": "2004.05281", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Weining Shen, Dehan Kong", "title": "Covariance Estimation for Matrix-valued Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance estimation for matrix-valued data has received an increasing\ninterest in applications including neuroscience and environmental studies.\nUnlike previous works that rely heavily on matrix normal distribution\nassumption and the requirement of fixed matrix size, we propose a class of\ndistribution-free regularized covariance estimation methods for\nhigh-dimensional matrix data under a separability condition and a bandable\ncovariance structure. Under these conditions, the original covariance matrix is\ndecomposed into a Kronecker product of two bandable small covariance matrices\nrepresenting the variability over row and column directions. We formulate a\nunified framework for estimating the banded and tapering covariance, and\nintroduce an efficient algorithm based on rank one unconstrained Kronecker\nproduct approximation. The convergence rates of the proposed estimators are\nstudied and compared to the ones for the usual vector-valued data. We further\nintroduce a class of robust covariance estimators and provide theoretical\nguarantees to deal with the potential heavy-tailed data. We demonstrate the\nsuperior finite-sample performance of our methods using simulations and real\napplications from an electroencephalography study and a gridded temperature\nanomalies dataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 02:15:26 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zhang", "Yichi", ""], ["Shen", "Weining", ""], ["Kong", "Dehan", ""]]}, {"id": "2004.05289", "submitter": "Petros Spachos", "authors": "Syeda Manjia Tahsien, Hadis Karimipour, Petros Spachos", "title": "Machine Learning Based Solutions for Security of Internet of Things\n  (IoT): A Survey", "comments": null, "journal-ref": null, "doi": "10.1016/j.jnca.2020.102630", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, IoT platforms have been developed into a global giant\nthat grabs every aspect of our daily lives by advancing human life with its\nunaccountable smart services. Because of easy accessibility and fast-growing\ndemand for smart devices and network, IoT is now facing more security\nchallenges than ever before. There are existing security measures that can be\napplied to protect IoT. However, traditional techniques are not as efficient\nwith the advancement booms as well as different attack types and their\nsevereness. Thus, a strong-dynamically enhanced and up to date security system\nis required for next-generation IoT system. A huge technological advancement\nhas been noticed in Machine Learning (ML) which has opened many possible\nresearch windows to address ongoing and future challenges in IoT. In order to\ndetect attacks and identify abnormal behaviors of smart devices and networks,\nML is being utilized as a powerful technology to fulfill this purpose. In this\nsurvey paper, the architecture of IoT is discussed, following a comprehensive\nliterature review on ML approaches the importance of security of IoT in terms\nof different types of possible attacks. Moreover, ML-based potential solutions\nfor IoT security has been presented and future challenges are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:08:24 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Tahsien", "Syeda Manjia", ""], ["Karimipour", "Hadis", ""], ["Spachos", "Petros", ""]]}, {"id": "2004.05290", "submitter": "Ian Manchester", "authors": "Max Revay, Ruigang Wang, Ian R. Manchester", "title": "A Convex Parameterization of Robust Recurrent Neural Networks", "comments": "conference submission, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a class of nonlinear dynamical systems\noften used to model sequence-to-sequence maps. RNNs have excellent expressive\npower but lack the stability or robustness guarantees that are necessary for\nmany applications. In this paper, we formulate convex sets of RNNs with\nstability and robustness guarantees. The guarantees are derived using\nincremental quadratic constraints and can ensure global exponential stability\nof all solutions, and bounds on incremental $ \\ell_2 $ gain (the Lipschitz\nconstant of the learned sequence-to-sequence mapping). Using an implicit model\nstructure, we construct a parametrization of RNNs that is jointly convex in the\nmodel parameters and stability certificate. We prove that this model structure\nincludes all previously-proposed convex sets of stable RNNs as special cases,\nand also includes all stable linear dynamical systems. We illustrate the\nutility of the proposed model class in the context of non-linear system\nidentification.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:12:42 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 08:48:04 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Revay", "Max", ""], ["Wang", "Ruigang", ""], ["Manchester", "Ian R.", ""]]}, {"id": "2004.05298", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Exploit Where Optimizer Explores via Residuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to train the neural networks faster, many efforts have been devoted\nto exploring a better solution trajectory, but few have been put into\nexploiting the existing solution trajectory. To exploit the trajectory of\n(momentum) stochastic gradient descent (SGD(m)) method, we propose a novel\nmethod named SGD(m) with residuals (RSGD(m)), which leads to a performance\nboost of both the convergence and generalization. Our new method can also be\napplied to other optimizers such as ASGD and Adam. We provide theoretical\nanalysis to show that RSGD achieves a smaller growth rate of the generalization\nerror and the same (but empirically better) convergence rate compared with SGD.\nExtensive deep learning experiments on image classification, language modeling\nand graph convolutional neural networks show that the proposed algorithm is\nfaster than SGD(m)/Adam at the initial training stage, and similar to or better\nthan SGD(m) at the end of training with better generalization error.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:50:59 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 12:13:54 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "2004.05316", "submitter": "Zhaobin Kuang", "authors": "Zhaobin Kuang, Frederic Sala, Nimit Sohoni, Sen Wu, Aldo\n  C\\'ordova-Palomera, Jared Dunnmon, James Priest, Christopher R\\'e", "title": "Ivy: Instrumental Variable Synthesis for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular way to estimate the causal effect of a variable x on y from\nobservational data is to use an instrumental variable (IV): a third variable z\nthat affects y only through x. The more strongly z is associated with x, the\nmore reliable the estimate is, but such strong IVs are difficult to find.\nInstead, practitioners combine more commonly available IV candidates---which\nare not necessarily strong, or even valid, IVs---into a single \"summary\" that\nis plugged into causal effect estimators in place of an IV. In genetic\nepidemiology, such approaches are known as allele scores. Allele scores require\nstrong assumptions---independence and validity of all IV candidates---for the\nresulting estimate to be reliable. To relax these assumptions, we propose Ivy,\na new method to combine IV candidates that can handle correlated and invalid IV\ncandidates in a robust manner. Theoretically, we characterize this robustness,\nits limits, and its impact on the resulting causal estimates. Empirically, Ivy\ncan correctly identify the directionality of known relationships and is robust\nagainst false discovery (median effect size <= 0.025) on three real-world\ndatasets with no causal effects, while allele scores return more biased\nestimates (median effect size >= 0.118).\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:11:04 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Kuang", "Zhaobin", ""], ["Sala", "Frederic", ""], ["Sohoni", "Nimit", ""], ["Wu", "Sen", ""], ["C\u00f3rdova-Palomera", "Aldo", ""], ["Dunnmon", "Jared", ""], ["Priest", "James", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2004.05318", "submitter": "Luchen Liu", "authors": "Luchen Liu, Zequn Liu, Haoxian Wu, Zichang Wang, Jianhao Shen, Yiping\n  Song, and Ming Zhang", "title": "Multi-task Learning via Adaptation to Similar Tasks for Mortality\n  Prediction of Diverse Rare Diseases", "comments": "10 pages, 3 Figures, submitted to AMIA Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mortality prediction of diverse rare diseases using electronic health record\n(EHR) data is a crucial task for intelligent healthcare. However, data\ninsufficiency and the clinical diversity of rare diseases make it hard for\ndirectly training deep learning models on individual disease data or all the\ndata from different diseases. Mortality prediction for these patients with\ndifferent diseases can be viewed as a multi-task learning problem with\ninsufficient data and large task number. But the tasks with little training\ndata also make it hard to train task-specific modules in multi-task learning\nmodels. To address the challenges of data insufficiency and task diversity, we\npropose an initialization-sharing multi-task learning method (Ada-Sit) which\nlearns the parameter initialization for fast adaptation to dynamically measured\nsimilar tasks. We use Ada-Sit to train long short-term memory networks (LSTM)\nbased prediction models on longitudinal EHR data. And experimental results\ndemonstrate that the proposed model is effective for mortality prediction of\ndiverse rare diseases.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:15:23 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:58:27 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Luchen", ""], ["Liu", "Zequn", ""], ["Wu", "Haoxian", ""], ["Wang", "Zichang", ""], ["Shen", "Jianhao", ""], ["Song", "Yiping", ""], ["Zhang", "Ming", ""]]}, {"id": "2004.05361", "submitter": "Martin Genzel", "authors": "Martin Genzel and Christian Kipp", "title": "Generic Error Bounds for the Generalized Lasso with Sub-Exponential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work performs a non-asymptotic analysis of the generalized Lasso under\nthe assumption of sub-exponential data. Our main results continue recent\nresearch on the benchmark case of (sub-)Gaussian sample distributions and\nthereby explore what conclusions are still valid when going beyond. While many\nstatistical features of the generalized Lasso remain unaffected (e.g.,\nconsistency), the key difference becomes manifested in the way how the\ncomplexity of the hypothesis set is measured. It turns out that the estimation\nerror can be controlled by means of two complexity parameters that arise\nnaturally from a generic-chaining-based proof strategy. The output model can be\nnon-realizable, while the only requirement for the input vector is a generic\nconcentration inequality of Bernstein-type, which can be implemented for a\nvariety of sub-exponential distributions. This abstract approach allows us to\nreproduce, unify, and extend previously known guarantees for the generalized\nLasso. In particular, we present applications to semi-parametric output models\nand phase retrieval via the lifted Lasso. Moreover, our findings are discussed\nin the context of sparse recovery and high-dimensional estimation problems.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 10:39:48 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 17:23:49 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Genzel", "Martin", ""], ["Kipp", "Christian", ""]]}, {"id": "2004.05366", "submitter": "Len Du", "authors": "Len Du", "title": "In-Machine-Learning Database: Reimagining Deep Learning with Old-School\n  SQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-database machine learning has been very popular, almost being a cliche.\nHowever, can we do it the other way around? In this work, we say \"yes\" by\napplying plain old SQL to deep learning, in a sense implementing deep learning\nalgorithms with SQL. Most deep learning frameworks, as well as generic machine\nlearning ones, share a de facto standard of multidimensional array operations,\nunderneath fancier infrastructure such as automatic differentiation. As SQL\ntables can be regarded as generalisations of (multi-dimensional) arrays, we\nhave found a way to express common deep learning operations in SQL, encouraging\na different way of thinking and thus potentially novel models. In particular,\none of the latest trend in deep learning was the introduction of sparsity in\nthe name of graph convolutional networks, whereas we take sparsity almost for\ngranted in the database world. As both databases and machine learning involve\ntransformation of datasets, we hope this work can inspire further works\nutilizing the large body of existing wisdom, algorithms and technologies in the\ndatabase field to advance the state of the art in machine learning, rather than\nmerely integerating machine learning into databases.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 11:00:26 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 18:08:28 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Du", "Len", ""]]}, {"id": "2004.05367", "submitter": "Giuseppe Brandi", "authors": "Giuseppe Brandi and T. Di Matteo", "title": "A new multilayer network construction via Tensor learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer networks proved to be suitable in extracting and providing\ndependency information of different complex systems. The construction of these\nnetworks is difficult and is mostly done with a static approach, neglecting\ntime delayed interdependences. Tensors are objects that naturally represent\nmultilayer networks and in this paper, we propose a new methodology based on\nTucker tensor autoregression in order to build a multilayer network directly\nfrom data. This methodology captures within and between connections across\nlayers and makes use of a filtering procedure to extract relevant information\nand improve visualization. We show the application of this methodology to\ndifferent stationary fractionally differenced financial data. We argue that our\nresult is useful to understand the dependencies across three different aspects\nof financial risk, namely market risk, liquidity risk, and volatility risk.\nIndeed, we show how the resulting visualization is a useful tool for risk\nmanagers depicting dependency asymmetries between different risk factors and\naccounting for delayed cross dependencies. The constructed multilayer network\nshows a strong interconnection between the volumes and prices layers across all\nthe stocks considered while a lower number of interconnections between the\nuncertainty measures is identified.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 11:06:33 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Brandi", "Giuseppe", ""], ["Di Matteo", "T.", ""]]}, {"id": "2004.05381", "submitter": "Sebastian Feld", "authors": "Sebastian Feld (1), Andreas Sedlmeier (1), Markus Friedrich (1), Jan\n  Franz (1), Lenz Belzner (2) ((1) Mobile and Distributed Systems Group LMU\n  Munich, (2) MaibornWolff Munich)", "title": "Bayesian Surprise in Indoor Environments", "comments": "10 pages, 16 figures", "journal-ref": "Proceedings of the 27th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (SIGSPATIAL '19), 2019, p. 129-138", "doi": "10.1145/3347146.3359358", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method to identify unexpected structures in 2D\nfloor plans using the concept of Bayesian Surprise. Taking into account that a\nperson's expectation is an important aspect of the perception of space, we\nexploit the theory of Bayesian Surprise to robustly model expectation and thus\nsurprise in the context of building structures. We use Isovist Analysis, which\nis a popular space syntax technique, to turn qualitative object attributes into\nquantitative environmental information. Since isovists are location-specific\npatterns of visibility, a sequence of isovists describes the spatial perception\nduring a movement along multiple points in space. We then use Bayesian Surprise\nin a feature space consisting of these isovist readings. To demonstrate the\nsuitability of our approach, we take \"snapshots\" of an agent's local\nenvironment to provide a short list of images that characterize a traversed\ntrajectory through a 2D indoor environment. Those fingerprints represent\nsurprising regions of a tour, characterize the traversed map and enable indoor\nLBS to focus more on important regions. Given this idea, we propose to use\n\"surprise\" as a new dimension of context in indoor location-based services\n(LBS). Agents of LBS, such as mobile robots or non-player characters in\ncomputer games, may use the context surprise to focus more on important regions\nof a map for a better use or understanding of the floor plan.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:09:51 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Feld", "Sebastian", ""], ["Sedlmeier", "Andreas", ""], ["Friedrich", "Markus", ""], ["Franz", "Jan", ""], ["Belzner", "Lenz", ""]]}, {"id": "2004.05383", "submitter": "Sebastian Feld", "authors": "Sebastian Feld (1), Steffen Illium (1), Andreas Sedlmeier (1), Lenz\n  Belzner (2) ((1) Mobile and Distributed Systems Group LMU Munich, (2)\n  MaibornWolff Munich)", "title": "Trajectory annotation using sequences of spatial perception", "comments": "10 pages, 17 figures", "journal-ref": "Proceedings of the 26th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (SIGSPATIAL '18), 2018, p. 329-338", "doi": "10.1145/3274895.3274968", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the near future, more and more machines will perform tasks in the vicinity\nof human spaces or support them directly in their spatially bound activities.\nIn order to simplify the verbal communication and the interaction between\nrobotic units and/or humans, reliable and robust systems w.r.t. noise and\nprocessing results are needed. This work builds a foundation to address this\ntask. By using a continuous representation of spatial perception in interiors\nlearned from trajectory data, our approach clusters movement in dependency to\nits spatial context. We propose an unsupervised learning approach based on a\nneural autoencoding that learns semantically meaningful continuous encodings of\nspatio-temporal trajectory data. This learned encoding can be used to form\nprototypical representations. We present promising results that clear the path\nfor future applications.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:22:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Feld", "Sebastian", ""], ["Illium", "Steffen", ""], ["Sedlmeier", "Andreas", ""], ["Belzner", "Lenz", ""]]}, {"id": "2004.05426", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues", "title": "Scaling Bayesian inference of mixed multinomial logit models to very\n  large datasets", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference methods have been shown to lead to significant\nimprovements in the computational efficiency of approximate Bayesian inference\nin mixed multinomial logit models when compared to standard Markov-chain Monte\nCarlo (MCMC) methods without compromising accuracy. However, despite their\ndemonstrated efficiency gains, existing methods still suffer from important\nlimitations that prevent them to scale to very large datasets, while providing\nthe flexibility to allow for rich prior distributions and to capture complex\nposterior distributions. In this paper, we propose an Amortized Variational\nInference approach that leverages stochastic backpropagation, automatic\ndifferentiation and GPU-accelerated computation, for effectively scaling\nBayesian inference in Mixed Multinomial Logit models to very large datasets.\nMoreover, we show how normalizing flows can be used to increase the flexibility\nof the variational posterior approximations. Through an extensive simulation\nstudy, we empirically show that the proposed approach is able to achieve\ncomputational speedups of multiple orders of magnitude over traditional MSLE\nand MCMC approaches for large datasets without compromising estimation\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 15:30:47 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Rodrigues", "Filipe", ""]]}, {"id": "2004.05439", "submitter": "Timothy Hospedales", "authors": "Timothy Hospedales, Antreas Antoniou, Paul Micaelli, Amos Storkey", "title": "Meta-Learning in Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of meta-learning, or learning-to-learn, has seen a dramatic rise in\ninterest in recent years. Contrary to conventional approaches to AI where tasks\nare solved from scratch using a fixed learning algorithm, meta-learning aims to\nimprove the learning algorithm itself, given the experience of multiple\nlearning episodes. This paradigm provides an opportunity to tackle many\nconventional challenges of deep learning, including data and computation\nbottlenecks, as well as generalization. This survey describes the contemporary\nmeta-learning landscape. We first discuss definitions of meta-learning and\nposition it with respect to related fields, such as transfer learning and\nhyperparameter optimization. We then propose a new taxonomy that provides a\nmore comprehensive breakdown of the space of meta-learning methods today. We\nsurvey promising applications and successes of meta-learning such as few-shot\nlearning and reinforcement learning. Finally, we discuss outstanding challenges\nand promising areas for future research.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:34:24 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 20:22:57 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hospedales", "Timothy", ""], ["Antoniou", "Antreas", ""], ["Micaelli", "Paul", ""], ["Storkey", "Amos", ""]]}, {"id": "2004.05442", "submitter": "Sandeep Juneja", "authors": "Achal Bassamboo, Vikas Deep, Sandeep Juneja and Assaf Zeevi", "title": "Discriminative Learning via Adaptive Questioning", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing an adaptive sequence of questions that\noptimally classify a candidate's ability into one of several categories or\ndiscriminative grades. A candidate's ability is modeled as an unknown\nparameter, which, together with the difficulty of the question asked,\ndetermines the likelihood with which s/he is able to answer a question\ncorrectly. The learning algorithm is only able to observe these noisy responses\nto its queries. We consider this problem from a fixed confidence-based\n$\\delta$-correct framework, that in our setting seeks to arrive at the correct\nability discrimination at the fastest possible rate while guaranteeing that the\nprobability of error is less than a pre-specified and small $\\delta$. In this\nsetting we develop lower bounds on any sequential questioning strategy and\ndevelop geometrical insights into the problem structure both from primal and\ndual formulation. In addition, we arrive at algorithms that essentially match\nthese lower bounds. Our key conclusions are that, asymptotically, any candidate\nneeds to be asked questions at most at two (candidate ability-specific) levels,\nalthough, in a reasonably general framework, questions need to be asked only at\na single level. Further, and interestingly, the problem structure facilitates\nendogenous exploration, so there is no need for a separately designed\nexploration stage in the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:50:00 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bassamboo", "Achal", ""], ["Deep", "Vikas", ""], ["Juneja", "Sandeep", ""], ["Zeevi", "Assaf", ""]]}, {"id": "2004.05462", "submitter": "Iordanis Fostiropoulos", "authors": "Iordanis Fostiropoulos", "title": "Depthwise Discrete Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in learning Discrete Representations as opposed to\ncontinuous ones have led to state of art results in tasks that involve\nLanguage, Audio and Vision. Some latent factors such as words, phonemes and\nshapes are better represented by discrete latent variables as opposed to\ncontinuous. Vector Quantized Variational Autoencoders (VQVAE) have produced\nremarkable results in multiple domains. VQVAE learns a prior distribution $z_e$\nalong with its mapping to a discrete number of $K$ vectors (Vector\nQuantization). We propose applying VQ along the feature axis. We hypothesize\nthat by doing so, we are learning a mapping between the codebook vectors and\nthe marginal distribution of the prior feature space. Our approach leads to\n33\\% improvement as compared to prevous discrete models and has similar\nperformance to state of the art auto-regressive models (e.g. PixelSNAIL). We\nevaluate our approach on a static prior using an artificial toy dataset\n(blobs). We further evaluate our approach on benchmarks for CIFAR-10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:57:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Fostiropoulos", "Iordanis", ""]]}, {"id": "2004.05465", "submitter": "Melanie Weber", "authors": "Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya Menon and\n  Sanjiv Kumar", "title": "Robust Large-Margin Learning in Hyperbolic Space", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a surge of interest in representation learning in\nhyperbolic spaces, driven by their ability to represent hierarchical data with\nsignificantly fewer dimensions than standard Euclidean spaces. However, the\nviability and benefits of hyperbolic spaces for downstream machine learning\ntasks have received less attention. In this paper, we present, to our\nknowledge, the first theoretical guarantees for learning a classifier in\nhyperbolic rather than Euclidean space. Specifically, we consider the problem\nof learning a large-margin classifier for data possessing a hierarchical\nstructure. Our first contribution is a hyperbolic perceptron algorithm, which\nprovably converges to a separating hyperplane. We then provide an algorithm to\nefficiently learn a large-margin hyperplane, relying on the careful injection\nof adversarial examples. Finally, we prove that for hierarchical data that\nembeds well into hyperbolic space, the low embedding dimension ensures superior\nguarantees when learning the classifier directly in hyperbolic space.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 19:11:30 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 17:25:50 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Weber", "Melanie", ""], ["Zaheer", "Manzil", ""], ["Rawat", "Ankit Singh", ""], ["Menon", "Aditya", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2004.05472", "submitter": "Conor Lazarou", "authors": "Conor Lazarou", "title": "Autoencoding Generative Adversarial Networks", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the years since Goodfellow et al. introduced Generative Adversarial\nNetworks (GANs), there has been an explosion in the breadth and quality of\ngenerative model applications. Despite this work, GANs still have a long way to\ngo before they see mainstream adoption, owing largely to their infamous\ntraining instability. Here I propose the Autoencoding Generative Adversarial\nNetwork (AEGAN), a four-network model which learns a bijective mapping between\na specified latent space and a given sample space by applying an adversarial\nloss and a reconstruction loss to both the generated images and the generated\nlatent vectors. The AEGAN technique offers several improvements to typical GAN\ntraining, including training stabilization, mode-collapse prevention, and\npermitting the direct interpolation between real samples. The effectiveness of\nthe technique is illustrated using an anime face dataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 19:51:04 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lazarou", "Conor", ""]]}, {"id": "2004.05485", "submitter": "Ashis Pati", "authors": "Ashis Pati, Alexander Lerch", "title": "Attribute-based Regularization of Latent Spaces for Variational\n  Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Selective manipulation of data attributes using deep generative models is an\nactive area of research. In this paper, we present a novel method to structure\nthe latent space of a Variational Auto-Encoder (VAE) to encode different\ncontinuous-valued attributes explicitly. This is accomplished by using an\nattribute regularization loss which enforces a monotonic relationship between\nthe attribute values and the latent code of the dimension along which the\nattribute is to be encoded. Consequently, post-training, the model can be used\nto manipulate the attribute by simply changing the latent code of the\ncorresponding regularized dimension. The results obtained from several\nquantitative and qualitative experiments show that the proposed method leads to\ndisentangled and interpretable latent spaces that can be used to effectively\nmanipulate a wide range of data attributes spanning image and symbolic music\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 20:53:13 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 03:38:16 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 01:16:24 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Pati", "Ashis", ""], ["Lerch", "Alexander", ""]]}, {"id": "2004.05512", "submitter": "Lisa Torrey", "authors": "Lisa Torrey", "title": "Reinforcement Learning via Reasoning from Demonstration", "comments": "Adaptive and Learning Agents Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demonstration is an appealing way for humans to provide assistance to\nreinforcement-learning agents. Most approaches in this area view demonstrations\nprimarily as sources of behavioral bias. But in sparse-reward tasks, humans\nseem to treat demonstrations more as sources of causal knowledge. This paper\nproposes a framework for agents that benefit from demonstration in this\nhuman-inspired way. In this framework, agents develop causal models through\nobservation, and reason from this knowledge to decompose tasks for effective\nreinforcement learning. Experimental results show that a basic implementation\nof Reasoning from Demonstration (RfD) is effective in a range of sparse-reward\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 00:41:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Torrey", "Lisa", ""]]}, {"id": "2004.05529", "submitter": "Fangzhou Mu", "authors": "Fangzhou Mu, Yingyu Liang, Yin Li", "title": "Gradients as Features for Deep Representation Learning", "comments": "ICLR 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenging problem of deep representation learning--the\nefficient adaption of a pre-trained deep network to different tasks.\nSpecifically, we propose to explore gradient-based features. These features are\ngradients of the model parameters with respect to a task-specific loss given an\ninput sample. Our key innovation is the design of a linear model that\nincorporates both gradient and activation of the pre-trained network. We show\nthat our model provides a local linear approximation to an underlying deep\nmodel, and discuss important theoretical insights. Moreover, we present an\nefficient algorithm for the training and inference of our model without\ncomputing the actual gradient. Our method is evaluated across a number of\nrepresentation-learning tasks on several datasets and using different network\narchitectures. Strong results are obtained in all settings, and are\nwell-aligned with our theoretical insights.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 02:57:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mu", "Fangzhou", ""], ["Liang", "Yingyu", ""], ["Li", "Yin", ""]]}, {"id": "2004.05553", "submitter": "Bishal Santra", "authors": "Bishal Santra, Prakhar Sharma, Sumegh Roychowdhury, Pawan Goyal", "title": "Exploring Effects of Random Walk Based Minibatch Selection Policy on\n  Knowledge Graph Completion", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have explored the effects of different minibatch sampling\ntechniques in Knowledge Graph Completion. Knowledge Graph Completion (KGC) or\nLink Prediction is the task of predicting missing facts in a knowledge graph.\nKGC models are usually trained using margin, soft-margin or cross-entropy loss\nfunction that promotes assigning a higher score or probability for true fact\ntriplets. Minibatch gradient descent is used to optimize these loss functions\nfor training the KGC models. But, as each minibatch consists of only a few\nrandomly sampled triplets from a large knowledge graph, any entity that occurs\nin a minibatch, occurs only once in most cases. Because of this, these loss\nfunctions ignore all other neighbors of any entity, whose embedding is being\nupdated at some minibatch step. In this paper, we propose a new random-walk\nbased minibatch sampling technique for training KGC models that optimizes the\nloss incurred by a minibatch of closely connected subgraph of triplets instead\nof randomly selected ones. We have shown results of experiments for different\nmodels and datasets with our sampling technique and found that the proposed\nsampling algorithm has varying effects on these datasets/models. Specifically,\nwe find that our proposed method achieves state-of-the-art performance on the\nDB100K dataset.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 06:16:57 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Santra", "Bishal", ""], ["Sharma", "Prakhar", ""], ["Roychowdhury", "Sumegh", ""], ["Goyal", "Pawan", ""]]}, {"id": "2004.05599", "submitter": "Omar Darwiche Domingues", "authors": "Omar Darwiche Domingues, Pierre M\\'enard, Matteo Pirotta, Emilie\n  Kaufmann, Michal Valko", "title": "Regret Bounds for Kernel-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration-exploitation dilemma in finite-horizon\nreinforcement learning problems whose state-action space is endowed with a\nmetric. We introduce Kernel-UCBVI, a model-based optimistic algorithm that\nleverages the smoothness of the MDP and a non-parametric kernel estimator of\nthe rewards and transitions to efficiently balance exploration and\nexploitation. Unlike existing approaches with regret guarantees, it does not\nuse any kind of partitioning of the state-action space. For problems with $K$\nepisodes and horizon $H$, we provide a regret bound of $O\\left( H^3\nK^{\\max\\left(\\frac{1}{2}, \\frac{2d}{2d+1}\\right)}\\right)$, where $d$ is the\ncovering dimension of the joint state-action space. We empirically validate\nKernel-UCBVI on discrete and continuous MDPs.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 12:23:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:19:40 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Domingues", "Omar Darwiche", ""], ["M\u00e9nard", "Pierre", ""], ["Pirotta", "Matteo", ""], ["Kaufmann", "Emilie", ""], ["Valko", "Michal", ""]]}, {"id": "2004.05607", "submitter": "Aleksandr Cariow", "authors": "Aleksandr Cariow and Galina Cariowa", "title": "Minimal Filtering Algorithms for Convolutional Neural Networks", "comments": "11 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present several resource-efficient algorithmic solutions\nregarding the fully parallel hardware implementation of the basic filtering\noperation performed in the convolutional layers of convolution neural networks.\nIn fact, these basic operations calculate two inner products of neighboring\nvectors formed by a sliding time window from the current data stream with an\nimpulse response of the M-tap finite impulse response filter. We used Winograd\nminimal filtering trick and applied it to develop fully parallel\nhardware-oriented algorithms for implementing the basic filtering operation for\nM=3,5,7,9, and 11. A fully parallel hardware implementation of the proposed\nalgorithms in each case gives approximately 30 percent savings in the number of\nembedded multipliers compared to a fully parallel hardware implementation of\nthe naive calculation methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 13:18:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cariow", "Aleksandr", ""], ["Cariowa", "Galina", ""]]}, {"id": "2004.05617", "submitter": "Rogan Morrow", "authors": "Rogan Morrow, Wei-Chen Chiu", "title": "Variational Autoencoders with Normalizing Flow Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed normalizing flow models such as Glow have been shown to be\nable to generate high quality, high dimensional images with relatively fast\nsampling speed. Due to their inherently restrictive architecture, however, it\nis necessary that they are excessively deep in order to train effectively. In\nthis paper we propose to combine Glow with an underlying variational\nautoencoder in order to counteract this issue. We demonstrate that our proposed\nmodel is competitive with Glow in terms of image quality and test likelihood\nwhile requiring far less time for training.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 14:11:15 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Morrow", "Rogan", ""], ["Chiu", "Wei-Chen", ""]]}, {"id": "2004.05629", "submitter": "Martin Huber", "authors": "Hannes Wallimann and David Imhof and Martin Huber", "title": "A Machine Learning Approach for Flagging Incomplete Bid-rigging Cartels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for flagging bid rigging, which is particularly\nuseful for detecting incomplete bid-rigging cartels. Our approach combines\nscreens, i.e. statistics derived from the distribution of bids in a tender,\nwith machine learning to predict the probability of collusion. As a\nmethodological innovation, we calculate such screens for all possible subgroups\nof three or four bids within a tender and use summary statistics like the mean,\nmedian, maximum, and minimum of each screen as predictors in the machine\nlearning algorithm. This approach tackles the issue that competitive bids in\nincomplete cartels distort the statistical signals produced by bid rigging. We\ndemonstrate that our algorithm outperforms previously suggested methods in\napplications to incomplete cartels based on empirical data from Switzerland.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 15:04:35 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wallimann", "Hannes", ""], ["Imhof", "David", ""], ["Huber", "Martin", ""]]}, {"id": "2004.05631", "submitter": "Tai-Danae Bradley", "authors": "Tai-Danae Bradley", "title": "At the Interface of Algebra and Statistics", "comments": "135 pages, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math.CT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis takes inspiration from quantum physics to investigate\nmathematical structure that lies at the interface of algebra and statistics.\nThe starting point is a passage from classical probability theory to quantum\nprobability theory. The quantum version of a probability distribution is a\ndensity operator, the quantum version of marginalizing is an operation called\nthe partial trace, and the quantum version of a marginal probability\ndistribution is a reduced density operator. Every joint probability\ndistribution on a finite set can be modeled as a rank one density operator. By\napplying the partial trace, we obtain reduced density operators whose diagonals\nrecover classical marginal probabilities. In general, these reduced densities\nwill have rank higher than one, and their eigenvalues and eigenvectors will\ncontain extra information that encodes subsystem interactions governed by\nstatistics. We decode this information, and show it is akin to conditional\nprobability, and then investigate the extent to which the eigenvectors capture\n\"concepts\" inherent in the original joint distribution. The theory is then\nillustrated with an experiment that exploits these ideas. Turning to a more\ntheoretical application, we also discuss a preliminary framework for modeling\nentailment and concept hierarchy in natural language, namely, by representing\nexpressions in the language as densities. Finally, initial inspiration for this\nthesis comes from formal concept analysis, which finds many striking parallels\nwith the linear algebra. The parallels are not coincidental, and a common\nblueprint is found in category theory. We close with an exposition on free\n(co)completions and how the free-forgetful adjunctions in which they arise\nstrongly suggest that in certain categorical contexts, the \"fixed points\" of a\nmorphism with its adjoint encode interesting information.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 15:22:07 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bradley", "Tai-Danae", ""]]}, {"id": "2004.05665", "submitter": "Biswajit Paria", "authors": "Biswajit Paria, Chih-Kuan Yeh, Ian E.H. Yen, Ning Xu, Pradeep\n  Ravikumar, Barnab\\'as P\\'oczos", "title": "Minimizing FLOPs to Learn Efficient Sparse Representations", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep representation learning has become one of the most widely adopted\napproaches for visual search, recommendation, and identification. Retrieval of\nsuch representations from a large database is however computationally\nchallenging. Approximate methods based on learning compact representations,\nhave been widely explored for this problem, such as locality sensitive hashing,\nproduct quantization, and PCA. In this work, in contrast to learning compact\nrepresentations, we propose to learn high dimensional and sparse\nrepresentations that have similar representational capacity as dense embeddings\nwhile being more efficient due to sparse matrix multiplication operations which\ncan be much faster than dense multiplication. Following the key insight that\nthe number of operations decreases quadratically with the sparsity of\nembeddings provided the non-zero entries are distributed uniformly across\ndimensions, we propose a novel approach to learn such distributed sparse\nembeddings via the use of a carefully constructed regularization function that\ndirectly minimizes a continuous relaxation of the number of floating-point\noperations (FLOPs) incurred during retrieval. Our experiments show that our\napproach is competitive to the other baselines and yields a similar or better\nspeed-vs-accuracy tradeoff on practical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 18:09:02 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Paria", "Biswajit", ""], ["Yeh", "Chih-Kuan", ""], ["Yen", "Ian E. H.", ""], ["Xu", "Ning", ""], ["Ravikumar", "Pradeep", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "2004.05675", "submitter": "Casey Meehan", "authors": "Casey Meehan, Kamalika Chaudhuri, Sanjoy Dasgupta", "title": "A Non-Parametric Test to Detect Data-Copying in Generative Models", "comments": "To be published in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting overfitting in generative models is an important challenge in\nmachine learning. In this work, we formalize a form of overfitting that we call\n{\\em{data-copying}} -- where the generative model memorizes and outputs\ntraining samples or small variations thereof. We provide a three sample\nnon-parametric test for detecting data-copying that uses the training set, a\nseparate sample from the target distribution, and a generated sample from the\nmodel, and study the performance of our test on several canonical models and\ndatasets.\n  For code \\& examples, visit https://github.com/casey-meehan/data-copying\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 18:59:29 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Meehan", "Casey", ""], ["Chaudhuri", "Kamalika", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "2004.05691", "submitter": "Aliaksei Mikhailiuk", "authors": "Aliaksei Mikhailiuk, Clifford Wilmot, Maria Perez-Ortiz, Dingcheng\n  Yue, Rafal Mantiuk", "title": "Active Sampling for Pairwise Comparisons via Approximate Message Passing\n  and Information Gain Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparison data arise in many domains with subjective assessment\nexperiments, for example in image and video quality assessment. In these\nexperiments observers are asked to express a preference between two conditions.\nHowever, many pairwise comparison protocols require a large number of\ncomparisons to infer accurate scores, which may be unfeasible when each\ncomparison is time-consuming (e.g. videos) or expensive (e.g. medical imaging).\nThis motivates the use of an active sampling algorithm that chooses only the\nmost informative pairs for comparison. In this paper we propose ASAP, an active\nsampling algorithm based on approximate message passing and expected\ninformation gain maximization. Unlike most existing methods, which rely on\npartial updates of the posterior distribution, we are able to perform full\nupdates and therefore much improve the accuracy of the inferred scores. The\nalgorithm relies on three techniques for reducing computational cost: inference\nbased on approximate message passing, selective evaluations of the information\ngain, and selecting pairs in a batch that forms a minimum spanning tree of the\ninverse of information gain. We demonstrate, with real and synthetic data, that\nASAP offers the highest accuracy of inferred scores compared to the existing\nmethods. We also provide an open-source GPU implementation of ASAP for\nlarge-scale experiments.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 20:48:10 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mikhailiuk", "Aliaksei", ""], ["Wilmot", "Clifford", ""], ["Perez-Ortiz", "Maria", ""], ["Yue", "Dingcheng", ""], ["Mantiuk", "Rafal", ""]]}, {"id": "2004.05703", "submitter": "Fan Mo", "authors": "Fan Mo, Ali Shahin Shamsabadi, Kleomenis Katevas, Soteris Demetriou,\n  Ilias Leontiadis, Andrea Cavallaro, Hamed Haddadi", "title": "DarkneTZ: Towards Model Privacy at the Edge using Trusted Execution\n  Environments", "comments": "13 pages, 8 figures, accepted to ACM MobiSys 2020", "journal-ref": null, "doi": "10.1145/3386901.3388946", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DarkneTZ, a framework that uses an edge device's Trusted Execution\nEnvironment (TEE) in conjunction with model partitioning to limit the attack\nsurface against Deep Neural Networks (DNNs). Increasingly, edge devices\n(smartphones and consumer IoT devices) are equipped with pre-trained DNNs for a\nvariety of applications. This trend comes with privacy risks as models can leak\ninformation about their training data through effective membership inference\nattacks (MIAs). We evaluate the performance of DarkneTZ, including CPU\nexecution time, memory usage, and accurate power consumption, using two small\nand six large image classification models. Due to the limited memory of the\nedge device's TEE, we partition model layers into more sensitive layers (to be\nexecuted inside the device TEE), and a set of layers to be executed in the\nuntrusted part of the operating system. Our results show that even if a single\nlayer is hidden, we can provide reliable model privacy and defend against state\nof the art MIAs, with only 3% performance overhead. When fully utilizing the\nTEE, DarkneTZ provides model protections with up to 10% overhead.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 21:42:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mo", "Fan", ""], ["Shamsabadi", "Ali Shahin", ""], ["Katevas", "Kleomenis", ""], ["Demetriou", "Soteris", ""], ["Leontiadis", "Ilias", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2004.05707", "submitter": "Zhibin Lu", "authors": "Zhibin Lu, Pan Du, Jian-Yun Nie", "title": "VGCN-BERT: Augmenting BERT with Graph Embedding for Text Classification", "comments": "12 pages, 2 figures", "journal-ref": "in J. M. Jose et al. (Eds.): ECIR 2020, LNCS 12035, pp.369-382,\n  2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much progress has been made recently on text classification with methods\nbased on neural networks. In particular, models using attention mechanism such\nas BERT have shown to have the capability of capturing the contextual\ninformation within a sentence or document. However, their ability of capturing\nthe global information about the vocabulary of a language is more limited. This\nlatter is the strength of Graph Convolutional Networks (GCN). In this paper, we\npropose VGCN-BERT model which combines the capability of BERT with a Vocabulary\nGraph Convolutional Network (VGCN). Local information and global information\ninteract through different layers of BERT, allowing them to influence mutually\nand to build together a final representation for classification. In our\nexperiments on several text classification datasets, our approach outperforms\nBERT and GCN alone, and achieve higher effectiveness than that reported in\nprevious studies.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 22:02:33 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Lu", "Zhibin", ""], ["Du", "Pan", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "2004.05718", "submitter": "Gabriele Corso", "authors": "Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li\\`o, Petar\n  Veli\\v{c}kovi\\'c", "title": "Principal Neighbourhood Aggregation for Graph Nets", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been shown to be effective models for\ndifferent predictive tasks on graph-structured data. Recent work on their\nexpressive power has focused on isomorphism tasks and countable feature spaces.\nWe extend this theoretical framework to include continuous features - which\noccur regularly in real-world input domains and within the hidden layers of\nGNNs - and we demonstrate the requirement for multiple aggregation functions in\nthis context. Accordingly, we propose Principal Neighbourhood Aggregation\n(PNA), a novel architecture combining multiple aggregators with degree-scalers\n(which generalize the sum aggregator). Finally, we compare the capacity of\ndifferent models to capture and exploit the graph structure via a novel\nbenchmark containing multiple tasks taken from classical graph theory,\nalongside existing benchmarks from real-world domains, all of which demonstrate\nthe strength of our model. With this work, we hope to steer some of the GNN\nresearch towards new aggregation methods which we believe are essential in the\nsearch for powerful and robust models.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:30:00 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 16:33:10 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 15:40:07 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 16:36:18 GMT"}, {"version": "v5", "created": "Thu, 31 Dec 2020 08:23:06 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Corso", "Gabriele", ""], ["Cavalleri", "Luca", ""], ["Beaini", "Dominique", ""], ["Li\u00f2", "Pietro", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2004.05758", "submitter": "Jong Chul Ye", "authors": "Yujin Oh, Sangjoon Park, Jong Chul Ye", "title": "Deep Learning COVID-19 Features on CXR using Limited Training Data Sets", "comments": "Accepted for IEEE Trans. on Medical Imaging Special Issue on\n  Imaging-based Diagnosis of COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the global pandemic of COVID-19, the use of artificial intelligence to\nanalyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is\nbecoming important. Unfortunately, due to the emergent nature of the COVID-19\npandemic, a systematic collection of the CXR data set for deep neural network\ntraining is difficult. To address this problem, here we propose a patch-based\nconvolutional neural network approach with a relatively small number of\ntrainable parameters for COVID-19 diagnosis. The proposed method is inspired by\nour statistical analysis of the potential imaging biomarkers of the CXR\nradiographs. Experimental results show that our method achieves\nstate-of-the-art performance and provides clinically interpretable saliency\nmaps, which are useful for COVID-19 diagnosis and patient triage.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 03:44:42 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 16:07:25 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Oh", "Yujin", ""], ["Park", "Sangjoon", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2004.05768", "submitter": "Kun Wang", "authors": "Kun Wang, Jun He, Lei Zhang", "title": "Sequential Weakly Labeled Multi-Activity Localization and Recognition on\n  Wearable Sensors using Recurrent Attention Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity and development of the wearable devices such as\nsmartphones, human activity recognition (HAR) based on sensors has become as a\nkey research area in human computer interaction and ubiquitous computing. The\nemergence of deep learning leads to a recent shift in the research of HAR,\nwhich requires massive strictly labeled data. In comparison with video data,\nactivity data recorded from accelerometer or gyroscope is often more difficult\nto interpret and segment. Recently, several attention mechanisms are proposed\nto handle the weakly labeled human activity data, which do not require accurate\ndata annotation. However, these attention-based models can only handle the\nweakly labeled dataset whose sample includes one target activity, as a result\nit limits efficiency and practicality. In the paper, we propose a recurrent\nattention networks (RAN) to handle sequential weakly labeled multi-activity\nrecognition and location tasks. The model can repeatedly perform steps of\nattention on multiple activities of one sample and each step is corresponding\nto the current focused activity. The effectiveness of the RAN model is\nvalidated on a collected sequential weakly labeled multi-activity dataset and\nthe other two public datasets. The experiment results show that our RAN model\ncan simultaneously infer multi-activity types from the coarse-grained\nsequential weak labels and determine specific locations of every target\nactivity with only knowledge of which types of activities contained in the long\nsequence. It will greatly reduce the burden of manual labeling.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 04:57:09 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:37:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Kun", ""], ["He", "Jun", ""], ["Zhang", "Lei", ""]]}, {"id": "2004.05774", "submitter": "Qiang Zhou", "authors": "Jingjing Gu, Qiang Zhou, Jingyuan Yang, Yanchi Liu, Fuzhen Zhuang,\n  Yanchao Zhao, and Hui Xiong", "title": "Exploiting Interpretable Patterns for Flow Prediction in Dockless Bike\n  Sharing Systems", "comments": "14 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike the traditional dock-based systems, dockless bike-sharing systems are\nmore convenient for users in terms of flexibility. However, the flexibility of\nthese dockless systems comes at the cost of management and operation\ncomplexity. Indeed, the imbalanced and dynamic use of bikes leads to mandatory\nrebalancing operations, which impose a critical need for effective bike traffic\nflow prediction. While efforts have been made in developing traffic flow\nprediction models, existing approaches lack interpretability, and thus have\nlimited value in practical deployment. To this end, we propose an Interpretable\nBike Flow Prediction (IBFP) framework, which can provide effective bike flow\nprediction with interpretable traffic patterns. Specifically, by dividing the\nurban area into regions according to flow density, we first model the\nspatio-temporal bike flows between regions with graph regularized sparse\nrepresentation, where graph Laplacian is used as a smooth operator to preserve\nthe commonalities of the periodic data structure. Then, we extract traffic\npatterns from bike flows using subspace clustering with sparse representation\nto construct interpretable base matrices. Moreover, the bike flows can be\npredicted with the interpretable base matrices and learned parameters. Finally,\nexperimental results on real-world data show the advantages of the IBFP method\nfor flow prediction in dockless bike sharing systems. In addition, the\ninterpretability of our flow pattern exploitation is further illustrated\nthrough a case study where IBFP provides valuable insights into bike flow\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 05:31:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gu", "Jingjing", ""], ["Zhou", "Qiang", ""], ["Yang", "Jingyuan", ""], ["Liu", "Yanchi", ""], ["Zhuang", "Fuzhen", ""], ["Zhao", "Yanchao", ""], ["Xiong", "Hui", ""]]}, {"id": "2004.05785", "submitter": "Anjin Liu", "authors": "Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, Guangquan Zhang", "title": "Learning under Concept Drift: A Review", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering 31, no. 12\n  (2018): 2346-2363", "doi": "10.1109/TKDE.2018.2876857", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift describes unforeseeable changes in the underlying distribution\nof streaming data over time. Concept drift research involves the development of\nmethodologies and techniques for drift detection, understanding and adaptation.\nData analysis has revealed that machine learning in a concept drift environment\nwill result in poor learning results if the drift is not addressed. To help\nresearchers identify which research topics are significant and how to apply\nrelated techniques in data analysis tasks, it is necessary that a high quality,\ninstructive review of current research developments and trends in the concept\ndrift field is conducted. In addition, due to the rapid development of concept\ndrift in recent years, the methodologies of learning under concept drift have\nbecome noticeably systematic, unveiling a framework which has not been\nmentioned in literature. This paper reviews over 130 high quality publications\nin concept drift related research areas, analyzes up-to-date developments in\nmethodologies and techniques, and establishes a framework of learning under\nconcept drift including three main components: concept drift detection, concept\ndrift understanding, and concept drift adaptation. This paper lists and\ndiscusses 10 popular synthetic datasets and 14 publicly available benchmark\ndatasets used for evaluating the performance of learning algorithms aiming at\nhandling concept drift. Also, concept drift related research directions are\ncovered and discussed. By providing state-of-the-art knowledge, this survey\nwill directly support researchers in their understanding of research\ndevelopments in the field of learning under concept drift.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 06:29:56 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lu", "Jie", ""], ["Liu", "Anjin", ""], ["Dong", "Fan", ""], ["Gu", "Feng", ""], ["Gama", "Joao", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2004.05793", "submitter": "Yiqun Liu", "authors": "Yiqun Liu, Shouzhen Chen, Lei Chen, Hai Chu, Xiaoyang Xu, Junping\n  Zhang, Leiming Ma", "title": "STAS: Adaptive Selecting Spatio-Temporal Deep Features for Improving\n  Bias Correction on Precipitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical Weather Prediction (NWP) can reduce human suffering by predicting\ndisastrous precipitation in time. A commonly-used NWP in the world is the\nEuropean Centre for medium-range weather forecasts (EC). However, it is\nnecessary to correct EC forecast through Bias Correcting on Precipitation\n(BCoP) since we still have not fully understood the mechanism of precipitation,\nmaking EC often have some biases. The existing BCoPs suffers from limited prior\ndata and the fixed Spatio-Temporal (ST) scale. We thus propose an end-to-end\ndeep-learning BCoP model named Spatio-Temporal feature Auto-Selective (STAS)\nmodel to select optimal ST regularity from EC via the ST Feature-selective\nMechanisms (SFM/TFM). Given different input features, these two mechanisms can\nautomatically adjust the spatial and temporal scales for correcting.\nExperiments on an EC public dataset indicate that compared with 8 published\nBCoP methods, STAS shows state-of-the-art performance on several criteria of\nBCoP, named threat scores (TS). Further, ablation studies justify that the\nSFM/TFM indeed work well in boosting the performance of BCoP, especially on the\nheavy precipitation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:00:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Yiqun", ""], ["Chen", "Shouzhen", ""], ["Chen", "Lei", ""], ["Chu", "Hai", ""], ["Xu", "Xiaoyang", ""], ["Zhang", "Junping", ""], ["Ma", "Leiming", ""]]}, {"id": "2004.05803", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Weonyoung Joo, Seungjae Shin, Kyungwoo Song, Il-Chul Moon", "title": "Adversarial Likelihood-Free Inference on Black-Box Generator", "comments": "10 pages for the main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) can be viewed as an implicit estimator\nof a data distribution, and this perspective motivates using the adversarial\nconcept in the true input parameter estimation of black-box generators. While\nprevious works on likelihood-free inference introduces an implicit proposal\ndistribution on the generator input, this paper analyzes theoretic limitations\nof the proposal distribution approach. On top of that, we introduce a new\nalgorithm, Adversarial Likelihood-Free Inference (ALFI), to mitigate the\nanalyzed limitations, so ALFI is able to find the posterior distribution on the\ninput parameter for black-box generative models. We experimented ALFI with\ndiverse simulation models as well as pre-trained statistical models, and we\nidentified that ALFI achieves the best parameter estimation accuracy with a\nlimited simulation budget.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:37:56 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:50:27 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kim", "Dongjun", ""], ["Joo", "Weonyoung", ""], ["Shin", "Seungjae", ""], ["Song", "Kyungwoo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2004.05810", "submitter": "Anjin Liu", "authors": "Anjin Liu, Jie Lu, Guangquan Zhang", "title": "Diverse Instances-Weighting Ensemble based on Region Drift Disagreement\n  for Concept Drift Adaptation", "comments": "in IEEE Transactions on Neural Networks and Learning Systems, 2020", "journal-ref": null, "doi": "10.1109/TNNLS.2020.2978523", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift refers to changes in the distribution of underlying data and is\nan inherent property of evolving data streams. Ensemble learning, with dynamic\nclassifiers, has proved to be an efficient method of handling concept drift.\nHowever, the best way to create and maintain ensemble diversity with evolving\nstreams is still a challenging problem. In contrast to estimating diversity via\ninputs, outputs, or classifier parameters, we propose a diversity measurement\nbased on whether the ensemble members agree on the probability of a regional\ndistribution change. In our method, estimations over regional distribution\nchanges are used as instance weights. Constructing different region sets\nthrough different schemes will lead to different drift estimation results,\nthereby creating diversity. The classifiers that disagree the most are selected\nto maximize diversity. Accordingly, an instance-based ensemble learning\nalgorithm, called the diverse instance weighting ensemble (DiwE), is developed\nto address concept drift for data stream classification problems. Evaluations\nof various synthetic and real-world data stream benchmarks show the\neffectiveness and advantages of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:59:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Anjin", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2004.05824", "submitter": "Lotta Meijerink", "authors": "Lotta Meijerink, Giovanni Cin\\`a, Michele Tonutti (Pacmed)", "title": "Uncertainty estimation for classification and risk prediction on medical\n  tabular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a data-scarce field such as healthcare, where models often deliver\npredictions on patients with rare conditions, the ability to measure the\nuncertainty of a model's prediction could potentially lead to improved\neffectiveness of decision support tools and increased user trust. This work\nadvances the understanding of uncertainty estimation for classification and\nrisk prediction on medical tabular data, in a two-fold way. First, we expand\nand refine the set of heuristics to select an uncertainty estimation technique,\nintroducing tests for clinically-relevant scenarios such as generalization to\nuncommon pathologies, changes in clinical protocol and simulations of corrupted\ndata. We furthermore differentiate these heuristics depending on the clinical\nuse-case. Second, we observe that ensembles and related techniques perform\npoorly when it comes to detecting out-of-domain examples, a critical task which\nis carried out more successfully by auto-encoders. These remarks are enriched\nby considerations of the interplay of uncertainty estimation with class\nimbalance, post-modeling calibration and other modeling procedures. Our\nfindings are supported by an array of experiments on toy and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:46:41 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 08:25:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Meijerink", "Lotta", "", "Pacmed"], ["Cin\u00e0", "Giovanni", "", "Pacmed"], ["Tonutti", "Michele", "", "Pacmed"]]}, {"id": "2004.05828", "submitter": "Ziqing Ma", "authors": "Ziqing Ma and Shuming Liu and Guancheng Guo and Xipeng Yu", "title": "Hybrid Attention Networks for Flow and Pressure Forecasting in Water\n  Distribution Systems", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate geo-sensory time series prediction is challenging because of the\ncomplex spatial and temporal correlation. In urban water distribution systems\n(WDS), numerous spatial-correlated sensors have been deployed to continuously\ncollect hydraulic data. Forecasts of monitored flow and pressure time series\nare of vital importance for operational decision making, alerts and anomaly\ndetection. To address this issue, we proposed a hybrid dual-stage\nspatial-temporal attention-based recurrent neural networks (hDS-RNN). Our model\nconsists of two stages: a spatial attention-based encoder and a temporal\nattention-based decoder. Specifically, a hybrid spatial attention mechanism\nthat employs inputs along temporal and spatial axes is proposed. Experiments on\na real-world dataset are conducted and demonstrate that our model outperformed\n9 baseline models in flow and pressure series prediction in WDS.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:00:26 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 03:48:28 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ma", "Ziqing", ""], ["Liu", "Shuming", ""], ["Guo", "Guancheng", ""], ["Yu", "Xipeng", ""]]}, {"id": "2004.05835", "submitter": "Rodolfo Miranda  Pereira", "authors": "Rodolfo M. Pereira, Diego Bertolini, Lucas O. Teixeira, Carlos N.\n  Silla Jr., and Yandre M. G. Costa", "title": "COVID-19 identification in chest X-ray images on flat and hierarchical\n  classification scenarios", "comments": "Accepted for publication in the Computer Methods and Programs in\n  Biomedicine Journal", "journal-ref": null, "doi": "10.1016/j.cmpb.2020.105532", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 can cause severe pneumonia and is estimated to have a high\nimpact on the healthcare system. The standard image diagnosis tests for\npneumonia are chest X-ray (CXR) and computed tomography (CT) scan. CXR are\nuseful in because it is cheaper, faster and more widespread than CT. This study\naims to identify pneumonia caused by COVID-19 from other types and also healthy\nlungs using only CXR images. In order to achieve the objectives, we have\nproposed a classification schema considering the multi-class and hierarchical\nperspectives, since pneumonia can be structured as a hierarchy. Given the\nnatural data imbalance in this domain, we also proposed the use of resampling\nalgorithms in order to re-balance the classes distribution. Our classification\nschema extract features using some well-known texture descriptors and also\nusing a pre-trained CNN model. We also explored early and late fusion\ntechniques in order to leverage the strength of multiple texture descriptors\nand base classifiers at once. To evaluate the approach, we composed a database,\nnamed RYDLS-20, containing CXR images of pneumonia caused by different\npathogens as well as CXR images of healthy lungs. The classes distribution\nfollows a real-world scenario in which some pathogens are more common than\nothers. The proposed approach achieved a macro-avg F1-Score of 0.65 using a\nmulti-class approach and a F1-Score of 0.89 for the COVID-19 identification in\nthe hierarchical classification scenario. As far as we know, we achieved the\nbest nominal rate obtained for COVID-19 identification in an unbalanced\nenvironment with more than three classes. We must also highlight the novel\nproposed hierarchical classification approach for this task, which considers\nthe types of pneumonia caused by the different pathogens and lead us to the\nbest COVID-19 recognition rate obtained here.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:22:32 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 21:46:17 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 14:15:00 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pereira", "Rodolfo M.", ""], ["Bertolini", "Diego", ""], ["Teixeira", "Lucas O.", ""], ["Silla", "Carlos N.", "Jr."], ["Costa", "Yandre M. G.", ""]]}, {"id": "2004.05839", "submitter": "Simone Garatti", "authors": "Marco C. Campi and Simone Garatti", "title": "Scenario optimization with relaxation: a new tool for design and\n  application to machine learning problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario optimization is by now a well established technique to perform\ndesigns in the presence of uncertainty. It relies on domain knowledge\nintegrated with first-hand information that comes from data and generates\nsolutions that are also accompanied by precise statements of reliability. In\nthis paper, following recent developments in (Garatti and Campi, 2019), we\nventure beyond the traditional set-up of scenario optimization by analyzing the\nconcept of constraints relaxation. By a solid theoretical underpinning, this\nnew paradigm furnishes fundamental tools to perform designs that meet a proper\ncompromise between robustness and performance. After suitably expanding the\nscope of constraints relaxation as proposed in (Garatti and Campi, 2019), we\nfocus on various classical Support Vector methods in machine learning -\nincluding SVM (Support Vector Machine), SVR (Support Vector Regression) and\nSVDD (Support Vector Data Description) - and derive new results for the ability\nof these methods to generalize.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:38:25 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 10:34:10 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 19:26:04 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Campi", "Marco C.", ""], ["Garatti", "Simone", ""]]}, {"id": "2004.05849", "submitter": "Yanghong Liu", "authors": "Yanghong Liu and Jia Lu and Tingting Li", "title": "MLPSVM:A new parallel support vector machine to multi-label learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning has attracted the attention of the machine learning\ncommunity. The problem conversion method Binary Relevance converts a familiar\nsingle label into a multi-label algorithm. The binary relevance method is\nwidely used because of its simple structure and efficient algorithm. But binary\nrelevance does not consider the links between labels, making it cumbersome to\nhandle some tasks. This paper proposes a multi-label learning algorithm that\ncan also be used for single-label classification. It is based on standard\nsupport vector machines and changes the original single decision hyperplane\ninto two parallel decision hyper-planes, which call multi-label parallel\nsupport vector machine (MLPSVM). At the end of the article, MLPSVM is compared\nwith other multi-label learning algorithms. The experimental results show that\nthe algorithm performs well on data sets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 10:04:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Yanghong", ""], ["Lu", "Jia", ""], ["Li", "Tingting", ""]]}, {"id": "2004.05867", "submitter": "Wei Huang", "authors": "Wei Huang and Weitao Du and Richard Yi Da Xu", "title": "On the Neural Tangent Kernel of Deep Networks with Orthogonal\n  Initialization", "comments": "revised theorems and completed proofs", "journal-ref": "IJCAI 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevailing thinking is that orthogonal weights are crucial to enforcing\ndynamical isometry and speeding up training. The increase in learning speed\nthat results from orthogonal initialization in linear networks has been\nwell-proven. However, while the same is believed to also hold for nonlinear\nnetworks when the dynamical isometry condition is satisfied, the training\ndynamics behind this contention have not been thoroughly explored. In this\nwork, we study the dynamics of ultra-wide networks across a range of\narchitectures, including Fully Connected Networks (FCNs) and Convolutional\nNeural Networks (CNNs) with orthogonal initialization via neural tangent kernel\n(NTK). Through a series of propositions and lemmas, we prove that two NTKs, one\ncorresponding to Gaussian weights and one to orthogonal weights, are equal when\nthe network width is infinite. Further, during training, the NTK of an\northogonally-initialized infinite-width network should theoretically remain\nconstant. This suggests that the orthogonal initialization cannot speed up\ntraining in the NTK (lazy training) regime, contrary to the prevailing\nthoughts. In order to explore under what circumstances can orthogonality\naccelerate training, we conduct a thorough empirical investigation outside the\nNTK regime. We find that when the hyper-parameters are set to achieve a linear\nregime in nonlinear activation, orthogonal initialization can improve the\nlearning speed with a large learning rate or large depth.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 11:12:53 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:10:55 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 06:06:05 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 08:08:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Huang", "Wei", ""], ["Du", "Weitao", ""], ["Da Xu", "Richard Yi", ""]]}, {"id": "2004.05884", "submitter": "Dongxian Wu", "authors": "Dongxian Wu, Shu-tao Xia, Yisen Wang", "title": "Adversarial Weight Perturbation Helps Robust Generalization", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study on improving the robustness of deep neural networks against\nadversarial examples grows rapidly in recent years. Among them, adversarial\ntraining is the most promising one, which flattens the input loss landscape\n(loss change with respect to input) via training on adversarially perturbed\nexamples. However, how the widely used weight loss landscape (loss change with\nrespect to weight) performs in adversarial training is rarely explored. In this\npaper, we investigate the weight loss landscape from a new perspective, and\nidentify a clear correlation between the flatness of weight loss landscape and\nrobust generalization gap. Several well-recognized adversarial training\nimprovements, such as early stopping, designing new objective functions, or\nleveraging unlabeled data, all implicitly flatten the weight loss landscape.\nBased on these observations, we propose a simple yet effective Adversarial\nWeight Perturbation (AWP) to explicitly regularize the flatness of weight loss\nlandscape, forming a double-perturbation mechanism in the adversarial training\nframework that adversarially perturbs both inputs and weights. Extensive\nexperiments demonstrate that AWP indeed brings flatter weight loss landscape\nand can be easily incorporated into various existing adversarial training\nmethods to further boost their adversarial robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 12:05:01 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:46:09 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Wu", "Dongxian", ""], ["Xia", "Shu-tao", ""], ["Wang", "Yisen", ""]]}, {"id": "2004.05898", "submitter": "Yash Akhauri", "authors": "Yash Akhauri", "title": "Exposing Hardware Building Blocks to Machine Learning Frameworks", "comments": "62 pages, 22 figures, 14 tables", "journal-ref": null, "doi": "10.13140/RG.2.2.31661.23527", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a plethora of applications that demand high throughput and low\nlatency algorithms leveraging machine learning methods. This need for real time\nprocessing can be seen in industries ranging from developing neural network\nbased pre-distortors for enhanced mobile broadband to designing FPGA-based\ntriggers in major scientific efforts by CERN for particle physics. In this\nthesis, we explore how niche domains can benefit vastly if we look at neurons\nas a unique boolean function of the form $f:B^{I} \\rightarrow B^{O}$, where $B\n= \\{0,1\\}$. We focus on how to design topologies that complement such a view of\nneurons, how to automate such a strategy of neural network design, and\ninference of such networks on Xilinx FPGAs. Major hardware borne constraints\narise when designing topologies that view neurons as unique boolean functions.\nFundamentally, realizing such topologies on hardware asserts a strict limit on\nthe 'fan-in' bits of a neuron due to the doubling of permutations possible with\nevery increment in input bit-length. We address this limit by exploring\ndifferent methods of implementing sparsity and explore activation quantization.\nFurther, we develop a library that supports training a neural network with\ncustom sparsity and quantization. This library also supports conversion of\ntrained Sparse Quantized networks from PyTorch to VERILOG code which is then\nsynthesized using Vivado, all of which is part of the LogicNet tool-flow. To\naid faster prototyping, we also support calculation of the worst-case hardware\ncost of any given topology. We hope that our insights into the behavior of\nextremely sparse quantized neural networks are of use to the research community\nand by extension allow people to use the LogicNet design flow to deploy highly\nefficient neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 14:26:00 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Akhauri", "Yash", ""]]}, {"id": "2004.05910", "submitter": "Xueshuang Xiang", "authors": "Meiyu Huang, Xueshuang Xiang, Yao Xu", "title": "Training few-shot classification via the perspective of minibatch and\n  pretraining", "comments": "arXiv admin note: text overlap with arXiv:1803.00676 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification is a challenging task which aims to formulate the\nability of humans to learn concepts from limited prior data and has drawn\nconsiderable attention in machine learning. Recent progress in few-shot\nclassification has featured meta-learning, in which a parameterized model for a\nlearning algorithm is defined and trained to learn the ability of handling\nclassification tasks on extremely large or infinite episodes representing\ndifferent classification task, each with a small labeled support set and its\ncorresponding query set. In this work, we advance this few-shot classification\nparadigm by formulating it as a supervised classification learning problem. We\nfurther propose multi-episode and cross-way training techniques, which\nrespectively correspond to the minibatch and pretraining in classification\nproblems. Experimental results on a state-of-the-art few-shot classification\nmethod (prototypical networks) demonstrate that both the proposed training\nstrategies can highly accelerate the training process without accuracy loss for\nvarying few-shot classification problems on Omniglot and miniImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 03:14:48 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Huang", "Meiyu", ""], ["Xiang", "Xueshuang", ""], ["Xu", "Yao", ""]]}, {"id": "2004.05912", "submitter": "Xueshuang Xiang", "authors": "Xuejiao Liu, Yao Xu, Xueshuang Xiang", "title": "Towards GANs' Approximation Ability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have attracted intense interest in the\nfield of generative models. However, few investigations focusing either on the\ntheoretical analysis or on algorithm design for the approximation ability of\nthe generator of GANs have been reported. This paper will first theoretically\nanalyze GANs' approximation property. Similar to the universal approximation\nproperty of the fully connected neural networks with one hidden layer, we prove\nthat the generator with the input latent variable in GANs can universally\napproximate the potential data distribution given the increasing hidden\nneurons. Furthermore, we propose an approach named stochastic data generation\n(SDG) to enhance GANs'approximation ability. Our approach is based on the\nsimple idea of imposing randomness through data generation in GANs by a prior\ndistribution on the conditional probability between the layers. SDG approach\ncan be easily implemented by using the reparameterization trick. The\nexperimental results on synthetic dataset verify the improved approximation\nability obtained by this SDG approach. In the practical dataset, four GANs\nusing SDG can also outperform the corresponding traditional GANs when the model\narchitectures are smaller.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:40:16 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 06:00:08 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Liu", "Xuejiao", ""], ["Xu", "Yao", ""], ["Xiang", "Xueshuang", ""]]}, {"id": "2004.05913", "submitter": "Xueshuang Xiang", "authors": "Haidong Xie, Lixin Qian, Xueshuang Xiang, Naijin Liu", "title": "Blind Adversarial Pruning: Balance Accuracy, Efficiency and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of interest in the attack and defense of deep neural\nnetworks, researchers are focusing more on the robustness of applying them to\ndevices with limited memory. Thus, unlike adversarial training, which only\nconsiders the balance between accuracy and robustness, we come to a more\nmeaningful and critical issue, i.e., the balance among accuracy, efficiency and\nrobustness (AER). Recently, some related works focused on this issue, but with\ndifferent observations, and the relations among AER remain unclear. This paper\nfirst investigates the robustness of pruned models with different compression\nratios under the gradual pruning process and concludes that the robustness of\nthe pruned model drastically varies with different pruning processes,\nespecially in response to attacks with large strength. Second, we test the\nperformance of mixing the clean data and adversarial examples (generated with a\nprescribed uniform budget) into the gradual pruning process, called adversarial\npruning, and find the following: the pruned model's robustness exhibits high\nsensitivity to the budget. Furthermore, to better balance the AER, we propose\nan approach called blind adversarial pruning (BAP), which introduces the idea\nof blind adversarial training into the gradual pruning process. The main idea\nis to use a cutoff-scale strategy to adaptively estimate a nonuniform budget to\nmodify the AEs used during pruning, thus ensuring that the strengths of AEs are\ndynamically located within a reasonable range at each pruning step and\nultimately improving the overall AER of the pruned model. The experimental\nresults obtained using BAP for pruning classification models based on several\nbenchmarks demonstrate the competitive performance of this method: the\nrobustness of the model pruned by BAP is more stable among varying pruning\nprocesses, and BAP exhibits better overall AER than adversarial pruning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:27:48 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Xie", "Haidong", ""], ["Qian", "Lixin", ""], ["Xiang", "Xueshuang", ""], ["Liu", "Naijin", ""]]}, {"id": "2004.05914", "submitter": "Xueshuang Xiang", "authors": "Haidong Xie, Xueshuang Xiang, Naijin Liu, Bin Dong", "title": "Blind Adversarial Training: Balance Accuracy and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) aims to improve the robustness of deep learning\nmodels by mixing clean data and adversarial examples (AEs). Most existing AT\napproaches can be grouped into restricted and unrestricted approaches.\nRestricted AT requires a prescribed uniform budget to constrain the magnitude\nof the AE perturbations during training, with the obtained results showing high\nsensitivity to the budget. On the other hand, unrestricted AT uses\nunconstrained AEs, resulting in the use of AEs located beyond the decision\nboundary; these overestimated AEs significantly lower the accuracy on clean\ndata. These limitations mean that the existing AT approaches have difficulty in\nobtaining a comprehensively robust model with high accuracy and robustness when\nconfronting attacks with varying strengths. Considering this problem, this\npaper proposes a novel AT approach named blind adversarial training (BAT) to\nbetter balance the accuracy and robustness. The main idea of this approach is\nto use a cutoff-scale strategy to adaptively estimate a nonuniform budget to\nmodify the AEs used in the training, ensuring that the strengths of the AEs are\ndynamically located in a reasonable range and ultimately improving the overall\nrobustness of the AT model. The experimental results obtained using BAT for\ntraining classification models on several benchmarks demonstrate the\ncompetitive performance of this method.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:16:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Xie", "Haidong", ""], ["Xiang", "Xueshuang", ""], ["Liu", "Naijin", ""], ["Dong", "Bin", ""]]}, {"id": "2004.05915", "submitter": "Navid Khoshavi", "authors": "Navid Khoshavi, Connor Broyles, and Yu Bi", "title": "A Survey on Impact of Transient Faults on BNN Inference Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over past years, the philosophy for designing the artificial intelligence\nalgorithms has significantly shifted towards automatically extracting the\ncomposable systems from massive data volumes. This paradigm shift has been\nexpedited by the big data booming which enables us to easily access and analyze\nthe highly large data sets. The most well-known class of big data analysis\ntechniques is called deep learning. These models require significant\ncomputation power and extremely high memory accesses which necessitate the\ndesign of novel approaches to reduce the memory access and improve power\nefficiency while taking into account the development of domain-specific\nhardware accelerators to support the current and future data sizes and model\nstructures.The current trends for designing application-specific integrated\ncircuits barely consider the essential requirement for maintaining the complex\nneural network computation to be resilient in the presence of soft errors. The\nsoft errors might strike either memory storage or combinational logic in the\nhardware accelerator that can affect the architectural behavior such that the\nprecision of the results fall behind the minimum allowable correctness. In this\nstudy, we demonstrate that the impact of soft errors on a customized deep\nlearning algorithm called Binarized Neural Network might cause drastic image\nmisclassification. Our experimental results show that the accuracy of image\nclassifier can drastically drop by 76.70% and 19.25% in lfcW1A1 and cnvW1A1\nnetworks,respectively across CIFAR-10 and MNIST datasets during the fault\ninjection for the worst-case scenarios\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:15:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Khoshavi", "Navid", ""], ["Broyles", "Connor", ""], ["Bi", "Yu", ""]]}, {"id": "2004.05923", "submitter": "Giacomo De Palma", "authors": "Giacomo De Palma, Bobak T. Kiani and Seth Lloyd", "title": "Adversarial Robustness Guarantees for Random Deep Neural Networks", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139:2522-2534, 2021", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math-ph math.MP quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliability of deep learning algorithms is fundamentally challenged by\nthe existence of adversarial examples, which are incorrectly classified inputs\nthat are extremely close to a correctly classified input. We explore the\nproperties of adversarial examples for deep neural networks with random weights\nand biases, and prove that for any $p\\ge1$, the $\\ell^p$ distance of any given\ninput from the classification boundary scales as one over the square root of\nthe dimension of the input times the $\\ell^p$ norm of the input. The results\nare based on the recently proved equivalence between Gaussian processes and\ndeep neural networks in the limit of infinite width of the hidden layers, and\nare validated with experiments on both random deep neural networks and deep\nneural networks trained on the MNIST and CIFAR10 datasets. The results\nconstitute a fundamental advance in the theoretical understanding of\nadversarial examples, and open the way to a thorough theoretical\ncharacterization of the relation between network architecture and robustness to\nadversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:07:26 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:53:02 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["De Palma", "Giacomo", ""], ["Kiani", "Bobak T.", ""], ["Lloyd", "Seth", ""]]}, {"id": "2004.05930", "submitter": "Francesco Conti", "authors": "Francesco Conti", "title": "Technical Report: NEMO DNN Quantization for Deployment Model", "comments": "12 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report aims at defining a formal framework for Deep Neural\nNetwork (DNN) layer-wise quantization, focusing in particular on the problems\nrelated to the final deployment. It also acts as a documentation for the NEMO\n(NEural Minimization for pytOrch) framework. It describes the four DNN\nrepresentations used in NEMO (FullPrecision, FakeQuantized, QuantizedDeployable\nand IntegerDeployable), focusing in particular on a formal definition of the\nlatter two. An important feature of this model, and in particular the\nIntegerDeployable representation, is that it enables DNN inference using purely\nintegers - without resorting to real-valued numbers in any part of the\ncomputation and without relying on an explicit fixed-point numerical\nrepresentation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:23:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Conti", "Francesco", ""]]}, {"id": "2004.05944", "submitter": "Min Ye", "authors": "Min Ye", "title": "Exact recovery and sharp thresholds of Stochastic Ising Block Model", "comments": "Fixed a gap in the original proof of Theorem 5. The new proof of\n  Theorem 5 relies on Lemma 5, which is the main new element in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model (SBM) is a random graph model in which the edges\nare generated according to the underlying cluster structure on the vertices.\nThe (ferromagnetic) Ising model, on the other hand, assigns $\\pm 1$ labels to\nvertices according to an underlying graph structure in a way that if two\nvertices are connected in the graph then they are more likely to be assigned\nthe same label. In SBM, one aims to recover the underlying clusters from the\ngraph structure while in Ising model, an extensively-studied problem is to\nrecover the underlying graph structure based on i.i.d. samples (labelings of\nthe vertices).\n  In this paper, we propose a natural composition of SBM and the Ising model,\nwhich we call the Stochastic Ising Block Model (SIBM). In SIBM, we take SBM in\nits simplest form, where $n$ vertices are divided into two equal-sized clusters\nand the edges are connected independently with probability $p$ within clusters\nand $q$ across clusters. Then we use the graph $G$ generated by the SBM as the\nunderlying graph of the Ising model and draw $m$ i.i.d. samples from it. The\nobjective is to exactly recover the two clusters in SBM from the samples\ngenerated by the Ising model, without observing the graph $G$. As the main\nresult of this paper, we establish a sharp threshold $m^\\ast$ on the sample\ncomplexity of this exact recovery problem in a properly chosen regime, where\n$m^\\ast$ can be calculated from the parameters of SIBM. We show that when $m\\ge\nm^\\ast$, one can recover the clusters from $m$ samples in $O(n)$ time as the\nnumber of vertices $n$ goes to infinity. When $m<m^\\ast$, we further show that\nfor almost all choices of parameters of SIBM, the success probability of any\nrecovery algorithms approaches $0$ as $n\\to\\infty$.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:59:13 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 02:52:37 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 07:21:59 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Ye", "Min", ""]]}, {"id": "2004.05958", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Madson L. D. Dias, C\\'esar Lincoln C. Mattos, Ticiana L. C. da Silva,\n  Jos\\'e Ant\\^onio F. de Macedo, Wellington C. P. Silva", "title": "Anomaly Detection in Trajectory Data with Normalizing Flows", "comments": "Accepted as a conference paper at 2020 International Joint Conference\n  on Neural Networks (IJCNN 2020), part of 2020 IEEE World Congress on\n  Computational Intelligence (IEEE WCCI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of detecting anomalous data patterns is as important in practical\napplications as challenging. In the context of spatial data, recognition of\nunexpected trajectories brings additional difficulties, such as high\ndimensionality and varying pattern lengths. We aim to tackle such a problem\nfrom a probability density estimation point of view, since it provides an\nunsupervised procedure to identify out of distribution samples. More\nspecifically, we pursue an approach based on normalizing flows, a recent\nframework that enables complex density estimation from data with neural\nnetworks. Our proposal computes exact model likelihood values, an important\nfeature of normalizing flows, for each segment of the trajectory. Then, we\naggregate the segments' likelihoods into a single coherent trajectory anomaly\nscore. Such a strategy enables handling possibly large sequences with different\nlengths. We evaluate our methodology, named aggregated anomaly detection with\nnormalizing flows (GRADINGS), using real world trajectory data and compare it\nwith more traditional anomaly detection techniques. The promising results\nobtained in the performed computational experiments indicate the feasibility of\nthe GRADINGS, specially the variant that considers autoregressive normalizing\nflows.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 14:16:40 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dias", "Madson L. D.", ""], ["Mattos", "C\u00e9sar Lincoln C.", ""], ["da Silva", "Ticiana L. C.", ""], ["de Macedo", "Jos\u00e9 Ant\u00f4nio F.", ""], ["Silva", "Wellington C. P.", ""]]}, {"id": "2004.05988", "submitter": "Huajie Shao", "authors": "Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu,\n  Dongxin Liu, Jun Wang, Tarek Abdelzaher", "title": "ControlVAE: Controllable Variational Autoencoder", "comments": "accepted by ICML2020", "journal-ref": "37th proceedings of ICML, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAE) and their variants have been widely used in a\nvariety of applications, such as dialog generation, image generation and\ndisentangled representation learning. However, the existing VAE models have\nsome limitations in different applications. For example, a VAE easily suffers\nfrom KL vanishing in language modeling and low reconstruction quality for\ndisentangling. To address these issues, we propose a novel controllable\nvariational autoencoder framework, ControlVAE, that combines a controller,\ninspired by automatic control theory, with the basic VAE to improve the\nperformance of resulting generative models. Specifically, we design a new\nnon-linear PI controller, a variant of the proportional-integral-derivative\n(PID) control, to automatically tune the hyperparameter (weight) added in the\nVAE objective using the output KL-divergence as feedback during model training.\nThe framework is evaluated using three applications; namely, language modeling,\ndisentangled representation learning, and image generation. The results show\nthat ControlVAE can achieve better disentangling and reconstruction quality\nthan the existing methods. For language modelling, it not only averts the\nKL-vanishing, but also improves the diversity of generated text. Finally, we\nalso demonstrate that ControlVAE improves the reconstruction quality of\ngenerated images compared to the original VAE.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:04:56 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 02:07:55 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 12:56:11 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 15:59:27 GMT"}, {"version": "v5", "created": "Sat, 20 Jun 2020 20:21:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Shao", "Huajie", ""], ["Yao", "Shuochao", ""], ["Sun", "Dachun", ""], ["Zhang", "Aston", ""], ["Liu", "Shengzhong", ""], ["Liu", "Dongxin", ""], ["Wang", "Jun", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2004.05990", "submitter": "Takeyuki Sasai", "authors": "Takeyuki Sasai and Hironori Fujisawa", "title": "Robust estimation with Lasso when outputs are adversarially contaminated", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust estimation when outputs are adversarially contaminated.\nNguyen and Tran (2012) proposed an extended Lasso for robust parameter\nestimation and then they showed the convergence rate of the estimation error.\nRecently, Dalalyan and Thompson (2019) gave some useful inequalities and then\nthey showed a faster convergence rate than Nguyen and Tran (2012). They focused\non the fact that the minimization problem of the extended Lasso can become that\nof the penalized Huber loss function with $L_1$ penalty. The distinguishing\npoint is that the Huber loss function includes an extra tuning parameter, which\nis different from the conventional method. We give the proof, which is\ndifferent from Dalalyan and Thompson (2019) and then we give the same\nconvergence rate as Dalalyan and Thompson (2019). The significance of our proof\nis to use some specific properties of the Huber function. Such techniques have\nnot been used in the past proofs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:06:45 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 17:13:44 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 16:01:45 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2020 06:22:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sasai", "Takeyuki", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "2004.05991", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, Mayank Meghwanshi, Bamdev Mishra", "title": "A Simple Approach to Learning Unsupervised Multilingual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on unsupervised learning of cross-lingual embeddings in\nbilingual setting has given impetus to learning a shared embedding space for\nseveral languages without any supervision. A popular framework to solve the\nlatter problem is to jointly solve the following two sub-problems: 1) learning\nunsupervised word alignment between several pairs of languages, and 2) learning\nhow to map the monolingual embeddings of every language to a shared\nmultilingual space. In contrast, we propose a simple, two-stage framework in\nwhich we decouple the above two sub-problems and solve them separately using\nexisting techniques. The proposed approach obtains surprisingly good\nperformance in various tasks such as bilingual lexicon induction, cross-lingual\nword similarity, multilingual document classification, and multilingual\ndependency parsing. When distant languages are involved, the proposed solution\nillustrates robustness and outperforms existing unsupervised multilingual word\nembedding approaches. Overall, our experimental results encourage development\nof multi-stage models for such challenging problems.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 05:54:10 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 15:17:01 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Meghwanshi", "Mayank", ""], ["Mishra", "Bamdev", ""]]}, {"id": "2004.05994", "submitter": "Stanis{\\l}aw Purga{\\l}", "authors": "Stanis{\\l}aw Purga{\\l}", "title": "Improving Expressivity of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Graph Neural Network with greater expressive power than commonly\nused GNNs - not constrained to only differentiate between graphs that\nWeisfeiler-Lehman test recognizes to be non-isomorphic. We use a graph\nattention network with expanding attention window that aggregates information\nfrom nodes exponentially far away. We also use partially random initial\nembeddings, allowing differentiation between nodes that would otherwise look\nthe same. This could cause problem with a traditional dropout mechanism,\ntherefore we use a \"head dropout\", randomly ignoring some attention heads\nrather than some dimensions of the embedding.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:24:58 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Purga\u0142", "Stanis\u0142aw", ""]]}, {"id": "2004.06014", "submitter": "Yedid Hoshen", "authors": "Yael Vinker and Nir Zabari and Yedid Hoshen", "title": "Training End-to-end Single Image Generators without GANs", "comments": "Project page: http://www.vision.huji.ac.il/augurone", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AugurOne, a novel approach for training single image generative\nmodels. Our approach trains an upscaling neural network using non-affine\naugmentations of the (single) input image, particularly including non-rigid\nthin plate spline image warps. The extensive augmentations significantly\nincrease the in-sample distribution for the upsampling network enabling the\nupscaling of highly variable inputs. A compact latent space is jointly learned\nallowing for controlled image synthesis. Differently from Single Image GAN, our\napproach does not require GAN training and takes place in an end-to-end fashion\nallowing fast and stable training. We experimentally evaluate our method and\nshow that it obtains compelling novel animations of single-image, as well as,\nstate-of-the-art performance on conditional generation tasks e.g.\npaint-to-image and edges-to-image.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:58:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Vinker", "Yael", ""], ["Zabari", "Nir", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2004.06025", "submitter": "Abhijeet Awasthi", "authors": "Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal, Sunita Sarawagi", "title": "Learning from Rules Generalizing Labeled Exemplars", "comments": "ICLR 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications labeled data is not readily available, and needs to be\ncollected via pain-staking human supervision. We propose a rule-exemplar method\nfor collecting human supervision to combine the efficiency of rules with the\nquality of instance labels. The supervision is coupled such that it is both\nnatural for humans and synergistic for learning. We propose a training\nalgorithm that jointly denoises rules via latent coverage variables, and trains\nthe model through a soft implication loss over the coverage and label\nvariables. The denoised rules and trained model are used jointly for inference.\nEmpirical evaluation on five different tasks shows that (1) our algorithm is\nmore accurate than several existing methods of learning from a mix of clean and\nnoisy supervision, and (2) the coupled rule-exemplar supervision is effective\nin denoising rules.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:57:54 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:56:59 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Awasthi", "Abhijeet", ""], ["Ghosh", "Sabyasachi", ""], ["Goyal", "Rasna", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "2004.06030", "submitter": "Yilun Du", "authors": "Yilun Du, Shuang Li, Igor Mordatch", "title": "Compositional Visual Generation and Inference with Energy Based Models", "comments": "NeurIPS 2020 Spotlight; Website at\n  https://energy-based-model.github.io/compositional-generation-inference/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vital aspect of human intelligence is the ability to compose increasingly\ncomplex concepts out of simpler ideas, enabling both rapid learning and\nadaptation of knowledge. In this paper we show that energy-based models can\nexhibit this ability by directly combining probability distributions. Samples\nfrom the combined distribution correspond to compositions of concepts. For\nexample, given a distribution for smiling faces, and another for male faces, we\ncan combine them to generate smiling male faces. This allows us to generate\nnatural images that simultaneously satisfy conjunctions, disjunctions, and\nnegations of concepts. We evaluate compositional generation abilities of our\nmodel on the CelebA dataset of natural faces and synthetic 3D scene images. We\nalso demonstrate other unique advantages of our model, such as the ability to\ncontinually learn and incorporate new concepts, or infer compositions of\nconcept properties underlying an image.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:01:40 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 22:50:40 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 09:26:00 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Du", "Yilun", ""], ["Li", "Shuang", ""], ["Mordatch", "Igor", ""]]}, {"id": "2004.06046", "submitter": "Hamad Ahmed", "authors": "Hamad Ahmed, Ronnie B Wilbur, Hari M Bharadwaj, and Jeffrey Mark\n  Siskind", "title": "Object classification from randomized EEG trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New results suggest strong limits to the feasibility of classifying human\nbrain activity evoked from image stimuli, as measured through EEG. Considerable\nprior work suffers from a confound between the stimulus class and the time\nsince the start of the experiment. A prior attempt to avoid this confound using\nrandomized trials was unable to achieve results above chance in a statistically\nsignificant fashion when the data sets were of the same size as the original\nexperiments. Here, we again attempt to replicate these experiments with\nrandomized trials on a far larger (20x) dataset of 1,000 stimulus presentations\nof each of forty classes, all from a single subject. To our knowledge, this is\nthe largest such EEG data collection effort from a single subject and is at the\nbounds of feasibility. We obtain classification accuracy that is marginally\nabove chance and above chance in a statistically significant fashion, and\nfurther assess how accuracy depends on the classifier used, the amount of\ntraining data used, and the number of classes. Reaching the limits of data\ncollection without substantial improvement in classification accuracy suggests\nlimits to the feasibility of this enterprise.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 22:06:11 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Ahmed", "Hamad", ""], ["Wilbur", "Ronnie B", ""], ["Bharadwaj", "Hari M", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "2004.06069", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Michael Flynn, James Large, Jason Lines and Matthew\n  Middlehurst", "title": "A tale of two toolkits, report the third: on the usage and performance\n  of HIVE-COTE v1.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Vote Collective of Transformation-based Ensembles\n(HIVE-COTE) is a heterogeneous meta ensemble for time series classification.\nSince it was first proposed in 2016, the algorithm has undergone some minor\nchanges and there is now a configurable, scalable and easy to use version\navailable in two open source repositories. We present an overview of the latest\nstable HIVE-COTE, version 1.0, and describe how it differs to the original. We\nprovide a walkthrough guide of how to use the classifier, and conduct extensive\nexperimental evaluation of its predictive performance and resource usage. We\ncompare the performance of HIVE-COTE to three recently proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:09:48 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 11:17:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bagnall", "Anthony", ""], ["Flynn", "Michael", ""], ["Large", "James", ""], ["Lines", "Jason", ""], ["Middlehurst", "Matthew", ""]]}, {"id": "2004.06089", "submitter": "Ted Xiao", "authors": "Ted Xiao, Eric Jang, Dmitry Kalashnikov, Sergey Levine, Julian Ibarz,\n  Karol Hausman, Alexander Herzog", "title": "Thinking While Moving: Deep Reinforcement Learning with Concurrent\n  Control", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study reinforcement learning in settings where sampling an action from the\npolicy must be done concurrently with the time evolution of the controlled\nsystem, such as when a robot must decide on the next action while still\nperforming the previous action. Much like a person or an animal, the robot must\nthink and move at the same time, deciding on its next action before the\nprevious one has completed. In order to develop an algorithmic framework for\nsuch concurrent control problems, we start with a continuous-time formulation\nof the Bellman equations, and then discretize them in a way that is aware of\nsystem delays. We instantiate this new class of approximate dynamic programming\nmethods via a simple architectural extension to existing value-based deep\nreinforcement learning algorithms. We evaluate our methods on simulated\nbenchmark tasks and a large-scale robotic grasping task where the robot must\n\"think while moving\".\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:49:29 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:31:07 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 23:22:39 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 21:19:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xiao", "Ted", ""], ["Jang", "Eric", ""], ["Kalashnikov", "Dmitry", ""], ["Levine", "Sergey", ""], ["Ibarz", "Julian", ""], ["Hausman", "Karol", ""], ["Herzog", "Alexander", ""]]}, {"id": "2004.06093", "submitter": "Lek-Heng Lim", "authors": "Gregory Naitzat, Andrey Zhitnikov, and Lek-Heng Lim", "title": "Topology of deep neural networks", "comments": "34 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the topology of a data set $M = M_a \\cup M_b \\subseteq\n\\mathbb{R}^d$, representing two classes $a$ and $b$ in a binary classification\nproblem, changes as it passes through the layers of a well-trained neural\nnetwork, i.e., with perfect accuracy on training set and near-zero\ngeneralization error ($\\approx 0.01\\%$). The goal is to shed light on two\nmysteries in deep neural networks: (i) a nonsmooth activation function like\nReLU outperforms a smooth one like hyperbolic tangent; (ii) successful neural\nnetwork architectures rely on having many layers, even though a shallow network\ncan approximate any function arbitrary well. We performed extensive experiments\non the persistent homology of a wide range of point cloud data sets, both real\nand simulated. The results consistently demonstrate the following: (1) Neural\nnetworks operate by changing topology, transforming a topologically complicated\ndata set into a topologically simple one as it passes through the layers. No\nmatter how complicated the topology of $M$ we begin with, when passed through a\nwell-trained neural network $f : \\mathbb{R}^d \\to \\mathbb{R}^p$, there is a\nvast reduction in the Betti numbers of both components $M_a$ and $M_b$; in fact\nthey nearly always reduce to their lowest possible values:\n$\\beta_k\\bigl(f(M_i)\\bigr) = 0$ for $k \\ge 1$ and $\\beta_0\\bigl(f(M_i)\\bigr) =\n1$, $i =a, b$. Furthermore, (2) the reduction in Betti numbers is significantly\nfaster for ReLU activation than hyperbolic tangent activation as the former\ndefines nonhomeomorphic maps that change topology, whereas the latter defines\nhomeomorphic maps that preserve topology. Lastly, (3) shallow and deep networks\ntransform data sets differently -- a shallow network operates mainly through\nchanging geometry and changes topology only in its final layers, a deep one\nspreads topological changes more evenly across all layers.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:53:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Naitzat", "Gregory", ""], ["Zhitnikov", "Andrey", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "2004.06111", "submitter": "Martina Mammarella Dr.", "authors": "Teodoro Alamo and Daniel G. Reina and Martina Mammarella and Alberto\n  Abella", "title": "Open Data Resources for Fighting COVID-19", "comments": "30 pages Minor improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an insight into the open data resources pertinent to the study of\nthe spread of Covid-19 pandemic and its control. We identify the variables\nrequired to analyze fundamental aspects like seasonal behaviour, regional\nmortality rates, and effectiveness of government measures. Open data resources,\nalong with data-driven methodologies, provide many opportunities to improve the\nresponse of the different administrations to the virus. We describe the present\nlimitations and difficulties encountered in most of the open-data resources. To\nfacilitate the access to the main open-data portals and resources, we identify\nthe most relevant institutions, at a world scale, providing Covid-19\ninformation and/or auxiliary variables (demographics, mobility, etc.). We also\ndescribe several open resources to access Covid-19 data-sets at a country-wide\nlevel (i.e. China, Italy, Spain, France, Germany, U.S., etc.). In an attempt to\nfacilitate the rapid response to the study of the seasonal behaviour of\nCovid-19, we enumerate the main open resources in terms of weather and climate\nvariables. CONCO-Team: The authors of this paper belong to the CONtrol COvid-19\nTeam, which is composed of different researches from universities of Spain,\nItaly, France, Germany, United Kingdom and Argentina. The main goal of\nCONCO-Team is to develop data-driven methods for the better understanding and\ncontrol of the pandemic.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:52:53 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 09:56:29 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 13:38:06 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Alamo", "Teodoro", ""], ["Reina", "Daniel G.", ""], ["Mammarella", "Martina", ""], ["Abella", "Alberto", ""]]}, {"id": "2004.06149", "submitter": "Cscott Brown", "authors": "CScott Brown", "title": "Local Model Feature Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local learning methods are a popular class of machine learning algorithms.\nThe basic idea for the entire cadre is to choose some non-local model family,\nto train many of them on small sections of neighboring data, and then to\n`stitch' the resulting models together in some way. Due to the limits of\nconstraining a training dataset to a small neighborhood, research on\nlocally-learned models has largely been restricted to simple model families.\nAlso, since simple model families have no complex structure by design, this has\nlimited use of the individual local models to predictive tasks. We hypothesize\nthat, using a sufficiently complex local model family, various properties of\nthe individual local models, such as their learned parameters, can be used as\nfeatures for further learning. This dissertation improves upon the current\nstate of research and works toward establishing this hypothesis by\ninvestigating algorithms for localization of more complex model families and by\nstudying their applications beyond predictions as a feature extraction\nmechanism. We summarize this generic technique of using local models as a\nfeature extraction step with the term ``local model feature transformations.''\nIn this document, we extend the local modeling paradigm to Gaussian processes,\northogonal quadric models and word embedding models, and extend the existing\ntheory for localized linear classifiers. We then demonstrate applications of\nlocal model feature transformations to epileptic event classification from EEG\nreadings, activity monitoring via chest accelerometry, 3D surface\nreconstruction, 3D point cloud segmentation, handwritten digit classification\nand event detection from Twitter feeds.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:41:03 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Brown", "CScott", ""]]}, {"id": "2004.06152", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh, Rahul Mazumder, Ali Saab", "title": "Sparse Regression at Scale: Branch-and-Bound rooted in First-Order\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the least squares regression problem, penalized with a\ncombination of the $\\ell_{0}$ and squared $\\ell_{2}$ penalty functions (a.k.a.\n$\\ell_0 \\ell_2$ regularization). Recent work shows that the resulting\nestimators are of key importance in many high-dimensional statistical settings.\nHowever, exact computation of these estimators remains a major challenge.\nIndeed, modern exact methods, based on mixed integer programming (MIP), face\ndifficulties when the number of features $p \\sim 10^4$. In this work, we\npresent a new exact MIP framework for $\\ell_0\\ell_2$-regularized regression\nthat can scale to $p \\sim 10^7$, achieving speedups of at least $5000$x,\ncompared to state-of-the-art exact methods. Unlike recent work, which relies on\nmodern commercial MIP solvers, we design a specialized nonlinear\nbranch-and-bound (BnB) framework, by critically exploiting the problem\nstructure. A key distinguishing component in our framework lies in efficiently\nsolving the node relaxations using a specialized first-order method, based on\ncoordinate descent (CD). Our CD-based method effectively leverages information\nacross the BnB nodes, through using warm starts, active sets, and gradient\nscreening. In addition, we design a novel method for obtaining dual bounds from\nprimal CD solutions, which certifiably works in high dimensions. Experiments on\nsynthetic and real high-dimensional datasets demonstrate that our framework is\nnot only significantly faster than the state of the art, but can also deliver\ncertifiably optimal solutions to statistically challenging instances that\ncannot be handled with existing methods. We open source the implementation\nthrough our toolkit L0BnB.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:45:29 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 20:18:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""], ["Saab", "Ali", ""]]}, {"id": "2004.06171", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Ehrich Leonard", "title": "Distributed Learning: Sequential Decision Making in Resource-Constrained\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study cost-effective communication strategies that can be used to improve\nthe performance of distributed learning systems in resource-constrained\nenvironments. For distributed learning in sequential decision making, we\npropose a new cost-effective partial communication protocol. We illustrate that\nwith this protocol the group obtains the same order of performance that it\nobtains with full communication. Moreover, we prove that under the proposed\npartial communication protocol the communication cost is $O(\\log T)$, where $T$\nis the time horizon of the decision-making process. This improves significantly\non protocols with full communication, which incur a communication cost that is\n$O(T)$. We validate our theoretical results using numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 19:46:35 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2004.06196", "submitter": "Alena Kopanicakova", "authors": "Lisa Gaedke-Merzh\\\"auser and Alena Kopani\\v{c}\\'akov\\'a and Rolf\n  Krause", "title": "Multilevel Minimization for Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new multilevel minimization framework for the training of deep\nresidual networks (ResNets), which has the potential to significantly reduce\ntraining time and effort. Our framework is based on the dynamical system's\nviewpoint, which formulates a ResNet as the discretization of an initial value\nproblem. The training process is then formulated as a time-dependent optimal\ncontrol problem, which we discretize using different time-discretization\nparameters, eventually generating multilevel-hierarchy of auxiliary networks\nwith different resolutions. The training of the original ResNet is then\nenhanced by training the auxiliary networks with reduced resolutions. By\ndesign, our framework is conveniently independent of the choice of the training\nstrategy chosen on each level of the multilevel hierarchy. By means of\nnumerical examples, we analyze the convergence behavior of the proposed method\nand demonstrate its robustness. For our examples we employ a multilevel\ngradient-based methods. Comparisons with standard single level methods show a\nspeedup of more than factor three while achieving the same validation accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 20:52:26 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Gaedke-Merzh\u00e4user", "Lisa", ""], ["Kopani\u010d\u00e1kov\u00e1", "Alena", ""], ["Krause", "Rolf", ""]]}, {"id": "2004.06230", "submitter": "Jiayu Yao", "authors": "Jiayu Yao, Emma Brunskill, Weiwei Pan, Susan Murphy, Finale\n  Doshi-Velez", "title": "Power Constrained Bandits", "comments": "Accepted at MLHC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits often provide simple and effective personalization in\ndecision making problems, making them popular tools to deliver personalized\ninterventions in mobile health as well as other health applications. However,\nwhen bandits are deployed in the context of a scientific study -- e.g. a\nclinical trial to test if a mobile health intervention is effective -- the aim\nis not only to personalize for an individual, but also to determine, with\nsufficient statistical power, whether or not the system's intervention is\neffective. It is essential to assess the effectiveness of the intervention\nbefore broader deployment for better resource allocation. The two objectives\nare often deployed under different model assumptions, making it hard to\ndetermine how achieving the personalization and statistical power affect each\nother. In this work, we develop general meta-algorithms to modify existing\nalgorithms such that sufficient power is guaranteed while still improving each\nuser's well-being. We also demonstrate that our meta-algorithms are robust to\nvarious model mis-specifications possibly appearing in statistical studies,\nthus providing a valuable tool to study designers.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:08:52 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 14:08:51 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 20:34:10 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 07:55:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yao", "Jiayu", ""], ["Brunskill", "Emma", ""], ["Pan", "Weiwei", ""], ["Murphy", "Susan", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2004.06231", "submitter": "Robert Peharz", "authors": "Robert Peharz, Steven Lang, Antonio Vergari, Karl Stelzner, Alejandro\n  Molina, Martin Trapp, Guy Van den Broeck, Kristian Kersting, Zoubin\n  Ghahramani", "title": "Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic\n  Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic circuits (PCs) are a promising avenue for probabilistic\nmodeling, as they permit a wide range of exact and efficient inference\nroutines. Recent ``deep-learning-style'' implementations of PCs strive for a\nbetter scalability, but are still difficult to train on real-world data, due to\ntheir sparsely connected computational graphs. In this paper, we propose Einsum\nNetworks (EiNets), a novel implementation design for PCs, improving prior art\nin several regards. At their core, EiNets combine a large number of arithmetic\noperations in a single monolithic einsum-operation, leading to speedups and\nmemory savings of up to two orders of magnitude, in comparison to previous\nimplementations. As an algorithmic contribution, we show that the\nimplementation of Expectation-Maximization (EM) can be simplified for PCs, by\nleveraging automatic differentiation. Furthermore, we demonstrate that EiNets\nscale well to datasets which were previously out of reach, such as SVHN and\nCelebA, and that they can be used as faithful generative image models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:09:15 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Peharz", "Robert", ""], ["Lang", "Steven", ""], ["Vergari", "Antonio", ""], ["Stelzner", "Karl", ""], ["Molina", "Alejandro", ""], ["Trapp", "Martin", ""], ["Broeck", "Guy Van den", ""], ["Kersting", "Kristian", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2004.06237", "submitter": "Geoffrey McLachlan", "authors": "Geoffrey J. McLachlan, Daniel Ahfock", "title": "Estimation of Classification Rules from Partially Classified Data", "comments": "Based on invited talk given to the 16th Conference of the\n  International Federation of Classification Societies in Thessaloniki, August\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the situation where the observed sample contains some\nobservations whose class of origin is known (that is, they are classified with\nrespect to the g underlying classes of interest), and where the remaining\nobservations in the sample are unclassified (that is, their class labels are\nunknown). For class-conditional distributions taken to be known up to a vector\nof unknown parameters, the aim is to estimate the Bayes' rule of allocation for\nthe allocation of subsequent unclassified observations. Estimation on the basis\nof both the classified and unclassified data can be undertaken in a\nstraightforward manner by fitting a g-component mixture model by maximum\nlikelihood (ML) via the EM algorithm in the situation where the observed data\ncan be assumed to be an observed random sample from the adopted mixture\ndistribution. This assumption applies if the missing-data mechanism is\nignorable in the terminology pioneered by Rubin (1976). An initial likelihood\napproach was to use the so-called classification ML approach whereby the\nmissing labels are taken to be parameters to be estimated along with the\nparameters of the class-conditional distributions. However, as it can lead to\ninconsistent estimates, the focus of attention switched to the mixture ML\napproach after the appearance of the EM algorithm (Dempster et al., 1977).\nParticular attention is given here to the asymptotic relative efficiency (ARE)\nof the Bayes' rule estimated from a partially classified sample. Lastly, we\nconsider briefly some recent results in situations where the missing label\npattern is non-ignorable for the purposes of ML estimation for the mixture\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:35:25 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["McLachlan", "Geoffrey J.", ""], ["Ahfock", "Daniel", ""]]}, {"id": "2004.06243", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha, Saurabh Dash, Saibal Mukhopadhyay", "title": "Physics-Incorporated Convolutional Recurrent Neural Networks for Source\n  Identification and Forecasting of Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal dynamics of physical processes are generally modeled using\npartial differential equations (PDEs). Though the core dynamics follows some\nprinciples of physics, real-world physical processes are often driven by\nunknown external sources. In such cases, developing a purely analytical model\nbecomes very difficult and data-driven modeling can be of assistance. In this\npaper, we present a hybrid framework combining physics-based numerical models\nwith deep learning for source identification and forecasting of spatio-temporal\ndynamical systems with unobservable time-varying external sources. We formulate\nour model PhICNet as a convolutional recurrent neural network (RNN) which is\nend-to-end trainable for spatio-temporal evolution prediction of dynamical\nsystems and learns the source behavior as an internal state of the RNN.\nExperimental results show that the proposed model can forecast the dynamics for\na relatively long time and identify the sources as well.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:27:18 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 02:19:38 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Saha", "Priyabrata", ""], ["Dash", "Saurabh", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2004.06247", "submitter": "Nemanja Djuric", "authors": "Eason Wang, Henggang Cui, Sai Yalamanchi, Mohana Moorthy, Fang-Chieh\n  Chou, Nemanja Djuric", "title": "Improving Movement Predictions of Traffic Actors in Bird's-Eye View\n  Models using GANs and Differentiable Trajectory Rasterization", "comments": "Accepted for publication at ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most critical pieces of the self-driving puzzle is the task of\npredicting future movement of surrounding traffic actors, which allows the\nautonomous vehicle to safely and effectively plan its future route in a complex\nworld. Recently, a number of algorithms have been proposed to address this\nimportant problem, spurred by a growing interest of researchers from both\nindustry and academia. Methods based on top-down scene rasterization on one\nside and Generative Adversarial Networks (GANs) on the other have shown to be\nparticularly successful, obtaining state-of-the-art accuracies on the task of\ntraffic movement prediction. In this paper we build upon these two directions\nand propose a raster-based conditional GAN architecture, powered by a novel\ndifferentiable rasterizer module at the input of the conditional discriminator\nthat maps generated trajectories into the raster space in a differentiable\nmanner. This simplifies the task for the discriminator as trajectories that are\nnot scene-compliant are easier to discern, and allows the gradients to flow\nback forcing the generator to output better, more realistic trajectories. We\nevaluated the proposed method on a large-scale, real-world data set, showing\nthat it outperforms state-of-the-art GAN-based baselines.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:41:17 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 02:59:56 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Wang", "Eason", ""], ["Cui", "Henggang", ""], ["Yalamanchi", "Sai", ""], ["Moorthy", "Mohana", ""], ["Chou", "Fang-Chieh", ""], ["Djuric", "Nemanja", ""]]}, {"id": "2004.06248", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha, Pierre Gaillard, Michal Valko", "title": "Improved Sleeping Bandits with Stochastic Actions Sets and Adversarial\n  Rewards", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of sleeping bandits with stochastic\naction sets and adversarial rewards. In this setting, in contrast to most work\nin bandits, the actions may not be available at all times. For instance, some\nproducts might be out of stock in item recommendation. The best existing\nefficient (i.e., polynomial-time) algorithms for this problem only guarantee an\n$O(T^{2/3})$ upper-bound on the regret. Yet, inefficient algorithms based on\nEXP4 can achieve $O(\\sqrt{T})$. In this paper, we provide a new computationally\nefficient algorithm inspired by EXP3 satisfying a regret of order $O(\\sqrt{T})$\nwhen the availabilities of each action $i \\in \\cA$ are independent. We then\nstudy the most general version of the problem where at each round available\nsets are generated from some unknown arbitrary distribution (i.e., without the\nindependence assumption) and propose an efficient algorithm with $O(\\sqrt {2^K\nT})$ regret guarantee. Our theoretical results are corroborated with\nexperimental evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:41:26 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 12:45:26 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gaillard", "Pierre", ""], ["Valko", "Michal", ""]]}, {"id": "2004.06277", "submitter": "Peter Vamplew", "authors": "Peter Vamplew, Cameron Foale and Richard Dazeley", "title": "A Demonstration of Issues with Value-Based Multiobjective Reinforcement\n  Learning Under Stochastic State Transitions", "comments": "6 pages. Accepted for presentation in the Adaptive and Learning\n  Agents Workshop, AAMAS 2020", "journal-ref": "The impact of environmental stochasticity on value-based\n  multiobjective reinforcement learning, Neural Computing and Applications,\n  2021", "doi": "10.1007/s00521-021-05859-1", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a previously unidentified issue with model-free, value-based\napproaches to multiobjective reinforcement learning in the context of\nenvironments with stochastic state transitions. An example multiobjective\nMarkov Decision Process (MOMDP) is used to demonstrate that under such\nconditions these approaches may be unable to discover the policy which\nmaximises the Scalarised Expected Return, and in fact may converge to a\nPareto-dominated solution. We discuss several alternative methods which may be\nmore suitable for maximising SER in MOMDPs with stochastic transitions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 02:55:12 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Vamplew", "Peter", ""], ["Foale", "Cameron", ""], ["Dazeley", "Richard", ""]]}, {"id": "2004.06288", "submitter": "Yeli Feng", "authors": "Yeli Feng, Yiyu Cai", "title": "Towards Robust Classification with Image Quality Assessment", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep convolutional neural networks (DCNN) are\nvulnerable to adversarial examples and sensitive to perceptual quality as well\nas the acquisition condition of images. These findings raise a big concern for\nthe adoption of DCNN-based applications for critical tasks. In the literature,\nvarious defense strategies have been introduced to increase the robustness of\nDCNN, including re-training an entire model with benign noise injection,\nadversarial examples, or adding extra layers. In this paper, we investigate the\nconnection between adversarial manipulation and image quality, subsequently\npropose a protective mechanism that doesnt require re-training a DCNN. Our\nmethod combines image quality assessment with knowledge distillation to detect\ninput images that would trigger a DCCN to produce egregiously wrong results.\nUsing the ResNet model trained on ImageNet as an example, we demonstrate that\nthe detector can effectively identify poor quality and adversarial images.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 03:27:35 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Feng", "Yeli", ""], ["Cai", "Yiyu", ""]]}, {"id": "2004.06298", "submitter": "Aditya Gangrade", "authors": "Aditya Gangrade, Durmus Alp Emre Acar, Venkatesh Saligrama", "title": "Budget Learning via Bracketing", "comments": "Slightly expanded version of a paper to be presented at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional machine learning applications in the mobile/IoT setting transmit\ndata to a cloud-server for predictions. Due to cost considerations (power,\nlatency, monetary), it is desirable to minimise device-to-server transmissions.\nThe budget learning (BL) problem poses the learner's goal as minimising use of\nthe cloud while suffering no discernible loss in accuracy, under the constraint\nthat the methods employed be edge-implementable.\n  We propose a new formulation for the BL problem via the concept of\nbracketings. Concretely, we propose to sandwich the cloud's prediction, $g,$\nvia functions $h^-, h^+$ from a `simple' class so that $h^- \\le g \\le h^+$\nnearly always. On an instance $x$, if $h^+(x)=h^-(x)$, we leverage local\nprocessing, and bypass the cloud. We explore theoretical aspects of this\nformulation, providing PAC-style learnability definitions; associating the\nnotion of budget learnability to approximability via brackets; and giving\nVC-theoretic analyses of their properties. We empirically validate our theory\non real-world datasets, demonstrating improved performance over prior gating\nbased methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 04:38:14 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Gangrade", "Aditya", ""], ["Acar", "Durmus Alp Emre", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "2004.06316", "submitter": "Yivan Zhang", "authors": "Yivan Zhang, Nontawat Charoenphakdee, Zhenguo Wu, Masashi Sugiyama", "title": "Learning from Aggregate Observations", "comments": "NeurIPS 2020 proceedings version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning from aggregate observations where\nsupervision signals are given to sets of instances instead of individual\ninstances, while the goal is still to predict labels of unseen individuals. A\nwell-known example is multiple instance learning (MIL). In this paper, we\nextend MIL beyond binary classification to other problems such as multiclass\nclassification and regression. We present a general probabilistic framework\nthat accommodates a variety of aggregate observations, e.g., pairwise\nsimilarity/triplet comparison for classification and mean/difference/rank\nobservation for regression. Simple maximum likelihood solutions can be applied\nto various differentiable models such as deep neural networks and gradient\nboosting machines. Moreover, we develop the concept of consistency up to an\nequivalence relation to characterize our estimator and show that it has nice\nconvergence properties under mild assumptions. Experiments on three problem\nsettings -- classification via triplet comparison and regression via mean/rank\nobservation indicate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 06:18:50 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 06:33:49 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 05:26:43 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Yivan", ""], ["Charoenphakdee", "Nontawat", ""], ["Wu", "Zhenguo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2004.06321", "submitter": "Yanjun Han", "authors": "Yanjun Han, Zhengqing Zhou, Zhengyuan Zhou, Jose Blanchet, Peter W.\n  Glynn, Yinyu Ye", "title": "Sequential Batch Learning in Finite-Action Linear Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sequential batch learning problem in linear contextual bandits\nwith finite action sets, where the decision maker is constrained to split\nincoming individuals into (at most) a fixed number of batches and can only\nobserve outcomes for the individuals within a batch at the batch's end.\nCompared to both standard online contextual bandits learning or offline policy\nlearning in contexutal bandits, this sequential batch learning problem provides\na finer-grained formulation of many personalized sequential decision making\nproblems in practical applications, including medical treatment in clinical\ntrials, product recommendation in e-commerce and adaptive experiment design in\ncrowdsourcing.\n  We study two settings of the problem: one where the contexts are arbitrarily\ngenerated and the other where the contexts are \\textit{iid} drawn from some\ndistribution. In each setting, we establish a regret lower bound and provide an\nalgorithm, whose regret upper bound nearly matches the lower bound. As an\nimportant insight revealed therefrom, in the former setting, we show that the\nnumber of batches required to achieve the fully online performance is\npolynomial in the time horizon, while for the latter setting, a\npure-exploitation algorithm with a judicious batch partition scheme achieves\nthe fully online performance even when the number of batches is less than\nlogarithmic in the time horizon. Together, our results provide a near-complete\ncharacterization of sequential decision making in linear contextual bandits\nwhen batch constraints are present.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 06:47:40 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Han", "Yanjun", ""], ["Zhou", "Zhengqing", ""], ["Zhou", "Zhengyuan", ""], ["Blanchet", "Jose", ""], ["Glynn", "Peter W.", ""], ["Ye", "Yinyu", ""]]}, {"id": "2004.06341", "submitter": "Kensuke Nakamura", "authors": "Kensuke Nakamura, Stefano Soatto, Byung-Woo Hong", "title": "Stochastic batch size for adaptive regularization in deep network\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a first-order stochastic optimization algorithm incorporating\nadaptive regularization applicable to machine learning problems in deep\nlearning framework. The adaptive regularization is imposed by stochastic\nprocess in determining batch size for each model parameter at each optimization\niteration. The stochastic batch size is determined by the update probability of\neach parameter following a distribution of gradient norms in consideration of\ntheir local and global properties in the neural network architecture where the\nrange of gradient norms may vary within and across layers. We empirically\ndemonstrate the effectiveness of our algorithm using an image classification\ntask based on conventional network models applied to commonly used benchmark\ndatasets. The quantitative evaluation indicates that our algorithm outperforms\nthe state-of-the-art optimization algorithms in generalization while providing\nless sensitivity to the selection of batch size which often plays a critical\nrole in optimization, thus achieving more robustness to the selection of\nregularity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 07:54:53 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Nakamura", "Kensuke", ""], ["Soatto", "Stefano", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "2004.06373", "submitter": "Tuanfei Zhu", "authors": "Tuanfei Zhu, Cheng Luo, Jing Li, Siqi Ren and Zhihong Zhang", "title": "Minority Oversampling for Imbalanced Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important real-world applications involve time-series data with skewed\ndistribution. Compared to conventional imbalance learning problems, the\nclassification of imbalanced time-series data is more challenging due to high\ndimensionality and high inter-variable correlation. This paper proposes a\nstructure preserving Oversampling method to combat the High-dimensional\nImbalanced Time-series classification (OHIT). OHIT first leverages a\ndensity-ratio based shared nearest neighbor clustering algorithm to capture the\nmodes of minority class in high-dimensional space. It then for each mode\napplies the shrinkage technique of large-dimensional covariance matrix to\nobtain accurate and reliable covariance structure. Finally, OHIT generates the\nstructure-preserving synthetic samples based on multivariate Gaussian\ndistribution by using the estimated covariance matrices. Experimental results\non several publicly available time-series datasets (including unimodal and\nmultimodal) demonstrate the superiority of OHIT against the state-of-the-art\noversampling algorithms in terms of F1, G-mean, and AUC.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 09:20:12 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 14:47:24 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 06:30:58 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 09:17:13 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhu", "Tuanfei", ""], ["Luo", "Cheng", ""], ["Li", "Jing", ""], ["Ren", "Siqi", ""], ["Zhang", "Zhihong", ""]]}, {"id": "2004.06383", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo, Roberto Santana and Jose A. Lozano", "title": "Extending Adversarial Attacks to Produce Adversarial Class Probability\n  Distributions", "comments": "13 pages, 7 figures, 2 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the remarkable performance and generalization levels of deep learning\nmodels in a wide range of artificial intelligence tasks, it has been\ndemonstrated that these models can be easily fooled by the addition of\nimperceptible but malicious perturbations to natural inputs. These altered\ninputs are known in the literature as adversarial examples. In this paper we\npropose a novel probabilistic framework to generalize and extend adversarial\nattacks in order to produce a desired probability distribution for the classes\nwhen we apply the attack method to a large number of inputs. This novel attack\nstrategy provides the attacker with greater control over the target model, and\nincreases the complexity of detecting that the model is being attacked. We\nintroduce three different strategies to efficiently generate such attacks, and\nillustrate our approach extending DeepFool, a state-of-the-art attack algorithm\nto generate adversarial examples. We also experimentally validate our approach\nfor the spoken command classification task, an exemplary machine learning\nproblem in the audio domain. Our results demonstrate that we can closely\napproximate any probability distribution for the classes while maintaining a\nhigh fooling rate and by injecting imperceptible perturbations to the inputs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 09:39:02 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""], ["Lozano", "Jose A.", ""]]}, {"id": "2004.06443", "submitter": "Lulu Kang", "authors": "Yiwei Wang, Jiuhai Chen, Chun Liu, Lulu Kang", "title": "Particle-based Energetic Variational Inference", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new variational inference (VI) framework, called energetic\nvariational inference (EVI). It minimizes the VI objective function based on a\nprescribed energy-dissipation law. Using the EVI framework, we can derive many\nexisting Particle-based Variational Inference (ParVI) methods, including the\npopular Stein Variational Gradient Descent (SVGD) approach. More importantly,\nmany new ParVI schemes can be created under this framework. For illustration,\nwe propose a new particle-based EVI scheme, which performs the particle-based\napproximation of the density first and then uses the approximated density in\nthe variational procedure, or \"Approximation-then-Variation\" for short. Thanks\nto this order of approximation and variation, the new scheme can maintain the\nvariational structure at the particle level, and can significantly decrease the\nKL-divergence in each iteration. Numerical experiments show the proposed method\noutperforms some existing ParVI methods in terms of fidelity to the target\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 12:14:08 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 18:55:35 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 15:02:28 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 18:29:58 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Wang", "Yiwei", ""], ["Chen", "Jiuhai", ""], ["Liu", "Chun", ""], ["Kang", "Lulu", ""]]}, {"id": "2004.06445", "submitter": "Amir Abdollahi", "authors": "Maryam Rahbaralam, Amir Abdollahi, Daniel Fern\\`andez-Garcia, Xavier\n  Sanchez-Vila", "title": "Stochastic modeling of non-linear adsorption with Gaussian kernel\n  density estimators", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adsorption is a relevant process in many fields, such as product\nmanufacturing or pollution remediation in porous materials. Adsorption takes\nplace at the molecular scale, amenable to be modeled by Lagrangian numerical\nmethods. We have proposed a chemical diffusion-reaction model for the\nsimulation of adsorption, based on the combination of a random walk particle\ntracking method involving the use of Gaussian Kernel Density Estimators. The\nmain feature of the proposed model is that it can effectively reproduce the\nnonlinear behavior characteristic of the Langmuir and Freundlich isotherms. In\nthe former, it is enough to add a finite number of sorption sites of\nhomogeneous sorption properties, and to set the process as the combination of\nthe forward and the backward reactions, each one of them with a prespecified\nreaction rate. To model the Freundlich isotherm instead, typical of low to\nintermediate range of solute concentrations, there is a need to assign a\ndifferent equilibrium constant to each specific sorption site, provided they\nare all drawn from a truncated power-law distribution. Both nonlinear models\ncan be combined in a single framework to obtain a typical observed behavior for\na wide range of concentration values.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 12:21:33 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Rahbaralam", "Maryam", ""], ["Abdollahi", "Amir", ""], ["Fern\u00e0ndez-Garcia", "Daniel", ""], ["Sanchez-Vila", "Xavier", ""]]}, {"id": "2004.06448", "submitter": "Huimin Peng", "authors": "Huimin Peng", "title": "Measurement Error in Nutritional Epidemiology: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews bias-correction models for measurement error of exposure\nvariables in the field of nutritional epidemiology. Measurement error usually\nattenuates estimated slope towards zero. Due to the influence of measurement\nerror, inference of parameter estimate is conservative and confidence interval\nof the slope parameter is too narrow. Bias-correction in estimators and\nconfidence intervals are of primary interest. We review the following\nbias-correction models: regression calibration methods, likelihood based\nmodels, missing data models, simulation based methods, nonparametric models and\nsampling based procedures.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 12:31:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 09:35:18 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Peng", "Huimin", ""]]}, {"id": "2004.06459", "submitter": "Gherardo Varando", "authors": "Federico Carli, Manuele Leonelli, Eva Riccomagno, Gherardo Varando", "title": "The R Package stagedtrees for Structural Learning of Stratified Staged\n  Trees", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  stagedtrees is an R package which includes several algorithms for learning\nthe structure of staged trees and chain event graphs from data. Score-based and\nclustering-based algorithms are implemented, as well as various functionalities\nto plot the models and perform inference. The capabilities of stagedtrees are\nillustrated using mainly two datasets both included in the package or bundled\nin R.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 13:02:59 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 17:11:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Carli", "Federico", ""], ["Leonelli", "Manuele", ""], ["Riccomagno", "Eva", ""], ["Varando", "Gherardo", ""]]}, {"id": "2004.06481", "submitter": "Tomoko Nagai", "authors": "Tomoko Nagai", "title": "The covariance matrix of Green's functions and its application to\n  machine learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a regression algorithm based on Green's function theory is\nproposed and implemented. We first survey Green's function for the Dirichlet\nboundary value problem of 2nd order linear ordinary differential equation,\nwhich is a reproducing kernel of a suitable Hilbert space. We next consider a\ncovariance matrix composed of the normalized Green's function, which is\nregarded as aprobability density function. By supporting Bayesian approach, the\ncovariance matrix gives predictive distribution, which has the predictive mean\n$\\mu$ and the confidence interval [$\\mu$-2s, $\\mu$+2s], where s stands for a\nstandard deviation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 13:26:01 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Nagai", "Tomoko", ""]]}, {"id": "2004.06493", "submitter": "Vikram Jadhao", "authors": "JCS Kadupitiya and Geoffrey C. Fox and Vikram Jadhao", "title": "Deep Learning Based Integrators for Solving Newton's Equations with\n  Large Timesteps", "comments": "14 pages, 11 figures; content is revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.soft cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical molecular dynamics simulations are based on Newton's equations of\nmotion and rely on numerical integrators to solve them. Using a small timestep\nto avoid discretization errors, Verlet integrators generate a trajectory of\nparticle positions as solutions to Newton's equations. We introduce an\nintegrator based on deep neural networks that is trained on trajectories\ngenerated using the Verlet integrator and learns to propagate the dynamics of\nparticles with timestep up to 4000$\\times$ larger compared to the Verlet\ntimestep. We demonstrate significant net speedup of up to 32000 for 1 - 16\nparticle 3D systems and over a variety of force fields.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 16:15:21 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 23:09:34 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kadupitiya", "JCS", ""], ["Fox", "Geoffrey C.", ""], ["Jadhao", "Vikram", ""]]}, {"id": "2004.06496", "submitter": "Michael Everett", "authors": "Michael Everett, Bjorn Lutjens, Jonathan P. How", "title": "Certifiable Robustness to Adversarial State Uncertainty in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1910.12908", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network-based systems are now the state-of-the-art in many\nrobotics tasks, but their application in safety-critical domains remains\ndangerous without formal guarantees on network robustness. Small perturbations\nto sensor inputs (from noise or adversarial examples) are often enough to\nchange network-based decisions, which was recently shown to cause an autonomous\nvehicle to swerve into another lane. In light of these dangers, numerous\nalgorithms have been developed as defensive mechanisms from these adversarial\ninputs, some of which provide formal robustness guarantees or certificates.\nThis work leverages research on certified adversarial robustness to develop an\nonline certifiably robust for deep reinforcement learning algorithms. The\nproposed defense computes guaranteed lower bounds on state-action values during\nexecution to identify and choose a robust action under a worst-case deviation\nin input space due to possible adversaries or noise. Moreover, the resulting\npolicy comes with a certificate of solution quality, even though the true state\nand optimal action are unknown to the certifier due to the perturbations. The\napproach is demonstrated on a Deep Q-Network policy and is shown to increase\nrobustness to noise and adversaries in pedestrian collision avoidance scenarios\nand a classic control task. This work extends one of our prior works with new\nperformance guarantees, extensions to other RL algorithms, expanded results\naggregated across more scenarios, an extension into scenarios with adversarial\nbehavior, comparisons with a more computationally expensive method, and\nvisualizations that provide intuition about the robustness algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 21:36:13 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:02:21 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 16:57:54 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 17:15:40 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2021 02:21:10 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Everett", "Michael", ""], ["Lutjens", "Bjorn", ""], ["How", "Jonathan P.", ""]]}, {"id": "2004.06517", "submitter": "Adalberto Claudio Quiros", "authors": "Adalberto Claudio Quiros, Roderick Murray-Smith, and Ke Yuan", "title": "Learning a low dimensional manifold of real cancer tissue with\n  PathologyGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Application of deep learning in digital pathology shows promise on improving\ndisease diagnosis and understanding. We present a deep generative model that\nlearns to simulate high-fidelity cancer tissue images while mapping the real\nimages onto an interpretable low dimensional latent space. The key to the model\nis an encoder trained by a previously developed generative adversarial network,\nPathologyGAN. We study the latent space using 249K images from two breast\ncancer cohorts. We find that the latent space encodes morphological\ncharacteristics of tissues (e.g. patterns of cancer, lymphocytes, and stromal\ncells). In addition, the latent space reveals distinctly enriched clusters of\ntissue architectures in the high-risk patient group.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:18:00 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Quiros", "Adalberto Claudio", ""], ["Murray-Smith", "Roderick", ""], ["Yuan", "Ke", ""]]}, {"id": "2004.06518", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Mojtaba Heidarysafa, Tolu Odukoya, Philip Potter,\n  Laura E. Barnes, Donald E. Brown", "title": "Gender Detection on Social Networks using Ensemble Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-63128-4_26", "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the ever-increasing volume of posts on social media sites such as\nFacebook and Twitter requires improved information processing methods for\nprofiling authorship. Document classification is central to this task, but the\nperformance of traditional supervised classifiers has degraded as the volume of\nsocial media has increased. This paper addresses this problem in the context of\ngender detection through ensemble classification that employs multi-model deep\nlearning architectures to generate specialized understanding from different\nfeature spaces.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:08:49 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 17:25:00 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 21:54:34 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kowsari", "Kamran", ""], ["Heidarysafa", "Mojtaba", ""], ["Odukoya", "Tolu", ""], ["Potter", "Philip", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "2004.06524", "submitter": "Viktoriia Sharmanska", "authors": "Viktoriia Sharmanska, Lisa Anne Hendricks, Trevor Darrell, Novi\n  Quadrianto", "title": "Contrastive Examples for Addressing the Tyranny of the Majority", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision algorithms, e.g. for face recognition, favour groups of\nindividuals that are better represented in the training data. This happens\nbecause of the generalization that classifiers have to make. It is simpler to\nfit the majority groups as this fit is more important to overall error. We\npropose to create a balanced training dataset, consisting of the original\ndataset plus new data points in which the group memberships are intervened,\nminorities become majorities and vice versa. We show that current generative\nadversarial networks are a powerful tool for learning these data points, called\ncontrastive examples. We experiment with the equalized odds bias measure on\ntabular data as well as image data (CelebA and Diversity in Faces datasets).\nContrastive examples allow us to expose correlations between group membership\nand other seemingly neutral features. Whenever a causal graph is available, we\ncan put those contrastive examples in the perspective of counterfactuals.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:06:44 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sharmanska", "Viktoriia", ""], ["Hendricks", "Lisa Anne", ""], ["Darrell", "Trevor", ""], ["Quadrianto", "Novi", ""]]}, {"id": "2004.06531", "submitter": "Baiming Chen", "authors": "Baiming Chen, Xiang Chen, Wu Qiong, Liang Li", "title": "Adversarial Evaluation of Autonomous Vehicles in Lane-Change Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles must be comprehensively evaluated before deployed in\ncities and highways. However, most existing evaluation approaches for\nautonomous vehicles are static and lack adaptability, so they are usually\ninefficient in generating challenging scenarios for tested vehicles. In this\npaper, we propose an adaptive evaluation framework to efficiently evaluate\nautonomous vehicles in adversarial environments generated by deep reinforcement\nlearning. Considering the multimodal nature of dangerous scenarios, we use\nensemble models to represent different local optimums for diversity. We then\nutilize a nonparametric Bayesian method to cluster the adversarial policies.\nThe proposed method is validated in a typical lane-change scenario that\ninvolves frequent interactions between the ego vehicle and the surrounding\nvehicles. Results show that the adversarial scenarios generated by our method\nsignificantly degrade the performance of the tested vehicles. We also\nillustrate different patterns of generated adversarial environments, which can\nbe used to infer the weaknesses of the tested vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:12:17 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:27:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Chen", "Baiming", ""], ["Chen", "Xiang", ""], ["Qiong", "Wu", ""], ["Li", "Liang", ""]]}, {"id": "2004.06565", "submitter": "Chirag Nagpal", "authors": "Chirag Nagpal, Robert E. Tillman, Prashant Reddy, Manuela Veloso", "title": "Bayesian Consensus: Consensus Estimates from Miscalibrated Instruments\n  under Heteroscedastic Noise", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness and Privacy", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating predictions or measurements from a set\nof human forecasters, models, sensors or other instruments which may be subject\nto bias or miscalibration and random heteroscedastic noise. We propose a\nBayesian consensus estimator that adjusts for miscalibration and noise and show\nthat this estimator is unbiased and asymptotically more efficient than naive\nalternatives. We further propose a Hierarchical Bayesian Model that leverages\nour proposed estimator and apply it to two real world forecasting challenges\nthat require consensus estimates from error prone individual estimates:\nforecasting influenza like illness (ILI) weekly percentages and forecasting\nannual earnings of public companies. We demonstrate that our approach is\neffective at mitigating bias and error and results in more accurate forecasts\nthan existing consensus models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:10:21 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 23:49:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Nagpal", "Chirag", ""], ["Tillman", "Robert E.", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.06567", "submitter": "Dominik Fay", "authors": "Dominik Fay, Jens Sj\\\"olund and Tobias J. Oechtering", "title": "Decentralized Differentially Private Segmentation with PATE", "comments": "Under review for MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to preserving privacy in medical machine learning, two\nimportant considerations are (1) keeping data local to the institution and (2)\navoiding inference of sensitive information from the trained model. These are\noften addressed using federated learning and differential privacy,\nrespectively. However, the commonly used Federated Averaging algorithm requires\na high degree of synchronization between participating institutions. For this\nreason, we turn our attention to Private Aggregation of Teacher Ensembles\n(PATE), where all local models can be trained independently without\ninter-institutional communication. The purpose of this paper is thus to explore\nhow PATE -- originally designed for classification -- can best be adapted for\nsemantic segmentation. To this end, we build low-dimensional representations of\nsegmentation masks which the student can obtain through low-sensitivity queries\nto the private aggregator. On the Brain Tumor Segmentation (BraTS 2019)\ndataset, an Autoencoder-based PATE variant achieves a higher Dice coefficient\nfor the same privacy guarantee than prior work based on noisy Federated\nAveraging.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 00:05:48 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Fay", "Dominik", ""], ["Sj\u00f6lund", "Jens", ""], ["Oechtering", "Tobias J.", ""]]}, {"id": "2004.06568", "submitter": "Abhik Ghosh PhD", "authors": "Abhik Ghosh, Rita SahaRay, Sayan Chakrabarty, Sayan Bhadra", "title": "Robust Generalised Quadratic Discriminant Analysis", "comments": "Pre-print. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic discriminant analysis (QDA) is a widely used statistical tool to\nclassify observations from different multivariate Normal populations. The\ngeneralized quadratic discriminant analysis (GQDA) classification\nrule/classifier, which generalizes the QDA and the minimum Mahalanobis distance\n(MMD) classifiers to discriminate between populations with underlying\nelliptically symmetric distributions competes quite favorably with the QDA\nclassifier when it is optimal and performs much better when QDA fails under\nnon-Normal underlying distributions, e.g. Cauchy distribution. However, the\nclassification rule in GQDA is based on the sample mean vector and the sample\ndispersion matrix of a training sample, which are extremely non-robust under\ndata contamination. In real world, since it is quite common to face data highly\nvulnerable to outliers, the lack of robustness of the classical estimators of\nthe mean vector and the dispersion matrix reduces the efficiency of the GQDA\nclassifier significantly, increasing the misclassification errors. The present\npaper investigates the performance of the GQDA classifier when the classical\nestimators of the mean vector and the dispersion matrix used therein are\nreplaced by various robust counterparts. Applications to various real data sets\nas well as simulation studies reveal far better performance of the proposed\nrobust versions of the GQDA classifier. A Comparative study has been made to\nadvocate the appropriate choice of the robust estimators to be used in a\nspecific situation of the degree of contamination of the data sets.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:21:06 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ghosh", "Abhik", ""], ["SahaRay", "Rita", ""], ["Chakrabarty", "Sayan", ""], ["Bhadra", "Sayan", ""]]}, {"id": "2004.06569", "submitter": "Davood Karimi", "authors": "Davood Karimi, Ali Gholipour", "title": "Improving Calibration and Out-of-Distribution Detection in Medical Image\n  Segmentation with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have shown to be powerful medical image\nsegmentation models. In this study, we address some of the main unresolved\nissues regarding these models. Specifically, training of these models on small\nmedical image datasets is still challenging, with many studies promoting\ntechniques such as transfer learning. Moreover, these models are infamous for\nproducing over-confident predictions and for failing silently when presented\nwith out-of-distribution (OOD) data at test time. In this paper, we advocate\nfor multi-task learning, i.e., training a single model on several different\ndatasets, spanning several different organs of interest and different imaging\nmodalities. We show that not only a single CNN learns to automatically\nrecognize the context and accurately segment the organ of interest in each\ncontext, but also that such a joint model often has more accurate and\nbetter-calibrated predictions than dedicated models trained separately on each\ndataset. Our experiments show that multi-task learning can outperform transfer\nlearning in medical image segmentation tasks. For detecting OOD data, we\npropose a method based on spectral analysis of CNN feature maps. We show that\ndifferent datasets, representing different imaging modalities and/or different\norgans of interest, have distinct spectral signatures, which can be used to\nidentify whether or not a test image is similar to the images used to train a\nmodel. We show that this approach is far more accurate than OOD detection based\non prediction uncertainty. The methods proposed in this paper contribute\nsignificantly to improving the accuracy and reliability of CNN-based medical\nimage segmentation models.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:42:51 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 13:52:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Karimi", "Davood", ""], ["Gholipour", "Ali", ""]]}, {"id": "2004.06615", "submitter": "Yuan Zhang", "authors": "Yuan Zhang, Dong Xia", "title": "Edgeworth expansions for network moments", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network method of moments arXiv:1202.5101 is an important tool for\nnonparametric network inference. However, there has been little investigation\non accurate descriptions of the sampling distributions of network moment\nstatistics. In this paper, we present the first higher-order accurate\napproximation to the sampling CDF of a studentized network moment by Edgeworth\nexpansion. In sharp contrast to classical literature on noiseless U-statistics,\nwe show that the Edgeworth expansion of a network moment statistic as a noisy\nU-statistic can achieve higher-order accuracy without non-lattice or smoothness\nassumptions but just requiring weak regularity conditions. Behind this result\nis our surprising discovery that the two typically-hated factors in network\nanalysis, namely, sparsity and edge-wise observational errors, jointly play a\nblessing role, contributing a crucial self-smoothing effect in the network\nmoment statistic and making it analytically tractable. Our assumptions match\nthe minimum requirements in related literature. For sparse networks, our theory\nshows a simple normal approximation achieves a gradually depreciating\nBerry-Esseen bound as the network becomes sparser. This result also refines the\nbest previous theoretical result.\n  For practitioners, our empirical Edgeworth expansion is highly accurate, fast\nand easy to implement. We demonstrate the clear advantage of our method by\ncomprehensive simulation studies.\n  We showcase three applications of our results in network inference. We prove,\nto our knowledge, the first theoretical guarantee of higher-order accuracy for\nsome network bootstrap schemes, and moreover, the first theoretical guidance\nfor selecting the sub-sample size for network sub-sampling. We also derive\none-sample test and Cornish-Fisher confidence interval for a given moment with\nhigher-order accurate controls of confidence level and type I error,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:02:26 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 05:08:25 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhang", "Yuan", ""], ["Xia", "Dong", ""]]}, {"id": "2004.06633", "submitter": "Chaitanya Poolla", "authors": "Chaitanya Poolla, Abraham K. Ishihara, Dan Liddell, Rodney Martin,\n  Steven Rosenberg", "title": "Occupant Plugload Management for Demand Response in Commercial\n  Buildings: Field Experimentation and Statistical Characterization", "comments": "20 pages, 15 figures, 4 tables, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial buildings account for approximately 36% of US electricity\nconsumption, of which nearly two-thirds is met by fossil fuels [1] resulting in\nan adverse impact on the environment. Reducing this impact requires improving\nenergy efficiency and lowering energy consumption. Most existing studies focus\non designing methods to regulate and reduce HVAC and lighting energy\nconsumption. However, few studies have focused on the control of occupant\nplugload energy consumption. In this study, we conducted multiple experiments\nto analyze changes in occupant plugload energy consumption due to monetary\nincentives and/or feedback. The experiments were performed in government office\nand university buildings at NASA Research Park located in Moffett Field, CA.\nAnalysis of the data reveal significant plugload energy reduction can be\nachieved via feedback and/or incentive mechanisms. Autoregressive models are\nused to predict expected plugload savings in the presence of exogenous\nvariables. The results of this study suggest that occupant-in-the-loop control\narchitectures have the potential to reduce energy consumption and hence lower\nthe carbon footprint of commercial buildings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:23:34 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 21:57:47 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 02:07:59 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 15:01:50 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Poolla", "Chaitanya", ""], ["Ishihara", "Abraham K.", ""], ["Liddell", "Dan", ""], ["Martin", "Rodney", ""], ["Rosenberg", "Steven", ""]]}, {"id": "2004.06660", "submitter": "Paul Michel", "authors": "Keita Kurita, Paul Michel, Graham Neubig", "title": "Weight Poisoning Attacks on Pre-trained Models", "comments": "Published as a long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, NLP has seen a surge in the usage of large pre-trained models.\nUsers download weights of models pre-trained on large datasets, then fine-tune\nthe weights on a task of their choice. This raises the question of whether\ndownloading untrusted pre-trained weights can pose a security threat. In this\npaper, we show that it is possible to construct ``weight poisoning'' attacks\nwhere pre-trained weights are injected with vulnerabilities that expose\n``backdoors'' after fine-tuning, enabling the attacker to manipulate the model\nprediction simply by injecting an arbitrary keyword. We show that by applying a\nregularization method, which we call RIPPLe, and an initialization procedure,\nwhich we call Embedding Surgery, such attacks are possible even with limited\nknowledge of the dataset and fine-tuning procedure. Our experiments on\nsentiment classification, toxicity detection, and spam detection show that this\nattack is widely applicable and poses a serious threat. Finally, we outline\npractical defenses against such attacks. Code to reproduce our experiments is\navailable at https://github.com/neulab/RIPPLe.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:51:42 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Kurita", "Keita", ""], ["Michel", "Paul", ""], ["Neubig", "Graham", ""]]}, {"id": "2004.06668", "submitter": "Zahraa Abdallah Dr", "authors": "Zahraa S. Abdallah, Mohamed Medhat Gaber", "title": "Co-eye: A Multi-resolution Symbolic Representation to TimeSeries\n  Diversified Ensemble Classification", "comments": "to appear in Machine Learning, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification (TSC) is a challenging task that attracted many\nresearchers in the last few years. One main challenge in TSC is the diversity\nof domains where time series data come from. Thus, there is no \"one model that\nfits all\" in TSC. Some algorithms are very accurate in classifying a specific\ntype of time series when the whole series is considered, while some only target\nthe existence/non-existence of specific patterns/shapelets. Yet other\ntechniques focus on the frequency of occurrences of discriminating\npatterns/features. This paper presents a new classification technique that\naddresses the inherent diversity problem in TSC using a nature-inspired method.\nThe technique is stimulated by how flies look at the world through \"compound\neyes\" that are made up of thousands of lenses, called ommatidia. Each\nommatidium is an eye with its own lens, and thousands of them together create a\nbroad field of vision. The developed technique similarly uses different lenses\nand representations to look at the time series, and then combines them for\nbroader visibility. These lenses have been created through\nhyper-parameterisation of symbolic representations (Piecewise Aggregate and\nFourier approximations). The algorithm builds a random forest for each lens,\nthen performs soft dynamic voting for classifying new instances using the most\nconfident eyes, i.e, forests. We evaluate the new technique, coined Co-eye,\nusing the recently released extended version of UCR archive, containing more\nthan 100 datasets across a wide range of domains. The results show the benefits\nof bringing together different perspectives reflecting on the accuracy and\nrobustness of Co-eye in comparison to other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:16:22 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 10:37:35 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Abdallah", "Zahraa S.", ""], ["Gaber", "Mohamed Medhat", ""]]}, {"id": "2004.06674", "submitter": "Ashish Rana", "authors": "Ashish Rana, Taranveer Singh, Harpreet Singh, Neeraj Kumar and\n  Prashant Singh Rana", "title": "Systematically designing better instance counting models on cell images\n  with Neural Arithmetic Logic Units", "comments": "* code repository for project:\n  https://github.com/ashishrana160796/nalu-cell-counting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The big problem for neural network models which are trained to count\ninstances is that whenever test range goes high training range generalization\nerror increases i.e. they are not good generalizers outside training range.\nConsider the case of automating cell counting process where more dense images\nwith higher cell counts are commonly encountered as compared to images used in\ntraining data. By making better predictions for higher ranges of cell count we\nare aiming to create better generalization systems for cell counting. With\narchitecture proposal of neural arithmetic logic units (NALU) for arithmetic\noperations, task of counting has become feasible for higher numeric ranges\nwhich were not included in training data with better accuracy. As a part of our\nstudy we used these units and different other activation functions for learning\ncell counting task with two different architectures namely Fully Convolutional\nRegression Network and U-Net. These numerically biased units are added in the\nform of residual concatenated layers to original architectures and a\ncomparative experimental study is done with these newly proposed changes. This\ncomparative study is described in terms of optimizing regression loss problem\nfrom these models trained with extensive data augmentation techniques. We were\nable to achieve better results in our experiments of cell counting tasks with\nintroduction of these numerically biased units to already existing\narchitectures in the form of residual layer concatenation connections. Our\nresults confirm that above stated numerically biased units does help models to\nlearn numeric quantities for better generalization results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:23:37 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 07:44:46 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rana", "Ashish", ""], ["Singh", "Taranveer", ""], ["Singh", "Harpreet", ""], ["Kumar", "Neeraj", ""], ["Rana", "Prashant Singh", ""]]}, {"id": "2004.06778", "submitter": "Negin Karisani", "authors": "Negin Karisani, Payam Karisani", "title": "Mining Coronavirus (COVID-19) Posts in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World Health Organization (WHO) characterized the novel coronavirus\n(COVID-19) as a global pandemic on March 11th, 2020. Before this and in late\nJanuary, more specifically on January 27th, while the majority of the infection\ncases were still reported in China and a few cruise ships, we began crawling\nsocial media user postings using the Twitter search API. Our goal was to\nleverage machine learning and linguistic tools to better understand the impact\nof the outbreak in China. Unlike our initial expectation to monitor a local\noutbreak, COVID-19 rapidly spread across the globe. In this short article we\nreport the preliminary results of our study on automatically detecting the\npositive reports of COVID-19 from social media user postings using\nstate-of-the-art machine learning models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:38:50 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Karisani", "Negin", ""], ["Karisani", "Payam", ""]]}, {"id": "2004.06784", "submitter": "Eugene Charniak", "authors": "Eugene Charniak", "title": "Extrapolation in Gridworld Markov-Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extrapolation in reinforcement learning is the ability to generalize at test\ntime given states that could never have occurred at training time. Here we\nconsider four factors that lead to improved extrapolation in a simple Gridworld\nenvironment: (a) avoiding maximum Q-value (or other deterministic methods) for\naction choice at test time, (b) ego-centric representation of the Gridworld,\n(c) building rotational and mirror symmetry into the learning mechanism using\nrotational and mirror invariant convolution (rather than standard\ntranslation-invariant convolution), and (d) adding a maximum entropy term to\nthe loss function to encourage equally good actions to be chosen equally often.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 20:07:10 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Charniak", "Eugene", ""]]}, {"id": "2004.06801", "submitter": "Anthony Corso", "authors": "Anthony Corso, Ritchie Lee, Mykel J. Kochenderfer", "title": "Scalable Autonomous Vehicle Safety Validation through Dynamic\n  Programming and Scene Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open question in autonomous driving is how best to use simulation to\nvalidate the safety of autonomous vehicles. Existing techniques rely on\nsimulated rollouts, which can be inefficient for finding rare failure events,\nwhile other techniques are designed to only discover a single failure. In this\nwork, we present a new safety validation approach that attempts to estimate the\ndistribution over failures of an autonomous policy using approximate dynamic\nprogramming. Knowledge of this distribution allows for the efficient discovery\nof many failure examples. To address the problem of scalability, we decompose\ncomplex driving scenarios into subproblems consisting of only the ego vehicle\nand one other vehicle. These subproblems can be solved with approximate dynamic\nprogramming and their solutions are recombined to approximate the solution to\nthe full scenario. We apply our approach to a simple two-vehicle scenario to\ndemonstrate the technique as well as a more complex five-vehicle scenario to\ndemonstrate scalability. In both experiments, we observed an increase in the\nnumber of failures discovered compared to baseline approaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 21:03:50 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:33:24 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Corso", "Anthony", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.06805", "submitter": "Anthony Corso", "authors": "Anthony Corso and Mykel J. Kochenderfer", "title": "Interpretable Safety Validation for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem for autonomous driving is how to validate the safety of an\nautonomous vehicle in simulation. Automated testing procedures can find\nfailures of an autonomous system but these failures may be difficult to\ninterpret due to their high dimensionality and may be so unlikely as to not be\nimportant. This work describes an approach for finding interpretable failures\nof an autonomous system. The failures are described by signal temporal logic\nexpressions that can be understood by a human, and are optimized to produce\nfailures that have high likelihood. Our methodology is demonstrated for the\nsafety validation of an autonomous vehicle in the context of an unprotected\nleft turn and a crosswalk with a pedestrian. Compared to a baseline importance\nsampling approach, our methodology finds more failures with higher likelihood\nwhile retaining interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 21:11:43 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:29:46 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Corso", "Anthony", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.06830", "submitter": "Huanyu Zhang", "authors": "Jayadev Acharya, Ziteng Sun, Huanyu Zhang", "title": "Differentially Private Assouad, Fano, and Le Cam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Le Cam's method, Fano's inequality, and Assouad's lemma are three widely used\ntechniques to prove lower bounds for statistical estimation tasks. We propose\ntheir analogues under central differential privacy. Our results are simple,\neasy to apply and we use them to establish sample complexity bounds in several\nestimation tasks. We establish the optimal sample complexity of discrete\ndistribution estimation under total variation distance and $\\ell_2$ distance.\nWe also provide lower bounds for several other distribution classes, including\nproduct distributions and Gaussian mixtures that are tight up to logarithmic\nfactors. The technical component of our paper relates coupling between\ndistributions to the sample complexity of estimation under differential\nprivacy.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 23:10:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 14:57:18 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 03:03:57 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Acharya", "Jayadev", ""], ["Sun", "Ziteng", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2004.06833", "submitter": "Saturnino Luz", "authors": "Saturnino Luz, Fasih Haider, Sofia de la Fuente, Davida Fromm, Brian\n  MacWhinney", "title": "Alzheimer's Dementia Recognition through Spontaneous Speech: The ADReSS\n  Challenge", "comments": "To appear in the Proceedings of INTERSPEECH 2020, Oct 2020, Shanghai,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ADReSS Challenge at INTERSPEECH 2020 defines a shared task through which\ndifferent approaches to the automated recognition of Alzheimer's dementia based\non spontaneous speech can be compared. ADReSS provides researchers with a\nbenchmark speech dataset which has been acoustically pre-processed and balanced\nin terms of age and gender, defining two cognitive assessment tasks, namely:\nthe Alzheimer's speech classification task and the neuropsychological score\nregression task. In the Alzheimer's speech classification task, ADReSS\nchallenge participants create models for classifying speech as dementia or\nhealthy control speech. In the the neuropsychological score regression task,\nparticipants create models to predict mini-mental state examination scores.\nThis paper describes the ADReSS Challenge in detail and presents a baseline for\nboth tasks, including feature extraction procedures and results for\nclassification and regression models. ADReSS aims to provide the speech and\nlanguage Alzheimer's research community with a platform for comprehensive\nmethodological comparisons. This will hopefully contribute to addressing the\nlack of standardisation that currently affects the field and shed light on\navenues for future research and clinical applicability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 23:25:09 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 20:24:03 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 22:44:29 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Luz", "Saturnino", ""], ["Haider", "Fasih", ""], ["de la Fuente", "Sofia", ""], ["Fromm", "Davida", ""], ["MacWhinney", "Brian", ""]]}, {"id": "2004.06838", "submitter": "Bilal Farooq", "authors": "Godwin Badu-Marfo, Bilal Farooq, and Zachary Paterson", "title": "Composite Travel Generative Adversarial Networks for Tabular and\n  Sequential Population Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based transportation modelling has become the standard to simulate\ntravel behaviour, mobility choices and activity preferences using disaggregate\ntravel demand data for entire populations, data that are not typically readily\navailable. Various methods have been proposed to synthesize population data for\nthis purpose. We present a Composite Travel Generative Adversarial Network\n(CTGAN), a novel deep generative model to estimate the underlying joint\ndistribution of a population, that is capable of reconstructing composite\nsynthetic agents having tabular (e.g. age and sex) as well as sequential\nmobility data (e.g. trip trajectory and sequence). The CTGAN model is compared\nwith other recently proposed methods such as the Variational Autoencoders (VAE)\nmethod, which has shown success in high dimensional tabular population\nsynthesis. We evaluate the performance of the synthesized outputs based on\ndistribution similarity, multi-variate correlations and spatio-temporal\nmetrics. The results show the consistent and accurate generation of synthetic\npopulations and their tabular and spatially sequential attributes, generated\nover varying spatial scales and dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:06:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Badu-Marfo", "Godwin", ""], ["Farooq", "Bilal", ""], ["Paterson", "Zachary", ""]]}, {"id": "2004.06840", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Michael I. Jordan, Ren\\'e Vidal", "title": "On dissipative symplectic integration with applications to\n  gradient-based optimization", "comments": "matches published version", "journal-ref": "J. Stat. Mech. (2021) 043402", "doi": "10.1088/1742-5468/abf5d4", "report-no": null, "categories": "math.OC cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, continuous-time dynamical systems have proved useful in providing\nconceptual and quantitative insights into gradient-based optimization, widely\nused in modern machine learning and statistics. An important question that\narises in this line of work is how to discretize the system in such a way that\nits stability and rates of convergence are preserved. In this paper we propose\na geometric framework in which such discretizations can be realized\nsystematically, enabling the derivation of \"rate-matching\" algorithms without\nthe need for a discrete convergence analysis. More specifically, we show that a\ngeneralization of symplectic integrators to nonconservative and in particular\ndissipative Hamiltonian systems is able to preserve rates of convergence up to\na controlled error. Moreover, such methods preserve a shadow Hamiltonian\ndespite the absence of a conservation law, extending key results of symplectic\nintegrators to nonconservative cases. Our arguments rely on a combination of\nbackward error analysis with fundamental results from symplectic geometry. We\nstress that although the original motivation for this work was the application\nto optimization, where dissipative systems play a natural role, they are fully\ngeneral and not only provide a differential geometric framework for dissipative\nHamiltonian systems but also substantially extend the theory of\nstructure-preserving integration.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:36:49 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 12:42:24 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 23:56:14 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 17:24:58 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Jordan", "Michael I.", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "2004.06843", "submitter": "Yibo Yang", "authors": "Yibo Yang, Mohamed Aziz Bhouri, Paris Perdikaris", "title": "Bayesian differential programming for robust systems identification\n  under uncertainty", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a machine learning framework for Bayesian systems\nidentification from noisy, sparse and irregular observations of nonlinear\ndynamical systems. The proposed method takes advantage of recent developments\nin differentiable programming to propagate gradient information through\nordinary differential equation solvers and perform Bayesian inference with\nrespect to unknown model parameters using Hamiltonian Monte Carlo. This allows\nus to efficiently infer posterior distributions over plausible models with\nquantified uncertainty, while the use of sparsity-promoting priors enables the\ndiscovery of interpretable and parsimonious representations for the underlying\nlatent dynamics. A series of numerical studies is presented to demonstrate the\neffectiveness of the proposed methods including nonlinear oscillators,\npredator-prey systems, chaotic dynamics and systems biology. Taken all\ntogether, our findings put forth a novel, flexible and robust workflow for\ndata-driven model discovery under uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:51:14 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 23:04:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yang", "Yibo", ""], ["Bhouri", "Mohamed Aziz", ""], ["Perdikaris", "Paris", ""]]}, {"id": "2004.06846", "submitter": "Yanfeng Zhang", "authors": "Yanyan Liang, Yanfeng Zhang, Dechao Gao, Qian Xu", "title": "MxPool: Multiplex Pooling for Hierarchical Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to utilize deep learning methods for graph classification tasks has\nattracted considerable research attention in the past few years. Regarding\ngraph classification tasks, the graphs to be classified may have various graph\nsizes (i.e., different number of nodes and edges) and have various graph\nproperties (e.g., average node degree, diameter, and clustering coefficient).\nThe diverse property of graphs has imposed significant challenges on existing\ngraph learning techniques since diverse graphs have different best-fit\nhyperparameters. It is difficult to learn graph features from a set of diverse\ngraphs by a unified graph neural network. This motivates us to use a multiplex\nstructure in a diverse way and utilize a priori properties of graphs to guide\nthe learning. In this paper, we propose MxPool, which concurrently uses\nmultiple graph convolution/pooling networks to build a hierarchical learning\nstructure for graph representation learning tasks. Our experiments on numerous\ngraph classification benchmarks show that our MxPool has superiority over other\nstate-of-the-art graph representation learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 01:05:29 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Liang", "Yanyan", ""], ["Zhang", "Yanfeng", ""], ["Gao", "Dechao", ""], ["Xu", "Qian", ""]]}, {"id": "2004.06882", "submitter": "Sujit Gujar Dr", "authors": "Manisha Padala, Debojit Das, and Sujit Gujar", "title": "Effect of Input Noise Dimension in GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are by far the most successful\ngenerative models. Learning the transformation which maps a low dimensional\ninput noise to the data distribution forms the foundation for GANs. Although\nthey have been applied in various domains, they are prone to certain challenges\nlike mode collapse and unstable training. To overcome the challenges,\nresearchers have proposed novel loss functions, architectures, and optimization\nmethods. In our work here, unlike the previous approaches, we focus on the\ninput noise and its role in the generation.\n  We aim to quantitatively and qualitatively study the effect of the dimension\nof the input noise on the performance of GANs. For quantitative measures,\ntypically \\emph{Fr\\'{e}chet Inception Distance (FID)} and \\emph{Inception Score\n(IS)} are used as performance measure on image data-sets. We compare the FID\nand IS values for DCGAN and WGAN-GP. We use three different image data-sets --\neach consisting of different levels of complexity. Through our experiments, we\nshow that the right dimension of input noise for optimal results depends on the\ndata-set and architecture used. We also observe that the state of the art\nperformance measures does not provide enough useful insights. Hence we conclude\nthat we need further theoretical analysis for understanding the relationship\nbetween the low dimensional distribution and the generated images. We also\nrequire better performance measures.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 04:56:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Padala", "Manisha", ""], ["Das", "Debojit", ""], ["Gujar", "Sujit", ""]]}, {"id": "2004.06896", "submitter": "Mao V. Ngo", "authors": "Mao V. Ngo, Tie Luo, Hakima Chaouchi, and Tony Q.S. Quek", "title": "Contextual-Bandit Anomaly Detection for IoT Data in Distributed\n  Hierarchical Edge Computing", "comments": "Accepted for presenting at IEEE International Conference on\n  Distributed Computing Systems (ICDCS), Demo Track, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNN) greatly bolster real-time detection of\nanomalous IoT data. However, IoT devices can hardly afford complex DNN models,\nand offloading anomaly detection tasks to the cloud incurs long delay. In this\npaper, we propose and build a demo for an adaptive anomaly detection approach\nfor distributed hierarchical edge computing (HEC) systems to solve this\nproblem, for both univariate and multivariate IoT data. First, we construct\nmultiple anomaly detection DNN models with increasing complexity, and associate\neach model with a layer in HEC from bottom to top. Then, we design an adaptive\nscheme to select one of these models on the fly, based on the contextual\ninformation extracted from each input data. The model selection is formulated\nas a contextual bandit problem characterized by a single-step Markov decision\nprocess, and is solved using a reinforcement learning policy network. We build\nan HEC testbed, implement our proposed approach, and evaluate it using real IoT\ndatasets. The demo shows that our proposed approach significantly reduces\ndetection delay (e.g., by 71.4% for univariate dataset) without sacrificing\naccuracy, as compared to offloading detection tasks to the cloud. We also\ncompare it with other baseline schemes and demonstrate that it achieves the\nbest accuracy-delay tradeoff. Our demo is also available online:\nhttps://rebrand.ly/91a71\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 06:13:33 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ngo", "Mao V.", ""], ["Luo", "Tie", ""], ["Chaouchi", "Hakima", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2004.06916", "submitter": "Edilson Arruda", "authors": "L. Tarrataca, C.M. Dias, D. B. Haddad, and E. F. Arruda", "title": "Flattening the curves: on-off lock-down strategies for COVID-19 with an\n  application to Brazi", "comments": null, "journal-ref": null, "doi": "10.1186/s13362-020-00098-w", "report-no": null, "categories": "q-bio.PE cs.LG cs.SY eess.SY q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current COVID-19 pandemic is affecting different countries in different\nways. The assortment of reporting techniques alongside other issues, such as\nunderreporting and budgetary constraints, makes predicting the spread and\nlethality of the virus a challenging task. This work attempts to gain a better\nunderstanding of how COVID-19 will affect one of the least studied countries,\nnamely Brazil. Currently, several Brazilian states are in a state of lock-down.\nHowever, there is political pressure for this type of measures to be lifted.\nThis work considers the impact that such a termination would have on how the\nvirus evolves locally. This was done by extending the SEIR model with an on /\noff strategy. Given the simplicity of SEIR we also attempted to gain more\ninsight by developing a neural regressor. We chose to employ features that\ncurrent clinical studies have pinpointed has having a connection to the\nlethality of COVID-19. We discuss how this data can be processed in order to\nobtain a robust assessment.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 07:37:08 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Tarrataca", "L.", ""], ["Dias", "C. M.", ""], ["Haddad", "D. B.", ""], ["Arruda", "E. F.", ""]]}, {"id": "2004.06947", "submitter": "Georg Steinbuss", "authors": "Georg Steinbuss and Klemens B\\\"ohm", "title": "Benchmarking Unsupervised Outlier Detection with Realistic Synthetic\n  Data", "comments": null, "journal-ref": null, "doi": "10.1145/3441453", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarking unsupervised outlier detection is difficult. Outliers are rare,\nand existing benchmark data contains outliers with various and unknown\ncharacteristics. Fully synthetic data usually consists of outliers and regular\ninstance with clear characteristics and thus allows for a more meaningful\nevaluation of detection methods in principle. Nonetheless, there have only been\nfew attempts to include synthetic data in benchmarks for outlier detection.\nThis might be due to the imprecise notion of outliers or to the difficulty to\narrive at a good coverage of different domains with synthetic data. In this\nwork we propose a generic process for the generation of data sets for such\nbenchmarking. The core idea is to reconstruct regular instances from existing\nreal-world benchmark data while generating outliers so that they exhibit\ninsightful characteristics. This allows both for a good coverage of domains and\nfor helpful interpretations of results. We also describe three instantiations\nof the generic process that generate outliers with specific characteristics,\nlike local outliers. A benchmark with state-of-the-art detection methods\nconfirms that our generic process is indeed practical.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 08:55:47 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Steinbuss", "Georg", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "2004.06963", "submitter": "Lorenzo Rimella", "authors": "Lorenzo Rimella and Nick Whiteley", "title": "Dynamic Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define an evolving in time Bayesian neural network called a Hidden Markov\nneural network. The weights of a feed-forward neural network are modelled with\nthe hidden states of a Hidden Markov model, whose observed process is given by\nthe available data. A filtering algorithm is used to learn a variational\napproximation to the evolving in time posterior over the weights. Training is\npursued through a sequential version of Bayes by Backprop Blundell et al. 2015,\nwhich is enriched with a stronger regularization technique called variational\nDropConnect. The experiments test variational DropConnect on MNIST and display\nthe performance of Hidden Markov neural networks on time series.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:18:18 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 14:29:17 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rimella", "Lorenzo", ""], ["Whiteley", "Nick", ""]]}, {"id": "2004.06977", "submitter": "Bin Shi", "authors": "Bin Shi, Weijie J. Su, Michael I. Jordan", "title": "On Learning Rates and Schr\\\"odinger Operators", "comments": "49 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate is perhaps the single most important parameter in the\ntraining of neural networks and, more broadly, in stochastic (nonconvex)\noptimization. Accordingly, there are numerous effective, but poorly understood,\ntechniques for tuning the learning rate, including learning rate decay, which\nstarts with a large initial learning rate that is gradually decreased. In this\npaper, we present a general theoretical analysis of the effect of the learning\nrate in stochastic gradient descent (SGD). Our analysis is based on the use of\na learning-rate-dependent stochastic differential equation (lr-dependent SDE)\nthat serves as a surrogate for SGD. For a broad class of objective functions,\nwe establish a linear rate of convergence for this continuous-time formulation\nof SGD, highlighting the fundamental importance of the learning rate in SGD,\nand contrasting to gradient descent and stochastic gradient Langevin dynamics.\nMoreover, we obtain an explicit expression for the optimal linear rate by\nanalyzing the spectrum of the Witten-Laplacian, a special case of the\nSchr\\\"odinger operator associated with the lr-dependent SDE. Strikingly, this\nexpression clearly reveals the dependence of the linear convergence rate on the\nlearning rate -- the linear rate decreases rapidly to zero as the learning rate\ntends to zero for a broad class of nonconvex functions, whereas it stays\nconstant for strongly convex functions. Based on this sharp distinction between\nnonconvex and convex problems, we provide a mathematical interpretation of the\nbenefits of using learning rate decay for nonconvex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:52:37 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Shi", "Bin", ""], ["Su", "Weijie J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2004.06989", "submitter": "Raja Giryes", "authors": "Raja Giryes", "title": "A function space analysis of finite neural networks with insights from\n  sampling theory", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.FA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work suggests using sampling theory to analyze the function space\nrepresented by neural networks. First, it shows, under the assumption of a\nfinite input domain, which is the common case in training neural networks, that\nthe function space generated by multi-layer networks with non-expansive\nactivation functions is smooth. This extends over previous works that show\nresults for the case of infinite width ReLU networks. Then, under the\nassumption that the input is band-limited, we provide novel error bounds for\nunivariate neural networks. We analyze both deterministic uniform and random\nsampling showing the advantage of the former.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 10:25:18 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Giryes", "Raja", ""]]}, {"id": "2004.07067", "submitter": "Mohamed El-Geish", "authors": "Mohamed El-Geish", "title": "Gestalt: a Stacking Ensemble for SQuAD2.0", "comments": "11 pages, 7 figures, Stanford CS224n Natural Language Processing with\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep-learning system -- for the SQuAD2.0 task -- that finds, or\nindicates the lack of, a correct answer to a question in a context paragraph.\nOur goal is to learn an ensemble of heterogeneous SQuAD2.0 models that, when\nblended properly, outperforms the best model in the ensemble per se. We created\na stacking ensemble that combines top-N predictions from two models, based on\nALBERT and RoBERTa, into a multiclass classification task to pick the best\nanswer out of their predictions. We explored various ensemble configurations,\ninput representations, and model architectures. For evaluation, we examined\ntest-set EM and F1 scores; our best-performing ensemble incorporated a\nCNN-based meta-model and scored 87.117 and 90.306, respectively -- a relative\nimprovement of 0.55% for EM and 0.61% for F1 scores, compared to the baseline\nperformance of the best model in the ensemble, an ALBERT-based model, at 86.644\nfor EM and 89.760 for F1.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:09:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["El-Geish", "Mohamed", ""]]}, {"id": "2004.07085", "submitter": "Lukas Faber", "authors": "Lukas Faber and Roger Wattenhofer", "title": "Neural Status Registers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Neural Networks can learn mathematical operations, but they do not\nextrapolate. Extrapolation means that the model can apply to larger numbers,\nwell beyond those observed during training. Recent architectures tackle\narithmetic operations and can extrapolate; however, the equally important\nproblem of quantitative reasoning remains unaddressed. In this work, we propose\na novel architectural element, the Neural Status Register (NSR), for\nquantitative reasoning over numbers. Our NSR relaxes the discrete bit logic of\nphysical status registers to continuous numbers and allows end-to-end learning\nwith gradient descent. Experiments show that the NSR achieves solutions that\nextrapolate to numbers many orders of magnitude larger than those in the\ntraining set. We successfully train the NSR on number comparisons, piecewise\ndiscontinuous functions, counting in sequences, recurrently finding minimums,\nfinding shortest paths in graphs, and comparing digits in images.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 13:34:37 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 18:58:29 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Faber", "Lukas", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2004.07093", "submitter": "Kazuki Miyazawa", "authors": "Kazuki Miyazawa, Tatsuya Aoki, Takato Horii, and Takayuki Nagai", "title": "lamBERT: Language and Action Learning Using Multimodal BERT", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the bidirectional encoder representations from transformers (BERT)\nmodel has attracted much attention in the field of natural language processing,\nowing to its high performance in language understanding-related tasks. The BERT\nmodel learns language representation that can be adapted to various tasks via\npre-training using a large corpus in an unsupervised manner. This study\nproposes the language and action learning using multimodal BERT (lamBERT) model\nthat enables the learning of language and actions by 1) extending the BERT\nmodel to multimodal representation and 2) integrating it with reinforcement\nlearning. To verify the proposed model, an experiment is conducted in a grid\nenvironment that requires language understanding for the agent to act properly.\nAs a result, the lamBERT model obtained higher rewards in multitask settings\nand transfer settings when compared to other models, such as the convolutional\nneural network-based model and the lamBERT model without pre-training.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 13:54:55 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Miyazawa", "Kazuki", ""], ["Aoki", "Tatsuya", ""], ["Horii", "Takato", ""], ["Nagai", "Takayuki", ""]]}, {"id": "2004.07116", "submitter": "Beatrice Bussolino", "authors": "Alberto Marchisio, Beatrice Bussolino, Alessio Colucci, Maurizio\n  Martina, Guido Masera, Muhammad Shafique", "title": "Q-CapsNets: A Specialized Framework for Quantizing Capsule Networks", "comments": "Accepted for publication at Design Automation Conference 2020 (DAC\n  2020)", "journal-ref": null, "doi": "10.1109/DAC18072.2020.9218746", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks (CapsNets), recently proposed by the Google Brain team, have\nsuperior learning capabilities in machine learning tasks, like image\nclassification, compared to the traditional CNNs. However, CapsNets require\nextremely intense computations and are difficult to be deployed in their\noriginal form at the resource-constrained edge devices. This paper makes the\nfirst attempt to quantize CapsNet models, to enable their efficient edge\nimplementations, by developing a specialized quantization framework for\nCapsNets. We evaluate our framework for several benchmarks. On a deep CapsNet\nmodel for the CIFAR10 dataset, the framework reduces the memory footprint by\n6.2x, with only 0.15% accuracy loss. We will open-source our framework at\nhttps://git.io/JvDIF in August 2020.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 14:32:45 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 08:13:57 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marchisio", "Alberto", ""], ["Bussolino", "Beatrice", ""], ["Colucci", "Alessio", ""], ["Martina", "Maurizio", ""], ["Masera", "Guido", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2004.07119", "submitter": "Xiaojie Guo", "authors": "Xiaojie Guo, Yuanqi Du, Sivani Tadepalli, Liang Zhao, and Amarda Shehu", "title": "Generating Tertiary Protein Structures via an Interpretative Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much scientific enquiry across disciplines is founded upon a mechanistic\ntreatment of dynamic systems that ties form to function. A highly visible\ninstance of this is in molecular biology, where an important goal is to\ndetermine functionally-relevant forms/structures that a protein molecule\nemploys to interact with molecular partners in the living cell. This goal is\ntypically pursued under the umbrella of stochastic optimization with algorithms\nthat optimize a scoring function. Research repeatedly shows that current\nscoring function, though steadily improving, correlate weakly with molecular\nactivity. Inspired by recent momentum in generative deep learning, this paper\nproposes and evaluates an alternative approach to generating\nfunctionally-relevant three-dimensional structures of a protein. Though\ntypically deep generative models struggle with highly-structured data, the work\npresented here circumvents this challenge via graph-generative models. A\ncomprehensive evaluation of several deep architectures shows the promise of\ngenerative models in directly revealing the latent space for sampling novel\ntertiary structures, as well as in highlighting axes/factors that carry\nstructural meaning and open the black box often associated with deep models.\nThe work presented here is a first step towards interpretative, deep generative\nmodels becoming viable and informative complementary approaches to protein\nstructure prediction.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:40:21 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 06:02:16 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Guo", "Xiaojie", ""], ["Du", "Yuanqi", ""], ["Tadepalli", "Sivani", ""], ["Zhao", "Liang", ""], ["Shehu", "Amarda", ""]]}, {"id": "2004.07126", "submitter": "Avi Caciularu", "authors": "Oren Barkan, Idan Rejwan, Avi Caciularu, Noam Koenigstein", "title": "Bayesian Hierarchical Words Representation Learning", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Bayesian Hierarchical Words Representation (BHWR)\nlearning algorithm. BHWR facilitates Variational Bayes word representation\nlearning combined with semantic taxonomy modeling via hierarchical priors. By\npropagating relevant information between related words, BHWR utilizes the\ntaxonomy to improve the quality of such representations. Evaluation of several\nlinguistic datasets demonstrates the advantages of BHWR over suitable\nalternatives that facilitate Bayesian modeling with or without semantic priors.\nFinally, we further show that BHWR produces better representations for rare\nwords.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 13:39:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Barkan", "Oren", ""], ["Rejwan", "Idan", ""], ["Caciularu", "Avi", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2004.07150", "submitter": "Jimit Majmudar", "authors": "Jimit Majmudar, Stephen Vavasis", "title": "Provable Overlapping Community Detection in Weighted Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is a widely-studied unsupervised learning problem in\nwhich the task is to group similar entities together based on observed pairwise\nentity interactions. This problem has applications in diverse domains such as\nsocial network analysis and computational biology. There is a significant\namount of literature studying this problem under the assumption that the\ncommunities do not overlap. When the communities are allowed to overlap, often\na pure nodes assumption is made, i.e. each community has a node that belongs\nexclusively to that community. This assumption, however, may not always be\nsatisfied in practice. In this paper, we provide a provable method to detect\noverlapping communities in weighted graphs without explicitly making the pure\nnodes assumption. Moreover, contrary to most existing algorithms, our approach\nis based on convex optimization, for which many useful theoretical properties\nare already known. We demonstrate the success of our algorithm on artificial\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:25:46 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 17:42:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Majmudar", "Jimit", ""], ["Vavasis", "Stephen", ""]]}, {"id": "2004.07155", "submitter": "Alvaro Ovalle", "authors": "Alvaro Ovalle, Simon M. Lucas", "title": "Bootstrapped model learning and error correction for planning with\n  uncertainty in model-based RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Having access to a forward model enables the use of planning algorithms such\nas Monte Carlo Tree Search and Rolling Horizon Evolution. Where a model is\nunavailable, a natural aim is to learn a model that reflects accurately the\ndynamics of the environment. In many situations it might not be possible and\nminimal glitches in the model may lead to poor performance and failure. This\npaper explores the problem of model misspecification through uncertainty-aware\nreinforcement learning agents. We propose a bootstrapped multi-headed neural\nnetwork that learns the distribution of future states and rewards. We\nexperiment with a number of schemes to extract the most likely predictions.\nMoreover, we also introduce a global error correction filter that applies\nhigh-level constraints guided by the context provided through the predictive\ndistribution. We illustrate our approach on Minipacman. The evaluation\ndemonstrates that when dealing with imperfect models, our methods exhibit\nincreased performance and stability, both in terms of model accuracy and in its\nuse within a planning algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:41:21 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ovalle", "Alvaro", ""], ["Lucas", "Simon M.", ""]]}, {"id": "2004.07200", "submitter": "Jingkang Wang", "authors": "Tianshi Cao, Jingkang Wang, Yining Zhang, Sivabalan Manivasagam", "title": "BabyAI++: Towards Grounded-Language Learning beyond Memorization", "comments": "Accepted to the ICLR 2020 workshop: Beyond tabula rasa in RL\n  (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite success in many real-world tasks (e.g., robotics), reinforcement\nlearning (RL) agents still learn from tabula rasa when facing new and dynamic\nscenarios. By contrast, humans can offload this burden through textual\ndescriptions. Although recent works have shown the benefits of instructive\ntexts in goal-conditioned RL, few have studied whether descriptive texts help\nagents to generalize across dynamic environments. To promote research in this\ndirection, we introduce a new platform, BabyAI++, to generate various dynamic\nenvironments along with corresponding descriptive texts. Moreover, we benchmark\nseveral baselines inherited from the instruction following setting and develop\na novel approach towards visually-grounded language learning on our platform.\nExtensive experiments show strong evidence that using descriptive texts\nimproves the generalization of RL agents across environments with varied\ndynamics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:58:19 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Cao", "Tianshi", ""], ["Wang", "Jingkang", ""], ["Zhang", "Yining", ""], ["Manivasagam", "Sivabalan", ""]]}, {"id": "2004.07211", "submitter": "Pietro Buzzega", "authors": "Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, Simone\n  Calderara", "title": "Dark Experience for General Continual Learning: a Strong, Simple\n  Baseline", "comments": "24 pages, 4 figures. Accepted at 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning has inspired a plethora of approaches and evaluation\nsettings; however, the majority of them overlooks the properties of a practical\nscenario, where the data stream cannot be shaped as a sequence of tasks and\noffline training is not viable. We work towards General Continual Learning\n(GCL), where task boundaries blur and the domain and class distributions shift\neither gradually or suddenly. We address it through mixing rehearsal with\nknowledge distillation and regularization; our simple baseline, Dark Experience\nReplay, matches the network's logits sampled throughout the optimization\ntrajectory, thus promoting consistency with its past. By conducting an\nextensive analysis on both standard benchmarks and a novel GCL evaluation\nsetting (MNIST-360), we show that such a seemingly simple baseline outperforms\nconsolidated approaches and leverages limited resources. We further explore the\ngeneralization capabilities of our objective, showing its regularization being\nbeneficial beyond mere performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:13:05 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:00:23 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Buzzega", "Pietro", ""], ["Boschini", "Matteo", ""], ["Porrello", "Angelo", ""], ["Abati", "Davide", ""], ["Calderara", "Simone", ""]]}, {"id": "2004.07219", "submitter": "Justin Fu", "authors": "Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine", "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning", "comments": "Website available at https://sites.google.com/view/d4rl/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The offline reinforcement learning (RL) setting (also known as full batch\nRL), where a policy is learned from a static dataset, is compelling as progress\nenables RL methods to take advantage of large, previously-collected datasets,\nmuch like how the rise of large datasets has fueled results in supervised\nlearning. However, existing online RL benchmarks are not tailored towards the\noffline setting and existing offline RL benchmarks are restricted to data\ngenerated by partially-trained agents, making progress in offline RL difficult\nto measure. In this work, we introduce benchmarks specifically designed for the\noffline setting, guided by key properties of datasets relevant to real-world\napplications of offline RL. With a focus on dataset collection, examples of\nsuch properties include: datasets generated via hand-designed controllers and\nhuman demonstrators, multitask datasets where an agent performs different tasks\nin the same environment, and datasets collected with mixtures of policies. By\nmoving beyond simple benchmark tasks and data collected by partially-trained RL\nagents, we reveal important and unappreciated deficiencies of existing\nalgorithms. To facilitate research, we have released our benchmark tasks and\ndatasets with a comprehensive evaluation of existing algorithms, an evaluation\nprotocol, and open-source examples. This serves as a common starting point for\nthe community to identify shortcomings in existing offline RL methods and a\ncollaborative route for progress in this emerging area.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:18:19 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 00:03:09 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 16:32:03 GMT"}, {"version": "v4", "created": "Sat, 6 Feb 2021 01:57:28 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fu", "Justin", ""], ["Kumar", "Aviral", ""], ["Nachum", "Ofir", ""], ["Tucker", "George", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.07225", "submitter": "Zahra Fatemi", "authors": "Zahra Fatemi, Elena Zheleva", "title": "Minimizing Interference and Selection Bias in Network Experiment Design", "comments": "This paper has been accepted at the International AAAI Conference on\n  Web and Social Media (ICWSM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to A/B testing in networks focus on limiting interference,\nthe concern that treatment effects can \"spill over\" from treatment nodes to\ncontrol nodes and lead to biased causal effect estimation. Prominent methods\nfor network experiment design rely on two-stage randomization, in which\nsparsely-connected clusters are identified and cluster randomization dictates\nthe node assignment to treatment and control. Here, we show that cluster\nrandomization does not ensure sufficient node randomization and it can lead to\nselection bias in which treatment and control nodes represent different\npopulations of users. To address this problem, we propose a principled\nframework for network experiment design which jointly minimizes interference\nand selection bias. We introduce the concepts of edge spillover probability and\ncluster matching and demonstrate their importance for designing network A/B\ntesting. Our experiments on a number of real-world datasets show that our\nproposed framework leads to significantly lower error in causal effect\nestimation than existing solutions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:34:13 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Fatemi", "Zahra", ""], ["Zheleva", "Elena", ""]]}, {"id": "2004.07229", "submitter": "Deisy Morselli Gysi", "authors": "Deisy Morselli Gysi and \\'Italo Do Valle and Marinka Zitnik and Asher\n  Ameli and Xiao Gan and Onur Varol and Susan Dina Ghiassian and JJ Patten and\n  Robert Davey and Joseph Loscalzo and Albert-L\\'aszl\\'o Barab\\'asi", "title": "Network Medicine Framework for Identifying Drug Repurposing\n  Opportunities for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current pandemic has highlighted the need for methodologies that can\nquickly and reliably prioritize clinically approved compounds for their\npotential effectiveness for SARS-CoV-2 infections. In the past decade, network\nmedicine has developed and validated multiple predictive algorithms for drug\nrepurposing, exploiting the sub-cellular network-based relationship between a\ndrug's targets and disease genes. Here, we deployed algorithms relying on\nartificial intelligence, network diffusion, and network proximity, tasking each\nof them to rank 6,340 drugs for their expected efficacy against SARS-CoV-2. To\ntest the predictions, we used as ground truth 918 drugs that had been\nexperimentally screened in VeroE6 cells, and the list of drugs under clinical\ntrial, that capture the medical community's assessment of drugs with potential\nCOVID-19 efficacy. We find that while most algorithms offer predictive power\nfor these ground truth data, no single method offers consistently reliable\noutcomes across all datasets and metrics. This prompted us to develop a\nmultimodal approach that fuses the predictions of all algorithms, showing that\na consensus among the different predictive methods consistently exceeds the\nperformance of the best individual pipelines. We find that 76 of the 77 drugs\nthat successfully reduced viral infection do not bind the proteins targeted by\nSARS-CoV-2, indicating that these drugs rely on network-based actions that\ncannot be identified using docking-based strategies. These advances offer a\nmethodological pathway to identify repurposable drugs for future pathogens and\nneglected diseases underserved by the costs and extended timeline of de novo\ndrug development.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:40:29 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 15:52:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gysi", "Deisy Morselli", ""], ["Valle", "\u00cdtalo Do", ""], ["Zitnik", "Marinka", ""], ["Ameli", "Asher", ""], ["Gan", "Xiao", ""], ["Varol", "Onur", ""], ["Ghiassian", "Susan Dina", ""], ["Patten", "JJ", ""], ["Davey", "Robert", ""], ["Loscalzo", "Joseph", ""], ["Barab\u00e1si", "Albert-L\u00e1szl\u00f3", ""]]}, {"id": "2004.07234", "submitter": "Erez Peterfreund", "authors": "Erez Peterfreund, Ofir Lindenbaum, Felix Dietrich, Tom Bertalan, Matan\n  Gavish, Ioannis G. Kevrekidis, Ronald R. Coifman", "title": "LOCA: LOcal Conformal Autoencoder for standardized data coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep-learning based method for obtaining standardized data\ncoordinates from scientific measurements.Data observations are modeled as\nsamples from an unknown, non-linear deformation of an underlying Riemannian\nmanifold, which is parametrized by a few normalized latent variables. By\nleveraging a repeated measurement sampling strategy, we present a method for\nlearning an embedding in $\\mathbb{R}^d$ that is isometric to the latent\nvariables of the manifold. These data coordinates, being invariant under smooth\nchanges of variables, enable matching between different instrumental\nobservations of the same phenomenon. Our embedding is obtained using a LOcal\nConformal Autoencoder (LOCA), an algorithm that constructs an embedding to\nrectify deformations by using a local z-scoring procedure while preserving\nrelevant geometric information. We demonstrate the isometric embedding\nproperties of LOCA on various model settings and observe that it exhibits\npromising interpolation and extrapolation capabilities. Finally, we apply LOCA\nto single-site Wi-Fi localization data, and to $3$-dimensional curved surface\nestimation based on a $2$-dimensional projection.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:49:37 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 14:10:49 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Peterfreund", "Erez", ""], ["Lindenbaum", "Ofir", ""], ["Dietrich", "Felix", ""], ["Bertalan", "Tom", ""], ["Gavish", "Matan", ""], ["Kevrekidis", "Ioannis G.", ""], ["Coifman", "Ronald R.", ""]]}, {"id": "2004.07296", "submitter": "Neda Tavakoli", "authors": "Neda Tavakoli, Sima Siami-Namini, Mahdi Adl Khanghah, Fahimeh Mirza\n  Soltani, Akbar Siami Namin", "title": "Clustering Time Series Data through Autoencoder-based Deep Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and in particular deep learning algorithms are the emerging\napproaches to data analysis. These techniques have transformed traditional data\nmining-based analysis radically into a learning-based model in which existing\ndata sets along with their cluster labels (i.e., train set) are learned to\nbuild a supervised learning model and predict the cluster labels of unseen data\n(i.e., test set). In particular, deep learning techniques are capable of\ncapturing and learning hidden features in a given data sets and thus building a\nmore accurate prediction model for clustering and labeling problem. However,\nthe major problem is that time series data are often unlabeled and thus\nsupervised learning-based deep learning algorithms cannot be directly adapted\nto solve the clustering problems for these special and complex types of data\nsets. To address this problem, this paper introduces a two-stage method for\nclustering time series data. First, a novel technique is introduced to utilize\nthe characteristics (e.g., volatility) of given time series data in order to\ncreate labels and thus be able to transform the problem from unsupervised\nlearning into supervised learning. Second, an autoencoder-based deep learning\nmodel is built to learn and model both known and hidden features of time series\ndata along with their created labels to predict the labels of unseen time\nseries data. The paper reports a case study in which financial and stock time\nseries data of selected 70 stock indices are clustered into distinct groups\nusing the introduced two-stage procedure. The results show that the proposed\nprocedure is capable of achieving 87.5\\% accuracy in clustering and predicting\nthe labels for unseen time series data.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:51:13 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tavakoli", "Neda", ""], ["Siami-Namini", "Sima", ""], ["Khanghah", "Mahdi Adl", ""], ["Soltani", "Fahimeh Mirza", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "2004.07300", "submitter": "Jing Liu", "authors": "Yaoxin Li, Jing Liu, Guozheng Lin, Yueyuan Hou, Muyun Mou and Jiang\n  Zhang", "title": "Gumbel-softmax-based Optimization: A Simple General Framework for\n  Optimization Problems on Graphs", "comments": "arXiv admin note: text overlap with arXiv:1909.07018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer science, there exist a large number of optimization problems\ndefined on graphs, that is to find a best node state configuration or a network\nstructure such that the designed objective function is optimized under some\nconstraints. However, these problems are notorious for their hardness to solve\nbecause most of them are NP-hard or NP-complete. Although traditional general\nmethods such as simulated annealing (SA), genetic algorithms (GA) and so forth\nhave been devised to these hard problems, their accuracy and time consumption\nare not satisfying in practice. In this work, we proposed a simple, fast, and\ngeneral algorithm framework based on advanced automatic differentiation\ntechnique empowered by deep learning frameworks. By introducing Gumbel-softmax\ntechnique, we can optimize the objective function directly by gradient descent\nalgorithm regardless of the discrete nature of variables. We also introduce\nevolution strategy to parallel version of our algorithm. We test our algorithm\non three representative optimization problems on graph including modularity\noptimization from network science, Sherrington-Kirkpatrick (SK) model from\nstatistical physics, maximum independent set (MIS) and minimum vertex cover\n(MVC) problem from combinatorial optimization on graph. High-quality solutions\ncan be obtained with much less time consuming compared to traditional\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:11:00 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Li", "Yaoxin", ""], ["Liu", "Jing", ""], ["Lin", "Guozheng", ""], ["Hou", "Yueyuan", ""], ["Mou", "Muyun", ""], ["Zhang", "Jiang", ""]]}, {"id": "2004.07320", "submitter": "Angela Fan", "authors": "Angela Fan, Pierre Stock, Benjamin Graham, Edouard Grave, Remi\n  Gribonval, Herve Jegou, Armand Joulin", "title": "Training with Quantization Noise for Extreme Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of producing compact models, maximizing their accuracy\nfor a given model size. A standard solution is to train networks with\nQuantization Aware Training, where the weights are quantized during training\nand the gradients approximated with the Straight-Through Estimator. In this\npaper, we extend this approach to work beyond int8 fixed-point quantization\nwith extreme compression methods where the approximations introduced by STE are\nsevere, such as Product Quantization. Our proposal is to only quantize a\ndifferent random subset of weights during each forward, allowing for unbiased\ngradients to flow through the other weights. Controlling the amount of noise\nand its form allows for extreme compression rates while maintaining the\nperformance of the original model. As a result we establish new\nstate-of-the-art compromises between accuracy and model size both in natural\nlanguage processing and image classification. For example, applying our method\nto state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5%\naccuracy on MNLI by compressing RoBERTa to 14MB and 80.0 top-1 accuracy on\nImageNet by compressing an EfficientNet-B3 to 3.3MB.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 20:10:53 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 11:59:18 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 21:43:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Fan", "Angela", ""], ["Stock", "Pierre", ""], ["Graham", "Benjamin", ""], ["Grave", "Edouard", ""], ["Gribonval", "Remi", ""], ["Jegou", "Herve", ""], ["Joulin", "Armand", ""]]}, {"id": "2004.07341", "submitter": "Yuanfei Dai", "authors": "Yuanfei Dai, Chenhao Guo, Wenzhong Guo, Carsten Eickhoff", "title": "Drug-Drug Interaction Prediction with Wasserstein Adversarial\n  Autoencoder-based Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction between pharmacological agents can trigger unexpected adverse\nevents. Capturing richer and more comprehensive information about drug-drug\ninteractions (DDI) is one of the key tasks in public health and drug\ndevelopment. Recently, several knowledge graph embedding approaches have\nreceived increasing attention in the DDI domain due to their capability of\nprojecting drugs and interactions into a low-dimensional feature space for\npredicting links and classifying triplets. However, existing methods only apply\na uniformly random mode to construct negative samples. As a consequence, these\nsamples are often too simplistic to train an effective model. In this paper, we\npropose a new knowledge graph embedding framework by introducing adversarial\nautoencoders (AAE) based on Wasserstein distances and Gumbel-Softmax relaxation\nfor drug-drug interactions tasks. In our framework, the autoencoder is employed\nto generate high-quality negative samples and the hidden vector of the\nautoencoder is regarded as a plausible drug candidate. Afterwards, the\ndiscriminator learns the embeddings of drugs and interactions based on both\npositive and negative triplets. Meanwhile, in order to solve vanishing gradient\nproblems on the discrete representation--an inherent flaw in traditional\ngenerative models--we utilize the Gumbel-Softmax relaxation and the Wasserstein\ndistance to train the embedding model steadily. We empirically evaluate our\nmethod on two tasks, link prediction and DDI classification. The experimental\nresults show that our framework can attain significant improvements and\nnoticeably outperform competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:03:29 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:02:02 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Dai", "Yuanfei", ""], ["Guo", "Chenhao", ""], ["Guo", "Wenzhong", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2004.07348", "submitter": "Michael Trosset", "authors": "Michael W. Trosset, Mingyue Gao, Minh Tang, Carey E. Priebe", "title": "Learning 1-Dimensional Submanifolds for Subsequent Inference on Random\n  Dot Product Graphs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random dot product graph (RDPG) is a generative model for networks in which\nvertices correspond to positions in a latent Euclidean space and edge\nprobabilities are determined by the dot products of the latent positions. We\nconsider RDPGs for which the latent positions are randomly sampled from an\nunknown $1$-dimensional submanifold of the latent space. In principle,\nrestricted inference, i.e., procedures that exploit the structure of the\nsubmanifold, should be more effective than unrestricted inference; however, it\nis not clear how to conduct restricted inference when the submanifold is\nunknown. We submit that techniques for manifold learning can be used to learn\nthe unknown submanifold well enough to realize benefit from restricted\ninference. To illustrate, we test $1$- and $2$-sample hypotheses about the\nFr\\'{e}chet means of small communities of vertices, using the complete set of\nvertices to infer latent structure. We propose test statistics that deploy the\nIsomap procedure for manifold learning, using shortest path distances on\nneighborhood graphs constructed from estimated latent positions to estimate arc\nlengths on the unknown $1$-dimensional submanifold. Unlike conventional\napplications of Isomap, the estimated latent positions do not lie on the\nsubmanifold of interest. We extend existing convergence results for Isomap to\nthis setting and use them to demonstrate that, as the number of auxiliary\nvertices increases, the power of our test converges to the power of the\ncorresponding test when the submanifold is known.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:20:10 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:32:50 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 17:41:56 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 16:10:07 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Trosset", "Michael W.", ""], ["Gao", "Mingyue", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2004.07351", "submitter": "Richeng Jin", "authors": "Richeng Jin, Xiaofan He and Huaiyu Dai", "title": "On the Design of Communication Efficient Federated Learning over\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, federated learning (FL), as a promising distributed machine\nlearning approach, has attracted lots of research efforts. In FL, the parameter\nserver and the mobile devices share the training parameters over wireless\nlinks. As a result, reducing the communication overhead becomes one of the most\ncritical challenges. Despite that there have been various\ncommunication-efficient machine learning algorithms in literature, few of the\nexisting works consider their implementation over wireless networks. In this\nwork, the idea of SignSGD is adopted and only the signs of the gradients are\nshared between the mobile devices and the parameter server. In addition,\ndifferent from most of the existing works that consider Channel State\nInformation (CSI) at both the transmitter side and the receiver side, only\nreceiver side CSI is assumed. In such a case, an essential problem for the\nmobile devices is to select appropriate local processing and communication\nparameters. In particular, two tradeoffs are observed under a fixed total\ntraining time: (i) given the time for each communication round, the energy\nconsumption versus the outage probability per communication round and (ii)\ngiven the energy consumption, the number of communication rounds versus the\noutage probability per communication round. Two optimization problems regarding\nthe aforementioned two tradeoffs are formulated and solved. The first problem\nminimizes the energy consumption given the outage probability (and therefore\nthe learning performance) requirement while the second problem optimizes the\nlearning performance given the energy consumption requirement. Furthermore, the\nheterogeneous data distribution scenario is considered and a new algorithm that\ncan deal with heterogeneous data distribution is proposed. Extensive\nsimulations are performed to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:25:13 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 03:26:37 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Jin", "Richeng", ""], ["He", "Xiaofan", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2004.07370", "submitter": "Kaizhi Qian", "authors": "Kaizhi Qian, Zeyu Jin, Mark Hasegawa-Johnson, Gautham J. Mysore", "title": "F0-consistent many-to-many non-parallel voice conversion via conditional\n  autoencoder", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054734", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel many-to-many voice conversion remains an interesting but\nchallenging speech processing task. Many style-transfer-inspired methods such\nas generative adversarial networks (GANs) and variational autoencoders (VAEs)\nhave been proposed. Recently, AutoVC, a conditional autoencoders (CAEs) based\nmethod achieved state-of-the-art results by disentangling the speaker identity\nand speech content using information-constraining bottlenecks, and it achieves\nzero-shot conversion by swapping in a different speaker's identity embedding to\nsynthesize a new voice. However, we found that while speaker identity is\ndisentangled from speech content, a significant amount of prosodic information,\nsuch as source F0, leaks through the bottleneck, causing target F0 to fluctuate\nunnaturally. Furthermore, AutoVC has no control of the converted F0 and thus\nunsuitable for many applications. In the paper, we modified and improved\nautoencoder-based voice conversion to disentangle content, F0, and speaker\nidentity at the same time. Therefore, we can control the F0 contour, generate\nspeech with F0 consistent with the target speaker, and significantly improve\nquality and similarity. We support our improvement through quantitative and\nqualitative analysis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:00:06 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Qian", "Kaizhi", ""], ["Jin", "Zeyu", ""], ["Hasegawa-Johnson", "Mark", ""], ["Mysore", "Gautham J.", ""]]}, {"id": "2004.07375", "submitter": "Arman Oganisian", "authors": "Arman Oganisian, Jason A. Roy", "title": "A Practical Introduction to Bayesian Estimation of Causal Effects:\n  Parametric and Nonparametric Approaches", "comments": "Currently under second-round revision. This version included edits\n  from first round", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial advances in Bayesian methods for causal inference have been\ndeveloped in recent years. We provide an introduction to Bayesian inference for\ncausal effects for practicing statisticians who have some familiarity with\nBayesian models and would like an overview of what it can add to causal\nestimation in practical settings. In the paper, we demonstrate how priors can\ninduce shrinkage and sparsity on parametric models and be used to perform\nprobabilistic sensitivity analyses around causal assumptions. We provide an\noverview of nonparametric Bayesian estimation and survey their applications in\nthe causal inference literature. Inference in the point-treatment and\ntime-varying treatment settings are considered. For the latter, we explore both\nstatic and dynamic treatment regimes. Throughout, we illustrate implementation\nusing off-the-shelf open source software. We hope the reader will walk away\nwith implementation-level knowledge of Bayesian causal inference using both\nparametric and nonparametric models. All synthetic examples and code used in\nthe paper are publicly available on a companion GitHub repository.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:32:16 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 17:29:08 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Oganisian", "Arman", ""], ["Roy", "Jason A.", ""]]}, {"id": "2004.07383", "submitter": "Brian Lucena", "authors": "Brian Lucena", "title": "Exploiting Categorical Structure Using Tree-Based Methods", "comments": "To appear in AISTATS 2020 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods of using categorical variables as predictors either endow\nthem with an ordinal structure or assume they have no structure at all.\nHowever, categorical variables often possess structure that is more complicated\nthan a linear ordering can capture. We develop a mathematical framework for\nrepresenting the structure of categorical variables and show how to generalize\ndecision trees to make use of this structure. This approach is applicable to\nmethods such as Gradient Boosted Trees which use a decision tree as the\nunderlying learner. We show results on weather data to demonstrate the\nimprovement yielded by this approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:58:27 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lucena", "Brian", ""]]}, {"id": "2004.07384", "submitter": "Anirudh Som", "authors": "Afra Nawar, Farhan Rahman, Narayanan Krishnamurthi, Anirudh Som and\n  Pavan Turaga", "title": "Topological Descriptors for Parkinson's Disease Classification and\n  Regression Analysis", "comments": "Accepted in the 42nd Annual International Conferences of the IEEE\n  Engineering in Medicine and Biology Society (EMBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the vast majority of human subjects with neurological disease are\nstill diagnosed through in-person assessments and qualitative analysis of\npatient data. In this paper, we propose to use Topological Data Analysis (TDA)\ntogether with machine learning tools to automate the process of Parkinson's\ndisease classification and severity assessment. An automated, stable, and\naccurate method to evaluate Parkinson's would be significant in streamlining\ndiagnoses of patients and providing families more time for corrective measures.\nWe propose a methodology which incorporates TDA into analyzing Parkinson's\ndisease postural shifts data through the representation of persistence images.\nStudying the topology of a system has proven to be invariant to small changes\nin data and has been shown to perform well in discrimination tasks. The\ncontributions of the paper are twofold. We propose a method to 1) classify\nhealthy patients from those afflicted by disease and 2) diagnose the severity\nof disease. We explore the use of the proposed method in an application\ninvolving a Parkinson's disease dataset comprised of healthy-elderly,\nhealthy-young and Parkinson's disease patients. Our code is available at\nhttps://github.com/itsmeafra/Sublevel-Set-TDA.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:59:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 04:09:16 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Nawar", "Afra", ""], ["Rahman", "Farhan", ""], ["Krishnamurthi", "Narayanan", ""], ["Som", "Anirudh", ""], ["Turaga", "Pavan", ""]]}, {"id": "2004.07395", "submitter": "Manyou Ma", "authors": "Manyou Ma and Vincent W.S. Wong", "title": "Joint User Pairing and Association for Multicell NOMA: A Pointer\n  Network-based Approach", "comments": "accepted for publication in Proc. of 6th International Workshop on\n  NOMA for 5G and Beyond, co-located with IEEE International Conference on\n  Communications (ICC), Dublin, Ireland, Jun. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the joint user pairing and association problem\nfor multicell non-orthogonal multiple access (NOMA) systems. We consider a\nscenario where the user equipments (UEs) are located in a multicell network\nequipped with multiple base stations. Each base station has multiple orthogonal\nphysical resource blocks (PRBs). Each PRB can be allocated to a pair of UEs\nusing NOMA. Each UE has the additional freedom to be served by any one of the\nbase stations, which further increases the complexity of the joint user pairing\nand association algorithm design. Leveraging the recent success on using\nmachine learning to solve numerical optimization problems, we formulate the\njoint user pairing and association problem as a combinatorial optimization\nproblem. The solution is found using an emerging deep learning architecture\ncalled Pointer Network (PtrNet), which has a lower computational complexity\ncompared to solutions based on iterative algorithms and has been proven to\nachieve near-optimal performance. The training phase of the PtrNet is based on\ndeep reinforcement learning (DRL), and does not require the use of the optimal\nsolution of the formulated problem as training labels. Simulation results show\nthat the proposed joint user pairing and association scheme achieves\nnear-optimal performance in terms of the aggregate data rate, and outperforms\nthe random user pairing and association heuristic by up to 30%.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 23:42:19 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ma", "Manyou", ""], ["Wong", "Vincent W. S.", ""]]}, {"id": "2004.07401", "submitter": "David Solans", "authors": "David Solans, Battista Biggio, Carlos Castillo", "title": "Poisoning Attacks on Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in adversarial machine learning has shown how the performance of\nmachine learning models can be seriously compromised by injecting even a small\nfraction of poisoning points into the training data. While the effects on model\naccuracy of such poisoning attacks have been widely studied, their potential\neffects on other model performance metrics remain to be evaluated. In this\nwork, we introduce an optimization framework for poisoning attacks against\nalgorithmic fairness, and develop a gradient-based poisoning attack aimed at\nintroducing classification disparities among different groups in the data. We\nempirically show that our attack is effective not only in the white-box\nsetting, in which the attacker has full access to the target model, but also in\na more challenging black-box scenario in which the attacks are optimized\nagainst a substitute model and then transferred to the target model. We believe\nthat our findings pave the way towards the definition of an entirely novel set\nof adversarial attacks targeting algorithmic fairness in different scenarios,\nand that investigating such vulnerabilities will help design more robust\nalgorithms and countermeasures in the future.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 08:07:01 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:09:38 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 08:17:44 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Solans", "David", ""], ["Biggio", "Battista", ""], ["Castillo", "Carlos", ""]]}, {"id": "2004.07414", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Hyunsoo Chung, Jinhwi Lee, Minsu Cho, Jaesik Park", "title": "Combinatorial 3D Shape Generation via Sequential Assembly", "comments": "14 pages, 20 figures, 1 table, presented at NeurIPS 2020 Workshop on\n  Machine Learning for Engineering Modeling, Simulation, and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential assembly with geometric primitives has drawn attention in robotics\nand 3D vision since it yields a practical blueprint to construct a target\nshape. However, due to its combinatorial property, a greedy method falls short\nof generating a sequence of volumetric primitives. To alleviate this\nconsequence induced by a huge number of feasible combinations, we propose a\ncombinatorial 3D shape generation framework. The proposed framework reflects an\nimportant aspect of human generation processes in real life -- we often create\na 3D shape by sequentially assembling unit primitives with geometric\nconstraints. To find the desired combination regarding combination evaluations,\nwe adopt Bayesian optimization, which is able to exploit and explore\nefficiently the feasible regions constrained by the current primitive\nplacements. An evaluation function conveys global structure guidance for an\nassembly process and stability in terms of gravity and external forces\nsimultaneously. Experimental results demonstrate that our method successfully\ngenerates combinatorial 3D shapes and simulates more realistic generation\nprocesses. We also introduce a new dataset for combinatorial 3D shape\ngeneration. All the codes are available at\n\\url{https://github.com/POSTECH-CVLab/Combinatorial-3D-Shape-Generation}.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 01:23:14 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 03:51:49 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kim", "Jungtaek", ""], ["Chung", "Hyunsoo", ""], ["Lee", "Jinhwi", ""], ["Cho", "Minsu", ""], ["Park", "Jaesik", ""]]}, {"id": "2004.07473", "submitter": "Patrick Ebel", "authors": "Patrick Ebel, Ibrahim Emre G\\\"ol, Christoph Lingenfelder and Andreas\n  Vogelsang", "title": "Destination Prediction Based on Partial Trajectory Data", "comments": "2020 IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-thirds of the people who buy a new car prefer to use a substitute instead\nof the built-in navigation system. However, for many applications, knowledge\nabout a user's intended destination and route is crucial. For example,\nsuggestions for available parking spots close to the destination can be made or\nride-sharing opportunities along the route are facilitated. Our approach\npredicts probable destinations and routes of a vehicle, based on the most\nrecent partial trajectory and additional contextual data. The approach follows\na three-step procedure: First, a $k$-d tree-based space discretization is\nperformed, mapping GPS locations to discrete regions. Secondly, a recurrent\nneural network is trained to predict the destination based on partial sequences\nof trajectories. The neural network produces destination scores, signifying the\nprobability of each region being the destination. Finally, the routes to the\nmost probable destinations are calculated. To evaluate the method, we compare\nmultiple neural architectures and present the experimental results of the\ndestination prediction. The experiments are based on two public datasets of\nnon-personalized, timestamped GPS locations of taxi trips. The best performing\nmodels were able to predict the destination of a vehicle with a mean error of\n1.3 km and 1.43 km respectively.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 06:26:10 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ebel", "Patrick", ""], ["G\u00f6l", "Ibrahim Emre", ""], ["Lingenfelder", "Christoph", ""], ["Vogelsang", "Andreas", ""]]}, {"id": "2004.07507", "submitter": "Janghyeon Lee", "authors": "Janghyeon Lee, Hyeong Gwon Hong, Donggyu Joo, Junmo Kim", "title": "Continual Learning with Extended Kronecker-factored Approximate\n  Curvature", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a quadratic penalty method for continual learning of neural\nnetworks that contain batch normalization (BN) layers. The Hessian of a loss\nfunction represents the curvature of the quadratic penalty function, and a\nKronecker-factored approximate curvature (K-FAC) is used widely to practically\ncompute the Hessian of a neural network. However, the approximation is not\nvalid if there is dependence between examples, typically caused by BN layers in\ndeep network architectures. We extend the K-FAC method so that the\ninter-example relations are taken into account and the Hessian of deep neural\nnetworks can be properly approximated under practical assumptions. We also\npropose a method of weight merging and reparameterization to properly handle\nstatistical parameters of BN, which plays a critical role for continual\nlearning with BN, and a method that selects hyperparameters without source task\ndata. Our method shows better performance than baselines in the permuted MNIST\ntask with BN layers and in sequential learning from the ImageNet classification\ntask to fine-grained classification tasks with ResNet-50, without any explicit\nor implicit use of source task data for hyperparameter selection.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:58:47 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lee", "Janghyeon", ""], ["Hong", "Hyeong Gwon", ""], ["Joo", "Donggyu", ""], ["Kim", "Junmo", ""]]}, {"id": "2004.07512", "submitter": "Dr. Pooja Saigal", "authors": "Pooja Saigal, Reshma Khemchandani", "title": "Nonparallel Hyperplane Classifiers for Multi-category Classification", "comments": "6 Pages. Applications and Future Directions (WCI). IEEE, 2015", "journal-ref": null, "doi": "10.1109/WCI.2015.7495510", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machines (SVMs) are widely used for solving classification and\nregression problems. Recently, various nonparallel hyperplanes classification\nalgorithms (NHCAs) have been proposed, which are comparable in terms of\nclassification accuracy when compared with SVM but are computationally more\nefficient. All these NHCAs are originally proposed for binary classification\nproblems. Since, most of the real world classification problems deal with\nmultiple classes, these algorithms are extended in multi-category scenario. In\nthis paper, we present a comparative study of four NHCAs i.e. Twin SVM (TWSVM),\nGeneralized eigenvalue proximal SVM (GEPSVM), Regularized GEPSVM (RegGEPSVM)\nand Improved GEPSVM (IGEPSVM)for multi-category classification. The\nmulti-category classification algorithms for NHCA classifiers are implemented\nusing OneAgainst-All (OAA), binary tree-based (BT) and ternary decision\nstructure (TDS) approaches and the experiments are performed on benchmark UCI\ndatasets. The experimental results show that TDS-TWSVM outperforms other\nmethods in terms of classification accuracy and BT-RegGEPSVM takes the minimum\ntime for building the classifier\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:03:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Saigal", "Pooja", ""], ["Khemchandani", "Reshma", ""]]}, {"id": "2004.07530", "submitter": "Christos Kaplanis", "authors": "Christos Kaplanis, Claudia Clopath, and Murray Shanahan", "title": "Continual Reinforcement Learning with Multi-Timescale Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a multi-timescale replay (MTR) buffer for improving\ncontinual learning in RL agents faced with environments that are changing\ncontinuously over time at timescales that are unknown to the agent. The basic\nMTR buffer comprises a cascade of sub-buffers that accumulate experiences at\ndifferent timescales, enabling the agent to improve the trade-off between\nadaptation to new data and retention of old knowledge. We also combine the MTR\nframework with invariant risk minimization, with the idea of encouraging the\nagent to learn a policy that is robust across the various environments it\nencounters over time. The MTR methods are evaluated in three different\ncontinual learning settings on two continuous control tasks and, in many cases,\nshow improvement over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:47:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kaplanis", "Christos", ""], ["Clopath", "Claudia", ""], ["Shanahan", "Murray", ""]]}, {"id": "2004.07534", "submitter": "Mahmoud Hossam", "authors": "Mahmoud Hossam, Trung Le, Viet Huynh, Michael Papasimeon, and Dinh\n  Phung", "title": "OptiGAN: Generative Adversarial Networks for Goal Optimized Sequence\n  Generation", "comments": "Preprint for accepted conference paper at International Joint\n  Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenging problems in sequence generation tasks is the optimized\ngeneration of sequences with specific desired goals. Current sequential\ngenerative models mainly generate sequences to closely mimic the training data,\nwithout direct optimization of desired goals or properties specific to the\ntask. We introduce OptiGAN, a generative model that incorporates both\nGenerative Adversarial Networks (GAN) and Reinforcement Learning (RL) to\noptimize desired goal scores using policy gradients. We apply our model to text\nand real-valued sequence generation, where our model is able to achieve higher\ndesired scores out-performing GAN and RL baselines, while not sacrificing\noutput sample diversity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:54:00 GMT"}, {"version": "v10", "created": "Thu, 14 Jan 2021 08:13:27 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 01:48:42 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 09:32:36 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 23:51:52 GMT"}, {"version": "v5", "created": "Wed, 2 Sep 2020 20:14:13 GMT"}, {"version": "v6", "created": "Mon, 14 Sep 2020 23:58:04 GMT"}, {"version": "v7", "created": "Wed, 16 Sep 2020 01:55:15 GMT"}, {"version": "v8", "created": "Thu, 15 Oct 2020 08:47:50 GMT"}, {"version": "v9", "created": "Wed, 18 Nov 2020 20:26:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hossam", "Mahmoud", ""], ["Le", "Trung", ""], ["Huynh", "Viet", ""], ["Papasimeon", "Michael", ""], ["Phung", "Dinh", ""]]}, {"id": "2004.07543", "submitter": "Saisubramaniam Gopalakrishnan Mr", "authors": "Saisubramaniam Gopalakrishnan, Pranshu Ranjan Singh, Yasin Yazici,\n  Chuan-Sheng Foo, Vijay Chandrasekhar, ArulMurugan Ambikapathi", "title": "Classification Representations Can be Reused for Downstream Generations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrary to the convention of using supervision for class-conditioned\n$\\it{generative}$ $\\it{modeling}$, this work explores and demonstrates the\nfeasibility of a learned supervised representation space trained on a\ndiscriminative classifier for the $\\it{downstream}$ task of sample generation.\nUnlike generative modeling approaches that aim to $\\it{model}$ the manifold\ndistribution, we directly $\\it{represent}$ the given data manifold in the\nclassification space and leverage properties of latent space representations to\ngenerate new representations that are guaranteed to be in the same class.\nInterestingly, such representations allow for controlled sample generations for\nany given class from existing samples and do not require enforcing prior\ndistribution. We show that these latent space representations can be smartly\nmanipulated (using convex combinations of $n$ samples, $n\\geq2$) to yield\nmeaningful sample generations. Experiments on image datasets of varying\nresolutions demonstrate that downstream generations have higher classification\naccuracy than existing conditional generative models while being competitive in\nterms of FID.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 09:13:44 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Gopalakrishnan", "Saisubramaniam", ""], ["Singh", "Pranshu Ranjan", ""], ["Yazici", "Yasin", ""], ["Foo", "Chuan-Sheng", ""], ["Chandrasekhar", "Vijay", ""], ["Ambikapathi", "ArulMurugan", ""]]}, {"id": "2004.07605", "submitter": "Anil Goyal", "authors": "Anil Goyal and Jihed Khiari", "title": "Diversity-Aware Weighted Majority Vote Classifier for Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a diversity-aware ensemble learning based\nalgorithm, referred to as DAMVI, to deal with imbalanced binary classification\ntasks. Specifically, after learning base classifiers, the algorithm i)\nincreases the weights of positive examples (minority class) which are \"hard\" to\nclassify with uniformly weighted base classifiers; and ii) then learns weights\nover base classifiers by optimizing the PAC-Bayesian C-Bound that takes into\naccount the accuracy and diversity between the classifiers. We show efficiency\nof the proposed approach with respect to state-of-art models on predictive\nmaintenance task, credit card fraud detection, webpage classification and\nmedical applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 11:27:50 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Goyal", "Anil", ""], ["Khiari", "Jihed", ""]]}, {"id": "2004.07636", "submitter": "Stratis Limnios", "authors": "Stratis Limnios, George Dasoulas, Dimitrios M. Thilikos, Michalis\n  Vazirgiannis", "title": "Hcore-Init: Neural Network Initialization based on Graph Degeneracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are the pinnacle of Artificial Intelligence, as in recent\nyears we witnessed many novel architectures, learning and optimization\ntechniques for deep learning. Capitalizing on the fact that neural networks\ninherently constitute multipartite graphs among neuron layers, we aim to\nanalyze directly their structure to extract meaningful information that can\nimprove the learning process. To our knowledge graph mining techniques for\nenhancing learning in neural networks have not been thoroughly investigated. In\nthis paper we propose an adapted version of the k-core structure for the\ncomplete weighted multipartite graph extracted from a deep learning\narchitecture. As a multipartite graph is a combination of bipartite graphs,\nthat are in turn the incidence graphs of hypergraphs, we design k-hypercore\ndecomposition, the hypergraph analogue of k-core degeneracy. We applied\nk-hypercore to several neural network architectures, more specifically to\nconvolutional neural networks and multilayer perceptrons for image recognition\ntasks after a very short pretraining. Then we used the information provided by\nthe hypercore numbers of the neurons to re-initialize the weights of the neural\nnetwork, thus biasing the gradient optimization scheme. Extensive experiments\nproved that k-hypercore outperforms the state-of-the-art initialization\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 12:57:14 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Limnios", "Stratis", ""], ["Dasoulas", "George", ""], ["Thilikos", "Dimitrios M.", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2004.07641", "submitter": "Lars Lorch", "authors": "Lars Lorch, Heiner Kremer, William Trouleau, Stratis Tsirtsis, Aron\n  Szanto, Bernhard Sch\\\"olkopf, and Manuel Gomez-Rodriguez", "title": "Quantifying the Effects of Contact Tracing, Testing, and Containment\n  Measures in the Presence of Infection Hotspots", "comments": "Statistical tests for overdispersion of secondary infections; contour\n  plots for parameter estimation; corrected experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple lines of evidence strongly suggest that infection hotspots, where a\nsingle individual infects many others, play a key role in the transmission\ndynamics of COVID-19. However, most of the existing epidemiological models fail\nto capture this aspect by neither representing the sites visited by individuals\nexplicitly nor characterizing disease transmission as a function of individual\nmobility patterns. In this work, we introduce a temporal point process modeling\nframework that specifically represents visits to the sites where individuals\nget in contact and infect each other. Under our model, the number of infections\ncaused by an infectious individual naturally emerges to be overdispersed. Using\nan efficient sampling algorithm, we demonstrate how to apply Bayesian\noptimization with longitudinal case data to estimate the transmission rate of\ninfectious individuals at the sites they visit and in their households.\nSimulations using fine-grained and publicly available demographic data and site\nlocations from Bern, Switzerland showcase the flexibility of our framework. To\nfacilitate research and analyses of other cities and regions, we release an\nopen-source implementation of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:18:32 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:29:32 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 13:58:12 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 13:36:24 GMT"}, {"version": "v5", "created": "Tue, 18 May 2021 13:15:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Lorch", "Lars", ""], ["Kremer", "Heiner", ""], ["Trouleau", "William", ""], ["Tsirtsis", "Stratis", ""], ["Szanto", "Aron", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2004.07644", "submitter": "Dawei Liu", "authors": "Dawei Liu, Zhiyi Tang, Yuequan Bao, Hui Li", "title": "Machine-learning-based methods for output only structural modal\n  identification", "comments": "21 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a machine-learning-based approach to identify the\nmodal parameters of the output-only data for structural health monitoring (SHM)\nthat makes full use of the characteristic of independence of modal responses\nand the principle of machine learning. By taking advantage of the independence\nfeature of each mode, we use the principle of unsupervised learning, making the\ntraining process of the deep neural network becomes the process of modal\nseparation. A self-coding deep neural network is designed to identify the\nstructural modal parameters from the vibration data of structures. The mixture\nsignals, that is, the structural response data, are used as the input of the\nneural network. Then we use a complex loss function to restrict the training\nprocess of the neural network, making the output of the third layer the modal\nresponses we want, and the weights of the last two layers are mode shapes. The\ndeep neural network is essentially a nonlinear objective function optimization\nproblem. A novel loss function is proposed to constrain the independent feature\nwith consideration of uncorrelation and non-Gaussianity to restrict the\ndesigned neural network to obtain the structural modal parameters. A numerical\nexample of a simple structure and an example of actual SHM data from a\ncable-stayed bridge are presented to illustrate the modal parameter\nidentification ability of the proposed approach. The results show the\napproach's good capability in blindly extracting modal information from system\nresponses.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 13:26:16 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 01:13:48 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Liu", "Dawei", ""], ["Tang", "Zhiyi", ""], ["Bao", "Yuequan", ""], ["Li", "Hui", ""]]}, {"id": "2004.07692", "submitter": "Jan Sokolowski", "authors": "Jan Sokolowski, Volker Schulz, Udo Schr\\\"oder, Hans-Peter Beise", "title": "A Hybrid Objective Function for Robustness of Artificial Neural Networks\n  -- Estimation of Parameters in a Mechanical System", "comments": "16 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several studies, hybrid neural networks have proven to be more robust\nagainst noisy input data compared to plain data driven neural networks. We\nconsider the task of estimating parameters of a mechanical vehicle model based\non acceleration profiles. We introduce a convolutional neural network\narchitecture that is capable to predict the parameters for a family of vehicle\nmodels that differ in the unknown parameters. We introduce a convolutional\nneural network architecture that given sequential data predicts the parameters\nof the underlying data's dynamics. This network is trained with two objective\nfunctions. The first one constitutes a more naive approach that assumes that\nthe true parameters are known. The second objective incorporates the knowledge\nof the underlying dynamics and is therefore considered as hybrid approach. We\nshow that in terms of robustness, the latter outperforms the first objective on\nnoisy input data.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:06:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Sokolowski", "Jan", ""], ["Schulz", "Volker", ""], ["Schr\u00f6der", "Udo", ""], ["Beise", "Hans-Peter", ""]]}, {"id": "2004.07707", "submitter": "Declan Oller", "authors": "Declan Oller, Tobias Glasmachers, Giuseppe Cuccu", "title": "Analyzing Reinforcement Learning Benchmarks with Random Weight Guessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for analyzing and visualizing the complexity of\nstandard reinforcement learning (RL) benchmarks based on score distributions. A\nlarge number of policy networks are generated by randomly guessing their\nparameters, and then evaluated on the benchmark task; the study of their\naggregated results provide insights into the benchmark complexity. Our method\nguarantees objectivity of evaluation by sidestepping learning altogether: the\npolicy network parameters are generated using Random Weight Guessing (RWG),\nmaking our method agnostic to (i) the classic RL setup, (ii) any learning\nalgorithm, and (iii) hyperparameter tuning. We show that this approach isolates\nthe environment complexity, highlights specific types of challenges, and\nprovides a proper foundation for the statistical analysis of the task's\ndifficulty. We test our approach on a variety of classic control benchmarks\nfrom the OpenAI Gym, where we show that small untrained networks can provide a\nrobust baseline for a variety of tasks. The networks generated often show good\nperformance even without gradual learning, incidentally highlighting the\ntriviality of a few popular benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:32:52 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Oller", "Declan", ""], ["Glasmachers", "Tobias", ""], ["Cuccu", "Giuseppe", ""]]}, {"id": "2004.07715", "submitter": "Siddharth Tourani", "authors": "Siddharth Tourani, Alexander Shekhovtsov, Carsten Rother, Bogdan\n  Savchynskyy", "title": "Taxonomy of Dual Block-Coordinate Ascent Methods for Discrete Energy\n  Minimization", "comments": "Accepted in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the maximum-a-posteriori inference problem in discrete graphical\nmodels and study solvers based on the dual block-coordinate ascent rule. We map\nall existing solvers in a single framework, allowing for a better understanding\nof their design principles. We theoretically show that some block-optimizing\nupdates are sub-optimal and how to strictly improve them. On a wide range of\nproblem instances of varying graph connectivity, we study the performance of\nexisting solvers as well as new variants that can be obtained within the\nframework. As a result of this exploration we build a new state-of-the art\nsolver, performing uniformly better on the whole range of test instances.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:49:13 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tourani", "Siddharth", ""], ["Shekhovtsov", "Alexander", ""], ["Rother", "Carsten", ""], ["Savchynskyy", "Bogdan", ""]]}, {"id": "2004.07736", "submitter": "Sandrine G\\\"umbel", "authors": "Sandrine G\\\"umbel, Thorsten Schmidt", "title": "Machine learning for multiple yield curve markets: fast calibration in\n  the Gaussian affine framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR math.PR q-fin.MF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration is a highly challenging task, in particular in multiple yield\ncurve markets. This paper is a first attempt to study the chances and\nchallenges of the application of machine learning techniques for this. We\nemploy Gaussian process regression, a machine learning methodology having many\nsimilarities with extended Kalman filtering - a technique which has been\napplied many times to interest rate markets and term structure models.\n  We find very good results for the single curve markets and many challenges\nfor the multi curve markets in a Vasicek framework. The Gaussian process\nregression is implemented with the Adam optimizer and the non-linear conjugate\ngradient method, where the latter performs best. We also point towards future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:16:39 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 14:21:43 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["G\u00fcmbel", "Sandrine", ""], ["Schmidt", "Thorsten", ""]]}, {"id": "2004.07740", "submitter": "Marcel Neunhoeffer", "authors": "Christian Arnold and Marcel Neunhoeffer", "title": "Really Useful Synthetic Data -- A Framework to Evaluate the Quality of\n  Differentially Private Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in generating synthetic data that allow to add principled\nways of protecting privacy -- such as Differential Privacy -- are a crucial\nstep in sharing statistical information in a privacy preserving way. But while\nthe focus has been on privacy guarantees, the resulting private synthetic data\nis only useful if it still carries statistical information from the original\ndata. To further optimise the inherent trade-off between data privacy and data\nquality, it is necessary to think closely about the latter. What is it that\ndata analysts want? Acknowledging that data quality is a subjective concept, we\ndevelop a framework to evaluate the quality of differentially private synthetic\ndata from an applied researcher's perspective. Data quality can be measured\nalong two dimensions. First, quality of synthetic data can be evaluated against\ntraining data or against an underlying population. Second, the quality of\nsynthetic data depends on general similarity of distributions or specific tasks\nsuch as inference or prediction. It is clear that accommodating all goals at\nonce is a formidable challenge. We invite the academic community to jointly\nadvance the privacy-quality frontier.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:24:22 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Arnold", "Christian", ""], ["Neunhoeffer", "Marcel", ""]]}, {"id": "2004.07754", "submitter": "Sarah Fabi", "authors": "Sarah Fabi, Sebastian Otte, Jonas Gregor Wiese, Martin V. Butz", "title": "Investigating Efficient Learning and Compositionality in Generative LSTM\n  Networks", "comments": "ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing human with artificial intelligence, one major difference is\napparent: Humans can generalize very broadly from sparse data sets because they\nare able to recombine and reintegrate data components in compositional manners.\nTo investigate differences in efficient learning, Joshua B. Tenenbaum and\ncolleagues developed the character challenge: First an algorithm is trained in\ngenerating handwritten characters. In a next step, one version of a new type of\ncharacter is presented. An efficient learning algorithm is expected to be able\nto re-generate this new character, to identify similar versions of this\ncharacter, to generate new variants of it, and to create completely new\ncharacter types. In the past, the character challenge was only met by complex\nalgorithms that were provided with stochastic primitives. Here, we tackle the\nchallenge without providing primitives. We apply a minimal recurrent neural\nnetwork (RNN) model with one feedforward layer and one LSTM layer and train it\nto generate sequential handwritten character trajectories from one-hot encoded\ninputs. To manage the re-generation of untrained characters, when presented\nwith only one example of them, we introduce a one-shot inference mechanism: the\ngradient signal is backpropagated to the feedforward layer weights only,\nleaving the LSTM layer untouched. We show that our model is able to meet the\ncharacter challenge by recombining previously learned dynamic substructures,\nwhich are visible in the hidden LSTM states. Making use of the compositional\nabilities of RNNs in this way might be an important step towards bridging the\ngap between human and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:41:44 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:50:24 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Fabi", "Sarah", ""], ["Otte", "Sebastian", ""], ["Wiese", "Jonas Gregor", ""], ["Butz", "Martin V.", ""]]}, {"id": "2004.07757", "submitter": "Parikshit Pareek", "authors": "Parikshit Pareek and Hung D. Nguyen", "title": "Gaussian Process Learning-based Probabilistic Optimal Power Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we present a novel Gaussian Process Learning-based\nProbabilistic Optimal Power Flow (GP-POPF) for solving POPF under renewable and\nload uncertainties of arbitrary distribution. The proposed method relies on a\nnon-parametric Bayesian inference-based uncertainty propagation approach,\ncalled Gaussian Process (GP). We also suggest a new type of sensitivity called\nSubspace-wise Sensitivity, using observations on the interpretability of\nGP-POPF hyperparameters. The simulation results on 14-bus and 30-bus systems\nshow that the proposed method provides reasonably accurate solutions when\ncompared with Monte-Carlo Simulations (MCS) solutions at different levels of\nuncertain renewable penetration as well as load uncertainties, while requiring\nmuch less number of samples and elapsed time.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:49:31 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Pareek", "Parikshit", ""], ["Nguyen", "Hung D.", ""]]}, {"id": "2004.07782", "submitter": "Mostafa Karimi", "authors": "Mostafa Karimi, Arman Hasanzadeh and Yang shen", "title": "Network-principled deep generative models for designing drug\n  combinations as graph sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combination therapy has shown to improve therapeutic efficacy while reducing\nside effects. Importantly, it has become an indispensable strategy to overcome\nresistance in antibiotics, anti-microbials, and anti-cancer drugs. Facing\nenormous chemical space and unclear design principles for small-molecule\ncombinations, the computational drug-combination design has not seen generative\nmodels to meet its potential to accelerate resistance-overcoming drug\ncombination discovery. We have developed the first deep generative model for\ndrug combination design, by jointly embedding graph-structured domain knowledge\nand iteratively training a reinforcement learning-based chemical graph-set\ndesigner. First, we have developed Hierarchical Variational Graph Auto-Encoders\n(HVGAE) trained end-to-end to jointly embed gene-gene, gene-disease, and\ndisease-disease networks. Novel attentional pooling is introduced here for\nlearning disease-representations from associated genes' representations.\nSecond, targeting diseases in learned representations, we have recast the\ndrug-combination design problem as graph-set generation and developed a deep\nlearning-based model with novel rewards. Specifically, besides chemical\nvalidity rewards, we have introduced a novel generative adversarial award,\nbeing generalized sliced Wasserstein, for chemically diverse molecules with\ndistributions similar to known drugs. We have also designed a network\nprinciple-based reward for drug combinations. Numerical results indicate that,\ncompared to graph embedding methods, HVGAE learns more informative and\ngeneralizable disease representations. Case studies on four diseases show that\nnetwork-principled drug combinations tend to have low toxicity. The generated\ndrug combinations collectively cover the disease module similar to FDA-approved\ndrug combinations and could potentially suggest novel systems-pharmacology\nstrategies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:22:39 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 22:38:15 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Karimi", "Mostafa", ""], ["Hasanzadeh", "Arman", ""], ["shen", "Yang", ""]]}, {"id": "2004.07790", "submitter": "Joe Stacey", "authors": "Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Sebastian Riedel,\n  Tim Rockt\\\"aschel", "title": "Avoiding the Hypothesis-Only Bias in Natural Language Inference via\n  Ensemble Adversarial Training", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) datasets contain annotation artefacts\nresulting in spurious correlations between the natural language utterances and\ntheir respective entailment classes. These artefacts are exploited by neural\nnetworks even when only considering the hypothesis and ignoring the premise,\nleading to unwanted biases. Belinkov et al. (2019b) proposed tackling this\nproblem via adversarial training, but this can lead to learned sentence\nrepresentations that still suffer from the same biases. We show that the bias\ncan be reduced in the sentence representations by using an ensemble of\nadversaries, encouraging the model to jointly decrease the accuracy of these\ndifferent adversaries while fitting the data. This approach produces more\nrobust NLI models, outperforming previous de-biasing efforts when generalised\nto 12 other datasets (Belinkov et al., 2019a; Mahabadi et al., 2020). In\naddition, we find that the optimal number of adversarial classifiers depends on\nthe dimensionality of the sentence representations, with larger sentence\nrepresentations being more difficult to de-bias while benefiting from using a\ngreater number of adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:37:15 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 17:19:14 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:47:32 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2020 17:12:15 GMT"}, {"version": "v5", "created": "Thu, 27 May 2021 17:14:46 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Stacey", "Joe", ""], ["Minervini", "Pasquale", ""], ["Dubossarsky", "Haim", ""], ["Riedel", "Sebastian", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2004.07802", "submitter": "Mikhail Khodak", "authors": "Liam Li, Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar", "title": "Geometry-Aware Gradient Algorithms for Neural Architecture Search", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art methods for neural architecture search (NAS) exploit\ngradient-based optimization by relaxing the problem into continuous\noptimization over architectures and shared-weights, a noisy process that\nremains poorly understood. We argue for the study of single-level empirical\nrisk minimization to understand NAS with weight-sharing, reducing the design of\nNAS methods to devising optimizers and regularizers that can quickly obtain\nhigh-quality solutions to this problem. Invoking the theory of mirror descent,\nwe present a geometry-aware framework that exploits the underlying structure of\nthis optimization to return sparse architectural parameters, leading to simple\nyet novel algorithms that enjoy fast convergence guarantees and achieve\nstate-of-the-art accuracy on the latest NAS benchmarks in computer vision.\nNotably, we exceed the best published results for both CIFAR and ImageNet on\nboth the DARTS search space and NAS-Bench201; on the latter we achieve\nnear-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory\nand experiments demonstrate a principled way to co-design optimizers and\ncontinuous relaxations of discrete NAS search spaces.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:46:39 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 16:03:42 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 22:20:48 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 14:44:17 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 17:47:28 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Li", "Liam", ""], ["Khodak", "Mikhail", ""], ["Balcan", "Maria-Florina", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2004.07804", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Igor Mordatch, Vikash Kumar", "title": "A Game Theoretic Framework for Model Based Reinforcement Learning", "comments": "ICML 2020. This version contains expanded discussion, hyperparameter\n  configurations, and ablation studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) has recently gained immense\ninterest due to its potential for sample efficiency and ability to incorporate\noff-policy data. However, designing stable and efficient MBRL algorithms using\nrich function approximators have remained challenging. To help expose the\npractical challenges in MBRL and simplify algorithm design from the lens of\nabstraction, we develop a new framework that casts MBRL as a game between: (1)\na policy player, which attempts to maximize rewards under the learned model;\n(2) a model player, which attempts to fit the real-world data collected by the\npolicy player. For algorithm development, we construct a Stackelberg game\nbetween the two players, and show that it can be solved with approximate\nbi-level optimization. This gives rise to two natural families of algorithms\nfor MBRL based on which player is chosen as the leader in the Stackelberg game.\nTogether, they encapsulate, unify, and generalize many previous MBRL\nalgorithms. Furthermore, our framework is consistent with and provides a clear\nbasis for heuristics known to be important in practice from prior works.\nFinally, through experiments we validate that our proposed algorithms are\nhighly sample efficient, match the asymptotic performance of model-free policy\ngradient, and scale gracefully to high-dimensional tasks like dexterous hand\nmanipulation. Additional details and code can be obtained from the project page\nat https://sites.google.com/view/mbrl-game\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:51:45 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 05:52:14 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Mordatch", "Igor", ""], ["Kumar", "Vikash", ""]]}, {"id": "2004.07807", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim and Bharathi Raja Chakravarthi and John P. McCrae and\n  Michael Cochez", "title": "Classification Benchmarks for Under-resourced Bengali Language based on\n  Multichannel Convolutional-LSTM Network", "comments": "This paper is under review in the Journal of Natural Language\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices but also\nenables people to express anti-social behaviour like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behaviours analysis, document\ncharacterization, and sentiment analysis by predicting the contexts mostly for\nhighly resourced languages such as English. However, there are languages that\nare under-resources, e.g., South Asian languages like Bengali, Tamil, Assamese,\nTelugu that lack of computational resources for the NLP tasks. In this paper,\nwe provide several classification benchmarks for Bengali, an under-resourced\nlanguage. We prepared three datasets of expressing hate, commonly used topics,\nand opinions for hate speech detection, document classification, and sentiment\nanalysis, respectively. We built the largest Bengali word embedding models to\ndate based on 250 million articles, which we call BengFastText. We perform\nthree different experiments, covering document classification, sentiment\nanalysis, and hate speech detection. We incorporate word embeddings into a\nMultichannel Convolutional-LSTM (MConv-LSTM) network for predicting different\ntypes of hate speech, document classification, and sentiment analysis.\nExperiments demonstrate that BengFastText can capture the semantics of words\nfrom respective contexts correctly. Evaluations against several baseline\nembedding models, e.g., Word2Vec and GloVe yield up to 92.30%, 82.25%, and\n90.45% F1-scores in case of document classification, sentiment analysis, and\nhate speech detection, respectively during 5-fold cross-validation tests.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 22:17:04 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 17:21:30 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Chakravarthi", "Bharathi Raja", ""], ["McCrae", "John P.", ""], ["Cochez", "Michael", ""]]}, {"id": "2004.07839", "submitter": "Eliad Tsfadia", "authors": "Haim Kaplan, Yishay Mansour, Uri Stemmer, Eliad Tsfadia", "title": "Private Learning of Halfspaces: Simplifying the Construction and\n  Reducing the Sample Complexity", "comments": "Accepted to NeurIPS 2020. In this version we added a new section\n  about our new method for privately optimizing high-dimensional functions.\n  arXiv admin note: text overlap with arXiv:1902.10731", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a differentially private learner for halfspaces over a finite grid\n$G$ in $\\mathbb{R}^d$ with sample complexity $\\approx d^{2.5}\\cdot\n2^{\\log^*|G|}$, which improves the state-of-the-art result of [Beimel et al.,\nCOLT 2019] by a $d^2$ factor. The building block for our learner is a new\ndifferentially private algorithm for approximately solving the linear\nfeasibility problem: Given a feasible collection of $m$ linear constraints of\nthe form $Ax\\geq b$, the task is to privately identify a solution $x$ that\nsatisfies most of the constraints. Our algorithm is iterative, where each\niteration determines the next coordinate of the constructed solution $x$.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:12:10 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 09:44:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Stemmer", "Uri", ""], ["Tsfadia", "Eliad", ""]]}, {"id": "2004.07871", "submitter": "Ali Siahkoohi", "authors": "Gabrio Rizzuti and Ali Siahkoohi and Philipp A. Witte and Felix J.\n  Herrmann", "title": "Parameterizing uncertainty by deep invertible networks, an application\n  to reservoir characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification for full-waveform inversion provides a\nprobabilistic characterization of the ill-conditioning of the problem,\ncomprising the sensitivity of the solution with respect to the starting model\nand data noise. This analysis allows to assess the confidence in the candidate\nsolution and how it is reflected in the tasks that are typically performed\nafter imaging (e.g., stratigraphic segmentation following reservoir\ncharacterization). Classically, uncertainty comes in the form of a probability\ndistribution formulated from Bayesian principles, from which we seek to obtain\nsamples. A popular solution involves Monte Carlo sampling. Here, we propose\ninstead an approach characterized by training a deep network that \"pushes\nforward\" Gaussian random inputs into the model space (representing, for\nexample, density or velocity) as if they were sampled from the actual posterior\ndistribution. Such network is designed to solve a variational optimization\nproblem based on the Kullback-Leibler divergence between the posterior and the\nnetwork output distributions. This work is fundamentally rooted in recent\ndevelopments for invertible networks. Special invertible architectures, besides\nbeing computational advantageous with respect to traditional networks, do also\nenable analytic computation of the output density function. Therefore, after\ntraining, these networks can be readily used as a new prior for a related\ninversion problem. This stands in stark contrast with Monte-Carlo methods,\nwhich only produce samples. We validate these ideas with an application to\nangle-versus-ray parameter analysis for reservoir characterization.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 18:37:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Rizzuti", "Gabrio", ""], ["Siahkoohi", "Ali", ""], ["Witte", "Philipp A.", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2004.07886", "submitter": "Uthaipon Tantipongpipat", "authors": "Vivek Madan, Aleksandar Nikolov, Mohit Singh, Uthaipon Tantipongpipat", "title": "Maximizing Determinants under Matroid Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given vectors $v_1,\\dots,v_n\\in\\mathbb{R}^d$ and a matroid $M=([n],I)$, we\nstudy the problem of finding a basis $S$ of $M$ such that $\\det(\\sum_{i \\in\nS}v_i v_i^\\top)$ is maximized. This problem appears in a diverse set of areas\nsuch as experimental design, fair allocation of goods, network design, and\nmachine learning. The current best results include an $e^{2k}$-estimation for\nany matroid of rank $k$ and a $(1+\\epsilon)^d$-approximation for a uniform\nmatroid of rank $k\\ge d+\\frac d\\epsilon$, where the rank $k\\ge d$ denotes the\ndesired size of the optimal set. Our main result is a new approximation\nalgorithm with an approximation guarantee that depends only on the dimension\n$d$ of the vectors and not on the size $k$ of the output set. In particular, we\nshow an $(O(d))^{d}$-estimation and an $(O(d))^{d^3}$-approximation for any\nmatroid, giving a significant improvement over prior work when $k\\gg d$.\n  Our result relies on the existence of an optimal solution to a convex\nprogramming relaxation for the problem which has sparse support; in particular,\nno more than $O(d^2)$ variables of the solution have fractional values. The\nsparsity results rely on the interplay between the first-order optimality\nconditions for the convex program and matroid theory. We believe that the\ntechniques introduced to show sparsity of optimal solutions to convex programs\nwill be of independent interest. We also give a randomized algorithm that\nrounds a sparse fractional solution to a feasible integral solution to the\noriginal problem. To show the approximation guarantee, we utilize recent works\non strongly log-concave polynomials and show new relationships between\ndifferent convex programs studied for the problem. Finally, we use the\nestimation algorithm and sparsity results to give an efficient deterministic\napproximation algorithm with an approximation guarantee that depends solely on\nthe dimension $d$.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 19:16:38 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Madan", "Vivek", ""], ["Nikolov", "Aleksandar", ""], ["Singh", "Mohit", ""], ["Tantipongpipat", "Uthaipon", ""]]}, {"id": "2004.07922", "submitter": "Ritu Yadav", "authors": "Ritu Yadav", "title": "Light-Weighted CNN for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For management, documents are categorized into a specific category, and to do\nthese, most of the organizations use manual labor. In today's automation era,\nmanual efforts on such a task are not justified, and to avoid this, we have so\nmany software out there in the market. However, efficiency and minimal resource\nconsumption is the focal point which is also creating a competition. The\ncategorization of such documents into specified classes by machine provides\nexcellent help. One of categorization technique is text classification using a\nConvolutional neural network(TextCNN). TextCNN uses multiple sizes of filters,\nas in the case of the inception layer introduced in Googlenet. The network\nprovides good accuracy but causes high memory consumption due to a large number\nof trainable parameters. As a solution to this problem, we introduced a whole\nnew architecture based on separable convolution. The idea of separable\nconvolution already exists in the field of image classification but not yet\nintroduces to text classification tasks. With the help of this architecture, we\ncan achieve a drastic reduction in trainable parameters.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:23:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Yadav", "Ritu", ""]]}, {"id": "2004.07928", "submitter": "Dmitry Kazhdan", "authors": "Dmitry Kazhdan, Zohreh Shams, Pietro Li\\`o", "title": "MARLeME: A Multi-Agent Reinforcement Learning Model Extraction Library", "comments": "Presented at the KR2ML workshop at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) encompasses a powerful class of\nmethodologies that have been applied in a wide range of fields. An effective\nway to further empower these methodologies is to develop libraries and tools\nthat could expand their interpretability and explainability. In this work, we\nintroduce MARLeME: a MARL model extraction library, designed to improve\nexplainability of MARL systems by approximating them with symbolic models.\nSymbolic models offer a high degree of interpretability, well-defined\nproperties, and verifiable behaviour. Consequently, they can be used to inspect\nand better understand the underlying MARL system and corresponding MARL agents,\nas well as to replace all/some of the agents that are particularly safety and\nsecurity critical.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:27:38 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Kazhdan", "Dmitry", ""], ["Shams", "Zohreh", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2004.07937", "submitter": "Syed Muhammad Usman", "authors": "Syed Muhammad Usman, Shahzad Latif, Arshad Beg", "title": "Principle components analysis for seizures prediction using wavelet\n  transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is a disease in which frequent seizures occur due to abnormal\nactivity of neurons. Patients affected by this disease can be treated with the\nhelp of medicines or surgical procedures. However, both of these methods are\nnot quite useful. The only method to treat epilepsy patients effectively is to\npredict the seizure before its onset. It has been observed that abnormal\nactivity in the brain signals starts before the occurrence of seizure known as\nthe preictal state. Many researchers have proposed machine learning models for\nprediction of epileptic seizures by detecting the start of preictal state.\nHowever, pre-processing, feature extraction and classification remains a great\nchallenge in the prediction of preictal state. Therefore, we propose a model\nthat uses common spatial pattern filtering and wavelet transform for\npreprocessing, principal component analysis for feature extraction and support\nvector machines for detecting preictal state. We have applied our model on 23\nsubjects and an average sensitivity of 93.1% has been observed for 84 seizures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 04:32:57 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Usman", "Syed Muhammad", ""], ["Latif", "Shahzad", ""], ["Beg", "Arshad", ""]]}, {"id": "2004.07941", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz", "title": "Continual Learning for Anomaly Detection in Surveillance Videos", "comments": "accepted to CVPR 2020: Workshop on Continual Learning in Computer\n  Vision. arXiv admin note: text overlap with arXiv:2004.02072", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in surveillance videos has been recently gaining attention.\nA challenging aspect of high-dimensional applications such as video\nsurveillance is continual learning. While current state-of-the-art deep\nlearning approaches perform well on existing public datasets, they fail to work\nin a continual learning framework due to computational and storage issues.\nFurthermore, online decision making is an important but mostly neglected factor\nin this domain. Motivated by these research gaps, we propose an online anomaly\ndetection method for surveillance videos using transfer learning and continual\nlearning, which in turn significantly reduces the training complexity and\nprovides a mechanism for continually learning from recent data without\nsuffering from catastrophic forgetting. Our proposed algorithm leverages the\nfeature extraction power of neural network-based models for transfer learning,\nand the continual learning capability of statistical detection methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:41:20 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2004.07984", "submitter": "Jean Kossaifi", "authors": "Majid Janzamin, Rong Ge, Jean Kossaifi and Anima Anandkumar", "title": "Spectral Learning on Matrices and Tensors", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning: Vol. 12: No. 5-6, pp\n  393-536 (2019)", "doi": "10.1561/2200000057", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods have been the mainstay in several domains such as machine\nlearning and scientific computing. They involve finding a certain kind of\nspectral decomposition to obtain basis functions that can capture important\nstructures for the problem at hand. The most common spectral method is the\nprincipal component analysis (PCA). It utilizes the top eigenvectors of the\ndata covariance matrix, e.g. to carry out dimensionality reduction. This data\npre-processing step is often effective in separating signal from noise. PCA and\nother spectral techniques applied to matrices have several limitations. By\nlimiting to only pairwise moments, they are effectively making a Gaussian\napproximation on the underlying data and fail on data with hidden variables\nwhich lead to non-Gaussianity. However, in most data sets, there are latent\neffects that cannot be directly observed, e.g., topics in a document corpus, or\nunderlying causes of a disease. By extending the spectral decomposition methods\nto higher order moments, we demonstrate the ability to learn a wide range of\nlatent variable models efficiently. Higher-order moments can be represented by\ntensors, and intuitively, they can encode more information than just pairwise\nmoment matrices. More crucially, tensor decomposition can pick up latent\neffects that are missed by matrix methods, e.g. uniquely identify\nnon-orthogonal components. Exploiting these aspects turns out to be fruitful\nfor provable unsupervised learning of a wide range of latent variable models.\nWe also outline the computational techniques to design efficient tensor\ndecomposition methods. We introduce Tensorly, which has a simple python\ninterface for expressing tensor operations. It has a flexible back-end system\nsupporting NumPy, PyTorch, TensorFlow and MXNet amongst others, allowing\nmulti-GPU and CPU operations and seamless integration with deep-learning\nfunctionalities.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 22:53:00 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Janzamin", "Majid", ""], ["Ge", "Rong", ""], ["Kossaifi", "Jean", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2004.07986", "submitter": "Zhao Song", "authors": "Zhao Song, David P. Woodruff, Peilin Zhong", "title": "Average Case Column Subset Selection for Entrywise $\\ell_1$-Norm Loss", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study the column subset selection problem with respect to the entrywise\n$\\ell_1$-norm loss. It is known that in the worst case, to obtain a good\nrank-$k$ approximation to a matrix, one needs an arbitrarily large\n$n^{\\Omega(1)}$ number of columns to obtain a $(1+\\epsilon)$-approximation to\nthe best entrywise $\\ell_1$-norm low rank approximation of an $n \\times n$\nmatrix. Nevertheless, we show that under certain minimal and realistic\ndistributional settings, it is possible to obtain a\n$(1+\\epsilon)$-approximation with a nearly linear running time and\npoly$(k/\\epsilon)+O(k\\log n)$ columns. Namely, we show that if the input matrix\n$A$ has the form $A = B + E$, where $B$ is an arbitrary rank-$k$ matrix, and\n$E$ is a matrix with i.i.d. entries drawn from any distribution $\\mu$ for which\nthe $(1+\\gamma)$-th moment exists, for an arbitrarily small constant $\\gamma >\n0$, then it is possible to obtain a $(1+\\epsilon)$-approximate column subset\nselection to the entrywise $\\ell_1$-norm in nearly linear time. Conversely we\nshow that if the first moment does not exist, then it is not possible to obtain\na $(1+\\epsilon)$-approximate subset selection algorithm even if one chooses any\n$n^{o(1)}$ columns. This is the first algorithm of any kind for achieving a\n$(1+\\epsilon)$-approximation for entrywise $\\ell_1$-norm loss low rank\napproximation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 22:57:06 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Song", "Zhao", ""], ["Woodruff", "David P.", ""], ["Zhong", "Peilin", ""]]}, {"id": "2004.08013", "submitter": "Niru Maheswaranathan", "authors": "Niru Maheswaranathan, David Sussillo", "title": "How recurrent networks implement contextual processing in sentiment\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have a remarkable capacity for contextual processing--using\nrecent or nearby inputs to modify processing of current input. For example, in\nnatural language, contextual processing is necessary to correctly interpret\nnegation (e.g. phrases such as \"not bad\"). However, our ability to understand\nhow networks process context is limited. Here, we propose general methods for\nreverse engineering recurrent neural networks (RNNs) to identify and elucidate\ncontextual processing. We apply these methods to understand RNNs trained on\nsentiment classification. This analysis reveals inputs that induce contextual\neffects, quantifies the strength and timescale of these effects, and identifies\nsets of these inputs with similar properties. Additionally, we analyze\ncontextual effects related to differential processing of the beginning and end\nof documents. Using the insights learned from the RNNs we improve baseline\nBag-of-Words models with simple extensions that incorporate contextual\nmodification, recovering greater than 90% of the RNN's performance increase\nover the baseline. This work yields a new understanding of how RNNs process\ncontextual information, and provides tools that should provide similar insight\nmore broadly.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 00:58:30 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Maheswaranathan", "Niru", ""], ["Sussillo", "David", ""]]}, {"id": "2004.08038", "submitter": "Tanwi Mallick", "authors": "Tanwi Mallick, Prasanna Balaprakash, Eric Rask, and Jane Macfarlane", "title": "Transfer Learning with Graph Neural Networks for Short-Term Highway\n  Traffic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highway traffic modeling and forecasting approaches are critical for\nintelligent transportation systems. Recently, deep-learning-based traffic\nforecasting methods have emerged as state of the art for a wide range of\ntraffic forecasting tasks. However, these methods require a large amount of\ntraining data, which needs to be collected over a significant period of time.\nThis can present a number of challenges for the development and deployment of\ndata-driven learning methods for highway networks that suffer from lack of\nhistorical data. A promising approach to address this issue is transfer\nlearning, where a model trained on one part of the highway network can be\nadapted for a different part of the highway network. We focus on diffusion\nconvolutional recurrent neural network (DCRNN), a state-of-the-art graph neural\nnetwork for highway network forecasting. It models the complex spatial and\ntemporal dynamics of the highway network using a graph-based diffusion\nconvolution operation within a recurrent neural network. DCRNN cannot perform\ntransfer learning, however, because it learns location-specific traffic\npatterns, which cannot be used for unseen regions of the network. To that end,\nwe develop a new transfer learning approach for DCRNN, where a single model\ntrained on data-rich regions of the highway network can be used to forecast\ntraffic on unseen regions of the highway network. We evaluate the ability of\nour approach to forecast the traffic on the entire California highway network\nwith one year of time series data. We show that TL-DCRNN can learn from several\nregions of the California highway network and forecast the traffic on the\nunseen regions of the network with high accuracy. Moreover, we demonstrate that\nTL-DCRNN can learn from San Francisco region traffic data and can forecast\ntraffic on the Los Angeles region and vice versa.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 02:29:42 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 13:12:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mallick", "Tanwi", ""], ["Balaprakash", "Prasanna", ""], ["Rask", "Eric", ""], ["Macfarlane", "Jane", ""]]}, {"id": "2004.08066", "submitter": "Toshihisa Tanaka", "authors": "Yuki Hagiwara and Toshihisa Tanaka", "title": "YuruGAN: Yuru-Chara Mascot Generator Using Generative Adversarial\n  Networks With Clustering Small Dataset", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A yuru-chara is a mascot character created by local governments and companies\nfor publicizing information on areas and products. Because it takes various\ncosts to create a yuruchara, the utilization of machine learning techniques\nsuch as generative adversarial networks (GANs) can be expected. In recent\nyears, it has been reported that the use of class conditions in a dataset for\nGANs training stabilizes learning and improves the quality of the generated\nimages. However, it is difficult to apply class conditional GANs when the\namount of original data is small and when a clear class is not given, such as a\nyuruchara image. In this paper, we propose a class conditional GAN based on\nclustering and data augmentation. Specifically, first, we performed clustering\nbased on K-means++ on the yuru-chara image dataset and converted it into a\nclass conditional dataset. Next, data augmentation was performed on the class\nconditional dataset so that the amount of data was increased five times. In\naddition, we built a model that incorporates ResBlock and self-attention into a\nnetwork based on class conditional GAN and trained the class conditional\nyuru-chara dataset. As a result of evaluating the generated images, the effect\non the generated images by the difference of the clustering method was\nconfirmed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 05:18:49 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hagiwara", "Yuki", ""], ["Tanaka", "Toshihisa", ""]]}, {"id": "2004.08068", "submitter": "Xiaocong Chen", "authors": "Xiaocong Chen, Chaoran Huang, Lina Yao, Xianzhi Wang, Wei Liu, Wenjie\n  Zhang", "title": "Knowledge-guided Deep Reinforcement Learning for Interactive\n  Recommendation", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207010", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive recommendation aims to learn from dynamic interactions between\nitems and users to achieve responsiveness and accuracy. Reinforcement learning\nis inherently advantageous for coping with dynamic environments and thus has\nattracted increasing attention in interactive recommendation research. Inspired\nby knowledge-aware recommendation, we proposed Knowledge-Guided deep\nReinforcement learning (KGRL) to harness the advantages of both reinforcement\nlearning and knowledge graphs for interactive recommendation. This model is\nimplemented upon the actor-critic network framework. It maintains a local\nknowledge network to guide decision-making and employs the attention mechanism\nto capture long-term semantics between items. We have conducted comprehensive\nexperiments in a simulated online environment with six public real-world\ndatasets and demonstrated the superiority of our model over several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 05:26:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Chen", "Xiaocong", ""], ["Huang", "Chaoran", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Liu", "Wei", ""], ["Zhang", "Wenjie", ""]]}, {"id": "2004.08083", "submitter": "Arkabandhu Chowdhury", "authors": "Arkabandhu Chowdhury, Dipak Chaudhari, Swarat Chaudhuri, Chris\n  Jermaine", "title": "Meta-Meta Classification for One-Shot Learning", "comments": "10 pages without references, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach, called meta-meta classification, to learning in\nsmall-data settings. In this approach, one uses a large set of learning\nproblems to design an ensemble of learners, where each learner has high bias\nand low variance and is skilled at solving a specific type of learning problem.\nThe meta-meta classifier learns how to examine a given learning problem and\ncombine the various learners to solve the problem. The meta-meta learning\napproach is especially suited to solving few-shot learning tasks, as it is\neasier to learn to classify a new learning problem with little data than it is\nto apply a learning algorithm to a small data set. We evaluate the approach on\na one-shot, one-class-versus-all classification task and show that it is able\nto outperform traditional meta-learning as well as ensembling approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:05:03 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 16:46:20 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 02:28:08 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 01:02:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chowdhury", "Arkabandhu", ""], ["Chaudhari", "Dipak", ""], ["Chaudhuri", "Swarat", ""], ["Jermaine", "Chris", ""]]}, {"id": "2004.08100", "submitter": "Mahdi Kherad", "authors": "Mahdi Kherad and Amir Jalaly Bidgoly", "title": "Recommendation system using a deep learning and graph analysis approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a user connects to the Internet to fulfill his needs, he often\nencounters a huge amount of related information. Recommender systems are the\ntechniques for massively filtering information and offering the items that\nusers find them satisfying and interesting. The advances in machine learning\nmethods, especially deep learning, have led to great achievements in\nrecommender systems, although these systems still suffer from challenges such\nas cold-start and sparsity problems. To solve these problems, context\ninformation such as user communication network is usually used. In this paper,\nwe have proposed a novel recommendation method based on Matrix Factorization\nand graph analysis methods. In addition, we leverage deep Autoencoders to\ninitialize users and items latent factors, and deep embedding method gathers\nusers' latent factors from the user trust graph. The proposed method is\nimplemented on two standard datasets. The experimental results and comparisons\ndemonstrate that the proposed approach is superior to the existing\nstate-of-the-art recommendation methods. Our approach outperforms other\ncomparative methods and achieves great improvements.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:05:33 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 11:59:00 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 07:46:45 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 05:26:05 GMT"}, {"version": "v5", "created": "Tue, 28 Jul 2020 06:42:44 GMT"}, {"version": "v6", "created": "Thu, 8 Jul 2021 12:28:08 GMT"}, {"version": "v7", "created": "Fri, 9 Jul 2021 14:12:47 GMT"}, {"version": "v8", "created": "Tue, 13 Jul 2021 18:28:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Kherad", "Mahdi", ""], ["Bidgoly", "Amir Jalaly", ""]]}, {"id": "2004.08101", "submitter": "Attila Tiba", "authors": "Andras Hajdu, Gyorgy Terdik, Attila Tiba, Henrietta Toman", "title": "A stochastic approach to handle knapsack problems in the creation of\n  ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble-based methods are highly popular approaches that increase the\naccuracy of a decision by aggregating the opinions of individual voters. The\ncommon point is to maximize accuracy; however, a natural limitation occurs if\nincremental costs are also assigned to the individual voters. Consequently, we\ninvestigate creating ensembles under an additional constraint on the total cost\nof the members. This task can be formulated as a knapsack problem, where the\nenergy is the ensemble accuracy formed by some aggregation rules. However, the\ngenerally applied aggregation rules lead to a nonseparable energy function,\nwhich takes the common solution tools -- such as dynamic programming -- out of\naction. We introduce a novel stochastic approach that considers the energy as\nthe joint probability function of the member accuracies. This type of knowledge\ncan be efficiently incorporated in a stochastic search process as a stopping\nrule, since we have the information on the expected accuracy or, alternatively,\nthe probability of finding more accurate ensembles. Experimental analyses of\nthe created ensembles of pattern classifiers and object detectors confirm the\nefficiency of our approach. Moreover, we propose a novel stochastic search\nstrategy that better fits the energy, compared with general approaches such as\nsimulated annealing.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:06:34 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hajdu", "Andras", ""], ["Terdik", "Gyorgy", ""], ["Tiba", "Attila", ""], ["Toman", "Henrietta", ""]]}, {"id": "2004.08108", "submitter": "Jorge Pe\\~na Queralta", "authors": "Wenshuai Zhao, Dihong Jiang, Jorge Pe\\~na Queralta, Tomi Westerlund", "title": "Multi-Scale Supervised 3D U-Net for Kidneys and Kidney Tumor\n  Segmentation", "comments": null, "journal-ref": null, "doi": "10.1016/j.imu.2020.100357", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate segmentation of kidneys and kidney tumors is an essential step for\nradiomic analysis as well as developing advanced surgical planning techniques.\nIn clinical analysis, the segmentation is currently performed by clinicians\nfrom the visual inspection images gathered through a computed tomography (CT)\nscan. This process is laborious and its success significantly depends on\nprevious experience. Moreover, the uncertainty in the tumor location and\nheterogeneity of scans across patients increases the error rate. To tackle this\nissue, computer-aided segmentation based on deep learning techniques have\nbecome increasingly popular. We present a multi-scale supervised 3D U-Net, MSS\nU-Net, to automatically segment kidneys and kidney tumors from CT images. Our\narchitecture combines deep supervision with exponential logarithmic loss to\nincrease the 3D U-Net training efficiency. Furthermore, we introduce a\nconnected-component based post processing method to enhance the performance of\nthe overall process. This architecture shows superior performance compared to\nstate-of-the-art works using data from KiTS19 public dataset, with the Dice\ncoefficient of kidney and tumor up to 0.969 and 0.805 respectively. The\nsegmentation techniques introduced in this paper have been tested in the KiTS19\nchallenge with its corresponding dataset.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:25:43 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Jiang", "Dihong", ""], ["Queralta", "Jorge Pe\u00f1a", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2004.08113", "submitter": "Senlin Shu", "authors": "Senlin Shu, Fengmao Lv, Lei Feng, Yan Yan, Shuo He, Jun He, Li Li", "title": "Incorporating Multiple Cluster Centers for Multi-Label Learning", "comments": "19 pages with 4 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning deals with the problem that each instance is associated\nwith multiple labels simultaneously. Most of the existing approaches aim to\nimprove the performance of multi-label learning by exploiting label\ncorrelations. Although the data augmentation technique is widely used in many\nmachine learning tasks, it is still unclear whether data augmentation is\nhelpful to multi-label learning. In this paper, (to the best of our knowledge)\nwe provide the first attempt to leverage the data augmentation technique to\nimprove the performance of multi-label learning. Specifically, we first propose\na novel data augmentation approach that performs clustering on the real\nexamples and treats the cluster centers as virtual examples, and these virtual\nexamples naturally embody the local label correlations and label importances.\nThen, motivated by the cluster assumption that examples in the same cluster\nshould have the same label, we propose a novel regularization term to bridge\nthe gap between the real examples and virtual examples, which can promote the\nlocal smoothness of the learning function. Extensive experimental results on a\nnumber of real-world multi-label data sets clearly demonstrate that our\nproposed approach outperforms the state-of-the-art counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:39:58 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 13:57:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Shu", "Senlin", ""], ["Lv", "Fengmao", ""], ["Feng", "Lei", ""], ["Yan", "Yan", ""], ["He", "Shuo", ""], ["He", "Jun", ""], ["Li", "Li", ""]]}, {"id": "2004.08115", "submitter": "Meixia Lin", "authors": "Meixia Lin, Defeng Sun, Kim-Chuan Toh, Chengjing Wang", "title": "Estimation of sparse Gaussian graphical models with hidden clustering\n  structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of Gaussian graphical models is important in natural science when\nmodeling the statistical relationships between variables in the form of a\ngraph. The sparsity and clustering structure of the concentration matrix is\nenforced to reduce model complexity and describe inherent regularities. We\npropose a model to estimate the sparse Gaussian graphical models with hidden\nclustering structure, which also allows additional linear constraints to be\nimposed on the concentration matrix. We design an efficient two-phase algorithm\nfor solving the proposed model. We develop a symmetric Gauss-Seidel based\nalternating direction method of the multipliers (sGS-ADMM) to generate an\ninitial point to warm-start the second phase algorithm, which is a proximal\naugmented Lagrangian method (pALM), to get a solution with high accuracy.\nNumerical experiments on both synthetic data and real data demonstrate the good\nperformance of our model, as well as the efficiency and robustness of our\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:43:31 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Lin", "Meixia", ""], ["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""], ["Wang", "Chengjing", ""]]}, {"id": "2004.08119", "submitter": "Raul De Maio PhD", "authors": "Laura Aquilanti, Simone Cacace, Fabio Camilli and Raul De Maio", "title": "A Mean Field Games model for finite mixtures of Bernoulli and\n  Categorical distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models are an important tool in the statistical analysis of\ndata, for example in data clustering. The optimal parameters of a mixture model\nare usually computed by maximizing the log-likelihood functional via the\nExpectation-Maximization algorithm. We propose an alternative approach based on\nthe theory of Mean Field Games, a class of differential games with an infinite\nnumber of agents. We show that the solution of a finite state space\nmulti-population Mean Field Games system characterizes the critical points of\nthe log-likelihood functional for a Bernoulli mixture. The approach is then\ngeneralized to mixture models of categorical distributions. Hence, the Mean\nField Games approach provides a method to compute the parameters of the mixture\nmodel, and we show its application to some standard examples in cluster\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:50:05 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 08:52:28 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Aquilanti", "Laura", ""], ["Cacace", "Simone", ""], ["Camilli", "Fabio", ""], ["De Maio", "Raul", ""]]}, {"id": "2004.08151", "submitter": "Wei Peng", "authors": "Wei Peng, Weien Zhou, Jun Zhang, Wen Yao", "title": "Accelerating Physics-Informed Neural Network Training with Prior\n  Dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-Informed Neural Networks (PINNs) can be regarded as general-purpose\nPDE solvers, but it might be slow to train PINNs on particular problems, and\nthere is no theoretical guarantee of corresponding error bounds. In this\nmanuscript, we propose a variant called Prior Dictionary based Physics-Informed\nNeural Networks (PD-PINNs). Equipped with task-dependent dictionaries, PD-PINNs\nenjoy enhanced representation power on the tasks, which helps to capture\nfeatures provided by dictionaries so that the proposed neural networks can\nachieve faster convergence in the process of training. In various numerical\nsimulations, compared with existing PINN methods, combining prior dictionaries\ncan significantly enhance convergence speed. In terms of theory, we obtain the\nerror bounds applicable to PINNs and PD-PINNs for solving elliptic partial\ndifferential equations of second order. It is proved that under certain mild\nconditions, the prediction error made by neural networks can be bounded by\nexpected loss of PDEs and boundary conditions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 10:14:41 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 02:10:56 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Peng", "Wei", ""], ["Zhou", "Weien", ""], ["Zhang", "Jun", ""], ["Yao", "Wen", ""]]}, {"id": "2004.08153", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Athanasios Voulodimos, Anastasios Doulamis,\n  Nikolaos Bakalos, Nikolaos Doulamis", "title": "Space-Time Domain Tensor Neural Networks: An Application on Human Pose\n  Classification", "comments": "8 pages, 8 figures, accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in sensing technologies require the design and development of\npattern recognition models capable of processing spatiotemporal data\nefficiently. In this study, we propose a spatially and temporally aware\ntensor-based neural network for human pose classification using\nthree-dimensional skeleton data. Our model employs three novel components.\nFirst, an input layer capable of constructing highly discriminative\nspatiotemporal features. Second, a tensor fusion operation that produces\ncompact yet rich representations of the data, and third, a tensor-based neural\nnetwork that processes data representations in their original tensor form. Our\nmodel is end-to-end trainable and characterized by a small number of trainable\nparameters making it suitable for problems where the annotated data is limited.\nExperimental evaluation of the proposed model indicates that it can achieve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 10:20:56 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 17:52:46 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Voulodimos", "Athanasios", ""], ["Doulamis", "Anastasios", ""], ["Bakalos", "Nikolaos", ""], ["Doulamis", "Nikolaos", ""]]}, {"id": "2004.08172", "submitter": "Maciej Wo{\\l}czyk", "authors": "Bartosz W\\'ojcik, Maciej Wo{\\l}czyk, Klaudia Ba{\\l}azy, Jacek Tabor", "title": "Finding the Optimal Network Depth in Classification Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a fast end-to-end method for training lightweight neural networks\nusing multiple classifier heads. By allowing the model to determine the\nimportance of each head and rewarding the choice of a single shallow\nclassifier, we are able to detect and remove unneeded components of the\nnetwork. This operation, which can be seen as finding the optimal depth of the\nmodel, significantly reduces the number of parameters and accelerates inference\nacross different hardware processing units, which is not the case for many\nstandard pruning methods. We show the performance of our method on multiple\nnetwork architectures and datasets, analyze its optimization properties, and\nconduct ablation studies.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:08:45 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["Wo\u0142czyk", "Maciej", ""], ["Ba\u0142azy", "Klaudia", ""], ["Tabor", "Jacek", ""]]}, {"id": "2004.08176", "submitter": "Maria Ines Silva", "authors": "Maria In\\^es Silva and Roberto Henriques", "title": "Exploring time-series motifs through DTW-SOM", "comments": "8 pages, 12 figures, Accepted for presentation at the International\n  Joint Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif discovery is a fundamental step in data mining tasks for time-series\ndata such as clustering, classification and anomaly detection. Even though many\npapers have addressed the problem of how to find motifs in time-series by\nproposing new motif discovery algorithms, not much work has been done on the\nexploration of the motifs extracted by these algorithms. In this paper, we\nargue that visually exploring time-series motifs computed by motif discovery\nalgorithms can be useful to understand and debug results. To explore the output\nof motif discovery algorithms, we propose the use of an adapted Self-Organizing\nMap, the DTW-SOM, on the list of motif's centers. In short, DTW-SOM is a\nvanilla Self-Organizing Map with three main differences, namely (1) the use the\nDynamic Time Warping distance instead of the Euclidean distance, (2) the\nadoption of two new network initialization routines (a random sample\ninitialization and an anchor initialization) and (3) the adjustment of the\nAdaptation phase of the training to work with variable-length time-series\nsequences. We test DTW-SOM in a synthetic motif dataset and two real\ntime-series datasets from the UCR Time Series Classification Archive. After an\nexploration of results, we conclude that DTW-SOM is capable of extracting\nrelevant information from a set of motifs and display it in a visualization\nthat is space-efficient.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:21:16 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Silva", "Maria In\u00eas", ""], ["Henriques", "Roberto", ""]]}, {"id": "2004.08212", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski and Josef Urban", "title": "Stateful Premise Selection by Recurrent Neural Networks", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a new learning-based method for selecting facts\n(premises) when proving new goals over large formal libraries. Unlike previous\nmethods that choose sets of facts independently of each other by their rank,\nthe new method uses the notion of \\emph{state} that is updated each time a\nchoice of a fact is made. Our stateful architecture is based on recurrent\nneural networks which have been recently very successful in stateful tasks such\nas language translation. The new method is combined with data augmentation\ntechniques, evaluated in several ways on a standard large-theory benchmark, and\ncompared to state-of-the-art premise approach based on gradient boosted trees.\nIt is shown to perform significantly better and to solve many new problems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:59:37 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "2004.08217", "submitter": "Lama Niyazi", "authors": "Lama B. Niyazi, Abla Kammoun, Hayssam Dahrouj, Mohamed-Slim Alouini,\n  and Tareq Y. Al-Naffouri", "title": "Asymptotic Analysis of an Ensemble of Randomly Projected Linear\n  Discriminants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets from the fields of bioinformatics, chemometrics, and face\nrecognition are typically characterized by small samples of high-dimensional\ndata. Among the many variants of linear discriminant analysis that have been\nproposed in order to rectify the issues associated with classification in such\na setting, the classifier in [1], composed of an ensemble of randomly projected\nlinear discriminants, seems especially promising; it is computationally\nefficient and, with the optimal projection dimension parameter setting, is\ncompetitive with the state-of-the-art. In this work, we seek to further\nunderstand the behavior of this classifier through asymptotic analysis. Under\nthe assumption of a growth regime in which the dataset and projection\ndimensions grow at constant rates to each other, we use random matrix theory to\nderive asymptotic misclassification probabilities showing the effect of the\nensemble as a regularization of the data sample covariance matrix. The\nasymptotic errors further help to identify situations in which the ensemble\noffers a performance advantage. We also develop a consistent estimator of the\nmisclassification probability as an alternative to the computationally-costly\ncross-validation estimator, which is conventionally used for parameter tuning.\nFinally, we demonstrate the use of our estimator for tuning the projection\ndimension on both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 12:47:04 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Niyazi", "Lama B.", ""], ["Kammoun", "Abla", ""], ["Dahrouj", "Hayssam", ""], ["Alouini", "Mohamed-Slim", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "2004.08227", "submitter": "Siddharth Tourani", "authors": "Siddharth Tourani, Alexander Shekhovtsov, Carsten Rother, Bogdan\n  Savchynskyy", "title": "MPLP++: Fast, Parallel Dual Block-Coordinate Ascent for Dense Graphical\n  Models", "comments": "Accepted in ECCV-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense, discrete Graphical Models with pairwise potentials are a powerful\nclass of models which are employed in state-of-the-art computer vision and\nbio-imaging applications. This work introduces a new MAP-solver, based on the\npopular Dual Block-Coordinate Ascent principle. Surprisingly, by making a small\nchange to the low-performing solver, the Max Product Linear Programming (MPLP)\nalgorithm, we derive the new solver MPLP++ that significantly outperforms all\nexisting solvers by a large margin, including the state-of-the-art solver\nTree-Reweighted Sequential (TRWS) message-passing algorithm. Additionally, our\nsolver is highly parallel, in contrast to TRWS, which gives a further boost in\nperformance with the proposed GPU and multi-thread CPU implementations. We\nverify the superiority of our algorithm on dense problems from publicly\navailable benchmarks, as well, as a new benchmark for 6D Object Pose\nestimation. We also provide an ablation study with respect to graph density.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:20:53 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tourani", "Siddharth", ""], ["Shekhovtsov", "Alexander", ""], ["Rother", "Carsten", ""], ["Savchynskyy", "Bogdan", ""]]}, {"id": "2004.08237", "submitter": "Yanghao Lin", "authors": "Xu Cao, Yanghao Lin", "title": "CAggNet: Crossing Aggregation Network for Medical Image Segmentation", "comments": "Accepted by ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Crossing Aggregation Network (CAggNet), a novel\ndensely connected semantic segmentation approach for medical image analysis.\nThe crossing aggregation network improves the idea from deep layer aggregation\nand makes significant innovations in semantic and spatial information fusion.\nIn CAggNet, the simple skip connection structure of general U-Net is replaced\nby aggregations of multi-level down-sampling and up-sampling layers, which is a\nnew form of nested skip connection. This aggregation architecture enables the\nnetwork to fuse both coarse and fine features interactively in semantic\nsegmentation. It also introduces weighted aggregation module to up-sample\nmulti-scale output at the end of the network. We have evaluated and compared\nour CAggNet with several advanced U-Net based methods in two public medical\nimage datasets, including the 2018 Data Science Bowl nuclei detection dataset\nand the 2015 MICCAI gland segmentation competition dataset. Experimental\nresults indicate that CAggNet improves medical object recognition and achieves\na more accurate and efficient segmentation compared to existing improved U-Net\nand UNet++ structure.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:39:38 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 13:28:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Cao", "Xu", ""], ["Lin", "Yanghao", ""]]}, {"id": "2004.08243", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, Mayank Meghwanshi, Bamdev Mishra", "title": "Geometry-aware Domain Adaptation for Unsupervised Alignment of Word\n  Embeddings", "comments": "Accepted as a short paper in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel manifold based geometric approach for learning\nunsupervised alignment of word embeddings between the source and the target\nlanguages. Our approach formulates the alignment learning problem as a domain\nadaptation problem over the manifold of doubly stochastic matrices. This\nviewpoint arises from the aim to align the second order information of the two\nlanguage spaces. The rich geometry of the doubly stochastic manifold allows to\nemploy efficient Riemannian conjugate gradient algorithm for the proposed\nformulation. Empirically, the proposed approach outperforms state-of-the-art\noptimal transport based approach on the bilingual lexicon induction task across\nseveral language pairs. The performance improvement is more significant for\ndistant language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 04:41:06 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 14:48:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Meghwanshi", "Mayank", ""], ["Mishra", "Bamdev", ""]]}, {"id": "2004.08249", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, Jiawei Han", "title": "Understanding the Difficulty of Training Transformers", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have proved effective in many NLP tasks. However, their training\nrequires non-trivial efforts regarding designing cutting-edge optimizers and\nlearning rate schedulers carefully (e.g., conventional SGD fails to train\nTransformers effectively). Our objective here is to understand $\\textit{what\ncomplicates Transformer training}$ from both empirical and theoretical\nperspectives. Our analysis reveals that unbalanced gradients are not the root\ncause of the instability of training. Instead, we identify an amplification\neffect that influences training substantially -- for each layer in a\nmulti-layer Transformer model, heavy dependency on its residual branch makes\ntraining unstable, since it amplifies small parameter perturbations (e.g.,\nparameter updates) and results in significant disturbances in the model output.\nYet we observe that a light dependency limits the model potential and leads to\ninferior trained models. Inspired by our analysis, we propose Admin\n($\\textbf{Ad}$aptive $\\textbf{m}$odel $\\textbf{in}$itialization) to stabilize\nstabilize the early stage's training and unleash its full potential in the late\nstage. Extensive experiments show that Admin is more stable, converges faster,\nand leads to better performance. Implementations are released at:\nhttps://github.com/LiyuanLucasLiu/Transforemr-Clinic.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 13:59:07 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 05:05:56 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Liu", "Liyuan", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Chen", "Weizhu", ""], ["Han", "Jiawei", ""]]}, {"id": "2004.08285", "submitter": "Shaocheng Huang", "authors": "Shaocheng Huang, Yu Ye, Ming Xiao", "title": "Learning Based Hybrid Beamforming Design for Full-Duplex Millimeter Wave\n  Systems", "comments": "13 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter Wave (mmWave) communications with full-duplex (FD) have the\npotential of increasing the spectral efficiency, relative to those with\nhalf-duplex. However, the residual self-interference (SI) from FD and high\npathloss inherent to mmWave signals may degrade the system performance.\nMeanwhile, hybrid beamforming (HBF) is an efficient technology to enhance the\nchannel gain and mitigate interference with reasonable complexity. However,\nconventional HBF approaches for FD mmWave systems are based on optimization\nprocesses, which are either too complex or strongly rely on the quality of\nchannel state information (CSI). We propose two learning schemes to design HBF\nfor FD mmWave systems, i.e., extreme learning machine based HBF (ELM-HBF) and\nconvolutional neural networks based HBF (CNN-HBF). Specifically, we first\npropose an alternating direction method of multipliers (ADMM) based algorithm\nto achieve SI cancellation beamforming, and then use a\nmajorization-minimization (MM) based algorithm for joint transmitting and\nreceiving HBF optimization. To train the learning networks, we simulate noisy\nchannels as input, and select the hybrid beamformers calculated by proposed\nalgorithms as targets. Results show that both learning based schemes can\nprovide more robust HBF performance and achieve at least 22.1% higher spectral\nefficiency compared to orthogonal matching pursuit (OMP) algorithms. Besides,\nthe online prediction time of proposed learning based schemes is almost 20\ntimes faster than the OMP scheme. Furthermore, the training time of ELM-HBF is\nabout 600 times faster than that of CNN-HBF with 64 transmitting and receiving\nantennas.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:48:57 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Huang", "Shaocheng", ""], ["Ye", "Yu", ""], ["Xiao", "Ming", ""]]}, {"id": "2004.08286", "submitter": "Bilal Farooq", "authors": "Lama Alfaseeh, Ran Tu, Bilal Farooq, and Marianne Hatzopoulou", "title": "Greenhouse Gas Emission Prediction on Road Network using Deep Sequence\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.trd.2020.102593", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating the substantial undesirable impact of transportation systems on\nthe environment is paramount. Thus, predicting Greenhouse Gas (GHG) emissions\nis one of the profound topics, especially with the emergence of intelligent\ntransportation systems (ITS). We develop a deep learning framework to predict\nlink-level GHG emission rate (ER) (in CO2eq gram/second) based on the most\nrepresentative predictors, such as speed, density, and the GHG ER of previous\ntime steps. In particular, various specifications of the long-short term memory\n(LSTM) networks with exogenous variables are examined and compared with\nclustering and the autoregressive integrated moving average (ARIMA) model with\nexogenous variables. The downtown Toronto road network is used as the case\nstudy and highly detailed data are synthesized using a calibrated traffic\nmicrosimulation and MOVES. It is found that LSTM specification with speed,\ndensity, GHG ER, and in-links speed from three previous minutes performs the\nbest while adopting 2 hidden layers and when the hyper-parameters are\nsystematically tuned. Adopting a 30 second updating interval improves slightly\nthe correlation between true and predicted GHG ERs, but contributes negatively\nto the prediction accuracy as reflected on the increased root mean square error\n(RMSE) value. Efficiently predicting GHG emissions at a higher frequency with\nlower data requirements will pave the way to non-myopic eco-routing on\nlarge-scale road networks {to alleviate the adverse impact on the global\nwarming\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:25:32 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 16:39:52 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Alfaseeh", "Lama", ""], ["Tu", "Ran", ""], ["Farooq", "Bilal", ""], ["Hatzopoulou", "Marianne", ""]]}, {"id": "2004.08287", "submitter": "Jyotibdha Acharya", "authors": "Jyotibdha Acharya, Arindam Basu", "title": "Deep Neural Network for Respiratory Sound Classification in Wearable\n  Devices Enabled by Patient Specific Model Tuning", "comments": null, "journal-ref": null, "doi": "10.1109/TBCAS.2020.2981172", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The primary objective of this paper is to build classification models and\nstrategies to identify breathing sound anomalies (wheeze, crackle) for\nautomated diagnosis of respiratory and pulmonary diseases. In this work we\npropose a deep CNN-RNN model that classifies respiratory sounds based on\nMel-spectrograms. We also implement a patient specific model tuning strategy\nthat first screens respiratory patients and then builds patient specific\nclassification models using limited patient data for reliable anomaly\ndetection. Moreover, we devise a local log quantization strategy for model\nweights to reduce the memory footprint for deployment in memory constrained\nsystems such as wearable devices. The proposed hybrid CNN-RNN model achieves a\nscore of 66.31% on four-class classification of breathing cycles for ICBHI'17\nscientific challenge respiratory sound database. When the model is re-trained\nwith patient specific data, it produces a score of 71.81% for leave-one-out\nvalidation. The proposed weight quantization technique achieves ~4X reduction\nin total memory cost without loss of performance. The main contribution of the\npaper is as follows: Firstly, the proposed model is able to achieve state of\nthe art score on the ICBHI'17 dataset. Secondly, deep learning models are shown\nto successfully learn domain specific knowledge when pre-trained with breathing\ndata and produce significantly superior performance compared to generalized\nmodels. Finally, local log quantization of trained weights is shown to be able\nto reduce the memory requirement significantly. This type of patient-specific\nre-training strategy can be very useful in developing reliable long-term\nautomated patient monitoring systems particularly in wearable healthcare\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:42:58 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Acharya", "Jyotibdha", ""], ["Basu", "Arindam", ""]]}, {"id": "2004.08289", "submitter": "Ozan Ozdenizci", "authors": "Mo Han, Ozan Ozdenizci, Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Disentangled Adversarial Transfer Learning for Physiological Biosignals", "comments": "42nd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in wearable sensors demonstrate promising results for\nmonitoring physiological status in effective and comfortable ways. One major\nchallenge of physiological status assessment is the problem of transfer\nlearning caused by the domain inconsistency of biosignals across users or\ndifferent recording sessions from the same user. We propose an adversarial\ninference approach for transfer learning to extract disentangled\nnuisance-robust representations from physiological biosignal data in stress\nstatus level assessment. We exploit the trade-off between task-related features\nand person-discriminative information by using both an adversary network and a\nnuisance network to jointly manipulate and disentangle the learned latent\nrepresentations by the encoder, which are then input to a discriminative\nclassifier. Results on cross-subjects transfer evaluations demonstrate the\nbenefits of the proposed adversarial framework, and thus show its capabilities\nto adapt to a broader range of subjects. Finally we highlight that our proposed\nadversarial transfer learning approach is also applicable to other deep feature\nlearning frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 01:56:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Han", "Mo", ""], ["Ozdenizci", "Ozan", ""], ["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2004.08297", "submitter": "Aakash Kaku", "authors": "Aakash Kaku, Avinash Parnandi, Anita Venkatesan, Natasha Pandit, Heidi\n  Schambra and Carlos Fernandez-Granda", "title": "Towards data-driven stroke rehabilitation via wearable sensors and deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovery after stroke is often incomplete, but rehabilitation training may\npotentiate recovery by engaging endogenous neuroplasticity. In preclinical\nmodels of stroke, high doses of rehabilitation training are required to restore\nfunctional movement to the affected limbs of animals. In humans, however, the\nnecessary dose of training to potentiate recovery is not known. This ignorance\nstems from the lack of objective, pragmatic approaches for measuring training\ndoses in rehabilitation activities. Here, to develop a measurement approach, we\ntook the critical first step of automatically identifying functional\nprimitives, the basic building block of activities. Forty-eight individuals\nwith chronic stroke performed a variety of rehabilitation activities while\nwearing inertial measurement units (IMUs) to capture upper body motion.\nPrimitives were identified by human labelers, who labeled and segmented the\nassociated IMU data. We performed automatic classification of these primitives\nusing machine learning. We designed a convolutional neural network model that\noutperformed existing methods. The model includes an initial module to compute\nseparate embeddings of different physical quantities in the sensor data. In\naddition, it replaces batch normalization (which performs normalization based\non statistics computed from the training data) with instance normalization\n(which uses statistics computed from the test data). This increases robustness\nto possible distributional shifts when applying the method to new patients.\nWith this approach, we attained an average classification accuracy of 70%.\nThus, using a combination of IMU-based motion capture and deep learning, we\nwere able to identify primitives automatically. This approach builds towards\nobjectively-measured rehabilitation training, enabling the identification and\ncounting of functional primitives that accrues to a training dose.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 18:05:44 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 15:51:24 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 22:24:10 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kaku", "Aakash", ""], ["Parnandi", "Avinash", ""], ["Venkatesan", "Anita", ""], ["Pandit", "Natasha", ""], ["Schambra", "Heidi", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "2004.08301", "submitter": "Koujin Takeda", "authors": "Hiroki Kitano, Koujin Takeda", "title": "Belief Propagation for Maximum Coverage on Weighted Bipartite Graph and\n  Application to Text Summarization", "comments": "4 pages, 4 figures", "journal-ref": "J. Phys. Soc. Jpn. 89, 043801 (2020)", "doi": "10.7566/JPSJ.89.043801", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study text summarization from the viewpoint of maximum coverage problem.\nIn graph theory, the task of text summarization is regarded as maximum coverage\nproblem on bipartite graph with weighted nodes. In recent study,\nbelief-propagation based algorithm for maximum coverage on unweighted graph was\nproposed using the idea of statistical mechanics. We generalize it to weighted\ngraph for text summarization. Then we apply our algorithm to weighted biregular\nrandom graph for verification of maximum coverage performance. We also apply it\nto bipartite graph representing real document in open text dataset, and check\nthe performance of text summarization. As a result, our algorithm exhibits\nbetter performance than greedy-type algorithm in some setting of text\nsummarization.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 05:50:20 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Kitano", "Hiroki", ""], ["Takeda", "Koujin", ""]]}, {"id": "2004.08318", "submitter": "Sokbae Lee", "authors": "Sung Jae Jun and Sokbae Lee", "title": "Causal Inference in Case-Control Studies", "comments": "58 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate partial identification of causal relative and attributable\nrisk---the ratio of two counterfactual proportions and the difference between\nthem---in case-control and case-population studies. The odds ratio is shown to\nbe a sharp upper bound on causal relative risk under the monotone treatment\nresponse and monotone treatment selection assumptions, without resorting to\nstrong ignorability, nor to the rare-disease assumption. Sharp bounds on causal\nattributable risk are also obtained under the same assumptions. Paying special\nattention to the (conditional) odds ratio, we propose a semiparametrically\nefficient estimator of the aggregated (log) odds ratio. Further, we develop\neasy-to-implement causal inference procedures for relative and attributable\nrisk. Finally, we showcase our methodology by applying it to two unique\ndatasets in the literature. We find that attending private school may have\nlittle effect on entering a very selective university in Pakistan and that\ndropping out of school could substantially increase relative and attributable\nrisk of joining a criminal gang in Brazil.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 16:01:34 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:48:47 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Jun", "Sung Jae", ""], ["Lee", "Sokbae", ""]]}, {"id": "2004.08336", "submitter": "J\\\"uri Lember", "authors": "Alexey Koloydenko, Kristi Kuljus, J\\\"uri Lember", "title": "MAP segmentation in Bayesian hidden Markov models: a case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the maximum posterior probability (MAP)\nstate sequence for a finite state and finite emission alphabet hidden Markov\nmodel (HMM) in the Bayesian setup, where both emission and transition matrices\nhave Dirichlet priors. We study a training set consisting of thousands of\nprotein alignment pairs. The training data is used to set the prior\nhyperparameters for Bayesian MAP segmentation. Since the Viterbi algorithm is\nnot applicable any more, there is no simple procedure to find the MAP path, and\nseveral iterative algorithms are considered and compared. The main goal of the\npaper is to test the Bayesian setup against the frequentist one, where the\nparameters of HMM are estimated using the training data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 16:42:18 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Koloydenko", "Alexey", ""], ["Kuljus", "Kristi", ""], ["Lember", "J\u00fcri", ""]]}, {"id": "2004.08349", "submitter": "George De Ath", "authors": "George De Ath and Jonathan E. Fieldsend and Richard M. Everson", "title": "What do you Mean? The Role of the Mean Function in Bayesian Optimisation", "comments": "Genetic and Evolutionary Computation Conference Companion 2020 (GECCO\n  '20 Companion). 9 pages (main paper) + 4 pages (supplementary material). Code\n  avaliable at http://github.com/georgedeath/bomean", "journal-ref": null, "doi": "10.1145/3377929.3398118", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular approach for optimising expensive\nblack-box functions. The next location to be evaluated is selected via\nmaximising an acquisition function that balances exploitation and exploration.\nGaussian processes, the surrogate models of choice in Bayesian optimisation,\nare often used with a constant prior mean function equal to the arithmetic mean\nof the observed function values. We show that the rate of convergence can\ndepend sensitively on the choice of mean function. We empirically investigate 8\nmean functions (constant functions equal to the arithmetic mean, minimum,\nmedian and maximum of the observed function evaluations, linear, quadratic\npolynomials, random forests and RBF networks), using 10 synthetic test problems\nand two real-world problems, and using the Expected Improvement and Upper\nConfidence Bound acquisition functions. We find that for design dimensions\n$\\ge5$ using a constant mean function equal to the worst observed quality value\nis consistently the best choice on the synthetic problems considered. We argue\nthat this worst-observed-quality function promotes exploitation leading to more\nrapid convergence. However, for the real-world tasks the more complex mean\nfunctions capable of modelling the fitness landscape may be effective, although\nthere is no clearly optimum choice.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:10:17 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 11:54:38 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["De Ath", "George", ""], ["Fieldsend", "Jonathan E.", ""], ["Everson", "Richard M.", ""]]}, {"id": "2004.08356", "submitter": "Aditi Mavalankar", "authors": "Aditi Mavalankar", "title": "Goal-conditioned Batch Reinforcement Learning for Rotation Invariant\n  Locomotion", "comments": "Accepted to the BeTR-RL workshop at ICLR 2020. Link to code:\n  https://github.com/aditimavalankar/gc-batch-rl-locomotion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to learn goal-conditioned policies for locomotion\nin a batch RL setting. The batch data is collected by a policy that is not\ngoal-conditioned. For the locomotion task, this translates to data collection\nusing a policy learnt by the agent for walking straight in one direction, and\nusing that data to learn a goal-conditioned policy that enables the agent to\nwalk in any direction. The data collection policy used should be invariant to\nthe direction the agent is facing i.e. regardless of its initial orientation,\nthe agent should take the same actions to walk forward. We exploit this\nproperty to learn a goal-conditioned policy using two key ideas: (1) augmenting\ndata by generating trajectories with the same actions in different directions,\nand (2) learning an encoder that enforces invariance between these rotated\ntrajectories with a Siamese framework. We show that our approach outperforms\nexisting RL algorithms on 3-D locomotion agents like Ant, Humanoid and\nMinitaur.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:25:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Mavalankar", "Aditi", ""]]}, {"id": "2004.08379", "submitter": "Sivaramakrishnan Rajaraman", "authors": "Sivaramakrishnan Rajaraman, Jen Siegelman, Philip O. Alderson, Lucas\n  S. Folio, Les R. Folio and Sameer K. Antani", "title": "Iteratively Pruned Deep Learning Ensembles for COVID-19 Detection in\n  Chest X-rays", "comments": "11 pages, 8 figures, IEEE Access journal published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate use of iteratively pruned deep learning model ensembles for\ndetecting pulmonary manifestation of COVID-19 with chest X-rays. This disease\nis caused by the novel Severe Acute Respiratory Syndrome Coronavirus 2\n(SARS-CoV-2) virus, also known as the novel Coronavirus (2019-nCoV). A custom\nconvolutional neural network and a selection of ImageNet pretrained models are\ntrained and evaluated at patient-level on publicly available CXR collections to\nlearn modality-specific feature representations. The learned knowledge is\ntransferred and fine-tuned to improve performance and generalization in the\nrelated task of classifying CXRs as normal, showing bacterial pneumonia, or\nCOVID-19-viral abnormalities. The best performing models are iteratively pruned\nto reduce complexity and improve memory efficiency. The predictions of the\nbest-performing pruned models are combined through different ensemble\nstrategies to improve classification performance. Empirical evaluations\ndemonstrate that the weighted average of the best-performing pruned models\nsignificantly improves performance resulting in an accuracy of 99.01% and area\nunder the curve of 0.9972 in detecting COVID-19 findings on CXRs. The combined\nuse of modality-specific knowledge transfer, iterative model pruning, and\nensemble learning resulted in improved predictions. We expect that this model\ncan be quickly adopted for COVID-19 screening using chest radiographs.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 00:09:29 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 15:18:01 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 15:05:31 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Rajaraman", "Sivaramakrishnan", ""], ["Siegelman", "Jen", ""], ["Alderson", "Philip O.", ""], ["Folio", "Lucas S.", ""], ["Folio", "Les R.", ""], ["Antani", "Sameer K.", ""]]}, {"id": "2004.08410", "submitter": "Xiao Li", "authors": "Xiao Li, Hanchen Xu, Jinming Zhang, Hua-hua Chang", "title": "Deep Reinforcement Learning for Adaptive Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate the adaptive learning problem---the problem of\nhow to find an individualized learning plan (called policy) that chooses the\nmost appropriate learning materials based on learner's latent traits---faced in\nadaptive learning systems as a Markov decision process (MDP). We assume latent\ntraits to be continuous with an unknown transition model. We apply a model-free\ndeep reinforcement learning algorithm---the deep Q-learning algorithm---that\ncan effectively find the optimal learning policy from data on learners'\nlearning process without knowing the actual transition model of the learners'\ncontinuous latent traits. To efficiently utilize available data, we also\ndevelop a transition model estimator that emulates the learner's learning\nprocess using neural networks. The transition model estimator can be used in\nthe deep Q-learning algorithm so that it can more efficiently discover the\noptimal learning policy for a learner. Numerical simulation studies verify that\nthe proposed algorithm is very efficient in finding a good learning policy,\nespecially with the aid of a transition model estimator, it can find the\noptimal learning policy after training using a small number of learners.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 18:04:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Li", "Xiao", ""], ["Xu", "Hanchen", ""], ["Zhang", "Jinming", ""], ["Chang", "Hua-hua", ""]]}, {"id": "2004.08423", "submitter": "Xin Chen", "authors": "Xin Chen, Lingxi Xie, Jun Wu, Longhui Wei, Yuhui Xu and Qi Tian", "title": "Fitting the Search Space of Weight-sharing NAS with Graph Convolutional\n  Networks", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has attracted wide attentions in both academia and\nindustry. To accelerate it, researchers proposed weight-sharing methods which\nfirst train a super-network to reuse computation among different operators,\nfrom which exponentially many sub-networks can be sampled and efficiently\nevaluated. These methods enjoy great advantages in terms of computational\ncosts, but the sampled sub-networks are not guaranteed to be estimated\nprecisely unless an individual training process is taken. This paper owes such\ninaccuracy to the inevitable mismatch between assembled network layers, so that\nthere is a random error term added to each estimation. We alleviate this issue\nby training a graph convolutional network to fit the performance of sampled\nsub-networks so that the impact of random errors becomes minimal. With this\nstrategy, we achieve a higher rank correlation coefficient in the selected set\nof candidates, which consequently leads to better performance of the final\narchitecture. In addition, our approach also enjoys the flexibility of being\nused under different hardware constraints, since the graph convolutional\nnetwork has provided an efficient lookup table of the performance of\narchitectures in the entire search space.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:12:39 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:47:03 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Chen", "Xin", ""], ["Xie", "Lingxi", ""], ["Wu", "Jun", ""], ["Wei", "Longhui", ""], ["Xu", "Yuhui", ""], ["Tian", "Qi", ""]]}, {"id": "2004.08431", "submitter": "Florian Mouret", "authors": "Florian Mouret and Mohanad Albughdadi and Sylvie Duthoit and Denis\n  Kouam\\'e and Guillaume Rieu and Jean-Yves Tourneret", "title": "Outlier detection at the parcel-level in wheat and rapeseed crops using\n  multispectral and SAR time series", "comments": null, "journal-ref": "Remote Sens. 2021, 13(5), 956", "doi": "10.3390/rs13050956", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the detection of anomalous crop development at the\nparcel-level based on an unsupervised outlier detection technique. The\nexperimental validation is conducted on rapeseed and wheat parcels located in\nBeauce (France). The proposed methodology consists of four sequential steps: 1)\npreprocessing of synthetic aperture radar (SAR) and multispectral images\nacquired using Sentinel-1 and Sentinel-2 satellites, 2) extraction of SAR and\nmultispectral pixel-level features, 3) computation of parcel-level features\nusing zonal statistics and 4) outlier detection. The different types of\nanomalies that can affect the studied crops are analyzed and described. The\ndifferent factors that can influence the outlier detection results are\ninvestigated with a particular attention devoted to the synergy between\nSentinel-1 and Sentinel-2 data. Overall, the best performance is obtained when\nusing jointly a selection of Sentinel-1 and Sentinel-2 features with the\nisolation forest algorithm. The selected features are VV and VH backscattering\ncoefficients for Sentinel-1 and 5 Vegetation Indexes for Sentinel-2 (among us,\nthe Normalized Difference Vegetation Index and two variants of the Normalized\nDifference Water). When using these features with an outlier ratio of 10%, the\npercentage of detected true positives (i.e., crop anomalies) is equal to 94.1%\nfor rapeseed parcels and 95.5% for wheat parcels.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:50:25 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:38:21 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 09:49:06 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Mouret", "Florian", ""], ["Albughdadi", "Mohanad", ""], ["Duthoit", "Sylvie", ""], ["Kouam\u00e9", "Denis", ""], ["Rieu", "Guillaume", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "2004.08436", "submitter": "Martin Wahl", "authors": "Alain Celisse and Martin Wahl", "title": "Analyzing the discrepancy principle for kernelized spectral filter\n  learning algorithms", "comments": "68 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the construction of early stopping rules in the nonparametric\nregression problem where iterative learning algorithms are used and the optimal\niteration number is unknown. More precisely, we study the discrepancy\nprinciple, as well as modifications based on smoothed residuals, for kernelized\nspectral filter learning algorithms including gradient descent. Our main\ntheoretical bounds are oracle inequalities established for the empirical\nestimation error (fixed design), and for the prediction error (random design).\nFrom these finite-sample bounds it follows that the classical discrepancy\nprinciple is statistically adaptive for slow rates occurring in the hard\nlearning scenario, while the smoothed discrepancy principles are adaptive over\nranges of faster rates (resp. higher smoothness parameters). Our approach\nrelies on deviation inequalities for the stopping rules in the fixed design\nsetting, combined with change-of-norm arguments to deal with the random design\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:08:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Celisse", "Alain", ""], ["Wahl", "Martin", ""]]}, {"id": "2004.08439", "submitter": "Alexander Hagen PhD", "authors": "Alex Hagen, Eric Church, Jan Strube, Kolahal Bhattacharya, and Vinay\n  Amatya", "title": "Scaling the training of particle classification on simulated MicroBooNE\n  events to multiple GPUs", "comments": "6 pages, 4 figures, Accepted for publication in Journal of Physics:\n  Conference Series - Proceedings of the 19th International Workshop on\n  Advanced Computing and Analysis Techniques in Physics Research", "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012104", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurements in Liquid Argon Time Projection Chamber (LArTPC) neutrino\ndetectors, such as the MicroBooNE detector at Fermilab, feature large, high\nfidelity event images. Deep learning techniques have been extremely successful\nin classification tasks of photographs, but their application to LArTPC event\nimages is challenging, due to the large size of the events. Events in these\ndetectors are typically two orders of magnitude larger than images found in\nclassical challenges, like recognition of handwritten digits contained in the\nMNIST database or object recognition in the ImageNet database. Ideally,\ntraining would occur on many instances of the entire event data, instead of\nmany instances of cropped regions of interest from the event data. However,\nsuch efforts lead to extremely long training cycles, which slow down the\nexploration of new network architectures and hyperparameter scans to improve\nthe classification performance. We present studies of scaling a LArTPC\nclassification problem on multiple architectures, spanning multiple nodes. The\nstudies are carried out on simulated events in the MicroBooNE detector. We\nemphasize that it is beyond the scope of this study to optimize networks or\nextract the physics from any results here. Institutional computing at Pacific\nNorthwest National Laboratory and the SummitDev machine at Oak Ridge National\nLaboratory's Leadership Computing Facility have been used. To our knowledge,\nthis is the first use of state-of-the-art Convolutional Neural Networks for\nparticle physics and their attendant compute techniques onto the DOE Leadership\nClass Facilities. We expect benefits to accrue particularly to the Deep\nUnderground Neutrino Experiment (DUNE) LArTPC program, the flagship US High\nEnergy Physics (HEP) program for the coming decades.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:21:27 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hagen", "Alex", ""], ["Church", "Eric", ""], ["Strube", "Jan", ""], ["Bhattacharya", "Kolahal", ""], ["Amatya", "Vinay", ""]]}, {"id": "2004.08454", "submitter": "Alexander Wein", "authors": "Justin Holmgren, Alexander S. Wein", "title": "Counterexamples to the Low-Degree Conjecture", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conjecture of Hopkins (2018) posits that for certain high-dimensional\nhypothesis testing problems, no polynomial-time algorithm can outperform\nso-called \"simple statistics\", which are low-degree polynomials in the data.\nThis conjecture formalizes the beliefs surrounding a line of recent work that\nseeks to understand statistical-versus-computational tradeoffs via the\nlow-degree likelihood ratio. In this work, we refute the conjecture of Hopkins.\nHowever, our counterexample crucially exploits the specifics of the noise\noperator used in the conjecture, and we point out a simple way to modify the\nconjecture to rule out our counterexample. We also give an example illustrating\nthat (even after the above modification), the symmetry assumption in the\nconjecture is necessary. These results do not undermine the low-degree\nframework for computational lower bounds, but rather aim to better understand\nwhat class of problems it is applicable to.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 21:08:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Holmgren", "Justin", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2004.08483", "submitter": "Santiago Ontanon", "authors": "Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek,\n  Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, Li\n  Yang", "title": "ETC: Encoding Long and Structured Inputs in Transformers", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer models have advanced the state of the art in many Natural\nLanguage Processing (NLP) tasks. In this paper, we present a new Transformer\narchitecture, Extended Transformer Construction (ETC), that addresses two key\nchallenges of standard Transformer architectures, namely scaling input length\nand encoding structured inputs. To scale attention to longer inputs, we\nintroduce a novel global-local attention mechanism between global tokens and\nregular input tokens. We also show that combining global-local attention with\nrelative position encodings and a Contrastive Predictive Coding (CPC)\npre-training objective allows ETC to encode structured inputs. We achieve\nstate-of-the-art results on four natural language datasets requiring long\nand/or structured inputs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 23:10:18 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 01:06:32 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 00:39:40 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 15:22:46 GMT"}, {"version": "v5", "created": "Tue, 27 Oct 2020 16:54:17 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ainslie", "Joshua", ""], ["Ontanon", "Santiago", ""], ["Alberti", "Chris", ""], ["Cvicek", "Vaclav", ""], ["Fisher", "Zachary", ""], ["Pham", "Philip", ""], ["Ravula", "Anirudh", ""], ["Sanghai", "Sumit", ""], ["Wang", "Qifan", ""], ["Yang", "Li", ""]]}, {"id": "2004.08545", "submitter": "Ahmed Guecioueur", "authors": "Ahmed Guecioueur and Franz J. Kir\\'aly", "title": "Kernels for time series with irregularly-spaced multivariate\n  observations", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are an interesting frontier for kernel-based methods, for the\nsimple reason that there is no kernel designed to represent them and their\nunique characteristics in full generality. Existing sequential kernels ignore\nthe time indices, with many assuming that the series must be regularly-spaced;\nsome such kernels are not even psd. In this manuscript, we show that a \"series\nkernel\" that is general enough to represent irregularly-spaced multivariate\ntime series may be built out of well-known \"vector kernels\". We also show that\nall series kernels constructed using our methodology are psd, and are thus\nwidely applicable. We demonstrate this point by formulating a Gaussian\nprocess-based strategy - with our series kernel at its heart - to make\npredictions about test series when given a training set. We validate the\nstrategy experimentally by estimating its generalisation error on multiple\ndatasets and comparing it to relevant baselines. We also demonstrate that our\nseries kernel may be used for the more traditional setting of time series\nclassification, where its performance is broadly in line with alternative\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 07:51:54 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Guecioueur", "Ahmed", ""], ["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "2004.08546", "submitter": "Chaoyang He", "authors": "Chaoyang He, Murali Annavaram, Salman Avestimehr", "title": "Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep\n  Learning via Neural Architecture Search", "comments": "accepted to CVPR 2020 workshop on neural architecture search and\n  beyond for representation learning. Code is released at https://fedml.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) has been proved to be an effective learning framework\nwhen data cannot be centralized due to privacy, communication costs, and\nregulatory restrictions. When training deep learning models under an FL\nsetting, people employ the predefined model architecture discovered in the\ncentralized environment. However, this predefined architecture may not be the\noptimal choice because it may not fit data with non-identical and independent\ndistribution (non-IID). Thus, we advocate automating federated learning\n(AutoFL) to improve model accuracy and reduce the manual design effort. We\nspecifically study AutoFL via Neural Architecture Search (NAS), which can\nautomate the design process. We propose a Federated NAS (FedNAS) algorithm to\nhelp scattered workers collaboratively searching for a better architecture with\nhigher accuracy. We also build a system based on FedNAS. Our experiments on\nnon-IID dataset show that the architecture searched by FedNAS can outperform\nthe manually predefined architecture.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 08:04:44 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 23:59:20 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 18:47:25 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 02:18:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["He", "Chaoyang", ""], ["Annavaram", "Murali", ""], ["Avestimehr", "Salman", ""]]}, {"id": "2004.08572", "submitter": "Viraj Kulkarni", "authors": "Sudeep Kondal, Viraj Kulkarni, Ashrika Gaikwad, Amit Kharat, Aniruddha\n  Pant", "title": "Automatic Grading of Knee Osteoarthritis on the Kellgren-Lawrence Scale\n  from Radiographs Using Convolutional Neural Networks", "comments": "5 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The severity of knee osteoarthritis is graded using the 5-point\nKellgren-Lawrence (KL) scale where healthy knees are assigned grade 0, and the\nsubsequent grades 1-4 represent increasing severity of the affliction. Although\nseveral methods have been proposed in recent years to develop models that can\nautomatically predict the KL grade from a given radiograph, most models have\nbeen developed and evaluated on datasets not sourced from India. These models\nfail to perform well on the radiographs of Indian patients. In this paper, we\npropose a novel method using convolutional neural networks to automatically\ngrade knee radiographs on the KL scale. Our method works in two connected\nstages: in the first stage, an object detection model segments individual knees\nfrom the rest of the image; in the second stage, a regression model\nautomatically grades each knee separately on the KL scale. We train our model\nusing the publicly available Osteoarthritis Initiative (OAI) dataset and\ndemonstrate that fine-tuning the model before evaluating it on a dataset from a\nprivate hospital significantly improves the mean absolute error from 1.09 (95%\nCI: 1.03-1.15) to 0.28 (95% CI: 0.25-0.32). Additionally, we compare\nclassification and regression models built for the same task and demonstrate\nthat regression outperforms classification.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 09:46:55 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Kondal", "Sudeep", ""], ["Kulkarni", "Viraj", ""], ["Gaikwad", "Ashrika", ""], ["Kharat", "Amit", ""], ["Pant", "Aniruddha", ""]]}, {"id": "2004.08580", "submitter": "Wang Zhou", "authors": "Xuejun Ma, Shaochen Wang, Wang Zhou", "title": "Statistical inference in massive datasets by empirical likelihood", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new statistical inference method for massive data\nsets, which is very simple and efficient by combining divide-and-conquer method\nand empirical likelihood. Compared with two popular methods (the bag of little\nbootstrap and the subsampled double bootstrap), we make full use of data sets,\nand reduce the computation burden. Extensive numerical studies and real data\nanalysis demonstrate the effectiveness and flexibility of our proposed method.\nFurthermore, the asymptotic property of our method is derived.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 10:18:07 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ma", "Xuejun", ""], ["Wang", "Shaochen", ""], ["Zhou", "Wang", ""]]}, {"id": "2004.08581", "submitter": "Zhe Liu", "authors": "Zhe Liu, Lina Yao, Xianzhi Wang, Lei Bai and Jake An", "title": "Are You A Risk Taker? Adversarial Learning of Asymmetric Cross-Domain\n  Alignment for Risk Tolerance Prediction", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207111", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current studies on survey analysis and risk tolerance modelling lack\nprofessional knowledge and domain-specific models. Given the effectiveness of\ngenerative adversarial learning in cross-domain information, we design an\nAsymmetric cross-Domain Generative Adversarial Network (ADGAN) for domain scale\ninequality. ADGAN utilizes the information-sufficient domain to provide extra\ninformation to improve the representation learning on the\ninformation-insufficient domain via domain alignment. We provide data analysis\nand user model on two data sources: Consumer Consumption Information and Survey\nInformation. We further test ADGAN on a real-world dataset with view embedding\nstructures and show ADGAN can better deal with the class imbalance and\nunqualified data space than state-of-the-art, demonstrating the effectiveness\nof leveraging asymmetrical domain information.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 10:20:28 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Liu", "Zhe", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Bai", "Lei", ""], ["An", "Jake", ""]]}, {"id": "2004.08597", "submitter": "Ananya Uppal", "authors": "Ananya Uppal, Shashank Singh, Barnabas Poczos", "title": "Robust Density Estimation under Besov IPM Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimax convergence rates of nonparametric density estimation in the\nHuber contamination model, in which a proportion of the data comes from an\nunknown outlier distribution. We provide the first results for this problem\nunder a large family of losses, called Besov integral probability metrics\n(IPMs), that includes $\\mathcal{L}^p$, Wasserstein, Kolmogorov-Smirnov, and\nother common distances between probability distributions. Specifically, under a\nrange of smoothness assumptions on the population and outlier distributions, we\nshow that a re-scaled thresholding wavelet series estimator achieves minimax\noptimal convergence rates under a wide variety of losses. Finally, based on\nconnections that have recently been shown between nonparametric density\nestimation under IPM losses and generative adversarial networks (GANs), we show\nthat certain GAN architectures also achieve these minimax rates.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:30:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Uppal", "Ananya", ""], ["Singh", "Shashank", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2004.08600", "submitter": "Chris Reinke", "authors": "Chris Reinke", "title": "Time Adaptive Reinforcement Learning", "comments": "ICLR 2020 Workshop: Beyond Tabula Rasa in Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) allows to solve complex tasks such as Go often\nwith a stronger performance than humans. However, the learned behaviors are\nusually fixed to specific tasks and unable to adapt to different contexts. Here\nwe consider the case of adapting RL agents to different time restrictions, such\nas finishing a task with a given time limit that might change from one task\nexecution to the next. We define such problems as Time Adaptive Markov Decision\nProcesses and introduce two model-free, value-based algorithms: the Independent\nGamma-Ensemble and the n-Step Ensemble. In difference to classical approaches,\nthey allow a zero-shot adaptation between different time restrictions. The\nproposed approaches represent general mechanisms to handle time adaptive tasks\nmaking them compatible with many existing RL methods, algorithms, and\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:52:07 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Reinke", "Chris", ""]]}, {"id": "2004.08620", "submitter": "Yongqiang Cai", "authors": "Yongqiang Cai, Qianxiao Li, Zuowei Shen", "title": "Optimization in Machine Learning: A Distribution Space Approach", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the viewpoint that optimization problems encountered in machine\nlearning can often be interpreted as minimizing a convex functional over a\nfunction space, but with a non-convex constraint set introduced by model\nparameterization. This observation allows us to repose such problems via a\nsuitable relaxation as convex optimization problems in the space of\ndistributions over the training parameters. We derive some simple relationships\nbetween the distribution-space problem and the original problem, e.g. a\ndistribution-space solution is at least as good as a solution in the original\nspace. Moreover, we develop a numerical algorithm based on mixture\ndistributions to perform approximate optimization directly in distribution\nspace. Consistency of this approximation is established and the numerical\nefficacy of the proposed algorithm is illustrated on simple examples. In both\ntheory and practice, this formulation provides an alternative approach to\nlarge-scale optimization in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 13:38:06 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cai", "Yongqiang", ""], ["Li", "Qianxiao", ""], ["Shen", "Zuowei", ""]]}, {"id": "2004.08648", "submitter": "Saeed Moazami", "authors": "Saeed Moazami, Peggy Doerschuk", "title": "Modeling Survival in model-based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent model-free reinforcement learning algorithms have been shown\nto be capable of mastering complicated decision-making tasks, the sample\ncomplexity of these methods has remained a hurdle to utilizing them in many\nreal-world applications. In this regard, model-based reinforcement learning\nproposes some remedies. Yet, inherently, model-based methods are more\ncomputationally expensive and susceptible to sub-optimality. One reason is that\nmodel-generated data are always less accurate than real data, and this often\nleads to inaccurate transition and reward function models. With the aim to\nmitigate this problem, this work presents the notion of survival by discussing\ncases in which the agent's goal is to survive and its analogy to maximizing the\nexpected rewards. To that end, a substitute model for the reward function\napproximator is introduced that learns to avoid terminal states rather than to\nmaximize accumulated rewards from safe states. Focusing on terminal states, as\na small fraction of state-space, reduces the training effort drastically. Next,\na model-based reinforcement learning method is proposed (Survive) to train an\nagent to avoid dangerous states through a safety map model built upon temporal\ncredit assignment in the vicinity of terminal states. Finally, the performance\nof the presented algorithm is investigated, along with a comparison between the\nproposed and current methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 15:49:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Moazami", "Saeed", ""], ["Doerschuk", "Peggy", ""]]}, {"id": "2004.08675", "submitter": "Valerii Likhosherstov", "authors": "Valerii Likhosherstov, Jared Davis, Krzysztof Choromanski, Adrian\n  Weller", "title": "CWY Parametrization: a Solution for Parallelized Optimization of\n  Orthogonal and Stiefel Matrices", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130. Copyright 2021 by the author(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient approach for optimization over orthogonal groups on\nhighly parallel computation units such as GPUs or TPUs. As in earlier work, we\nparametrize an orthogonal matrix as a product of Householder reflections.\nHowever, to overcome low parallelization capabilities of computing Householder\nreflections sequentially, we propose employing an accumulation scheme called\nthe compact WY (or CWY) transform -- a compact parallelization-friendly matrix\nrepresentation for the series of Householder reflections. We further develop a\nnovel Truncated CWY (or T-CWY) approach for Stiefel manifold parametrization\nwhich has a competitive complexity and, again, yields benefits when computed on\nGPUs and TPUs. We prove that our CWY and T-CWY methods lead to convergence to a\nstationary point of the training objective when coupled with stochastic\ngradient descent. We apply our methods to train recurrent neural network\narchitectures in the tasks of neural machine translation and video prediction.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 17:58:43 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 18:40:06 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 13:19:03 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Likhosherstov", "Valerii", ""], ["Davis", "Jared", ""], ["Choromanski", "Krzysztof", ""], ["Weller", "Adrian", ""]]}, {"id": "2004.08688", "submitter": "Fabi\\'an Latorre", "authors": "Fabian Latorre, Paul Rolland, Volkan Cevher", "title": "Lipschitz constant estimation of Neural Networks via sparse polynomial\n  optimization", "comments": "Published as a conference paper in ICLR2020, originally submitted in\n  September 25 2019 and available at https://openreview.net/forum?id=rJe4_xSFDB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce LiPopt, a polynomial optimization framework for computing\nincreasingly tighter upper bounds on the Lipschitz constant of neural networks.\nThe underlying optimization problems boil down to either linear (LP) or\nsemidefinite (SDP) programming. We show how to use the sparse connectivity of a\nnetwork, to significantly reduce the complexity of computation. This is\nspecially useful for convolutional as well as pruned neural networks. We\nconduct experiments on networks with random weights as well as networks trained\non MNIST, showing that in the particular case of the $\\ell_\\infty$-Lipschitz\nconstant, our approach yields superior estimates, compared to baselines\navailable in the literature.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 18:55:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Latorre", "Fabian", ""], ["Rolland", "Paul", ""], ["Cevher", "Volkan", ""]]}, {"id": "2004.08697", "submitter": "Mengyue Yang", "authors": "Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, Jun\n  Wang", "title": "CausalVAE: Disentangled Representation Learning via Neural Structural\n  Causal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentanglement aims at finding a low dimensional representation\nwhich consists of multiple explanatory and generative factors of the\nobservational data. The framework of variational autoencoder (VAE) is commonly\nused to disentangle independent factors from observations. However, in real\nscenarios, factors with semantics are not necessarily independent. Instead,\nthere might be an underlying causal structure which renders these factors\ndependent. We thus propose a new VAE based framework named CausalVAE, which\nincludes a Causal Layer to transform independent exogenous factors into causal\nendogenous ones that correspond to causally related concepts in data. We\nfurther analyze the model identifiabitily, showing that the proposed model\nlearned from observations recovers the true one up to a certain degree.\nExperiments are conducted on various datasets, including synthetic and real\nword benchmark CelebA. Results show that the causal representations learned by\nCausalVAE are semantically interpretable, and their causal relationship as a\nDirected Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we\ndemonstrate that the proposed CausalVAE model is able to generate\ncounterfactual data through \"do-operation\" to the causal factors.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 20:09:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 08:58:52 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 06:57:18 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 06:31:17 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 06:46:00 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Yang", "Mengyue", ""], ["Liu", "Furui", ""], ["Chen", "Zhitang", ""], ["Shen", "Xinwei", ""], ["Hao", "Jianye", ""], ["Wang", "Jun", ""]]}, {"id": "2004.08704", "submitter": "Hongxu Yin", "authors": "Wenhan Xia, Hongxu Yin, Niraj K. Jha", "title": "Efficient Synthesis of Compact Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been deployed in myriad machine learning\napplications. However, advances in their accuracy are often achieved with\nincreasingly complex and deep network architectures. These large, deep models\nare often unsuitable for real-world applications, due to their massive\ncomputational cost, high memory bandwidth, and long latency. For example,\nautonomous driving requires fast inference based on Internet-of-Things (IoT)\nedge devices operating under run-time energy and memory storage constraints. In\nsuch cases, compact DNNs can facilitate deployment due to their reduced energy\nconsumption, memory requirement, and inference latency. Long short-term\nmemories (LSTMs) are a type of recurrent neural network that have also found\nwidespread use in the context of sequential data modeling. They also face a\nmodel size vs. accuracy trade-off. In this paper, we review major approaches\nfor automatically synthesizing compact, yet accurate, DNN/LSTM models suitable\nfor real-world applications. We also outline some challenges and future areas\nof exploration.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 21:20:04 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Xia", "Wenhan", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2004.08705", "submitter": "Victor Gallego", "authors": "Victor Gallego, Roi Naveiro, Alberto Redondo, David Rios Insua,\n  Fabrizio Ruggeri", "title": "Protecting Classifiers From Attacks. A Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification problems in security settings are usually modeled as\nconfrontations in which an adversary tries to fool a classifier manipulating\nthe covariates of instances to obtain a benefit. Most approaches to such\nproblems have focused on game-theoretic ideas with strong underlying common\nknowledge assumptions, which are not realistic in the security realm. We\nprovide an alternative Bayesian framework that accounts for the lack of precise\nknowledge about the attacker's behavior using adversarial risk analysis. A key\ningredient required by our framework is the ability to sample from the\ndistribution of originating instances given the possibly attacked observed one.\nWe propose a sampling procedure based on approximate Bayesian computation, in\nwhich we simulate the attacker's problem taking into account our uncertainty\nabout his elements. For large scale problems, we propose an alternative,\nscalable approach that could be used when dealing with differentiable\nclassifiers. Within it, we move the computational load to the training phase,\nsimulating attacks from an adversary, adapting the framework to obtain a\nclassifier robustified against attacks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 21:21:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gallego", "Victor", ""], ["Naveiro", "Roi", ""], ["Redondo", "Alberto", ""], ["Insua", "David Rios", ""], ["Ruggeri", "Fabrizio", ""]]}, {"id": "2004.08763", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Kevin Xie, Florian Shkurti", "title": "Model-Predictive Control via Cross-Entropy and Gradient-Based\n  Optimization", "comments": "L4DC 2020; Accepted for presentation in the 2nd Annual Conference on\n  Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in high-dimensional model-predictive control and model-based\nreinforcement learning with learned dynamics and reward models have resorted to\npopulation-based optimization methods, such as the Cross-Entropy Method (CEM),\nfor planning a sequence of actions. To decide on an action to take, CEM\nconducts a search for the action sequence with the highest return according to\nthe dynamics model and reward. Action sequences are typically randomly sampled\nfrom an unconditional Gaussian distribution and evaluated on the environment.\nThis distribution is iteratively updated towards action sequences with higher\nreturns. However, this planning method can be very inefficient, especially for\nhigh-dimensional action spaces. An alternative line of approaches optimize\naction sequences directly via gradient descent, but are prone to local optima.\nWe propose a method to solve this planning problem by interleaving CEM and\ngradient descent steps in optimizing the action sequence. Our experiments show\nfaster convergence of the proposed hybrid approach, even for high-dimensional\naction spaces, avoidance of local minima, and better or equal performance to\nCEM. Code accompanying the paper is available here\nhttps://github.com/homangab/gradcem.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 03:54:50 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Xie", "Kevin", ""], ["Shkurti", "Florian", ""]]}, {"id": "2004.08773", "submitter": "Alper Atamturk", "authors": "Alper Atamt\\\"urk and Andr\\'es G\\'omez", "title": "Safe Screening Rules for $\\ell_0$-Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give safe screening rules to eliminate variables from regression with\n$\\ell_0$ regularization or cardinality constraint. These rules are based on\nguarantees that a feature may or may not be selected in an optimal solution.\nThe screening rules can be computed from a convex relaxation solution in linear\ntime, without solving the $\\ell_0$ optimization problem. Thus, they can be used\nin a preprocessing step to safely remove variables from consideration apriori.\nNumerical experiments on real and synthetic data indicate that, on average,\n76\\% of the variables can be fixed to their optimal values, hence, reducing the\ncomputational burden for optimization substantially. Therefore, the proposed\nfast and effective screening rules extend the scope of algorithms for\n$\\ell_0$-regression to larger data sets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 06:07:09 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Atamt\u00fcrk", "Alper", ""], ["G\u00f3mez", "Andr\u00e9s", ""]]}, {"id": "2004.08780", "submitter": "Brian Kenji Iwana", "authors": "Brian Kenji Iwana and Seiichi Uchida", "title": "Time Series Data Augmentation for Neural Networks by Time Warping with a\n  Discriminative Teacher", "comments": "Submitted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become a powerful tool in pattern recognition and part\nof their success is due to generalization from using large datasets. However,\nunlike other domains, time series classification datasets are often small. In\norder to address this problem, we propose a novel time series data augmentation\ncalled guided warping. While many data augmentation methods are based on random\ntransformations, guided warping exploits the element alignment properties of\nDynamic Time Warping (DTW) and shapeDTW, a high-level DTW method based on shape\ndescriptors, to deterministically warp sample patterns. In this way, the time\nseries are mixed by warping the features of a sample pattern to match the time\nsteps of a reference pattern. Furthermore, we introduce a discriminative\nteacher in order to serve as a directed reference for the guided warping. We\nevaluate the method on all 85 datasets in the 2015 UCR Time Series Archive with\na deep convolutional neural network (CNN) and a recurrent neural network (RNN).\nThe code with an easy to use implementation can be found at\nhttps://github.com/uchidalab/time_series_augmentation .\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 06:33:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Iwana", "Brian Kenji", ""], ["Uchida", "Seiichi", ""]]}, {"id": "2004.08830", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Improving Robot Dual-System Motor Learning with Intrinsically Motivated\n  Meta-Control and Latent-Space Experience Imagination", "comments": null, "journal-ref": "Robotics and Autonomous Systems 133 (2020) 103630", "doi": "10.1016/j.robot.2020.103630", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining model-based and model-free learning systems has been shown to\nimprove the sample efficiency of learning to perform complex robotic tasks.\nHowever, dual-system approaches fail to consider the reliability of the learned\nmodel when it is applied to make multiple-step predictions, resulting in a\ncompounding of prediction errors and performance degradation. In this paper, we\npresent a novel dual-system motor learning approach where a meta-controller\narbitrates online between model-based and model-free decisions based on an\nestimate of the local reliability of the learned model. The reliability\nestimate is used in computing an intrinsic feedback signal, encouraging actions\nthat lead to data that improves the model. Our approach also integrates\narbitration with imagination where a learned latent-space model generates\nimagined experiences, based on its local reliability, to be used as additional\ntraining data. We evaluate our approach against baseline and state-of-the-art\nmethods on learning vision-based robotic grasping in simulation and real world.\nThe results show that our approach outperforms the compared methods and learns\nnear-optimal grasping policies in dense- and sparse-reward environments.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 12:14:46 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:03:29 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 09:12:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "2004.08861", "submitter": "Jie Fu", "authors": "Jie Fu, Xue Geng, Zhijian Duan, Bohan Zhuang, Xingdi Yuan, Adam\n  Trischler, Jie Lin, Chris Pal, Hao Dong", "title": "Role-Wise Data Augmentation for Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a common method for transferring the\n``knowledge'' learned by one machine learning model (the \\textit{teacher}) into\nanother model (the \\textit{student}), where typically, the teacher has a\ngreater capacity (e.g., more parameters or higher bit-widths). To our\nknowledge, existing methods overlook the fact that although the student absorbs\nextra knowledge from the teacher, both models share the same input data -- and\nthis data is the only medium by which the teacher's knowledge can be\ndemonstrated. Due to the difference in model capacities, the student may not\nbenefit fully from the same data points on which the teacher is trained. On the\nother hand, a human teacher may demonstrate a piece of knowledge with\nindividualized examples adapted to a particular student, for instance, in terms\nof her cultural background and interests. Inspired by this behavior, we design\ndata augmentation agents with distinct roles to facilitate knowledge\ndistillation. Our data augmentation agents generate distinct training data for\nthe teacher and student, respectively. We find empirically that specially\ntailored data points enable the teacher's knowledge to be demonstrated more\neffectively to the student. We compare our approach with existing KD methods on\ntraining popular neural architectures and demonstrate that role-wise data\naugmentation improves the effectiveness of KD over strong prior approaches. The\ncode for reproducing our results can be found at\nhttps://github.com/bigaidream-projects/role-kd\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:22:17 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Fu", "Jie", ""], ["Geng", "Xue", ""], ["Duan", "Zhijian", ""], ["Zhuang", "Bohan", ""], ["Yuan", "Xingdi", ""], ["Trischler", "Adam", ""], ["Lin", "Jie", ""], ["Pal", "Chris", ""], ["Dong", "Hao", ""]]}, {"id": "2004.08867", "submitter": "Yulong Lu", "authors": "Yulong Lu and Jianfeng Lu", "title": "A Universal Approximation Theorem of Deep Neural Networks for Expressing\n  Probability Distributions", "comments": "Accepted in the Thirty-fourth Conference on Neural Information\n  Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the universal approximation property of deep neural\nnetworks for representing probability distributions. Given a target\ndistribution $\\pi$ and a source distribution $p_z$ both defined on\n$\\mathbb{R}^d$, we prove under some assumptions that there exists a deep neural\nnetwork $g:\\mathbb{R}^d\\rightarrow \\mathbb{R}$ with ReLU activation such that\nthe push-forward measure $(\\nabla g)_\\# p_z$ of $p_z$ under the map $\\nabla g$\nis arbitrarily close to the target measure $\\pi$. The closeness are measured by\nthree classes of integral probability metrics between probability\ndistributions: $1$-Wasserstein distance, maximum mean distance (MMD) and\nkernelized Stein discrepancy (KSD). We prove upper bounds for the size (width\nand depth) of the deep neural network in terms of the dimension $d$ and the\napproximation error $\\varepsilon$ with respect to the three discrepancies. In\nparticular, the size of neural network can grow exponentially in $d$ when\n$1$-Wasserstein distance is used as the discrepancy, whereas for both MMD and\nKSD the size of neural network only depends on $d$ at most polynomially. Our\nproof relies on convergence estimates of empirical measures under\naforementioned discrepancies and semi-discrete optimal transport.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:45:47 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 19:05:19 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 04:29:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lu", "Yulong", ""], ["Lu", "Jianfeng", ""]]}, {"id": "2004.08870", "submitter": "Marcin Mozejko", "authors": "Marcin Mo\\.zejko, Tomasz Latkowski, {\\L}ukasz Treszczotko, Micha{\\l}\n  Szafraniuk, Krzysztof Trojanowski", "title": "Superkernel Neural Architecture Search for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in Neural Architecture Search(NAS) resulted in finding\nnew state-of-the-art Artificial Neural Network (ANN) solutions for tasks like\nimage classification, object detection, or semantic segmentation without\nsubstantial human supervision. In this paper, we focus on exploring NAS for a\ndense prediction task that is image denoising. Due to a costly training\nprocedure, most NAS solutions for image enhancement rely on reinforcement\nlearning or evolutionary algorithm exploration, which usually take weeks (or\neven months) to train. Therefore, we introduce a new efficient implementation\nof various superkernel techniques that enable fast (6-8 RTX2080 GPU hours)\nsingle-shot training of models for dense predictions. We demonstrate the\neffectiveness of our method on the SIDD+ benchmark for image denoising.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:52:22 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mo\u017cejko", "Marcin", ""], ["Latkowski", "Tomasz", ""], ["Treszczotko", "\u0141ukasz", ""], ["Szafraniuk", "Micha\u0142", ""], ["Trojanowski", "Krzysztof", ""]]}, {"id": "2004.08883", "submitter": "Chao Qu", "authors": "Chao Qu, Hui Li, Chang Liu, Junwu Xiong, James Zhang, Wei Chu,\n  Weiqiang Wang, Yuan Qi, Le Song", "title": "Intention Propagation for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of an AI agent is to mimic human beings to understand and interact\nwith others. In this paper, we propose a collaborative multi-agent\nreinforcement learning algorithm to learn a \\emph{joint} policy through the\ninteractions over agents. To make a joint decision over the group, each agent\nmakes an initial decision and tells its policy to its neighbors. Then each\nagent modifies its own policy properly based on received messages and spreads\nout its plan. As this intention propagation procedure goes on, we prove that it\nconverges to a mean-field approximation of the joint policy with the framework\nof neural embedded probabilistic inference. We evaluate our algorithm on\nseveral large scale challenging tasks and demonstrate that it outperforms\nprevious state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 15:42:55 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 05:13:41 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 02:16:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Qu", "Chao", ""], ["Li", "Hui", ""], ["Liu", "Chang", ""], ["Xiong", "Junwu", ""], ["Zhang", "James", ""], ["Chu", "Wei", ""], ["Wang", "Weiqiang", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "2004.08889", "submitter": "Indranil SenGupta", "authors": "Michael Roberts, Indranil SenGupta", "title": "Sequential hypothesis testing in machine learning, and crude oil price\n  jump size detection", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.MF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a sequential hypothesis test for the detection of\ngeneral jump size distrubution. Infinitesimal generators for the corresponding\nlog-likelihood ratios are presented and analyzed. Bounds for infinitesimal\ngenerators in terms of super-solutions and sub-solutions are computed. This is\nshown to be implementable in relation to various classification problems for a\ncrude oil price data set. Machine and deep learning algorithms are implemented\nto extract a specific deterministic component from the crude oil data set, and\nthe deterministic component is implemented to improve the Barndorff-Nielsen and\nShephard model, a commonly used stochastic model for derivative and commodity\nmarket analysis.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:02:08 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 19:20:37 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 15:51:02 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Roberts", "Michael", ""], ["SenGupta", "Indranil", ""]]}, {"id": "2004.08891", "submitter": "Weiguan Wang", "authors": "Johannes Ruf, Weiguan Wang", "title": "Hedging with Linear Regressions and Neural Networks", "comments": "Forthcoming in the Journal of Business & Economic Statistics", "journal-ref": null, "doi": "10.1080/07350015.2021.1931241", "report-no": null, "categories": "q-fin.RM cs.LG q-fin.MF q-fin.ST stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study neural networks as nonparametric estimation tools for the hedging of\noptions. To this end, we design a network, named HedgeNet, that directly\noutputs a hedging strategy. This network is trained to minimise the hedging\nerror instead of the pricing error. Applied to end-of-day and tick prices of\nS&P 500 and Euro Stoxx 50 options, the network is able to reduce the mean\nsquared hedging error of the Black-Scholes benchmark significantly. However, a\nsimilar benefit arises by simple linear regressions that incorporate the\nleverage effect.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:07:45 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:23:09 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 08:11:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ruf", "Johannes", ""], ["Wang", "Weiguan", ""]]}, {"id": "2004.08919", "submitter": "Kexin Huang", "authors": "Kexin Huang, Tianfan Fu, Lucas Glass, Marinka Zitnik, Cao Xiao, Jimeng\n  Sun", "title": "DeepPurpose: a Deep Learning Library for Drug-Target Interaction\n  Prediction", "comments": "Published in Bioinformatics (2020)", "journal-ref": null, "doi": "10.1093/bioinformatics/btaa1005", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate prediction of drug-target interactions (DTI) is crucial for drug\ndiscovery. Recently, deep learning (DL) models for show promising performance\nfor DTI prediction. However, these models can be difficult to use for both\ncomputer scientists entering the biomedical field and bioinformaticians with\nlimited DL experience. We present DeepPurpose, a comprehensive and easy-to-use\ndeep learning library for DTI prediction. DeepPurpose supports training of\ncustomized DTI prediction models by implementing 15 compound and protein\nencoders and over 50 neural architectures, along with providing many other\nuseful features. We demonstrate state-of-the-art performance of DeepPurpose on\nseveral benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 17:31:55 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 13:10:26 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 23:14:48 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Huang", "Kexin", ""], ["Fu", "Tianfan", ""], ["Glass", "Lucas", ""], ["Zitnik", "Marinka", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "2004.08924", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy and Joseph E. Gonzalez and Michael I. Jordan and\n  Ion Stoica", "title": "Mechanism Design with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-round welfare-maximising mechanism design problem in\ninstances where agents do not know their values. On each round, a mechanism\nassigns an allocation each to a set of agents and charges them a price; then\nthe agents provide (stochastic) feedback to the mechanism for the allocation\nthey received. This is motivated by applications in cloud markets and online\nadvertising where an agent may know her value for an allocation only after\nexperiencing it. Therefore, the mechanism needs to explore different\nallocations for each agent, while simultaneously attempting to find the\nsocially optimal set of allocations. Our focus is on truthful and individually\nrational mechanisms which imitate the classical VCG mechanism in the long run.\nTo that end, we define three notions of regret for the welfare, the individual\nutilities of each agent and that of the mechanism. We show that these three\nterms are interdependent via an $\\Omega(T^{\\frac{2}{3}})$ lower bound for the\nmaximum of these three terms after $T$ rounds of allocations, and describe a\nfamily of anytime algorithms which achieve this rate. Our framework provides\nflexibility to control the pricing scheme so as to trade-off between the agent\nand seller regrets, and additionally to control the degree of truthfulness and\nindividual rationality.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:00:58 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:23:06 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 22:03:03 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Gonzalez", "Joseph E.", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "2004.08925", "submitter": "Benjamin Paassen", "authors": "Benjamin Paassen, Irena Koprinska, Kalina Yacef", "title": "Tree Echo State Autoencoders with Grammars", "comments": "accepted at the 2020 International Joint Conference on Neural\n  Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree data occurs in many forms, such as computer programs, chemical\nmolecules, or natural language. Unfortunately, the non-vectorial and discrete\nnature of trees makes it challenging to construct functions with tree-formed\noutput, complicating tasks such as optimization or time series prediction.\nAutoencoders address this challenge by mapping trees to a vectorial latent\nspace, where tasks are easier to solve, and then mapping the solution back to a\ntree structure. However, existing autoencoding approaches for tree data fail to\ntake the specific grammatical structure of tree domains into account and rely\non deep learning, thus requiring large training datasets and long training\ntimes. In this paper, we propose tree echo state autoencoders (TES-AE), which\nare guided by a tree grammar and can be trained within seconds by virtue of\nreservoir computing. In our evaluation on three datasets, we demonstrate that\nour proposed approach is not only much faster than a state-of-the-art deep\nlearning autoencoding approach (D-VAE) but also has less autoencoding error if\nlittle data and time is given.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:04:33 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Paassen", "Benjamin", ""], ["Koprinska", "Irena", ""], ["Yacef", "Kalina", ""]]}, {"id": "2004.08930", "submitter": "Bo Li", "authors": "Alexander Mozeika and Bo Li and David Saad", "title": "Space of Functions Computed by Deep-Layered Machines", "comments": null, "journal-ref": "Phys. Rev. Lett. 125, 168301 (2020)", "doi": "10.1103/PhysRevLett.125.168301", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the space of functions computed by random-layered machines,\nincluding deep neural networks and Boolean circuits. Investigating the\ndistribution of Boolean functions computed on the recurrent and layer-dependent\narchitectures, we find that it is the same in both models. Depending on the\ninitial conditions and computing elements used, we characterize the space of\nfunctions computed at the large depth limit and show that the macroscopic\nentropy of Boolean functions is either monotonically increasing or decreasing\nwith the growing depth.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:31:03 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 21:06:29 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 01:36:46 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Mozeika", "Alexander", ""], ["Li", "Bo", ""], ["Saad", "David", ""]]}, {"id": "2004.08935", "submitter": "Robert Lunde", "authors": "Qiaohui Lin, Robert Lunde, Purnamrita Sarkar", "title": "On the Theoretical Properties of the Network Jackknife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the properties of a leave-node-out jackknife procedure for network\ndata. Under the sparse graphon model, we prove an Efron-Stein-type inequality,\nshowing that the network jackknife leads to conservative estimates of the\nvariance (in expectation) for any network functional that is invariant to node\npermutation. For a general class of count functionals, we also establish\nconsistency of the network jackknife. We complement our theoretical analysis\nwith a range of simulated and real-data examples and show that the network\njackknife offers competitive performance in cases where other resampling\nmethods are known to be valid. In fact, for several network statistics, we see\nthat the jackknife provides more accurate inferences compared to related\nmethods such as subsampling.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 19:03:32 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 08:53:12 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lin", "Qiaohui", ""], ["Lunde", "Robert", ""], ["Sarkar", "Purnamrita", ""]]}, {"id": "2004.08957", "submitter": "Min Gao", "authors": "Min Gao, Yukun Guo, Tristan T. Hormel, Jiande Sun, Thomas Hwang and\n  Yali Jia", "title": "Reconstruction of high-resolution 6x6-mm OCT angiograms using deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical optical coherence tomographic angiography (OCTA) acquisition areas on\ncommercial devices are 3x3- or 6x6-mm. Compared to 3x3-mm angiograms with\nproper sampling density, 6x6-mm angiograms have significantly lower scan\nquality, with reduced signal-to-noise ratio and worse shadow artifacts due to\nundersampling. Here, we propose a deep-learning-based high-resolution angiogram\nreconstruction network (HARNet) to generate enhanced 6x6-mm superficial\nvascular complex (SVC) angiograms. The network was trained on data from 3x3-mm\nand 6x6-mm angiograms from the same eyes. The reconstructed 6x6-mm angiograms\nhave significantly lower noise intensity and better vascular connectivity than\nthe original images. The algorithm did not generate false flow signal at the\nnoise level presented by the original angiograms. The image enhancement\nproduced by our algorithm may improve biomarker measurements and qualitative\nclinical assessment of 6x6-mm OCTA.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 20:43:13 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:18:03 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Gao", "Min", ""], ["Guo", "Yukun", ""], ["Hormel", "Tristan T.", ""], ["Sun", "Jiande", ""], ["Hwang", "Thomas", ""], ["Jia", "Yali", ""]]}, {"id": "2004.08981", "submitter": "Daniil Merkulov", "authors": "Daniil Merkulov, Ivan Oseledets", "title": "Stochastic gradient algorithms from ODE splitting perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a different view on stochastic optimization, which goes back to\nthe splitting schemes for approximate solutions of ODE. In this work, we\nprovide a connection between stochastic gradient descent approach and\nfirst-order splitting scheme for ODE. We consider the special case of\nsplitting, which is inspired by machine learning applications and derive a new\nupper bound on the global splitting error for it. We present, that the Kaczmarz\nmethod is the limit case of the splitting scheme for the unit batch SGD for\nlinear least squares problem. We support our findings with systematic empirical\nstudies, which demonstrates, that a more accurate solution of local problems\nleads to the stepsize robustness and provides better convergence in time and\niterations on the softmax regression problem.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 22:45:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Merkulov", "Daniil", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2004.08998", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, H. He, T. Yang, X. Wang, R. C. de Lamare", "title": "Study of Diffusion Normalized Least Mean M-estimate Algorithms", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes diffusion normalized least mean M-estimate algorithm based\non the modified Huber function, which can equip distributed networks with\nrobust learning capability in the presence of impulsive interference. In order\nto exploit the system's underlying sparsity to further improve the learning\nperformance, a sparse-aware variant is also developed by incorporating the\n$l_0$-norm of the estimates into the update process. We then analyze the\ntransient, steady-state and stability behaviors of the algorithms in a unified\nframework. In particular, we present an analytical method that is simpler than\nconventional approaches to deal with the score function since it removes the\nrequirements of integrals and Price's theorem. Simulations in various impulsive\nnoise scenarios show that the proposed algorithms are superior to some existing\ndiffusion algorithms and the theoretical results are verifiable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 00:28:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yu", "Y.", ""], ["He", "H.", ""], ["Yang", "T.", ""], ["Wang", "X.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "2004.09007", "submitter": "Ahmed Abdelkader", "authors": "Ahmed Abdelkader, Michael J. Curry, Liam Fowl, Tom Goldstein, Avi\n  Schwarzschild, Manli Shu, Christoph Studer, Chen Zhu", "title": "Headless Horseman: Adversarial Attacks on Transfer Learning Models", "comments": "5 pages, 2 figures. Accepted in ICASSP 2020. Code available on\n  https://github.com/zhuchen03/headless-attack.git", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053181", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning facilitates the training of task-specific classifiers using\npre-trained models as feature extractors. We present a family of transferable\nadversarial attacks against such classifiers, generated without access to the\nclassification head; we call these \\emph{headless attacks}. We first\ndemonstrate successful transfer attacks against a victim network using\n\\textit{only} its feature extractor. This motivates the introduction of a\nlabel-blind adversarial attack. This transfer attack method does not require\nany information about the class-label space of the victim. Our attack lowers\nthe accuracy of a ResNet18 trained on CIFAR10 by over 40\\%.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 01:07:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Abdelkader", "Ahmed", ""], ["Curry", "Michael J.", ""], ["Fowl", "Liam", ""], ["Goldstein", "Tom", ""], ["Schwarzschild", "Avi", ""], ["Shu", "Manli", ""], ["Studer", "Christoph", ""], ["Zhu", "Chen", ""]]}, {"id": "2004.09010", "submitter": "Imran Razzak Dr", "authors": "Arshia Rehman, Saeeda Naz, Imran Razzak", "title": "Leveraging Big Data Analytics in Healthcare Enhancement: Trends,\n  Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinicians decisions are becoming more and more evidence-based meaning in no\nother field the big data analytics so promising as in healthcare. Due to the\nsheer size and availability of healthcare data, big data analytics has\nrevolutionized this industry and promises us a world of opportunities. It\npromises us the power of early detection, prediction, prevention and helps us\nto improve the quality of life. Researchers and clinicians are working to\ninhibit big data from having a positive impact on health in the future.\nDifferent tools and techniques are being used to analyze, process, accumulate,\nassimilate and manage large amount of healthcare data either in structured or\nunstructured form. In this paper, we would like to address the need of big data\nanalytics in healthcare: why and how can it help to improve life?. We present\nthe emerging landscape of big data and analytical techniques in the five\nsub-disciplines of healthcare i.e.medical image analysis and imaging\ninformatics, bioinformatics, clinical informatics, public health informatics\nand medical signal analytics. We presents different architectures, advantages\nand repositories of each discipline that draws an integrated depiction of how\ndistinct healthcare activities are accomplished in the pipeline to facilitate\nindividual patients from multiple perspectives. Finally the paper ends with the\nnotable applications and challenges in adoption of big data analytics in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:46:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rehman", "Arshia", ""], ["Naz", "Saeeda", ""], ["Razzak", "Imran", ""]]}, {"id": "2004.09017", "submitter": "Qiao Liu", "authors": "Qiao Liu, Jiaze Xu, Rui Jiang, Wing Hung Wong", "title": "Roundtrip: A Deep Generative Neural Density Estimator", "comments": null, "journal-ref": "Proceedings of the National Academy of Sciences, 2021, 118(15)", "doi": "10.1073/pnas.2101344118", "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is a fundamental problem in both statistics and machine\nlearning. In this study, we proposed Roundtrip as a general-purpose neural\ndensity estimator based on deep generative models. Roundtrip retains the\ngenerative power of generative adversarial networks (GANs) but also provides\nestimates of density values. Unlike previous neural density estimators that put\nstringent conditions on the transformation from the latent space to the data\nspace, Roundtrip enables the use of much more general mappings. In a series of\nexperiments, Roundtrip achieves state-of-the-art performance in a diverse range\nof density estimation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 01:47:00 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 02:30:16 GMT"}, {"version": "v3", "created": "Sun, 10 May 2020 06:30:26 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 07:17:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Liu", "Qiao", ""], ["Xu", "Jiaze", ""], ["Jiang", "Rui", ""], ["Wong", "Wing Hung", ""]]}, {"id": "2004.09031", "submitter": "Huanrui Yang", "authors": "Huanrui Yang, Minxue Tang, Wei Wen, Feng Yan, Daniel Hu, Ang Li, Hai\n  Li, Yiran Chen", "title": "Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality\n  Regularization and Singular Value Sparsification", "comments": "In proceeding of 2020 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition Workshops (CVPRW). To be presented at EDLCV 2020 workshop\n  co-located with CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks (DNNs) often require high memory consumption and\nlarge computational loads. In order to deploy DNN algorithms efficiently on\nedge or mobile devices, a series of DNN compression algorithms have been\nexplored, including factorization methods. Factorization methods approximate\nthe weight matrix of a DNN layer with the multiplication of two or multiple\nlow-rank matrices. However, it is hard to measure the ranks of DNN layers\nduring the training process. Previous works mainly induce low-rank through\nimplicit approximations or via costly singular value decomposition (SVD)\nprocess on every training step. The former approach usually induces a high\naccuracy loss while the latter has a low efficiency. In this work, we propose\nSVD training, the first method to explicitly achieve low-rank DNNs during\ntraining without applying SVD on every step. SVD training first decomposes each\nlayer into the form of its full-rank SVD, then performs training directly on\nthe decomposed weights. We add orthogonality regularization to the singular\nvectors, which ensure the valid form of SVD and avoid gradient\nvanishing/exploding. Low-rank is encouraged by applying sparsity-inducing\nregularizers on the singular values of each layer. Singular value pruning is\napplied at the end to explicitly reach a low-rank model. We empirically show\nthat SVD training can significantly reduce the rank of DNN layers and achieve\nhigher reduction on computation load under the same accuracy, comparing to not\nonly previous factorization methods but also state-of-the-art filter pruning\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 02:40:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yang", "Huanrui", ""], ["Tang", "Minxue", ""], ["Wen", "Wei", ""], ["Yan", "Feng", ""], ["Hu", "Daniel", ""], ["Li", "Ang", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2004.09043", "submitter": "Eric Zelikman", "authors": "Eric Zelikman, William Yin, Kenneth Wang", "title": "Learning as Reinforcement: Applying Principles of Neuroscience for More\n  General Reinforcement Learning Agents", "comments": "Originally completed as part of Stanford's CS 234 \"Reinforcement\n  Learning.\" Presented at the California Cognitive Science Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge in developing AI that can generalize well is\ndesigning agents that learn about their world without being told what to learn,\nand apply that learning to challenges with sparse rewards. Moreover, most\ntraditional reinforcement learning approaches explicitly separate learning and\ndecision making in a way that does not correspond to biological learning. We\nimplement an architecture founded in principles of experimental neuroscience,\nby combining computationally efficient abstractions of biological algorithms.\nOur approach is inspired by research on spike-timing dependent plasticity, the\ntransition between short and long term memory, and the role of various\nneurotransmitters in rewarding curiosity. The Neurons-in-a-Box architecture can\nlearn in a wholly generalizable manner, and demonstrates an efficient way to\nbuild and apply representations without explicitly optimizing over a set of\ncriteria or actions. We find it performs well in many environments including\nOpenAI Gym's Mountain Car, which has no reward besides touching a hard-to-reach\nflag on a hill, Inverted Pendulum, where it learns simple strategies to improve\nthe time it holds a pendulum up, a video stream, where it spontaneously learns\nto distinguish an open and closed hand, as well as other environments like\nGoogle Chrome's Dinosaur Game.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 04:06:21 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zelikman", "Eric", ""], ["Yin", "William", ""], ["Wang", "Kenneth", ""]]}, {"id": "2004.09073", "submitter": "Ranjan Maitra", "authors": "Geoffrey Z. Thompson and Ranjan Maitra", "title": "CatSIM: A Categorical Image Similarity Metric", "comments": "17 pages, 16 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CatSIM, a new similarity metric for binary and multinary two-\nand three-dimensional images and volumes. CatSIM uses a structural similarity\nimage quality paradigm and is robust to small perturbations in location so that\nstructures in similar, but not entirely overlapping, regions of two images are\nrated higher than using simple matching. The metric can also compare arbitrary\nregions inside images. CatSIM is evaluated on artificial data sets, image\nquality assessment surveys and two imaging applications\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 06:03:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Thompson", "Geoffrey Z.", ""], ["Maitra", "Ranjan", ""]]}, {"id": "2004.09112", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Christopher Strohmeier, Georg Menz, and Deanna Needell", "title": "COVID-19 Time-series Prediction by Joint Dictionary Learning and Online\n  NMF", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the spread and containment of COVID-19 is a challenge of utmost\nimportance that the broader scientific community is currently facing. One of\nthe main sources of difficulty is that a very limited amount of daily COVID-19\ncase data is available, and with few exceptions, the majority of countries are\ncurrently in the \"exponential spread stage,\" and thus there is scarce\ninformation available which would enable one to predict the phase transition\nbetween spread and containment.\n  In this paper, we propose a novel approach to predicting the spread of\nCOVID-19 based on dictionary learning and online nonnegative matrix\nfactorization (online NMF). The key idea is to learn dictionary patterns of\nshort evolution instances of the new daily cases in multiple countries at the\nsame time, so that their latent correlation structures are captured in the\ndictionary patterns. We first learn such patterns by minibatch learning from\nthe entire time-series and then further adapt them to the time-series by online\nNMF. As we progressively adapt and improve the learned dictionary patterns to\nthe more recent observations, we also use them to make one-step predictions by\nthe partial fitting. Lastly, by recursively applying the one-step predictions,\nwe can extrapolate our predictions into the near future. Our prediction results\ncan be directly attributed to the learned dictionary patterns due to their\ninterpretability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:02:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Strohmeier", "Christopher", ""], ["Menz", "Georg", ""], ["Needell", "Deanna", ""]]}, {"id": "2004.09140", "submitter": "Alexey Zaytsev", "authors": "Roman Kail, Alexey Zaytsev, Evgeny Burnaev", "title": "Recurrent Convolutional Neural Networks help to predict location of\n  Earthquakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the applicability of modern neural network architectures to the\nmidterm prediction of earthquakes. Our data-based classification model aims to\npredict if an earthquake with the magnitude above a threshold takes place at a\ngiven area of size $10 \\times 10$ kilometers in $10$-$60$ days from a given\nmoment. Our deep neural network model has a recurrent part (LSTM) that accounts\nfor time dependencies between earthquakes and a convolutional part that\naccounts for spatial dependencies. Obtained results show that neural\nnetworks-based models beat baseline feature-based models that also account for\nspatio-temporal dependencies between different earthquakes. For historical data\non Japan earthquakes our model predicts occurrence of an earthquake in $10$ to\n$60$ days from a given moment with magnitude $M_c > 5$ with quality metrics ROC\nAUC $0.975$ and PR AUC $0.0890$, making $1.18 \\cdot 10^3$ correct predictions,\nwhile missing $2.09 \\cdot 10^3$ earthquakes and making $192 \\cdot 10^3$ false\nalarms. The baseline approach has similar ROC AUC $0.992$, number of correct\npredictions $1.19 \\cdot 10^3$, and missing $2.07 \\cdot 10^3$ earthquakes, but\nsignificantly worse PR AUC $0.00911$, and number of false alarms $1004 \\cdot\n10^3$.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:05:13 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 17:25:20 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 14:13:17 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Kail", "Roman", ""], ["Zaytsev", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2004.09148", "submitter": "Fredrik Hellstr\\\"om", "authors": "Fredrik Hellstr\\\"om, Giuseppe Durisi", "title": "Generalization Error Bounds via $m$th Central Moments of the Information\n  Density", "comments": "ISIT 2020. Corrected Corollary 7 and the discussion in section II-D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general approach to deriving bounds on the generalization error\nof randomized learning algorithms. Our approach can be used to obtain bounds on\nthe average generalization error as well as bounds on its tail probabilities,\nboth for the case in which a new hypothesis is randomly generated every time\nthe algorithm is used - as often assumed in the probably approximately correct\n(PAC)-Bayesian literature - and in the single-draw case, where the hypothesis\nis extracted only once. For this last scenario, we present a novel bound that\nis explicit in the central moments of the information density. The bound\nreveals that the higher the order of the information density moment that can be\ncontrolled, the milder the dependence of the generalization bound on the\ndesired confidence level. Furthermore, we use tools from binary hypothesis\ntesting to derive a second bound, which is explicit in the tail of the\ninformation density. This bound confirms that a fast decay of the tail of the\ninformation density yields a more favorable dependence of the generalization\nbound on the confidence level.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:23:49 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:11:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hellstr\u00f6m", "Fredrik", ""], ["Durisi", "Giuseppe", ""]]}, {"id": "2004.09152", "submitter": "Fredrik Bagge Carlson", "authors": "Fredrik Bagge Carlson, Mandar Chitre", "title": "New Metrics Between Rational Spectra and their Connection to Optimal\n  Transport", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SP eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a series of metrics between pairs of signals, linear systems or\nrational spectra, based on optimal transport and linear-systems theory. The\nmetrics operate on the locations of the poles of rational functions and admit\nvery efficient computation of distances, barycenters, displacement\ninterpolation and projections. We establish the connection to the Wasserstein\ndistance between rational spectra, and demonstrate the use of the metrics in\ntasks such as signal classification, clustering, detection and approximation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:29:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Carlson", "Fredrik Bagge", ""], ["Chitre", "Mandar", ""]]}, {"id": "2004.09166", "submitter": "Matthias Rath", "authors": "Matthias Rath and Alexandru Paul Condurache", "title": "Invariant Integration in Deep Convolutional Feature Space", "comments": "Accepted at ESANN 2020 (European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we show how to incorporate prior knowledge to a deep\nneural network architecture in a principled manner. We enforce feature space\ninvariances using a novel layer based on invariant integration. This allows us\nto construct a complete feature space invariant to finite transformation\ngroups.\n  We apply our proposed layer to explicitly insert invariance properties for\nvision-related classification tasks, demonstrate our approach for the case of\nrotation invariance and report state-of-the-art performance on the\nRotated-MNIST dataset. Our method is especially beneficial when training with\nlimited data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:45:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rath", "Matthias", ""], ["Condurache", "Alexandru Paul", ""]]}, {"id": "2004.09179", "submitter": "Julia Lust", "authors": "Julia Lust and Alexandru Paul Condurache", "title": "GraN: An Efficient Gradient-Norm Based Detector for Adversarial and\n  Misclassified Examples", "comments": "Accepted at ESANN 2020 (European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples and other\ndata perturbations. Especially in safety critical applications of DNNs, it is\ntherefore crucial to detect misclassified samples. The current state-of-the-art\ndetection methods require either significantly more runtime or more parameters\nthan the original network itself. This paper therefore proposes GraN, a time-\nand parameter-efficient method that is easily adaptable to any DNN.\n  GraN is based on the layer-wise norm of the DNN's gradient regarding the loss\nof the current input-output combination, which can be computed via\nbackpropagation. GraN achieves state-of-the-art performance on numerous problem\nset-ups.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:09:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Lust", "Julia", ""], ["Condurache", "Alexandru Paul", ""]]}, {"id": "2004.09189", "submitter": "Chen Wu", "authors": "Chen Wu, Prince Zizhuang Wang, William Yang Wang", "title": "On the Encoder-Decoder Incompatibility in Variational Text Modeling and\n  Beyond", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) combine latent variables with amortized\nvariational inference, whose optimization usually converges into a trivial\nlocal optimum termed posterior collapse, especially in text modeling. By\ntracking the optimization dynamics, we observe the encoder-decoder\nincompatibility that leads to poor parameterizations of the data manifold. We\nargue that the trivial local optimum may be avoided by improving the encoder\nand decoder parameterizations since the posterior network is part of a\ntransition map between them. To this end, we propose Coupled-VAE, which couples\na VAE model with a deterministic autoencoder with the same structure and\nimproves the encoder and decoder parameterizations via encoder weight sharing\nand decoder signal matching. We apply the proposed Coupled-VAE approach to\nvarious VAE models with different regularization, posterior family, decoder\nstructure, and optimization strategy. Experiments on benchmark datasets (i.e.,\nPTB, Yelp, and Yahoo) show consistently improved results in terms of\nprobability estimation and richness of the latent space. We also generalize our\nmethod to conditional language modeling and propose Coupled-CVAE, which largely\nimproves the diversity of dialogue generation on the Switchboard dataset.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:34:10 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wu", "Chen", ""], ["Wang", "Prince Zizhuang", ""], ["Wang", "William Yang", ""]]}, {"id": "2004.09219", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, N T V Satya Dev, Anoop Kunchukuttan, Bamdev Mishra", "title": "Learning Geometric Word Meta-Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a geometric framework for learning meta-embeddings of words from\ndifferent embedding sources. Our framework transforms the embeddings into a\ncommon latent space, where, for example, simple averaging of different\nembeddings (of a given word) is more amenable. The proposed latent space arises\nfrom two particular geometric transformations - the orthogonal rotations and\nthe Mahalanobis metric scaling. Empirical results on several word similarity\nand word analogy benchmarks illustrate the efficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:49:04 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Dev", "N T V Satya", ""], ["Kunchukuttan", "Anoop", ""], ["Mishra", "Bamdev", ""]]}, {"id": "2004.09222", "submitter": "Alexandr Katrutsa", "authors": "Julia Gusak, Larisa Markeeva, Talgat Daulbaev, Alexandr Katrutsa,\n  Andrzej Cichocki, Ivan Oseledets", "title": "Towards Understanding Normalization in Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization is an important and vastly investigated technique in deep\nlearning. However, its role for Ordinary Differential Equation based networks\n(neural ODEs) is still poorly understood. This paper investigates how different\nnormalization techniques affect the performance of neural ODEs. Particularly,\nwe show that it is possible to achieve 93% accuracy in the CIFAR-10\nclassification task, and to the best of our knowledge, this is the highest\nreported accuracy among neural ODEs tested on this problem.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:54:55 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 19:43:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Gusak", "Julia", ""], ["Markeeva", "Larisa", ""], ["Daulbaev", "Talgat", ""], ["Katrutsa", "Alexandr", ""], ["Cichocki", "Andrzej", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2004.09258", "submitter": "Vidit Saxena", "authors": "Vidit Saxena, Joseph E. Gonzalez, and Joakim Jald\\'en", "title": "Thompson Sampling for Linearly Constrained Bandits", "comments": "10 pages, 2 figures, updated version of paper accepted at AISTATS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We address multi-armed bandits (MAB) where the objective is to maximize the\ncumulative reward under a probabilistic linear constraint. For a few real-world\ninstances of this problem, constrained extensions of the well-known Thompson\nSampling (TS) heuristic have recently been proposed. However, finite-time\nanalysis of constrained TS is challenging; as a result, only O(\\sqrt{T}) bounds\non the cumulative reward loss (i.e., the regret) are available. In this paper,\nwe describe LinConTS, a TS-based algorithm for bandits that place a linear\nconstraint on the probability of earning a reward in every round. We show that\nfor LinConTS, the regret as well as the cumulative constraint violations are\nupper bounded by O(\\log T) for the suboptimal arms. We develop a proof\ntechnique that relies on careful analysis of the dual problem and combine it\nwith recent theoretical work on unconstrained TS. Through numerical experiments\non two real-world datasets, we demonstrate that LinConTS outperforms an\nasymptotically optimal upper confidence bound (UCB) scheme in terms of\nsimultaneously minimizing the regret and the violation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:06:35 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:34:47 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Saxena", "Vidit", ""], ["Gonzalez", "Joseph E.", ""], ["Jald\u00e9n", "Joakim", ""]]}, {"id": "2004.09259", "submitter": "Johannes Kruse", "authors": "Johannes Kruse, Benjamin Sch\\\"afer and Dirk Witthaut", "title": "Predictability of Power Grid Frequency", "comments": "12 pages, 8 figures, Supplementary material on data preparation", "journal-ref": "IEEE Access, vol. 8, August 2020, pp. 149435-149446", "doi": "10.1109/ACCESS.2020.3016477", "report-no": null, "categories": "physics.soc-ph cs.SY eess.SP eess.SY physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power grid frequency is the central observable in power system control,\nas it measures the balance of electrical supply and demand. A reliable\nfrequency forecast can facilitate rapid control actions and may thus greatly\nimprove power system stability. Here, we develop a weighted-nearest-neighbor\n(WNN) predictor to investigate how predictable the frequency trajectories are.\nOur forecasts for up to one hour are more precise than averaged daily profiles\nand could increase the efficiency of frequency control actions. Furthermore, we\ngain an increased understanding of the specific properties of different\nsynchronous areas by interpreting the optimal prediction parameters (number of\nnearest neighbors, the prediction horizon, etc.) in terms of the physical\nsystem. Finally, prediction errors indicate the occurrence of exceptional\nexternal perturbations. Overall, we provide a diagnostics tool and an accurate\npredictor of the power grid frequency time series, allowing better\nunderstanding of the underlying dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:12:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kruse", "Johannes", ""], ["Sch\u00e4fer", "Benjamin", ""], ["Witthaut", "Dirk", ""]]}, {"id": "2004.09275", "submitter": "Zhila Esna Ashari", "authors": "Niloofar Hezarjaribi, Zhila Esna Ashari, James F. Frenzel, Hassan\n  Ghasemzadeh, and Saied Hemati", "title": "Personality Assessment from Text for Machine Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents PerSense, a framework to estimate human personality\ntraits based on expressed texts and to use them for commonsense reasoning\nanalysis. The personality assessment approaches include an aggregated\nProbability Density Functions (PDF), and Machine Learning (ML) models. Our goal\nis to demonstrate the feasibility of using machine learning algorithms on\npersonality trait data to predict humans' responses to open-ended commonsense\nquestions. We assess the performance of the PerSense algorithms for personality\nassessment by conducting an experiment focused on Neuroticism, an important\npersonality trait crucial in mental health analysis and suicide prevention by\ncollecting data from a diverse population with different Neuroticism scores.\nOur analysis shows that the algorithms achieve comparable results to the ground\ntruth data. Specifically, the PDF approach achieves 97% accuracy when the\nconfidence factor, the logarithmic ratio of the first to the second guess\nprobability, is greater than 3. Additionally, ML approach obtains its highest\naccuracy, 82.2%, with a multilayer Perceptron classifier. To assess the\nfeasibility of commonsense reasoning analysis, we train ML algorithms to\npredict responses to commonsense questions. Our analysis of data collected with\n300 participants demonstrate that PerSense predicts answers to commonsense\nquestions with 82.3% accuracy using a Random Forest classifier.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 07:30:47 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hezarjaribi", "Niloofar", ""], ["Ashari", "Zhila Esna", ""], ["Frenzel", "James F.", ""], ["Ghasemzadeh", "Hassan", ""], ["Hemati", "Saied", ""]]}, {"id": "2004.09281", "submitter": "James-A. Goulet", "authors": "James-A. Goulet, Luong Ha Nguyen and Saeid Amiri", "title": "Tractable Approximate Gaussian Inference for Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an analytical method allowing for tractable\napproximate Gaussian inference (TAGI) in Bayesian neural networks. The method\nenables: (1) the analytical inference of the posterior mean vector and diagonal\ncovariance matrix for weights and bias, (2) the end-to-end treatment of\nuncertainty from the input layer to the output, and (3) the online inference of\nmodel parameters using a single observation at a time. The method proposed has\na computational complexity of O(n) with respect to the number of parameters n,\nand the tests performed on regression and classification benchmarks confirm\nthat, for a same network architecture, it matches the performance of existing\nmethods relying on gradient backpropagation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:37:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Goulet", "James-A.", ""], ["Nguyen", "Luong Ha", ""], ["Amiri", "Saeid", ""]]}, {"id": "2004.09304", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Ryan Murray, Matthew Thorpe", "title": "From graph cuts to isoperimetric inequalities: Convergence rates of\n  Cheeger cuts on data clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.SP cs.CG cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study statistical properties of graph-based clustering\nalgorithms that rely on the optimization of balanced graph cuts, the main\nexample being the optimization of Cheeger cuts. We consider proximity graphs\nbuilt from data sampled from an underlying distribution supported on a generic\nsmooth compact manifold $M$. In this setting, we obtain high probability\nconvergence rates for both the Cheeger constant and the associated Cheeger cuts\ntowards their continuum counterparts. The key technical tools are careful\nestimates of interpolation operators which lift empirical Cheeger cuts to the\ncontinuum, as well as continuum stability estimates for isoperimetric problems.\nTo our knowledge the quantitative estimates obtained here are the first of\ntheir kind.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:58:52 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""], ["Thorpe", "Matthew", ""]]}, {"id": "2004.09320", "submitter": "Max Ehrlich", "authors": "Max Ehrlich, Larry Davis, Ser-Nam Lim, Abhinav Shrivastava", "title": "Quantization Guided JPEG Artifact Correction", "comments": "Published in the proceedings of ECCV 2020, please see our released\n  code and models at https://gitlab.com/Queuecumber/quantization-guided-ac", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The JPEG image compression algorithm is the most popular method of image\ncompression because of its ability for large compression ratios. However, to\nachieve such high compression, information is lost. For aggressive quantization\nsettings, this leads to a noticeable reduction in image quality. Artifact\ncorrection has been studied in the context of deep neural networks for some\ntime, but the current state-of-the-art methods require a different model to be\ntrained for each quality setting, greatly limiting their practical application.\nWe solve this problem by creating a novel architecture which is parameterized\nby the JPEG files quantization matrix. This allows our single model to achieve\nstate-of-the-art performance over models trained for specific quality settings.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 00:10:08 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:28:51 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Ehrlich", "Max", ""], ["Davis", "Larry", ""], ["Lim", "Ser-Nam", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2004.09335", "submitter": "Filip Tronarp", "authors": "Filip Tronarp and Simo S\\\"arkk\\\"a", "title": "Continuous-Discrete Filtering and Smoothing on Submanifolds of Euclidean\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the issue of filtering and smoothing in continuous discrete\ntime is studied when the state variable evolves in some submanifold of\nEuclidean space, which may not have the usual Lebesgue measure. Formal\nexpressions for prediction and smoothing problems are derived, which agree with\nthe classical results except that the formal adjoint of the generator is\ndifferent in general. For approximate filtering and smoothing the projection\napproach is taken, where it turns out that the prediction and smoothing\nequations are the same as in the case when the state variable evolves in\nEuclidean space. The approach is used to develop projection filters and\nsmoothers based on the von Mises-Fisher distribution.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:36:06 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Tronarp", "Filip", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2004.09347", "submitter": "Abhishek Niranjan", "authors": "Abhishek Niranjan, Mukesh Sharma, Sai Bharath Chandra Gutha, M Ali\n  Basha Shaik", "title": "End-to-End Whisper to Natural Speech Conversion using Modified\n  Transformer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine recognition of an atypical speech like whispered speech, is a\nchallenging task. We introduce whisper-to-natural-speech conversion using\nsequence-to-sequence approach by proposing enhanced transformer architecture,\nwhich uses both parallel and non-parallel data. We investigate different\nfeatures like Mel frequency cepstral coefficients and smoothed spectral\nfeatures. The proposed networks are trained end-to-end using supervised\napproach for feature-to-feature transformation. Further, we also investigate\nthe effectiveness of embedded auxillary decoder used after N encoder\nsub-layers, trained with the frame-level objective function for identifying\nsource phoneme labels. We show results on opensource wTIMIT and CHAINS datasets\nby measuring word error rate using end-to-end ASR and also BLEU scores for the\ngenerated speech. Alternatively, we also propose a novel method to measure\nspectral shape of it by measuring formant distributions w.r.t. reference\nspeech, as formant divergence metric. We have found whisper-to-natural\nconverted speech formants probability distribution is similar to the\ngroundtruth distribution. To the authors' best knowledge, this is the first\ntime enhanced transformer has been proposed, both with and without auxiliary\ndecoder for whisper-to-natural-speech conversion and vice versa.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:47:46 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:08:37 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 09:27:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Niranjan", "Abhishek", ""], ["Sharma", "Mukesh", ""], ["Gutha", "Sai Bharath Chandra", ""], ["Shaik", "M Ali Basha", ""]]}, {"id": "2004.09367", "submitter": "Jung-Woo Ha", "authors": "Jung-Woo Ha, Kihyun Nam, Jingu Kang, Sang-Woo Lee, Sohee Yang,\n  Hyunhoon Jung, Eunmi Kim, Hyeji Kim, Soojin Kim, Hyun Ah Kim, Kyoungtae Doh,\n  Chan Kyu Lee, Nako Sung, Sunghun Kim", "title": "ClovaCall: Korean Goal-Oriented Dialog Speech Corpus for Automatic\n  Speech Recognition of Contact Centers", "comments": "5 pages, 2 figures, 4 tables, The first two authors equally\n  contributed to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) via call is essential for various\napplications, including AI for contact center (AICC) services. Despite the\nadvancement of ASR, however, most publicly available call-based speech corpora\nsuch as Switchboard are old-fashioned. Also, most existing call corpora are in\nEnglish and mainly focus on open domain dialog or general scenarios such as\naudiobooks. Here we introduce a new large-scale Korean call-based speech corpus\nunder a goal-oriented dialog scenario from more than 11,000 people, i.e.,\nClovaCall corpus. ClovaCall includes approximately 60,000 pairs of a short\nsentence and its corresponding spoken utterance in a restaurant reservation\ndomain. We validate the effectiveness of our dataset with intensive experiments\nusing two standard ASR models. Furthermore, we release our ClovaCall dataset\nand baseline source codes to be available via\nhttps://github.com/ClovaAI/ClovaCall.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:12:29 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 06:53:34 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ha", "Jung-Woo", ""], ["Nam", "Kihyun", ""], ["Kang", "Jingu", ""], ["Lee", "Sang-Woo", ""], ["Yang", "Sohee", ""], ["Jung", "Hyunhoon", ""], ["Kim", "Eunmi", ""], ["Kim", "Hyeji", ""], ["Kim", "Soojin", ""], ["Kim", "Hyun Ah", ""], ["Doh", "Kyoungtae", ""], ["Lee", "Chan Kyu", ""], ["Sung", "Nako", ""], ["Kim", "Sunghun", ""]]}, {"id": "2004.09388", "submitter": "Yu-Feng Li", "authors": "Tong Wei, Feng Shi, Hai Wang, Wei-Wei Tu. Yu-Feng Li", "title": "MixPUL: Consistency-based Augmentation for Positive and Unlabeled\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from positive and unlabeled data (PU learning) is prevalent in\npractical applications where only a couple of examples are positively labeled.\nPrevious PU learning studies typically rely on existing samples such that the\ndata distribution is not extensively explored. In this work, we propose a\nsimple yet effective data augmentation method, coined~\\algo, based on\n\\emph{consistency regularization} which provides a new perspective of using PU\ndata. In particular, the proposed~\\algo~incorporates supervised and\nunsupervised consistency training to generate augmented data. To facilitate\nsupervised consistency, reliable negative examples are mined from unlabeled\ndata due to the absence of negative samples. Unsupervised consistency is\nfurther encouraged between unlabeled datapoints. In addition,~\\algo~reduces\nmargin loss between positive and unlabeled pairs, which explicitly optimizes\nAUC and yields faster convergence. Finally, we conduct a series of studies to\ndemonstrate the effectiveness of consistency regularization. We examined three\nkinds of reliable negative mining methods. We show that~\\algo~achieves an\naveraged improvement of classification error from 16.49 to 13.09 on the\nCIFAR-10 dataset across different positive data amount.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:43:33 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wei", "Tong", ""], ["Shi", "Feng", ""], ["Wang", "Hai", ""], ["Li", "Wei-Wei Tu. Yu-Feng", ""]]}, {"id": "2004.09395", "submitter": "Minghuan Liu", "authors": "Minghuan Liu, Tairan He, Minkai Xu, Weinan Zhang", "title": "Energy-Based Imitation Learning", "comments": "Correct minor errors. 15 pages (6 pages of supplementary), 8 figures,\n  Accepted by AAMAS-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle a common scenario in imitation learning (IL), where agents try to\nrecover the optimal policy from expert demonstrations without further access to\nthe expert or environment reward signals. Except the simple Behavior Cloning\n(BC) that adopts supervised learning followed by the problem of compounding\nerror, previous solutions like inverse reinforcement learning (IRL) and recent\ngenerative adversarial methods involve a bi-level or alternating optimization\nfor updating the reward function and the policy, suffering from high\ncomputational cost and training instability. Inspired by recent progress in\nenergy-based model (EBM), in this paper, we propose a simplified IL framework\nnamed Energy-Based Imitation Learning (EBIL). Instead of updating the reward\nand policy iteratively, EBIL breaks out of the traditional IRL paradigm by a\nsimple and flexible two-stage solution: first estimating the expert energy as\nthe surrogate reward function through score matching, then utilizing such a\nreward for learning the policy by reinforcement learning algorithms. EBIL\ncombines the idea of both EBM and occupancy measure matching, and via theoretic\nanalysis we reveal that EBIL and Max-Entropy IRL (MaxEnt IRL) approaches are\ntwo sides of the same coin, and thus EBIL could be an alternative of\nadversarial IRL methods. Extensive experiments on qualitative and quantitative\nevaluations indicate that EBIL is able to recover meaningful and interpretative\nreward signals while achieving effective and comparable performance against\nexisting algorithms on IL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:49:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 16:39:21 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 13:14:13 GMT"}, {"version": "v4", "created": "Thu, 15 Apr 2021 04:30:35 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Liu", "Minghuan", ""], ["He", "Tairan", ""], ["Xu", "Minkai", ""], ["Zhang", "Weinan", ""]]}, {"id": "2004.09397", "submitter": "Ricardo Cerri", "authors": "Ricardo Cerri, Joel David Costa J\\'unior, Elaine Ribeiro de Faria\n  Paiva and Jo\\~ao Manuel Portela da Gama", "title": "Multi-label Stream Classification with Self-Organizing Maps", "comments": "7 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several learning algorithms have been proposed for offline multi-label\nclassification. However, applications in areas such as traffic monitoring,\nsocial networks, and sensors produce data continuously, the so called data\nstreams, posing challenges to batch multi-label learning. With the lack of\nstationarity in the distribution of data streams, new algorithms are needed to\nonline adapt to such changes (concept drift). Also, in realistic applications,\nchanges occur in scenarios of infinitely delayed labels, where the true classes\nof the arrival instances are never available. We propose an online unsupervised\nincremental method based on self-organizing maps for multi-label stream\nclassification with infinitely delayed labels. In the classification phase, we\nuse a k-nearest neighbors strategy to compute the winning neurons in the maps,\nadapting to concept drift by online adjusting neuron weight vectors and dataset\nlabel cardinality. We predict labels for each instance using the Bayes rule and\nthe outputs of each neuron, adapting the probabilities and conditional\nprobabilities of the classes in the stream. Experiments using synthetic and\nreal datasets show that our method is highly competitive with several ones from\nthe literature, in both stationary and concept drift scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:52:38 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cerri", "Ricardo", ""], ["J\u00fanior", "Joel David Costa", ""], ["Paiva", "Elaine Ribeiro de Faria", ""], ["da Gama", "Jo\u00e3o Manuel Portela", ""]]}, {"id": "2004.09406", "submitter": "Christina Funke", "authors": "Christina M. Funke, Judy Borowski, Karolina Stosio, Wieland Brendel,\n  Thomas S. A. Wallis, Matthias Bethge", "title": "Five Points to Check when Comparing Visual Perception in Humans and\n  Machines", "comments": "V3: minor changes like in published JOV version\n  (https://doi.org/10.1167/jov.21.3.16) V2: New title; added general section\n  (checklist); manuscript restructured such that each case study is one\n  chapter; adversarial examples in first study replaced by different analysis", "journal-ref": "Journal of Vision 21, no. 3 (2021): 16-16", "doi": "10.1167/jov.21.3.16", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of machines to human-level performance in complex recognition\ntasks, a growing amount of work is directed towards comparing information\nprocessing in humans and machines. These studies are an exciting chance to\nlearn about one system by studying the other. Here, we propose ideas on how to\ndesign, conduct and interpret experiments such that they adequately support the\ninvestigation of mechanisms when comparing human and machine perception. We\ndemonstrate and apply these ideas through three case studies. The first case\nstudy shows how human bias can affect how we interpret results, and that\nseveral analytic tools can help to overcome this human reference point. In the\nsecond case study, we highlight the difference between necessary and sufficient\nmechanisms in visual reasoning tasks. Thereby, we show that contrary to\nprevious suggestions, feedback mechanisms might not be necessary for the tasks\nin question. The third case study highlights the importance of aligning\nexperimental conditions. We find that a previously-observed difference in\nobject recognition does not hold when adapting the experiment to make\nconditions more equitable between humans and machines. In presenting a\nchecklist for comparative studies of visual reasoning in humans and machines,\nwe hope to highlight how to overcome potential pitfalls in design or inference.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:05:36 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 08:37:22 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 16:03:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Funke", "Christina M.", ""], ["Borowski", "Judy", ""], ["Stosio", "Karolina", ""], ["Brendel", "Wieland", ""], ["Wallis", "Thomas S. A.", ""], ["Bethge", "Matthias", ""]]}, {"id": "2004.09416", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Nicolas Skatchkovsky and Osvaldo Simeone", "title": "VOWEL: A Local Online Learning Rule for Recurrent Networks of\n  Probabilistic Spiking Winner-Take-All Circuits", "comments": "14 pages, submitted for possible conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of spiking neurons and Winner-Take-All spiking circuits (WTA-SNNs)\ncan detect information encoded in spatio-temporal multi-valued events. These\nare described by the timing of events of interest, e.g., clicks, as well as by\ncategorical numerical values assigned to each event, e.g., like or dislike.\nOther use cases include object recognition from data collected by neuromorphic\ncameras, which produce, for each pixel, signed bits at the times of\nsufficiently large brightness variations. Existing schemes for training\nWTA-SNNs are limited to rate-encoding solutions, and are hence able to detect\nonly spatial patterns. Developing more general training algorithms for\narbitrary WTA-SNNs inherits the challenges of training (binary) Spiking Neural\nNetworks (SNNs). These amount, most notably, to the non-differentiability of\nthreshold functions, to the recurrent behavior of spiking neural models, and to\nthe difficulty of implementing backpropagation in neuromorphic hardware. In\nthis paper, we develop a variational online local training rule for WTA-SNNs,\nreferred to as VOWEL, that leverages only local pre- and post-synaptic\ninformation for visible circuits, and an additional common reward signal for\nhidden circuits. The method is based on probabilistic generalized linear neural\nmodels, control variates, and variational regularization. Experimental results\non real-world neuromorphic datasets with multi-valued events demonstrate the\nadvantages of WTA-SNNs over conventional binary SNNs trained with\nstate-of-the-art methods, especially in the presence of limited computing\nresources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:21:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jang", "Hyeryung", ""], ["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2004.09434", "submitter": "Barbara Pascal", "authors": "Barbara Pascal and Samuel Vaiter and Nelly Pustelnik and Patrice Abry", "title": "Automated data-driven selection of the hyperparameters for\n  Total-Variation based texture segmentation", "comments": "Submitted to SIAM Imaging Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized Least Squares are widely used in signal and image processing. Yet,\nit suffers from a major limitation since it requires fine-tuning of the\nregularization parameters. Under assumptions on the noise probability\ndistribution, Stein-based approaches provide unbiased estimator of the\nquadratic risk. The Generalized Stein Unbiased Risk Estimator is revisited to\nhandle correlated Gaussian noise without requiring to invert the covariance\nmatrix. Then, in order to avoid expansive grid search, it is necessary to\ndesign algorithmic scheme minimizing the quadratic risk with respect to\nregularization parameters. This work extends the Stein's Unbiased GrAdient\nestimator of the Risk of Deledalle et al. to the case of correlated Gaussian\nnoise, deriving a general automatic tuning of regularization parameters. First,\nthe theoretical asymptotic unbiasedness of the gradient estimator is\ndemonstrated in the case of general correlated Gaussian noise. Then, the\nproposed parameter selection strategy is particularized to fractal texture\nsegmentation, where problem formulation naturally entails inter-scale and\nspatially correlated noise. Numerical assessment is provided, as well as\ndiscussion of the practical issues.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:43:09 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 16:43:41 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Pascal", "Barbara", ""], ["Vaiter", "Samuel", ""], ["Pustelnik", "Nelly", ""], ["Abry", "Patrice", ""]]}, {"id": "2004.09466", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto", "title": "Causality-aware counterfactual confounding adjustment for feature\n  representations learned by deep models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal modeling has been recognized as a potential solution to many\nchallenging problems in machine learning (ML). Here, we describe how a recently\nproposed counterfactual approach developed to deconfound linear structural\ncausal models can still be used to deconfound the feature representations\nlearned by deep neural network (DNN) models. The key insight is that by\ntraining an accurate DNN using softmax activation at the classification layer,\nand then adopting the representation learned by the last layer prior to the\noutput layer as our features, we have that, by construction, the learned\nfeatures will fit well a (multi-class) logistic regression model, and will be\nlinearly associated with the labels. As a consequence, deconfounding approaches\nbased on simple linear models can be used to deconfound the feature\nrepresentations learned by DNNs. We validate the proposed methodology using\ncolored versions of the MNIST dataset. Our results illustrate how the approach\ncan effectively combat confounding and improve model stability in the context\nof dataset shifts generated by selection biases.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:37:36 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 02:07:04 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 17:31:26 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 03:25:16 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Neto", "Elias Chaibub", ""]]}, {"id": "2004.09468", "submitter": "Wojciech Czarnecki", "authors": "Wojciech Marian Czarnecki, Gauthier Gidel, Brendan Tracey, Karl Tuyls,\n  Shayegan Omidshafiei, David Balduzzi, Max Jaderberg", "title": "Real World Games Look Like Spinning Tops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the geometrical properties of real world games (e.g.\nTic-Tac-Toe, Go, StarCraft II). We hypothesise that their geometrical structure\nresemble a spinning top, with the upright axis representing transitive\nstrength, and the radial axis, which corresponds to the number of cycles that\nexist at a particular transitive strength, representing the non-transitive\ndimension. We prove the existence of this geometry for a wide class of real\nworld games, exposing their temporal nature. Additionally, we show that this\nunique structure also has consequences for learning - it clarifies why\npopulations of strategies are necessary for training of agents, and how\npopulation size relates to the structure of the game. Finally, we empirically\nvalidate these claims by using a selection of nine real world two-player\nzero-sum symmetric games, showing 1) the spinning top structure is revealed and\ncan be easily re-constructed by using a new method of Nash clustering to\nmeasure the interaction between transitive and cyclical strategy behaviour, and\n2) the effect that population size has on the convergence in these games.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:41:42 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:41:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["Gidel", "Gauthier", ""], ["Tracey", "Brendan", ""], ["Tuyls", "Karl", ""], ["Omidshafiei", "Shayegan", ""], ["Balduzzi", "David", ""], ["Jaderberg", "Max", ""]]}, {"id": "2004.09473", "submitter": "Haiguang Liao", "authors": "Haiguang Liao, Qingyi Dong, Xuliang Dong, Wentai Zhang, Wangyang\n  Zhang, Weiyi Qi, Elias Fallon, Levent Burak Kara", "title": "Attention Routing: track-assignment detailed routing using\n  attention-based reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the physical design of integrated circuits, global and detailed routing\nare critical stages involving the determination of the interconnected paths of\neach net on a circuit while satisfying the design constraints. Existing actual\nrouters as well as routability predictors either have to resort to expensive\napproaches that lead to high computational times, or use heuristics that do not\ngeneralize well. Even though new, learning-based routing methods have been\nproposed to address this need, requirements on labelled data and difficulties\nin addressing complex design rule constraints have limited their adoption in\nadvanced technology node physical design problems. In this work, we propose a\nnew router: attention router, which is the first attempt to solve the\ntrack-assignment detailed routing problem using reinforcement learning. Complex\ndesign rule constraints are encoded into the routing algorithm and an\nattention-model-based REINFORCE algorithm is applied to solve the most critical\nstep in routing: sequencing device pairs to be routed. The attention router and\nits baseline genetic router are applied to solve different commercial advanced\ntechnologies analog circuits problem sets. The attention router demonstrates\ngeneralization ability to unseen problems and is also able to achieve more than\n100 times acceleration over the genetic router without significantly\ncompromising the routing solution quality. We also discover a similarity\nbetween the attention router and the baseline genetic router in terms of\npositive correlations in cost and routing patterns, which demonstrate the\nattention router's ability to be utilized not only as a detailed router but\nalso as a predictor for routability and congestion.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:50:13 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:44:33 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Liao", "Haiguang", ""], ["Dong", "Qingyi", ""], ["Dong", "Xuliang", ""], ["Zhang", "Wentai", ""], ["Zhang", "Wangyang", ""], ["Qi", "Weiyi", ""], ["Fallon", "Elias", ""], ["Kara", "Levent Burak", ""]]}, {"id": "2004.09506", "submitter": "Maciej Skorski", "authors": "Maciej Skorski, Alessandro Temperoni, Martin Theobald", "title": "Revisiting Initialization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proper initialization of weights is crucial for the effective training\nand fast convergence of deep neural networks (DNNs). Prior work in this area\nhas mostly focused on balancing the variance among weights per layer to\nmaintain stability of (i) the input data propagated forwards through the\nnetwork and (ii) the loss gradients propagated backwards, respectively. This\nprevalent heuristic is however agnostic of dependencies among gradients across\nthe various layers and captures only firstorder effects. In this paper, we\npropose and discuss an initialization principle that is based on a rigorous\nestimation of the global curvature of weights across layers by approximating\nand controlling the norm of their Hessian matrix. The proposed approach is more\nsystematic and recovers previous results for DNN activations such as smooth\nfunctions, dropouts, and ReLU. Our experiments on Word2Vec and the MNIST/CIFAR\nimage classification tasks confirm that tracking the Hessian norm is a useful\ndiagnostic tool which helps to more rigorously initialize weights\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:12:56 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:55:16 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 17:51:07 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Skorski", "Maciej", ""], ["Temperoni", "Alessandro", ""], ["Theobald", "Martin", ""]]}, {"id": "2004.09508", "submitter": "Reza Pourreza", "authors": "Vijay Veerabadran, Reza Pourreza, Amirhossein Habibian, Taco Cohen", "title": "Adversarial Distortion for Learned Video Compression", "comments": "CVPR Workshops, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel adversarial lossy video compression model.\nAt extremely low bit-rates, standard video coding schemes suffer from\nunpleasant reconstruction artifacts such as blocking, ringing etc. Existing\nlearned neural approaches to video compression have achieved reasonable success\non reducing the bit-rate for efficient transmission and reduce the impact of\nartifacts to an extent. However, they still tend to produce blurred results\nunder extreme compression. In this paper, we present a deep adversarial learned\nvideo compression model that minimizes an auxiliary adversarial distortion\nobjective. We find this adversarial objective to correlate better with human\nperceptual quality judgement relative to traditional quality metrics such as\nMS-SSIM and PSNR. Our experiments using a state-of-the-art learned video\ncompression system demonstrate a reduction of perceptual artifacts and\nreconstruction of detail lost especially under extremely high compression.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:06:31 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 01:57:34 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 18:42:25 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Veerabadran", "Vijay", ""], ["Pourreza", "Reza", ""], ["Habibian", "Amirhossein", ""], ["Cohen", "Taco", ""]]}, {"id": "2004.09546", "submitter": "Ali Javed", "authors": "Ali Javed, Byung Suk Lee, Dona M. Rizzo", "title": "A Benchmark Study on Time Series Clustering", "comments": "Typos corrected, figures resolution changed", "journal-ref": "Machine Learning with Applications, 1:100001, 2020", "doi": "10.1016/j.mlwa.2020.100001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first time series clustering benchmark utilizing all\ntime series datasets currently available in the University of California\nRiverside (UCR) archive -- the state of the art repository of time series data.\nSpecifically, the benchmark examines eight popular clustering methods\nrepresenting three categories of clustering algorithms (partitional,\nhierarchical and density-based) and three types of distance measures\n(Euclidean, dynamic time warping, and shape-based). We lay out six restrictions\nwith special attention to making the benchmark as unbiased as possible. A\nphased evaluation approach was then designed for summarizing dataset-level\nassessment metrics and discussing the results. The benchmark study presented\ncan be a useful reference for the research community on its own; and the\ndataset-level assessment metrics reported may be used for designing evaluation\nframeworks to answer different research questions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:06:42 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 16:15:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Javed", "Ali", ""], ["Lee", "Byung Suk", ""], ["Rizzo", "Dona M.", ""]]}, {"id": "2004.09557", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "SoCal: Selective Oracle Questioning for Consistency-based Active\n  Learning of Cardiac Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ubiquity and rate of collection of cardiac signals produce large,\nunlabelled datasets. Active learning (AL) can exploit such datasets by\nincorporating human annotators (oracles) to improve generalization performance.\nHowever, the over-reliance of existing algorithms on oracles continues to\nburden physicians. To minimize this burden, we propose SoCal, a\nconsistency-based AL framework that dynamically determines whether to request a\nlabel from an oracle or to generate a pseudo-label instead. We show that our\nframework decreases the labelling burden while maintaining strong performance,\neven in the presence of a noisy oracle.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:20:03 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 18:49:00 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2004.09563", "submitter": "Yingyu Liang", "authors": "Hui Yuan, Yingyu Liang", "title": "Learning Entangled Single-Sample Distributions via Iterative Trimming", "comments": "Updated on AISTAT 2020 camera-ready: added comments on existing work\n  at the end of Section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of entangled single-sample distributions, the goal is to\nestimate some common parameter shared by a family of distributions, given one\n\\emph{single} sample from each distribution. We study mean estimation and\nlinear regression under general conditions, and analyze a simple and\ncomputationally efficient method based on iteratively trimming samples and\nre-estimating the parameter on the trimmed sample set. We show that the method\nin logarithmic iterations outputs an estimation whose error only depends on the\nnoise level of the $\\lceil \\alpha n \\rceil$-th noisiest data point where\n$\\alpha$ is a constant and $n$ is the sample size. This means it can tolerate a\nconstant fraction of high-noise points. These are the first such results for\nthe method under our general conditions. It also justifies the wide application\nand empirical success of iterative trimming in practice. Our theoretical\nresults are complemented by experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:37:43 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 16:04:55 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yuan", "Hui", ""], ["Liang", "Yingyu", ""]]}, {"id": "2004.09569", "submitter": "Moritz Wolter", "authors": "Moritz Wolter (Bonn University, Fraunhofer Center for Machine Learning\n  and SCAI) and Shaohui Lin (National University of Singapore) and Angela Yao\n  (National University of Singapore)", "title": "Neural network compression via learnable wavelet transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wavelets are well known for data compression, yet have rarely been applied to\nthe compression of neural networks. This paper shows how the fast wavelet\ntransform can be used to compress linear layers in neural networks. Linear\nlayers still occupy a significant portion of the parameters in recurrent neural\nnetworks (RNNs). Through our method, we can learn both the wavelet bases and\ncorresponding coefficients to efficiently represent the linear layers of RNNs.\nOur wavelet compressed RNNs have significantly fewer parameters yet still\nperform competitively with the state-of-the-art on synthetic and real-world RNN\nbenchmarks. Wavelet optimization adds basis flexibility, without large numbers\nof extra weights. Source code is available at\nhttps://github.com/v0lta/Wavelet-network-compression.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:52:05 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 14:49:49 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 11:59:07 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Wolter", "Moritz", "", "Bonn University, Fraunhofer Center for Machine Learning\n  and SCAI"], ["Lin", "Shaohui", "", "National University of Singapore"], ["Yao", "Angela", "", "National University of Singapore"]]}, {"id": "2004.09571", "submitter": "Arindrima Datta", "authors": "Arindrima Datta, Bhuvana Ramabhadran, Jesse Emond, Anjuli Kannan,\n  Brian Roark", "title": "Language-agnostic Multilingual Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Automated Speech Recognition (ASR) systems allow for the joint\ntraining of data-rich and data-scarce languages in a single model. This enables\ndata and parameter sharing across languages, which is especially beneficial for\nthe data-scarce languages. However, most state-of-the-art multilingual models\nrequire the encoding of language information and therefore are not as flexible\nor scalable when expanding to newer languages. Language-independent\nmultilingual models help to address this issue, and are also better suited for\nmulticultural societies where several languages are frequently used together\n(but often rendered with different writing systems). In this paper, we propose\na new approach to building a language-agnostic multilingual ASR system which\ntransforms all languages to one writing system through a many-to-one\ntransliteration transducer. Thus, similar sounding acoustics are mapped to a\nsingle, canonical target sequence of graphemes, effectively separating the\nmodeling and rendering problems. We show with four Indic languages, namely,\nHindi, Bengali, Tamil and Kannada, that the language-agnostic multilingual\nmodel achieves up to 10% relative reduction in Word Error Rate (WER) over a\nlanguage-dependent multilingual model.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:57:43 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Datta", "Arindrima", ""], ["Ramabhadran", "Bhuvana", ""], ["Emond", "Jesse", ""], ["Kannan", "Anjuli", ""], ["Roark", "Brian", ""]]}, {"id": "2004.09576", "submitter": "Yash Bhalgat", "authors": "Yash Bhalgat, Jinwon Lee, Markus Nagel, Tijmen Blankevoort, Nojun Kwak", "title": "LSQ+: Improving low-bit quantization through learnable offsets and\n  better initialization", "comments": "Camera-ready for Joint Workshop on Efficient Deep Learning in\n  Computer Vision, CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unlike ReLU, newer activation functions (like Swish, H-swish, Mish) that are\nfrequently employed in popular efficient architectures can also result in\nnegative activation values, with skewed positive and negative ranges. Typical\nlearnable quantization schemes [PACT, LSQ] assume unsigned quantization for\nactivations and quantize all negative activations to zero which leads to\nsignificant loss in performance. Naively using signed quantization to\naccommodate these negative values requires an extra sign bit which is expensive\nfor low-bit (2-, 3-, 4-bit) quantization. To solve this problem, we propose\nLSQ+, a natural extension of LSQ, wherein we introduce a general asymmetric\nquantization scheme with trainable scale and offset parameters that can learn\nto accommodate the negative activations. Gradient-based learnable quantization\nschemes also commonly suffer from high instability or variance in the final\ntraining performance, hence requiring a great deal of hyper-parameter tuning to\nreach a satisfactory performance. LSQ+ alleviates this problem by using an\nMSE-based initialization scheme for the quantization parameters. We show that\nthis initialization leads to significantly lower variance in final performance\nacross multiple training runs. Overall, LSQ+ shows state-of-the-art results for\nEfficientNet and MixNet and also significantly outperforms LSQ for low-bit\nquantization of neural nets with Swish activations (e.g.: 1.8% gain with W4A4\nquantization and upto 5.6% gain with W2A2 quantization of EfficientNet-B0 on\nImageNet dataset). To the best of our knowledge, ours is the first work to\nquantize such architectures to extremely low bit-widths.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:04:51 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Bhalgat", "Yash", ""], ["Lee", "Jinwon", ""], ["Nagel", "Markus", ""], ["Blankevoort", "Tijmen", ""], ["Kwak", "Nojun", ""]]}, {"id": "2004.09578", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "CLOPS: Continual Learning of Physiological Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms are known to experience destructive interference\nwhen instances violate the assumption of being independent and identically\ndistributed (i.i.d). This violation, however, is ubiquitous in clinical\nsettings where data are streamed temporally and from a multitude of\nphysiological sensors. To overcome this obstacle, we propose CLOPS, a\nreplay-based continual learning strategy. In three continual learning scenarios\nbased on three publically-available datasets, we show that CLOPS can outperform\nthe state-of-the-art methods, GEM and MIR. Moreover, we propose end-to-end\ntrainable parameters, which we term task-instance parameters, that can be used\nto quantify task difficulty and similarity. This quantification yields insights\ninto both network interpretability and clinical applications, where task\ndifficulty is poorly quantified.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:09:18 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 17:05:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2004.09579", "submitter": "Qingchun Hou", "authors": "Qingchun Hou, Ning Zhang, Daniel S. Kirschen, Ershun Du, Yaohua Cheng,\n  Chongqing Kang", "title": "Sparse Oblique Decision Tree for Power System Security Rules Extraction\n  and Embedding", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the penetration of variable generation has a substantial effect on\nthe operational reliability of power systems. The higher level of uncertainty\nthat stems from this variability makes it more difficult to determine whether a\ngiven operating condition will be secure or insecure. Data-driven techniques\nprovide a promising way to identify security rules that can be embedded in\neconomic dispatch model to keep power system operating states secure. This\npaper proposes using a sparse weighted oblique decision tree to learn accurate,\nunderstandable, and embeddable security rules that are linear and can be\nextracted as sparse matrices using a recursive algorithm. These matrices can\nthen be easily embedded as security constraints in power system economic\ndispatch calculations using the Big-M method. Tests on several large datasets\nwith high renewable energy penetration demonstrate the effectiveness of the\nproposed method. In particular, the sparse weighted oblique decision tree\noutperforms the state-of-art weighted oblique decision tree while keeping the\nsecurity rules simple. When embedded in the economic dispatch, these rules\nsignificantly increase the percentage of secure states and reduce the average\nsolution time.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:11:41 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hou", "Qingchun", ""], ["Zhang", "Ning", ""], ["Kirschen", "Daniel S.", ""], ["Du", "Ershun", ""], ["Cheng", "Yaohua", ""], ["Kang", "Chongqing", ""]]}, {"id": "2004.09588", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep Mukhopadhyay, Kaijun Wang", "title": "On The Problem of Relevance in Statistical Inference", "comments": "Revised (much-improved) version. The procedure (including all the\n  datasets) is implemented in the R-package LPRelevance", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is dedicated to the \"50 Years of the Relevance Problem\" - a\nlong-neglected topic that begs attention from practical statisticians who are\nconcerned with the problem of drawing inference from large-scale heterogeneous\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:31:00 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 00:32:32 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 18:24:47 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Mukhopadhyay", "Subhadeep", ""], ["Wang", "Kaijun", ""]]}, {"id": "2004.09589", "submitter": "Timothy Chu", "authors": "Timothy Chu and Gary L. Miller and Noel J. Walkington and Alex L. Wang", "title": "Weighted Cheeger and Buser Inequalities, with Applications to Clustering\n  and Cutting Probability Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how sparse or isoperimetric cuts of a probability\ndensity function relate to Cheeger cuts of its principal eigenfunction, for\nappropriate definitions of `sparse cut' and `principal eigenfunction'.\n  We construct these appropriate definitions of sparse cut and principal\neigenfunction in the probability density setting. Then, we prove Cheeger and\nBuser type inequalities similar to those for the normalized graph Laplacian of\nAlon-Milman. We demonstrate that no such inequalities hold for most prior\ndefinitions of sparse cut and principal eigenfunction. We apply this result to\ngenerate novel algorithms for cutting probability densities and clustering\ndata, including a principled variant of spectral clustering.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:31:25 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 17:21:30 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 15:40:42 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Chu", "Timothy", ""], ["Miller", "Gary L.", ""], ["Walkington", "Noel J.", ""], ["Wang", "Alex L.", ""]]}, {"id": "2004.09602", "submitter": "Patrick Judd", "authors": "Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev, Paulius\n  Micikevicius", "title": "Integer Quantization for Deep Learning Inference: Principles and\n  Empirical Evaluation", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization techniques can reduce the size of Deep Neural Networks and\nimprove inference latency and throughput by taking advantage of high throughput\ninteger instructions. In this paper we review the mathematical aspects of\nquantization parameters and evaluate their choices on a wide range of neural\nnetwork models for different application domains, including vision, speech, and\nlanguage. We focus on quantization techniques that are amenable to acceleration\nby processors with high-throughput integer math pipelines. We also present a\nworkflow for 8-bit quantization that is able to maintain accuracy within 1% of\nthe floating-point baseline on all networks studied, including models that are\nmore difficult to quantize, such as MobileNets and BERT-large.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:59:22 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Wu", "Hao", ""], ["Judd", "Patrick", ""], ["Zhang", "Xiaojie", ""], ["Isaev", "Mikhail", ""], ["Micikevicius", "Paulius", ""]]}, {"id": "2004.09608", "submitter": "Kimon Fountoulakis", "authors": "K. Fountoulakis, M. Liu, D. F. Gleich, and M. W. Mahoney", "title": "Flow-based Algorithms for Improving Clusters: A Unifying Framework,\n  Software, and Performance", "comments": "71 Pages, 21 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering points in a vector space or nodes in a graph is a ubiquitous\nprimitive in statistical data analysis, and it is commonly used for exploratory\ndata analysis. In practice, it is often of interest to \"refine\" or \"improve\" a\ngiven cluster that has been obtained by some other method. In this survey, we\nfocus on principled algorithms for this cluster improvement problem. Many such\ncluster improvement algorithms are flow-based methods, by which we mean that\noperationally they require the solution of a sequence of maximum flow problems\non a (typically implicitly) modified data graph. These cluster improvement\nalgorithms are powerful, both in theory and in practice, but they have not been\nwidely adopted for problems such as community detection, local graph\nclustering, semi-supervised learning, etc. Possible reasons for this are: the\nsteep learning curve for these algorithms; the lack of efficient and easy to\nuse software; and the lack of detailed numerical experiments on real-world data\nthat demonstrate their usefulness. Our objective here is to address these\nissues. To do so, we guide the reader through the whole process of\nunderstanding how to implement and apply these powerful algorithms. We present\na unifying fractional programming optimization framework that permits us to\ndistill out in a simple way the crucial components of all these algorithms. It\nalso makes apparent similarities and differences between related methods.\nViewing these cluster improvement algorithms via a fractional programming\nframework suggests directions for future algorithm development. Finally, we\ndevelop efficient implementations of these algorithms in our\nLocalGraphClustering python package, and we perform extensive numerical\nexperiments to demonstrate the performance of these methods on social networks\nand image-based data graphs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:14:00 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 05:23:40 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Fountoulakis", "K.", ""], ["Liu", "M.", ""], ["Gleich", "D. F.", ""], ["Mahoney", "M. W.", ""]]}, {"id": "2004.09612", "submitter": "Ricardo Bessa Dr.", "authors": "Carla Gon\\c{c}alves and Ricardo J. Bessa and Pierre Pinson", "title": "A Critical Overview of Privacy-Preserving Approaches for Collaborative\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation between different data owners may lead to an improvement in\nforecast quality - for instance by benefiting from spatial-temporal\ndependencies in geographically distributed time series. Due to business\ncompetitive factors and personal data protection questions, said data owners\nmight be unwilling to share their data, which increases the interest in\ncollaborative privacy-preserving forecasting. This paper analyses the\nstate-of-the-art and unveils several shortcomings of existing methods in\nguaranteeing data privacy when employing Vector Autoregressive (VAR) models.\nThe paper also provides mathematical proofs and numerical analysis to evaluate\nexisting privacy-preserving methods, dividing them into three groups: data\ntransformation, secure multi-party computations, and decomposition methods. The\nanalysis shows that state-of-the-art techniques have limitations in preserving\ndata privacy, such as a trade-off between privacy and forecasting accuracy,\nwhile the original data in iterative model fitting processes, in which\nintermediate results are shared, can be inferred after some iterations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:21:04 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 21:08:19 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 09:54:50 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 08:56:09 GMT"}, {"version": "v5", "created": "Fri, 22 May 2020 10:09:04 GMT"}, {"version": "v6", "created": "Sat, 10 Oct 2020 12:37:17 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Gon\u00e7alves", "Carla", ""], ["Bessa", "Ricardo J.", ""], ["Pinson", "Pierre", ""]]}, {"id": "2004.09628", "submitter": "James Ferlez", "authors": "James Ferlez and Xiaowu Sun and Yasser Shoukry", "title": "Two-Level Lattice Neural Network Architectures for Control of Nonlinear\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of automatically designing a Rectified\nLinear Unit (ReLU) Neural Network (NN) architecture (number of layers and\nnumber of neurons per layer) with the guarantee that it is sufficiently\nparametrized to control a nonlinear system. Whereas current state-of-the-art\ntechniques are based on hand-picked architectures or heuristic based search to\nfind such NN architectures, our approach exploits the given model of the system\nto design an architecture; as a result, we provide a guarantee that the\nresulting NN architecture is sufficient to implement a controller that\nsatisfies an achievable specification. Our approach exploits two basic ideas.\nFirst, assuming that the system can be controlled by an unknown\nLipschitz-continuous state-feedback controller with some Lipschitz constant\nupper-bounded by $K_\\text{cont}$, we bound the number of affine functions\nneeded to construct a Continuous Piecewise Affine (CPWA) function that can\napproximate the unknown Lipschitz-continuous controller. Second, we utilize the\nauthors' recent results on a novel NN architecture named as the Two-Level\nLattice (TLL) NN architecture, which was shown to be capable of implementing\nany CPWA function just from the knowledge of the number of affine functions\nthat compromises this CPWA function.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:45:08 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 18:24:51 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Ferlez", "James", ""], ["Sun", "Xiaowu", ""], ["Shoukry", "Yasser", ""]]}, {"id": "2004.09646", "submitter": "Qing Zhou", "authors": "Bingling Wang and Qing Zhou", "title": "Causal network learning with non-invertible functional relationships", "comments": null, "journal-ref": "Computational Statistics and Data Analysis, 156: 107141 (2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of causal relationships from observational data is an important\nproblem in many areas. Several recent results have established the\nidentifiability of causal DAGs with non-Gaussian and/or nonlinear structural\nequation models (SEMs). In this paper, we focus on nonlinear SEMs defined by\nnon-invertible functions, which exist in many data domains, and propose a novel\ntest for non-invertible bivariate causal models. We further develop a method to\nincorporate this test in structure learning of DAGs that contain both linear\nand nonlinear causal relations. By extensive numerical comparisons, we show\nthat our algorithms outperform existing DAG learning methods in identifying\ncausal graphical structures. We illustrate the practical application of our\nmethod in learning causal networks for combinatorial binding of transcription\nfactors from ChIP-Seq data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 21:32:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wang", "Bingling", ""], ["Zhou", "Qing", ""]]}, {"id": "2004.09656", "submitter": "Mohammad Sadegh Talebi", "authors": "Hippolyte Bourel and Odalric-Ambrym Maillard and Mohammad Sadegh\n  Talebi", "title": "Tightening Exploration in Upper Confidence Reinforcement Learning", "comments": "Appeared in Proceedings of the 27th International Conference on\n  Machine Learning (ICML 2020). This is an improved post-proceeding version\n  correcting minor errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upper confidence reinforcement learning (UCRL2) algorithm introduced in\n(Jaksch et al., 2010) is a popular method to perform regret minimization in\nunknown discrete Markov Decision Processes under the average-reward criterion.\nDespite its nice and generic theoretical regret guarantees, this algorithm and\nits variants have remained until now mostly theoretical as numerical\nexperiments in simple environments exhibit long burn-in phases before the\nlearning takes place. In pursuit of practical efficiency, we present UCRL3,\nfollowing the lines of UCRL2, but with two key modifications: First, it uses\nstate-of-the-art time-uniform concentration inequalities to compute confidence\nsets on the reward and (component-wise) transition distributions for each\nstate-action pair. Furthermore, to tighten exploration, it uses an adaptive\ncomputation of the support of each transition distribution, which in turn\nenables us to revisit the extended value iteration procedure of UCRL2 to\noptimize over distributions with reduced support by disregarding low\nprobability transitions, while still ensuring near-optimism. We demonstrate,\nthrough numerical experiments in standard environments, that reducing\nexploration this way yields a substantial numerical improvement compared to\nUCRL2 and its variants. On the theoretical side, these key modifications enable\nus to derive a regret bound for UCRL3 improving on UCRL2, that for the first\ntime makes appear notions of local diameter and local effective support, thanks\nto variance-aware concentration bounds.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 21:52:10 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 11:45:41 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 19:21:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Bourel", "Hippolyte", ""], ["Maillard", "Odalric-Ambrym", ""], ["Talebi", "Mohammad Sadegh", ""]]}, {"id": "2004.09665", "submitter": "Zexi Chen", "authors": "Zexi Chen, Benjamin Dutton, Bharathkumar Ramachandra, Tianfu Wu, Ranga\n  Raju Vatsavai", "title": "Local Clustering with Mean Teacher for Semi-supervised Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mean Teacher (MT) model of Tarvainen and Valpola has shown favorable\nperformance on several semi-supervised benchmark datasets. MT maintains a\nteacher model's weights as the exponential moving average of a student model's\nweights and minimizes the divergence between their probability predictions\nunder diverse perturbations of the inputs. However, MT is known to suffer from\nconfirmation bias, that is, reinforcing incorrect teacher model predictions. In\nthis work, we propose a simple yet effective method called Local Clustering\n(LC) to mitigate the effect of confirmation bias. In MT, each data point is\nconsidered independent of other points during training; however, data points\nare likely to be close to each other in feature space if they share similar\nfeatures. Motivated by this, we cluster data points locally by minimizing the\npairwise distance between neighboring data points in feature space. Combined\nwith a standard classification cross-entropy objective on labeled data points,\nthe misclassified unlabeled data points are pulled towards high-density regions\nof their correct class with the help of their neighbors, thus improving model\nperformance. We demonstrate on semi-supervised benchmark datasets SVHN and\nCIFAR-10 that adding our LC loss to MT yields significant improvements compared\nto MT and performance comparable to the state of the art in semi-supervised\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 22:31:31 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 00:47:01 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Chen", "Zexi", ""], ["Dutton", "Benjamin", ""], ["Ramachandra", "Bharathkumar", ""], ["Wu", "Tianfu", ""], ["Vatsavai", "Ranga Raju", ""]]}, {"id": "2004.09677", "submitter": "Finbarr Timbers", "authors": "Finbarr Timbers, Edward Lockhart, Marc Lanctot, Martin Schmid, Julian\n  Schrittwieser, Thomas Hubert, Michael Bowling", "title": "Approximate exploitability: Learning a best response in large games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard metric used to measure the approximate optimality of policies in\nimperfect information games is exploitability, i.e. the performance of a policy\nagainst its worst-case opponent. However, exploitability is intractable to\ncompute in large games as it requires a full traversal of the game tree to\ncalculate a best response to the given policy. We introduce a new metric,\napproximate exploitability, that calculates an analogous metric using an\napproximate best response; the approximation is done by using search and\nreinforcement learning. This is a generalization of local best response, a\ndomain specific evaluation metric used in poker. We provide empirical results\nfor a specific instance of the method, demonstrating that our method converges\nto exploitability in the tabular and function approximation settings for small\ngames. In large games, our method learns to exploit both strong and weak\nagents, learning to exploit an AlphaZero agent.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:36:40 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 16:13:05 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 15:59:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Timbers", "Finbarr", ""], ["Lockhart", "Edward", ""], ["Lanctot", "Marc", ""], ["Schmid", "Martin", ""], ["Schrittwieser", "Julian", ""], ["Hubert", "Thomas", ""], ["Bowling", "Michael", ""]]}, {"id": "2004.09691", "submitter": "Gabriele Cesa", "authors": "Mirgahney Mohamed, Gabriele Cesa, Taco S. Cohen and Max Welling", "title": "A Data and Compute Efficient Design for Limited-Resources Deep Learning", "comments": "Accepted for poster presentation at the Practical Machine Learning\n  for Developing Countries (PML4DC) workshop, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thanks to their improved data efficiency, equivariant neural networks have\ngained increased interest in the deep learning community. They have been\nsuccessfully applied in the medical domain where symmetries in the data can be\neffectively exploited to build more accurate and robust models. To be able to\nreach a much larger body of patients, mobile, on-device implementations of deep\nlearning solutions have been developed for medical applications. However,\nequivariant models are commonly implemented using large and computationally\nexpensive architectures, not suitable to run on mobile devices. In this work,\nwe design and test an equivariant version of MobileNetV2 and further optimize\nit with model quantization to enable more efficient inference. We achieve\nclose-to state of the art performance on the Patch Camelyon (PCam) medical\ndataset while being more computationally efficient.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 00:49:11 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 11:29:18 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Mohamed", "Mirgahney", ""], ["Cesa", "Gabriele", ""], ["Cohen", "Taco S.", ""], ["Welling", "Max", ""]]}, {"id": "2004.09702", "submitter": "Will Zou", "authors": "Will Y. Zou, Shuyang Du, James Lee, Jan Pedersen", "title": "Heterogeneous Causal Learning for Effectiveness Optimization in User\n  Marketing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  User marketing is a key focus of consumer-based internet companies. Learning\nalgorithms are effective to optimize marketing campaigns which increase user\nengagement, and facilitates cross-marketing to related products. By attracting\nusers with rewards, marketing methods are effective to boost user activity in\nthe desired products. Rewards incur significant cost that can be off-set by\nincrease in future revenue. Most methodologies rely on churn predictions to\nprevent losing users to make marketing decisions, which cannot capture up-lift\nacross counterfactual outcomes with business metrics. Other predictive models\nare capable of estimating heterogeneous treatment effects, but fail to capture\nthe balance of cost versus benefit. We propose a treatment effect optimization\nmethodology for user marketing. This algorithm learns from past experiments and\nutilizes novel optimization methods to optimize cost efficiency with respect to\nuser selection. The method optimizes decisions using deep learning optimization\nmodels to treat and reward users, which is effective in producing\ncost-effective, impactful marketing campaigns. Our methodology demonstrates\nsuperior algorithmic flexibility with integration with deep learning methods\nand dealing with business constraints. The effectiveness of our model surpasses\nthe quasi-oracle estimation (R-learner) model and causal forests. We also\nestablished evaluation metrics that reflect the cost-efficiency and real-world\nbusiness value. Our proposed constrained and direct optimization algorithms\noutperform by 24.6% compared with the best performing method in prior art and\nbaseline methods. The methodology is useful in many product scenarios such as\noptimal treatment allocation and it has been deployed in production world-wide.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:34:34 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zou", "Will Y.", ""], ["Du", "Shuyang", ""], ["Lee", "James", ""], ["Pedersen", "Jan", ""]]}, {"id": "2004.09703", "submitter": "Will Zou", "authors": "Will Y. Zou, Smitha Shyam, Michael Mui, Mingshi Wang, Jan Pedersen,\n  Zoubin Ghahramani", "title": "Learning Continuous Treatment Policy and Bipartite Embeddings for\n  Matching with Heterogeneous Causal Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Causal inference methods are widely applied in the fields of medicine,\npolicy, and economics. Central to these applications is the estimation of\ntreatment effects to make decisions. Current methods make binary yes-or-no\ndecisions based on the treatment effect of a single outcome dimension. These\nmethods are unable to capture continuous space treatment policies with a\nmeasure of intensity. They also lack the capacity to consider the complexity of\ntreatment such as matching candidate treatments with the subject. We propose to\nformulate the effectiveness of treatment as a parametrizable model, expanding\nto a multitude of treatment intensities and complexities through the continuous\npolicy treatment function, and the likelihood of matching. Our proposal to\ndecompose treatment effect functions into effectiveness factors presents a\nframework to model a rich space of actions using causal inference. We utilize\ndeep learning to optimize the desired holistic metric space instead of\npredicting single-dimensional treatment counterfactual. This approach employs a\npopulation-wide effectiveness measure and significantly improves the overall\neffectiveness of the model. The performance of our algorithms is. demonstrated\nwith experiments. When using generic continuous space treatments and matching\narchitecture, we observe a 41% improvement upon prior art with\ncost-effectiveness and 68% improvement upon a similar method in the average\ntreatment effect. The algorithms capture subtle variations in treatment space,\nstructures the efficient optimizations techniques, and opens up the arena for\nmany applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:36:20 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zou", "Will Y.", ""], ["Shyam", "Smitha", ""], ["Mui", "Michael", ""], ["Wang", "Mingshi", ""], ["Pedersen", "Jan", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2004.09709", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao, Peter Bickel and Charles Weko", "title": "Identifiability and consistency of network inference using the hub model\n  and variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical network analysis primarily focuses on inferring the parameters of\nan observed network. In many applications, especially in the social sciences,\nthe observed data is the groups formed by individual subjects. In these\napplications, the network is itself a parameter of a statistical model. Zhao\nand Weko (2019) propose a model-based approach, called the hub model, to infer\nimplicit networks from grouping behavior. The hub model assumes that each\nmember of the group is brought together by a member of the group called the\nhub. The hub model belongs to the family of Bernoulli mixture models.\nIdentifiability of parameters is a notoriously difficult problem for Bernoulli\nmixture models. This paper proves identifiability of the hub model parameters\nand estimation consistency under mild conditions. Furthermore, this paper\ngeneralizes the hub model by introducing a model component that allows hubless\ngroups in which individual nodes spontaneously appear independent of any other\nindividual. We refer to this additional component as the null component. The\nnew model bridges the gap between the hub model and the degenerate case of the\nmixture model -- the Bernoulli product. Identifiability and consistency are\nalso proved for the new model. Numerical studies are provided to demonstrate\nthe theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:01:00 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 17:10:21 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 23:52:37 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Zhao", "Yunpeng", ""], ["Bickel", "Peter", ""], ["Weko", "Charles", ""]]}, {"id": "2004.09710", "submitter": "Gianlucca Zuin", "authors": "Gianlucca Zuin, Adriano Veloso, Jo\\~ao C\\^andido Portinari and Nivio\n  Ziviani", "title": "Automatic Tag Recommendation for Painting Artworks Using Diachronic\n  Descriptions", "comments": "IJCNN-2020. July 19-24th, 2020. Glasgow (UK)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the problem of automatic tag recommendation for\npainting artworks. Diachronic descriptions containing deviations on the\nvocabulary used to describe each painting usually occur when the work is done\nby many experts over time. The objective of this work is to provide a framework\nthat produces a more accurate and homogeneous set of tags for each painting in\na large collection. To validate our method we build a model based on a\nweakly-supervised neural network for over $5{,}300$ paintings with hand-labeled\ndescriptions made by experts for the paintings of the Brazilian painter Candido\nPortinari. This work takes place with the Portinari Project which started in\n1979 intending to recover and catalog the paintings of the Brazilian painter.\nThe Portinari paintings at that time were in private collections and museums\nspread around the world and thus inaccessible to the public. The descriptions\nof each painting were made by a large number of collaborators over 40 years as\nthe paintings were recovered and these diachronic descriptions caused\ndeviations on the vocabulary used to describe each painting. Our proposed\nframework consists of (i) a neural network that receives as input the image of\neach painting and uses frequent itemsets as possible tags, and (ii) a\nclustering step in which we group related tags based on the output of the\npre-trained classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:10:00 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zuin", "Gianlucca", ""], ["Veloso", "Adriano", ""], ["Portinari", "Jo\u00e3o C\u00e2ndido", ""], ["Ziviani", "Nivio", ""]]}, {"id": "2004.09721", "submitter": "Viet Trinh", "authors": "Viet Trinh, Vikrant More, Samira Zare, and Sheideh Homayon", "title": "Quarantine Deceiving Yelp's Users by Detecting Unreliable Rating Reviews", "comments": "5 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews have become a valuable and significant resource, for not only\nconsumers but companies, in decision making. In the absence of a trusted\nsystem, highly popular and trustworthy internet users will be assumed as\nmembers of the trusted circle. In this paper, we describe our focus on\nquarantining deceiving Yelp's users that employ both review spike detection\n(RSD) algorithm and spam detection technique in bridging review networks (BRN),\non extracted key features. We found that more than 80% of Yelp's accounts are\nunreliable, and more than 80% of highly-rated businesses are subject to\nspamming.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:44:10 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Trinh", "Viet", ""], ["More", "Vikrant", ""], ["Zare", "Samira", ""], ["Homayon", "Sheideh", ""]]}, {"id": "2004.09735", "submitter": "Tatsuya Akutsu", "authors": "Avraham A. Melkman, Sini Guo, Wai-Ki Ching, Pengyu Liu, Tatsuya Akutsu", "title": "On the Compressive Power of Boolean Threshold Autoencoders", "comments": "13 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autoencoder is a layered neural network whose structure can be viewed as\nconsisting of an encoder, which compresses an input vector of dimension $D$ to\na vector of low dimension $d$, and a decoder which transforms the\nlow-dimensional vector back to the original input vector (or one that is very\nsimilar). In this paper we explore the compressive power of autoencoders that\nare Boolean threshold networks by studying the numbers of nodes and layers that\nare required to ensure that the numbers of nodes and layers that are required\nto ensure that each vector in a given set of distinct input binary vectors is\ntransformed back to its original. We show that for any set of $n$ distinct\nvectors there exists a seven-layer autoencoder with the smallest possible\nmiddle layer, (i.e., its size is logarithmic in $n$), but that there is a set\nof $n$ vectors for which there is no three-layer autoencoder with a middle\nlayer of the same size. In addition we present a kind of trade-off: if a\nconsiderably larger middle layer is permissible then a five-layer autoencoder\ndoes exist. We also study encoding by itself. The results we obtain suggest\nthat it is the decoding that constitutes the bottleneck of autoencoding. For\nexample, there always is a three-layer Boolean threshold encoder that\ncompresses $n$ vectors into a dimension that is reduced to twice the logarithm\nof $n$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 03:21:43 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Melkman", "Avraham A.", ""], ["Guo", "Sini", ""], ["Ching", "Wai-Ki", ""], ["Liu", "Pengyu", ""], ["Akutsu", "Tatsuya", ""]]}, {"id": "2004.09740", "submitter": "Wenjie Li", "authors": "Wenjie Li, Zhaoyang Zhang, Xinjiang Wang, Ping Luo", "title": "AdaX: Adaptive Gradient Descent with Exponential Long Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although adaptive optimization algorithms such as Adam show fast convergence\nin many machine learning tasks, this paper identifies a problem of Adam by\nanalyzing its performance in a simple non-convex synthetic problem, showing\nthat Adam's fast convergence would possibly lead the algorithm to local\nminimums. To address this problem, we improve Adam by proposing a novel\nadaptive gradient descent algorithm named AdaX. Unlike Adam that ignores the\npast gradients, AdaX exponentially accumulates the long-term gradient\ninformation in the past during training, to adaptively tune the learning rate.\nWe thoroughly prove the convergence of AdaX in both the convex and non-convex\nsettings. Extensive experiments show that AdaX outperforms Adam in various\ntasks of computer vision and natural language processing and can catch up with\nStochastic Gradient Descent.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 03:46:58 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 21:05:58 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Wenjie", ""], ["Zhang", "Zhaoyang", ""], ["Wang", "Xinjiang", ""], ["Luo", "Ping", ""]]}, {"id": "2004.09749", "submitter": "Duy Vo Nguyen Le", "authors": "Vo Nguyen Le Duy, Ichiro Takeuchi", "title": "Parametric Programming Approach for More Powerful and General Lasso\n  Selective Inference", "comments": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective Inference (SI) has been actively studied in the past few years for\nconducting inference on the features of linear models that are adaptively\nselected by feature selection methods such as Lasso. The basic idea of SI is to\nmake inference conditional on the selection event. Unfortunately, the main\nlimitation of the original SI approach for Lasso is that the inference is\nconducted not only conditional on the selected features but also on their signs\n-- this leads to loss of power because of over-conditioning. Although this\nlimitation can be circumvented by considering the union of such selection\nevents for all possible combinations of signs, this is only feasible when the\nnumber of selected features is sufficiently small. To address this\ncomputational bottleneck, we propose a parametric programming-based method that\ncan conduct SI without conditioning on signs even when we have thousands of\nactive features. The main idea is to compute the continuum path of Lasso\nsolutions in the direction of a test statistic, and identify the subset of the\ndata space corresponding to the feature selection event by following the\nsolution path. The proposed parametric programming-based method not only avoids\nthe aforementioned computational bottleneck but also improves the performance\nand practicality of SI for Lasso in various respects. We conduct several\nexperiments to demonstrate the effectiveness and efficiency of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 04:46:29 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 08:23:47 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 13:18:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2004.09756", "submitter": "Seyedmehdi Abtahi", "authors": "SeyedMehdi Abtahi and Nima Assadian", "title": "Integrated attitude estimation and control of satellite with thruster\n  actuator using ANFIS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed a new estimation and control strategy to control the\nsatellite attitude. As the attitude control strategy plays an essential role in\nthe different kinds of space missions, scientists try to improve the\nperformance of the satellite attitude system, regardless of the expense. In\nthis study, we proposed an adaptive neuro-fuzzy integrated (ANFIS) satellite\nattitude estimation and control system. A pulse modulator is used to generate\nthe right ON/OFF commands of the thruster actuator. To evaluate the performance\nof the ANFIS controller in closed-loop simulation, an ANFIS observer is used to\nestimate the attitude and angular velocities of the satellite using a\nmagnetometer, sun sensor, and rate gyro data. Besides, a new ANFIS system will\nbe proposed and evaluated that can simultaneously control and estimate the\nsystem. The performance of the ANFIS controller is compared with the optimal\nPID controller in a Monte Carlo simulation using different initial conditions,\ndisturbance, and noise. The simulations are performed to verify the ANFIS\ncontroller's ability to decrease settling time and fuel consumption in\ncomparison with the optimal PID controller. Also, examine the ANFIS estimator,\nand the results demonstrate the high skill of these designated observers.\nMoreover, we proposed an integrated ANFIS estimator and controller for\nsatellite attitude control and estimation in the presence of noise and\nuncertainty, which can reduce the computational effort and offer smooth\nactuator actions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 05:09:26 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 15:52:07 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Abtahi", "SeyedMehdi", ""], ["Assadian", "Nima", ""]]}, {"id": "2004.09764", "submitter": "Fang Xianghong", "authors": "Xianghong Fang and Haoli Bai and Zenglin Xu and Michael Lyu and Irwin\n  King", "title": "Discrete Variational Attention Models for Language Generation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Variational autoencoders have been widely applied for natural language\ngeneration, however, there are two long-standing problems: information\nunder-representation and posterior collapse. The former arises from the fact\nthat only the last hidden state from the encoder is transformed to the latent\nspace, which is insufficient to summarize data. The latter comes as a result of\nthe imbalanced scale between the reconstruction loss and the KL divergence in\nthe objective function. To tackle these issues, in this paper we propose the\ndiscrete variational attention model with categorical distribution over the\nattention mechanism owing to the discrete nature in languages. Our approach is\ncombined with an auto-regressive prior to capture the sequential dependency\nfrom observations, which can enhance the latent space for language generation.\nMoreover, thanks to the property of discreteness, the training of our proposed\napproach does not suffer from posterior collapse. Furthermore, we carefully\nanalyze the superiority of discrete latent space over the continuous space with\nthe common Gaussian distribution. Extensive experiments on language generation\ndemonstrate superior advantages of our proposed approach in comparison with the\nstate-of-the-art counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 05:49:04 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 08:02:24 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 15:18:57 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 06:35:02 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Fang", "Xianghong", ""], ["Bai", "Haoli", ""], ["Xu", "Zenglin", ""], ["Lyu", "Michael", ""], ["King", "Irwin", ""]]}, {"id": "2004.09780", "submitter": "Shaofeng Deng", "authors": "Shaofeng Deng, Shuyang Ling, Thomas Strohmer", "title": "Strong Consistency, Graph Laplacians, and the Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering has become one of the most popular algorithms in data\nclustering and community detection. We study the performance of classical\ntwo-step spectral clustering via the graph Laplacian to learn the stochastic\nblock model. Our aim is to answer the following question: when is spectral\nclustering via the graph Laplacian able to achieve strong consistency, i.e.,\nthe exact recovery of the underlying hidden communities? Our work provides an\nentrywise analysis (an $\\ell_{\\infty}$-norm perturbation bound) of the Fielder\neigenvector of both the unnormalized and the normalized Laplacian associated\nwith the adjacency matrix sampled from the stochastic block model. We prove\nthat spectral clustering is able to achieve exact recovery of the planted\ncommunity structure under conditions that match the information-theoretic\nlimits.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:16:46 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Deng", "Shaofeng", ""], ["Ling", "Shuyang", ""], ["Strohmer", "Thomas", ""]]}, {"id": "2004.09788", "submitter": "Jinyoung Kim Dr.", "authors": "Jinyoung Kim, Remi Patriat, Jordan Kaplan, Oren Solomon, Noam Harel", "title": "Deep Cerebellar Nuclei Segmentation via Semi-Supervised Deep\n  Context-Aware Learning from 7T Diffusion MRI", "comments": "56 pages (one column), 13 figures, 5 tables, supplementary materials,\n  Accepted for publication in IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep cerebellar nuclei are a key structure of the cerebellum that are\ninvolved in processing motor and sensory information. It is thus a crucial step\nto accurately segment deep cerebellar nuclei for the understanding of the\ncerebellum system and its utility in deep brain stimulation treatment. However,\nit is challenging to clearly visualize such small nuclei under standard\nclinical magnetic resonance imaging (MRI) protocols and therefore precise\nsegmentation is not feasible. Recent advances in 7 Tesla (T) MRI technology and\ngreat potential of deep neural networks facilitate automatic patient-specific\nsegmentation. In this paper, we propose a novel deep learning framework\n(referred to as DCN-Net) for fast, accurate, and robust patient-specific\nsegmentation of deep cerebellar dentate and interposed nuclei on 7T diffusion\nMRI. DCN-Net effectively encodes contextual information on the patch images\nwithout consecutive pooling operations and adding complexity via proposed\ndilated dense blocks. During the end-to-end training, label probabilities of\ndentate and interposed nuclei are independently learned with a hybrid loss,\nhandling highly imbalanced data. Finally, we utilize self-training strategies\nto cope with the problem of limited labeled data. To this end, auxiliary\ndentate and interposed nuclei labels are created on unlabeled data by using\nDCN-Net trained on manual labels. We validate the proposed framework using 7T\nB0 MRIs from 60 subjects. Experimental results demonstrate that DCN-Net\nprovides better segmentation than atlas-based deep cerebellar nuclei\nsegmentation tools and other state-of-the-art deep neural networks in terms of\naccuracy and consistency. We further prove the effectiveness of the proposed\ncomponents within DCN-Net in dentate and interposed nuclei segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:30:07 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 06:26:20 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 01:47:33 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Kim", "Jinyoung", ""], ["Patriat", "Remi", ""], ["Kaplan", "Jordan", ""], ["Solomon", "Oren", ""], ["Harel", "Noam", ""]]}, {"id": "2004.09808", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Ruxin Wang, Hongyan Wu", "title": "Perturb More, Trap More: Understanding Behaviors of Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While graph neural networks (GNNs) have shown a great potential in various\ntasks on graph, the lack of transparency has hindered understanding how GNNs\narrived at its predictions. Although few explainers for GNNs are explored, the\nconsideration of local fidelity, indicating how the model behaves around an\ninstance should be predicted, is neglected. In this paper, we first propose a\nnovel post-hoc framework based on local fidelity for any trained GNNs - TraP2,\nwhich can generate a high-fidelity explanation. Considering that both relevant\ngraph structure and important features inside each node need to be highlighted,\na three-layer architecture in TraP2 is designed: i) interpretation domain are\ndefined by Translation layer in advance; ii) local predictive behavior of GNNs\nbeing explained are probed and monitored by Perturbation layer, in which\nmultiple perturbations for graph structure and feature-level are conducted in\ninterpretation domain; iii) high faithful explanations are generated by fitting\nthe local decision boundary through Paraphrase layer. Finally, TraP2 is\nevaluated on six benchmark datasets based on five desired attributions:\naccuracy, fidelity, decisiveness, insight and inspiration, which achieves\n$10.2\\%$ higher explanation accuracy than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:07:01 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:08:51 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ji", "Chaojie", ""], ["Wang", "Ruxin", ""], ["Wu", "Hongyan", ""]]}, {"id": "2004.09820", "submitter": "Liwei Jiang", "authors": "Liwei Jiang, Dan Li, Qisheng Wang, Shuai Wang, Songtao Wang", "title": "Improving Positive Unlabeled Learning: Practical AUL Estimation and New\n  Training Method for Extremely Imbalanced Data Sets", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive Unlabeled (PU) learning is widely used in many applications, where a\nbinary classifier is trained on the datasets consisting of only positive and\nunlabeled samples. In this paper, we improve PU learning over state-of-the-art\nfrom two aspects. Firstly, existing model evaluation methods for PU learning\nrequires ground truth of unlabeled samples, which is unlikely to be obtained in\npractice. In order to release this restriction, we propose an asymptotic\nunbiased practical AUL (area under the lift) estimation method, which makes use\nof raw PU data without prior knowledge of unlabeled samples.\n  Secondly, we propose ProbTagging, a new training method for extremely\nimbalanced data sets, where the number of unlabeled samples is hundreds or\nthousands of times that of positive samples. ProbTagging introduces probability\ninto the aggregation method. Specifically, each unlabeled sample is tagged\npositive or negative with the probability calculated based on the similarity to\nits positive neighbors. Based on this, multiple data sets are generated to\ntrain different models, which are then combined into an ensemble model.\nCompared to state-of-the-art work, the experimental results show that\nProbTagging can increase the AUC by up to 10%, based on three industrial and\ntwo artificial PU data sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:32:57 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Jiang", "Liwei", ""], ["Li", "Dan", ""], ["Wang", "Qisheng", ""], ["Wang", "Shuai", ""], ["Wang", "Songtao", ""]]}, {"id": "2004.09845", "submitter": "Xueying Shi", "authors": "Xueying Shi, Yueming Jin, Qi Dou, Pheng-Ann Heng", "title": "LRTD: Long-Range Temporal Dependency based Active Learning for Surgical\n  Workflow Recognition", "comments": "Accepted as a conference paper in IPCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic surgical workflow recognition in video is an essentially\nfundamental yet challenging problem for developing computer-assisted and\nrobotic-assisted surgery. Existing approaches with deep learning have achieved\nremarkable performance on analysis of surgical videos, however, heavily relying\non large-scale labelled datasets. Unfortunately, the annotation is not often\navailable in abundance, because it requires the domain knowledge of surgeons.\nIn this paper, we propose a novel active learning method for cost-effective\nsurgical video analysis. Specifically, we propose a non-local recurrent\nconvolutional network (NL-RCNet), which introduces non-local block to capture\nthe long-range temporal dependency (LRTD) among continuous frames. We then\nformulate an intra-clip dependency score to represent the overall dependency\nwithin this clip. By ranking scores among clips in unlabelled data pool, we\nselect the clips with weak dependencies to annotate, which indicates the most\ninformative ones to better benefit network training. We validate our approach\non a large surgical video dataset (Cholec80) by performing surgical workflow\nrecognition task. By using our LRTD based selection strategy, we can outperform\nother state-of-the-art active learning methods. Using only up to 50% of\nsamples, our approach can exceed the performance of full-data training.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:21:22 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 05:57:47 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Shi", "Xueying", ""], ["Jin", "Yueming", ""], ["Dou", "Qi", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "2004.09846", "submitter": "Richa Verma", "authors": "Somjit Nath, Richa Verma, Abhik Ray, Harshad Khadilkar", "title": "SIBRE: Self Improvement Based REwards for Adaptive Feedback in\n  Reinforcement Learning", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a generic reward shaping approach for improving the rate of\nconvergence in reinforcement learning (RL), called Self Improvement Based\nREwards, or SIBRE. The approach is designed for use in conjunction with any\nexisting RL algorithm, and consists of rewarding improvement over the agent's\nown past performance. We prove that SIBRE converges in expectation under the\nsame conditions as the original RL algorithm. The reshaped rewards help\ndiscriminate between policies when the original rewards are weakly\ndiscriminated or sparse. Experiments on several well-known benchmark\nenvironments with different RL algorithms show that SIBRE converges to the\noptimal policy faster and more stably. We also perform sensitivity analysis\nwith respect to hyper-parameters, in comparison with baseline RL algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:22:16 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 04:27:49 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 10:08:03 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Nath", "Somjit", ""], ["Verma", "Richa", ""], ["Ray", "Abhik", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2004.09863", "submitter": "Asunci\\'on Jim\\'enez-Cordero", "authors": "Asunci\\'on Jim\\'enez-Cordero, Juan Miguel Morales and Salvador Pineda", "title": "A novel embedded min-max approach for feature selection in nonlinear\n  support vector machine classification", "comments": "Published at European Journal of Operational Research", "journal-ref": null, "doi": "10.1016/j.ejor.2020.12.009", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, feature selection has become a challenging problem in\nseveral machine learning fields, such as classification problems. Support\nVector Machine (SVM) is a well-known technique applied in classification tasks.\nVarious methodologies have been proposed in the literature to select the most\nrelevant features in SVM. Unfortunately, all of them either deal with the\nfeature selection problem in the linear classification setting or propose\nad-hoc approaches that are difficult to implement in practice. In contrast, we\npropose an embedded feature selection method based on a min-max optimization\nproblem, where a trade-off between model complexity and classification accuracy\nis sought. By leveraging duality theory, we equivalently reformulate the\nmin-max problem and solve it without further ado using off-the-shelf software\nfor nonlinear optimization. The efficiency and usefulness of our approach are\ntested on several benchmark data sets in terms of accuracy, number of selected\nfeatures and interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:40:38 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 14:24:48 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 16:35:04 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 15:40:42 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Jim\u00e9nez-Cordero", "Asunci\u00f3n", ""], ["Morales", "Juan Miguel", ""], ["Pineda", "Salvador", ""]]}, {"id": "2004.09900", "submitter": "Harvineet Singh", "authors": "Harvineet Singh, Moumita Sinha, Atanu R. Sinha, Sahil Garg, Neha\n  Banerjee", "title": "An RNN-Survival Model to Decide Email Send Times", "comments": "11 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Email communications are ubiquitous. Firms control send times of emails and\nthereby the instants at which emails reach recipients (it is assumed email is\nreceived instantaneously from the send time). However, they do not control the\nduration it takes for recipients to open emails, labeled as time-to-open.\nImportantly, among emails that are opened, most occur within a short window\nfrom their send times. We posit that emails are likely to be opened sooner when\nsend times are convenient for recipients, while for other send times, emails\ncan get ignored. Thus, to compute appropriate send times it is important to\npredict times-to-open accurately. We propose a recurrent neural network (RNN)\nin a survival model framework to predict times-to-open, for each recipient.\nUsing that we compute appropriate send times. We experiment on a data set of\nemails sent to a million customers over five months. The sequence of emails\nreceived by a person from a sender is a result of interactions with past emails\nfrom the sender, and hence contain useful signal that inform our model. This\nsequential dependence affords our proposed RNN-Survival (RNN-S) approach to\noutperform survival analysis approaches in predicting times-to-open. We show\nthat best times to send emails can be computed accurately from predicted\ntimes-to-open. This approach allows a firm to tune send times of emails, which\nis in its control, to favorably influence open rates and engagement.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 10:53:14 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Singh", "Harvineet", ""], ["Sinha", "Moumita", ""], ["Sinha", "Atanu R.", ""], ["Garg", "Sahil", ""], ["Banerjee", "Neha", ""]]}, {"id": "2004.09931", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic and Tias Guns and Andrew Cropper", "title": "Knowledge Refactoring for Inductive Program Synthesis", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans constantly restructure knowledge to use it more efficiently. Our goal\nis to give a machine learning system similar abilities so that it can learn\nmore efficiently. We introduce the \\textit{knowledge refactoring} problem,\nwhere the goal is to restructure a learner's knowledge base to reduce its size\nand to minimise redundancy in it. We focus on inductive logic programming,\nwhere the knowledge base is a logic program. We introduce Knorf, a system which\nsolves the refactoring problem using constraint optimisation. We evaluate our\napproach on two program induction domains: real-world string transformations\nand building Lego structures. Our experiments show that learning from\nrefactored knowledge can improve predictive accuracies fourfold and reduce\nlearning times by half.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:04:38 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:19:22 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 08:23:31 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Guns", "Tias", ""], ["Cropper", "Andrew", ""]]}, {"id": "2004.09957", "submitter": "Jason Rhuggenaath", "authors": "Jason Rhuggenaath, Alp Akcay, Yingqian Zhang and Uzay Kaymak", "title": "Algorithms for slate bandits with non-separable reward functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a slate bandit problem where the function that\ndetermines the slate-level reward is non-separable: the optimal value of the\nfunction cannot be determined by learning the optimal action for each slot. We\nare mainly concerned with cases where the number of slates is large relative to\nthe time horizon, so that trying each slate as a separate arm in a traditional\nmulti-armed bandit, would not be feasible. Our main contribution is the design\nof algorithms that still have sub-linear regret with respect to the time\nhorizon, despite the large number of slates. Experimental results on simulated\ndata and real-world data show that our proposed method outperforms popular\nbenchmark bandit algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:45:02 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Rhuggenaath", "Jason", ""], ["Akcay", "Alp", ""], ["Zhang", "Yingqian", ""], ["Kaymak", "Uzay", ""]]}, {"id": "2004.09986", "submitter": "Daniel Leite", "authors": "Daniel Leite, Leticia Decker, Marcio Santana, Paulo Souza", "title": "EGFC: Evolving Gaussian Fuzzy Classifier from Never-Ending\n  Semi-Supervised Data Streams -- With Application to Power Quality Disturbance\n  Detection and Classification", "comments": "10 pages, 6 figures, 1 table, IEEE International Conference on Fuzzy\n  Systems (FUZZ-IEEE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-quality disturbances lead to several drawbacks such as limitation of\nthe production capacity, increased line and equipment currents, and consequent\nohmic losses; higher operating temperatures, premature faults, reduction of\nlife expectancy of machines, malfunction of equipment, and unplanned outages.\nReal-time detection and classification of disturbances are deemed essential to\nindustry standards. We propose an Evolving Gaussian Fuzzy Classification (EGFC)\nframework for semi-supervised disturbance detection and classification combined\nwith a hybrid Hodrick-Prescott and Discrete-Fourier-Transform\nattribute-extraction method applied over a landmark window of voltage\nwaveforms. Disturbances such as spikes, notching, harmonics, and oscillatory\ntransient are considered. Different from other monitoring systems, which\nrequire offline training of models based on a limited amount of data and\noccurrences, the proposed online data-stream-based EGFC method is able to learn\ndisturbance patterns autonomously from never-ending data streams by adapting\nthe parameters and structure of a fuzzy rule base on the fly. Moreover, the\nfuzzy model obtained is linguistically interpretable, which improves model\nacceptability. We show encouraging classification results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:08:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Leite", "Daniel", ""], ["Decker", "Leticia", ""], ["Santana", "Marcio", ""], ["Souza", "Paulo", ""]]}, {"id": "2004.10019", "submitter": "Yuan Zhou", "authors": "Zihan Zhang, Yuan Zhou, Xiangyang Ji", "title": "Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage\n  Decomposition", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reinforcement learning problem in the setting of finite-horizon\nepisodic Markov Decision Processes (MDPs) with $S$ states, $A$ actions, and\nepisode length $H$. We propose a model-free algorithm UCB-Advantage and prove\nthat it achieves $\\tilde{O}(\\sqrt{H^2SAT})$ regret where $T = KH$ and $K$ is\nthe number of episodes to play. Our regret bound improves upon the results of\n[Jin et al., 2018] and matches the best known model-based algorithms as well as\nthe information theoretic lower bound up to logarithmic factors. We also show\nthat UCB-Advantage achieves low local switching cost and applies to concurrent\nreinforcement learning, improving upon the recent results of [Bai et al.,\n2019].\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:00:06 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 13:35:38 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhang", "Zihan", ""], ["Zhou", "Yuan", ""], ["Ji", "Xiangyang", ""]]}, {"id": "2004.10076", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan and Erik B Dam", "title": "Tensor Networks for Medical Image Classification", "comments": "Accepted for publication at International Conference on Medical\n  Imaging with Deep Learning (MIDL), 2020. Reviews on Openreview here:\n  https://openreview.net/forum?id=jjk6bxk07G", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of machine learning tools like neural networks\nacross several domains, interesting connections and comparisons to concepts\nfrom other domains are coming to light. In this work, we focus on the class of\nTensor Networks, which has been a work horse for physicists in the last two\ndecades to analyse quantum many-body systems. Building on the recent interest\nin tensor networks for machine learning, we extend the Matrix Product State\ntensor networks (which can be interpreted as linear classifiers operating in\nexponentially high dimensional spaces) to be useful in medical image analysis\ntasks. We focus on classification problems as a first step where we motivate\nthe use of tensor networks and propose adaptions for 2D images using classical\nimage domain concepts such as local orderlessness of images. With the proposed\nlocally orderless tensor network model (LoTeNet), we show that tensor networks\nare capable of attaining performance that is comparable to state-of-the-art\ndeep learning methods. We evaluate the model on two publicly available medical\nimaging datasets and show performance improvements with fewer model\nhyperparameters and lesser computational resources compared to relevant\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:02:58 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Selvan", "Raghavendra", ""], ["Dam", "Erik B", ""]]}, {"id": "2004.10098", "submitter": "Nikhil Mehta", "authors": "Nikhil Mehta, Kevin J Liang, Vinay K Verma and Lawrence Carin", "title": "Continual Learning using a Bayesian Nonparametric Dictionary of Weight\n  Factors", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021 Post-conference updates: Fixed\n  typo in equation (11) and updated references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Naively trained neural networks tend to experience catastrophic forgetting in\nsequential task settings, where data from previous tasks are unavailable. A\nnumber of methods, using various model expansion strategies, have been proposed\nrecently as possible solutions. However, determining how much to expand the\nmodel is left to the practitioner, and often a constant schedule is chosen for\nsimplicity, regardless of how complex the incoming task is. Instead, we propose\na principled Bayesian nonparametric approach based on the Indian Buffet Process\n(IBP) prior, letting the data determine how much to expand the model\ncomplexity. We pair this with a factorization of the neural network's weight\nmatrices. Such an approach allows the number of factors of each weight matrix\nto scale with the complexity of the task, while the IBP prior encourages sparse\nweight factor selection and factor reuse, promoting positive knowledge transfer\nbetween tasks. We demonstrate the effectiveness of our method on a number of\ncontinual learning benchmarks and analyze how weight factors are allocated and\nreused throughout the training.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:20:19 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 04:08:52 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 23:28:11 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Mehta", "Nikhil", ""], ["Liang", "Kevin J", ""], ["Verma", "Vinay K", ""], ["Carin", "Lawrence", ""]]}, {"id": "2004.10126", "submitter": "Takato Yasuno", "authors": "Takato Yasuno", "title": "Generative Synthetic Augmentation using Label-to-Image Translation for\n  Nuclei Image Segmentation", "comments": "15pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical image diagnosis, pathology image analysis using semantic\nsegmentation becomes important for efficient screening as a field of digital\npathology. The spatial augmentation is ordinary used for semantic segmentation.\nTumor images under malignant are rare and to annotate the labels of nuclei\nregion takes much time-consuming. We require an effective use of dataset to\nmaximize the segmentation accuracy. It is expected that some augmentation to\ntransform generalized images influence the segmentation performance. We propose\na synthetic augmentation using label-to-image translation, mapping from a\nsemantic label with the edge structure to a real image. Exactly this paper deal\nwith stain slides of nuclei in tumor. Actually, we demonstrate several\nsegmentation algorithms applied to the initial dataset that contains real\nimages and labels using synthetic augmentation in order to add their\ngeneralized images. We computes and reports that a proposed synthetic\naugmentation procedure improve their accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:10:11 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:00:27 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 22:48:46 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Yasuno", "Takato", ""]]}, {"id": "2004.10130", "submitter": "Takato Yasuno", "authors": "Takato Yasuno, Masazumi Amakata, Masahiro Okano", "title": "Natural Disaster Classification using Aerial Photography Explainable for\n  Typhoon Damaged Feature", "comments": "10pages, 5figures", "journal-ref": "ICPR2020 Workshops and Challenges (forthcoming on 10 January 2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years, typhoon damages has become social problem owing to climate\nchange. In 9 September 2019, Typhoon Faxai passed on the Chiba in Japan, whose\ndamages included with electric provision stop because of strong wind recorded\non the maximum 45 meter per second. A large amount of tree fell down, and the\nneighbor electric poles also fell down at the same time. These disaster\nfeatures have caused that it took 18 days for recovery longer than past ones.\nImmediate responses are important for faster recovery. As long as we can,\naerial survey for global screening of devastated region would be required for\ndecision support to respond where to recover ahead. This paper proposes a\npractical method to visualize the damaged areas focused on the typhoon disaster\nfeatures using aerial photography. This method can classify eight classes which\ncontains land covers without damages and areas with disaster. Using target\nfeature class probabilities, we can visualize disaster feature map to scale a\ncolor range. Furthermore, we can realize explainable map on each unit grid\nimages to compute the convolutional activation map using Grad-CAM. We\ndemonstrate case studies applied to aerial photographs recorded at the Chiba\nregion after typhoon.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:21:52 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 10:46:54 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 16:43:35 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 09:06:28 GMT"}, {"version": "v5", "created": "Mon, 16 Nov 2020 14:29:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yasuno", "Takato", ""], ["Amakata", "Masazumi", ""], ["Okano", "Masahiro", ""]]}, {"id": "2004.10162", "submitter": "Sanchari Sen", "authors": "Sanchari Sen, Balaraman Ravindran, Anand Raghunathan", "title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased\n  Robustness against Adversarial Attacks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their\nadoption in safety-critical applications such as self-driving cars, drones, and\nhealthcare. Notably, DNNs are vulnerable to adversarial attacks in which small\ninput perturbations can produce catastrophic misclassifications. In this work,\nwe propose EMPIR, ensembles of quantized DNN models with different numerical\nprecisions, as a new approach to increase robustness against adversarial\nattacks. EMPIR is based on the observation that quantized neural networks often\ndemonstrate much higher robustness to adversarial attacks than full precision\nnetworks, but at the cost of a substantial loss in accuracy on the original\n(unperturbed) inputs. EMPIR overcomes this limitation to achieve the 'best of\nboth worlds', i.e., the higher unperturbed accuracies of the full precision\nmodels combined with the higher robustness of the low precision models, by\ncomposing them in an ensemble. Further, as low precision DNN models have\nsignificantly lower computational and storage requirements than full precision\nmodels, EMPIR models only incur modest compute and memory overheads compared to\na single full-precision model (<25% in our evaluations). We evaluate EMPIR\nacross a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10\nand ImageNet) and under 4 different adversarial attacks. Our results indicate\nthat EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5%\nfor the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets\nrespectively, when compared to single full-precision models, without\nsacrificing accuracy on the unperturbed inputs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:17:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Sen", "Sanchari", ""], ["Ravindran", "Balaraman", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2004.10170", "submitter": "Victor Blanco", "authors": "V\\'ictor Blanco, Alberto Jap\\'on and Justo Puerto", "title": "A Mathematical Programming approach to Binary Supervised Classification\n  with Label Noise", "comments": "17 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose novel methodologies to construct Support Vector\nMachine -based classifiers that takes into account that label noises occur in\nthe training sample. We propose different alternatives based on solving Mixed\nInteger Linear and Non Linear models by incorporating decisions on relabeling\nsome of the observations in the training dataset. The first method incorporates\nrelabeling directly in the SVM model while a second family of methods combines\nclustering with classification at the same time, giving rise to a model that\napplies simultaneously similarity measures and SVM. Extensive computational\nexperiments are reported based on a battery of standard datasets taken from UCI\nMachine Learning repository, showing the effectiveness of the proposed\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:25:54 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Blanco", "V\u00edctor", ""], ["Jap\u00f3n", "Alberto", ""], ["Puerto", "Justo", ""]]}, {"id": "2004.10178", "submitter": "Ariel Neufeld", "authors": "Pushpendu Ghosh, Ariel Neufeld, Jajati Keshari Sahoo", "title": "Forecasting directional movements of stock prices for intraday trading\n  using LSTM and random forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as\ntraining methodologies to analyze their effectiveness in forecasting\nout-of-sample directional movements of constituent stocks of the S&P 500 from\nJanuary 1993 till December 2018 for intraday trading. We introduce a\nmulti-feature setting consisting not only of the returns with respect to the\nclosing prices, but also with respect to the opening prices and intraday\nreturns. As trading strategy, we use Krauss et al. (2017) and Fischer & Krauss\n(2018) as benchmark. On each trading day, we buy the 10 stocks with the highest\nprobability and sell short the 10 stocks with the lowest probability to\noutperform the market in terms of intraday returns -- all with equal monetary\nweight. Our empirical results show that the multi-feature setting provides a\ndaily return, prior to transaction costs, of 0.64% using LSTM networks, and\n0.54% using random forests. Hence we outperform the single-feature setting in\nFischer & Krauss (2018) and Krauss et al. (2017) consisting only of the daily\nreturns with respect to the closing prices, having corresponding daily returns\nof 0.41% and of 0.39% with respect to LSTM and random forests, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:35:48 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 19:16:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ghosh", "Pushpendu", ""], ["Neufeld", "Ariel", ""], ["Sahoo", "Jajati Keshari", ""]]}, {"id": "2004.10181", "submitter": "Suyash Gupta", "authors": "Maxime Cauchois and Suyash Gupta and John Duchi", "title": "Knowing what you know: valid and validated confidence sets in multiclass\n  and multilabel prediction", "comments": "Updated section on multilabel settings addressing the cases when\n  labels may repel each other", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop conformal prediction methods for constructing valid predictive\nconfidence sets in multiclass and multilabel problems without assumptions on\nthe data generating distribution. A challenge here is that typical conformal\nprediction methods---which give marginal validity (coverage)\nguarantees---provide uneven coverage, in that they address easy examples at the\nexpense of essentially ignoring difficult examples. By leveraging ideas from\nquantile regression, we build methods that always guarantee correct coverage\nbut additionally provide (asymptotically optimal) conditional coverage for both\nmulticlass and multilabel prediction problems. To address the potential\nchallenge of exponentially large confidence sets in multilabel prediction, we\nbuild tree-structured classifiers that efficiently account for interactions\nbetween labels. Our methods can be bolted on top of any classification\nmodel---neural network, random forest, boosted tree---to guarantee its\nvalidity. We also provide an empirical evaluation, simultaneously providing new\nvalidation methods, that suggests the more robust coverage of our confidence\nsets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:45:38 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 22:53:23 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 18:22:12 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Cauchois", "Maxime", ""], ["Gupta", "Suyash", ""], ["Duchi", "John", ""]]}, {"id": "2004.10188", "submitter": "Marc'Aurelio Ranzato", "authors": "Anton Bakhtin and Yuntian Deng and Sam Gross and Myle Ott and\n  Marc'Aurelio Ranzato and Arthur Szlam", "title": "Residual Energy-Based Models for Text", "comments": "long journal version", "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-41", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current large-scale auto-regressive language models display impressive\nfluency and can generate convincing text. In this work we start by asking the\nquestion: Can the generations of these models be reliably distinguished from\nreal text by statistical discriminators? We find experimentally that the answer\nis affirmative when we have access to the training data for the model, and\nguardedly affirmative even if we do not.\n  This suggests that the auto-regressive models can be improved by\nincorporating the (globally normalized) discriminators into the generative\nprocess. We give a formalism for this using the Energy-Based Model framework,\nand show that it indeed improves the results of the generative models, measured\nboth in terms of perplexity and in terms of human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:44:03 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:50:36 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bakhtin", "Anton", ""], ["Deng", "Yuntian", ""], ["Gross", "Sam", ""], ["Ott", "Myle", ""], ["Ranzato", "Marc'Aurelio", ""], ["Szlam", "Arthur", ""]]}, {"id": "2004.10190", "submitter": "Ryan Julian", "authors": "Ryan Julian, Benjamin Swanson, Gaurav S. Sukhatme, Sergey Levine,\n  Chelsea Finn, and Karol Hausman", "title": "Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic\n  Reinforcement Learning", "comments": "8.5 pages, 9 figures. See video overview and experiments at\n  https://youtu.be/pPDVewcSpdc and project website at\n  https://ryanjulian.me/continual-fine-tuning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the great promises of robot learning systems is that they will be able\nto learn from their mistakes and continuously adapt to ever-changing\nenvironments. Despite this potential, most of the robot learning systems today\nare deployed as a fixed policy and they are not being adapted after their\ndeployment. Can we efficiently adapt previously learned behaviors to new\nenvironments, objects and percepts in the real world? In this paper, we present\na method and empirical evidence towards a robot learning framework that\nfacilitates continuous adaption. In particular, we demonstrate how to adapt\nvision-based robotic manipulation policies to new variations by fine-tuning via\noff-policy reinforcement learning, including changes in background, object\nshape and appearance, lighting conditions, and robot morphology. Further, this\nadaptation uses less than 0.2% of the data necessary to learn the task from\nscratch. We find that our approach of adapting pre-trained policies leads to\nsubstantial performance gains over the course of fine-tuning, and that\npre-training via RL is essential: training from scratch or adapting from\nsupervised ImageNet features are both unsuccessful with such small amounts of\ndata. We also find that these positive results hold in a limited continual\nlearning setting, in which we repeatedly fine-tune a single lineage of policies\nusing data from a succession of new tasks. Our empirical conclusions are\nconsistently supported by experiments on simulated manipulation tasks, and by\n52 unique fine-tuning experiments on a real robotic grasping system pre-trained\non 580,000 grasps.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:57:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 13:43:53 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Julian", "Ryan", ""], ["Swanson", "Benjamin", ""], ["Sukhatme", "Gaurav S.", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""], ["Hausman", "Karol", ""]]}, {"id": "2004.10240", "submitter": "Konstantinos Benidis", "authors": "Konstantinos Benidis, Syama Sundar Rangapuram, Valentin Flunkert,\n  Bernie Wang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael\n  Bohlke-Schneider, David Salinas, Lorenzo Stella, Laurent Callot, Tim\n  Januschowski", "title": "Neural forecasting: Introduction and literature overview", "comments": "66 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based forecasting methods have become ubiquitous in\nlarge-scale industrial forecasting applications over the last years. As the\nprevalence of neural network based solutions among the best entries in the\nrecent M4 competition shows, the recent popularity of neural forecasting\nmethods is not limited to industry and has also reached academia. This article\naims at providing an introduction and an overview of some of the advances that\nhave permitted the resurgence of neural networks in machine learning. Building\non these foundations, the article then gives an overview of the recent\nliterature on neural networks for forecasting and applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 18:53:42 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Benidis", "Konstantinos", ""], ["Rangapuram", "Syama Sundar", ""], ["Flunkert", "Valentin", ""], ["Wang", "Bernie", ""], ["Maddix", "Danielle", ""], ["Turkmen", "Caner", ""], ["Gasthaus", "Jan", ""], ["Bohlke-Schneider", "Michael", ""], ["Salinas", "David", ""], ["Stella", "Lorenzo", ""], ["Callot", "Laurent", ""], ["Januschowski", "Tim", ""]]}, {"id": "2004.10245", "submitter": "Daphney-Stavroula Zois", "authors": "Yasitha Warahena Liyanage, Daphney-Stavroula Zois, Charalampos Chelmis", "title": "On-the-Fly Joint Feature Selection and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint feature selection and classification in an online setting is essential\nfor time-sensitive decision making. However, most existing methods treat this\ncoupled problem independently. Specifically, online feature selection methods\ncan handle either streaming features or data instances offline to produce a\nfixed set of features for classification, while online classification methods\nclassify incoming instances using full knowledge about the feature space.\nNevertheless, all existing methods utilize a set of features, common for all\ndata instances, for classification. Instead, we propose a framework to perform\njoint feature selection and classification on-the-fly, so as to minimize the\nnumber of features evaluated for every data instance and maximize\nclassification accuracy. We derive the optimum solution of the associated\noptimization problem and analyze its structure. Two algorithms are proposed,\nETANA and F-ETANA, which are based on the optimum solution and its properties.\nWe evaluate the performance of the proposed algorithms on several public\ndatasets, demonstrating (i) the dominance of the proposed algorithms over the\nstate-of-the-art, and (ii) its applicability to broad range of application\ndomains including clinical research and natural language processing.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:19:39 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Liyanage", "Yasitha Warahena", ""], ["Zois", "Daphney-Stavroula", ""], ["Chelmis", "Charalampos", ""]]}, {"id": "2004.10250", "submitter": "David Evans", "authors": "Mainuddin Ahmad Jonas, David Evans", "title": "Certifying Joint Adversarial Robustness for Model Ensembles", "comments": "Open source code for our implementation and for reproducing our\n  experiments is available at\n  https://github.com/jonas-maj/ensemble-adversarial-robustness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are often vulnerable to adversarial\nexamples.Several proposed defenses deploy an ensemble of models with the hope\nthat, although the individual models may be vulnerable, an adversary will not\nbe able to find an adversarial example that succeeds against the ensemble.\nDepending on how the ensemble is used, an attacker may need to find a single\nadversarial example that succeeds against all, or a majority, of the models in\nthe ensemble. The effectiveness of ensemble defenses against strong adversaries\ndepends on the vulnerability spaces of models in the ensemble being disjoint.\nWe consider the joint vulnerability of an ensemble of models, and propose a\nnovel technique for certifying the joint robustness of ensembles, building upon\nprior works on single-model robustness certification. We evaluate the\nrobustness of various models ensembles, including models trained using\ncost-sensitive robustness to be diverse, to improve understanding of the\npotential effectiveness of ensemble models as a defense against adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:38:31 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Jonas", "Mainuddin Ahmad", ""], ["Evans", "David", ""]]}, {"id": "2004.10255", "submitter": "Yonatan Woodbridge", "authors": "Yonatan Woodbridge, Gal Elidan and Ami Wiesel", "title": "Convex Nonparanormal Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying uncertainty in predictions or, more generally, estimating the\nposterior conditional distribution, is a core challenge in machine learning and\nstatistics. We introduce Convex Nonparanormal Regression (CNR), a conditional\nnonparanormal approach for coping with this task. CNR involves a convex\noptimization of a posterior defined via a rich dictionary of pre-defined non\nlinear transformations on Gaussians. It can fit an arbitrary conditional\ndistribution, including multimodal and non-symmetric posteriors. For the\nspecial but powerful case of a piecewise linear dictionary, we provide a closed\nform of the posterior mean which can be used for point-wise predictions.\nFinally, we demonstrate the advantages of CNR over classical competitors using\nsynthetic and real world data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:42:43 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 05:46:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Woodbridge", "Yonatan", ""], ["Elidan", "Gal", ""], ["Wiesel", "Ami", ""]]}, {"id": "2004.10267", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Yaqing Wang, Changyou Chen, Jing Gao", "title": "Decomposed Adversarial Learned Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective inference for a generative adversarial model remains an important\nand challenging problem. We propose a novel approach, Decomposed Adversarial\nLearned Inference (DALI), which explicitly matches prior and conditional\ndistributions in both data and code spaces, and puts a direct constraint on the\ndependency structure of the generative model. We derive an equivalent form of\nthe prior and conditional matching objective that can be optimized efficiently\nwithout any parametric assumption on the data. We validate the effectiveness of\nDALI on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative and\nqualitative evaluations. Results demonstrate that DALI significantly improves\nboth reconstruction and generation as compared to other adversarial inference\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:00:35 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Wang", "Yaqing", ""], ["Chen", "Changyou", ""], ["Gao", "Jing", ""]]}, {"id": "2004.10281", "submitter": "Matthew Wicker", "authors": "Matthew Wicker, Luca Laurenti, Andrea Patane, Marta Kwiatkowska", "title": "Probabilistic Safety for Bayesian Neural Networks", "comments": "UAI 2020; 13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistic safety for Bayesian Neural Networks (BNNs) under\nadversarial input perturbations. Given a compact set of input points, $T\n\\subseteq \\mathbb{R}^m$, we study the probability w.r.t. the BNN posterior that\nall the points in $T$ are mapped to the same region $S$ in the output space. In\nparticular, this can be used to evaluate the probability that a network sampled\nfrom the BNN is vulnerable to adversarial attacks. We rely on relaxation\ntechniques from non-convex optimization to develop a method for computing a\nlower bound on probabilistic safety for BNNs, deriving explicit procedures for\nthe case of interval and linear function propagation techniques. We apply our\nmethods to BNNs trained on a regression task, airborne collision avoidance, and\nMNIST, empirically showing that our approach allows one to certify\nprobabilistic safety of BNNs with millions of parameters.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:25:33 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 02:06:15 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2004.10337", "submitter": "Paul Zivich", "authors": "Paul N Zivich, Alexander Breskin", "title": "Machine learning for causal inference: on the use of cross-fit\n  estimators", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": "10.1097/EDE.0000000000001332", "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern causal inference methods allow machine learning to be used to weaken\nparametric modeling assumptions. However, the use of machine learning may\nresult in complications for inference. Doubly-robust cross-fit estimators have\nbeen proposed to yield better statistical properties.\n  We conducted a simulation study to assess the performance of several\ndifferent estimators for the average causal effect (ACE). The data generating\nmechanisms for the simulated treatment and outcome included log-transforms,\npolynomial terms, and discontinuities. We compared singly-robust estimators\n(g-computation, inverse probability weighting) and doubly-robust estimators\n(augmented inverse probability weighting, targeted maximum likelihood\nestimation). Nuisance functions were estimated with parametric models and\nensemble machine learning, separately. We further assessed doubly-robust\ncross-fit estimators.\n  With correctly specified parametric models, all of the estimators were\nunbiased and confidence intervals achieved nominal coverage. When used with\nmachine learning, the doubly-robust cross-fit estimators substantially\noutperformed all of the other estimators in terms of bias, variance, and\nconfidence interval coverage.\n  Due to the difficulty of properly specifying parametric models in high\ndimensional data, doubly-robust estimators with ensemble learning and\ncross-fitting may be the preferred approach for estimation of the ACE in most\nepidemiologic studies. However, these approaches may require larger sample\nsizes to avoid finite-sample issues.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:09:55 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 15:40:04 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 15:21:23 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 19:30:14 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zivich", "Paul N", ""], ["Breskin", "Alexander", ""]]}, {"id": "2004.10342", "submitter": "Ankit Singh Rawat", "authors": "Felix X. Yu, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar", "title": "Federated Learning with Only Positive Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning a multi-class classification model in the federated\nsetting, where each user has access to the positive data associated with only a\nsingle class. As a result, during each federated learning round, the users need\nto locally update the classifier without having access to the features and the\nmodel parameters for the negative classes. Thus, naively employing conventional\ndecentralized learning such as the distributed SGD or Federated Averaging may\nlead to trivial or extremely poor classifiers. In particular, for the embedding\nbased classifiers, all the class embeddings might collapse to a single point.\n  To address this problem, we propose a generic framework for training with\nonly positive labels, namely Federated Averaging with Spreadout (FedAwS), where\nthe server imposes a geometric regularizer after each round to encourage\nclasses to be spreadout in the embedding space. We show, both theoretically and\nempirically, that FedAwS can almost match the performance of conventional\nlearning where users have access to negative labels. We further extend the\nproposed method to the settings with large output spaces.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:35:02 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Yu", "Felix X.", ""], ["Rawat", "Ankit Singh", ""], ["Menon", "Aditya Krishna", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2004.10356", "submitter": "Denis Dos Reis", "authors": "Denis dos Reis, Marc\\'ilio de Souto, Elaine de Sousa, Gustavo Batista", "title": "Quantifying With Only Positive Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is the research field that studies the task of counting how\nmany data points belong to each class in an unlabeled sample. Traditionally,\nresearchers in this field assume the availability of training data containing\nlabeled observations for all classes to induce quantification models. Although\nquantification methods usually estimate counts for every class, we are often\ninterested in those regarding only a target class. In this context, we have\nproposed a novel setting, known as One-class Quantification (OCQ), where\nreliable training data is only available for the target class. On the other\nhand, Positive and Unlabeled Learning (PUL), which is another branch of Machine\nLearning, has offered solutions that can be applied to OCQ, despite\nquantification not being the focal point of PUL. In this article, we close the\ngap between PUL and OCQ and bring both areas together under a unified view. We\ncompare our methods, Passive Aggressive Threshold (PAT) and One Distribution\nInside (ODIn), against PUL methods and show that PAT generally is the fastest\nand most accurate algorithm. Contrary to PUL methods, PAT and ODIn also can\ninduce quantification models that can be replied to quantify different samples\nof data. We additionally introduce Exhaustive TIcE (ExTIcE), an improved\nversion of the PUL algorithm Tree Induction for c Estimation (TIcE), and show\nthat it quantifies more accurately than PAT and the other algorithms in\nscenarios where a considerable number of negative observations are identical to\npositive observations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 01:18:25 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Reis", "Denis dos", ""], ["de Souto", "Marc\u00edlio", ""], ["de Sousa", "Elaine", ""], ["Batista", "Gustavo", ""]]}, {"id": "2004.10386", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Cheng Li, Antonio Robles-Kelly and Mohan Kankanhalli", "title": "Hierarchically Fair Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the federated learning is adopted among competitive agents with siloed\ndatasets, agents are self-interested and participate only if they are fairly\nrewarded. To encourage the application of federated learning, this paper\nemploys a management strategy, i.e., more contributions should lead to more\nrewards. We propose a novel hierarchically fair federated learning (HFFL)\nframework. Under this framework, agents are rewarded in proportion to their\npre-negotiated contribution levels. HFFL+ extends this to incorporate\nheterogeneous models. Theoretical analysis and empirical evaluation on several\ndatasets confirm the efficacy of our frameworks in upholding fairness and thus\nfacilitating federated learning in the competitive settings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:41:06 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 11:42:33 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Li", "Cheng", ""], ["Robles-Kelly", "Antonio", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2004.10387", "submitter": "Qing Han", "authors": "Qing Han, Shusen Yang, Xuebin Ren, Cong Zhao, Jingqi Zhang, Xinyu Yang", "title": "OL4EL: Online Learning for Edge-cloud Collaborative Learning on\n  Heterogeneous Edges with Resource Constraints", "comments": "7 pages, 5 figures, to appear in IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning (ML) at network edge is a promising paradigm\nthat can preserve both network bandwidth and privacy of data providers.\nHowever, heterogeneous and limited computation and communication resources on\nedge servers (or edges) pose great challenges on distributed ML and formulate a\nnew paradigm of Edge Learning (i.e. edge-cloud collaborative machine learning).\nIn this article, we propose a novel framework of 'learning to learn' for\neffective Edge Learning (EL) on heterogeneous edges with resource constraints.\nWe first model the dynamic determination of collaboration strategy (i.e. the\nallocation of local iterations at edge servers and global aggregations on the\nCloud during collaborative learning process) as an online optimization problem\nto achieve the tradeoff between the performance of EL and the resource\nconsumption of edge servers. Then, we propose an Online Learning for EL (OL4EL)\nframework based on the budget-limited multi-armed bandit model. OL4EL supports\nboth synchronous and asynchronous learning patterns, and can be used for both\nsupervised and unsupervised learning tasks. To evaluate the performance of\nOL4EL, we conducted both real-world testbed experiments and extensive\nsimulations based on docker containers, where both Support Vector Machine and\nK-means were considered as use cases. Experimental results demonstrate that\nOL4EL significantly outperforms state-of-the-art EL and other collaborative ML\napproaches in terms of the trade-off between learning performance and resource\nconsumption.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:51:58 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 08:13:55 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Han", "Qing", ""], ["Yang", "Shusen", ""], ["Ren", "Xuebin", ""], ["Zhao", "Cong", ""], ["Zhang", "Jingqi", ""], ["Yang", "Xinyu", ""]]}, {"id": "2004.10390", "submitter": "Yang Guo", "authors": "Xi Wu, Yang Guo, Jiefeng Chen, Yingyu Liang, Somesh Jha, Prasad\n  Chalasani", "title": "Representation Bayesian Risk Decompositions and Multi-Source Domain\n  Adaptation", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider representation learning (hypothesis class $\\mathcal{H} =\n\\mathcal{F}\\circ\\mathcal{G}$) where training and test distributions can be\ndifferent. Recent studies provide hints and failure examples for domain\ninvariant representation learning, a common approach for this problem, but the\nexplanations provided are somewhat different and do not provide a unified\npicture. In this paper, we provide new decompositions of risk which give\nfiner-grained explanations and clarify potential generalization issues. For\nSingle-Source Domain Adaptation, we give an exact decomposition (an equality)\nof the target risk, via a natural hybrid argument, as sum of three factors: (1)\nsource risk, (2) representation conditional label divergence, and (3)\nrepresentation covariate shift. We derive a similar decomposition for the\nMulti-Source case. These decompositions reveal factors (2) and (3) as the\nprecise reasons for failure to generalize. For example, we demonstrate that\ndomain adversarial neural networks (DANN) attempt to regularize for (3) but\nmiss (2), while a recent technique Invariant Risk Minimization (IRM) attempts\nto account for (2) but does not consider (3). We also verify our observations\nexperimentally.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 04:09:21 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 02:25:37 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wu", "Xi", ""], ["Guo", "Yang", ""], ["Chen", "Jiefeng", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""], ["Chalasani", "Prasad", ""]]}, {"id": "2004.10397", "submitter": "Wenqi Wei", "authors": "Wenqi Wei, Ling Liu, Margaret Loper, Ka-Ho Chow, Mehmet Emre Gursoy,\n  Stacey Truex and Yanzhao Wu", "title": "A Framework for Evaluating Gradient Leakage Attacks in Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging distributed machine learning framework\nfor collaborative model training with a network of clients (edge devices). FL\noffers default client privacy by allowing clients to keep their sensitive data\non local devices and to only share local training parameter updates with the\nfederated server. However, recent studies have shown that even sharing local\nparameter updates from a client to the federated server may be susceptible to\ngradient leakage attacks and intrude the client privacy regarding its training\ndata. In this paper, we present a principled framework for evaluating and\ncomparing different forms of client privacy leakage attacks. We first provide\nformal and experimental analysis to show how adversaries can reconstruct the\nprivate local training data by simply analyzing the shared parameter update\nfrom local training (e.g., local gradient or weight update vector). We then\nanalyze how different hyperparameter configurations in federated learning and\ndifferent settings of the attack algorithm may impact on both attack\neffectiveness and attack cost. Our framework also measures, evaluates, and\nanalyzes the effectiveness of client privacy leakage attacks under different\ngradient compression ratios when using communication efficient FL protocols.\nOur experiments also include some preliminary mitigation strategies to\nhighlight the importance of providing a systematic attack evaluation framework\ntowards an in-depth understanding of the various forms of client privacy\nleakage threats in federated learning and developing theoretical foundations\nfor attack mitigation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 05:15:03 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 04:31:26 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""], ["Loper", "Margaret", ""], ["Chow", "Ka-Ho", ""], ["Gursoy", "Mehmet Emre", ""], ["Truex", "Stacey", ""], ["Wu", "Yanzhao", ""]]}, {"id": "2004.10398", "submitter": "Min-hwan Oh", "authors": "Min-hwan Oh, Garud Iyengar", "title": "Sequential Anomaly Detection using Inverse Reinforcement Learning", "comments": "Published in KDD 2019 (Oral in Research Paper Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most interesting application scenarios in anomaly detection is\nwhen sequential data are targeted. For example, in a safety-critical\nenvironment, it is crucial to have an automatic detection system to screen the\nstreaming data gathered by monitoring sensors and to report abnormal\nobservations if detected in real-time. Oftentimes, stakes are much higher when\nthese potential anomalies are intentional or goal-oriented. We propose an\nend-to-end framework for sequential anomaly detection using inverse\nreinforcement learning (IRL), whose objective is to determine the\ndecision-making agent's underlying function which triggers his/her behavior.\nThe proposed method takes the sequence of actions of a target agent (and\npossibly other meta information) as input. The agent's normal behavior is then\nunderstood by the reward function which is inferred via IRL. We use a neural\nnetwork to represent a reward function. Using a learned reward function, we\nevaluate whether a new observation from the target agent follows a normal\npattern. In order to construct a reliable anomaly detection method and take\ninto consideration the confidence of the predicted anomaly score, we adopt a\nBayesian approach for IRL. The empirical study on publicly available real-world\ndata shows that our proposed method is effective in identifying anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 05:17:36 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Oh", "Min-hwan", ""], ["Iyengar", "Garud", ""]]}, {"id": "2004.10410", "submitter": "Joeran Beel", "authors": "Mark Grennan, Joeran Beel", "title": "Synthetic vs. Real Reference Strings for Citation Parsing, and the\n  Importance of Re-training and Out-Of-Sample Data for Meaningful Evaluations:\n  Experiments with GROBID, GIANT and Cora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation parsing, particularly with deep neural networks, suffers from a lack\nof training data as available datasets typically contain only a few thousand\ntraining instances. Manually labelling citation strings is very time-consuming,\nhence synthetically created training data could be a solution. However, as of\nnow, it is unknown if synthetically created reference-strings are suitable to\ntrain machine learning algorithms for citation parsing. To find out, we train\nGrobid, which uses Conditional Random Fields, with a) human-labelled reference\nstrings from 'real' bibliographies and b) synthetically created reference\nstrings from the GIANT dataset. We find that both synthetic and organic\nreference strings are equally suited for training Grobid (F1 = 0.74). We\nadditionally find that retraining Grobid has a notable impact on its\nperformance, for both synthetic and real data (+30% in F1). Having as many\ntypes of labelled fields as possible during training also improves\neffectiveness, even if these fields are not available in the evaluation data\n(+13.5% F1). We conclude that synthetic data is suitable for training (deep)\ncitation parsing models. We further suggest that in future evaluations of\nreference parsers both evaluation data similar and dissimilar to the training\ndata should be used for more meaningful evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 06:34:36 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 14:36:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Grennan", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "2004.10468", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "SoQal: Selective Oracle Questioning in Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Large sets of unlabelled data within the healthcare domain remain\nunderutilized. Active learning offers a way to exploit these datasets by\niteratively requesting an oracle (e.g. medical professional) to label\ninstances. This process, which can be costly and time-consuming is\noverly-dependent upon an oracle. To alleviate this burden, we propose SoQal, a\nquestioning strategy that dynamically determines when a label should be\nrequested from an oracle. We perform experiments on five publically-available\ndatasets and illustrate SoQal's superiority relative to baseline approaches,\nincluding its ability to reduce oracle label requests by up to 35%. SoQal also\nperforms competitively in the presence of label noise: a scenario that\nsimulates clinicians' uncertain diagnoses when faced with difficult\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:53:55 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2004.10484", "submitter": "Gary Goh", "authors": "Gary S. W. Goh, Sebastian Lapuschkin, Leander Weber, Wojciech Samek,\n  Alexander Binder", "title": "Understanding Integrated Gradients with SmoothTaylor for Deep Neural\n  Network Attribution", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated gradients as an attribution method for deep neural network models\noffers simple implementability. However, it also suffers from noisiness of\nexplanations, which affects the ease of interpretability. In this paper, we\npresent Smooth Integrated Gradients as a statistically improved attribution\nmethod inspired by Taylor's theorem, which does not require a fixed baseline to\nbe chosen. We apply both methods to the image classification problem, using the\nILSVRC2012 ImageNet object recognition dataset, and a couple of pretrained\nimage models to generate attribution maps of their predictions. These\nattribution maps are visualized by saliency maps which can be evaluated\nqualitatively. We also empirically evaluate them using quantitative metrics\nsuch as perturbations-based score drops and multi-scaled total variance. We\nfurther propose adaptive noising to optimize for the noise scale hyperparameter\nvalue in our proposed method. From our experiments, we find that the Smooth\nIntegrated Gradients approach together with adaptive noising is able to\ngenerate better quality saliency maps with lesser noise and higher sensitivity\nto the relevant points in the input space.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 10:43:19 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Goh", "Gary S. W.", ""], ["Lapuschkin", "Sebastian", ""], ["Weber", "Leander", ""], ["Samek", "Wojciech", ""], ["Binder", "Alexander", ""]]}, {"id": "2004.10495", "submitter": "Dong Wang", "authors": "Dong Wang, Xiaoqian Qin, Fengyi Song, Li Cheng", "title": "Stabilizing Training of Generative Adversarial Nets via Langevin Stein\n  Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs), famous for the capability of learning\ncomplex underlying data distribution, are however known to be tricky in the\ntraining process, which would probably result in mode collapse or performance\ndeterioration. Current approaches of dealing with GANs' issues almost utilize\nsome practical training techniques for the purpose of regularization, which on\nthe other hand undermines the convergence and theoretical soundness of GAN. In\nthis paper, we propose to stabilize GAN training via a novel particle-based\nvariational inference -- Langevin Stein variational gradient descent (LSVGD),\nwhich not only inherits the flexibility and efficiency of original SVGD but\naims to address its instability issues by incorporating an extra disturbance\ninto the update dynamics. We further demonstrate that by properly adjusting the\nnoise variance, LSVGD simulates a Langevin process whose stationary\ndistribution is exactly the target distribution. We also show that LSVGD\ndynamics has an implicit regularization which is able to enhance particles'\nspread-out and diversity. At last we present an efficient way of applying\nparticle-based variational inference on a general GAN training procedure no\nmatter what loss function is adopted. Experimental results on one synthetic\ndataset and three popular benchmark datasets -- Cifar-10, Tiny-ImageNet and\nCelebA validate that LSVGD can remarkably improve the performance and stability\nof various GAN models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:20:04 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Dong", ""], ["Qin", "Xiaoqian", ""], ["Song", "Fengyi", ""], ["Cheng", "Li", ""]]}, {"id": "2004.10521", "submitter": "Ezequiel Smucler", "authors": "Ezequiel Smucler, Facundo Sapienza and Andrea Rotnitzky", "title": "Efficient adjustment sets in causal graphical models with hidden\n  variables", "comments": "Fixed an error in Example 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the selection of covariate adjustment sets for estimating the value\nof point exposure dynamic policies, also known as dynamic treatment regimes,\nassuming a non-parametric causal graphical model with hidden variables, in\nwhich at least one adjustment set is fully observable. We show that recently\ndeveloped criteria, for graphs without hidden variables, to compare the\nasymptotic variance of non-parametric estimators of static policy values that\ncontrol for certain adjustment sets, are also valid under dynamic policies and\ngraphs with hidden variables. We show that there exist adjustment sets that are\noptimal minimal (minimum), in the sense of yielding estimators with the\nsmallest variance among those that control for adjustment sets that are minimal\n(of minimum cardinality). Moreover, we show that if either no variables are\nhidden or if all the observable variables are ancestors of either treatment,\noutcome, or the variables that are used to decide treatment, a globally optimal\nadjustment set exists. We provide polynomial time algorithms to compute the\nglobally optimal (when it exists), optimal minimal, and optimal minimum\nadjustment sets. Our results are based on the construction of an undirected\ngraph in which vertex cuts between the treatment and outcome variables\ncorrespond to adjustment sets. In this undirected graph, a partial order\nbetween minimal vertex cuts can be defined that makes the set of minimal cuts a\nlattice. This partial order corresponds directly to the ordering of the\nasymptotic variances of the corresponding non-parametrically adjusted\nestimators.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:22:01 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 14:50:19 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 15:32:54 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Smucler", "Ezequiel", ""], ["Sapienza", "Facundo", ""], ["Rotnitzky", "Andrea", ""]]}, {"id": "2004.10522", "submitter": "Lucie Perrotta", "authors": "Lucie Perrotta", "title": "Practical calibration of the temperature parameter in Gibbs posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PAC-Bayesian algorithms and Gibbs posteriors are gaining popularity due to\ntheir robustness against model misspecification even when Bayesian inference is\ninconsistent. The PAC-Bayesian alpha-posterior is a generalization of the\nstandard Bayes posterior which can be tempered with a parameter alpha to handle\ninconsistency. Data driven methods for tuning alpha have been proposed but are\nstill few, and are often computationally heavy. Additionally, the adequacy of\nthese methods in cases where we use variational approximations instead of exact\nalpha-posteriors is not clear. This narrows their usage to simple models and\nprevents their application to large-scale problems. We hence need fast methods\nto tune alpha that work with both exact and variational alpha-posteriors.\nFirst, we propose two data driven methods for tuning alpha, based on\nsample-splitting and bootstrapping respectively. Second, we formulate the\n(exact or variational) posteriors of three popular statistical models, and\nmodify them into alpha-posteriors. For each model, we test our strategies and\ncompare them with standard Bayes and Grunwald's SafeBayes. While bootstrapping\nachieves mixed results, sample-splitting and SafeBayes perform well on the\nexact and variational alpha-posteriors we describe, and achieve better results\nthan standard Bayes in misspecified or complex models. Additionally,\nsample-splitting outperforms SafeBayes in terms of speed. Sample-splitting\noffers a fast and easy solution to inconsistency and typically performs\nsimilarly or better than Bayesian inference. Our results provide hints on the\ncalibration of alpha in PAC-Bayesian and Gibbs posteriors, and may facilitate\nusing these methods in large and complex models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:23:45 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Perrotta", "Lucie", ""]]}, {"id": "2004.10536", "submitter": "Iris Huijben", "authors": "Iris A.M. Huijben, Bastiaan S. Veeling, and Ruud J.G. van Sloun", "title": "Learning Sampling and Model-Based Signal Recovery for Compressed Sensing\n  MRI", "comments": null, "journal-ref": "In ICASSP 2020-2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9053331", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) MRI relies on adequate undersampling of the k-space\nto accelerate the acquisition without compromising image quality. Consequently,\nthe design of optimal sampling patterns for these k-space coefficients has\nreceived significant attention, with many CS MRI methods exploiting\nvariable-density probability distributions. Realizing that an optimal sampling\npattern may depend on the downstream task (e.g. image reconstruction,\nsegmentation, or classification), we here propose joint learning of both\ntask-adaptive k-space sampling and a subsequent model-based proximal-gradient\nrecovery network. The former is enabled through a probabilistic generative\nmodel that leverages the Gumbel-softmax relaxation to sample across trainable\nbeliefs while maintaining differentiability. The proposed combination of a\nhighly flexible sampling model and a model-based (sampling-adaptive) image\nreconstruction network facilitates exploration and efficient training, yielding\nimproved MR image quality compared to other sampling baselines.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:50:03 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Huijben", "Iris A. M.", ""], ["Veeling", "Bastiaan S.", ""], ["van Sloun", "Ruud J. G.", ""]]}, {"id": "2004.10537", "submitter": "Dominik Martin", "authors": "Dominik Martin, Philipp Spitzer, Niklas K\\\"uhl", "title": "A New Metric for Lumpy and Intermittent Demand Forecasts:\n  Stock-keeping-oriented Prediction Error Costs", "comments": "Proceedings of the 53rd Annual Hawaii International Conference on\n  System Sciences (HICSS-53), Grand Wailea, Maui, HI, January 7-10, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasts of product demand are essential for short- and long-term\noptimization of logistics and production. Thus, the most accurate prediction\npossible is desirable. In order to optimally train predictive models, the\ndeviation of the forecast compared to the actual demand needs to be assessed by\na proper metric. However, if a metric does not represent the actual prediction\nerror, predictive models are insufficiently optimized and, consequently, will\nyield inaccurate predictions. The most common metrics such as MAPE or RMSE,\nhowever, are not suitable for the evaluation of forecasting errors, especially\nfor lumpy and intermittent demand patterns, as they do not sufficiently account\nfor, e.g., temporal shifts (prediction before or after actual demand) or\ncost-related aspects. Therefore, we propose a novel metric that, in addition to\nstatistical considerations, also addresses business aspects. Additionally, we\nevaluate the metric based on simulated and real demand time series from the\nautomotive aftermarket.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:50:24 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Martin", "Dominik", ""], ["Spitzer", "Philipp", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2004.10568", "submitter": "Markus Nagel", "authors": "Markus Nagel, Rana Ali Amjad, Mart van Baalen, Christos Louizos,\n  Tijmen Blankevoort", "title": "Up or Down? Adaptive Rounding for Post-Training Quantization", "comments": "Published as a conference paper at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When quantizing neural networks, assigning each floating-point weight to its\nnearest fixed-point value is the predominant approach. We find that, perhaps\nsurprisingly, this is not the best we can do. In this paper, we propose\nAdaRound, a better weight-rounding mechanism for post-training quantization\nthat adapts to the data and the task loss. AdaRound is fast, does not require\nfine-tuning of the network, and only uses a small amount of unlabelled data. We\nstart by theoretically analyzing the rounding problem for a pre-trained neural\nnetwork. By approximating the task loss with a Taylor series expansion, the\nrounding task is posed as a quadratic unconstrained binary optimization\nproblem. We simplify this to a layer-wise local loss and propose to optimize\nthis loss with a soft relaxation. AdaRound not only outperforms\nrounding-to-nearest by a significant margin but also establishes a new\nstate-of-the-art for post-training quantization on several networks and tasks.\nWithout fine-tuning, we can quantize the weights of Resnet18 and Resnet50 to 4\nbits while staying within an accuracy loss of 1%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 13:44:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:51:23 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Nagel", "Markus", ""], ["Amjad", "Rana Ali", ""], ["van Baalen", "Mart", ""], ["Louizos", "Christos", ""], ["Blankevoort", "Tijmen", ""]]}, {"id": "2004.10586", "submitter": "Sam Coveney Dr", "authors": "Sam Coveney, Cesare Corrado, Caroline H Roney, Daniel O'Hare, Steven E\n  Williams, Mark D O'Neill, Steven A Niederer, Richard H Clayton, Jeremy E\n  Oakley, Richard D Wilkinson", "title": "Gaussian Process Manifold Interpolation for Probabilistic Atrial\n  Activation Maps and Uncertain Conduction Velocity", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2019.0345", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In patients with atrial fibrillation, local activation time (LAT) maps are\nroutinely used for characterising patient pathophysiology. The gradient of LAT\nmaps can be used to calculate conduction velocity (CV), which directly relates\nto material conductivity and may provide an important measure of atrial\nsubstrate properties. Including uncertainty in CV calculations would help with\ninterpreting the reliability of these measurements. Here, we build upon a\nrecent insight into reduced-rank Gaussian processes (GP) to perform\nprobabilistic interpolation of uncertain LAT directly on human atrial\nmanifolds. Our Gaussian Process Manifold Interpolation (GPMI) method accounts\nfor the topology of the atria, and allows for calculation of statistics for\npredicted CV. We demonstrate our method on two clinical cases, and perform\nvalidation against a simulated ground truth. CV uncertainty depends on data\ndensity, wave propagation direction, and CV magnitude. GPMI is suitable for\nprobabilistic interpolation of other uncertain quantities on non-Euclidean\nmanifolds.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:10:05 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 10:57:59 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Coveney", "Sam", ""], ["Corrado", "Cesare", ""], ["Roney", "Caroline H", ""], ["O'Hare", "Daniel", ""], ["Williams", "Steven E", ""], ["O'Neill", "Mark D", ""], ["Niederer", "Steven A", ""], ["Clayton", "Richard H", ""], ["Oakley", "Jeremy E", ""], ["Wilkinson", "Richard D", ""]]}, {"id": "2004.10599", "submitter": "Antoine Blanchard", "authors": "Antoine Blanchard and Themistoklis Sapsis", "title": "Bayesian Optimization with Output-Weighted Optimal Sampling", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109901", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian optimization, accounting for the importance of the output\nrelative to the input is a crucial yet challenging exercise, as it can\nconsiderably improve the final result but often involves inaccurate and\ncumbersome entropy estimations. We approach the problem from the perspective of\nimportance-sampling theory, and advocate the use of the likelihood ratio to\nguide the search algorithm towards regions of the input space where the\nobjective function to be minimized assumes abnormally small values. The\nlikelihood ratio acts as a sampling weight and can be computed at each\niteration without severely deteriorating the overall efficiency of the\nalgorithm. In particular, it can be approximated in a way that makes the\napproach tractable in high dimensions. The \"likelihood-weighted\" acquisition\nfunctions introduced in this work are found to outperform their unweighted\ncounterparts in a number of applications.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:38:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 16:37:03 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 15:54:17 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 21:58:21 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Blanchard", "Antoine", ""], ["Sapsis", "Themistoklis", ""]]}, {"id": "2004.10603", "submitter": "Yang Zhao", "authors": "Yang Zhao, Ping Yu, Suchismit Mahapatra, Qinliang Su and Changyou Chen", "title": "Improve Variational Autoencoder for Text Generationwith Discrete Latent\n  Bottleneck", "comments": "replaced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are essential tools in end-to-end\nrepresentation learning. However, the sequential text generation common pitfall\nwith VAEs is that the model tends to ignore latent variables with a strong\nauto-regressive decoder. In this paper, we propose a principled approach to\nalleviate this issue by applying a discretized bottleneck to enforce an\nimplicit latent feature matching in a more compact latent space. We impose a\nshared discrete latent space where each input is learned to choose a\ncombination of latent atoms as a regularized latent representation. Our model\nendows a promising capability to model underlying semantics of discrete\nsequences and thus provide more interpretative latent structures. Empirically,\nwe demonstrate our model's efficiency and effectiveness on a broad range of\ntasks, including language modeling, unaligned text style transfer, dialog\nresponse generation, and neural machine translation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:41:37 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:16:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zhao", "Yang", ""], ["Yu", "Ping", ""], ["Mahapatra", "Suchismit", ""], ["Su", "Qinliang", ""], ["Chen", "Changyou", ""]]}, {"id": "2004.10605", "submitter": "Ioan-Adrian Cosma Mr.", "authors": "Adrian Cosma, Mihai Ghidoveanu, Michael Panaitescu-Liess and Marius\n  Popescu", "title": "Self-Supervised Representation Learning on Document Images", "comments": "15 pages, 5 figures. Accepted at DAS 2020: IAPR International\n  Workshop on Document Analysis Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work analyses the impact of self-supervised pre-training on document\nimages in the context of document image classification. While previous\napproaches explore the effect of self-supervision on natural images, we show\nthat patch-based pre-training performs poorly on document images because of\ntheir different structural properties and poor intra-sample semantic\ninformation. We propose two context-aware alternatives to improve performance\non the Tobacco-3482 image classification task. We also propose a novel method\nfor self-supervision, which makes use of the inherent multi-modality of\ndocuments (image and text), which performs better than other popular\nself-supervised methods, including supervised ImageNet pre-training, on\ndocument image classification scenarios with a limited amount of data.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 10:14:06 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 08:48:48 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Cosma", "Adrian", ""], ["Ghidoveanu", "Mihai", ""], ["Panaitescu-Liess", "Michael", ""], ["Popescu", "Marius", ""]]}, {"id": "2004.10608", "submitter": "Filipe Condessa", "authors": "Filipe Condessa, Zico Kolter", "title": "Provably robust deep generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in adversarial attacks has developed provably robust methods for\ntraining deep neural network classifiers. However, although they are often\nmentioned in the context of robustness, deep generative models themselves have\nreceived relatively little attention in terms of formally analyzing their\nrobustness properties. In this paper, we propose a method for training provably\nrobust generative models, specifically a provably robust version of the\nvariational auto-encoder (VAE). To do so, we first formally define a\n(certifiably) robust lower bound on the variational lower bound of the\nlikelihood, and then show how this bound can be optimized during training to\nproduce a robust VAE. We evaluate the method on simple examples, and show that\nit is able to produce generative models that are substantially more robust to\nadversarial attacks (i.e., an adversary trying to perturb inputs so as to\ndrastically lower their likelihood under the model).\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:47:41 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Condessa", "Filipe", ""], ["Kolter", "Zico", ""]]}, {"id": "2004.10618", "submitter": "Werner Zellinger", "authors": "Werner Zellinger", "title": "Moment-Based Domain Adaptation: Learning Bounds and Algorithms", "comments": "Doctoral Thesis developed at the Department of Knowledge-Based\n  Mathematical Systems at the Johannes Kepler University Linz under the\n  supervision of Susanne Saminger-Platz and Bernhard Moser", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis contributes to the mathematical foundation of domain adaptation\nas emerging field in machine learning. In contrast to classical statistical\nlearning, the framework of domain adaptation takes into account deviations\nbetween probability distributions in the training and application setting.\nDomain adaptation applies for a wider range of applications as future samples\noften follow a distribution that differs from the ones of the training samples.\nA decisive point is the generality of the assumptions about the similarity of\nthe distributions. Therefore, in this thesis we study domain adaptation\nproblems under as weak similarity assumptions as can be modelled by finitely\nmany moments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:59:08 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Zellinger", "Werner", ""]]}, {"id": "2004.10629", "submitter": "Stefan T. Radev", "authors": "Stefan T. Radev, Marco D'Alessandro, Ulf K. Mertens, Andreas Voss,\n  Ullrich K\\\"othe, Paul-Christian B\\\"urkner", "title": "Amortized Bayesian model comparison with evidential deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Comparing competing mathematical models of complex natural processes is a\nshared goal among many branches of science. The Bayesian probabilistic\nframework offers a principled way to perform model comparison and extract\nuseful metrics for guiding decisions. However, many interesting models are\nintractable with standard Bayesian methods, as they lack a closed-form\nlikelihood function or the likelihood is computationally too expensive to\nevaluate. With this work, we propose a novel method for performing Bayesian\nmodel comparison using specialized deep learning architectures. Our method is\npurely simulation-based and circumvents the step of explicitly fitting all\nalternative models under consideration to each observed dataset. Moreover, it\nrequires no hand-crafted summary statistics of the data and is designed to\namortize the cost of simulation over multiple models and observable datasets.\nThis makes the method particularly effective in scenarios where model fit needs\nto be assessed for a large number of datasets, so that per-dataset inference is\npractically infeasible.Finally, we propose a novel way to measure epistemic\nuncertainty in model comparison problems. We demonstrate the utility of our\nmethod on toy examples and simulated data from non-trivial models from\ncognitive science and single-cell neuroscience. We show that our method\nachieves excellent results in terms of accuracy, calibration, and efficiency\nacross the examples considered in this work. We argue that our framework can\nenhance and enrich model-based analysis and inference in many fields dealing\nwith computational models of natural processes. We further argue that the\nproposed measure of epistemic uncertainty provides a unique proxy to quantify\nabsolute evidence even in a framework which assumes that the true\ndata-generating model is within a finite set of candidate models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:15:46 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 10:46:25 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 22:11:39 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 09:20:49 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Radev", "Stefan T.", ""], ["D'Alessandro", "Marco", ""], ["Mertens", "Ulf K.", ""], ["Voss", "Andreas", ""], ["K\u00f6the", "Ullrich", ""], ["B\u00fcrkner", "Paul-Christian", ""]]}, {"id": "2004.10638", "submitter": "Michal Najman", "authors": "Olga Petrova, Karel Durkota, Galina Alperovich, Karel Horak, Michal\n  Najman, Branislav Bosansky, Viliam Lisy", "title": "Discovering Imperfectly Observable Adversarial Actions using Anomaly\n  Detection", "comments": "9 pages, 3 figures, 3 tables. Extended Abstract of this paper is\n  accepted to AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a method for discovering unusual and suspicious\nbehavior. In many real-world scenarios, the examined events can be directly\nlinked to the actions of an adversary, such as attacks on computer networks or\nfrauds in financial operations. While the defender wants to discover such\nmalicious behavior, the attacker seeks to accomplish their goal (e.g.,\nexfiltrating data) while avoiding the detection. To this end, anomaly detectors\nhave been used in a game-theoretic framework that captures these goals of a\ntwo-player competition. We extend the existing models to more realistic\nsettings by (1) allowing both players to have continuous action spaces and by\nassuming that (2) the defender cannot perfectly observe the action of the\nattacker. We propose two algorithms for solving such games -- a direct\nextension of existing algorithms based on discretizing the feature space and\nlinear programming and the second algorithm based on constrained learning.\nExperiments show that both algorithms are applicable for cases with low feature\nspace dimensions but the learning-based method produces less exploitable\nstrategies and it is scalable to higher dimensions. Moreover, we use real-world\ndata to compare our approaches with existing classifiers in a data-exfiltration\nscenario via the DNS channel. The results show that our models are\nsignificantly less exploitable by an informed attacker.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:31:53 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Petrova", "Olga", ""], ["Durkota", "Karel", ""], ["Alperovich", "Galina", ""], ["Horak", "Karel", ""], ["Najman", "Michal", ""], ["Bosansky", "Branislav", ""], ["Lisy", "Viliam", ""]]}, {"id": "2004.10657", "submitter": "Miltiadis Allamanis", "authors": "Miltiadis Allamanis, Earl T. Barr, Soline Ducousso, and Zheng Gao", "title": "Typilus: Neural Type Hints", "comments": "Accepted to PLDI 2020", "journal-ref": null, "doi": "10.1145/3385412.3385997", "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type inference over partial contexts in dynamically typed languages is\nchallenging. In this work, we present a graph neural network model that\npredicts types by probabilistically reasoning over a program's structure,\nnames, and patterns. The network uses deep similarity learning to learn a\nTypeSpace -- a continuous relaxation of the discrete space of types -- and how\nto embed the type properties of a symbol (i.e. identifier) into it.\nImportantly, our model can employ one-shot learning to predict an open\nvocabulary of types, including rare and user-defined ones. We realise our\napproach in Typilus for Python that combines the TypeSpace with an optional\ntype checker. We show that Typilus accurately predicts types. Typilus\nconfidently predicts types for 70% of all annotatable symbols; when it predicts\na type, that type optionally type checks 95% of the time. Typilus can also find\nincorrect type annotations; two important and popular open source libraries,\nfairseq and allennlp, accepted our pull requests that fixed the annotation\nerrors Typilus discovered.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:14:03 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Allamanis", "Miltiadis", ""], ["Barr", "Earl T.", ""], ["Ducousso", "Soline", ""], ["Gao", "Zheng", ""]]}, {"id": "2004.10664", "submitter": "Tongxue Zhou", "authors": "Tongxue Zhou, Su Ruan, St\\'ephane Canu", "title": "A review: Deep learning for medical image segmentation using\n  multi-modality fusion", "comments": "26 pages, 8 figures", "journal-ref": "Array, Volumes 3-4, September-December 2019, Article 100004", "doi": "10.1016/j.array.2019.100004", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modality is widely used in medical imaging, because it can provide\nmultiinformation about a target (tumor, organ or tissue). Segmentation using\nmultimodality consists of fusing multi-information to improve the segmentation.\nRecently, deep learning-based approaches have presented the state-of-the-art\nperformance in image classification, segmentation, object detection and\ntracking tasks. Due to their self-learning and generalization ability over\nlarge amounts of data, deep learning recently has also gained great interest in\nmulti-modal medical image segmentation. In this paper, we give an overview of\ndeep learning-based approaches for multi-modal medical image segmentation task.\nFirstly, we introduce the general principle of deep learning and multi-modal\nmedical image segmentation. Secondly, we present different deep learning\nnetwork architectures, then analyze their fusion strategies and compare their\nresults. The earlier fusion is commonly used, since it's simple and it focuses\non the subsequent segmentation network architecture. However, the later fusion\ngives more attention on fusion strategy to learn the complex relationship\nbetween different modalities. In general, compared to the earlier fusion, the\nlater fusion can give more accurate result if the fusion method is effective\nenough. We also discuss some common problems in medical image segmentation.\nFinally, we summarize and provide some perspectives on the future research.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 16:00:53 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:33:31 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhou", "Tongxue", ""], ["Ruan", "Su", ""], ["Canu", "St\u00e9phane", ""]]}, {"id": "2004.10696", "submitter": "Demetris Marnerides", "authors": "Demetris Marnerides, Thomas Bashford-Rogers and Kurt Debattista", "title": "Spectrally Consistent UNet for High Fidelity Image Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are the current de-facto models used for\nmany imaging tasks due to their high learning capacity as well as their\narchitectural qualities. The ubiquitous UNet architecture provides an efficient\nand multi-scale solution that combines local and global information. Despite\nthe success of UNet architectures, the use of upsampling layers can cause\nartefacts. In this work, a method for assessing the structural biases of UNets\nand the effects these have on the outputs is presented, characterising their\nimpact in the Fourier domain. A new upsampling module is proposed, based on a\nnovel use of the Guided Image Filter, that provides spectrally consistent\noutputs when used in a UNet architecture, forming the Guided UNet (GUNet). The\nGUNet architecture is applied and evaluated for example applications of inverse\ntone mapping/dynamic range expansion and colourisation from grey-scale images\nand is shown to provide higher fidelity outputs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:04:02 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:32:09 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Marnerides", "Demetris", ""], ["Bashford-Rogers", "Thomas", ""], ["Debattista", "Kurt", ""]]}, {"id": "2004.10700", "submitter": "Netanel Raviv", "authors": "Netanel Raviv, Siddharth Jain, Pulakesh Upadhyaya, Jehoshua Bruck, and\n  Anxiao Jiang", "title": "CodNN -- Robust Neural Networks From Coded Classification", "comments": "To appear in ISIT '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are a revolutionary force in the ongoing\ninformation revolution, and yet their intrinsic properties remain a mystery. In\nparticular, it is widely known that DNNs are highly sensitive to noise, whether\nadversarial or random. This poses a fundamental challenge for hardware\nimplementations of DNNs, and for their deployment in critical applications such\nas autonomous driving. In this paper we construct robust DNNs via error\ncorrecting codes. By our approach, either the data or internal layers of the\nDNN are coded with error correcting codes, and successful computation under\nnoise is guaranteed. Since DNNs can be seen as a layered concatenation of\nclassification tasks, our research begins with the core task of classifying\nnoisy coded inputs, and progresses towards robust DNNs. We focus on binary data\nand linear codes. Our main result is that the prevalent parity code can\nguarantee robustness for a large family of DNNs, which includes the recently\npopularized binarized neural networks. Further, we show that the coded\nclassification problem has a deep connection to Fourier analysis of Boolean\nfunctions. In contrast to existing solutions in the literature, our results do\nnot rely on altering the training process of the DNN, and provide\nmathematically rigorous guarantees rather than experimental evidence.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:07:15 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 22:55:41 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Raviv", "Netanel", ""], ["Jain", "Siddharth", ""], ["Upadhyaya", "Pulakesh", ""], ["Bruck", "Jehoshua", ""], ["Jiang", "Anxiao", ""]]}, {"id": "2004.10705", "submitter": "Stanis{\\l}aw Ka\\'zmierczak", "authors": "Stanis{\\l}aw Ka\\'zmierczak, Jacek Ma\\'ndziuk", "title": "A Committee of Convolutional Neural Networks for Image Classication in\n  the Concurrent Presence of Feature and Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has become a ubiquitous task. Models trained on good\nquality data achieve accuracy which in some application domains is already\nabove human-level performance. Unfortunately, real-world data are quite often\ndegenerated by the noise existing in features and/or labels. There are quite\nmany papers that handle the problem of either feature or label noise,\nseparately. However, to the best of our knowledge, this piece of research is\nthe first attempt to address the problem of concurrent occurrence of both types\nof noise. Basing on the MNIST, CIFAR-10 and CIFAR-100 datasets, we\nexperimentally proved that the difference by which committees beat single\nmodels increases along with noise level, no matter it is an attribute or label\ndisruption. Thus, it makes ensembles legitimate to be applied to noisy images\nwith noisy labels. The aforementioned committees' advantage over single models\nis positively correlated with dataset difficulty level as well. We propose\nthree committee selection algorithms that outperform a strong baseline\nalgorithm which relies on an ensemble of individual (nonassociated) best\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 00:22:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:54:13 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ka\u017amierczak", "Stanis\u0142aw", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2004.10710", "submitter": "Jo\\~ao Caldeira", "authors": "Jo\\~ao Caldeira, Brian Nord", "title": "Deeply Uncertain: Comparing Methods of Uncertainty Quantification in\n  Deep Learning Algorithms", "comments": "11 pages, 3 figures; Presented at ICLR 2020 Workshop on Fundamental\n  Science in the era of AI; changes to match accepted version", "journal-ref": "Mach. Learn.: Sci. Technol. 2 015002 (2021)", "doi": "10.1088/2632-2153/aba6f3", "report-no": "FERMILAB-PUB-20-157-SCD", "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparison of methods for uncertainty quantification (UQ) in\ndeep learning algorithms in the context of a simple physical system. Three of\nthe most common uncertainty quantification methods - Bayesian Neural Networks\n(BNN), Concrete Dropout (CD), and Deep Ensembles (DE) - are compared to the\nstandard analytic error propagation. We discuss this comparison in terms\nendemic to both machine learning (\"epistemic\" and \"aleatoric\") and the physical\nsciences (\"statistical\" and \"systematic\"). The comparisons are presented in\nterms of simulated experimental measurements of a single pendulum - a\nprototypical physical system for studying measurement and analysis techniques.\nOur results highlight some pitfalls that may occur when using these UQ methods.\nFor example, when the variation of noise in the training set is small, all\nmethods predicted the same relative uncertainty independently of the inputs.\nThis issue is particularly hard to avoid in BNN. On the other hand, when the\ntest set contains samples far from the training distribution, we found that no\nmethods sufficiently increased the uncertainties associated to their\npredictions. This problem was particularly clear for CD. In light of these\nresults, we make some recommendations for usage and interpretation of UQ\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:13:15 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 16:09:59 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 17:21:41 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Caldeira", "Jo\u00e3o", ""], ["Nord", "Brian", ""]]}, {"id": "2004.10723", "submitter": "Shi Yu", "authors": "Shi Yu", "title": "Eigendecomposition of Q in Equally Constrained Quadratic Programming", "comments": "Needs further improvement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying eigenvalue decomposition on the quadratic term matrix in a type\nof linear equally constrained quadratic programming (EQP), there exists a\nlinear mapping to project optimal solutions between the new EQP formulation\nwhere $Q$ is diagonalized and the original formulation. Although such a mapping\nrequires a particular type of equality constraints, it is generalizable to some\nreal problems such as efficient frontier for portfolio allocation and\nclassification of Least Square Support Vector Machines (LSSVM). The established\nmapping could be potentially useful to explore optimal solutions in subspace,\nbut it is not very clear to the author. This work was inspired by similar work\nproved on unconstrained formulation discussed earlier in \\cite{Tan}, but its\ncurrent proof is much improved and generalized. To the author's knowledge, very\nfew similar discussion appears in literature.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:25:46 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:07:45 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Yu", "Shi", ""]]}, {"id": "2004.10756", "submitter": "Hayata Yamasaki", "authors": "Hayata Yamasaki, Sathyawageeswar Subramanian, Sho Sonoda, Masato\n  Koashi", "title": "Learning with Optimized Random Features: Exponential Speedup by Quantum\n  Machine Learning without Sparsity and Low-Rank Assumptions", "comments": "37 pages, 2 figures, accepted at Thirty-fourth Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods augmented with random features give scalable algorithms for\nlearning from big data. But it has been computationally hard to sample random\nfeatures according to a probability distribution that is optimized for the\ndata, so as to minimize the required number of features for achieving the\nlearning to a desired accuracy. Here, we develop a quantum algorithm for\nsampling from this optimized distribution over features, in runtime $O(D)$ that\nis linear in the dimension $D$ of the input data. Our algorithm achieves an\nexponential speedup in $D$ compared to any known classical algorithm for this\nsampling task. In contrast to existing quantum machine learning algorithms, our\nalgorithm circumvents sparsity and low-rank assumptions and thus has wide\napplicability. We also show that the sampled features can be combined with\nregression by stochastic gradient descent to achieve the learning without\ncanceling out our exponential speedup. Our algorithm based on sampling\noptimized random features leads to an accelerated framework for machine\nlearning that takes advantage of quantum computers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 18:00:00 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:07:42 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Yamasaki", "Hayata", ""], ["Subramanian", "Sathyawageeswar", ""], ["Sonoda", "Sho", ""], ["Koashi", "Masato", ""]]}, {"id": "2004.10798", "submitter": "Bahman Moraffah", "authors": "Bahman Moraffah and Antonia Papndreou-Suppopola", "title": "Bayesian nonparametric modeling for predicting dynamic dependencies in\n  multiple object tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some challenging problems in tracking multiple objects include the\ntime-dependent cardinality, unordered measurements and object parameter\nlabeling. In this paper, we employ Bayesian Bayesian nonparametric methods to\naddress these challenges. In particular, we propose modeling the multiple\nobject parameter state prior using the dependent Dirichlet and Pitman-Yor\nprocesses. These nonparametric models have been shown to be more flexible and\nrobust, when compared to existing methods, for estimating the time-varying\nnumber of objects, providing object labeling and identifying measurement to\nobject associations. Monte Carlo sampling methods are then proposed to\nefficiently learn the trajectory of objects from noisy measurements. Using\nsimulations, we demonstrate the estimation performance advantage of the new\nmethods when compared to existing algorithms such as the generalized labeled\nmulti-Bernoulli filter.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:07:35 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Moraffah", "Bahman", ""], ["Papndreou-Suppopola", "Antonia", ""]]}, {"id": "2004.10802", "submitter": "Jared Kaplan", "authors": "Utkarsh Sharma, Jared Kaplan", "title": "A Neural Scaling Law from the Dimension of the Data Manifold", "comments": "16+12 pages, 11+11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data is plentiful, the loss achieved by well-trained neural networks\nscales as a power-law $L \\propto N^{-\\alpha}$ in the number of network\nparameters $N$. This empirical scaling law holds for a wide variety of data\nmodalities, and may persist over many orders of magnitude. The scaling law can\nbe explained if neural models are effectively just performing regression on a\ndata manifold of intrinsic dimension $d$. This simple theory predicts that the\nscaling exponents $\\alpha \\approx 4/d$ for cross-entropy and mean-squared error\nlosses. We confirm the theory by independently measuring the intrinsic\ndimension and the scaling exponents in a teacher/student framework, where we\ncan study a variety of $d$ and $\\alpha$ by dialing the properties of random\nteacher networks. We also test the theory with CNN image classifiers on several\ndatasets and with GPT-type language models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:16:06 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Sharma", "Utkarsh", ""], ["Kaplan", "Jared", ""]]}, {"id": "2004.10823", "submitter": "Tomoki Koriyama", "authors": "Tomoki Koriyama, Hiroshi Saruwatari", "title": "Utterance-level Sequential Modeling For Deep Gaussian Process Based\n  Speech Synthesis Using Simple Recurrent Unit", "comments": "5 pages. Accepted by ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep Gaussian process (DGP) model with a recurrent\narchitecture for speech sequence modeling. DGP is a Bayesian deep model that\ncan be trained effectively with the consideration of model complexity and is a\nkernel regression model that can have high expressibility. In the previous\nstudies, it was shown that the DGP-based speech synthesis outperformed neural\nnetwork-based one, in which both models used a feed-forward architecture. To\nimprove the naturalness of synthetic speech, in this paper, we show that DGP\ncan be applied to utterance-level modeling using recurrent architecture models.\nWe adopt a simple recurrent unit (SRU) for the proposed model to achieve a\nrecurrent architecture, in which we can execute fast speech parameter\ngeneration by using the high parallelization nature of SRU. The objective and\nsubjective evaluation results show that the proposed SRU-DGP-based speech\nsynthesis outperforms not only feed-forward DGP but also automatically tuned\nSRU- and long short-term memory (LSTM)-based neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:51:36 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Koriyama", "Tomoki", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "2004.10824", "submitter": "Dan Nascimento Gomes Do Valle", "authors": "Dan Valle, Tiago Pimentel, Adriano Veloso", "title": "Assessing the Reliability of Visual Explanations of Deep Models with\n  Adversarial Perturbations", "comments": "Accepted for publication at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in complex deep neural networks for computer vision applications\nis increasing. This leads to the need for improving the interpretable\ncapabilities of these models. Recent explanation methods present visualizations\nof the relevance of pixels from input images, thus enabling the direct\ninterpretation of properties of the input that lead to a specific output. These\nmethods produce maps of pixel importance, which are commonly evaluated by\nvisual inspection. This means that the effectiveness of an explanation method\nis assessed based on human expectation instead of actual feature importance.\nThus, in this work we propose an objective measure to evaluate the reliability\nof explanations of deep models. Specifically, our approach is based on changes\nin the network's outcome resulting from the perturbation of input images in an\nadversarial way. We present a comparison between widely-known explanation\nmethods using our proposed approach. Finally, we also propose a straightforward\napplication of our approach to clean relevance maps, creating more\ninterpretable maps without any loss in essential explanation (as per our\nproposed measure).\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:57:34 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Valle", "Dan", ""], ["Pimentel", "Tiago", ""], ["Veloso", "Adriano", ""]]}, {"id": "2004.10856", "submitter": "Zhenkun Cai", "authors": "Zhenkun Cai, Kaihao Ma, Xiao Yan, Yidi Wu, Yuzhen Huang, James Cheng,\n  Teng Su, Fan Yu", "title": "TensorOpt: Exploring the Tradeoffs in Distributed DNN Training with\n  Auto-Parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good parallelization strategy can significantly improve the efficiency or\nreduce the cost for the distributed training of deep neural networks (DNNs).\nRecently, several methods have been proposed to find efficient parallelization\nstrategies but they all optimize a single objective (e.g., execution time,\nmemory consumption) and produce only one strategy. We propose FT, an efficient\nalgorithm that searches for an optimal set of parallelization strategies to\nallow the trade-off among different objectives. FT can adapt to different\nscenarios by minimizing the memory consumption when the number of devices is\nlimited and fully utilize additional resources to reduce the execution time.\nFor popular DNN models (e.g., vision, language), an in-depth analysis is\nconducted to understand the trade-offs among different objectives and their\ninfluence on the parallelization strategies. We also develop a user-friendly\nsystem, called TensorOpt, which allows users to run their distributed DNN\ntraining jobs without caring the details of parallelization strategies.\nExperimental results show that FT runs efficiently and provides accurate\nestimation of runtime costs, and TensorOpt is more flexible in adapting to\nresource availability compared with existing frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 02:57:35 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Cai", "Zhenkun", ""], ["Ma", "Kaihao", ""], ["Yan", "Xiao", ""], ["Wu", "Yidi", ""], ["Huang", "Yuzhen", ""], ["Cheng", "James", ""], ["Su", "Teng", ""], ["Yu", "Fan", ""]]}, {"id": "2004.10882", "submitter": "Jan Philip G\\\"opfert", "authors": "Niklas Risse, Christina G\\\"opfert, and Jan Philip G\\\"opfert", "title": "How to compare adversarial robustness of classifiers from a global\n  perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness of machine learning models has attracted considerable\nattention over recent years. Adversarial attacks undermine the reliability of\nand trust in machine learning models, but the construction of more robust\nmodels hinges on a rigorous understanding of adversarial robustness as a\nproperty of a given model. Point-wise measures for specific threat models are\ncurrently the most popular tool for comparing the robustness of classifiers and\nare used in most recent publications on adversarial robustness. In this work,\nwe use recently proposed robustness curves to show that point-wise measures\nfail to capture important global properties that are essential to reliably\ncompare the robustness of different classifiers. We introduce new ways in which\nrobustness curves can be used to systematically uncover these properties and\nprovide concrete recommendations for researchers and practitioners when\nassessing and comparing the robustness of trained models. Furthermore, we\ncharacterize scale as a way to distinguish small and large perturbations, and\nrelate it to inherent properties of data sets, demonstrating that robustness\nthresholds must be chosen accordingly. We release code to reproduce all\nexperiments presented in this paper, which includes a Python module to\ncalculate robustness curves for arbitrary data sets and classifiers, supporting\na number of frameworks, including TensorFlow, PyTorch and JAX.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:07:49 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 20:05:25 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Risse", "Niklas", ""], ["G\u00f6pfert", "Christina", ""], ["G\u00f6pfert", "Jan Philip", ""]]}, {"id": "2004.10888", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Shimon Whiteson", "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:23:44 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:57:35 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 16:42:41 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 01:02:59 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2004.10914", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Kannan Ramchandran", "title": "Alternating Minimization Converges Super-Linearly for Mixed Linear\n  Regression", "comments": "Accepted for publication at AISTATS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of solving mixed random linear equations. We have\nunlabeled observations coming from multiple linear regressions, and each\nobservation corresponds to exactly one of the regression models. The goal is to\nlearn the linear regressors from the observations. Classically, Alternating\nMinimization (AM) (which is a variant of Expectation Maximization (EM)) is used\nto solve this problem. AM iteratively alternates between the estimation of\nlabels and solving the regression problems with the estimated labels.\nEmpirically, it is observed that, for a large variety of non-convex problems\nincluding mixed linear regression, AM converges at a much faster rate compared\nto gradient based algorithms. However, the existing theory suggests similar\nrate of convergence for AM and gradient based methods, failing to capture this\nempirical behavior. In this paper, we close this gap between theory and\npractice for the special case of a mixture of $2$ linear regressions. We show\nthat, provided initialized properly, AM enjoys a \\emph{super-linear} rate of\nconvergence in certain parameter regimes. To the best of our knowledge, this is\nthe first work that theoretically establishes such rate for AM. Hence, if we\nwant to recover the unknown regressors upto an error (in $\\ell_2$ norm) of\n$\\epsilon$, AM only takes $\\mathcal{O}(\\log \\log (1/\\epsilon))$ iterations.\nFurthermore, we compare AM with a gradient based heuristic algorithm\nempirically and show that AM dominates in iteration complexity as well as\nwall-clock time.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 00:42:21 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 18:57:59 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ghosh", "Avishek", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2004.10915", "submitter": "Aditya Menon", "authors": "Ankit Singh Rawat, Aditya Krishna Menon, Andreas Veit, Felix Yu,\n  Sashank J. Reddi, Sanjiv Kumar", "title": "Doubly-stochastic mining for heterogeneous retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern retrieval problems are characterised by training sets with potentially\nbillions of labels, and heterogeneous data distributions across subpopulations\n(e.g., users of a retrieval system may be from different countries), each of\nwhich poses a challenge. The first challenge concerns scalability: with a large\nnumber of labels, standard losses are difficult to optimise even on a single\nexample. The second challenge concerns uniformity: one ideally wants good\nperformance on each subpopulation. While several solutions have been proposed\nto address the first challenge, the second challenge has received relatively\nless attention. In this paper, we propose doubly-stochastic mining (S2M ), a\nstochastic optimization technique that addresses both challenges. In each\niteration of S2M, we compute a per-example loss based on a subset of hardest\nlabels, and then compute the minibatch loss based on the hardest examples. We\nshow theoretically and empirically that by focusing on the hardest examples,\nS2M ensures that all data subpopulations are modelled well.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 00:43:13 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Rawat", "Ankit Singh", ""], ["Menon", "Aditya Krishna", ""], ["Veit", "Andreas", ""], ["Yu", "Felix", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2004.10931", "submitter": "Xiaowei Yue", "authors": "Xiaowei Yue, Yuchen Wen, Jeffrey H. Hunt, and Jianjun Shi", "title": "Active Learning for Gaussian Process Considering Uncertainties with\n  Application to Shape Control of Composite Fuselage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the machine learning domain, active learning is an iterative data\nselection algorithm for maximizing information acquisition and improving model\nperformance with limited training samples. It is very useful, especially for\nthe industrial applications where training samples are expensive,\ntime-consuming, or difficult to obtain. Existing methods mainly focus on active\nlearning for classification, and a few methods are designed for regression such\nas linear regression or Gaussian process. Uncertainties from measurement errors\nand intrinsic input noise inevitably exist in the experimental data, which\nfurther affects the modeling performance. The existing active learning methods\ndo not incorporate these uncertainties for Gaussian process. In this paper, we\npropose two new active learning algorithms for the Gaussian process with\nuncertainties, which are variance-based weighted active learning algorithm and\nD-optimal weighted active learning algorithm. Through numerical study, we show\nthat the proposed approach can incorporate the impact from uncertainties, and\nrealize better prediction performance. This approach has been applied to\nimproving the predictive modeling for automatic shape control of composite\nfuselage.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 02:04:53 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Yue", "Xiaowei", ""], ["Wen", "Yuchen", ""], ["Hunt", "Jeffrey H.", ""], ["Shi", "Jianjun", ""]]}, {"id": "2004.10941", "submitter": "Raef Bassily", "authors": "Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan\n  Ullman, Zhiwei Steven Wu", "title": "Private Query Release Assisted by Public Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private query release assisted by\naccess to public data. In this problem, the goal is to answer a large class\n$\\mathcal{H}$ of statistical queries with error no more than $\\alpha$ using a\ncombination of public and private samples. The algorithm is required to satisfy\ndifferential privacy only with respect to the private samples. We study the\nlimits of this task in terms of the private and public sample complexities.\n  First, we show that we can solve the problem for any query class\n$\\mathcal{H}$ of finite VC-dimension using only $d/\\alpha$ public samples and\n$\\sqrt{p}d^{3/2}/\\alpha^2$ private samples, where $d$ and $p$ are the\nVC-dimension and dual VC-dimension of $\\mathcal{H}$, respectively. In\ncomparison, with only private samples, this problem cannot be solved even for\nsimple query classes with VC-dimension one, and without any private samples, a\nlarger public sample of size $d/\\alpha^2$ is needed. Next, we give sample\ncomplexity lower bounds that exhibit tight dependence on $p$ and $\\alpha$. For\nthe class of decision stumps, we give a lower bound of $\\sqrt{p}/\\alpha$ on the\nprivate sample complexity whenever the public sample size is less than\n$1/\\alpha^2$. Given our upper bounds, this shows that the dependence on\n$\\sqrt{p}$ is necessary in the private sample complexity. We also give a lower\nbound of $1/\\alpha$ on the public sample complexity for a broad family of query\nclasses, which by our upper bound, is tight in $\\alpha$.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 02:46:37 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bassily", "Raef", ""], ["Cheu", "Albert", ""], ["Moran", "Shay", ""], ["Nikolov", "Aleksandar", ""], ["Ullman", "Jonathan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2004.10956", "submitter": "Xiaoyu Tao", "authors": "Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei,\n  Yihong Gong", "title": "Few-Shot Class-Incremental Learning", "comments": "Accepted by CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to incrementally learn new classes is crucial to the development\nof real-world artificial intelligence systems. In this paper, we focus on a\nchallenging but practical few-shot class-incremental learning (FSCIL) problem.\nFSCIL requires CNN models to incrementally learn new classes from very few\nlabelled samples, without forgetting the previously learned ones. To address\nthis problem, we represent the knowledge using a neural gas (NG) network, which\ncan learn and preserve the topology of the feature manifold formed by different\nclasses. On this basis, we propose the TOpology-Preserving knowledge\nInCrementer (TOPIC) framework. TOPIC mitigates the forgetting of the old\nclasses by stabilizing NG's topology and improves the representation learning\nfor few-shot new classes by growing and adapting NG to new training samples.\nComprehensive experimental results demonstrate that our proposed method\nsignificantly outperforms other state-of-the-art class-incremental learning\nmethods on CIFAR100, miniImageNet, and CUB200 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 03:38:33 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:12:32 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tao", "Xiaoyu", ""], ["Hong", "Xiaopeng", ""], ["Chang", "Xinyuan", ""], ["Dong", "Songlin", ""], ["Wei", "Xing", ""], ["Gong", "Yihong", ""]]}, {"id": "2004.10975", "submitter": "Warasinee Chaisangmongkon", "authors": "Isarun Chamveha, Trongtum Tongdee, Pairash Saiviroonporn, and\n  Warasinee Chaisangmongkon", "title": "Local Adaptation Improves Accuracy of Deep Learning Model for Automated\n  X-Ray Thoracic Disease Detection : A Thai Study", "comments": "9 pages, 2 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite much promising research in the area of artificial intelligence for\nmedical image diagnosis, there has been no large-scale validation study done in\nThailand to confirm the accuracy and utility of such algorithms when applied to\nlocal datasets. Here we present a wide-reaching development and testing of a\ndeep learning algorithm for automated thoracic disease detection, utilizing\n421,859 local chest radiographs. Our study shows that convolutional neural\nnetworks can achieve remarkable performance in detecting 13 common abnormality\nconditions on chest X-ray, and the incorporation of local images into the\ntraining set is key to the model's success. This paper presents a\nstate-of-the-art model for CXR abnormality detection, reaching an average AUROC\nof 0.91. This model, if integrated to the workflow, can result in up to 55.6%\nwork reduction for medical practitioners in the CXR analysis process. Our work\nemphasizes the importance of investing in local research of medical diagnosis\nalgorithms to ensure safe and efficient usage within the intended region.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:25:26 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:03:23 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 08:20:14 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Chamveha", "Isarun", ""], ["Tongdee", "Trongtum", ""], ["Saiviroonporn", "Pairash", ""], ["Chaisangmongkon", "Warasinee", ""]]}, {"id": "2004.10980", "submitter": "Woo Seok Lee", "authors": "Woo Seok Lee and Sergej Flach", "title": "Deep Learning of Chaos Classification", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train an artificial neural network which distinguishes chaotic and regular\ndynamics of the two-dimensional Chirikov standard map. We use finite length\ntrajectories and compare the performance with traditional numerical methods\nwhich need to evaluate the Lyapunov exponent. The neural network has superior\nperformance for short periods with length down to 10 Lyapunov times on which\nthe traditional Lyapunov exponent computation is far from converging. We show\nthe robustness of the neural network to varying control parameters, in\nparticular we train with one set of control parameters, and successfully test\nin a complementary set. Furthermore, we use the neural network to successfully\ntest the dynamics of discrete maps in different dimensions, e.g. the\none-dimensional logistic map and a three-dimensional discrete version of the\nLorenz system. Our results demonstrate that a convolutional neural network can\nbe used as an excellent chaos indicator.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:50:44 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Lee", "Woo Seok", ""], ["Flach", "Sergej", ""]]}, {"id": "2004.10981", "submitter": "Kexin Lyu", "authors": "Jia Cai, Kexin Lv, Junyi Huo, Xiaolin Huang, Jie Yang", "title": "Sparse Generalized Canonical Correlation Analysis: Distributed\n  Alternating Iteration based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse canonical correlation analysis (CCA) is a useful statistical tool to\ndetect latent information with sparse structures. However, sparse CCA works\nonly for two datasets, i.e., there are only two views or two distinct objects.\nTo overcome this limitation, in this paper, we propose a sparse generalized\ncanonical correlation analysis (GCCA), which could detect the latent relations\nof multiview data with sparse structures. Moreover, the introduced sparsity\ncould be considered as Laplace prior on the canonical variates. Specifically,\nwe convert the GCCA into a linear system of equations and impose $\\ell_1$\nminimization penalty for sparsity pursuit. This results in a nonconvex problem\non Stiefel manifold, which is difficult to solve. Motivated by Boyd's consensus\nproblem, an algorithm based on distributed alternating iteration approach is\ndeveloped and theoretical consistency analysis is investigated elaborately\nunder mild conditions. Experiments on several synthetic and real world datasets\ndemonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:53:48 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Cai", "Jia", ""], ["Lv", "Kexin", ""], ["Huo", "Junyi", ""], ["Huang", "Xiaolin", ""], ["Yang", "Jie", ""]]}, {"id": "2004.10984", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger and Oliver Schulte", "title": "A Complete Characterization of Projectivity for Statistical Relational\n  Models", "comments": "Extended version (with proof appendix) of paper that is too appear in\n  Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A generative probabilistic model for relational data consists of a family of\nprobability distributions for relational structures over domains of different\nsizes. In most existing statistical relational learning (SRL) frameworks, these\nmodels are not projective in the sense that the marginal of the distribution\nfor size-$n$ structures on induced sub-structures of size $k<n$ is equal to the\ngiven distribution for size-$k$ structures. Projectivity is very beneficial in\nthat it directly enables lifted inference and statistically consistent learning\nfrom sub-sampled relational structures. In earlier work some simple fragments\nof SRL languages have been identified that represent projective models.\nHowever, no complete characterization of, and representation framework for\nprojective models has been given. In this paper we fill this gap: exploiting\nrepresentation theorems for infinite exchangeable arrays we introduce a class\nof directed graphical latent variable models that precisely correspond to the\nclass of projective relational models. As a by-product we also obtain a\ncharacterization for when a given distribution over size-$k$ structures is the\nstatistical frequency distribution of size-$k$ sub-structures in much larger\nsize-$n$ structures. These results shed new light onto the old open problem of\nhow to apply Halpern et al.'s \"random worlds approach\" for probabilistic\ninference to general relational signatures.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:58:27 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 11:44:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jaeger", "Manfred", ""], ["Schulte", "Oliver", ""]]}, {"id": "2004.11055", "submitter": "Alma Rahat PhD", "authors": "Alma Rahat and Michael Wood", "title": "On Bayesian Search for the Feasible Space Under Computationally\n  Expensive Constraints", "comments": "Accepted at The Sixth International Conference on Machine Learning,\n  Optimization, and Data Science. Main content 12 pages, a total of 19 pages\n  with supplementary. 3 Figures and 2 tables. Python code for Bayesian search\n  is available at: http://bitbucket.org/arahat/lod-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are often interested in identifying the feasible subset of a decision\nspace under multiple constraints to permit effective design exploration. If\ndetermining feasibility required computationally expensive simulations, the\ncost of exploration would be prohibitive. Bayesian search is data-efficient for\nsuch problems: starting from a small dataset, the central concept is to use\nBayesian models of constraints with an acquisition function to locate promising\nsolutions that may improve predictions of feasibility when the dataset is\naugmented. At the end of this sequential active learning approach with a\nlimited number of expensive evaluations, the models can accurately predict the\nfeasibility of any solution obviating the need for full simulations. In this\npaper, we propose a novel acquisition function that combines the probability\nthat a solution lies at the boundary between feasible and infeasible spaces\n(representing exploitation) and the entropy in predictions (representing\nexploration). Experiments confirmed the efficacy of the proposed function.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:22:32 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 12:00:05 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rahat", "Alma", ""], ["Wood", "Michael", ""]]}, {"id": "2004.11077", "submitter": "Barbara Barabasz", "authors": "Barbara Barabasz", "title": "Quantaized Winograd/Toom-Cook Convolution for DNNs: Beyond Canonical\n  Polynomials Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem how to speed up the convolution computations in Deep Neural\nNetworks is widely investigated in recent years. The Winograd convolution\nalgorithm is a common used method that significantly reduces time consumption.\nHowever, it suffers from a problem with numerical accuracy particularly for\nlower precisions. In this paper we present the application of base change\ntechnique for quantized Winograd-aware training model. We show that we can\ntrain the $8$ bit quantized network to nearly the same accuracy (up to 0.5%\nloss) for tested network (Resnet18) and dataset (CIFAR10) as for quantized\ndirect convolution with few additional operations in pre/post transformations.\nKeeping Hadamard product on $9$ bits allow us to obtain the same accuracy as\nfor direct convolution.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:15:27 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Barabasz", "Barbara", ""]]}, {"id": "2004.11094", "submitter": "Alec Koppel", "authors": "Alec Koppel, Hrusikesha Pradhan, Ketan Rajawat", "title": "Consistent Online Gaussian Process Regression Without the Sample\n  Complexity Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes provide a framework for nonlinear nonparametric Bayesian\ninference widely applicable across science and engineering. Unfortunately,\ntheir computational burden scales cubically with the training sample size,\nwhich in the case that samples arrive in perpetuity, approaches infinity. This\nissue necessitates approximations for use with streaming data, which to date\nmostly lack convergence guarantees. Thus, we develop the first online Gaussian\nprocess approximation that preserves convergence to the population posterior,\ni.e., asymptotic posterior consistency, while ameliorating its intractable\ncomplexity growth with the sample size. We propose an online compression scheme\nthat, following each a posteriori update, fixes an error neighborhood with\nrespect to the Hellinger metric centered at the current posterior, and greedily\ntosses out past kernel dictionary elements until its boundary is hit. We call\nthe resulting method Parsimonious Online Gaussian Processes (POG). For\ndiminishing error radius, exact asymptotic consistency is preserved (Theorem\n1(i)) at the cost of unbounded memory in the limit. On the other hand, for\nconstant error radius, POG converges to a neighborhood of the population\nposterior (Theorem 1(ii))but with finite memory at-worst determined by the\nmetric entropy of the feature space (Theorem 2). Experimental results are\npresented on several nonlinear regression problems which illuminates the merits\nof this approach as compared with alternatives that fix the subspace dimension\ndefining the history of past points.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:52:06 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 15:49:51 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Koppel", "Alec", ""], ["Pradhan", "Hrusikesha", ""], ["Rajawat", "Ketan", ""]]}, {"id": "2004.11098", "submitter": "Friedrich Solowjow", "authors": "Friedrich Solowjow, Dominik Baumann, Christian Fiedler, Andreas\n  Jocham, Thomas Seel, and Sebastian Trimpe", "title": "A Kernel Two-sample Test for Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating whether data streams were generated by the same distribution is at\nthe heart of many machine learning problems, e.g. to detect changes. This is\nparticularly relevant for data generated by dynamical systems since they are\nessential for many real-world processes in biomedical, economic, or engineering\nsystems. While kernel two-sample tests are powerful for comparing independent\nand identically distributed random variables, no established method exists for\ncomparing dynamical systems. The key problem is the critical independence\nassumption, which is inherently violated in dynamical systems. We propose a\nnovel two-sample test for dynamical systems by addressing three core\nchallenges: we (i) introduce a novel notion of mixing that captures\nautocorrelations in a relevant metric, (ii) propose an efficient way to\nestimate the speed of mixing purely from data, and (iii) integrate these into\nestablished kernel-two sample tests. The result is a data-driven method for\ncomparison of dynamical systems that is easy to use in practice and comes with\nsound theoretical guarantees. In an example application to anomaly detection\nfrom human walking data, we show that the test readily applies without the need\nfor feature engineering, heuristics, and human expert knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:57:26 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 17:08:22 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Solowjow", "Friedrich", ""], ["Baumann", "Dominik", ""], ["Fiedler", "Christian", ""], ["Jocham", "Andreas", ""], ["Seel", "Thomas", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2004.11114", "submitter": "Patrick McClure", "authors": "Patrick McClure, Dustin Moraczewski, Ka Chun Lam, Adam Thomas,\n  Francisco Pereira", "title": "Improving the Interpretability of fMRI Decoding using Deep Neural\n  Networks and Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are being increasingly used to make predictions\nfrom functional magnetic resonance imaging (fMRI) data. However, they are\nwidely seen as uninterpretable \"black boxes\", as it can be difficult to\ndiscover what input information is used by the DNN in the process, something\nimportant in both cognitive neuroscience and clinical applications. A saliency\nmap is a common approach for producing interpretable visualizations of the\nrelative importance of input features for a prediction. However, methods for\ncreating maps often fail due to DNNs being sensitive to input noise, or by\nfocusing too much on the input and too little on the model. It is also\nchallenging to evaluate how well saliency maps correspond to the truly relevant\ninput information, as ground truth is not always available. In this paper, we\nreview a variety of methods for producing gradient-based saliency maps, and\npresent a new adversarial training method we developed to make DNNs robust to\ninput noise, with the goal of improving interpretability. We introduce two\nquantitative evaluation procedures for saliency map methods in fMRI, applicable\nwhenever a DNN or linear model is being trained to decode some information from\nimaging data. We evaluate the procedures using a synthetic dataset where the\ncomplex activation structure is known, and on saliency maps produced for DNN\nand linear models for task decoding in the Human Connectome Project (HCP)\ndataset. Our key finding is that saliency maps produced with different methods\nvary widely in interpretability, in both in synthetic and HCP fMRI data.\nStrikingly, even when DNN and linear models decode at comparable levels of\nperformance, DNN saliency maps score higher on interpretability than linear\nmodel saliency maps (derived via weights or gradient). Finally, saliency maps\nproduced with our adversarial training method outperform those from other\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 12:56:24 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 16:15:40 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 16:01:57 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["McClure", "Patrick", ""], ["Moraczewski", "Dustin", ""], ["Lam", "Ka Chun", ""], ["Thomas", "Adam", ""], ["Pereira", "Francisco", ""]]}, {"id": "2004.11116", "submitter": "Guillaume Sanchez", "authors": "Guillaume Sanchez, Vincente Guis, Ricard Marxer, Fr\\'ed\\'eric Bouchara", "title": "Deep Learning Classification With Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning systems have shown tremendous accuracy in image classification,\nat the cost of big image datasets. Collecting such amounts of data can lead to\nlabelling errors in the training set. Indexing multimedia content for\nretrieval, classification or recommendation can involve tagging or\nclassification based on multiple criteria. In our case, we train face\nrecognition systems for actors identification with a closed set of identities\nwhile being exposed to a significant number of perturbators (actors unknown to\nour database). Face classifiers are known to be sensitive to label noise. We\nreview recent works on how to manage noisy annotations when training deep\nlearning classifiers, independently from our interest in face recognition.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:02:45 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Sanchez", "Guillaume", ""], ["Guis", "Vincente", ""], ["Marxer", "Ricard", ""], ["Bouchara", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2004.11120", "submitter": "Varun Bhatt", "authors": "Varun Bhatt, Shalini Shrivastava, Tanmay Chavan, Udayan Ganguly", "title": "Software-Level Accuracy Using Stochastic Computing With\n  Charge-Trap-Flash Based Weight Matrix", "comments": "8 pages, 8 figures, submitted to the International Joint Conference\n  on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The in-memory computing paradigm with emerging memory devices has been\nrecently shown to be a promising way to accelerate deep learning. Resistive\nprocessing unit (RPU) has been proposed to enable the vector-vector outer\nproduct in a crossbar array using a stochastic train of identical pulses to\nenable one-shot weight update, promising intense speed-up in matrix\nmultiplication operations, which form the bulk of training neural networks.\nHowever, the performance of the system suffers if the device does not satisfy\nthe condition of linear conductance change over around 1,000 conductance\nlevels. This is a challenge for nanoscale memories. Recently, Charge Trap Flash\n(CTF) memory was shown to have a large number of levels before saturation, but\nvariable non-linearity. In this paper, we explore the trade-off between the\nrange of conductance change and linearity. We show, through simulations, that\nat an optimum choice of the range, our system performs nearly as well as the\nmodels trained using exact floating point operations, with less than 1%\nreduction in the performance. Our system reaches an accuracy of 97.9% on MNIST\ndataset, 89.1% and 70.5% accuracy on CIFAR-10 and CIFAR-100 datasets (using\npre-extracted features). We also show its use in reinforcement learning, where\nit is used for value function approximation in Q-Learning, and learns to\ncomplete an episode the mountain car control problem in around 146 steps.\nBenchmarked to state-of-the-art, the CTF based RPU shows best in class\nperformance to enable software equivalent performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 02:45:58 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bhatt", "Varun", ""], ["Shrivastava", "Shalini", ""], ["Chavan", "Tanmay", ""], ["Ganguly", "Udayan", ""]]}, {"id": "2004.11123", "submitter": "Georgios Leontidis", "authors": "Benedict Delahaye Chivers, John Wallbank, Steven J. Cole, Ondrej\n  Sebek, Simon Stanley, Matthew Fry and Georgios Leontidis", "title": "Imputation of missing sub-hourly precipitation data in a large sensor\n  network: a machine learning approach", "comments": "24 pages, 7 figures, 5 tables", "journal-ref": "Journal of Hydrology 2020", "doi": "10.1016/j.jhydrol.2020.125126", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precipitation data collected at sub-hourly resolution represents specific\nchallenges for missing data recovery by being largely stochastic in nature and\nhighly unbalanced in the duration of rain vs non-rain. Here we present a\ntwo-step analysis utilising current machine learning techniques for imputing\nprecipitation data sampled at 30-minute intervals by devolving the task into\n(a) the classification of rain or non-rain samples, and (b) regressing the\nabsolute values of predicted rain samples. Investigating 37 weather stations in\nthe UK, this machine learning process produces more accurate predictions for\nrecovering precipitation data than an established surface fitting technique\nutilising neighbouring rain gauges. Increasing available features for the\ntraining of machine learning algorithms increases performance with the\nintegration of weather data at the target site with externally sourced rain\ngauges providing the highest performance. This method informs machine learning\nmodels by utilising information in concurrently collected environmental data to\nmake accurate predictions of missing rain data. Capturing complex non-linear\nrelationships from weakly correlated variables is critical for data recovery at\nsub-hourly resolutions. Such pipelines for data recovery can be developed and\ndeployed for highly automated and near instantaneous imputation of missing\nvalues in ongoing datasets at high temporal resolutions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:47:18 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 09:11:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chivers", "Benedict Delahaye", ""], ["Wallbank", "John", ""], ["Cole", "Steven J.", ""], ["Sebek", "Ondrej", ""], ["Stanley", "Simon", ""], ["Fry", "Matthew", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2004.11145", "submitter": "Xiangfeng Wang", "authors": "Wenhao Li and Bo Jin and Xiangfeng Wang and Junchi Yan and Hongyuan\n  Zha", "title": "F2A2: Flexible Fully-decentralized Approximate Actor-critic for\n  Cooperative Multi-agent Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1810.02912,\n  arXiv:1803.11485 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional centralized multi-agent reinforcement learning (MARL) algorithms\nare sometimes unpractical in complicated applications, due to non-interactivity\nbetween agents, curse of dimensionality and computation complexity. Hence,\nseveral decentralized MARL algorithms are motivated. However, existing\ndecentralized methods only handle the fully cooperative setting where massive\ninformation needs to be transmitted in training. The block coordinate gradient\ndescent scheme they used for successive independent actor and critic steps can\nsimplify the calculation, but it causes serious bias. In this paper, we propose\na flexible fully decentralized actor-critic MARL framework, which can combine\nmost of actor-critic methods, and handle large-scale general cooperative\nmulti-agent setting. A primal-dual hybrid gradient descent type algorithm\nframework is designed to learn individual agents separately for\ndecentralization. From the perspective of each agent, policy improvement and\nvalue evaluation are jointly optimized, which can stabilize multi-agent policy\nlearning. Furthermore, our framework can achieve scalability and stability for\nlarge-scale environment and reduce information transmission, by the parameter\nsharing mechanism and a novel modeling-other-agents methods based on\ntheory-of-mind and online supervised learning. Sufficient experiments in\ncooperative Multi-agent Particle Environment and StarCraft II show that our\ndecentralized MARL instantiation algorithms perform competitively against\nconventional centralized and decentralized methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 14:56:29 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Li", "Wenhao", ""], ["Jin", "Bo", ""], ["Wang", "Xiangfeng", ""], ["Yan", "Junchi", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2004.11147", "submitter": "Hanchen Wang", "authors": "Hanchen Wang, Defu Lian, Ying Zhang, Lu Qin, Xiangjian He, Yiguang\n  Lin, Xuemin Lin", "title": "Binarized Graph Neural Network", "comments": null, "journal-ref": null, "doi": "10.1007/s11280-021-00878-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been some breakthroughs in graph analysis by applying\nthe graph neural networks (GNNs) following a neighborhood aggregation scheme,\nwhich demonstrate outstanding performance in many tasks. However, we observe\nthat the parameters of the network and the embedding of nodes are represented\nin real-valued matrices in existing GNN-based graph embedding approaches which\nmay limit the efficiency and scalability of these models. It is well-known that\nbinary vector is usually much more space and time efficient than the\nreal-valued vector. This motivates us to develop a binarized graph neural\nnetwork to learn the binary representations of the nodes with binary network\nparameters following the GNN-based paradigm. Our proposed method can be\nseamlessly integrated into the existing GNN-based embedding approaches to\nbinarize the model parameters and learn the compact embedding. Extensive\nexperiments indicate that the proposed binarized graph neural network, namely\nBGN, is orders of magnitude more efficient in terms of both time and space\nwhile matching the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 09:43:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Hanchen", ""], ["Lian", "Defu", ""], ["Zhang", "Ying", ""], ["Qin", "Lu", ""], ["He", "Xiangjian", ""], ["Lin", "Yiguang", ""], ["Lin", "Xuemin", ""]]}, {"id": "2004.11149", "submitter": "Huimin Peng", "authors": "Huimin Peng", "title": "A Comprehensive Overview and Survey of Recent Advances in Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews meta-learning also known as learning-to-learn which\nseeks rapid and accurate model adaptation to unseen tasks with applications in\nhighly automated AI, few-shot learning, natural language processing and\nrobotics. Unlike deep learning, meta-learning can be applied to few-shot\nhigh-dimensional datasets and considers further improving model generalization\nto unseen tasks. Deep learning is focused upon in-sample prediction and\nmeta-learning concerns model adaptation for out-of-sample prediction.\nMeta-learning can continually perform self-improvement to achieve highly\nautonomous AI. Meta-learning may serve as an additional generalization block\ncomplementary for original deep learning model. Meta-learning seeks adaptation\nof machine learning models to unseen tasks which are vastly different from\ntrained tasks. Meta-learning with coevolution between agent and environment\nprovides solutions for complex tasks unsolvable by training from scratch.\nMeta-learning methodology covers a wide range of great minds and thoughts. We\nbriefly introduce meta-learning methodologies in the following categories:\nblack-box meta-learning, metric-based meta-learning, layered meta-learning and\nBayesian meta-learning framework. Recent applications concentrate upon the\nintegration of meta-learning with other machine learning framework to provide\nfeasible integrated problem solutions. We briefly present recent meta-learning\nadvances and discuss potential future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:11:08 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 02:10:16 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 08:48:02 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 08:12:11 GMT"}, {"version": "v5", "created": "Sun, 7 Jun 2020 08:16:14 GMT"}, {"version": "v6", "created": "Sat, 11 Jul 2020 14:26:42 GMT"}, {"version": "v7", "created": "Mon, 26 Oct 2020 06:18:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Peng", "Huimin", ""]]}, {"id": "2004.11154", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens", "title": "Random Features for Kernel Approximation: A Survey on Algorithms,\n  Theory, and Beyond", "comments": "Short version will be published on IEEE TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features is one of the most popular techniques to speed up kernel\nmethods in large-scale problems. Related works have been recognized by the\nNeurIPS Test-of-Time award in 2017 and the ICML Best Paper Finalist in 2019.\nThe body of work on random features has grown rapidly, and hence it is\ndesirable to have a comprehensive overview on this topic explaining the\nconnections among various algorithms and theoretical results. In this survey,\nwe systematically review the work on random features from the past ten years.\nFirst, the motivations, characteristics and contributions of representative\nrandom features based algorithms are summarized according to their sampling\nschemes, learning procedures, variance reduction properties and how they\nexploit training data. Second, we review theoretical results that center around\nthe following key question: how many random features are needed to ensure a\nhigh approximation quality or no loss in the empirical/expected risks of the\nlearned estimator. Third, we provide a comprehensive evaluation of popular\nrandom features based algorithms on several large-scale benchmark datasets and\ndiscuss their approximation quality and prediction performance for\nclassification. Last, we discuss the relationship between random features and\nmodern over-parameterized deep neural networks (DNNs), including the use of\nhigh dimensional random features in the analysis of DNNs as well as the gaps\nbetween current theoretical and empirical results. This survey may serve as a\ngentle introduction to this topic, and as a users' guide for practitioners\ninterested in applying the representative algorithms and understanding\ntheoretical results under various technical assumptions. We hope that this\nsurvey will facilitate discussion on the open problems in this topic, and more\nimportantly, shed light on future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:44:48 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 20:32:47 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 19:26:26 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 11:13:28 GMT"}, {"version": "v5", "created": "Sun, 11 Jul 2021 18:59:32 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Fanghui", ""], ["Huang", "Xiaolin", ""], ["Chen", "Yudong", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2004.11165", "submitter": "Susanne Dandl", "authors": "Susanne Dandl, Christoph Molnar, Martin Binder and Bernd Bischl", "title": "Multi-Objective Counterfactual Explanations", "comments": null, "journal-ref": "Parallel Problem Solving from Nature - PPSN XVI. PPSN 2020.\n  Lecture Notes in Computer Science, vol 12269", "doi": "10.1007/978-3-030-58112-1_31", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Counterfactual explanations are one of the most popular methods to make\npredictions of black box machine learning models interpretable by providing\nexplanations in the form of `what-if scenarios'. Most current approaches\noptimize a collapsed, weighted sum of multiple objectives, which are naturally\ndifficult to balance a-priori. We propose the Multi-Objective Counterfactuals\n(MOC) method, which translates the counterfactual search into a multi-objective\noptimization problem. Our approach not only returns a diverse set of\ncounterfactuals with different trade-offs between the proposed objectives, but\nalso maintains diversity in feature space. This enables a more detailed\npost-hoc analysis to facilitate better understanding and also more options for\nactionable user responses to change the predicted outcome. Our approach is also\nmodel-agnostic and works for numerical and categorical input features. We show\nthe usefulness of MOC in concrete cases and compare our approach with\nstate-of-the-art methods for counterfactual explanations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:56:39 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 10:03:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Dandl", "Susanne", ""], ["Molnar", "Christoph", ""], ["Binder", "Martin", ""], ["Bischl", "Bernd", ""]]}, {"id": "2004.11170", "submitter": "Andrea De Lorenzo", "authors": "Marco Virgolin, Andrea De Lorenzo, Eric Medvet, and Francesca Randone", "title": "Learning a Formula of Interpretability to Learn Interpretable Formulas", "comments": "16 pages, 4 figures Accepted at PPSN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many risk-sensitive applications require Machine Learning (ML) models to be\ninterpretable. Attempts to obtain interpretable models typically rely on\ntuning, by trial-and-error, hyper-parameters of model complexity that are only\nloosely related to interpretability. We show that it is instead possible to\ntake a meta-learning approach: an ML model of non-trivial Proxies of Human\nInterpretability (PHIs) can be learned from human feedback, then this model can\nbe incorporated within an ML training process to directly optimize for\ninterpretability. We show this for evolutionary symbolic regression. We first\ndesign and distribute a survey finalized at finding a link between features of\nmathematical formulas and two established PHIs, simulatability and\ndecomposability. Next, we use the resulting dataset to learn an ML model of\ninterpretability. Lastly, we query this model to estimate the interpretability\nof evolving solutions within bi-objective genetic programming. We perform\nexperiments on five synthetic and eight real-world symbolic regression\nproblems, comparing to the traditional use of solution size minimization. The\nresults show that the use of our model leads to formulas that are, for a same\nlevel of accuracy-interpretability trade-off, either significantly more or\nequally accurate. Moreover, the formulas are also arguably more interpretable.\nGiven the very positive results, we believe that our approach represents an\nimportant stepping stone for the design of next-generation interpretable\n(evolutionary) ML algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:59:49 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:08:37 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Virgolin", "Marco", ""], ["De Lorenzo", "Andrea", ""], ["Medvet", "Eric", ""], ["Randone", "Francesca", ""]]}, {"id": "2004.11195", "submitter": "Shangzhi Hong", "authors": "Shangzhi Hong, Yuqi Sun, Hanying Li, Henry S. Lynn", "title": "Influence of parallel computing strategies of iterative imputation of\n  missing data: a case study on missForest", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning iterative imputation methods have been well accepted by\nresearchers for imputing missing data, but they can be time-consuming when\nhandling large datasets. To overcome this drawback, parallel computing\nstrategies have been proposed but their impact on imputation results and\nsubsequent statistical analyses are relatively unknown. This study examines the\ntwo parallel strategies (variable-wise distributed computation and model-wise\ndistributed computation) implemented in the random-forest imputation method,\nmissForest. Results from the simulation experiments showed that the two\nparallel strategies can influence both the imputation process and the final\nimputation results differently. Specifically, even though both strategies\nproduced similar normalized root mean squared prediction errors, the\nvariable-wise distributed strategy led to additional biases when estimating the\nmean and inter-correlation of the covariates and their regression coefficients.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:41:52 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Hong", "Shangzhi", ""], ["Sun", "Yuqi", ""], ["Li", "Hanying", ""], ["Lynn", "Henry S.", ""]]}, {"id": "2004.11198", "submitter": "Fabrizio Frasca", "authors": "Fabrizio Frasca, Emanuele Rossi, Davide Eynard, Ben Chamberlain,\n  Michael Bronstein, Federico Monti", "title": "SIGN: Scalable Inception Graph Neural Networks", "comments": "Extended experiments to ogbn-papers100M", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has recently been applied to a broad spectrum\nof problems ranging from computer graphics and chemistry to high energy physics\nand social media. The popularity of graph neural networks has sparked interest,\nboth in academia and in industry, in developing methods that scale to very\nlarge graphs such as Facebook or Twitter social networks. In most of these\napproaches, the computational cost is alleviated by a sampling strategy\nretaining a subset of node neighbors or subgraphs at training time. In this\npaper we propose a new, efficient and scalable graph deep learning architecture\nwhich sidesteps the need for graph sampling by using graph convolutional\nfilters of different size that are amenable to efficient precomputation,\nallowing extremely fast training and inference. Our architecture allows using\ndifferent local graph operators (e.g. motif-induced adjacency matrices or\nPersonalized Page Rank diffusion matrix) to best suit the task at hand. We\nconduct extensive experimental evaluation on various open benchmarks and show\nthat our approach is competitive with other state-of-the-art architectures,\nwhile requiring a fraction of the training and inference time. Moreover, we\nobtain state-of-the-art results on ogbn-papers100M, the largest public graph\ndataset, with over 110 million nodes and 1.5 billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:46:10 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 10:34:37 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 19:20:22 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Frasca", "Fabrizio", ""], ["Rossi", "Emanuele", ""], ["Eynard", "Davide", ""], ["Chamberlain", "Ben", ""], ["Bronstein", "Michael", ""], ["Monti", "Federico", ""]]}, {"id": "2004.11231", "submitter": "Khaoula El Mekkaoui", "authors": "Khaoula El Mekkaoui, Diego Mesquita, Paul Blomstedt, Samuel Kaski", "title": "Federated Stochastic Gradient Langevin Dynamics", "comments": "Accepted to UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient MCMC methods, such as stochastic gradient Langevin\ndynamics (SGLD), employ fast but noisy gradient estimates to enable large-scale\nposterior sampling. Although we can easily extend SGLD to distributed settings,\nit suffers from two issues when applied to federated non-IID data. First, the\nvariance of these estimates increases significantly. Second, delaying\ncommunication causes the Markov chains to diverge from the true posterior even\nfor very simple models. To alleviate both these problems, we propose conducive\ngradients, a simple mechanism that combines local likelihood approximations to\ncorrect gradient updates. Notably, conducive gradients are easy to compute, and\nsince we only calculate the approximations once, they incur negligible\noverhead. We apply conducive gradients to distributed stochastic gradient\nLangevin dynamics (DSGLD) and call the resulting method federated stochastic\ngradient Langevin dynamics (FSGLD). We demonstrate that our approach can handle\ndelayed communication rounds, converging to the target posterior in cases where\nDSGLD fails. We also show that FSGLD outperforms DSGLD for non-IID federated\ndata with experiments on metric learning and neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:25:09 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 14:50:31 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 23:50:47 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mekkaoui", "Khaoula El", ""], ["Mesquita", "Diego", ""], ["Blomstedt", "Paul", ""], ["Kaski", "Samuel", ""]]}, {"id": "2004.11234", "submitter": "Juan-Pablo Ortega", "authors": "Lukas Gonon, Lyudmila Grigoryeva, and Juan-Pablo Ortega", "title": "Memory and forecasting capacities of nonlinear recurrent networks", "comments": "27 pages, 1 figure. To appear in Physica D", "journal-ref": null, "doi": "10.1016/j.physd.2020.132721", "report-no": null, "categories": "math.OC cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of memory capacity, originally introduced for echo state and\nlinear networks with independent inputs, is generalized to nonlinear recurrent\nnetworks with stationary but dependent inputs. The presence of dependence in\nthe inputs makes natural the introduction of the network forecasting capacity,\nthat measures the possibility of forecasting time series values using network\nstates. Generic bounds for memory and forecasting capacities are formulated in\nterms of the number of neurons of the nonlinear recurrent network and the\nautocovariance function or the spectral density of the input. These bounds\ngeneralize well-known estimates in the literature to a dependent inputs setup.\nFinally, for the particular case of linear recurrent networks with independent\ninputs it is proved that the memory capacity is given by the rank of the\nassociated controllability matrix, a fact that has been for a long time assumed\nto be true without proof by the community.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:10:51 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 10:53:00 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Gonon", "Lukas", ""], ["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "2004.11238", "submitter": "Andreas Rene Geist", "authors": "A. Rene Geist and Sebastian Trimpe", "title": "Learning Constrained Dynamics with Gauss Principle adhering Gaussian\n  Processes", "comments": "To be published in 2nd Annual Conference on Learning for Dynamics and\n  Control (L4DC), Proceedings of Machine Learning Research 2020", "journal-ref": "Proceedings of the 2nd Conference on Learning for Dynamics and\n  Control, PMLR 120:225-234, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of the constrained dynamics of mechanical systems is often\nchallenging. Learning methods promise to ease an analytical analysis, but\nrequire considerable amounts of data for training. We propose to combine\ninsights from analytical mechanics with Gaussian process regression to improve\nthe model's data efficiency and constraint integrity. The result is a Gaussian\nprocess model that incorporates a priori constraint knowledge such that its\npredictions adhere to Gauss' principle of least constraint. In return,\npredictions of the system's acceleration naturally respect potentially\nnon-ideal (non-)holonomic equality constraints. As corollary results, our model\nenables to infer the acceleration of the unconstrained system from data of the\nconstrained system and enables knowledge transfer between differing constraint\nconfigurations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:26:51 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Geist", "A. Rene", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2004.11243", "submitter": "Monica Arul", "authors": "Monica Arul and Ahsan Kareem", "title": "Applications of shapelet transform to time series classification of\n  earthquake, wind and wave data", "comments": "24 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:1911.09086", "journal-ref": "Eng. Struct 228 (2021) 111564", "doi": "10.1016/j.engstruct.2020.111564", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous detection of desired events from large databases using time series\nclassification is becoming increasingly important in civil engineering as a\nresult of continued long-term health monitoring of a large number of\nengineering structures encompassing buildings, bridges, towers, and offshore\nplatforms. In this context, this paper proposes the application of a relatively\nnew time series representation named \"Shapelet transform\", which is based on\nlocal similarity in the shape of the time series subsequences. In consideration\nof the individual attributes distinctive to time series signals in earthquake,\nwind and ocean engineering, the application of this transform yields a new\nshape-based feature representation. Combining this shape-based representation\nwith a standard machine learning algorithm, a truly \"white-box\" machine\nlearning model is proposed with understandable features and a transparent\nalgorithm. This model automates event detection without the intervention of\ndomain practitioners, yielding a practical event detection procedure. The\nefficacy of this proposed shapelet transform-based autonomous detection\nprocedure is demonstrated by examples, to identify known and unknown earthquake\nevents from continuously recorded ground-motion measurements, to detect pulses\nin the velocity time history of ground motions to distinguish between\nnear-field and far-field ground motions, to identify thunderstorms from\ncontinuous wind speed measurements, to detect large-amplitude wind-induced\nvibrations from the bridge monitoring data, and to identify plunging breaking\nwaves that have a significant impact on offshore structures.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 10:17:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Arul", "Monica", ""], ["Kareem", "Ahsan", ""]]}, {"id": "2004.11262", "submitter": "Lukas Hedegaard", "authors": "Lukas Hedegaard, Omar Ali Sheikh-Omar, Alexandros Iosifidis", "title": "Supervised Domain Adaptation: A Graph Embedding Perspective and a\n  Rectified Experimental Protocol", "comments": "13 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of machine learning models tends to suffer when the\ndistributions of training and test data differ. This distribution gap can be\nalleviated with a process known as Domain Adaptation. In this paper, we show\nthat Domain Adaptation methods using pair-wise relationships between source and\ntarget domain data can be formulated as a Graph Embedding in which the domain\nlabels are incorporated into the structure of the intrinsic and penalty graphs.\nSpecifically, we analyse the loss functions of three existing state-of-the-art\nSupervised Domain Adaptation methods and demonstrate that they perform Graph\nEmbedding. Moreover, we highlight some generalisation and reproducibility\nissues related to the experimental setup commonly used to demonstrate the\nfew-shot learning capabilities of these methods. To assess and compare\nSupervised Domain Adaptation methods accurately, we propose a rectified\nevaluation protocol, and report updated benchmarks on the standard datasets\nOffice31 (Amazon, DSLR, and Webcam) and Digits (MNIST, USPS, SVHN, and\nMNIST-M).\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:46:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 09:39:35 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 13:46:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Hedegaard", "Lukas", ""], ["Sheikh-Omar", "Omar Ali", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2004.11293", "submitter": "Yawen Wu", "authors": "Yawen Wu, Zhepeng Wang, Zhenge Jia, Yiyu Shi, Jingtong Hu", "title": "Intermittent Inference with Nonuniformly Compressed Multi-Exit Neural\n  Network for Energy Harvesting Powered Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to enable persistent, event-driven sensing and decision\ncapabilities for energy-harvesting (EH)-powered devices by deploying\nlightweight DNNs onto EH-powered devices. However, harvested energy is usually\nweak and unpredictable and even lightweight DNNs take multiple power cycles to\nfinish one inference. To eliminate the indefinite long wait to accumulate\nenergy for one inference and to optimize the accuracy, we developed a power\ntrace-aware and exit-guided network compression algorithm to compress and\ndeploy multi-exit neural networks to EH-powered microcontrollers (MCUs) and\nselect exits during execution according to available energy. The experimental\nresults show superior accuracy and latency compared with state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:19:22 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 17:18:03 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Wu", "Yawen", ""], ["Wang", "Zhepeng", ""], ["Jia", "Zhenge", ""], ["Shi", "Yiyu", ""], ["Hu", "Jingtong", ""]]}, {"id": "2004.11349", "submitter": "Huy Phan", "authors": "Huy Phan, Kaare Mikkelsen, Oliver Y. Ch\\'en, Philipp Koch, Alfred\n  Mertins, Preben Kidmose, Maarten De Vos", "title": "Personalized Automatic Sleep Staging with Single-Night Data: a Pilot\n  Study with KL-Divergence Regularization", "comments": "This article has been published in Physiological Measurement", "journal-ref": null, "doi": "10.1088/1361-6579/ab921e", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain waves vary between people. An obvious way to improve automatic sleep\nstaging for longitudinal sleep monitoring is personalization of algorithms\nbased on individual characteristics extracted from the first night of data. As\na single night is a very small amount of data to train a sleep staging model,\nwe propose a Kullback-Leibler (KL) divergence regularized transfer learning\napproach to address this problem. We employ the pretrained SeqSleepNet (i.e.\nthe subject independent model) as a starting point and finetune it with the\nsingle-night personalization data to derive the personalized model. This is\ndone by adding the KL divergence between the output of the subject independent\nmodel and the output of the personalized model to the loss function during\nfinetuning. In effect, KL-divergence regularization prevents the personalized\nmodel from overfitting to the single-night data and straying too far away from\nthe subject independent model. Experimental results on the Sleep-EDF Expanded\ndatabase with 75 subjects show that sleep staging personalization with a\nsingle-night data is possible with help of the proposed KL-divergence\nregularization. On average, we achieve a personalized sleep staging accuracy of\n79.6%, a Cohen's kappa of 0.706, a macro F1-score of 73.0%, a sensitivity of\n71.8%, and a specificity of 94.2%. We find both that the approach is robust\nagainst overfitting and that it improves the accuracy by 4.5 percentage points\ncompared to non-personalization and 2.2 percentage points compared to\npersonalization without regularization.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:48:22 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 23:16:17 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Phan", "Huy", ""], ["Mikkelsen", "Kaare", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["Mertins", "Alfred", ""], ["Kidmose", "Preben", ""], ["De Vos", "Maarten", ""]]}, {"id": "2004.11362", "submitter": "Aaron Maschinot", "authors": "Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian,\n  Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan", "title": "Supervised Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning applied to self-supervised representation learning has\nseen a resurgence in recent years, leading to state of the art performance in\nthe unsupervised training of deep image models. Modern batch contrastive\napproaches subsume or significantly outperform traditional contrastive losses\nsuch as triplet, max-margin and the N-pairs loss. In this work, we extend the\nself-supervised batch contrastive approach to the fully-supervised setting,\nallowing us to effectively leverage label information. Clusters of points\nbelonging to the same class are pulled together in embedding space, while\nsimultaneously pushing apart clusters of samples from different classes. We\nanalyze two possible versions of the supervised contrastive (SupCon) loss,\nidentifying the best-performing formulation of the loss. On ResNet-200, we\nachieve top-1 accuracy of 81.4% on the ImageNet dataset, which is 0.8% above\nthe best number reported for this architecture. We show consistent\noutperformance over cross-entropy on other datasets and two ResNet variants.\nThe loss shows benefits for robustness to natural corruptions and is more\nstable to hyperparameter settings such as optimizers and data augmentations.\nOur loss function is simple to implement, and reference TensorFlow code is\nreleased at https://t.ly/supcon.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:58:56 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:51:35 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 15:16:53 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 22:25:05 GMT"}, {"version": "v5", "created": "Wed, 10 Mar 2021 19:11:45 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Khosla", "Prannay", ""], ["Teterwak", "Piotr", ""], ["Wang", "Chen", ""], ["Sarna", "Aaron", ""], ["Tian", "Yonglong", ""], ["Isola", "Phillip", ""], ["Maschinot", "Aaron", ""], ["Liu", "Ce", ""], ["Krishnan", "Dilip", ""]]}, {"id": "2004.11368", "submitter": "William Aiken", "authors": "William Aiken, Hyoungshick Kim, Simon Woo", "title": "Neural Network Laundering: Removing Black-Box Backdoor Watermarks from\n  Deep Neural Networks", "comments": "15 pages, 12 figures, 8 tables, formatted for ASIACCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating a state-of-the-art deep-learning system requires vast amounts of\ndata, expertise, and hardware, yet research into embedding copyright protection\nfor neural networks has been limited. One of the main methods for achieving\nsuch protection involves relying on the susceptibility of neural networks to\nbackdoor attacks, but the robustness of these tactics has been primarily\nevaluated against pruning, fine-tuning, and model inversion attacks. In this\nwork, we propose a neural network \"laundering\" algorithm to remove black-box\nbackdoor watermarks from neural networks even when the adversary has no prior\nknowledge of the structure of the watermark.\n  We are able to effectively remove watermarks used for recent defense or\ncopyright protection mechanisms while achieving test accuracies above 97% and\n80% for both MNIST and CIFAR-10, respectively. For all backdoor watermarking\nmethods addressed in this paper, we find that the robustness of the watermark\nis significantly weaker than the original claims. We also demonstrate the\nfeasibility of our algorithm in more complex tasks as well as in more realistic\nscenarios where the adversary is able to carry out efficient laundering attacks\nusing less than 1% of the original training set size, demonstrating that\nexisting backdoor watermarks are not sufficient to reach their claims.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:02:47 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Aiken", "William", ""], ["Kim", "Hyoungshick", ""], ["Woo", "Simon", ""]]}, {"id": "2004.11370", "submitter": "Robby Costales", "authors": "Robby Costales, Chengzhi Mao, Raphael Norwitz, Bryan Kim, Junfeng Yang", "title": "Live Trojan Attacks on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like all software systems, the execution of deep learning models is dictated\nin part by logic represented as data in memory. For decades, attackers have\nexploited traditional software programs by manipulating this data. We propose a\nlive attack on deep learning systems that patches model parameters in memory to\nachieve predefined malicious behavior on a certain set of inputs. By minimizing\nthe size and number of these patches, the attacker can reduce the amount of\nnetwork communication and memory overwrites, with minimal risk of system\nmalfunctions or other detectable side effects. We demonstrate the feasibility\nof this attack by computing efficient patches on multiple deep learning models.\nWe show that the desired trojan behavior can be induced with a few small\npatches and with limited access to training data. We describe the details of\nhow this attack is carried out on real systems and provide sample code for\npatching TensorFlow model parameters in Windows and in Linux. Lastly, we\npresent a technique for effectively manipulating entropy on perturbed inputs to\nbypass STRIP, a state-of-the-art run-time trojan detection technique.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:08:29 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 21:21:46 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Costales", "Robby", ""], ["Mao", "Chengzhi", ""], ["Norwitz", "Raphael", ""], ["Kim", "Bryan", ""], ["Yang", "Junfeng", ""]]}, {"id": "2004.11372", "submitter": "Ajitesh Srivastava", "authors": "Ajitesh Srivastava, Viktor K. Prasanna", "title": "Learning to Forecast and Forecasting to Learn from the COVID-19 Pandemic", "comments": "12 pages, 8 figures. Added a figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasts of COVID-19 is central to resource management and building\nstrategies to deal with the epidemic. We propose a heterogeneous infection rate\nmodel with human mobility for epidemic modeling, a preliminary version of which\nwe have successfully used during DARPA Grand Challenge 2014. By linearizing the\nmodel and using weighted least squares, our model is able to quickly adapt to\nchanging trends and provide extremely accurate predictions of confirmed cases\nat the level of countries and states of the United States. We show that during\nthe earlier part of the epidemic, using travel data increases the predictions.\nTraining the model to forecast also enables learning characteristics of the\nepidemic. In particular, we show that changes in model parameters over time can\nhelp us quantify how well a state or a country has responded to the epidemic.\nThe variations in parameters also allow us to forecast different scenarios such\nas what would happen if we were to disregard social distancing suggestions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 07:25:46 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 04:19:01 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 19:13:08 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Srivastava", "Ajitesh", ""], ["Prasanna", "Viktor K.", ""]]}, {"id": "2004.11380", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel M. Kane, Shachar Lovett, Gaurav Mahajan", "title": "Point Location and Active Learning: Learning Halfspaces Almost Optimally", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite set $X \\subset \\mathbb{R}^d$ and a binary linear classifier\n$c: \\mathbb{R}^d \\to \\{0,1\\}$, how many queries of the form $c(x)$ are required\nto learn the label of every point in $X$? Known as \\textit{point location},\nthis problem has inspired over 35 years of research in the pursuit of an\noptimal algorithm. Building on the prior work of Kane, Lovett, and Moran (ICALP\n2018), we provide the first nearly optimal solution, a randomized linear\ndecision tree of depth $\\tilde{O}(d\\log(|X|))$, improving on the previous best\nof $\\tilde{O}(d^2\\log(|X|))$ from Ezra and Sharir (Discrete and Computational\nGeometry, 2019). As a corollary, we also provide the first nearly optimal\nalgorithm for actively learning halfspaces in the membership query model. En\nroute to these results, we prove a novel characterization of Barthe's Theorem\n(Inventiones Mathematicae, 1998) of independent interest. In particular, we\nshow that $X$ may be transformed into approximate isotropic position if and\nonly if there exists no $k$-dimensional subspace with more than a\n$k/d$-fraction of $X$, and provide a similar characterization for exact\nisotropic position.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:00:00 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""], ["Mahajan", "Gaurav", ""]]}, {"id": "2004.11410", "submitter": "Giambattista Parascandolo", "authors": "Giambattista Parascandolo, Lars Buesing, Josh Merel, Leonard\n  Hasenclever, John Aslanides, Jessica B. Hamrick, Nicolas Heess, Alexander\n  Neitz, Theophane Weber", "title": "Divide-and-Conquer Monte Carlo Tree Search For Goal-Directed Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard planners for sequential decision making (including Monte Carlo\nplanning, tree search, dynamic programming, etc.) are constrained by an\nimplicit sequential planning assumption: The order in which a plan is\nconstructed is the same in which it is executed. We consider alternatives to\nthis assumption for the class of goal-directed Reinforcement Learning (RL)\nproblems. Instead of an environment transition model, we assume an imperfect,\ngoal-directed policy. This low-level policy can be improved by a plan,\nconsisting of an appropriate sequence of sub-goals that guide it from the start\nto the goal state. We propose a planning algorithm, Divide-and-Conquer Monte\nCarlo Tree Search (DC-MCTS), for approximating the optimal plan by means of\nproposing intermediate sub-goals which hierarchically partition the initial\ntasks into simpler ones that are then solved independently and recursively. The\nalgorithm critically makes use of a learned sub-goal proposal for finding\nappropriate partitions trees of new tasks based on prior experience. Different\nstrategies for learning sub-goal proposals give rise to different planning\nstrategies that strictly generalize sequential planning. We show that this\nalgorithmic flexibility over planning order leads to improved results in\nnavigation tasks in grid-worlds as well as in challenging continuous control\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:08:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Buesing", "Lars", ""], ["Merel", "Josh", ""], ["Hasenclever", "Leonard", ""], ["Aslanides", "John", ""], ["Hamrick", "Jessica B.", ""], ["Heess", "Nicolas", ""], ["Neitz", "Alexander", ""], ["Weber", "Theophane", ""]]}, {"id": "2004.11437", "submitter": "Douglas Matos De Souza", "authors": "Douglas M. Souza, J\\^onatas Wehrmann, Duncan D. Ruiz", "title": "Efficient Neural Architecture for Text-to-Image Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-image synthesis is the task of generating images from text\ndescriptions. Image generation, by itself, is a challenging task. When we\ncombine image generation and text, we bring complexity to a new level: we need\nto combine data from two different modalities. Most of recent works in\ntext-to-image synthesis follow a similar approach when it comes to neural\narchitectures. Due to aforementioned difficulties, plus the inherent difficulty\nof training GANs at high resolutions, most methods have adopted a multi-stage\ntraining strategy. In this paper we shift the architectural paradigm currently\nused in text-to-image methods and show that an effective neural architecture\ncan achieve state-of-the-art performance using a single stage training with a\nsingle generator and a single discriminator. We do so by applying deep residual\nnetworks along with a novel sentence interpolation strategy that enables\nlearning a smooth conditional space. Finally, our work points a new direction\nfor text-to-image research, which has not experimented with novel neural\narchitectures recently.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:33:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Souza", "Douglas M.", ""], ["Wehrmann", "J\u00f4natas", ""], ["Ruiz", "Duncan D.", ""]]}, {"id": "2004.11460", "submitter": "Jimmy Jose", "authors": "Amruthlal M, Devika S, Ameer Suhail P A, Aravind K Menon, Vignesh\n  Krishnan, Alan Thomas, Manu Thomas, Sanjay G, Lakshmi Kanth L R, Jimmy Jose,\n  Harikrishnan S", "title": "Development of a Machine Learning Model and Mobile Application to Aid in\n  Predicting Dosage of Vitamin K Antagonists Among Indian Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients who undergo mechanical heart valve replacements or have conditions\nlike Atrial Fibrillation have to take Vitamin K Antagonists (VKA) drugs to\nprevent coagulation of blood. These drugs have narrow therapeutic range and\nneed to be very closely monitored due to life threatening side effects. The\ndosage of VKA drug is determined and revised by a physician based on\nProthrombin Time - International Normalised Ratio (PT-INR) value obtained\nthrough a blood test. Our work aimed at predicting the maintenance dosage of\nwarfarin, the present most widely recommended anticoagulant drug, using the\nde-identified medical data collected from 109 patients from Kerala. A Support\nVector Machine (SVM) Regression model was built to predict the maintenance\ndosage of warfarin, for patients who have been undergoing treatment from a\nphysician and have reached stable INR values between 2.0 and 4.0.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 05:54:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["M", "Amruthlal", ""], ["S", "Devika", ""], ["A", "Ameer Suhail P", ""], ["Menon", "Aravind K", ""], ["Krishnan", "Vignesh", ""], ["Thomas", "Alan", ""], ["Thomas", "Manu", ""], ["G", "Sanjay", ""], ["R", "Lakshmi Kanth L", ""], ["Jose", "Jimmy", ""], ["S", "Harikrishnan", ""]]}, {"id": "2004.11464", "submitter": "Jocelyn Mazarura", "authors": "Jocelyn Mazarura, Alta de Waal and Pieter de Villiers", "title": "A Gamma-Poisson Mixture Topic Model for Short Text", "comments": "26 pages, 14 Figures, to be published in Mathematical Problems in\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most topic models are constructed under the assumption that documents follow\na multinomial distribution. The Poisson distribution is an alternative\ndistribution to describe the probability of count data. For topic modelling,\nthe Poisson distribution describes the number of occurrences of a word in\ndocuments of fixed length. The Poisson distribution has been successfully\napplied in text classification, but its application to topic modelling is not\nwell documented, specifically in the context of a generative probabilistic\nmodel. Furthermore, the few Poisson topic models in literature are admixture\nmodels, making the assumption that a document is generated from a mixture of\ntopics. In this study, we focus on short text. Many studies have shown that the\nsimpler assumption of a mixture model fits short text better. With mixture\nmodels, as opposed to admixture models, the generative assumption is that a\ndocument is generated from a single topic. One topic model, which makes this\none-topic-per-document assumption, is the Dirichlet-multinomial mixture model.\nThe main contributions of this work are a new Gamma-Poisson mixture model, as\nwell as a collapsed Gibbs sampler for the model. The benefit of the collapsed\nGibbs sampler derivation is that the model is able to automatically select the\nnumber of topics contained in the corpus. The results show that the\nGamma-Poisson mixture model performs better than the Dirichlet-multinomial\nmixture model at selecting the number of topics in labelled corpora.\nFurthermore, the Gamma-Poisson mixture produces better topic coherence scores\nthan the Dirichlet-multinomial mixture model, thus making it a viable option\nfor the challenging task of topic modelling of short text.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 21:13:53 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Mazarura", "Jocelyn", ""], ["de Waal", "Alta", ""], ["de Villiers", "Pieter", ""]]}, {"id": "2004.11468", "submitter": "Zsigmond Benk\\H{o}", "authors": "Zsigmond Benk\\H{o}, Tam\\'as B\\'abel, Zolt\\'an Somogyv\\'ari", "title": "How to find a unicorn: a novel model-free, unsupervised anomaly\n  detection method for time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of anomalous events is a challenging but critical task in many\nscientific and industrial fields, especially when the properties of anomalies\nare unknown. In this paper, we introduce a new anomaly concept called \"unicorn\"\nor unique event and present a new, model-free, unsupervised detection algorithm\nto detect unicorns. The key component of the new algorithm is the Temporal\nOutlier Factor (TOF) to measure the uniqueness of events in continuous data\nsets from dynamic systems. The concept of unique events differs significantly\nfrom traditional outliers in many aspects: while repetitive outliers are no\nlonger unique events, a unique event is not necessarily an outlier; it does not\nnecessarily fall out from the distribution of normal activity. The performance\nof our algorithm was examined in recognizing unique events on different types\nof simulated data sets with anomalies and it was compared with the Local\nOutlier Factor (LOF) and discord discovery algorithms. TOF had superior\nperformance compared to LOF and discord algorithms even in recognizing\ntraditional outliers and it also recognized unique events that those did not.\nThe benefits of the unicorn concept and the new detection method were\nillustrated by example data sets from very different scientific fields. Our\nalgorithm successfully recognized unique events in those cases where they were\nalready known such as the gravitational waves of a binary black hole merger on\nLIGO detector data and the signs of respiratory failure on ECG data series.\nFurthermore, unique events were found on the LIBOR data set of the last 30\nyears.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 21:38:38 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 14:58:17 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 09:08:02 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Benk\u0151", "Zsigmond", ""], ["B\u00e1bel", "Tam\u00e1s", ""], ["Somogyv\u00e1ri", "Zolt\u00e1n", ""]]}, {"id": "2004.11483", "submitter": "Leonardo Nascimento Ferreira", "authors": "Leonardo N. Ferreira, Didier A. Vega-Oliveros, Moshe Cotacallapa,\n  Manoel F. Cardoso, Marcos G. Quiles, Liang Zhao, Elbert E. N. Macau", "title": "Spatiotemporal data analysis with chronological networks", "comments": null, "journal-ref": "Nat Commun 11, 4036 (2020)", "doi": "10.1038/s41467-020-17634-2", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The amount and size of spatiotemporal data sets from different domains have\nbeen rapidly increasing in the last years, which demands the development of\nrobust and fast methods to analyze and extract information from them. In this\npaper, we propose a network-based model for spatiotemporal data analysis called\nchronnet. It consists of dividing a geometrical space into grid cells\nrepresented by nodes connected chronologically. The main goal of this model is\nto represent consecutive recurrent events between cells with strong links in\nthe network. This representation permits the use of network science and\ngraphing mining tools to extract information from spatiotemporal data. The\nchronnet construction process is fast, which makes it suitable for large data\nsets. In this paper, we describe how to use our model considering artificial\nand real data. For this purpose, we propose an artificial spatiotemporal data\nset generator to show how chronnets capture not just simple statistics, but\nalso frequent patterns, spatial changes, outliers, and spatiotemporal clusters.\nAdditionally, we analyze a real-world data set composed of global fire\ndetections, in which we describe the frequency of fire events, outlier fire\ndetections, and the seasonal activity, using a single chronnet.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 22:50:43 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 12:20:45 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ferreira", "Leonardo N.", ""], ["Vega-Oliveros", "Didier A.", ""], ["Cotacallapa", "Moshe", ""], ["Cardoso", "Manoel F.", ""], ["Quiles", "Marcos G.", ""], ["Zhao", "Liang", ""], ["Macau", "Elbert E. N.", ""]]}, {"id": "2004.11485", "submitter": "Dimitris Korobilis Prof", "authors": "Dimitris Korobilis", "title": "High-dimensional macroeconomic forecasting using message passing\n  algorithms", "comments": "89 pages; to appear in Journal of Business and Economic Statistics", "journal-ref": null, "doi": "10.1080/07350015.2019.1677472", "report-no": null, "categories": "stat.ME econ.EM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two distinct contributions to econometric analysis of\nlarge information sets and structural instabilities. First, it treats a\nregression model with time-varying coefficients, stochastic volatility and\nexogenous predictors, as an equivalent high-dimensional static regression\nproblem with thousands of covariates. Inference in this specification proceeds\nusing Bayesian hierarchical priors that shrink the high-dimensional vector of\ncoefficients either towards zero or time-invariance. Second, it introduces the\nframeworks of factor graphs and message passing as a means of designing\nefficient Bayesian estimation algorithms. In particular, a Generalized\nApproximate Message Passing (GAMP) algorithm is derived that has low\nalgorithmic complexity and is trivially parallelizable. The result is a\ncomprehensive methodology that can be used to estimate time-varying parameter\nregressions with arbitrarily large number of exogenous predictors. In a\nforecasting exercise for U.S. price inflation this methodology is shown to work\nvery well.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 23:10:04 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Korobilis", "Dimitris", ""]]}, {"id": "2004.11488", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Mengnan Du, Ruocheng Guo, Huan Liu, Xia Hu", "title": "Adversarial Attacks and Defenses: An Interpretation Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent advances in a wide spectrum of applications, machine\nlearning models, especially deep neural networks, have been shown to be\nvulnerable to adversarial attacks. Attackers add carefully-crafted\nperturbations to input, where the perturbations are almost imperceptible to\nhumans, but can cause models to make wrong predictions. Techniques to protect\nmodels against adversarial input are called adversarial defense methods.\nAlthough many approaches have been proposed to study adversarial attacks and\ndefenses in different scenarios, an intriguing and crucial challenge remains\nthat how to really understand model vulnerability? Inspired by the saying that\n\"if you know yourself and your enemy, you need not fear the battles\", we may\ntackle the aforementioned challenge after interpreting machine learning models\nto open the black-boxes. The goal of model interpretation, or interpretable\nmachine learning, is to extract human-understandable terms for the working\nmechanism of models. Recently, some approaches start incorporating\ninterpretation into the exploration of adversarial attacks and defenses.\nMeanwhile, we also observe that many existing methods of adversarial attacks\nand defenses, although not explicitly claimed, can be understood from the\nperspective of interpretation. In this paper, we review recent work on\nadversarial attacks and defenses, particularly from the perspective of machine\nlearning interpretation. We categorize interpretation into two types,\nfeature-level interpretation and model-level interpretation. For each type of\ninterpretation, we elaborate on how it could be used for adversarial attacks\nand defenses. We then briefly illustrate additional correlations between\ninterpretation and adversaries. Finally, we discuss the challenges and future\ndirections along tackling adversary issues with interpretation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 23:19:00 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 15:43:26 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Liu", "Ninghao", ""], ["Du", "Mengnan", ""], ["Guo", "Ruocheng", ""], ["Liu", "Huan", ""], ["Hu", "Xia", ""]]}, {"id": "2004.11494", "submitter": "Yanjun  Qi Dr.", "authors": "Arshdeep Sekhon, Beilun Wang, Zhe Wang, Yanjun Qi", "title": "Differential Network Learning Beyond Data Samples", "comments": "9 pages of main draft; 25 pages of Appendix; 5 Tables ; 14 Figures ;\n  Learning of Structure Difference between Two Graphical Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the change of statistical dependencies between random variables is\nan essential task for many real-life applications, mostly in the high\ndimensional low sample regime. In this paper, we propose a novel differential\nparameter estimator that, in comparison to current methods, simultaneously\nallows (a) the flexible integration of multiple sources of information (data\nsamples, variable groupings, extra pairwise evidence, etc.), (b) being scalable\nto a large number of variables, and (c) achieving a sharp asymptotic\nconvergence rate. Our experiments, on more than 100 simulated and two\nreal-world datasets, validate the flexibility of our approach and highlight the\nbenefits of integrating spatial and anatomic information for brain connectome\nchange discovery and epigenetic network identification.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 00:01:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Sekhon", "Arshdeep", ""], ["Wang", "Beilun", ""], ["Wang", "Zhe", ""], ["Qi", "Yanjun", ""]]}, {"id": "2004.11497", "submitter": "Thanh Vinh Vo", "authors": "Thanh Vinh Vo, Pengfei Wei, Wicher Bergsma, Tze-Yun Leong", "title": "Causal Modeling with Stochastic Confounders", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends causal inference with stochastic confounders. We propose a\nnew approach to variational estimation for causal inference based on a\nrepresenter theorem with a random input space. We estimate causal effects\ninvolving latent confounders that may be interdependent and time-varying from\nsequential, repeated measurements in an observational study. Our approach\nextends current work that assumes independent, non-temporal latent confounders,\nwith potentially biased estimators. We introduce a simple yet elegant algorithm\nwithout parametric specification on model components. Our method avoids the\nneed for expensive and careful parameterization in deploying complex models,\nsuch as deep neural networks, for causal inference in existing approaches. We\ndemonstrate the effectiveness of our approach on various benchmark temporal\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 00:34:44 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 00:43:40 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 11:46:47 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 05:53:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Vo", "Thanh Vinh", ""], ["Wei", "Pengfei", ""], ["Bergsma", "Wicher", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2004.11506", "submitter": "Tao Wang", "authors": "Tao Wang, Junsong Wang, Chang Xu and Chao Xue", "title": "Automatic low-bit hybrid quantization of neural networks through meta\n  learning", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model quantization is a widely used technique to compress and accelerate deep\nneural network (DNN) inference, especially when deploying to edge or IoT\ndevices with limited computation capacity and power consumption budget. The\nuniform bit width quantization across all the layers is usually sub-optimal and\nthe exploration of hybrid quantization for different layers is vital for\nefficient deep compression. In this paper, we employ the meta learning method\nto automatically realize low-bit hybrid quantization of neural networks. A\nMetaQuantNet, together with a Quantization function, are trained to generate\nthe quantized weights for the target DNN. Then, we apply a genetic algorithm to\nsearch the best hybrid quantization policy that meets compression constraints.\nWith the best searched quantization policy, we subsequently retrain or finetune\nto further improve the performance of the quantized target network. Extensive\nexperiments demonstrate the performance of searched hybrid quantization scheme\nsurpass that of uniform bitwidth counterpart. Compared to the existing\nreinforcement learning (RL) based hybrid quantization search approach that\nrelies on tedious explorations, our meta learning approach is more efficient\nand effective for any compression requirements since the MetaQuantNet only\nneeds be trained once.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 02:01:26 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wang", "Tao", ""], ["Wang", "Junsong", ""], ["Xu", "Chang", ""], ["Xue", "Chao", ""]]}, {"id": "2004.11515", "submitter": "Konstantin Pieper", "authors": "Konstantin Pieper and Armenak Petrosyan", "title": "Nonconvex penalization for sparse neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training methods for artificial neural networks often rely on\nover-parameterization and random initialization in order to avoid spurious\nlocal minima of the loss function that fail to fit the data properly. To\nsidestep this, one can employ convex neural networks, which combine a convex\ninterpretation of the loss term, sparsity promoting penalization of the outer\nweights, and greedy neuron insertion. However, the canonical $\\ell_1$ penalty\ndoes not achieve a sufficient reduction in the number of nodes in a shallow\nnetwork in the presence of large amounts of data, as observed in practice and\nsupported by our theory. As a remedy, we propose a nonconvex penalization\nmethod for the outer weights that maintains the advantages of the convex\napproach. We investigate the analytic aspects of the method in the context of\nneural network integral representations and prove attainability of minimizers,\ntogether with a finite support property and approximation guarantees.\nAdditionally, we describe how to numerically solve the minimization problem\nwith an adaptive algorithm combining local gradient based training, and\nadaptive node insertion and extraction.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 03:03:21 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Pieper", "Konstantin", ""], ["Petrosyan", "Armenak", ""]]}, {"id": "2004.11530", "submitter": "Joyce Whang", "authors": "Joyce Jiyoung Whang and Inderjit S. Dhillon", "title": "Non-Exhaustive, Overlapping Co-Clustering: An Extended Analysis", "comments": null, "journal-ref": "\"Non-Exhaustive, Overlapping Co-Clustering\", Proceedings of the\n  26th ACM Conference on Information and Knowledge Management (CIKM), pages\n  2367-2370, November 2017", "doi": "10.1145/3132847.3133078", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of co-clustering is to simultaneously identify a clustering of rows\nas well as columns of a two dimensional data matrix. A number of co-clustering\ntechniques have been proposed including information-theoretic co-clustering and\nthe minimum sum-squared residue co-clustering method. However, most existing\nco-clustering algorithms are designed to find pairwise disjoint and exhaustive\nco-clusters while many real-world datasets contain not only a large overlap\nbetween co-clusters but also outliers which should not belong to any\nco-cluster. In this paper, we formulate the problem of Non-Exhaustive,\nOverlapping Co-Clustering where both of the row and column clusters are allowed\nto overlap with each other and outliers for each dimension of the data matrix\nare not assigned to any cluster. To solve this problem, we propose intuitive\nobjective functions, and develop an an efficient iterative algorithm which we\ncall the NEO-CC algorithm. We theoretically show that the NEO-CC algorithm\nmonotonically decreases the proposed objective functions. Experimental results\nshow that the NEO-CC algorithm is able to effectively capture the underlying\nco-clustering structure of real-world data, and thus outperforms\nstate-of-the-art clustering and co-clustering methods. This manuscript includes\nan extended analysis of [21].\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 04:39:14 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Whang", "Joyce Jiyoung", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "2004.11532", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia, Foster Provost, Jesse Anderton, Benjamin\n  Carterette, Praveen Chandar", "title": "A Comparison of Methods for Treatment Assignment with an Application to\n  Playlist Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a systematic comparison of methods for individual\ntreatment assignment, a general problem that arises in many applications and\nhas received significant attention from economists, computer scientists, and\nsocial scientists. We characterize the various methods proposed in the\nliterature into three general approaches: learning models to predict outcomes,\nlearning models to predict causal effects, and learning models to predict\noptimal treatment assignments. We show analytically that optimizing for outcome\nor causal effect prediction is not the same as optimizing for treatment\nassignments, and thus we should prefer learning models that optimize for\ntreatment assignments. We then compare and contrast the three approaches\nempirically in the context of choosing, for each user, the best algorithm for\nplaylist generation in order to optimize engagement. This is the first\ncomparison of the different treatment assignment approaches on a real-world\napplication at scale (based on more than half a billion individual treatment\nassignments). Our results show (i) that applying different algorithms to\ndifferent users can improve streams substantially compared to deploying the\nsame algorithm for everyone, (ii) that personalized assignments improve\nsubstantially with larger data sets, and (iii) that learning models by\noptimizing for treatment assignment can increase engagement by 28% more than\nwhen optimizing for outcome or causal effect predictions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 04:56:15 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 03:27:10 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 14:33:52 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 17:51:45 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Provost", "Foster", ""], ["Anderton", "Jesse", ""], ["Carterette", "Benjamin", ""], ["Chandar", "Praveen", ""]]}, {"id": "2004.11545", "submitter": "Seyed Iman Mirzadeh", "authors": "Seyed-Iman Mirzadeh, Mehrdad Farajtabar, Hassan Ghasemzadeh", "title": "Dropout as an Implicit Gating Mechanism For Continual Learning", "comments": "CVPR 2020 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have demonstrated an outstanding ability to\nachieve complex learning tasks across various domains. However, they suffer\nfrom the \"catastrophic forgetting\" problem when they face a sequence of\nlearning tasks, where they forget the old ones as they learn new tasks. This\nproblem is also highly related to the \"stability-plasticity dilemma\". The more\nplastic the network, the easier it can learn new tasks, but the faster it also\nforgets previous ones. Conversely, a stable network cannot learn new tasks as\nfast as a very plastic network. However, it is more reliable to preserve the\nknowledge it has learned from the previous tasks. Several solutions have been\nproposed to overcome the forgetting problem by making the neural network\nparameters more stable, and some of them have mentioned the significance of\ndropout in continual learning. However, their relationship has not been\nsufficiently studied yet. In this paper, we investigate this relationship and\nshow that a stable network with dropout learns a gating mechanism such that for\ndifferent tasks, different paths of the network are active. Our experiments\nshow that the stability achieved by this implicit gating plays a very critical\nrole in leading to performance comparable to or better than other involved\ncontinual learning algorithms to overcome catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 06:04:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Mirzadeh", "Seyed-Iman", ""], ["Farajtabar", "Mehrdad", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2004.11587", "submitter": "Anjin Liu", "authors": "Anjin Liu, Jie Lu, Guangquan Zhang", "title": "Concept Drift Detection via Equal Intensity k-means Space Partitioning", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, vol. Early Access, pp. 1-C14,\n  2020", "doi": "10.1109/TCYB.2020.2983962", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stream poses additional challenges to statistical classification tasks\nbecause distributions of the training and target samples may differ as time\npasses. Such distribution change in streaming data is called concept drift.\nNumerous histogram-based distribution change detection methods have been\nproposed to detect drift. Most histograms are developed on grid-based or\ntree-based space partitioning algorithms which makes the space partitions\narbitrary, unexplainable, and may cause drift blind-spots. There is a need to\nimprove the drift detection accuracy for histogram-based methods with the\nunsupervised setting. To address this problem, we propose a cluster-based\nhistogram, called equal intensity k-means space partitioning (EI-kMeans). In\naddition, a heuristic method to improve the sensitivity of drift detection is\nintroduced. The fundamental idea of improving the sensitivity is to minimize\nthe risk of creating partitions in distribution offset regions. Pearson's\nchi-square test is used as the statistical hypothesis test so that the test\nstatistics remain independent of the sample distribution. The number of bins\nand their shapes, which strongly influence the ability to detect drift, are\ndetermined dynamically from the sample based on an asymptotic constraint in the\nchi-square test. Accordingly, three algorithms are developed to implement\nconcept drift detection, including a greedy centroids initialization algorithm,\na cluster amplify-shrink algorithm, and a drift detection algorithm. For drift\nadaptation, we recommend retraining the learner if a drift is detected. The\nresults of experiments on synthetic and real-world datasets demonstrate the\nadvantages of EI-kMeans and show its efficacy in detecting concept drift.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 08:00:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Anjin", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2004.11627", "submitter": "Zhongzhan Huang", "authors": "Zhongzhan Huang, Wenqi Shao, Xinjiang Wang, Ping Luo", "title": "Convolution-Weight-Distribution Assumption: Rethinking the Criteria of\n  Channel Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel pruning is a popular technique for compressing convolutional neural\nnetworks (CNNs), where various pruning criteria have been proposed to remove\nthe redundant filters. From our comprehensive experiments, we found two blind\nspots in the study of pruning criteria: (1) Similarity: There are some strong\nsimilarities among several primary pruning criteria that are widely cited and\ncompared. According to these criteria, the ranks of filters'Importance Score\nare almost identical, resulting in similar pruned structures. (2)\nApplicability: The filters'Importance Score measured by some pruning criteria\nare too close to distinguish the network redundancy well. In this paper, we\nanalyze these two blind spots on different types of pruning criteria with\nlayer-wise pruning or global pruning. The analyses are based on the empirical\nexperiments and our assumption (Convolutional Weight Distribution Assumption)\nthat the well-trained convolutional filters each layer approximately follow a\nGaussian-alike distribution. This assumption has been verified through\nsystematic and extensive statistical tests.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 09:54:21 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 06:36:14 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Shao", "Wenqi", ""], ["Wang", "Xinjiang", ""], ["Luo", "Ping", ""]]}, {"id": "2004.11648", "submitter": "Cheng-Te Li", "authors": "Yi-Ju Lu and Cheng-Te Li", "title": "GCAN: Graph-aware Co-Attention Networks for Explainable Fake News\n  Detection on Social Media", "comments": "To appear in Proceedings of The 58th Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020. Code is available here\n  https://github.com/l852888/GCAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper solves the fake news detection problem under a more realistic\nscenario on social media. Given the source short-text tweet and the\ncorresponding sequence of retweet users without text comments, we aim at\npredicting whether the source tweet is fake or not, and generating explanation\nby highlighting the evidences on suspicious retweeters and the words they\nconcern. We develop a novel neural network-based model, Graph-aware\nCo-Attention Networks (GCAN), to achieve the goal. Extensive experiments\nconducted on real tweet datasets exhibit that GCAN can significantly outperform\nstate-of-the-art methods by 16% in accuracy on average. In addition, the case\nstudies also show that GCAN can produce reasonable explanations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 10:42:49 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Lu", "Yi-Ju", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2004.11667", "submitter": "Guillaume Matheron", "authors": "Guillaume Matheron, Nicolas Perrin, Olivier Sigaud", "title": "PBCS : Efficient Exploration and Exploitation Using a Synergy between\n  Reinforcement Learning and Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration-exploitation trade-off is at the heart of reinforcement\nlearning (RL). However, most continuous control benchmarks used in recent RL\nresearch only require local exploration. This led to the development of\nalgorithms that have basic exploration capabilities, and behave poorly in\nbenchmarks that require more versatile exploration. For instance, as\ndemonstrated in our empirical study, state-of-the-art RL algorithms such as\nDDPG and TD3 are unable to steer a point mass in even small 2D mazes. In this\npaper, we propose a new algorithm called \"Plan, Backplay, Chain Skills\" (PBCS)\nthat combines motion planning and reinforcement learning to solve hard\nexploration environments. In a first phase, a motion planning algorithm is used\nto find a single good trajectory, then an RL algorithm is trained using a\ncurriculum derived from the trajectory, by combining a variant of the Backplay\nalgorithm and skill chaining. We show that this method outperforms\nstate-of-the-art RL algorithms in 2D maze environments of various sizes, and is\nable to improve on the trajectory obtained by the motion planning phase.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 11:37:09 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Matheron", "Guillaume", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2004.11675", "submitter": "Ying Da Wang", "authors": "Ying Da Wang, Traiwit Chung, Ryan T. Armstrong, and Peyman Mostaghimi", "title": "ML-LBM: Machine Learning Aided Flow Simulation in Porous Media", "comments": "23 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation of fluid flow in porous media has many applications, from the\nmicro-scale (cell membranes, filters, rocks) to macro-scale (groundwater,\nhydrocarbon reservoirs, and geothermal) and beyond. Direct simulation of flow\nin porous media requires significant computational resources to solve within\nreasonable timeframes. An integrated method combining predictions of fluid flow\n(fast, limited accuracy) with direct flow simulation (slow, high accuracy) is\noutlined. In the tortuous flow paths of porous media, Deep Learning techniques\nbased on Convolutional Neural Networks (CNNs) are shown to give an accurate\nestimate of the steady state velocity fields (in all axes), and by extension,\nthe macro-scale permeability. This estimate can be used as-is, or as initial\nconditions in direct simulation to reach a fully accurate result in a fraction\nof the compute time. A Gated U-Net Convolutional Neural Network is trained on a\ndatasets of 2D and 3D porous media generated by correlated fields, with their\nsteady state velocity fields calculated from direct LBM simulation. Sensitivity\nanalysis indicates that network accuracy is dependent on (1) the tortuosity of\nthe domain, (2) the size of convolution filters, (3) the use of distance maps\nas input, (4) the use of mass conservation loss functions. Permeability\nestimation from these predicted fields reaches over 90\\% accuracy for 80\\% of\ncases. It is further shown that these velocity fields are error prone when used\nfor solute transport simulation. Using the predicted velocity fields as initial\nconditions is shown to accelerate direct flow simulation to physically true\nsteady state conditions an order of magnitude less compute time. Using Deep\nLearning predictions (or potentially any other approximation method) to\naccelerate flow simulation to steady state in complex pore structures shows\npromise as a technique push the boundaries fluid flow modelling.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 01:55:59 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Da Wang", "Ying", ""], ["Chung", "Traiwit", ""], ["Armstrong", "Ryan T.", ""], ["Mostaghimi", "Peyman", ""]]}, {"id": "2004.11685", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Yann Chevaleyre, Jeremy Rapin, Cl\\'ement W. Royer,\n  Olivier Teytaud", "title": "On averaging the best samples in evolutionary computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing the right selection rate is a long standing issue in evolutionary\ncomputation. In the continuous unconstrained case, we prove mathematically that\na single parent $\\mu=1$ leads to a sub-optimal simple regret in the case of the\nsphere function. We provide a theoretically-based selection rate $\\mu/\\lambda$\nthat leads to better progress rates. With our choice of selection rate, we get\na provable regret of order $O(\\lambda^{-1})$ which has to be compared with\n$O(\\lambda^{-2/d})$ in the case where $\\mu=1$. We complete our study with\nexperiments to confirm our theoretical claims.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:25:39 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 13:22:44 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 18:32:33 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Meunier", "Laurent", ""], ["Chevaleyre", "Yann", ""], ["Rapin", "Jeremy", ""], ["Royer", "Cl\u00e9ment W.", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2004.11687", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Carola Doerr, Jeremy Rapin, Olivier Teytaud", "title": "Variance Reduction for Better Sampling in Continuous Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of experiments, random search, initialization of population-based\nmethods, or sampling inside an epoch of an evolutionary algorithm use a sample\ndrawn according to some probability distribution for approximating the location\nof an optimum. Recent papers have shown that the optimal search distribution,\nused for the sampling, might be more peaked around the center of the\ndistribution than the prior distribution modelling our uncertainty about the\nlocation of the optimum. We confirm this statement, provide explicit values for\nthis reshaping of the search distribution depending on the population size\n$\\lambda$ and the dimension $d$, and validate our results experimentally.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:25:48 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Meunier", "Laurent", ""], ["Doerr", "Carola", ""], ["Rapin", "Jeremy", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2004.11691", "submitter": "Peter Wakeford", "authors": "Peter Robert Wakeford, Enrico Pellegrini, Gavin Robertson, Michael\n  Verhoek, Alan Duncan Fleming, Jano van Hemert and Ik Siong Heng", "title": "Optic disc and fovea localisation in ultra-widefield scanning laser\n  ophthalmoscope images captured in multiple modalities", "comments": "Submitted to the 23rd Conference on Medical Image Understanding and\n  Analysis (MIUA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a convolutional neural network for localising the centres of the\noptic disc (OD) and fovea in ultra-wide field of view scanning laser\nophthalmoscope (UWFoV-SLO) images of the retina. Images captured in both\nreflectance and autofluorescence (AF) modes, and central pole and eyesteered\ngazes, were used. The method achieved an OD localisation accuracy of 99.4%\nwithin one OD radius, and fovea localisation accuracy of 99.1% within one OD\nradius on a test set comprising of 1790 images. The performance of fovea\nlocalisation in AF images was comparable to the variation between human\nannotators at this task. The laterality of the image (whether the image is of\nthe left or right eye) was inferred from the OD and fovea coordinates with an\naccuracy of 99.9%\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:29:10 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wakeford", "Peter Robert", ""], ["Pellegrini", "Enrico", ""], ["Robertson", "Gavin", ""], ["Verhoek", "Michael", ""], ["Fleming", "Alan Duncan", ""], ["van Hemert", "Jano", ""], ["Heng", "Ik Siong", ""]]}, {"id": "2004.11694", "submitter": "Navedanjum Ansari Mr", "authors": "Navedanjum Ansari, Rajesh Sharma", "title": "Identifying Semantically Duplicate Questions Using Data Science\n  Approach: A Quora Case Study", "comments": "11 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying semantically identical questions on, Question and Answering\nsocial media platforms like Quora is exceptionally significant to ensure that\nthe quality and the quantity of content are presented to users, based on the\nintent of the question and thus enriching overall user experience. Detecting\nduplicate questions is a challenging problem because natural language is very\nexpressive, and a unique intent can be conveyed using different words, phrases,\nand sentence structuring. Machine learning and deep learning methods are known\nto have accomplished superior results over traditional natural language\nprocessing techniques in identifying similar texts. In this paper, taking Quora\nfor our case study, we explored and applied different machine learning and deep\nlearning techniques on the task of identifying duplicate questions on Quora's\ndataset. By using feature engineering, feature importance techniques, and\nexperimenting with seven selected machine learning classifiers, we demonstrated\nthat our models outperformed previous studies on this task. Xgboost model with\ncharacter level term frequency and inverse term frequency is our best machine\nlearning model that has also outperformed a few of the Deep learning baseline\nmodels. We applied deep learning techniques to model four different deep neural\nnetworks of multiple layers consisting of Glove embeddings, Long Short Term\nMemory, Convolution, Max pooling, Dense, Batch Normalization, Activation\nfunctions, and model merge. Our deep learning models achieved better accuracy\nthan machine learning models. Three out of four proposed architectures\noutperformed the accuracy from previous machine learning and deep learning\nresearch work, two out of four models outperformed accuracy from previous deep\nlearning study on Quora's question pair dataset, and our best model achieved\naccuracy of 85.82% which is close to Quora state of the art accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 19:39:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ansari", "Navedanjum", ""], ["Sharma", "Rajesh", ""]]}, {"id": "2004.11697", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab and Jaydip Sen", "title": "A Time Series Analysis-Based Stock Price Prediction Using Machine\n  Learning and Deep Learning Models", "comments": "This is the preprint of our paper accepted for publication in the\n  Inderscience Journal International Journal of Business Forecasting and\n  Marketing Intelligence. The paper consists of 53 pages, 26 Tables, and 46\n  Figures", "journal-ref": "International Journal of Business Forecasting and Marketing\n  Intelligence (IJBFMI), Vol 6, No 4, pp. 272 - 335, 2020. Inderscience\n  Publishers", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future movement of stock prices has always been a challenging\ntask for the researchers. While the advocates of the efficient market\nhypothesis (EMH) believe that it is impossible to design any predictive\nframework that can accurately predict the movement of stock prices, there are\nseminal work in the literature that have clearly demonstrated that the\nseemingly random movement patterns in the time series of a stock price can be\npredicted with a high level of accuracy. Design of such predictive models\nrequires choice of appropriate variables, right transformation methods of the\nvariables, and tuning of the parameters of the models. In this work, we present\na very robust and accurate framework of stock price prediction that consists of\nan agglomeration of statistical, machine learning and deep learning models. We\nuse the daily stock price data, collected at five minutes interval of time, of\na very well known company that is listed in the National Stock Exchange (NSE)\nof India. The granular data is aggregated into three slots in a day, and the\naggregated data is used for building and training the forecasting models. We\ncontend that the agglomerative approach of model building that uses a\ncombination of statistical, machine learning, and deep learning approaches, can\nvery effectively learn from the volatile and random movement patterns in a\nstock price data. We build eight classification and eight regression models\nbased on statistical and machine learning approaches. In addition to these\nmodels, a deep learning regression model using a long-and-short-term memory\n(LSTM) network is also built. Extensive results have been presented on the\nperformance of these models, and the results are critically analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:41:22 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 14:46:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""]]}, {"id": "2004.11706", "submitter": "Sanjay Kumar Sonbhadra Mr.", "authors": "Sanjay Kumar Sonbhadra, Sonali Agarwal and P. Nagabhushan", "title": "Target specific mining of COVID-19 scholarly articles using one-class\n  approach", "comments": null, "journal-ref": "Chaos, Solitons and Fractals, 2020", "doi": "10.1016/j.chaos.2020.110155", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several research articles have been published in the field\nof corona-virus caused diseases like severe acute respiratory syndrome (SARS),\nmiddle east respiratory syndrome (MERS) and COVID-19. In the presence of\nnumerous research articles, extracting best-suited articles is time-consuming\nand manually impractical. The objective of this paper is to extract the\nactivity and trends of corona-virus related research articles using machine\nlearning approaches. The COVID-19 open research dataset (CORD-19) is used for\nexperiments, whereas several target-tasks along with explanations are defined\nfor classification, based on domain knowledge. Clustering techniques are used\nto create the different clusters of available articles, and later the task\nassignment is performed using parallel one-class support vector machines\n(OCSVMs). Experiments with original and reduced features validate the\nperformance of the approach. It is evident that the k-means clustering\nalgorithm, followed by parallel OCSVMs, outperforms other methods for both\noriginal and reduced feature space.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:39:54 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 13:31:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sonbhadra", "Sanjay Kumar", ""], ["Agarwal", "Sonali", ""], ["Nagabhushan", "P.", ""]]}, {"id": "2004.11722", "submitter": "Houssam Zenati", "authors": "Houssam Zenati, Alberto Bietti, Matthieu Martin, Eustache Diemert,\n  Julien Mairal", "title": "Counterfactual Learning of Continuous Stochastic Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual reasoning from logged data has become increasingly important\nfor many applications such as web advertising or healthcare. In this paper, we\naddress the problem of counterfactual risk minimization (CRM) for learning a\nstochastic policy with continuous actions. First, we introduce a new modelling\nstrategy based on a joint kernel embedding of contexts and actions, which\novercomes the shortcomings of previous discretization strategies. Second, we\nempirically show that the optimization perspective of CRM is more important\nthan previously thought, and we demonstrate the benefits of proximal point\nalgorithms and differentiable estimators. Finally, we propose an evaluation\nprotocol for offline policies in real-world logged systems, which is\nchallenging since policies cannot be replayed on test data, and we release a\nnew large-scale dataset along with multiple synthetic, yet realistic,\nevaluation setups.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 07:42:30 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 18:40:02 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 15:07:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zenati", "Houssam", ""], ["Bietti", "Alberto", ""], ["Martin", "Matthieu", ""], ["Diemert", "Eustache", ""], ["Mairal", "Julien", ""]]}, {"id": "2004.11734", "submitter": "Jules Depersin", "authors": "Jules Depersin", "title": "Robust subgaussian estimation with VC-dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Median-of-means (MOM) based procedures provide non-asymptotic and strong\ndeviation bounds even when data are heavy-tailed and/or corrupted. This work\nproposes a new general way to bound the excess risk for MOM estimators. The\ncore technique is the use of VC-dimension (instead of Rademacher complexity) to\nmeasure the statistical complexity. In particular, this allows to give the\nfirst robust estimators for sparse estimation which achieves the so-called\nsubgaussian rate only assuming a finite second moment for the uncorrupted data.\nBy comparison, previous works using Rademacher complexities required a number\nof finite moments that grows logarithmically with the dimension. With this\ntechnique, we derive new robust sugaussian bounds for mean estimation in any\nnorm. We also derive a new robust estimator for covariance estimation that is\nthe first to achieve subgaussian bounds without $L_4-L_2$ norm equivalence.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 13:21:09 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:59:18 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 16:16:13 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Depersin", "Jules", ""]]}, {"id": "2004.11766", "submitter": "Cemil Dibek", "authors": "Matthew Andrews, Cemil Dibek, Karina Palyutina", "title": "Evolution of Q Values for Deep Q Learning in Stable Baselines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the evolution of the Q values for the implementation of Deep Q\nLearning (DQL) in the Stable Baselines library. Stable Baselines incorporates\nthe latest Reinforcement Learning techniques and achieves superhuman\nperformance in many game environments. However, for some simple non-game\nenvironments, the DQL in Stable Baselines can struggle to find the correct\nactions. In this paper we aim to understand the types of environment where this\nsuboptimal behavior can happen, and also investigate the corresponding\nevolution of the Q values for individual states.\n  We compare a smart TrafficLight environment (where performance is poor) with\nthe AI Gym FrozenLake environment (where performance is perfect). We observe\nthat DQL struggles with TrafficLight because actions are reversible and hence\nthe Q values in a given state are closer than in FrozenLake. We then\ninvestigate the evolution of the Q values using a recent decomposition\ntechnique of Achiam et al.. We observe that for TrafficLight, the function\napproximation error and the complex relationships between the states lead to a\nsituation where some Q values meander far from optimal.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:13:46 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Andrews", "Matthew", ""], ["Dibek", "Cemil", ""], ["Palyutina", "Karina", ""]]}, {"id": "2004.11778", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Junaid Malik, Habib Ben Abdallah, Turker Ince,\n  Alexandros Iosifidis and Moncef Gabbouj", "title": "Self-Organized Operational Neural Networks with Generative Neurons", "comments": "14 pages, 14 figures, journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operational Neural Networks (ONNs) have recently been proposed to address the\nwell-known limitations and drawbacks of conventional Convolutional Neural\nNetworks (CNNs) such as network homogeneity with the sole linear neuron model.\nONNs are heterogenous networks with a generalized neuron model that can\nencapsulate any set of non-linear operators to boost diversity and to learn\nhighly complex and multi-modal functions or spaces with minimal network\ncomplexity and training data. However, Greedy Iterative Search (GIS) method,\nwhich is the search method used to find optimal operators in ONNs takes many\ntraining sessions to find a single operator set per layer. This is not only\ncomputationally demanding, but the network heterogeneity is also limited since\nthe same set of operators will then be used for all neurons in each layer.\nMoreover, the performance of ONNs directly depends on the operator set library\nused, which introduces a certain risk of performance degradation especially\nwhen the optimal operator set required for a particular task is missing from\nthe library. In order to address these issues and achieve an ultimate\nheterogeneity level to boost the network diversity along with computational\nefficiency, in this study we propose Self-organized ONNs (Self-ONNs) with\ngenerative neurons that have the ability to adapt (optimize) the nodal operator\nof each connection during the training process. Therefore, Self-ONNs can have\nan utmost heterogeneity level required by the learning problem at hand.\nMoreover, this ability voids the need of having a fixed operator set library\nand the prior operator search within the library in order to find the best\npossible set of operators. We further formulate the training method to\nback-propagate the error through the operational layers of Self-ONNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:37:56 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Malik", "Junaid", ""], ["Abdallah", "Habib Ben", ""], ["Ince", "Turker", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2004.11791", "submitter": "Christopher Briggs", "authors": "Christopher Briggs, Zhong Fan, Peter Andras", "title": "Federated learning with hierarchical clustering of local updates to\n  improve training on non-IID data", "comments": "Accepted to 2020 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a well established method for performing machine\nlearning tasks over massively distributed data. However in settings where data\nis distributed in a non-iid (not independent and identically distributed)\nfashion -- as is typical in real world situations -- the joint model produced\nby FL suffers in terms of test set accuracy and/or communication costs compared\nto training on iid data. We show that learning a single joint model is often\nnot optimal in the presence of certain types of non-iid data. In this work we\npresent a modification to FL by introducing a hierarchical clustering step\n(FL+HC) to separate clusters of clients by the similarity of their local\nupdates to the global joint model. Once separated, the clusters are trained\nindependently and in parallel on specialised models. We present a robust\nempirical analysis of the hyperparameters for FL+HC for several iid and non-iid\nsettings. We show how FL+HC allows model training to converge in fewer\ncommunication rounds (significantly so under some non-iid settings) compared to\nFL without clustering. Additionally, FL+HC allows for a greater percentage of\nclients to reach a target accuracy compared to standard FL. Finally we make\nsuggestions for good default hyperparameters to promote superior performing\nspecialised models without modifying the the underlying federated learning\ncommunication protocol.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:16:01 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:28:10 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Briggs", "Christopher", ""], ["Fan", "Zhong", ""], ["Andras", "Peter", ""]]}, {"id": "2004.11794", "submitter": "Christopher Briggs", "authors": "Christopher Briggs, Zhong Fan, Peter Andras", "title": "A Review of Privacy-preserving Federated Learning for the\n  Internet-of-Things", "comments": "Abstract accepted for publication in a book titled: \"Federated\n  Learning Systems: Towards Next Generation AI\" in Springer's Series on\n  Studides in Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet-of-Things (IoT) generates vast quantities of data, much of it\nattributable to individuals' activity and behaviour. Gathering personal data\nand performing machine learning tasks on this data in a central location\npresents a significant privacy risk to individuals as well as challenges with\ncommunicating this data to the cloud. However, analytics based on machine\nlearning and in particular deep learning benefit greatly from large amounts of\ndata to develop high-performance predictive models. This work reviews federated\nlearning as an approach for performing machine learning on distributed data\nwith the goal of protecting the privacy of user-generated data as well as\nreducing communication costs associated with data transfer. We survey a wide\nvariety of papers covering communication-efficiency, client heterogeneity and\nprivacy preserving methods that are crucial for federated learning in the\ncontext of the IoT. Throughout this review, we identify the strengths and\nweaknesses of different methods applied to federated learning and finally, we\noutline future directions for privacy preserving federated learning research,\nparticularly focusing on IoT applications.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:27:23 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 14:08:19 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Briggs", "Christopher", ""], ["Fan", "Zhong", ""], ["Andras", "Peter", ""]]}, {"id": "2004.11803", "submitter": "Larissa Triess", "authors": "Larissa T. Triess, David Peter, Christoph B. Rist, J. Marius Z\\\"ollner", "title": "Scan-based Semantic Segmentation of LiDAR Point Clouds: An Experimental\n  Study", "comments": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2020. The code\n  can be found here: http://ltriess.github.io/scan-semseg", "journal-ref": null, "doi": "10.1109/IV47402.2020.9304631", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles need to have a semantic understanding of the\nthree-dimensional world around them in order to reason about their environment.\nState of the art methods use deep neural networks to predict semantic classes\nfor each point in a LiDAR scan. A powerful and efficient way to process LiDAR\nmeasurements is to use two-dimensional, image-like projections. In this work,\nwe perform a comprehensive experimental study of image-based semantic\nsegmentation architectures for LiDAR point clouds. We demonstrate various\ntechniques to boost the performance and to improve runtime as well as memory\nconstraints.\n  First, we examine the effect of network size and suggest that much faster\ninference times can be achieved at a very low cost to accuracy. Next, we\nintroduce an improved point cloud projection technique that does not suffer\nfrom systematic occlusions. We use a cyclic padding mechanism that provides\ncontext at the horizontal field-of-view boundaries. In a third part, we perform\nexperiments with a soft Dice loss function that directly optimizes for the\nintersection-over-union metric. Finally, we propose a new kind of convolution\nlayer with a reduced amount of weight-sharing along one of the two spatial\ndimensions, addressing the large difference in appearance along the vertical\naxis of a LiDAR scan. We propose a final set of the above methods with which\nthe model achieves an increase of 3.2% in mIoU segmentation performance over\nthe baseline while requiring only 42% of the original inference time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:08:12 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 07:12:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Triess", "Larissa T.", ""], ["Peter", "David", ""], ["Rist", "Christoph B.", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2004.11812", "submitter": "Pascal Klink", "authors": "Pascal Klink, Carlo D'Eramo, Jan Peters, Joni Pajarinen", "title": "Self-Paced Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum reinforcement learning (CRL) improves the learning speed and\nstability of an agent by exposing it to a tailored series of tasks throughout\nlearning. Despite empirical successes, an open question in CRL is how to\nautomatically generate a curriculum for a given reinforcement learning (RL)\nagent, avoiding manual design. In this paper, we propose an answer by\ninterpreting the curriculum generation as an inference problem, where\ndistributions over tasks are progressively learned to approach the target task.\nThis approach leads to an automatic curriculum generation, whose pace is\ncontrolled by the agent, with solid theoretical motivation and easily\nintegrated with deep RL algorithms. In the conducted experiments, the curricula\ngenerated with the proposed algorithm significantly improve learning\nperformance across several environments and deep RL algorithms, matching or\noutperforming state-of-the-art existing CRL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:48:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 11:51:39 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 13:41:19 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 19:51:56 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 09:42:00 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Klink", "Pascal", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2004.11815", "submitter": "Yiye Jiang", "authors": "Yiye Jiang (1 and 2), J\\'er\\'emie Bigot (1) and Sofian Maabout (2)\n  ((1) Institut de Math\\'ematiques de Bordeaux, Universit\\'e de Bordeaux, (2)\n  Laboratoire Bordelais de Recherche en Informatique, Universit\\'e de Bordeaux)", "title": "Sensor selection on graphs via data-driven node sub-sampling in network\n  time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned by the problem of selecting an optimal sampling set\nof sensors over a network of time series for the purpose of signal recovery at\nnon-observed sensors with a minimal reconstruction error. The problem is\nmotivated by applications where time-dependent graph signals are collected over\nredundant networks. In this setting, one may wish to only use a subset of\nsensors to predict data streams over the whole collection of nodes in the\nunderlying graph. A typical application is the possibility to reduce the power\nconsumption in a network of sensors that may have limited battery supplies. We\npropose and compare various data-driven strategies to turn off a fixed number\nof sensors or equivalently to select a sampling set of nodes. We also relate\nour approach to the existing literature on sensor selection from multivariate\ndata with a (possibly) underlying graph structure. Our methodology combines\ntools from multivariate time series analysis, graph signal processing,\nstatistical learning in high-dimension and deep learning. To illustrate the\nperformances of our approach, we report numerical experiments on the analysis\nof real data from bike sharing networks in different cities.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:51:57 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Jiang", "Yiye", "", "1 and 2"], ["Bigot", "J\u00e9r\u00e9mie", ""], ["Maabout", "Sofian", ""]]}, {"id": "2004.11819", "submitter": "Junhee Kim", "authors": "Younghwan Na, Jun Hee Kim, Kyungsu Lee, Juhum Park, Jae Youn Hwang,\n  Jihwan P. Choi", "title": "Domain Adaptive Transfer Attack (DATA)-based Segmentation Networks for\n  Building Extraction from Aerial Images", "comments": "11pages, 12 figures", "journal-ref": null, "doi": "10.1109/TGRS.2020.3010055", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation models based on convolutional neural networks (CNNs)\nhave gained much attention in relation to remote sensing and have achieved\nremarkable performance for the extraction of buildings from high-resolution\naerial images. However, the issue of limited generalization for unseen images\nremains. When there is a domain gap between the training and test datasets,\nCNN-based segmentation models trained by a training dataset fail to segment\nbuildings for the test dataset. In this paper, we propose segmentation networks\nbased on a domain adaptive transfer attack (DATA) scheme for building\nextraction from aerial images. The proposed system combines the domain transfer\nand adversarial attack concepts. Based on the DATA scheme, the distribution of\nthe input images can be shifted to that of the target images while turning\nimages into adversarial examples against a target network. Defending\nadversarial examples adapted to the target domain can overcome the performance\ndegradation due to the domain gap and increase the robustness of the\nsegmentation model. Cross-dataset experiments and the ablation study are\nconducted for the three different datasets: the Inria aerial image labeling\ndataset, the Massachusetts building dataset, and the WHU East Asia dataset.\nCompared to the performance of the segmentation network without the DATA\nscheme, the proposed method shows improvements in the overall IoU. Moreover, it\nis verified that the proposed method outperforms even when compared to feature\nadaptation (FA) and output space adaptation (OSA).\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:17:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 06:12:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Na", "Younghwan", ""], ["Kim", "Jun Hee", ""], ["Lee", "Kyungsu", ""], ["Park", "Juhum", ""], ["Hwang", "Jae Youn", ""], ["Choi", "Jihwan P.", ""]]}, {"id": "2004.11820", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma, Xiang Kong, Shanghang Zhang, Eduard Hovy", "title": "Decoupling Global and Local Representations via Invertible Generative\n  Flows", "comments": "Camera-ready at ICLR 2021. 23 pages (plus appendix), 16 figures, 5\n  tables. Due to arxiv size constraints, this version is using downscaled\n  images. Please download the full-resolution version from\n  https://vixra.org/abs/2004.0222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new generative model that is capable of\nautomatically decoupling global and local representations of images in an\nentirely unsupervised setting, by embedding a generative flow in the VAE\nframework to model the decoder. Specifically, the proposed model utilizes the\nvariational auto-encoding framework to learn a (low-dimensional) vector of\nlatent variables to capture the global information of an image, which is fed as\na conditional input to a flow-based invertible decoder with architecture\nborrowed from style transfer literature. Experimental results on standard image\nbenchmarks demonstrate the effectiveness of our model in terms of density\nestimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive\nbiases, a generative model with a likelihood-based objective is capable of\nlearning decoupled representations, requiring no explicit supervision. The code\nfor our model is available at https://github.com/XuezheMax/wolf.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 03:18:13 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 20:17:34 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ma", "Xuezhe", ""], ["Kong", "Xiang", ""], ["Zhang", "Shanghang", ""], ["Hovy", "Eduard", ""]]}, {"id": "2004.11829", "submitter": "Ievgen Redko", "authors": "Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, Youn\\`es\n  Bennani", "title": "A survey on domain adaptation theory: learning bounds and theoretical\n  guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All famous machine learning algorithms that comprise both supervised and\nsemi-supervised learning work well only under a common assumption: the training\nand test data follow the same distribution. When the distribution changes, most\nstatistical models must be reconstructed from newly collected data, which for\nsome applications can be costly or impossible to obtain. Therefore, it has\nbecome necessary to develop approaches that reduce the need and the effort to\nobtain new labeled samples by exploiting data that are available in related\nareas, and using these further across similar fields. This has given rise to a\nnew machine learning framework known as transfer learning: a learning setting\ninspired by the capability of a human being to extrapolate knowledge across\ntasks to learn more efficiently. Despite a large amount of different transfer\nlearning scenarios, the main objective of this survey is to provide an overview\nof the state-of-the-art theoretical results in a specific, and arguably the\nmost popular, sub-field of transfer learning, called domain adaptation. In this\nsub-field, the data distribution is assumed to change across the training and\nthe test data, while the learning task remains the same. We provide a first\nup-to-date description of existing results related to domain adaptation problem\nthat cover learning bounds based on different statistical learning frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 16:11:03 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:29:02 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 12:04:58 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 11:57:24 GMT"}, {"version": "v5", "created": "Thu, 6 Aug 2020 13:34:43 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Redko", "Ievgen", ""], ["Morvant", "Emilie", ""], ["Habrard", "Amaury", ""], ["Sebban", "Marc", ""], ["Bennani", "Youn\u00e8s", ""]]}, {"id": "2004.11834", "submitter": "Grzegorz Dudek", "authors": "Pawe{\\l} Pe{\\l}ka and Grzegorz Dudek", "title": "Pattern-based Long Short-term Memory for Mid-term Electrical Load\n  Forecasting", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a Long Short-Term Memory (LSTM) network for forecasting a\nmonthly electricity demand time series with a one-year horizon. The novelty of\nthis work is the use of pattern representation of the seasonal time series as\nan alternative to decomposition. Pattern representation simplifies the complex\nnonlinear and nonstationary time series, filtering out the trend and equalizing\nvariance. Two types of patterns are defined: x-pattern and y-pattern. The\nformer requires additional forecasting for the coding variables. The latter\ndetermines the coding variables from the process history. A hybrid approach\nbased on x-patterns turned out to be more accurate than the standard LSTM\napproach based on a raw time series. In this combined approach an x-pattern is\nforecasted using a sequence-to-sequence LSTM network and the coding variables\nare forecasted using exponential smoothing. A simulation study performed on the\nmonthly electricity demand time series for 35 European countries confirmed the\nhigh performance of the proposed model and its competitiveness to classical\nmodels such as ARIMA and exponential smoothing as well as the MLP neural\nnetwork model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:39:32 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Pe\u0142ka", "Pawe\u0142", ""], ["Dudek", "Grzegorz", ""]]}, {"id": "2004.11836", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Convolutional Neural Network Array for Sign Language Recognition using\n  Wearable IMUs", "comments": "https://doi.org/10.1109/SPIN.2019.8711745", "journal-ref": null, "doi": "10.1109/SPIN.2019.8711745", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in gesture recognition algorithms have led to a significant\ngrowth in sign language translation. By making use of efficient intelligent\nmodels, signs can be recognized with precision. The proposed work presents a\nnovel one-dimensional Convolutional Neural Network (CNN) array architecture for\nrecognition of signs from the Indian sign language using signals recorded from\na custom designed wearable IMU device. The IMU device makes use of tri-axial\naccelerometer and gyroscope. The signals recorded using the IMU device are\nsegregated on the basis of their context, such as whether they correspond to\nsigning for a general sentence or an interrogative sentence. The array\ncomprises of two individual CNNs, one classifying the general sentences and the\nother classifying the interrogative sentence. Performances of individual CNNs\nin the array architecture are compared to that of a conventional CNN\nclassifying the unsegregated dataset. Peak classification accuracies of 94.20%\nfor general sentences and 95.00% for interrogative sentences achieved with the\nproposed CNN array in comparison to 93.50% for conventional CNN assert the\nsuitability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:11:04 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2004.11839", "submitter": "Chang Wei Tan", "authors": "Chang Wei Tan, Mahsa Salehi, Geoffrey Mackellar", "title": "Detecting Driver's Distraction using Long-term Recurrent Convolutional\n  Network", "comments": "3 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we demonstrate a novel Brain Computer Interface (BCI) approach\nto detect driver distraction events to improve road safety. We use a commercial\nwireless headset that generates EEG signals from the brain. We collected real\nEEG signals from participants who undertook a 40-minute driving simulation and\nwere required to perform different tasks while driving. These signals are\nsegmented into short windows and labelled using a time series classification\n(TSC) model. We studied different TSC approaches and designed a Long-term\nRecurrent Convolutional Network (LCRN) model for this task. Our results showed\nthat our LRCN model performs better than the state of the art TSC models at\ndetecting driver distraction events.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:35:28 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tan", "Chang Wei", ""], ["Salehi", "Mahsa", ""], ["Mackellar", "Geoffrey", ""]]}, {"id": "2004.11841", "submitter": "Felix Sattler", "authors": "Felix Sattler, Jackie Ma, Patrick Wagner, David Neumann, Markus\n  Wenzel, Ralf Sch\\\"afer, Wojciech Samek, Klaus-Robert M\\\"uller, Thomas Wiegand", "title": "Risk Estimation of SARS-CoV-2 Transmission from Bluetooth Low Energy\n  Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.PE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contact tracing approaches based on Bluetooth low energy (BLE) have\nthe potential to efficiently contain and delay outbreaks of infectious diseases\nsuch as the ongoing SARS-CoV-2 pandemic. In this work we propose a novel\nmachine learning based approach to reliably detect subjects that have spent\nenough time in close proximity to be at risk of being infected. Our study is an\nimportant proof of concept that will aid the battery of epidemiological\npolicies aiming to slow down the rapid spread of COVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 20:10:35 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Sattler", "Felix", ""], ["Ma", "Jackie", ""], ["Wagner", "Patrick", ""], ["Neumann", "David", ""], ["Wenzel", "Markus", ""], ["Sch\u00e4fer", "Ralf", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Wiegand", "Thomas", ""]]}, {"id": "2004.11848", "submitter": "Chao Zhou", "authors": "Xinting Yang, Song Zhang, Jintao Liu, Qinfeng Gao, Shuanglin Dong,\n  Chao Zhou", "title": "Deep learning for smart fish farming: applications, opportunities and\n  challenges", "comments": "43 pages, 7 figures", "journal-ref": "Reviews in aquaculture,2020", "doi": "10.1111/raq.12464", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid emergence of deep learning (DL) technology, it has been\nsuccessfully used in various fields including aquaculture. This change can\ncreate new opportunities and a series of challenges for information and data\nprocessing in smart fish farming. This paper focuses on the applications of DL\nin aquaculture, including live fish identification, species classification,\nbehavioral analysis, feeding decision-making, size or biomass estimation, water\nquality prediction. In addition, the technical details of DL methods applied to\nsmart fish farming are also analyzed, including data, algorithms, computing\npower, and performance. The results of this review show that the most\nsignificant contribution of DL is the ability to automatically extract\nfeatures. However, challenges still exist; DL is still in an era of weak\nartificial intelligence. A large number of labeled data are needed for\ntraining, which has become a bottleneck restricting further DL applications in\naquaculture. Nevertheless, DL still offers breakthroughs in the handling of\ncomplex data in aquaculture. In brief, our purpose is to provide researchers\nand practitioners with a better understanding of the current state of the art\nof DL in aquaculture, which can provide strong support for the implementation\nof smart fish farming.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:07:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:11:22 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Yang", "Xinting", ""], ["Zhang", "Song", ""], ["Liu", "Jintao", ""], ["Gao", "Qinfeng", ""], ["Dong", "Shuanglin", ""], ["Zhou", "Chao", ""]]}, {"id": "2004.11890", "submitter": "Thibaut Vidal", "authors": "Daniel Gribel, Thibaut Vidal, Michel Gendreau", "title": "Assortative-Constrained Stochastic Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic block models (SBMs) are often used to find assortative community\nstructures in networks, such that the probability of connections within\ncommunities is higher than in between communities. However, classic SBMs are\nnot limited to assortative structures. In this study, we discuss the\nimplications of this model-inherent indifference towards assortativity or\ndisassortativity, and show that this characteristic can lead to undesirable\noutcomes for networks which are presupposedy assortative but which contain a\nreduced amount of information. To circumvent this issue, we introduce a\nconstrained SBM that imposes strong assortativity constraints, along with\nefficient algorithmic approaches to solve it. These constraints significantly\nboost community recovery capabilities in regimes that are close to the\ninformation-theoretic threshold. They also permit to identify\nstructurally-different communities in networks representing cerebral-cortex\nactivity regions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:52:59 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Gribel", "Daniel", ""], ["Vidal", "Thibaut", ""], ["Gendreau", "Michel", ""]]}, {"id": "2004.11898", "submitter": "Nathaniel Bastian PhD", "authors": "Elie Alhajjar and Paul Maxwell and Nathaniel D. Bastian", "title": "Adversarial Machine Learning in Network Intrusion Detection Systems", "comments": "25 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs to a machine learning system intentionally\ncrafted by an attacker to fool the model into producing an incorrect output.\nThese examples have achieved a great deal of success in several domains such as\nimage recognition, speech recognition and spam detection. In this paper, we\nstudy the nature of the adversarial problem in Network Intrusion Detection\nSystems (NIDS). We focus on the attack perspective, which includes techniques\nto generate adversarial examples capable of evading a variety of machine\nlearning models. More specifically, we explore the use of evolutionary\ncomputation (particle swarm optimization and genetic algorithm) and deep\nlearning (generative adversarial networks) as tools for adversarial example\ngeneration. To assess the performance of these algorithms in evading a NIDS, we\napply them to two publicly available data sets, namely the NSL-KDD and\nUNSW-NB15, and we contrast them to a baseline perturbation method: Monte Carlo\nsimulation. The results show that our adversarial example generation techniques\ncause high misclassification rates in eleven different machine learning models,\nalong with a voting classifier. Our work highlights the vulnerability of\nmachine learning based NIDS in the face of adversarial perturbation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:47:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Alhajjar", "Elie", ""], ["Maxwell", "Paul", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2004.11909", "submitter": "Diego Alberto Mercado-Ravell Dr.", "authors": "Marichelo Garcia-Venegas, Diego A. Mercado-Ravell and Carlos A.\n  Carballo-Monsivais", "title": "On the safety of vulnerable road users by cyclist orientation detection\n  using Deep Learning", "comments": "\"This paper is a preprint of a paper submitted to IET Intelligent\n  Transport Systems. If accepted, the copy of record will be available at the\n  IET Digital Library\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, orientation detection using Deep Learning is acknowledged for a\nparticularly vulnerable class of road users,the cyclists. Knowing the cyclists'\norientation is of great relevance since it provides a good notion about their\nfuture trajectory, which is crucial to avoid accidents in the context of\nintelligent transportation systems. Using Transfer Learning with pre-trained\nmodels and TensorFlow, we present a performance comparison between the main\nalgorithms reported in the literature for object detection,such as SSD, Faster\nR-CNN and R-FCN along with MobilenetV2, InceptionV2, ResNet50, ResNet101\nfeature extractors. Moreover, we propose multi-class detection with eight\ndifferent classes according to orientations. To do so, we introduce a new\ndataset called \"Detect-Bike\", containing 20,229 cyclist instances over 11,103\nimages, which has been labeled based on cyclist's orientation. Then, the same\nDeep Learning methods used for detection are trained to determine the target's\nheading. Our experimental results and vast evaluation showed satisfactory\nperformance of all of the studied methods for the cyclists and their\norientation detection, especially using Faster R-CNN with ResNet50 proved to be\nprecise but significantly slower. Meanwhile, SSD using InceptionV2 provided\ngood trade-off between precision and execution time, and is to be preferred for\nreal-time embedded applications.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 18:10:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Garcia-Venegas", "Marichelo", ""], ["Mercado-Ravell", "Diego A.", ""], ["Carballo-Monsivais", "Carlos A.", ""]]}, {"id": "2004.11910", "submitter": "Gang Liu", "authors": "Gang Liu and Jing Wang", "title": "A Relation Spectrum Inheriting Taylor Series: Muscle Synergy and\n  Coupling for Hand", "comments": "Dendrite Net and Relation spectrum unify online performance and\n  offline results", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two famous function decomposition methods in math: Taylor Series\nand Fourier Series. Fourier series developed into Fourier spectrum, which was\napplied to signal decomposition\\analysis. However, because the Taylor series\nwhose function without a definite functional expression cannot be solved,\nTaylor Series has rarely been used in engineering. Here, we developed Taylor\nseries by our Dendrite Net, constructed a relation spectrum, and applied it to\nmodel or system decomposition\\analysis. Specific engineering: the knowledge of\nthe intuitive link between muscle activity and the finger movement is vital for\nthe design of commercial prosthetic hands that do not need user pre-training.\nHowever, this link has yet to be understood due to the complexity of human\nhand. In this study, the relation spectrum was applied to analyze the\nmuscle-finger system. One single muscle actuates multiple fingers, or multiple\nmuscles actuate one single finger simultaneously. Thus, the research was in\nmuscle synergy and muscle coupling for hand. This paper has two main\ncontributions. (1) The findings of hand contribute to designing prosthetic\nhands. (2) The relation spectrum makes the online model human-readable, which\nunifies online performance and offline results. Code (novel tool for most\nfields) is available at https://github.com/liugang1234567/Gang-neuron.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:26:11 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 09:42:09 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 21:37:35 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Liu", "Gang", ""], ["Wang", "Jing", ""]]}, {"id": "2004.11929", "submitter": "Nathan Musoke", "authors": "Grigor Aslanyan, Richard Easther, Nathan Musoke, Layne C. Price", "title": "Robust posterior inference when statistically emulating forward\n  simulations", "comments": "code available from https://doi.org/10.5281/zenodo.3764460 or\n  https://github.com/auckland-cosmo/LearnAsYouGoEmulator", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific analyses often rely on slow, but accurate forward models for\nobservable data conditioned on known model parameters. While various emulation\nschemes exist to approximate these slow calculations, these approaches are only\nsafe if the approximations are well understood and controlled. This workshop\nsubmission reviews and updates a previously published method, which has been\nused in cosmological simulations, to (1) train an emulator while simultaneously\nestimating posterior probabilities with MCMC and (2) explicitly propagate the\nemulation error into errors on the posterior probabilities for model\nparameters. We demonstrate how these techniques can be applied to quickly\nestimate posterior distributions for parameters of the $\\Lambda$CDM cosmology\nmodel, while also gauging the robustness of the emulator approximation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:15:59 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Aslanyan", "Grigor", ""], ["Easther", "Richard", ""], ["Musoke", "Nathan", ""], ["Price", "Layne C.", ""]]}, {"id": "2004.11934", "submitter": "Ruohong Zhang", "authors": "Ruohong Zhang, Yu Hao, Donghan Yu, Wei-Cheng Chang, Guokun Lai, Yiming\n  Yang", "title": "Correlation-aware Unsupervised Change-point Detection via Graph Neural\n  Networks", "comments": "Accepted for publication in the International Conference on Neural\n  Information Processing (ICONIP) 2020 Original paper is 12 pages, additional\n  appendix is available on arxiv", "journal-ref": "ICONIP 2020: Neural Information Processing", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change-point detection (CPD) aims to detect abrupt changes over time series\ndata. Intuitively, effective CPD over multivariate time series should require\nexplicit modeling of the dependencies across input variables. However, existing\nCPD methods either ignore the dependency structures entirely or rely on the\n(unrealistic) assumption that the correlation structures are static over time.\nIn this paper, we propose a Correlation-aware Dynamics Model for CPD, which\nexplicitly models the correlation structure and dynamics of variables by\nincorporating graph neural networks into an encoder-decoder framework.\nExtensive experiments on synthetic and real-world datasets demonstrate the\nadvantageous performance of the proposed model on CPD tasks over strong\nbaselines, as well as its ability to classify the change-points as correlation\nchanges or independent changes. Keywords: Multivariate Time Series,\nChange-point Detection, Graph Neural Networks\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:28:57 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 05:07:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Ruohong", ""], ["Hao", "Yu", ""], ["Yu", "Donghan", ""], ["Chang", "Wei-Cheng", ""], ["Lai", "Guokun", ""], ["Yang", "Yiming", ""]]}, {"id": "2004.11935", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Yoshua Bengio, Matthew Botvinick, Sergey Levine", "title": "The Variational Bandwidth Bottleneck: Stochastic Evaluation on an\n  Information Budget", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, it is desirable to extract only the relevant\ninformation from complex input data, which involves making a decision about\nwhich input features are relevant. The information bottleneck method formalizes\nthis as an information-theoretic optimization problem by maintaining an optimal\ntradeoff between compression (throwing away irrelevant input information), and\npredicting the target. In many problem settings, including the reinforcement\nlearning problems we consider in this work, we might prefer to compress only\npart of the input. This is typically the case when we have a standard\nconditioning input, such as a state observation, and a \"privileged\" input,\nwhich might correspond to the goal of a task, the output of a costly planning\nalgorithm, or communication with another agent. In such cases, we might prefer\nto compress the privileged input, either to achieve better generalization\n(e.g., with respect to goals) or to minimize access to costly information\n(e.g., in the case of communication). Practical implementations of the\ninformation bottleneck based on variational inference require access to the\nprivileged input in order to compute the bottleneck variable, so although they\nperform compression, this compression operation itself needs unrestricted,\nlossless access. In this work, we propose the variational bandwidth bottleneck,\nwhich decides for each example on the estimated value of the privileged\ninformation before seeing it, i.e., only based on the standard input, and then\naccordingly chooses stochastically, whether to access the privileged input or\nnot. We formulate a tractable approximation to this framework and demonstrate\nin a series of reinforcement learning experiments that it can improve\ngeneralization and reduce access to computationally costly information.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:29:31 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Botvinick", "Matthew", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.11938", "submitter": "Rico Jonschkowski", "authors": "Michael Zhu, Kevin Murphy, Rico Jonschkowski", "title": "Towards Differentiable Resampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resampling is a key component of sample-based recursive state estimation in\nparticle filters. Recent work explores differentiable particle filters for\nend-to-end learning. However, resampling remains a challenge in these works, as\nit is inherently non-differentiable. We address this challenge by replacing\ntraditional resampling with a learned neural network resampler. We present a\nnovel network architecture, the particle transformer, and train it for particle\nresampling using a likelihood-based loss function over sets of particles.\nIncorporated into a differentiable particle filter, our model can be end-to-end\noptimized jointly with the other particle filter components via gradient\ndescent. Our results show that our learned resampler outperforms traditional\nresampling techniques on synthetic data and in a simulated robot localization\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:37:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhu", "Michael", ""], ["Murphy", "Kevin", ""], ["Jonschkowski", "Rico", ""]]}, {"id": "2004.11946", "submitter": "Fei Sun", "authors": "Fei Sun, Minghai Qin, Tianyun Zhang, Liu Liu, Yen-Kuang Chen, Yuan Xie", "title": "Computation on Sparse Neural Networks: an Inspiration for Future\n  Hardware", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models are widely used in solving many challenging problems,\nsuch as computer vision, personalized recommendation, and natural language\nprocessing. Those models are very computationally intensive and reach the\nhardware limit of the existing server and IoT devices. Thus, finding better\nmodel architectures with much less amount of computation while maximally\npreserving the accuracy is a popular research topic. Among various mechanisms\nthat aim to reduce the computation complexity, identifying the zero values in\nthe model weights and in the activations to avoid computing them is a promising\ndirection.\n  In this paper, we summarize the current status of the research on the\ncomputation of sparse neural networks, from the perspective of the sparse\nalgorithms, the software frameworks, and the hardware accelerations. We observe\nthat the search for the sparse structure can be a general methodology for\nhigh-quality model explorations, in addition to a strategy for high-efficiency\nmodel execution. We discuss the model accuracy influenced by the number of\nweight parameters and the structure of the model. The corresponding models are\ncalled to be located in the weight dominated and structure dominated regions,\nrespectively. We show that for practically complicated problems, it is more\nbeneficial to search large and sparse models in the weight dominated region. In\norder to achieve the goal, new approaches are required to search for proper\nsparse structures, and new sparse training hardware needs to be developed to\nfacilitate fast iterations of sparse models.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:13:50 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sun", "Fei", ""], ["Qin", "Minghai", ""], ["Zhang", "Tianyun", ""], ["Liu", "Liu", ""], ["Chen", "Yen-Kuang", ""], ["Xie", "Yuan", ""]]}, {"id": "2004.11947", "submitter": "Jiri Kubalik", "authors": "J. Kubal\\'ik, E. Derner, R. Babu\\v{s}ka", "title": "Symbolic Regression Driven by Training Data and Prior Knowledge", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3377930.3390152", "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symbolic regression, the search for analytic models is typically driven\npurely by the prediction error observed on the training data samples. However,\nwhen the data samples do not sufficiently cover the input space, the prediction\nerror does not provide sufficient guidance toward desired models. Standard\nsymbolic regression techniques then yield models that are partially incorrect,\nfor instance, in terms of their steady-state characteristics or local behavior.\nIf these properties were considered already during the search process, more\naccurate and relevant models could be produced. We propose a multi-objective\nsymbolic regression approach that is driven by both the training data and the\nprior knowledge of the properties the desired model should manifest. The\nproperties given in the form of formal constraints are internally represented\nby a set of discrete data samples on which candidate models are exactly\nchecked. The proposed approach was experimentally evaluated on three test\nproblems with results clearly demonstrating its capability to evolve realistic\nmodels that fit the training data well while complying with the prior knowledge\nof the desired model characteristics at the same time. It outperforms standard\nsymbolic regression by several orders of magnitude in terms of the mean squared\ndeviation from a reference model.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:15:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kubal\u00edk", "J.", ""], ["Derner", "E.", ""], ["Babu\u0161ka", "R.", ""]]}, {"id": "2004.11963", "submitter": "Shatian Wang", "authors": "Shatian Wang, Shuoguang Yang, Zhen Xu, Van-Anh Truong", "title": "Online Learning with Cumulative Oversampling: Application to Budgeted\n  Influence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cumulative oversampling (CO) method for online learning. Our key\nidea is to sample parameter estimations from the updated belief space once in\neach round (similar to Thompson Sampling), and utilize the cumulative samples\nup to the current round to construct optimistic parameter estimations that\nasymptotically concentrate around the true parameters as tighter upper\nconfidence bounds compared to the ones constructed with standard UCB methods.\nWe apply CO to a novel budgeted variant of the Influence Maximization (IM)\nsemi-bandits with linear generalization of edge weights, whose offline problem\nis NP-hard. Combining CO with the oracle we design for the offline problem, our\nonline learning algorithm simultaneously tackles budget allocation, parameter\nlearning, and reward maximization. We show that for IM semi-bandits, our\nCO-based algorithm achieves a scaled regret comparable to that of the UCB-based\nalgorithms in theory, and performs on par with Thompson Sampling in numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:46:41 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 04:11:57 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 01:51:09 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Shatian", ""], ["Yang", "Shuoguang", ""], ["Xu", "Zhen", ""], ["Truong", "Van-Anh", ""]]}, {"id": "2004.11967", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou, Massimiliano Patacchiola, Mateusz Ochal and Amos\n  Storkey", "title": "Defining Benchmarks for Continual Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both few-shot and continual learning have seen substantial progress in the\nlast years due to the introduction of proper benchmarks. That being said, the\nfield has still to frame a suite of benchmarks for the highly desirable setting\nof continual few-shot learning, where the learner is presented a number of\nfew-shot tasks, one after the other, and then asked to perform well on a\nvalidation set stemming from all previously seen tasks. Continual few-shot\nlearning has a small computational footprint and is thus an excellent setting\nfor efficient investigation and experimentation. In this paper we first define\na theoretical framework for continual few-shot learning, taking into account\nrecent literature, then we propose a range of flexible benchmarks that unify\nthe evaluation criteria and allows exploring the problem from multiple\nperspectives. As part of the benchmark, we introduce a compact variant of\nImageNet, called SlimageNet64, which retains all original 1000 classes but only\ncontains 200 instances of each one (a total of 200K data-points) downscaled to\n64 x 64 pixels. We provide baselines for the proposed benchmarks using a number\nof popular few-shot learning algorithms, as a result, exposing previously\nunknown strengths and weaknesses of those algorithms in continual and\ndata-limited settings.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:41:01 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Antoniou", "Antreas", ""], ["Patacchiola", "Massimiliano", ""], ["Ochal", "Mateusz", ""], ["Storkey", "Amos", ""]]}, {"id": "2004.11985", "submitter": "Nina Varney", "authors": "Nina Varney, Vijayan K. Asari and Quinn Graehling", "title": "DALES: A Large-scale Aerial LiDAR Data Set for Semantic Segmentation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Dayton Annotated LiDAR Earth Scan (DALES) data set, a new\nlarge-scale aerial LiDAR data set with over a half-billion hand-labeled points\nspanning 10 square kilometers of area and eight object categories. Large\nannotated point cloud data sets have become the standard for evaluating deep\nlearning methods. However, most of the existing data sets focus on data\ncollected from a mobile or terrestrial scanner with few focusing on aerial\ndata. Point cloud data collected from an Aerial Laser Scanner (ALS) presents a\nnew set of challenges and applications in areas such as 3D urban modeling and\nlarge-scale surveillance. DALES is the most extensive publicly available ALS\ndata set with over 400 times the number of points and six times the resolution\nof other currently available annotated aerial point cloud data sets. This data\nset gives a critical number of expert verified hand-labeled points for the\nevaluation of new 3D deep learning algorithms, helping to expand the focus of\ncurrent algorithms to aerial data. We describe the nature of our data,\nannotation workflow, and provide a benchmark of current state-of-the-art\nalgorithm performance on the DALES data set.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 20:05:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Varney", "Nina", ""], ["Asari", "Vijayan K.", ""], ["Graehling", "Quinn", ""]]}, {"id": "2004.11992", "submitter": "Bram Wallace", "authors": "Bram Wallace, Bharath Hariharan", "title": "Extending and Analyzing Self-Supervised Learning Across Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning has achieved impressive results in\nrecent years, with experiments primarily coming on ImageNet or other similarly\nlarge internet imagery datasets. There has been little to no work with these\nmethods on other smaller domains, such as satellite, textural, or biological\nimagery. We experiment with several popular methods on an unprecedented variety\nof domains. We discover, among other findings, that Rotation is by far the most\nsemantically meaningful task, with much of the performance of Jigsaw and\nInstance Discrimination being attributable to the nature of their induced\ndistribution rather than semantic understanding. Additionally, there are\nseveral areas, such as fine-grain classification, where all tasks underperform.\nWe quantitatively and qualitatively diagnose the reasons for these failures and\nsuccesses via novel experiments studying pretext generalization, random\nlabelings, and implicit dimensionality. Code and models are available at\nhttps://github.com/BramSW/Extending_SSRL_Across_Domains/.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:18:02 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 16:13:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wallace", "Bram", ""], ["Hariharan", "Bharath", ""]]}, {"id": "2004.12019", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Philip M. Long", "title": "Finite-sample Analysis of Interpolating Linear Classifiers in the\n  Overparameterized Regime", "comments": "Corrected typographical errors from the previous version of this\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove bounds on the population risk of the maximum margin algorithm for\ntwo-class linear classification. For linearly separable training data, the\nmaximum margin algorithm has been shown in previous work to be equivalent to a\nlimit of training with logistic loss using gradient descent, as the training\nerror is driven to zero. We analyze this algorithm applied to random data\nincluding misclassification noise. Our assumptions on the clean data include\nthe case in which the class-conditional distributions are standard normal\ndistributions. The misclassification noise may be chosen by an adversary,\nsubject to a limit on the fraction of corrupted labels. Our bounds show that,\nwith sufficient over-parameterization, the maximum margin algorithm trained on\nnoisy data can achieve nearly optimal population risk.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:06:18 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 05:46:13 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 21:45:53 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 18:03:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Long", "Philip M.", ""]]}, {"id": "2004.12028", "submitter": "Jixiong Wang", "authors": "Jixiong Wang, Ashish Patel, James M.S. Wason, Paul J. Newcombe", "title": "Two-Stage Penalized Regression Screening to Detect Biomarker-Treatment\n  Interactions in Randomized Clinical Trials", "comments": "Accepted version, to be published in Biometrics", "journal-ref": null, "doi": "10.1111/biom.13424", "report-no": null, "categories": "stat.ME cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional biomarkers such as genomics are increasingly being measured\nin randomized clinical trials. Consequently, there is a growing interest in\ndeveloping methods that improve the power to detect biomarker-treatment\ninteractions. We adapt recently proposed two-stage interaction detecting\nprocedures in the setting of randomized clinical trials. We also propose a new\nstage 1 multivariate screening strategy using ridge regression to account for\ncorrelations among biomarkers. For this multivariate screening, we prove the\nasymptotic between-stage independence, required for family-wise error rate\ncontrol, under biomarker-treatment independence. Simulation results show that\nin various scenarios, the ridge regression screening procedure can provide\nsubstantially greater power than the traditional one-biomarker-at-a-time\nscreening procedure in highly correlated data. We also exemplify our approach\nin two real clinical trial data applications.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:50:09 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 19:48:30 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wang", "Jixiong", ""], ["Patel", "Ashish", ""], ["Wason", "James M. S.", ""], ["Newcombe", "Paul J.", ""]]}, {"id": "2004.12041", "submitter": "Gina Adam", "authors": "Siyuan Huang, Brian D. Hoskins, Matthew W. Daniels, Mark D. Stiles,\n  Gina C. Adam", "title": "Memory-efficient training with streaming dimensionality reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The movement of large quantities of data during the training of a Deep Neural\nNetwork presents immense challenges for machine learning workloads. To minimize\nthis overhead, especially on the movement and calculation of gradient\ninformation, we introduce streaming batch principal component analysis as an\nupdate algorithm. Streaming batch principal component analysis uses stochastic\npower iterations to generate a stochastic k-rank approximation of the network\ngradient. We demonstrate that the low rank updates produced by streaming batch\nprincipal component analysis can effectively train convolutional neural\nnetworks on a variety of common datasets, with performance comparable to\nstandard mini batch gradient descent. These results can lead to both\nimprovements in the design of application specific integrated circuits for deep\nlearning and in the speed of synchronization of machine learning models trained\nwith data parallelism.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 02:13:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Huang", "Siyuan", ""], ["Hoskins", "Brian D.", ""], ["Daniels", "Matthew W.", ""], ["Stiles", "Mark D.", ""], ["Adam", "Gina C.", ""]]}, {"id": "2004.12058", "submitter": "Mohamed Abdelpakey", "authors": "Mohamed H. Abdelpakey, Mohamed S. Shehata", "title": "NullSpaceNet: Nullspace Convoluional Neural Network with Differentiable\n  Loss Function", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NullSpaceNet, a novel network that maps from the pixel level input\nto a joint-nullspace (as opposed to the traditional feature space), where the\nnewly learned joint-nullspace features have clearer interpretation and are more\nseparable. NullSpaceNet ensures that all inputs from the same class are\ncollapsed into one point in this new joint-nullspace, and the different classes\nare collapsed into different points with high separation margins. Moreover, a\nnovel differentiable loss function is proposed that has a closed-form solution\nwith no free-parameters. NullSpaceNet exhibits superior performance when tested\nagainst VGG16 with fully-connected layer over 4 different datasets, with\naccuracy gain of up to 4.55%, a reduction in learnable parameters from 135M to\n19M, and reduction in inference time of 99% in favor of NullSpaceNet. This\nmeans that NullSpaceNet needs less than 1% of the time it takes a traditional\nCNN to classify a batch of images with better accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 04:58:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Abdelpakey", "Mohamed H.", ""], ["Shehata", "Mohamed S.", ""]]}, {"id": "2004.12063", "submitter": "Alexander Wein", "authors": "David Gamarnik, Aukosh Jagannath, Alexander S. Wein", "title": "Low-Degree Hardness of Random Optimization Problems", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math-ph math.MP math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding nearly optimal solutions of optimization\nproblems with random objective functions. Such problems arise widely in the\ntheory of random graphs, theoretical computer science, and statistical physics.\nTwo concrete problems we consider are (a) optimizing the Hamiltonian of a\nspherical or Ising p-spin glass model, and (b) finding a large independent set\nin a sparse Erdos-Renyi graph. Two families of algorithms are considered: (a)\nlow-degree polynomials of the input---a general framework that captures methods\nsuch as approximate message passing and local algorithms on sparse graphs,\namong others; and (b) the Langevin dynamics algorithm, a canonical Monte Carlo\nanalogue of the gradient descent algorithm (applicable only for the spherical\np-spin glass Hamiltonian).\n  We show that neither family of algorithms can produce nearly optimal\nsolutions with high probability. Our proof uses the fact that both models are\nknown to exhibit a variant of the overlap gap property (OGP) of near-optimal\nsolutions. Specifically, for both models, every two solutions whose objectives\nare above a certain threshold are either close or far from each other. The crux\nof our proof is the stability of both algorithms: a small perturbation of the\ninput induces a small perturbation of the output. By an interpolation argument,\nsuch a stable algorithm cannot overcome the OGP barrier.\n  The stability of the Langevin dynamics is an immediate consequence of the\nwell-posedness of stochastic differential equations. The stability of\nlow-degree polynomials is established using concepts from Gaussian and Boolean\nFourier analysis, including noise sensitivity, hypercontractivity, and total\ninfluence.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 05:45:59 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gamarnik", "David", ""], ["Jagannath", "Aukosh", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2004.12092", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir, Sam Campbell, Deborah Scott, Dan\n  Lubman", "title": "Towards Accurate Predictions and Causal 'What-if' Analyses for Planning\n  and Policy-making: A Case Study in Emergency Medical Services Demand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency Medical Services (EMS) demand load has become a considerable burden\nfor many government authorities, and EMS demand is often an early indicator for\nstress in communities, a warning sign of emerging problems. In this paper, we\nintroduce Deep Planning and Policy Making Net (DeepPPMNet), a Long Short-Term\nMemory network based, global forecasting and inference framework to forecast\nthe EMS demand, analyse causal relationships, and perform `what-if' analyses\nfor policy-making across multiple local government areas. Unless traditional\nunivariate forecasting techniques, the proposed method follows the global\nforecasting methodology, where a model is trained across all the available EMS\ndemand time series to exploit the potential cross-series information available.\nDeepPPMNet also uses seasonal decomposition techniques, incorporated in two\ndifferent training paradigms into the framework, to suit various\ncharacteristics of the EMS related time series data. We then explore causal\nrelationships using the notion of Granger Causality, where the global\nforecasting framework enables us to perform `what-if' analyses that could be\nused for the national policy-making process. We empirically evaluate our\nmethod, using a set of EMS datasets related to alcohol, drug use and self-harm\nin Australia. The proposed framework is able to outperform many\nstate-of-the-art techniques and achieve competitive results in terms of\nforecasting accuracy. We finally illustrate its use for policy-making in an\nexample regarding alcohol outlet licenses.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 09:03:10 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Campbell", "Sam", ""], ["Scott", "Deborah", ""], ["Lubman", "Dan", ""]]}, {"id": "2004.12130", "submitter": "Philip Nadler", "authors": "Philip Nadler, Shuo Wang, Rossella Arcucci, Xian Yang, Yike Guo", "title": "An Epidemiological Modelling Approach for Covid19 via Data Assimilation", "comments": "Initial conference version accepted at International Conference of\n  Machine Learning(ICML) workshop. Extended journal version was published in\n  the European Journal of Epidemiology\n  (https://doi.org/10.1007/s10654-020-00676-7). Please cite as accordingly", "journal-ref": null, "doi": "10.1007/s10654-020-00676-7", "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global pandemic of the 2019-nCov requires the evaluation of policy\ninterventions to mitigate future social and economic costs of quarantine\nmeasures worldwide. We propose an epidemiological model for forecasting and\npolicy evaluation which incorporates new data in real-time through variational\ndata assimilation. We analyze and discuss infection rates in China, the US and\nItaly. In particular, we develop a custom compartmental SIR model fit to\nvariables related to the epidemic in Chinese cities, named SITR model. We\ncompare and discuss model results which conducts updates as new observations\nbecome available. A hybrid data assimilation approach is applied to make\nresults robust to initial conditions. We use the model to do inference on\ninfection numbers as well as parameters such as the disease transmissibility\nrate or the rate of recovery. The parameterisation of the model is parsimonious\nand extendable, allowing for the incorporation of additional data and\nparameters of interest. This allows for scalability and the extension of the\nmodel to other locations or the adaption of novel data sources.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 12:46:36 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:11:32 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 12:48:52 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Nadler", "Philip", ""], ["Wang", "Shuo", ""], ["Arcucci", "Rossella", ""], ["Yang", "Xian", ""], ["Guo", "Yike", ""]]}, {"id": "2004.12131", "submitter": "Philipp Petersen", "authors": "Moritz Geist, Philipp Petersen, Mones Raslan, Reinhold Schneider,\n  Gitta Kutyniok", "title": "Numerical Solution of the Parametric Diffusion Equation by Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a comprehensive numerical study of the effect of\napproximation-theoretical results for neural networks on practical learning\nproblems in the context of numerical analysis. As the underlying model, we\nstudy the machine-learning-based solution of parametric partial differential\nequations. Here, approximation theory predicts that the performance of the\nmodel should depend only very mildly on the dimension of the parameter space\nand is determined by the intrinsic dimension of the solution manifold of the\nparametric partial differential equation. We use various methods to establish\ncomparability between test-cases by minimizing the effect of the choice of\ntest-cases on the optimization and sampling aspects of the learning problem. We\nfind strong support for the hypothesis that approximation-theoretical effects\nheavily influence the practical behavior of learning problems in numerical\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 12:48:31 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Geist", "Moritz", ""], ["Petersen", "Philipp", ""], ["Raslan", "Mones", ""], ["Schneider", "Reinhold", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "2004.12157", "submitter": "Roger Guimera", "authors": "Roger Guimera and Ignasi Reichardt and Antoni Aguilar-Mogas and\n  Francesco A Massucci and Manuel Miranda and Jordi Pallares and Marta\n  Sales-Pardo", "title": "A Bayesian machine scientist to aid in the solution of challenging\n  scientific problems", "comments": null, "journal-ref": "Sci. Adv. 6 (5) , eaav6971 (2020)", "doi": "10.1126/sciadv.aav6971", "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Closed-form, interpretable mathematical models have been instrumental for\nadvancing our understanding of the world; with the data revolution, we may now\nbe in a position to uncover new such models for many systems from physics to\nthe social sciences. However, to deal with increasing amounts of data, we need\n\"machine scientists\" that are able to extract these models automatically from\ndata. Here, we introduce a Bayesian machine scientist, which establishes the\nplausibility of models using explicit approximations to the exact marginal\nposterior over models and establishes its prior expectations about models by\nlearning from a large empirical corpus of mathematical expressions. It explores\nthe space of models using Markov chain Monte Carlo. We show that this approach\nuncovers accurate models for synthetic and real data and provides out-of-sample\npredictions that are more accurate than those of existing approaches and of\nother nonparametric methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:42:13 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Guimera", "Roger", ""], ["Reichardt", "Ignasi", ""], ["Aguilar-Mogas", "Antoni", ""], ["Massucci", "Francesco A", ""], ["Miranda", "Manuel", ""], ["Pallares", "Jordi", ""], ["Sales-Pardo", "Marta", ""]]}, {"id": "2004.12164", "submitter": "Xiao Guo", "authors": "Xiao Guo, Yixuan Qiu, Hai Zhang, Xiangyu Chang", "title": "Randomized spectral co-clustering for large-scale directed networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed networks are generally used to represent asymmetric relationships\namong units. Co-clustering aims to cluster the senders and receivers of\ndirected networks simultaneously. In particular, the well-known spectral\nclustering algorithm could be modified as the spectral co-clustering to\nco-cluster directed networks. However, large-scale networks pose computational\nchallenge to it. In this paper, we leverage randomized sketching techniques to\naccelerate the spectral co-clustering algorithms in order to co-cluster\nlarge-scale directed networks more efficiently. Specifically, we derive two\nseries of randomized spectral co-clustering algorithms, one is\nrandom-projection-based and the other is random-sampling-based. Theoretically,\nwe analyze the resulting algorithms under two generative models\\textendash the\n\\emph{stochastic co-block model} and the \\emph{degree corrected stochastic\nco-block model}. The approximation error rates and misclustering error rates of\nproposed two randomized spectral co-clustering algorithms are established,\nwhich indicate better bounds than the state-of-the-art results of co-clustering\nliterature. Numerically, we conduct simulations to support our theoretical\nresults and test the efficiency of the algorithms on real networks with up to\ntens of millions of nodes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 15:00:55 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:09:54 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Guo", "Xiao", ""], ["Qiu", "Yixuan", ""], ["Zhang", "Hai", ""], ["Chang", "Xiangyu", ""]]}, {"id": "2004.12199", "submitter": "Alexander Jung", "authors": "Alexander Jung and Yasmin SarcheshmehPour", "title": "Local Graph Clustering with Network Lasso", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3045832", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical and computational properties of a network Lasso\nmethod for local graph clustering. The clusters delivered by nLasso can be\ncharacterized elegantly via network flows between cluster boundary and seed\nnodes. While spectral clustering methods are guided by a minimization of the\ngraph Laplacian quadratic form, nLasso minimizes the total variation of cluster\nindicator signals. As demonstrated theoretically and numerically, nLasso\nmethods can handle very sparse clusters (chain-like) which are difficult for\nspectral clustering. We also verify that a primal-dual method for nonsmooth\noptimization allows to approximate nLasso solutions with optimal worst-case\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:52:05 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:45:53 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 14:13:40 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Jung", "Alexander", ""], ["SarcheshmehPour", "Yasmin", ""]]}, {"id": "2004.12204", "submitter": "Eduardo Nigri", "authors": "Eduardo Nigri, Nivio Ziviani, Fabio Cappabianco, Augusto Antunes,\n  Adriano Veloso", "title": "Explainable Deep CNNs for MRI-Based Diagnosis of Alzheimer's Disease", "comments": "Accepted for the IEEE International Joint Conference on Neural\n  Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) are becoming prominent models for\nsemi-automated diagnosis of Alzheimer's Disease (AD) using brain Magnetic\nResonance Imaging (MRI). Although being highly accurate, deep CNN models lack\ntransparency and interpretability, precluding adequate clinical reasoning and\nnot complying with most current regulatory demands. One popular choice for\nexplaining deep image models is occluding regions of the image to isolate their\ninfluence on the prediction. However, existing methods for occluding patches of\nbrain scans generate images outside the distribution to which the model was\ntrained for, thus leading to unreliable explanations. In this paper, we propose\nan alternative explanation method that is specifically designed for the brain\nscan task. Our method, which we refer to as Swap Test, produces heatmaps that\ndepict the areas of the brain that are most indicative of AD, providing\ninterpretability for the model's decisions in a format understandable to\nclinicians. Experimental results using an axiomatic evaluation show that the\nproposed method is more suitable for explaining the diagnosis of AD using MRI\nwhile the opposite trend was observed when using a typical occlusion test.\nTherefore, we believe our method may address the inherent black-box nature of\ndeep neural networks that are capable of diagnosing AD.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 18:14:49 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Nigri", "Eduardo", ""], ["Ziviani", "Nivio", ""], ["Cappabianco", "Fabio", ""], ["Antunes", "Augusto", ""], ["Veloso", "Adriano", ""]]}, {"id": "2004.12209", "submitter": "Yingyi Ma", "authors": "Yingyi Ma, Vignesh Ganapathiraman, Yaoliang Yu, Xinhua Zhang", "title": "Convex Representation Learning for Generalized Invariance in\n  Semi-Inner-Product Space", "comments": "to appear in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariance (defined in a general sense) has been one of the most effective\npriors for representation learning. Direct factorization of parametric models\nis feasible only for a small range of invariances, while regularization\napproaches, despite improved generality, lead to nonconvex optimization. In\nthis work, we develop a convex representation learning algorithm for a variety\nof generalized invariances that can be modeled as semi-norms. Novel Euclidean\nembeddings are introduced for kernel representers in a semi-inner-product\nspace, and approximation bounds are established. This allows invariant\nrepresentations to be learned efficiently and effectively as confirmed in our\nexperiments, along with accurate predictions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 18:54:37 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 23:37:53 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 17:06:53 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ma", "Yingyi", ""], ["Ganapathiraman", "Vignesh", ""], ["Yu", "Yaoliang", ""], ["Zhang", "Xinhua", ""]]}, {"id": "2004.12211", "submitter": "Kamran Javid Mr", "authors": "Kamran Javid, Will Handley, Mike Hobson, Anthony Lasenby", "title": "Compromise-free Bayesian neural networks", "comments": "https://github.com/PolyChord/PolyChordLite;\n  https://github.com/SuperKam91/bnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a thorough analysis of the relationship between the out-of-sample\nperformance and the Bayesian evidence (marginal likelihood) of Bayesian neural\nnetworks (BNNs), as well as looking at the performance of ensembles of BNNs,\nboth using the Boston housing dataset. Using the state-of-the-art in nested\nsampling, we numerically sample the full (non-Gaussian and multimodal) network\nposterior and obtain numerical estimates of the Bayesian evidence, considering\nnetwork models with up to 156 trainable parameters. The networks have between\nzero and four hidden layers, either $\\tanh$ or $ReLU$ activation functions, and\nwith and without hierarchical priors. The ensembles of BNNs are obtained by\ndetermining the posterior distribution over networks, from the posterior\nsamples of individual BNNs re-weighted by the associated Bayesian evidence\nvalues. There is good correlation between out-of-sample performance and\nevidence, as well as a remarkable symmetry between the evidence versus model\nsize and out-of-sample performance versus model size planes. Networks with\n$ReLU$ activation functions have consistently higher evidences than those with\n$\\tanh$ functions, and this is reflected in their out-of-sample performance.\nEnsembling over architectures acts to further improve performance relative to\nthe individual BNNs.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 19:12:56 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:23:29 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 12:03:28 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Javid", "Kamran", ""], ["Handley", "Will", ""], ["Hobson", "Mike", ""], ["Lasenby", "Anthony", ""]]}, {"id": "2004.12214", "submitter": "Ozan Sener", "authors": "Ozan Sener, Vladlen Koltun", "title": "Learning to Guide Random Search", "comments": "Published at ICLR 2020, Code is available at:\n  https://github.com/intel-isl/LMRS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in derivative-free optimization of high-dimensional\nfunctions. The sample complexity of existing methods is high and depends on\nproblem dimensionality, unlike the dimensionality-independent rates of\nfirst-order methods. The recent success of deep learning suggests that many\ndatasets lie on low-dimensional manifolds that can be represented by deep\nnonlinear models. We therefore consider derivative-free optimization of a\nhigh-dimensional function that lies on a latent low-dimensional manifold. We\ndevelop an online learning approach that learns this manifold while performing\nthe optimization. In other words, we jointly learn the manifold and optimize\nthe function. Our analysis suggests that the presented method significantly\nreduces sample complexity. We empirically evaluate the method on continuous\noptimization benchmarks and high-dimensional continuous control problems. Our\nmethod achieves significantly lower sample complexity than Augmented Random\nSearch, Bayesian optimization, covariance matrix adaptation (CMA-ES), and other\nderivative-free optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 19:21:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sener", "Ozan", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2004.12227", "submitter": "Yuanhao Xiong", "authors": "Yuanhao Xiong and Cho-Jui Hsieh", "title": "Improved Adversarial Training via Learned Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack has recently become a tremendous threat to deep learning\nmodels. To improve the robustness of machine learning models, adversarial\ntraining, formulated as a minimax optimization problem, has been recognized as\none of the most effective defense mechanisms. However, the non-convex and\nnon-concave property poses a great challenge to the minimax training. In this\npaper, we empirically demonstrate that the commonly used PGD attack may not be\noptimal for inner maximization, and improved inner optimizer can lead to a more\nrobust model. Then we leverage a learning-to-learn (L2L) framework to train an\noptimizer with recurrent neural networks, providing update directions and steps\nadaptively for the inner problem. By co-training optimizer's parameters and\nmodel's weights, the proposed framework consistently improves the model\nrobustness over PGD-based adversarial training and TRADES.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 20:15:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xiong", "Yuanhao", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2004.12235", "submitter": "Hendrick de Haan", "authors": "Martin Magill and Andrew M. Nagel and Hendrick W. de Haan", "title": "Neural Network Solutions to Differential Equations in Non-Convex\n  Domains: Solving the Electric Field in the Slit-Well Microfluidic Device", "comments": "16 pages, 12 figures, 1 table", "journal-ref": "Phys. Rev. Research 2, 033110 (2020)", "doi": "10.1103/PhysRevResearch.2.033110", "report-no": null, "categories": "physics.comp-ph cond-mat.soft stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural network method of solving differential equations is used to\napproximate the electric potential and corresponding electric field in the\nslit-well microfluidic device. The device's geometry is non-convex, making this\na challenging problem to solve using the neural network method. To validate the\nmethod, the neural network solutions are compared to a reference solution\nobtained using the finite element method. Additional metrics are presented that\nmeasure how well the neural networks recover important physical invariants that\nare not explicitly enforced during training: spatial symmetries and\nconservation of electric flux. Finally, as an application-specific test of\nvalidity, neural network electric fields are incorporated into particle\nsimulations. Conveniently, the same loss functional used to train the neural\nnetworks also seems to provide a reliable estimator of the networks' true\nerrors, as measured by any of the metrics considered here. In all metrics, deep\nneural networks significantly outperform shallow neural networks, even when\nnormalized by computational cost. Altogether, the results suggest that the\nneural network method can reliably produce solutions of acceptable accuracy for\nuse in subsequent physical computations, such as particle simulations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 21:20:03 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Magill", "Martin", ""], ["Nagel", "Andrew M.", ""], ["de Haan", "Hendrick W.", ""]]}, {"id": "2004.12254", "submitter": "Fatemehsadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Mohammadkazem Taram, Praneeth Vepakomma,\n  Abhishek Singh, Ramesh Raskar, Hadi Esmaeilzadeh", "title": "Privacy in Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing advances of deep learning in many areas including vision,\nrecommendation systems, natural language processing, etc., have led to the\nadoption of Deep Neural Networks (DNNs) in production systems. The availability\nof large datasets and high computational power are the main contributors to\nthese advances. The datasets are usually crowdsourced and may contain sensitive\ninformation. This poses serious privacy concerns as this data can be misused or\nleaked through various vulnerabilities. Even if the cloud provider and the\ncommunication link is trusted, there are still threats of inference attacks\nwhere an attacker could speculate properties of the data used for training, or\nfind the underlying model architecture and parameters. In this survey, we\nreview the privacy concerns brought by deep learning, and the mitigating\ntechniques introduced to tackle these issues. We also show that there is a gap\nin the literature regarding test-time inference privacy, and propose possible\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 23:47:25 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 17:13:21 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 22:19:53 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 20:54:34 GMT"}, {"version": "v5", "created": "Sat, 7 Nov 2020 01:52:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Taram", "Mohammadkazem", ""], ["Vepakomma", "Praneeth", ""], ["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2004.12289", "submitter": "Dara Bahri", "authors": "Dara Bahri, Heinrich Jiang, Maya Gupta", "title": "Deep k-NN for Noisy Labels", "comments": "Full paper (including supplemental) can be found at\n  https://github.com/dbahri/deepknn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models are often trained on examples with noisy\nlabels that hurt performance and are hard to identify. In this paper, we\nprovide an empirical study showing that a simple $k$-nearest neighbor-based\nfiltering approach on the logit layer of a preliminary model can remove\nmislabeled training data and produce more accurate models than many recently\nproposed methods. We also provide new statistical guarantees into its efficacy.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 05:15:36 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bahri", "Dara", ""], ["Jiang", "Heinrich", ""], ["Gupta", "Maya", ""]]}, {"id": "2004.12293", "submitter": "Yichen Zhu", "authors": "Yichen Zhu, Cheng Li and David B. Dunson", "title": "Classification Trees for Imbalanced and Sparse Data: Surface-to-Volume\n  Regularization", "comments": "Submitted to Journal of American Statistical Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms face difficulties when one or more classes have\nlimited training data. We are particularly interested in classification trees,\ndue to their interpretability and flexibility. When data are limited in one or\nmore of the classes, the estimated decision boundaries are often irregularly\nshaped due to the limited sample size, leading to poor generalization error. We\npropose a novel approach that penalizes the Surface-to-Volume Ratio (SVR) of\nthe decision set, obtaining a new class of SVR-Tree algorithms. We develop a\nsimple and computationally efficient implementation while proving estimation\nconsistency for SVR-Tree and rate of convergence for an idealized empirical\nrisk minimizer of SVR-Tree. SVR-Tree is compared with multiple algorithms that\nare designed to deal with imbalance through real data applications.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 06:22:47 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 05:41:40 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhu", "Yichen", ""], ["Li", "Cheng", ""], ["Dunson", "David B.", ""]]}, {"id": "2004.12314", "submitter": "Zhaohan Xiong", "authors": "Zhaohan Xiong, Qing Xia, Zhiqiang Hu, Ning Huang, Cheng Bian, Yefeng\n  Zheng, Sulaiman Vesal, Nishant Ravikumar, Andreas Maier, Xin Yang, Pheng-Ann\n  Heng, Dong Ni, Caizi Li, Qianqian Tong, Weixin Si, Elodie Puybareau, Younes\n  Khoudli, Thierry Geraud, Chen Chen, Wenjia Bai, Daniel Rueckert, Lingchao Xu,\n  Xiahai Zhuang, Xinzhe Luo, Shuman Jia, Maxime Sermesant, Yashu Liu, Kuanquan\n  Wang, Davide Borra, Alessandro Masci, Cristiana Corsi, Coen de Vente, Mitko\n  Veta, Rashed Karim, Chandrakanth Jayachandran Preetha, Sandy Engelhardt,\n  Menyun Qiao, Yuanyuan Wang, Qian Tao, Marta Nunez-Garcia, Oscar Camara,\n  Nicolo Savioli, Pablo Lamata, Jichao Zhao", "title": "A Global Benchmark of Algorithms for Segmenting Late Gadolinium-Enhanced\n  Cardiac Magnetic Resonance Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Segmentation of cardiac images, particularly late gadolinium-enhanced\nmagnetic resonance imaging (LGE-MRI) widely used for visualizing diseased\ncardiac structures, is a crucial first step for clinical diagnosis and\ntreatment. However, direct segmentation of LGE-MRIs is challenging due to its\nattenuated contrast. Since most clinical studies have relied on manual and\nlabor-intensive approaches, automatic methods are of high interest,\nparticularly optimized machine learning approaches. To address this, we\norganized the \"2018 Left Atrium Segmentation Challenge\" using 154 3D LGE-MRIs,\ncurrently the world's largest cardiac LGE-MRI dataset, and associated labels of\nthe left atrium segmented by three medical experts, ultimately attracting the\nparticipation of 27 international teams. In this paper, extensive analysis of\nthe submitted algorithms using technical and biological metrics was performed\nby undergoing subgroup analysis and conducting hyper-parameter analysis,\noffering an overall picture of the major design choices of convolutional neural\nnetworks (CNNs) and practical considerations for achieving state-of-the-art\nleft atrium segmentation. Results show the top method achieved a dice score of\n93.2% and a mean surface to a surface distance of 0.7 mm, significantly\noutperforming prior state-of-the-art. Particularly, our analysis demonstrated\nthat double, sequentially used CNNs, in which a first CNN is used for automatic\nregion-of-interest localization and a subsequent CNN is used for refined\nregional segmentation, achieved far superior results than traditional methods\nand pipelines containing single CNNs. This large-scale benchmarking study makes\na significant step towards much-improved segmentation methods for cardiac\nLGE-MRIs, and will serve as an important benchmark for evaluating and comparing\nthe future works in the field.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:49:17 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 09:54:48 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 14:05:14 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Xiong", "Zhaohan", ""], ["Xia", "Qing", ""], ["Hu", "Zhiqiang", ""], ["Huang", "Ning", ""], ["Bian", "Cheng", ""], ["Zheng", "Yefeng", ""], ["Vesal", "Sulaiman", ""], ["Ravikumar", "Nishant", ""], ["Maier", "Andreas", ""], ["Yang", "Xin", ""], ["Heng", "Pheng-Ann", ""], ["Ni", "Dong", ""], ["Li", "Caizi", ""], ["Tong", "Qianqian", ""], ["Si", "Weixin", ""], ["Puybareau", "Elodie", ""], ["Khoudli", "Younes", ""], ["Geraud", "Thierry", ""], ["Chen", "Chen", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""], ["Xu", "Lingchao", ""], ["Zhuang", "Xiahai", ""], ["Luo", "Xinzhe", ""], ["Jia", "Shuman", ""], ["Sermesant", "Maxime", ""], ["Liu", "Yashu", ""], ["Wang", "Kuanquan", ""], ["Borra", "Davide", ""], ["Masci", "Alessandro", ""], ["Corsi", "Cristiana", ""], ["de Vente", "Coen", ""], ["Veta", "Mitko", ""], ["Karim", "Rashed", ""], ["Preetha", "Chandrakanth Jayachandran", ""], ["Engelhardt", "Sandy", ""], ["Qiao", "Menyun", ""], ["Wang", "Yuanyuan", ""], ["Tao", "Qian", ""], ["Nunez-Garcia", "Marta", ""], ["Camara", "Oscar", ""], ["Savioli", "Nicolo", ""], ["Lamata", "Pablo", ""], ["Zhao", "Jichao", ""]]}, {"id": "2004.12427", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Cross-Domain Structure Preserving Projection for Heterogeneous Domain\n  Adaptation", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous Domain Adaptation (HDA) addresses the transfer learning\nproblems where data from the source and target domains are of different\nmodalities (e.g., texts and images) or feature dimensions (e.g., features\nextracted with different methods). It is useful for multi-modal data analysis.\nTraditional domain adaptation algorithms assume that the representations of\nsource and target samples reside in the same feature space, hence are likely to\nfail in solving the heterogeneous domain adaptation problem. Contemporary\nstate-of-the-art HDA approaches are usually composed of complex optimization\nobjectives for favourable performance and are therefore computationally\nexpensive and less generalizable. To address these issues, we propose a novel\nCross-Domain Structure Preserving Projection (CDSPP) algorithm for HDA. As an\nextension of the classic LPP to heterogeneous domains, CDSPP aims to learn\ndomain-specific projections to map sample features from source and target\ndomains into a common subspace such that the class consistency is preserved and\ndata distributions are sufficiently aligned. CDSPP is simple and has\ndeterministic solutions by solving a generalized eigenvalue problem. It is\nnaturally suitable for supervised HDA but has also been extended for\nsemi-supervised HDA where the unlabeled target domain samples are available.\nExtensive experiments have been conducted on commonly used benchmark datasets\n(i.e. Office-Caltech, Multilingual Reuters Collection, NUS-WIDE-ImageNet) for\nHDA as well as the Office-Home dataset firstly introduced for HDA by ourselves\ndue to its significantly larger number of classes than the existing ones (65 vs\n10, 6 and 8). The experimental results of both supervised and semi-supervised\nHDA demonstrate the superior performance of our proposed method against\ncontemporary state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 16:22:28 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 20:59:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2004.12430", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris", "title": "Low-rank matrix completion theory via Plucker coordinates", "comments": "12 pages, major revision in terms of presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the popularity of low-rank matrix completion, the majority of its\ntheory has been developed under the assumption of random observation patterns,\nwhereas very little is known about the practically relevant case of non-random\npatterns. Specifically, a fundamental yet largely open question is to describe\npatterns that allow for unique or finitely many completions. This paper\nprovides two such families of patterns for any rank. A key to achieving this is\na novel formulation of low-rank matrix completion in terms of Plucker\ncoordinates, the latter a traditional tool in computer vision. This connection\nis of potential significance to a wide family of matrix and subspace learning\nproblems with incomplete data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 16:38:58 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:25:06 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 16:10:17 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 13:50:56 GMT"}, {"version": "v5", "created": "Wed, 26 May 2021 14:07:39 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Tsakiris", "Manolis C.", ""]]}, {"id": "2004.12443", "submitter": "Xingjian Li", "authors": "Xingjian Li, Haoyi Xiong, Haozhe An, Dejing Dou, Chengzhong Xu", "title": "COLAM: Co-Learning of Deep Neural Networks and Soft Labels via\n  Alternating Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softening labels of training datasets with respect to data representations\nhas been frequently used to improve the training of deep neural networks\n(DNNs). While such a practice has been studied as a way to leverage privileged\ninformation about the distribution of the data, a well-trained learner with\nsoft classification outputs should be first obtained as a prior to generate\nsuch privileged information. To solve such chicken-egg problem, we propose\nCOLAM framework that Co-Learns DNNs and soft labels through Alternating\nMinimization of two objectives - (a) the training loss subject to soft labels\nand (b) the objective to learn improved soft labels - in one end-to-end\ntraining procedure. We performed extensive experiments to compare our proposed\nmethod with a series of baselines. The experiment results show that COLAM\nachieves improved performance on many tasks with better testing classification\naccuracy. We also provide both qualitative and quantitative analyses that\nexplain why COLAM works well.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 17:50:20 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Xingjian", ""], ["Xiong", "Haoyi", ""], ["An", "Haozhe", ""], ["Dou", "Dejing", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2004.12478", "submitter": "J. Edward Hu", "authors": "J. Edward Hu, Adith Swaminathan, Hadi Salman, Greg Yang", "title": "Improved Image Wasserstein Attacks and Defenses", "comments": "Best paper award at ICLR Trustworthy ML Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness against image perturbations bounded by a $\\ell_p$ ball have been\nwell-studied in recent literature. Perturbations in the real-world, however,\nrarely exhibit the pixel independence that $\\ell_p$ threat models assume. A\nrecently proposed Wasserstein distance-bounded threat model is a promising\nalternative that limits the perturbation to pixel mass movements. We point out\nand rectify flaws in previous definition of the Wasserstein threat model and\nexplore stronger attacks and defenses under our better-defined framework.\nLastly, we discuss the inability of current Wasserstein-robust models in\ndefending against perturbations seen in the real world. Our code and trained\nmodels are available at https://github.com/edwardjhu/improved_wasserstein .\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 20:50:33 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hu", "J. Edward", ""], ["Swaminathan", "Adith", ""], ["Salman", "Hadi", ""], ["Yang", "Greg", ""]]}, {"id": "2004.12488", "submitter": "Daniel Bakkelund", "authors": "Daniel Bakkelund", "title": "Order preserving hierarchical agglomerative clustering", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for hierarchical clustering of directed acyclic graphs\nand other strictly partially ordered data that preserves the data structure. In\nparticular, if we have $a<b$ in the original data and denote their respective\nclusters by $[a]$ and $[b]$, we get $[a]<[b]$ in the produced clustering. The\nclustering uses standard linkage functions, such as single- and complete\nlinkage, and is a generalisation of hierarchical clustering of non-ordered\nsets. To achieve this, we define the output from running hierarchical\nclustering algorithms on strictly ordered data to be partial dendrograms;\nsub-trees of classical dendrograms with several connected components. We then\nconstruct an embedding of partial dendrograms over a set into the family of\nultrametrics over the same set. An optimal hierarchical clustering is now\ndefined as follows: Given a collection of partial dendrograms, the optimal\nclustering is the partial dendrogram corresponding to the ultrametric closest\nto the original dissimilarity measure, measured in the $p$-norm. Thus, the\nmethod is a combination of classical hierarchical clustering and ultrametric\nfitting.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:58:53 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 14:23:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bakkelund", "Daniel", ""]]}, {"id": "2004.12492", "submitter": "Benjamin Tan", "authors": "Kang Liu, Benjamin Tan, Gaurav Rajavendra Reddy, Siddharth Garg,\n  Yiorgos Makris, Ramesh Karri", "title": "Bias Busters: Robustifying DL-based Lithographic Hotspot Detectors\n  Against Backdooring Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) offers potential improvements throughout the CAD\ntool-flow, one promising application being lithographic hotspot detection.\nHowever, DL techniques have been shown to be especially vulnerable to inference\nand training time adversarial attacks. Recent work has demonstrated that a\nsmall fraction of malicious physical designers can stealthily \"backdoor\" a\nDL-based hotspot detector during its training phase such that it accurately\nclassifies regular layout clips but predicts hotspots containing a specially\ncrafted trigger shape as non-hotspots. We propose a novel training data\naugmentation strategy as a powerful defense against such backdooring attacks.\nThe defense works by eliminating the intentional biases introduced in the\ntraining data but does not require knowledge of which training samples are\npoisoned or the nature of the backdoor trigger. Our results show that the\ndefense can drastically reduce the attack success rate from 84% to ~0%.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 22:30:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Reddy", "Gaurav Rajavendra", ""], ["Garg", "Siddharth", ""], ["Makris", "Yiorgos", ""], ["Karri", "Ramesh", ""]]}, {"id": "2004.12500", "submitter": "Chandra Mouli Madhav Kotteti", "authors": "Chandra Mouli Madhav Kotteti, Xishuang Dong, Lijun Qian", "title": "Ensemble Deep Learning on Time-Series Representation of Tweets for Rumor\n  Detection in Social Media", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is a popular platform for timely information sharing. One of the\nimportant challenges for social media platforms like Twitter is whether to\ntrust news shared on them when there is no systematic news verification\nprocess. On the other hand, timely detection of rumors is a non-trivial task,\ngiven the fast-paced social media environment. In this work, we proposed an\nensemble model, which performs majority-voting on a collection of predictions\nby deep neural networks using time-series vector representation of Twitter data\nfor timely detection of rumors. By combining the proposed data pre-processing\nmethod with the ensemble model, better performance of rumor detection has been\ndemonstrated in the experiments using PHEME dataset. Experimental results show\nthat the classification performance has been improved by 7.9% in terms of micro\nF1 score compared to the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 23:13:31 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kotteti", "Chandra Mouli Madhav", ""], ["Dong", "Xishuang", ""], ["Qian", "Lijun", ""]]}, {"id": "2004.12519", "submitter": "Nathan Inkawhich", "authors": "Nathan Inkawhich, Kevin J Liang, Lawrence Carin and Yiran Chen", "title": "Transferable Perturbations of Deep Feature Distributions", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all current adversarial attacks of CNN classifiers rely on information\nderived from the output layer of the network. This work presents a new\nadversarial attack based on the modeling and exploitation of class-wise and\nlayer-wise deep feature distributions. We achieve state-of-the-art targeted\nblackbox transfer-based attack results for undefended ImageNet models. Further,\nwe place a priority on explainability and interpretability of the attacking\nprocess. Our methodology affords an analysis of how adversarial attacks change\nthe intermediate feature distributions of CNNs, as well as a measure of\nlayer-wise and class-wise feature distributional separability/entanglement. We\nalso conceptualize a transition from task/data-specific to model-specific\nfeatures within a CNN architecture that directly impacts the transferability of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 00:32:25 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Inkawhich", "Nathan", ""], ["Liang", "Kevin J", ""], ["Carin", "Lawrence", ""], ["Chen", "Yiran", ""]]}, {"id": "2004.12524", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Parisa Rashidi", "title": "Sequential Interpretability: Methods, Applications, and Future Direction\n  for Understanding Deep Learning Models in the Context of Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning continues to revolutionize an ever-growing number of critical\napplication areas including healthcare, transportation, finance, and basic\nsciences. Despite their increased predictive power, model transparency and\nhuman explainability remain a significant challenge due to the \"black box\"\nnature of modern deep learning models. In many cases the desired balance\nbetween interpretability and performance is predominately task specific.\nHuman-centric domains such as healthcare necessitate a renewed focus on\nunderstanding how and why these frameworks are arriving at critical and\npotentially life-or-death decisions. Given the quantity of research and\nempirical successes of deep learning for computer vision, most of the existing\ninterpretability research has focused on image processing techniques.\nComparatively, less attention has been paid to interpreting deep learning\nframeworks using sequential data. Given recent deep learning advancements in\nhighly sequential domains such as natural language processing and physiological\nsignal processing, the need for deep sequential explanations is at an all-time\nhigh. In this paper, we review current techniques for interpreting deep\nlearning techniques involving sequential data, identify similarities to\nnon-sequential methods, and discuss current limitations and future avenues of\nsequential interpretability research.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 00:58:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shickel", "Benjamin", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.12529", "submitter": "Zhongyi Han", "authors": "Zhongyi Han, Xian-Jin Gui, Chaoran Cui, Yilong Yin", "title": "Towards Accurate and Robust Domain Adaptation under Noisy Environments", "comments": "To appear in Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In non-stationary environments, learning machines usually confront the domain\nadaptation scenario where the data distribution does change over time. Previous\ndomain adaptation works have achieved great success in theory and practice.\nHowever, they always lose robustness in noisy environments where the labels and\nfeatures of examples from the source domain become corrupted. In this paper, we\nreport our attempt towards achieving accurate noise-robust domain adaptation.\nWe first give a theoretical analysis that reveals how harmful noises influence\nunsupervised domain adaptation. To eliminate the effect of label noise, we\npropose an offline curriculum learning for minimizing a newly-defined empirical\nsource risk. To reduce the impact of feature noise, we propose a proxy\ndistribution based margin discrepancy. We seamlessly transform our methods into\nan adversarial network that performs efficient joint optimization for them,\nsuccessfully mitigating the negative influence from both data corruption and\ndistribution shift. A series of empirical studies show that our algorithm\nremarkably outperforms state of the art, over 10% accuracy improvements in some\ndomain adaptation tasks under noisy environments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:07:19 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 01:18:01 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Han", "Zhongyi", ""], ["Gui", "Xian-Jin", ""], ["Cui", "Chaoran", ""], ["Yin", "Yilong", ""]]}, {"id": "2004.12531", "submitter": "Kazuya Nishimura", "authors": "Kazuya Nishimura, Ryoma Bise", "title": "Spatial-Temporal Mitosis Detection in Phase-Contrast Microscopy via\n  Likelihood Map Estimation by 3DCNN", "comments": "5 pages, 6 figures, Accepted in EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated mitotic detection in time-lapse phasecontrast microscopy provides\nus much information for cell behavior analysis, and thus several mitosis\ndetection methods have been proposed. However, these methods still have two\nproblems; 1) they cannot detect multiple mitosis events when there are closely\nplaced. 2) they do not consider the annotation gaps, which may occur since the\nappearances of mitosis cells are very similar before and after the annotated\nframe. In this paper, we propose a novel mitosis detection method that can\ndetect multiple mitosis events in a candidate sequence and mitigate the human\nannotation gap via estimating a spatiotemporal likelihood map by 3DCNN. In this\ntraining, the loss gradually decreases with the gap size between ground truth\nand estimation. This mitigates the annotation gaps. Our method outperformed the\ncompared methods in terms of F1- score using a challenging dataset that\ncontains the data under four different conditions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:12:48 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 13:59:38 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Nishimura", "Kazuya", ""], ["Bise", "Ryoma", ""]]}, {"id": "2004.12540", "submitter": "Hao Zhang", "authors": "Hao Zhang, Zhan Li, Zhixing Ren", "title": "Data-Driven Construction of Data Center Graph of Things for Anomaly\n  Detection", "comments": "17 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data center (DC) contains both IT devices and facility equipment, and the\noperation of a DC requires a high-quality monitoring (anomaly detection)\nsystem. There are lots of sensors in computer rooms for the DC monitoring\nsystem, and they are inherently related. This work proposes a data-driven\npipeline (ts2graph) to build a DC graph of things (sensor graph) from the time\nseries measurements of sensors. The sensor graph is an undirected weighted\nproperty graph, where sensors are the nodes, sensor features are the node\nproperties, and sensor connections are the edges. The sensor node property is\ndefined by features that characterize the sensor events (behaviors), instead of\nthe original time series. The sensor connection (edge weight) is defined by the\nprobability of concurrent events between two sensors. A graph of things\nprototype is constructed from the sensor time series of a real data center, and\nit successfully reveals meaningful relationships between the sensors. To\ndemonstrate the use of the DC sensor graph for anomaly detection, we compare\nthe performance of graph neural network (GNN) and existing standard methods on\nsynthetic anomaly data. GNN outperforms existing algorithms by a factor of 2 to\n3 (in terms of precision and F1 score), because it takes into account the\ntopology relationship between DC sensors. We expect that the DC sensor graph\ncan serve as the infrastructure for the DC monitoring system since it\nrepresents the sensor relationships.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:54:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Hao", ""], ["Li", "Zhan", ""], ["Ren", "Zhixing", ""]]}, {"id": "2004.12551", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Tyler J. Loftus, Shounak Datta, Tezcan\n  Ozrazgat-Baslanti, Azra Bihorac, Parisa Rashidi", "title": "Interpretable Multi-Task Deep Neural Networks for Dynamic Predictions of\n  Postoperative Complications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of postoperative complications can inform shared\ndecisions between patients and surgeons regarding the appropriateness of\nsurgery, preoperative risk-reduction strategies, and postoperative resource\nuse. Traditional predictive analytic tools are hindered by suboptimal\nperformance and usability. We hypothesized that novel deep learning techniques\nwould outperform logistic regression models in predicting postoperative\ncomplications. In a single-center longitudinal cohort of 43,943 adult patients\nundergoing 52,529 major inpatient surgeries, deep learning yielded greater\ndiscrimination than logistic regression for all nine complications. Predictive\nperformance was strongest when leveraging the full spectrum of preoperative and\nintraoperative physiologic time-series electronic health record data. A single\nmulti-task deep learning model yielded greater performance than separate models\ntrained on individual complications. Integrated gradients interpretability\nmechanisms demonstrated the substantial importance of missing data.\nInterpretable, multi-task deep neural networks made accurate, patient-level\npredictions that harbor the potential to augment surgical decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:32:32 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shickel", "Benjamin", ""], ["Loftus", "Tyler J.", ""], ["Datta", "Shounak", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.12554", "submitter": "Frederico Gadelha Guimaraes", "authors": "Petr\\^onio C\\^andido de Lima e Silva, Carlos Alberto Severiano Junior,\n  Marcos Antonio Alves, Rodrigo Silva, Miri Weiss Cohen, Frederico Gadelha\n  Guimar\\~aes", "title": "Forecasting in Non-stationary Environments with Fuzzy Time Series", "comments": "21 pages, 7 figures, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a Non-Stationary Fuzzy Time Series (NSFTS) method\nwith time varying parameters adapted from the distribution of the data. In this\napproach, we employ Non-Stationary Fuzzy Sets, in which perturbation functions\nare used to adapt the membership function parameters in the knowledge base in\nresponse to statistical changes in the time series. The proposed method is\ncapable of dynamically adapting its fuzzy sets to reflect the changes in the\nstochastic process based on the residual errors, without the need to retraining\nthe model. This method can handle non-stationary and heteroskedastic data as\nwell as scenarios with concept-drift. The proposed approach allows the model to\nbe trained only once and remain useful long after while keeping reasonable\naccuracy. The flexibility of the method by means of computational experiments\nwas tested with eight synthetic non-stationary time series data with several\nkinds of concept drifts, four real market indices (Dow Jones, NASDAQ, SP500 and\nTAIEX), three real FOREX pairs (EUR-USD, EUR-GBP, GBP-USD), and two real\ncryptocoins exchange rates (Bitcoin-USD and Ethereum-USD). As competitor models\nthe Time Variant fuzzy time series and the Incremental Ensemble were used,\nthese are two of the major approaches for handling non-stationary data sets.\nNon-parametric tests are employed to check the significance of the results. The\nproposed method shows resilience to concept drift, by adapting parameters of\nthe model, while preserving the symbolic structure of the knowledge base.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:35:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Silva", "Petr\u00f4nio C\u00e2ndido de Lima e", ""], ["Junior", "Carlos Alberto Severiano", ""], ["Alves", "Marcos Antonio", ""], ["Silva", "Rodrigo", ""], ["Cohen", "Miri Weiss", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2004.12570", "submitter": "Abhishek Gupta", "authors": "Henry Zhu, Justin Yu, Abhishek Gupta, Dhruv Shah, Kristian\n  Hartikainen, Avi Singh, Vikash Kumar, Sergey Levine", "title": "The Ingredients of Real-World Robotic Reinforcement Learning", "comments": "First three authors contributed equally. Accepted as a spotlight\n  presentation at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of reinforcement learning for real world robotics has been, in\nmany cases limited to instrumented laboratory scenarios, often requiring\narduous human effort and oversight to enable continuous learning. In this work,\nwe discuss the elements that are needed for a robotic learning system that can\ncontinually and autonomously improve with data collected in the real world. We\npropose a particular instantiation of such a system, using dexterous\nmanipulation as our case study. Subsequently, we investigate a number of\nchallenges that come up when learning without instrumentation. In such\nsettings, learning must be feasible without manually designed resets, using\nonly on-board perception, and without hand-engineered reward functions. We\npropose simple and scalable solutions to these challenges, and then demonstrate\nthe efficacy of our proposed system on a set of dexterous robotic manipulation\ntasks, providing an in-depth analysis of the challenges associated with this\nlearning paradigm. We demonstrate that our complete system can learn without\nany human intervention, acquiring a variety of vision-based skills with a\nreal-world three-fingered hand. Results and videos can be found at\nhttps://sites.google.com/view/realworld-rl/\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 03:36:10 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhu", "Henry", ""], ["Yu", "Justin", ""], ["Gupta", "Abhishek", ""], ["Shah", "Dhruv", ""], ["Hartikainen", "Kristian", ""], ["Singh", "Avi", ""], ["Kumar", "Vikash", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.12588", "submitter": "Hugo Lewi Hammer Dr.", "authors": "Hugo L. Hammer, Anis Yazidi, Michael A. Riegler and H{\\aa}vard Rue", "title": "Efficient Quantile Tracking Using an Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For incremental quantile estimators the step size and possibly other tuning\nparameters must be carefully set. However, little attention has been given on\nhow to set these values in an online manner. In this article we suggest two\nnovel procedures that address this issue.\n  The core part of the procedures is to estimate the current tracking mean\nsquared error (MSE). The MSE is decomposed in tracking variance and bias and\nnovel and efficient procedures to estimate these quantities are presented. It\nis shown that estimation bias can be tracked by associating it with the portion\nof observations below the quantile estimates.\n  The first procedure runs an ensemble of $L$ quantile estimators for wide\nrange of values of the tuning parameters and typically around $L = 100$. In\neach iteration an oracle selects the best estimate by the guidance of the\nestimated MSEs. The second method only runs an ensemble of $L = 3$ estimators\nand thus the values of the tuning parameters need from time to time to be\nadjusted for the running estimators. The procedures have a low memory foot\nprint of $8L$ and a computational complexity of $8L$ per iteration.\n  The experiments show that the procedures are highly efficient and track\nquantiles with an error close to the theoretical optimum. The Oracle approach\nperforms best, but comes with higher computational cost. The procedures were\nfurther applied to a massive real-life data stream of tweets and proofed real\nworld applicability of them.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 05:49:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hammer", "Hugo L.", ""], ["Yazidi", "Anis", ""], ["Riegler", "Michael A.", ""], ["Rue", "H\u00e5vard", ""]]}, {"id": "2004.12602", "submitter": "Qiang Liu", "authors": "Qiang Liu and Zhaocheng Liu and Haoli Zhang", "title": "An Empirical Study on Feature Discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with continuous numeric features, we usually adopt feature\ndiscretization. In this work, to find the best way to conduct feature\ndiscretization, we present some theoretical analysis, in which we focus on\nanalyzing correctness and robustness of feature discretization. Then, we\npropose a novel discretization method called Local Linear Encoding (LLE).\nExperiments on two numeric datasets show that, LLE can outperform conventional\ndiscretization method with much fewer model parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 06:50:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Qiang", ""], ["Liu", "Zhaocheng", ""], ["Zhang", "Haoli", ""]]}, {"id": "2004.12615", "submitter": "Jingjing Li", "authors": "Li Jingjing, Chen Erpeng, Ding Zhengming, Zhu Lei, Lu Ke, Shen Heng\n  Tao", "title": "Maximum Density Divergence for Domain Adaptation", "comments": "Published on IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "journal-ref": null, "doi": "10.1109/TPAMI.2020.2991050", "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation addresses the problem of transferring\nknowledge from a well-labeled source domain to an unlabeled target domain where\nthe two domains have distinctive data distributions. Thus, the essence of\ndomain adaptation is to mitigate the distribution divergence between the two\ndomains. The state-of-the-art methods practice this very idea by either\nconducting adversarial training or minimizing a metric which defines the\ndistribution gaps. In this paper, we propose a new domain adaptation method\nnamed Adversarial Tight Match (ATM) which enjoys the benefits of both\nadversarial training and metric learning. Specifically, at first, we propose a\nnovel distance loss, named Maximum Density Divergence (MDD), to quantify the\ndistribution divergence. MDD minimizes the inter-domain divergence (\"match\" in\nATM) and maximizes the intra-class density (\"tight\" in ATM). Then, to address\nthe equilibrium challenge issue in adversarial domain adaptation, we consider\nleveraging the proposed MDD into adversarial domain adaptation framework. At\nlast, we tailor the proposed MDD as a practical learning loss and report our\nATM. Both empirical evaluation and theoretical analysis are reported to verify\nthe effectiveness of the proposed method. The experimental results on four\nbenchmarks, both classical and large-scale, show that our method is able to\nachieve new state-of-the-art performance on most evaluations. Codes and\ndatasets used in this paper are available at {\\it github.com/lijin118/ATM}.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 07:35:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Jingjing", "Li", ""], ["Erpeng", "Chen", ""], ["Zhengming", "Ding", ""], ["Lei", "Zhu", ""], ["Ke", "Lu", ""], ["Tao", "Shen Heng", ""]]}, {"id": "2004.12644", "submitter": "Valerio Bonometti", "authors": "Valerio Bonometti, Charles Ringer, Mathieu Ruiz, Alex Wade, Anders\n  Drachen", "title": "From Theory to Behaviour: Towards a General Model of Engagement", "comments": "In review for being included in the proceedings of \"Conference on\n  Games\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engagement is a fuzzy concept. In the present work we operationalize\nengagement mechanistically by linking it directly to human behaviour and show\nthat the construct of engagement can be used for shaping and interpreting\ndata-driven methods. First we outline a formal framework for engagement\nmodelling. Second we expanded on our previous work on theory-inspired\ndata-driven approaches to better model the engagement process by proposing a\nnew modelling technique, the Melchoir Model. Third, we illustrate how, through\nmodel comparison and inspection, we can link machine-learned models and\nunderlying theoretical frameworks. Finally we discuss our results in light of a\ntheory-driven hypothesis and highlight potential application of our work in\nindustry.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 08:44:30 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bonometti", "Valerio", ""], ["Ringer", "Charles", ""], ["Ruiz", "Mathieu", ""], ["Wade", "Alex", ""], ["Drachen", "Anders", ""]]}, {"id": "2004.12678", "submitter": "Christian Muench", "authors": "Christian Muench, Frans A. Oliehoek, Dariu M. Gavrila", "title": "Diversity in Action: General-Sum Multi-Agent Continuous Inverse Optimal\n  Control", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic scenarios are inherently interactive. Multiple decision-makers\npredict the actions of others and choose strategies that maximize their\nrewards. We view these interactions from the perspective of game theory which\nintroduces various challenges. Humans are not entirely rational, their rewards\nneed to be inferred from real-world data, and any prediction algorithm needs to\nbe real-time capable so that we can use it in an autonomous vehicle (AV). In\nthis work, we present a game-theoretic method that addresses all of the points\nabove. Compared to many existing methods used for AVs, our approach does 1) not\nrequire perfect communication, and 2) allows for individual rewards per agent.\nOur experiments demonstrate that these more realistic assumptions lead to\nqualitatively and quantitatively different reward inference and prediction of\nfuture actions that match better with expected real-world behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 09:53:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Muench", "Christian", ""], ["Oliehoek", "Frans A.", ""], ["Gavrila", "Dariu M.", ""]]}, {"id": "2004.12696", "submitter": "Shell Hu", "authors": "Shell Xu Hu, Pablo G. Moreno, Yang Xiao, Xi Shen, Guillaume Obozinski,\n  Neil D. Lawrence, Andreas Damianou", "title": "Empirical Bayes Transductive Meta-Learning with Synthetic Gradients", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a meta-learning approach that learns from multiple tasks in a\ntransductive setting, by leveraging the unlabeled query set in addition to the\nsupport set to generate a more powerful model for each task. To develop our\nframework, we revisit the empirical Bayes formulation for multi-task learning.\nThe evidence lower bound of the marginal log-likelihood of empirical Bayes\ndecomposes as a sum of local KL divergences between the variational posterior\nand the true posterior on the query set of each task. We derive a novel\namortized variational inference that couples all the variational posteriors via\na meta-model, which consists of a synthetic gradient network and an\ninitialization network. Each variational posterior is derived from synthetic\ngradient descent to approximate the true posterior on the query set, although\nwhere we do not have access to the true gradient. Our results on the\nMini-ImageNet and CIFAR-FS benchmarks for episodic few-shot classification\noutperform previous state-of-the-art methods. Besides, we conduct two zero-shot\nlearning experiments to further explore the potential of the synthetic\ngradient.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:39:33 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hu", "Shell Xu", ""], ["Moreno", "Pablo G.", ""], ["Xiao", "Yang", ""], ["Shen", "Xi", ""], ["Obozinski", "Guillaume", ""], ["Lawrence", "Neil D.", ""], ["Damianou", "Andreas", ""]]}, {"id": "2004.12731", "submitter": "YouCheng Huang", "authors": "Youcheng Huang and Tangchen Wei and Jundong Zhou and Chunxin Yang", "title": "Lifelong Learning Process: Self-Memory Supervising and Dynamically\n  Growing Networks", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From childhood to youth, human gradually come to know the world. But for\nneural networks, this growing process seems difficult. Trapped in catastrophic\nforgetting, current researchers feed data of all categories to a neural network\nwhich remains the same structure in the whole training process. We compare this\ntraining process with human learing patterns, and find two major conflicts. In\nthis paper, we study how to solve these conflicts on generative models based on\nthe conditional variational autoencoder(CVAE) model. To solve the uncontinuous\nconflict, we apply memory playback strategy to maintain the model's recognizing\nand generating ability on invisible used categories. And we extend the\ntraditional one-way CVAE to a circulatory mode to better accomplish memory\nplayback strategy. To solve the `dead' structure conflict, we rewrite the CVAE\nformula then are able to make a novel interpretation about the funtions of\ndifferent parts in CVAE models. Based on the new understanding, we find ways to\ndynamically extend the network structure when training on new categories. We\nverify the effectiveness of our methods on MNIST and Fashion MNIST and display\nsome very insteresting results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:00:18 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Huang", "Youcheng", ""], ["Wei", "Tangchen", ""], ["Zhou", "Jundong", ""], ["Yang", "Chunxin", ""]]}, {"id": "2004.12756", "submitter": "Yunxia Lin", "authors": "Yunxia Lin, Songcan Chen", "title": "A Centroid Auto-Fused Hierarchical Fuzzy c-Means Clustering", "comments": "12 pages, accepted by IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like k-means and Gaussian Mixture Model (GMM), fuzzy c-means (FCM) with soft\npartition has also become a popular clustering algorithm and still is\nextensively studied. However, these algorithms and their variants still suffer\nfrom some difficulties such as determination of the optimal number of clusters\nwhich is a key factor for clustering quality. A common approach for overcoming\nthis difficulty is to use the trial-and-validation strategy, i.e., traversing\nevery integer from large number like $\\sqrt{n}$ to 2 until finding the optimal\nnumber corresponding to the peak value of some cluster validity index. But it\nis scarcely possible to naturally construct an adaptively agglomerative\nhierarchical cluster structure as using the trial-and-validation strategy. Even\npossible, existing different validity indices also lead to different number of\nclusters. To effectively mitigate the problems while motivated by convex\nclustering, in this paper we present a Centroid Auto-Fused Hierarchical Fuzzy\nc-means method (CAF-HFCM) whose optimization procedure can automatically\nagglomerate to form a cluster hierarchy, more importantly, yielding an optimal\nnumber of clusters without resorting to any validity index. Although a\nrecently-proposed robust-learning fuzzy c-means (RL-FCM) can also automatically\nobtain the best number of clusters without the help of any validity index,\nso-involved 3 hyper-parameters need to adjust expensively, conversely, our\nCAF-HFCM involves just 1 hyper-parameter which makes the corresponding\nadjustment is relatively easier and more operational. Further, as an additional\nbenefit from our optimization objective, the CAF-HFCM effectively reduces the\nsensitivity to the initialization of clustering performance. Moreover, our\nproposed CAF-HFCM method is able to be straightforwardly extended to various\nvariants of FCM.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:59:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Lin", "Yunxia", ""], ["Chen", "Songcan", ""]]}, {"id": "2004.12782", "submitter": "Himanshu Tyagi", "authors": "Aditya Gopalan and Himanshu Tyagi", "title": "How Reliable are Test Numbers for Revealing the COVID-19 Ground Truth\n  and Applying Interventions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG q-bio.PE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of confirmed cases of COVID-19 is often used as a proxy for the\nactual number of ground truth COVID-19 infected cases in both public discourse\nand policy making. However, the number of confirmed cases depends on the\ntesting policy, and it is important to understand how the number of positive\ncases obtained using different testing policies reveals the unknown ground\ntruth. We develop an agent-based simulation framework in Python that can\nsimulate various testing policies as well as interventions such as lockdown\nbased on them. The interaction between the agents can take into account various\ncommunities and mobility patterns. A distinguishing feature of our framework is\nthe presence of another `flu'-like illness with symptoms similar to COVID-19,\nthat allows us to model the noise in selecting the pool of patients to be\ntested. We instantiate our model for the city of Bengaluru in India, using\ncensus data to distribute agents geographically, and traffic flow mobility data\nto model long-distance interactions and mixing. We use the simulation framework\nto compare the performance of three testing policies: Random Symptomatic\nTesting (RST), Contact Tracing (CT), and a new Location Based Testing policy\n(LBT). We observe that if a sufficient fraction of symptomatic patients come\nout for testing, then RST can capture the ground truth quite closely even with\nvery few daily tests. However, CT consistently captures more positive cases.\nInterestingly, our new LBT, which is operationally less intensive than CT,\ngives performance that is comparable with CT. In another direction, we compare\nthe efficacy of these three testing policies in enabling lockdown, and observe\nthat CT flattens the ground truth curve maximally, followed closely by LBT, and\nsignificantly better than RST.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:39:49 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gopalan", "Aditya", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "2004.12814", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Michele Scarpiniti, Enzo Baccarelli, Aurelio Uncini", "title": "Why should we add early exits to neural networks?", "comments": "Published in Cognitive Computation", "journal-ref": "Cognitive Computation, 2020", "doi": "10.1007/s12559-020-09734-4", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are generally designed as a stack of differentiable\nlayers, in which a prediction is obtained only after running the full stack.\nRecently, some contributions have proposed techniques to endow the networks\nwith early exits, allowing to obtain predictions at intermediate points of the\nstack. These multi-output networks have a number of advantages, including: (i)\nsignificant reductions of the inference time, (ii) reduced tendency to\noverfitting and vanishing gradients, and (iii) capability of being distributed\nover multi-tier computation platforms. In addition, they connect to the wider\nthemes of biological plausibility and layered cognitive reasoning. In this\npaper, we provide a comprehensive introduction to this family of neural\nnetworks, by describing in a unified fashion the way these architectures can be\ndesigned, trained, and actually deployed in time-constrained scenarios. We also\ndescribe in-depth their application scenarios in 5G and Fog computing\nenvironments, as long as some of the open research questions connected to them.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 13:53:16 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:42:10 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Baccarelli", "Enzo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2004.12873", "submitter": "Saurabh Arora", "authors": "Saurabh Arora, Bikramjit Banerjee, Prashant Doshi", "title": "Maximum Entropy Multi-Task Inverse RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task IRL allows for the possibility that the expert could be switching\nbetween multiple ways of solving the same problem, or interleaving\ndemonstrations of multiple tasks. The learner aims to learn the multiple reward\nfunctions that guide these ways of solving the problem. We present a new method\nfor multi-task IRL that generalizes the well-known maximum entropy approach to\nIRL by combining it with the Dirichlet process based clustering of the observed\ninput. This yields a single nonlinear optimization problem, called MaxEnt\nMulti-task IRL, which can be solved using the Lagrangian relaxation and\ngradient descent methods. We evaluate MaxEnt Multi-task IRL in simulation on\nthe robotic task of sorting onions on a processing line where the expert\nutilizes multiple ways of detecting and removing blemished onions. The method\nis able to learn the underlying reward functions to a high level of accuracy\nand it improves on the previous approaches to multi-task IRL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:30:58 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Arora", "Saurabh", ""], ["Banerjee", "Bikramjit", ""], ["Doshi", "Prashant", ""]]}, {"id": "2004.12905", "submitter": "James Mullenbach", "authors": "James Mullenbach, Jordan Swartz, T. Greg McKelvey, Hui Dai, David\n  Sontag", "title": "Knowledge Base Completion for Constructing Problem-Oriented Medical\n  Records", "comments": "MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both electronic health records and personal health records are typically\norganized by data type, with medical problems, medications, procedures, and\nlaboratory results chronologically sorted in separate areas of the chart. As a\nresult, it can be difficult to find all of the relevant information for\nanswering a clinical question about a given medical problem. A promising\nalternative is to instead organize by problems, with related medications,\nprocedures, and other pertinent information all grouped together. A recent\neffort by Buchanan (2017) manually defined, through expert consensus, 11\nmedical problems and the relevant labs and medications for each. We show how to\nuse machine learning on electronic health records to instead automatically\nconstruct these problem-based groupings of relevant medications, procedures,\nand laboratory tests. We formulate the learning task as one of knowledge base\ncompletion, and annotate a dataset that expands the set of problems from 11 to\n32. We develop a model architecture that exploits both pre-trained concept\nembeddings and usage data relating the concepts contained in a longitudinal\ndataset from a large health system. We evaluate our algorithms' ability to\nsuggest relevant medications, procedures, and lab tests, and find that the\napproach provides feasible suggestions even for problems that are hidden during\ntraining. The dataset, along with code to reproduce our results, is available\nat https://github.com/asappresearch/kbc-pomr.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:05:23 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:22:31 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mullenbach", "James", ""], ["Swartz", "Jordan", ""], ["McKelvey", "T. Greg", ""], ["Dai", "Hui", ""], ["Sontag", "David", ""]]}, {"id": "2004.12906", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Ivan Ustyuzhaninov, Peter Gehler, Matthias\n  Bethge, Bernhard Sch\\\"olkopf", "title": "Towards causal generative scene models via competition of experts", "comments": "Presented at the ICLR 2020 workshop \"Causal learning for decision\n  making\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning how to model complex scenes in a modular way with recombinable\ncomponents is a pre-requisite for higher-order reasoning and acting in the\nphysical world. However, current generative models lack the ability to capture\nthe inherently compositional and layered nature of visual scenes. While recent\nwork has made progress towards unsupervised learning of object-based scene\nrepresentations, most models still maintain a global representation space\n(i.e., objects are not explicitly separated), and cannot generate scenes with\nnovel object arrangement and depth ordering. Here, we present an alternative\napproach which uses an inductive bias encouraging modularity by training an\nensemble of generative models (experts). During training, experts compete for\nexplaining parts of a scene, and thus specialise on different object classes,\nwith objects being identified as parts that re-occur across multiple scenes.\nOur model allows for controllable sampling of individual objects and\nrecombination of experts in physically plausible ways. In contrast to other\nmethods, depth layering and occlusion are handled correctly, moving this\napproach closer to a causal generative scene model. Experiments on simple toy\ndata qualitatively demonstrate the conceptual advantages of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:10:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Ustyuzhaninov", "Ivan", ""], ["Gehler", "Peter", ""], ["Bethge", "Matthias", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2004.12908", "submitter": "Jayanta Dey", "authors": "Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak\n  D. Mehta, Ali Geisa, Gido M. van de Ven, Emily Chang, Chenyu Gao, Weiwei\n  Yang, Bryan Tower, Jonathan Larson, Christopher M. White, and Carey E. Priebe", "title": "Omnidirectional Transfer for Quasilinear Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biological learning, data are used to improve performance not only on the\ncurrent task, but also on previously encountered and as yet unencountered\ntasks. In contrast, classical machine learning starts from a blank slate, or\ntabula rasa, using data only for the single task at hand. While typical\ntransfer learning algorithms can improve performance on future tasks, their\nperformance on prior tasks degrades upon learning new tasks (called\ncatastrophic forgetting). Many recent approaches for continual or lifelong\nlearning have attempted to maintain performance given new tasks. But striving\nto avoid forgetting sets the goal unnecessarily low: the goal of lifelong\nlearning, whether biological or artificial, should be to improve performance on\nall tasks (including past and future) with any new data. We propose\nomnidirectional transfer learning algorithms, which includes two special cases\nof interest: decision forests and deep networks. Our key insight is the\ndevelopment of the omni-voter layer, which ensembles representations learned\nindependently on all tasks to jointly decide how to proceed on any given new\ndata point, thereby improving performance on both past and future tasks. Our\nalgorithms demonstrate omnidirectional transfer in a variety of simulated and\nreal data scenarios, including tabular data, image data, spoken data, and\nadversarial tasks. Moreover, they do so with quasilinear space and time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:16:30 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:42:48 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 19:10:05 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 19:22:48 GMT"}, {"version": "v5", "created": "Thu, 20 Aug 2020 14:34:24 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 15:46:10 GMT"}, {"version": "v7", "created": "Mon, 14 Jun 2021 15:35:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vogelstein", "Joshua T.", ""], ["Dey", "Jayanta", ""], ["Helm", "Hayden S.", ""], ["LeVine", "Will", ""], ["Mehta", "Ronak D.", ""], ["Geisa", "Ali", ""], ["van de Ven", "Gido M.", ""], ["Chang", "Emily", ""], ["Gao", "Chenyu", ""], ["Yang", "Weiwei", ""], ["Tower", "Bryan", ""], ["Larson", "Jonathan", ""], ["White", "Christopher M.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2004.12909", "submitter": "Hao Sun", "authors": "Hao Sun, Xinyu Pan, Bo Dai, Dahua Lin, Bolei Zhou", "title": "Evolutionary Stochastic Policy Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving the Goal-Conditioned Reward Sparse (GCRS) task is a challenging\nreinforcement learning problem due to the sparsity of reward signals. In this\nwork, we propose a new formulation of GCRS tasks from the perspective of the\ndrifted random walk on the state space, and design a novel method called\nEvolutionary Stochastic Policy Distillation (ESPD) to solve them based on the\ninsight of reducing the First Hitting Time of the stochastic process. As a\nself-imitate approach, ESPD enables a target policy to learn from a series of\nits stochastic variants through the technique of policy distillation (PD). The\nlearning mechanism of ESPD can be considered as an Evolution Strategy (ES) that\napplies perturbations upon policy directly on the action space, with a SELECT\nfunction to check the superiority of stochastic variants and then use PD to\nupdate the policy. The experiments based on the MuJoCo robotics control suite\nshow the high learning efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:19:25 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:00:24 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Sun", "Hao", ""], ["Pan", "Xinyu", ""], ["Dai", "Bo", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "2004.12956", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhe Wang, Yingbin Liang", "title": "Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The actor-critic (AC) algorithm is a popular method to find an optimal policy\nin reinforcement learning. In the infinite horizon scenario, the finite-sample\nconvergence rate for the AC and natural actor-critic (NAC) algorithms has been\nestablished recently, but under independent and identically distributed\n(i.i.d.) sampling and single-sample update at each iteration. In contrast, this\npaper characterizes the convergence rate and sample complexity of AC and NAC\nunder Markovian sampling, with mini-batch data for each iteration, and with\nactor having general policy class approximation. We show that the overall\nsample complexity for a mini-batch AC to attain an $\\epsilon$-accurate\nstationary point improves the best known sample complexity of AC by an order of\n$\\mathcal{O}(\\epsilon^{-1}\\log(1/\\epsilon))$, and the overall sample complexity\nfor a mini-batch NAC to attain an $\\epsilon$-accurate globally optimal point\nimproves the existing sample complexity of NAC by an order of\n$\\mathcal{O}(\\epsilon^{-1}/\\log(1/\\epsilon))$. Moreover, the sample complexity\nof AC and NAC characterized in this work outperforms that of policy gradient\n(PG) and natural policy gradient (NPG) by a factor of\n$\\mathcal{O}((1-\\gamma)^{-3})$ and\n$\\mathcal{O}((1-\\gamma)^{-4}\\epsilon^{-1}/\\log(1/\\epsilon))$, respectively.\nThis is the first theoretical study establishing that AC and NAC attain\norderwise performance improvement over PG and NPG under infinite horizon due to\nthe incorporation of critic.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:11:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:20:38 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 17:23:59 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 01:00:43 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Xu", "Tengyu", ""], ["Wang", "Zhe", ""], ["Liang", "Yingbin", ""]]}, {"id": "2004.12983", "submitter": "Mahdi Haghifam", "authors": "Mahdi Haghifam, Jeffrey Negrea, Ashish Khisti, Daniel M. Roy, Gintare\n  Karolina Dziugaite", "title": "Sharpened Generalization Bounds based on Conditional Mutual Information\n  and an Application to Noisy, Iterative Algorithms", "comments": "23 Pages, 3 Figures. To appear in, Advances in Neural Information\n  Processing Systems (34), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information-theoretic framework of Russo and J. Zou (2016) and Xu and\nRaginsky (2017) provides bounds on the generalization error of a learning\nalgorithm in terms of the mutual information between the algorithm's output and\nthe training sample. In this work, we study the proposal, by Steinke and\nZakynthinou (2020), to reason about the generalization error of a learning\nalgorithm by introducing a super sample that contains the training sample as a\nrandom subset and computing mutual information conditional on the super sample.\nWe first show that these new bounds based on the conditional mutual information\nare tighter than those based on the unconditional mutual information. We then\nintroduce yet tighter bounds, building on the \"individual sample\" idea of Bu,\nS. Zou, and Veeravalli (2019) and the \"data dependent\" ideas of Negrea et al.\n(2019), using disintegrated mutual information. Finally, we apply these bounds\nto the study of Langevin dynamics algorithm, showing that conditioning on the\nsuper sample allows us to exploit information in the optimization trajectory to\nobtain tighter bounds based on hypothesis tests.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:51:09 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 14:10:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Haghifam", "Mahdi", ""], ["Negrea", "Jeffrey", ""], ["Khisti", "Ashish", ""], ["Roy", "Daniel M.", ""], ["Dziugaite", "Gintare Karolina", ""]]}, {"id": "2004.13002", "submitter": "Swagatam Das", "authors": "Arka Ghosh, Sankha Subhra Mullick, Shounak Datta, Swagatam Das,\n  Rammohan Mallipeddi, Asit Kr. Das", "title": "One Sparse Perturbation to Fool them All, almost Always!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing adversarial perturbations for deep neural networks is an\nimportant direction of research. Crafting image-dependent adversarial\nperturbations using white-box feedback has hitherto been the norm for such\nadversarial attacks. However, black-box attacks are much more practical for\nreal-world applications. Universal perturbations applicable across multiple\nimages are gaining popularity due to their innate generalizability. There have\nalso been efforts to restrict the perturbations to a few pixels in the image.\nThis helps to retain visual similarity with the original images making such\nattacks hard to detect. This paper marks an important step which combines all\nthese directions of research. We propose the DEceit algorithm for constructing\neffective universal pixel-restricted perturbations using only black-box\nfeedback from the target network. We conduct empirical investigations using the\nImageNet validation set on the state-of-the-art deep neural classifiers by\nvarying the number of pixels to be perturbed from a meagre 10 pixels to as high\nas all pixels in the image. We find that perturbing only about 10% of the\npixels in an image using DEceit achieves a commendable and highly transferable\nFooling Rate while retaining the visual quality. We further demonstrate that\nDEceit can be successfully applied to image dependent attacks as well. In both\nsets of experiments, we outperformed several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:42:00 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:02:32 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Ghosh", "Arka", ""], ["Mullick", "Sankha Subhra", ""], ["Datta", "Shounak", ""], ["Das", "Swagatam", ""], ["Mallipeddi", "Rammohan", ""], ["Das", "Asit Kr.", ""]]}, {"id": "2004.13003", "submitter": "Tian Shi", "authors": "Tian Shi, Xuchao Zhang, Ping Wang, Chandan K. Reddy", "title": "Corpus-level and Concept-based Explanations for Interpretable Document\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using attention weights to identify information that is important for models'\ndecision-making is a popular approach to interpret attention-based neural\nnetworks. This is commonly realized in practice through the generation of a\nheat-map for every single document based on attention weights. However, this\ninterpretation method is fragile, and easy to find contradictory examples. In\nthis paper, we propose a corpus-level explanation approach, which aims to\ncapture causal relationships between keywords and model predictions via\nlearning the importance of keywords for predicted labels across a training\ncorpus based on attention weights. Based on this idea, we further propose a\nconcept-based explanation method that can automatically learn higher-level\nconcepts and their importance to model prediction tasks. Our concept-based\nexplanation method is built upon a novel Abstraction-Aggregation Network, which\ncan automatically cluster important keywords during an end-to-end training\nprocess. We apply these methods to the document classification task and show\nthat they are powerful in extracting semantically meaningful keywords and\nconcepts. Our consistency analysis results based on an attention-based Na\\\"ive\nBayes classifier also demonstrate these keywords and concepts are important for\nmodel predictions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:54:17 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 21:48:26 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 04:50:32 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 03:22:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shi", "Tian", ""], ["Zhang", "Xuchao", ""], ["Wang", "Ping", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "2004.13005", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Amro El-Jaroudi, William Hartmann, Damianos Karakos,\n  Lingjun Zhao", "title": "Cross-lingual Information Retrieval with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple neural language models have been developed recently, e.g., BERT and\nXLNet, and achieved impressive results in various NLP tasks including sentence\nclassification, question answering and document ranking. In this paper, we\nexplore the use of the popular bidirectional language model, BERT, to model and\nlearn the relevance between English queries and foreign-language documents in\nthe task of cross-lingual information retrieval. A deep relevance matching\nmodel based on BERT is introduced and trained by finetuning a pretrained\nmultilingual BERT model with weak supervision, using home-made CLIR training\ndata derived from parallel corpora. Experimental results of the retrieval of\nLithuanian documents against short English queries show that our model is\neffective and outperforms the competitive baseline approaches.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:32:13 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jiang", "Zhuolin", ""], ["El-Jaroudi", "Amro", ""], ["Hartmann", "William", ""], ["Karakos", "Damianos", ""], ["Zhao", "Lingjun", ""]]}, {"id": "2004.13006", "submitter": "Onur Barut", "authors": "Onur Barut, Yan Luo, Tong Zhang, Weigang Li, Peilong Li", "title": "NetML: A Challenge for Network Traffic Analytics", "comments": "27 pages, 39 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classifying network traffic is the basis for important network applications.\nPrior research in this area has faced challenges on the availability of\nrepresentative datasets, and many of the results cannot be readily reproduced.\nSuch a problem is exacerbated by emerging data-driven machine learning based\napproaches. To address this issue, we provide three open datasets containing\nalmost 1.3M labeled flows in total, with flow features and anonymized raw\npackets, for the research community. We focus on broad aspects in network\ntraffic analysis, including both malware detection and application\nclassification. We release the datasets in the form of an open challenge called\nNetML and implement several machine learning methods including random-forest,\nSVM and MLP. As we continue to grow NetML, we expect the datasets to serve as a\ncommon platform for AI driven, reproducible research on network flow analytics.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 01:12:17 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Barut", "Onur", ""], ["Luo", "Yan", ""], ["Zhang", "Tong", ""], ["Li", "Weigang", ""], ["Li", "Peilong", ""]]}, {"id": "2004.13012", "submitter": "Dara Bahri", "authors": "Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, Andrew Tomkins", "title": "Choppy: Cut Transformer For Ranked List Truncation", "comments": "SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work in information retrieval has traditionally focused on ranking and\nrelevance: given a query, return some number of results ordered by relevance to\nthe user. However, the problem of determining how many results to return, i.e.\nhow to optimally truncate the ranked result list, has received less attention\ndespite being of critical importance in a range of applications. Such\ntruncation is a balancing act between the overall relevance, or usefulness of\nthe results, with the user cost of processing more results. In this work, we\npropose Choppy, an assumption-free model based on the widely successful\nTransformer architecture, to the ranked list truncation problem. Needing\nnothing more than the relevance scores of the results, the model uses a\npowerful multi-head attention mechanism to directly optimize any user-defined\nIR metric. We show Choppy improves upon recent state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 00:52:49 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bahri", "Dara", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Metzler", "Donald", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2004.13023", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient Inverse-Free Incremental and Decremental Algorithms for\n  Multiple Hidden Nodes in Extreme Learning Machine", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.04856", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse-free extreme learning machine (ELM) algorithm proposed in [4] was\nbased on an inverse-free algorithm to compute the regularized pseudo-inverse,\nwhich was deduced from an inverse-free recursive algorithm to update the\ninverse of a Hermitian matrix. Before that recursive algorithm was applied in\n[4], its improved version had been utilized in previous literatures [9], [10].\nAccordingly from the improved recursive algorithm [9], [10], several efficient\ninverse-free algorithms for ELM were proposed in [13] to reduce the\ncomputational complexity. In this paper, we propose two inverse-free algorithms\nfor ELM with Tikhonov regularization, which can increase multiple hidden nodes\nin an iteration. On the other hand, we also propose two efficient decremental\nlearning algorithms for ELM with Tikhonov regularization, which can remove\nmultiple redundant nodes in an iteration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 07:04:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "2004.13066", "submitter": "Azra Bihorac", "authors": "Yanjun Li (4)(5), Yuanfang Ren (1)(5), Tyler J. Loftus (2,5), Shounak\n  Datta (1) (5), M. Ruppert (1)(5), Ziyuan Guan (1)(5), Dapeng Wu (4), Parisa\n  Rashidi (3)(5), Tezcan Ozrazgat-Baslanti (1)(5)(6), and Azra Bihorac\n  (3)(5)(6) ((1) Department of Medicine, Division of Nephrology, Hypertension,\n  and Renal Transplantation, University of Florida, Gainesville, FL. (2)\n  Department of Surgery, University of Florida, Gainesville, FL. (3) J. Crayton\n  Pruitt Family Department of Biomedical Engineering, University of Florida,\n  Gainesville, FL. (4) NSF Center for Big Learning, University of Florida,\n  Gainesville, FL. (5) Precision and Intelligent Systems in Medicine (PrismaP),\n  University of Florida, Gainesville, FL (6) Sepsis and Critical Illness\n  Research Center, University of Florida, Gainesville, FL. )", "title": "Application of Deep Interpolation Network for Clustering of Physiologic\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: During the early stages of hospital admission, clinicians must\nuse limited information to make diagnostic and treatment decisions as patient\nacuity evolves. However, it is common that the time series vital sign\ninformation from patients to be both sparse and irregularly collected, which\nposes a significant challenge for machine / deep learning techniques to analyze\nand facilitate the clinicians to improve the human health outcome. To deal with\nthis problem, We propose a novel deep interpolation network to extract latent\nrepresentations from sparse and irregularly sampled time-series vital signs\nmeasured within six hours of hospital admission. Methods: We created a\nsingle-center longitudinal dataset of electronic health record data for all\n(n=75,762) adult patient admissions to a tertiary care center lasting six hours\nor longer, using 55% of the dataset for training, 23% for validation, and 22%\nfor testing. All raw time series within six hours of hospital admission were\nextracted for six vital signs (systolic blood pressure, diastolic blood\npressure, heart rate, temperature, blood oxygen saturation, and respiratory\nrate). A deep interpolation network is proposed to learn from such irregular\nand sparse multivariate time series data to extract the fixed low-dimensional\nlatent patterns. We use k-means clustering algorithm to clusters the patient\nadmissions resulting into 7 clusters. Findings: Training, validation, and\ntesting cohorts had similar age (55-57 years), sex (55% female), and admission\nvital signs. Seven distinct clusters were identified. M Interpretation: In a\nheterogeneous cohort of hospitalized patients, a deep interpolation network\nextracted representations from vital sign data measured within six hours of\nhospital admission. This approach may have important implications for clinical\ndecision-support under time constraints and uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:03:24 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Li", "Yanjun", ""], ["Ren", "Yuanfang", ""], ["Loftus", "Tyler J.", ""], ["Datta", "Shounak", ""], ["Ruppert", "M.", ""], ["Guan", "Ziyuan", ""], ["Wu", "Dapeng", ""], ["Rashidi", "Parisa", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""]]}, {"id": "2004.13106", "submitter": "Beyza Ermis Ms", "authors": "Beyza Ermis, Patrick Ernst, Yannik Stein, Giovanni Zappella", "title": "Learning to Rank in the Position Based Model with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is a crucial aspect of many online experiences. In\nparticular, content ranking is often a key component in delivering\nsophisticated personalization results. Commonly, supervised learning-to-rank\nmethods are applied, which suffer from bias introduced during data collection\nby production systems in charge of producing the ranking. To compensate for\nthis problem, we leverage contextual multi-armed bandits. We propose novel\nextensions of two well-known algorithms viz. LinUCB and Linear Thompson\nSampling to the ranking use-case. To account for the biases in a production\nenvironment, we employ the position-based click model. Finally, we show the\nvalidity of the proposed algorithms by conducting extensive offline experiments\non synthetic datasets as well as customer facing online A/B experiments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 19:12:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ermis", "Beyza", ""], ["Ernst", "Patrick", ""], ["Stein", "Yannik", ""], ["Zappella", "Giovanni", ""]]}, {"id": "2004.13122", "submitter": "Seifedine Kadry", "authors": "Seifedine Kadry, Venkatesan Rajinikanth, Seungmin Rho, Nadaradjane Sri\n  Madhava Raja, Vaddi Seshagiri Rao, Krishnan Palani Thanaraj", "title": "Development of a Machine-Learning System to Classify Lung CT Scan Images\n  into Normal/COVID-19 Class", "comments": "16 PAGES", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the lung infection due to Coronavirus Disease (COVID-19) affected a\nlarge human group worldwide and the assessment of the infection rate in the\nlung is essential for treatment planning. This research aims to propose a\nMachine-Learning-System (MLS) to detect the COVID-19 infection using the CT\nscan Slices (CTS). This MLS implements a sequence of methods, such as\nmulti-thresholding, image separation using threshold filter,\nfeature-extraction, feature-selection, feature-fusion and classification. The\ninitial part implements the Chaotic-Bat-Algorithm and Kapur's Entropy (CBA+KE)\nthresholding to enhance the CTS. The threshold filter separates the image into\ntwo segments based on a chosen threshold 'Th'. The texture features of these\nimages are extracted, refined and selected using the chosen procedures.\nFinally, a two-class classifier system is implemented to categorize the chosen\nCTS (n=500 with a pixel dimension of 512x512x1) into normal/COVID-19 group. In\nthis work, the classifiers, such as Naive Bayes (NB), k-Nearest Neighbors\n(KNN), Decision Tree (DT), Random Forest (RF) and Support Vector Machine with\nlinear kernel (SVM) are implemented and the classification task is performed\nusing various feature vectors. The experimental outcome of the SVM with\nFused-Feature-Vector (FFV) helped to attain a detection accuracy of 89.80%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:52:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Kadry", "Seifedine", ""], ["Rajinikanth", "Venkatesan", ""], ["Rho", "Seungmin", ""], ["Raja", "Nadaradjane Sri Madhava", ""], ["Rao", "Vaddi Seshagiri", ""], ["Thanaraj", "Krishnan Palani", ""]]}, {"id": "2004.13135", "submitter": "Florian Krach", "authors": "Calypso Herrera, Florian Krach, Josef Teichmann", "title": "Estimating Full Lipschitz Constants of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the Lipschitz constants of the gradient of a deep neural network\nand the network itself with respect to the full set of parameters. We first\ndevelop estimates for a deep feed-forward densely connected network and then,\nin a more general framework, for all neural networks that can be represented as\nsolutions of controlled ordinary differential equations, where time appears as\ncontinuous depth. These estimates can be used to set the step size of\nstochastic gradient descent methods, which is illustrated for one example\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:02:04 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:29:11 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Herrera", "Calypso", ""], ["Krach", "Florian", ""], ["Teichmann", "Josef", ""]]}, {"id": "2004.13148", "submitter": "Lauri Alho", "authors": "Lauri Alho, Adrian Burian, Janne Helenius, Joni Pajarinen", "title": "Machine Learning Based Mobile Network Throughput Classification", "comments": "Submitted to IEEE International Symposium on Personal, Indoor and\n  Mobile Radio Communications 2020 (IEEE PIMRC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying mobile network problems in 4G cells is more challenging when the\ncomplexity of the network increases, and privacy concerns limit the information\ncontent of the data. This paper proposes a data driven model for identifying 4G\ncells that have fundamental network throughput problems. The proposed model\ntakes advantage of clustering and Deep Neural Networks (DNNs). Model parameters\nare learnt using a small number of expert-labeled data. To achieve case\nspecific classification, we propose a model that contains a multiple clustering\nmodels block, for capturing features common for problematic cells. The captured\nfeatures of this block are then used as an input to a DNN. Experiments show\nthat the proposed model outperforms a simple classifier in identifying cells\nwith network throughput problems. To the best of the authors' knowledge, there\nis no related research where network throughput classification is performed on\nthe cell level with information gathered only from the service provider's side.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:08:06 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Alho", "Lauri", ""], ["Burian", "Adrian", ""], ["Helenius", "Janne", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2004.13152", "submitter": "Joshua Lockhart", "authors": "Joshua Lockhart, Samuel Assefa, Tucker Balch, Manuela Veloso", "title": "Some people aren't worth listening to: periodically retraining\n  classifiers with feedback from a team of end users", "comments": "Presented at the 2019 ICML Workshop on AI in Finance: Applications\n  and Infrastructure for Multi-Agent Learning. Long Beach, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document classification is ubiquitous in a business setting, but often the\nend users of a classifier are engaged in an ongoing feedback-retrain loop with\nthe team that maintain it. We consider this feedback-retrain loop from a\nmulti-agent point of view, considering the end users as autonomous agents that\nprovide feedback on the labelled data provided by the classifier. This allows\nus to examine the effect on the classifier's performance of unreliable end\nusers who provide incorrect feedback. We demonstrate a classifier that can\nlearn which users tend to be unreliable, filtering their feedback out of the\nloop, thus improving performance in subsequent iterations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:18:29 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lockhart", "Joshua", ""], ["Assefa", "Samuel", ""], ["Balch", "Tucker", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.13160", "submitter": "Jie Yang", "authors": "Jie Yang and Chin-Teng Lin", "title": "Clustering via torque balance with mass and distance", "comments": "28 pages, 12 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grouping similar objects is a fundamental tool of scientific analysis,\nubiquitous in disciplines from biology and chemistry to astronomy and pattern\nrecognition. Inspired by the torque balance that exists in gravitational\ninteractions when galaxies merge, we propose a novel clustering method based on\ntwo natural properties of the universe: mass and distance. The concept of\ntorque describing the interactions of mass and distance forms the basis of the\nproposed parameter-free clustering algorithm, which harnesses torque balance to\nrecognize any cluster, regardless of shape, size, or density. The gravitational\ninteractions govern the merger process, while the concept of torque balance\nreveals partitions that do not conform to the natural order for removal.\nExperiments on benchmark data sets show the enormous versatility of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:34:06 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yang", "Jie", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2004.13167", "submitter": "Joshua Meier", "authors": "Yilun Du, Joshua Meier, Jerry Ma, Rob Fergus, Alexander Rives", "title": "Energy-based models for atomic-resolution protein conformations", "comments": "Accepted to ICLR 2020", "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an energy-based model (EBM) of protein conformations that operates\nat atomic scale. The model is trained solely on crystallized protein data. By\ncontrast, existing approaches for scoring conformations use energy functions\nthat incorporate knowledge of physical principles and features that are the\ncomplex product of several decades of research and tuning. To evaluate the\nmodel, we benchmark on the rotamer recovery task, the problem of predicting the\nconformation of a side chain from its context within a protein structure, which\nhas been used to evaluate energy functions for protein design. The model\nachieves performance close to that of the Rosetta energy function, a\nstate-of-the-art method widely used in protein structure prediction and design.\nAn investigation of the model's outputs and hidden representations finds that\nit captures physicochemical properties relevant to protein energy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:45:12 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Du", "Yilun", ""], ["Meier", "Joshua", ""], ["Ma", "Jerry", ""], ["Fergus", "Rob", ""], ["Rives", "Alexander", ""]]}, {"id": "2004.13181", "submitter": "Sheldon Tan", "authors": "Wentian Jin, Sheriff Sadiqbatcha, Jinwei Zhang, Sheldon X.-D. Tan", "title": "EM-GAN: Fast Stress Analysis for Multi-Segment Interconnect Using\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fast transient hydrostatic stress analysis for\nelectromigration (EM) failure assessment for multi-segment interconnects using\ngenerative adversarial networks (GANs). Our work leverages the image synthesis\nfeature of GAN-based generative deep neural networks. The stress evaluation of\nmulti-segment interconnects, modeled by partial differential equations, can be\nviewed as time-varying 2D-images-to-image problem where the input is the\nmulti-segment interconnects topology with current densities and the output is\nthe EM stress distribution in those wire segments at the given aging time.\nBased on this observation, we train conditional GAN model using the images of\nmany self-generated multi-segment wires and wire current densities and aging\ntime (as conditions) against the COMSOL simulation results. Different\nhyperparameters of GAN were studied and compared. The proposed algorithm,\ncalled {\\it EM-GAN}, can quickly give accurate stress distribution of a general\nmulti-segment wire tree for a given aging time, which is important for\nfull-chip fast EM failure assessment. Our experimental results show that the\nEM-GAN shows 6.6\\% averaged error compared to COMSOL simulation results with\norders of magnitude speedup. It also delivers 8.3X speedup over\nstate-of-the-art analytic based EM analysis solver.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 21:18:11 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jin", "Wentian", ""], ["Sadiqbatcha", "Sheriff", ""], ["Zhang", "Jinwei", ""], ["Tan", "Sheldon X. -D.", ""]]}, {"id": "2004.13195", "submitter": "Naomi Saphra", "authors": "Naomi Saphra and Adam Lopez", "title": "Word Interdependence Exposes How LSTMs Compose Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in NLP shows that LSTM language models capture compositional\nstructure in language data. For a closer look at how these representations are\ncomposed hierarchically, we present a novel measure of interdependence between\nword meanings in an LSTM, based on their interactions at the internal gates. To\nexplore how compositional representations arise over training, we conduct\nsimple experiments on synthetic data, which illustrate our measure by showing\nhow high interdependence can hurt generalization. These synthetic experiments\nalso illustrate a specific hypothesis about how hierarchical structures are\ndiscovered over the course of training: that parent constituents rely on\neffective representations of their children, rather than on learning long-range\nrelations independently. We further support this measure with experiments on\nEnglish language data, where interdependence is higher for more closely\nsyntactically linked word pairs.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 21:48:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "2004.13202", "submitter": "Bohan Fan", "authors": "Bohan Fan, Diego Ihara Centurion, Neshat Mohammadi, Francesco Sgherzi,\n  Anastasios Sidiropoulos, Mina Valizadeh", "title": "Learning Lines with Ordinal Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a mapping $f$ from a set of points into the\nreal line, under ordinal triple constraints. An ordinal constraint for a triple\nof points $(u,v,w)$ asserts that $|f(u)-f(v)|<|f(u)-f(w)|$. We present an\napproximation algorithm for the dense case of this problem. Given an instance\nthat admits a solution that satisfies $(1-\\varepsilon)$-fraction of all\nconstraints, our algorithm computes a solution that satisfies\n$(1-O(\\varepsilon^{1/8}))$-fraction of all constraints, in time $O(n^7) +\n(1/\\varepsilon)^{O(1/\\varepsilon^{1/8})} n$.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 22:45:04 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 20:18:26 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Fan", "Bohan", ""], ["Centurion", "Diego Ihara", ""], ["Mohammadi", "Neshat", ""], ["Sgherzi", "Francesco", ""], ["Sidiropoulos", "Anastasios", ""], ["Valizadeh", "Mina", ""]]}, {"id": "2004.13233", "submitter": "Shixiang Chen", "authors": "Shixiang Chen, Alfredo Garcia and Shahin Shahrampour", "title": "On Distributed Non-convex Optimization: Projected Subgradient Method For\n  Weakly Convex Problems in Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TAC.2021.3056535", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic subgradient method is a widely-used algorithm for solving\nlarge-scale optimization problems arising in machine learning. Often these\nproblems are neither smooth nor convex. Recently, Davis et al. [1-2]\ncharacterized the convergence of the stochastic subgradient method for the\nweakly convex case, which encompasses many important applications (e.g., robust\nphase retrieval, blind deconvolution, biconvex compressive sensing, and\ndictionary learning). In practice, distributed implementations of the projected\nstochastic subgradient method (stoDPSM) are used to speed-up risk minimization.\nIn this paper, we propose a distributed implementation of the stochastic\nsubgradient method with a theoretical guarantee. Specifically, we show the\nglobal convergence of stoDPSM using the Moreau envelope stationarity measure.\nFurthermore, under a so-called sharpness condition, we show that deterministic\nDPSM (with a proper initialization) converges linearly to the sharp minima,\nusing geometrically diminishing step-size. We provide numerical experiments to\nsupport our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 01:01:49 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 20:32:36 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chen", "Shixiang", ""], ["Garcia", "Alfredo", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2004.13237", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "An ASP-Based Approach to Counterfactual Explanations for Classification", "comments": "Revised and extended version. To appear in Proc. RuleML+RR, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose answer-set programs that specify and compute counterfactual\ninterventions as a basis for causality-based explanations to decisions produced\nby classification models. They can be applied with black-box models and models\nthat can be specified as logic programs, such as rule-based classifiers. The\nmain focus in on the specification and computation of maximum responsibility\ncausal explanations. The use of additional semantic knowledge is investigated.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 01:36:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:56:13 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "2004.13242", "submitter": "Cameron Allen", "authors": "Cameron Allen, Michael Katz, Tim Klinger, George Konidaris, Matthew\n  Riemer, Gerald Tesauro", "title": "Efficient Black-Box Planning Using Macro-Actions with Focused Effects", "comments": "To appear at IJCAI 2021; code available at\n  https://github.com/camall3n/focused-macros", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of deterministic planning increases exponentially with\nsearch-tree depth. Black-box planning presents an even greater challenge, since\nplanners must operate without an explicit model of the domain. Heuristics can\nmake search more efficient, but goal-aware heuristics for black-box planning\nusually rely on goal counting, which is often quite uninformative. In this\nwork, we show how to overcome this limitation by discovering macro-actions that\nmake the goal-count heuristic more accurate. Our approach searches for\nmacro-actions with focused effects (i.e. macros that modify only a small number\nof state variables), which align well with the assumptions made by the\ngoal-count heuristic. Focused macros dramatically improve black-box planning\nefficiency across a wide range of planning domains, sometimes beating even\nstate-of-the-art planners with access to a full domain model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:13:12 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:17:18 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 19:38:24 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Allen", "Cameron", ""], ["Katz", "Michael", ""], ["Klinger", "Tim", ""], ["Konidaris", "George", ""], ["Riemer", "Matthew", ""], ["Tesauro", "Gerald", ""]]}, {"id": "2004.13245", "submitter": "Dai Tran", "authors": "Dai Hoang Tran, Quan Z. Sheng, Wei Emma Zhang, Salma Abdalla Hamad,\n  Munazza Zaib, Nguyen H. Tran, Lina Yao, Nguyen Lu Dang Khoa", "title": "Deep Conversational Recommender Systems: A New Frontier for\n  Goal-Oriented Dialogue Systems", "comments": "7 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the emerging topics of recommender systems that take\nadvantage of natural language processing techniques have attracted much\nattention, and one of their applications is the Conversational Recommender\nSystem (CRS). Unlike traditional recommender systems with content-based and\ncollaborative filtering approaches, CRS learns and models user's preferences\nthrough interactive dialogue conversations. In this work, we provide a\nsummarization of the recent evolution of CRS, where deep learning approaches\nare applied to CRS and have produced fruitful results. We first analyze the\nresearch problems and present key challenges in the development of Deep\nConversational Recommender Systems (DCRS), then present the current state of\nthe field taken from the most recent researches, including the most common deep\nlearning models that benefit DCRS. Finally, we discuss future directions for\nthis vibrant area.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:20:42 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Tran", "Dai Hoang", ""], ["Sheng", "Quan Z.", ""], ["Zhang", "Wei Emma", ""], ["Hamad", "Salma Abdalla", ""], ["Zaib", "Munazza", ""], ["Tran", "Nguyen H.", ""], ["Yao", "Lina", ""], ["Khoa", "Nguyen Lu Dang", ""]]}, {"id": "2004.13277", "submitter": "Akira Matsui", "authors": "Akira Matsui, Teruyoshi Kobayashi, Daisuke Moriwaki, Emilio Ferrara", "title": "Detecting multi-timescale consumption patterns from receipt data: A\n  non-negative tensor factorization approach", "comments": "16 pages, 10 figures", "journal-ref": "Journal of Computational Social Science (2020)", "doi": "10.1007/s42001-020-00078-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding consumer behavior is an important task, not only for developing\nmarketing strategies but also for the management of economic policies.\nDetecting consumption patterns, however, is a high-dimensional problem in which\nvarious factors that would affect consumers' behavior need to be considered,\nsuch as consumers' demographics, circadian rhythm, seasonal cycles, etc. Here,\nwe develop a method to extract multi-timescale expenditure patterns of\nconsumers from a large dataset of scanned receipts. We use a non-negative\ntensor factorization (NTF) to detect intra- and inter-week consumption patterns\nat one time. The proposed method allows us to characterize consumers based on\ntheir consumption patterns that are correlated over different timescales.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:07:03 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 04:03:23 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Matsui", "Akira", ""], ["Kobayashi", "Teruyoshi", ""], ["Moriwaki", "Daisuke", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2004.13303", "submitter": "Joey Tianyi Zhou Dr", "authors": "Joey Tianyi Zhou, Xi Peng and Yew-Soon Ong", "title": "Heterogeneous Representation Learning: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-world data usually exhibits heterogeneous properties such as\nmodalities, views, or resources, which brings some unique challenges wherein\nthe key is Heterogeneous Representation Learning (HRL) termed in this paper.\nThis brief survey covers the topic of HRL, centered around several major\nlearning settings and real-world applications. First of all, from the\nmathematical perspective, we present a unified learning framework which is able\nto model most existing learning settings with the heterogeneous inputs. After\nthat, we conduct a comprehensive discussion on the HRL framework by reviewing\nsome selected learning problems along with the mathematics perspectives,\nincluding multi-view learning, heterogeneous transfer learning, Learning using\nprivileged information and heterogeneous multi-task learning. For each learning\ntask, we also discuss some applications under these learning problems and\ninstantiates the terms in the mathematical framework. Finally, we highlight the\nchallenges that are less-touched in HRL and present future research directions.\nTo the best of our knowledge, there is no such framework to unify these\nheterogeneous problems, and this survey would benefit the community.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 05:12:31 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:46:43 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhou", "Joey Tianyi", ""], ["Peng", "Xi", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "2004.13314", "submitter": "Hamed Majidifard", "authors": "Hamed Majidifard, Yaw Adu-Gyamfi, William G. Buttlar", "title": "Deep Machine Learning Approach to Develop a New Asphalt Pavement\n  Condition Index", "comments": null, "journal-ref": null, "doi": "10.1016/j.conbuildmat.2020.118513", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated pavement distress detection via road images is still a challenging\nissue among pavement researchers and computer-vision community. In recent\nyears, advancement in deep learning has enabled researchers to develop robust\ntools for analyzing pavement images at unprecedented accuracies. Nevertheless,\ndeep learning models necessitate a big ground truth dataset, which is often not\nreadily accessible for pavement field. In this study, we reviewed our previous\nstudy, which a labeled pavement dataset was presented as the first step towards\na more robust, easy-to-deploy pavement condition assessment system. In total,\n7237 google street-view images were extracted, manually annotated for\nclassification (nine categories of distress classes). Afterward, YOLO (you look\nonly once) deep learning framework was implemented to train the model using the\nlabeled dataset. In the current study, a U-net based model is developed to\nquantify the severity of the distresses, and finally, a hybrid model is\ndeveloped by integrating the YOLO and U-net model to classify the distresses\nand quantify their severity simultaneously. Various pavement condition indices\nare developed by implementing various machine learning algorithms using the\nYOLO deep learning framework for distress classification and U-net for\nsegmentation and distress densification. The output of the distress\nclassification and segmentation models are used to develop a comprehensive\npavement condition tool which rates each pavement image according to the type\nand severity of distress extracted.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 05:57:43 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Majidifard", "Hamed", ""], ["Adu-Gyamfi", "Yaw", ""], ["Buttlar", "William G.", ""]]}, {"id": "2004.13321", "submitter": "Islem Rekik", "authors": "Ismail Bilgen and Goktug Guvercin and Islem Rekik", "title": "Machine Learning Methods for Brain Network Classification: Application\n  to Autism Diagnosis using Cortical Morphological Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) affects the brain connectivity at different\nlevels. Nonetheless, non-invasively distinguishing such effects using magnetic\nresonance imaging (MRI) remains very challenging to machine learning diagnostic\nframeworks due to ASD heterogeneity. So far, existing network neuroscience\nworks mainly focused on functional (derived from functional MRI) and structural\n(derived from diffusion MRI) brain connectivity, which might not capture\nrelational morphological changes between brain regions. Indeed, machine\nlearning (ML) studies for ASD diagnosis using morphological brain networks\nderived from conventional T1-weighted MRI are very scarce. To fill this gap, we\nleverage crowdsourcing by organizing a Kaggle competition to build a pool of\nmachine learning pipelines for neurological disorder diagnosis with application\nto ASD diagnosis using cortical morphological networks derived from T1-weighted\nMRI. During the competition, participants were provided with a training dataset\nand only allowed to check their performance on a public test data. The final\nevaluation was performed on both public and hidden test datasets based on\naccuracy, sensitivity, and specificity metrics. Teams were ranked using each\nperformance metric separately and the final ranking was determined based on the\nmean of all rankings. The first-ranked team achieved 70% accuracy, 72.5%\nsensitivity, and 67.5% specificity, while the second-ranked team achieved\n63.8%, 62.5%, 65% respectively. Leveraging participants to design ML diagnostic\nmethods within a competitive machine learning setting has allowed the\nexploration and benchmarking of wide spectrum of ML methods for ASD diagnosis\nusing cortical morphological networks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:23:29 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bilgen", "Ismail", ""], ["Guvercin", "Goktug", ""], ["Rekik", "Islem", ""]]}, {"id": "2004.13332", "submitter": "Stephan Zheng", "authors": "Stephan Zheng, Alexander Trott, Sunil Srinivasa, Nikhil Naik, Melvin\n  Gruesbeck, David C. Parkes, Richard Socher", "title": "The AI Economist: Improving Equality and Productivity with AI-Driven Tax\n  Policies", "comments": "46 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tackling real-world socio-economic challenges requires designing and testing\neconomic policies. However, this is hard in practice, due to a lack of\nappropriate (micro-level) economic data and limited opportunity to experiment.\nIn this work, we train social planners that discover tax policies in dynamic\neconomies that can effectively trade-off economic equality and productivity. We\npropose a two-level deep reinforcement learning approach to learn dynamic tax\npolicies, based on economic simulations in which both agents and a government\nlearn and adapt. Our data-driven approach does not make use of economic\nmodeling assumptions, and learns from observational data alone. We make four\nmain contributions. First, we present an economic simulation environment that\nfeatures competitive pressures and market dynamics. We validate the simulation\nby showing that baseline tax systems perform in a way that is consistent with\neconomic theory, including in regard to learned agent behaviors and\nspecializations. Second, we show that AI-driven tax policies improve the\ntrade-off between equality and productivity by 16% over baseline policies,\nincluding the prominent Saez tax framework. Third, we showcase several emergent\nfeatures: AI-driven tax policies are qualitatively different from baselines,\nsetting a higher top tax rate and higher net subsidies for low incomes.\nMoreover, AI-driven tax policies perform strongly in the face of emergent\ntax-gaming strategies learned by AI agents. Lastly, AI-driven tax policies are\nalso effective when used in experiments with human participants. In experiments\nconducted on MTurk, an AI tax policy provides an equality-productivity\ntrade-off that is similar to that provided by the Saez framework along with\nhigher inverse-income weighted social welfare.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:57:18 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zheng", "Stephan", ""], ["Trott", "Alexander", ""], ["Srinivasa", "Sunil", ""], ["Naik", "Nikhil", ""], ["Gruesbeck", "Melvin", ""], ["Parkes", "David C.", ""], ["Socher", "Richard", ""]]}, {"id": "2004.13335", "submitter": "Alam Zaib", "authors": "Alam Zaib, Tarig Ballal, Shahid Khattak and Tareq Y. Al-Naffouri", "title": "A Doubly Regularized Linear Discriminant Analysis Classifier with\n  Automatic Parameter Selection", "comments": "11 pages, 40 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear discriminant analysis (LDA) based classifiers tend to falter in many\npractical settings where the training data size is smaller than, or comparable\nto, the number of features. As a remedy, different regularized LDA (RLDA)\nmethods have been proposed. These methods may still perform poorly depending on\nthe size and quality of the available training data. In particular, the test\ndata deviation from the training data model, for example, due to noise\ncontamination, can cause severe performance degradation. Moreover, these\nmethods commit further to the Gaussian assumption (upon which LDA is\nestablished) to tune their regularization parameters, which may compromise\naccuracy when dealing with real data. To address these issues, we propose a\ndoubly regularized LDA classifier that we denote as R2LDA. In the proposed\nR2LDA approach, the RLDA score function is converted into an inner product of\ntwo vectors. By substituting the expressions of the regularized estimators of\nthese vectors, we obtain the R2LDA score function that involves two\nregularization parameters. To set the values of these parameters, we adopt\nthree existing regularization techniques; the constrained perturbation\nregularization approach (COPRA), the bounded perturbation regularization (BPR)\nalgorithm, and the generalized cross-validation (GCV) method. These methods are\nused to tune the regularization parameters based on linear estimation models,\nwith the sample covariance matrix's square root being the linear operator.\nResults obtained from both synthetic and real data demonstrate the consistency\nand effectiveness of the proposed R2LDA approach, especially in scenarios\ninvolving test data contaminated with noise that is not observed during the\ntraining phase.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:09:22 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 17:44:19 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zaib", "Alam", ""], ["Ballal", "Tarig", ""], ["Khattak", "Shahid", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "2004.13336", "submitter": "Yuanzhong Xu", "authors": "Yuanzhong Xu, HyoukJoong Lee, Dehao Chen, Hongjun Choi, Blake\n  Hechtman, Shibo Wang", "title": "Automatic Cross-Replica Sharding of Weight Update in Data-Parallel\n  Training", "comments": "12 pages, 23 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data-parallel synchronous training of deep neural networks, different\ndevices (replicas) run the same program with different partitions of the\ntraining batch, but weight update computation is repeated on all replicas,\nbecause the weights do not have a batch dimension to partition. This can be a\nbottleneck for performance and scalability in typical language models with\nlarge weights, and models with small per-replica batch size which is typical in\nlarge-scale training. This paper presents an approach to automatically shard\nthe weight update computation across replicas with efficient communication\nprimitives and data formatting, using static analysis and transformations on\nthe training computation graph. We show this technique achieves substantial\nspeedups on typical image and language models on Cloud TPUs, requiring no\nchange to model code. This technique helps close the gap between traditionally\nexpensive (ADAM) and cheap (SGD) optimizers, as they will only take a small\npart of training step time and have similar peak memory usage. It helped us to\nachieve state-of-the-art training performance in Google's MLPerf 0.6\nsubmission.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:13:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xu", "Yuanzhong", ""], ["Lee", "HyoukJoong", ""], ["Chen", "Dehao", ""], ["Choi", "Hongjun", ""], ["Hechtman", "Blake", ""], ["Wang", "Shibo", ""]]}, {"id": "2004.13344", "submitter": "Shufei Zhang Mr", "authors": "Shufei Zhang, Zhuang Qian, Kaizhu Huang, Jimin Xiao, Yuan He", "title": "Robust Generative Adversarial Network", "comments": "This paper has been submitted to ICLR in Sep 25. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are powerful generative models, but\nusually suffer from instability and generalization problem which may lead to\npoor generations. Most existing works focus on stabilizing the training of the\ndiscriminator while ignoring the generalization properties. In this work, we\naim to improve the generalization capability of GANs by promoting the local\nrobustness within the small neighborhood of the training samples. We also prove\nthat the robustness in small neighborhood of training sets can lead to better\ngeneralization. Particularly, we design a robust optimization framework where\nthe generator and discriminator compete with each other in a\n\\textit{worst-case} setting within a small Wasserstein ball. The generator\ntries to map \\textit{the worst input distribution} (rather than a Gaussian\ndistribution used in most GANs) to the real data distribution, while the\ndiscriminator attempts to distinguish the real and fake distribution\n\\textit{with the worst perturbation}. We have proved that our robust method can\nobtain a tighter generalization upper bound than traditional GANs under mild\nassumptions, ensuring a theoretical superiority of RGAN over GANs. A series of\nexperiments on CIFAR-10, STL-10 and CelebA datasets indicate that our proposed\nrobust framework can improve on five baseline GAN models substantially and\nconsistently.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:37:01 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhang", "Shufei", ""], ["Qian", "Zhuang", ""], ["Huang", "Kaizhu", ""], ["Xiao", "Jimin", ""], ["He", "Yuan", ""]]}, {"id": "2004.13361", "submitter": "Manuel Morante", "authors": "Manuel Morante", "title": "A lite parametric model for the Hemodynamic Response Function", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working with task-related fMRI data, one of the most crucial parts of\nthe data analysis consists of determining a proper estimate of the BOLD\nresponse. The following document presents a lite model for the Hemodynamic\nResponse Function HRF. Between other advances, the proposed model present less\nnumber of parameters compared to other similar HRF alternative, which reduces\nits optimization complexity and facilitates its potential applications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 08:29:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Morante", "Manuel", ""]]}, {"id": "2004.13384", "submitter": "Bogdan Boc\\c{s}e", "authors": "Bogdan Bocse and Ioan Radu Jinga", "title": "The Immersion of Directed Multi-graphs in Embedding Fields.\n  Generalisations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The purpose of this paper is to outline a generalised model for representing\nhybrids of relational-categorical, symbolic, perceptual-sensory and\nperceptual-latent data, so as to embody, in the same architectural data layer,\nrepresentations for the input, output and latent tensors. This variety of\nrepresentation is currently used by various machine-learning models in computer\nvision, NLP/NLU, reinforcement learning which allows for direct application of\ncross-domain queries and functions. This is achieved by endowing a directed\nTensor-Typed Multi-Graph with at least some edge attributes which represent the\nembeddings from various latent spaces, so as to define, construct and compute\nnew similarity and distance relationships between and across tensorial forms,\nincluding visual, linguistic, auditory latent representations, thus stitching\nthe logical-categorical view of the observed universe to the\nBayesian/statistical view.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 09:28:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bocse", "Bogdan", ""], ["Jinga", "Ioan Radu", ""]]}, {"id": "2004.13390", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, Sherrie Wang, Marco K\\\"orner, David Lobell", "title": "Meta-Learning for Few-Shot Land Cover Classification", "comments": "accepted to the CVPR 2020 EarthVision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The representations of the Earth's surface vary from one geographic region to\nanother. For instance, the appearance of urban areas differs between\ncontinents, and seasonality influences the appearance of vegetation. To capture\nthe diversity within a single category, like as urban or vegetation, requires a\nlarge model capacity and, consequently, large datasets. In this work, we\npropose a different perspective and view this diversity as an inductive\ntransfer learning problem where few data samples from one region allow a model\nto adapt to an unseen region. We evaluate the model-agnostic meta-learning\n(MAML) algorithm on classification and segmentation tasks using globally and\nregionally distributed datasets. We find that few-shot model adaptation\noutperforms pre-training with regular gradient descent and fine-tuning on (1)\nthe Sen12MS dataset and (2) DeepGlobe data when the source domain and target\ndomain differ. This indicates that model optimization with meta-learning may\nbenefit tasks in the Earth sciences whose data show a high degree of diversity\nfrom region to region, while traditional gradient-based supervised learning\nremains suitable in the absence of a feature or label shift.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 09:42:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["Wang", "Sherrie", ""], ["K\u00f6rner", "Marco", ""], ["Lobell", "David", ""]]}, {"id": "2004.13408", "submitter": "Bryan Lim", "authors": "Bryan Lim and Stefan Zohren", "title": "Time Series Forecasting With Deep Learning: A Survey", "comments": null, "journal-ref": "Philosophical Transactions of the Royal Society A 2020", "doi": "10.1098/rsta.2020.0209", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous deep learning architectures have been developed to accommodate the\ndiversity of time series datasets across different domains. In this article, we\nsurvey common encoder and decoder designs used in both one-step-ahead and\nmulti-horizon time series forecasting -- describing how temporal information is\nincorporated into predictions by each model. Next, we highlight recent\ndevelopments in hybrid deep learning models, which combine well-studied\nstatistical models with neural network components to improve pure methods in\neither category. Lastly, we outline some ways in which deep learning can also\nfacilitate decision support with time series data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 10:32:26 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 14:10:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""]]}, {"id": "2004.13414", "submitter": "Bhasker Sri Harsha Suri", "authors": "Bhasker Sri Harsha Suri, Kalidas Yeturu", "title": "Pseudo Rehearsal using non photo-realistic images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural networks forget previously learnt tasks when they are faced with\nlearning new tasks. This is called catastrophic forgetting. Rehearsing the\nneural network with the training data of the previous task can protect the\nnetwork from catastrophic forgetting. Since rehearsing requires the storage of\nentire previous data, Pseudo rehearsal was proposed, where samples belonging to\nthe previous data are generated synthetically for rehearsal. In an image\nclassification setting, while current techniques try to generate synthetic data\nthat is photo-realistic, we demonstrated that Neural networks can be rehearsed\non data that is not photo-realistic and still achieve good retention of the\nprevious task. We also demonstrated that forgoing the constraint of having\nphoto realism in the generated data can result in a significant reduction in\nthe consumption of computational and memory resources for pseudo rehearsal.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 10:44:57 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Suri", "Bhasker Sri Harsha", ""], ["Yeturu", "Kalidas", ""]]}, {"id": "2004.13465", "submitter": "Bo Xue", "authors": "Bo Xue, Guanghui Wang, Yimu Wang and Lijun Zhang", "title": "Nearly Optimal Regret for Stochastic Linear Bandits with Heavy-Tailed\n  Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of stochastic linear bandits with finite\naction sets. Most of existing work assume the payoffs are bounded or\nsub-Gaussian, which may be violated in some scenarios such as financial\nmarkets. To settle this issue, we analyze the linear bandits with heavy-tailed\npayoffs, where the payoffs admit finite $1+\\epsilon$ moments for some\n$\\epsilon\\in(0,1]$. Through median of means and dynamic truncation, we propose\ntwo novel algorithms which enjoy a sublinear regret bound of\n$\\widetilde{O}(d^{\\frac{1}{2}}T^{\\frac{1}{1+\\epsilon}})$, where $d$ is the\ndimension of contextual information and $T$ is the time horizon. Meanwhile, we\nprovide an $\\Omega(d^{\\frac{\\epsilon}{1+\\epsilon}}T^{\\frac{1}{1+\\epsilon}})$\nlower bound, which implies our upper bound matches the lower bound up to\npolylogarithmic factors in the order of $d$ and $T$ when $\\epsilon=1$. Finally,\nwe conduct numerical experiments to demonstrate the effectiveness of our\nalgorithms and the empirical results strongly support our theoretical\nguarantees.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:01:38 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Xue", "Bo", ""], ["Wang", "Guanghui", ""], ["Wang", "Yimu", ""], ["Zhang", "Lijun", ""]]}, {"id": "2004.13480", "submitter": "Zhong Meng", "authors": "Zhong Meng, Hu Hu, Jinyu Li, Changliang Liu, Yan Huang, Yifan Gong,\n  Chin-Hui Lee", "title": "L-Vector: Neural Label Embedding for Domain Adaptation", "comments": "5 pages, 2 figure, ICASSP 2020", "journal-ref": "2019 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural label embedding (NLE) scheme for the domain\nadaptation of a deep neural network (DNN) acoustic model with unpaired data\nsamples from source and target domains. With NLE method, we distill the\nknowledge from a powerful source-domain DNN into a dictionary of label\nembeddings, or l-vectors, one for each senone class. Each l-vector is a\nrepresentation of the senone-specific output distributions of the source-domain\nDNN and is learned to minimize the average L2, Kullback-Leibler (KL) or\nsymmetric KL distance to the output vectors with the same label through simple\naveraging or standard back-propagation. During adaptation, the l-vectors serve\nas the soft targets to train the target-domain model with cross-entropy loss.\nWithout parallel data constraint as in the teacher-student learning, NLE is\nspecially suited for the situation where the paired target-domain data cannot\nbe simulated from the source-domain data. We adapt a 6400 hours\nmulti-conditional US English acoustic model to each of the 9 accented English\n(80 to 830 hours) and kids' speech (80 hours). NLE achieves up to 14.1%\nrelative word error rate reduction over direct re-training with one-hot labels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 06:40:31 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Meng", "Zhong", ""], ["Hu", "Hu", ""], ["Li", "Jinyu", ""], ["Liu", "Changliang", ""], ["Huang", "Yan", ""], ["Gong", "Yifan", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2004.13489", "submitter": "Babacar Mbaye Ndiaye", "authors": "Babacar Mbaye Ndiaye, Lena Tendeng, Diaraf Seck", "title": "Comparative prediction of confirmed cases with COVID-19 pandemic by\n  machine learning, deterministic and stochastic SIR models", "comments": "arXiv admin note: text overlap with arXiv:2004.01574", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a machine learning technics and SIR models\n(deterministic and stochastic cases) with numerical approximations to predict\nthe number of cases infected with the COVID-19, for both in few days and the\nfollowing three weeks. Like in [1] and based on the public data from [2], we\nestimate parameters and make predictions to help on how to find concrete\nactions to control the situation. Under optimistic estimation, the pandemic in\nsome countries will end soon, while for most of the countries in the world, the\nhit of anti-pandemic will be no later than the beginning of May.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 22:54:10 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ndiaye", "Babacar Mbaye", ""], ["Tendeng", "Lena", ""], ["Seck", "Diaraf", ""]]}, {"id": "2004.13521", "submitter": "Sourav Sen", "authors": "Sourav Sen", "title": "Detect Language of Transliterated Texts", "comments": "10 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informal transliteration from other languages to English is prevalent in\nsocial media threads, instant messaging, and discussion forums. Without\nidentifying the language of such transliterated text, users who do not speak\nthat language cannot understand its content using translation tools. We propose\na Language Identification (LID) system, with an approach for feature\nextraction, which can detect the language of transliterated texts reasonably\nwell even with limited training data and computational resources. We tokenize\nthe words into phonetic syllables and use a simple Long Short-term Memory\n(LSTM) network architecture to detect the language of transliterated texts.\nWith intensive experiments, we show that the tokenization of transliterated\nwords as phonetic syllables effectively represents their causal sound patterns.\nPhonetic syllable tokenization, therefore, makes it easier for even simpler\nmodel architectures to learn the characteristic patterns to identify any\nlanguage.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 10:28:02 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Sen", "Sourav", ""]]}, {"id": "2004.13546", "submitter": "Fabian K\\\"uppers", "authors": "Fabian K\\\"uppers, Jan Kronenberger, Amirhossein Shantia, Anselm\n  Haselhoff", "title": "Multivariate Confidence Calibration for Object Detection", "comments": "Accepted on CVPR 2020 Workshop: \"2nd Workshop on Safe Artificial\n  Intelligence for Automated Driving (SAIAD)\"", "journal-ref": null, "doi": "10.1109/CVPRW50498.2020.00171", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unbiased confidence estimates of neural networks are crucial especially for\nsafety-critical applications. Many methods have been developed to calibrate\nbiased confidence estimates. Though there is a variety of methods for\nclassification, the field of object detection has not been addressed yet.\nTherefore, we present a novel framework to measure and calibrate biased (or\nmiscalibrated) confidence estimates of object detection methods. The main\ndifference to related work in the field of classifier calibration is that we\nalso use additional information of the regression output of an object detector\nfor calibration. Our approach allows, for the first time, to obtain calibrated\nconfidence estimates with respect to image location and box scale. In addition,\nwe propose a new measure to evaluate miscalibration of object detectors.\nFinally, we show that our developed methods outperform state-of-the-art\ncalibration models for the task of object detection and provides reliable\nconfidence estimates across different locations and scales.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 14:17:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["K\u00fcppers", "Fabian", ""], ["Kronenberger", "Jan", ""], ["Shantia", "Amirhossein", ""], ["Haselhoff", "Anselm", ""]]}, {"id": "2004.13550", "submitter": "Durgesh Samariya", "authors": "Durgesh Samariya, Sunil Aryal, Kai Ming Ting", "title": "A new effective and efficient measure for outlying aspect mining", "comments": "Co-authors are not agree with submission of paper on arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlying Aspect Mining (OAM) aims to find the subspaces (a.k.a. aspects) in\nwhich a given query is an outlier with respect to a given dataset. Existing OAM\nalgorithms use traditional distance/density-based outlier scores to rank\nsubspaces. Because these distance/density-based scores depend on the\ndimensionality of subspaces, they cannot be compared directly between subspaces\nof different dimensionality. $Z$-score normalisation has been used to make them\ncomparable. It requires to compute outlier scores of all instances in each\nsubspace. This adds significant computational overhead on top of already\nexpensive density estimation---making OAM algorithms infeasible to run in large\nand/or high-dimensional datasets. We also discover that $Z$-score normalisation\nis inappropriate for OAM in some cases. In this paper, we introduce a new score\ncalled SiNNE, which is independent of the dimensionality of subspaces. This\nenables the scores in subspaces with different dimensionalities to be compared\ndirectly without any additional normalisation. Our experimental results\nrevealed that SiNNE produces better or at least the same results as existing\nscores; and it significantly improves the runtime of an existing OAM algorithm\nbased on beam search.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 14:20:51 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 06:03:29 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 03:58:30 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Samariya", "Durgesh", ""], ["Aryal", "Sunil", ""], ["Ting", "Kai Ming", ""]]}, {"id": "2004.13557", "submitter": "Shunbo Lei", "authors": "Shunbo Lei, David Hong, Johanna L. Mathieu, Ian A. Hiskens", "title": "Baseline Estimation of Commercial Building HVAC Fan Power Using Tensor\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial building heating, ventilation, and air conditioning (HVAC) systems\nhave been studied for providing ancillary services to power grids via demand\nresponse (DR). One critical issue is to estimate the counterfactual baseline\npower consumption that would have prevailed without DR. Baseline methods have\nbeen developed based on whole building electric load profiles. New methods are\nnecessary to estimate the baseline power consumption of HVAC sub-components\n(e.g., supply and return fans), which have different characteristics compared\nto that of the whole building. Tensor completion can estimate the unobserved\nentries of multi-dimensional tensors describing complex data sets. It exploits\nhigh-dimensional data to capture granular insights into the problem. This paper\nproposes to use it for baselining HVAC fan power, by utilizing its capability\nof capturing dominant fan power patterns. The tensor completion method is\nevaluated using HVAC fan power data from several buildings at the University of\nMichigan, and compared with several existing methods. The tensor completion\nmethod generally outperforms the benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:03:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lei", "Shunbo", ""], ["Hong", "David", ""], ["Mathieu", "Johanna L.", ""], ["Hiskens", "Ian A.", ""]]}, {"id": "2004.13558", "submitter": "Atiyeh Fotoohinasab", "authors": "Atiyeh Fotoohinasab, Toby Hocking, and Fatemeh Afghah", "title": "A Graph-constrained Changepoint Detection Approach for ECG Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) signal is the most commonly used non-invasive tool in\nthe assessment of cardiovascular diseases. Segmentation of the ECG signal to\nlocate its constitutive waves, in particular the R-peaks, is a key step in ECG\nprocessing and analysis. Over the years, several segmentation and QRS complex\ndetection algorithms have been proposed with different features; however, their\nperformance highly depends on applying preprocessing steps which makes them\nunreliable in real-time data analysis of ambulatory care settings and remote\nmonitoring systems, where the collected data is highly noisy. Moreover, some\nissues still remain with the current algorithms in regard to the diverse\nmorphological categories for the ECG signal and their high computation cost. In\nthis paper, we introduce a novel graph-based optimal changepoint detection\n(GCCD) method for reliable detection of R-peak positions without employing any\npreprocessing step. The proposed model guarantees to compute the globally\noptimal changepoint detection solution. It is also generic in nature and can be\napplied to other time-series biomedical signals. Based on the MIT-BIH\narrhythmia (MIT-BIH-AR) database, the proposed method achieves overall\nsensitivity Sen = 99.76, positive predictivity PPR = 99.68, and detection error\nrate DER = 0.55 which are comparable to other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:41:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Fotoohinasab", "Atiyeh", ""], ["Hocking", "Toby", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "2004.13560", "submitter": "Haibin Chang", "authors": "Nanzhe Wang, Haibin Chang, Dongxiao Zhang", "title": "Efficient Uncertainty Quantification for Dynamic Subsurface Flow with\n  Surrogate by Theory-guided Neural Network", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113492", "report-no": null, "categories": "eess.SP cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsurface flow problems usually involve some degree of uncertainty.\nConsequently, uncertainty quantification is commonly necessary for subsurface\nflow prediction. In this work, we propose a methodology for efficient\nuncertainty quantification for dynamic subsurface flow with a surrogate\nconstructed by the Theory-guided Neural Network (TgNN). The TgNN here is\nspecially designed for problems with stochastic parameters. In the TgNN,\nstochastic parameters, time and location comprise the input of the neural\nnetwork, while the quantity of interest is the output. The neural network is\ntrained with available simulation data, while being simultaneously guided by\ntheory (e.g., the governing equation, boundary conditions, initial conditions,\netc.) of the underlying problem. The trained neural network can predict\nsolutions of subsurface flow problems with new stochastic parameters. With the\nTgNN surrogate, the Monte Carlo (MC) method can be efficiently implemented for\nuncertainty quantification. The proposed methodology is evaluated with\ntwo-dimensional dynamic saturated flow problems in porous medium. Numerical\nresults show that the TgNN based surrogate can significantly improve the\nefficiency of uncertainty quantification tasks compared with simulation based\nimplementation. Further investigations regarding stochastic fields with smaller\ncorrelation length, larger variance, changing boundary values and\nout-of-distribution variances are performed, and satisfactory results are\nobtained.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 12:41:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Nanzhe", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2004.13562", "submitter": "Yuntian Chen", "authors": "Yuntian Chen and Dongxiao Zhang", "title": "Ensemble long short-term memory (EnLSTM) network", "comments": "18 pages, 3 figures, including Supporting Information", "journal-ref": "Geophysical Research Letters, 2020", "doi": "10.1029/2020GL087685", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose an ensemble long short-term memory (EnLSTM)\nnetwork, which can be trained on a small dataset and process sequential data.\nThe EnLSTM is built by combining the ensemble neural network (ENN) and the\ncascaded long short-term memory (C-LSTM) network to leverage their\ncomplementary strengths. In order to resolve the issues of over-convergence and\ndisturbance compensation associated with training failure owing to the nature\nof small-data problems, model parameter perturbation and high-fidelity\nobservation perturbation methods are introduced. The EnLSTM is compared with\ncommonly-used models on a published dataset, and proven to be the\nstate-of-the-art model in generating well logs with a mean-square-error (MSE)\nreduction of 34%. In the case study, 12 well logs that cannot be measured while\ndrilling are generated based on logging-while-drilling (LWD) data. The EnLSTM\nis capable to reduce cost and save time in practice.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 05:42:18 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 02:17:49 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chen", "Yuntian", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2004.13576", "submitter": "Giuseppe Di Benedetto", "authors": "Giuseppe Di Benedetto, Vito Bellini, Giovanni Zappella", "title": "A Linear Bandit for Seasonal Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are extremely popular and widely used in\nrecommendation systems to provide online personalised recommendations. A\nrecurrent assumption is the stationarity of the reward function, which is\nrather unrealistic in most of the real-world applications. In the music\nrecommendation scenario for instance, people's music taste can abruptly change\nduring certain events, such as Halloween or Christmas, and revert to the\nprevious music taste soon after.\n  We would therefore need an algorithm which can promptly react to these\nchanges. Moreover, we would like to leverage already observed rewards collected\nduring different stationary periods which can potentially reoccur, without the\nneed of restarting the learning process from scratch. A growing literature has\naddressed the problem of reward's non-stationarity, providing algorithms that\ncould quickly adapt to the changing environment. However, up to our knowledge,\nthere is no algorithm which deals with seasonal changes of the reward function.\nHere we present a contextual bandit algorithm which detects and adapts to\nabrupt changes of the reward function and leverages previous estimations\nwhenever the environment falls back to a previously observed state. We show\nthat the proposed method can outperform state-of-the-art algorithms for\nnon-stationary environments. We ran our experiment on both synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:03:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Di Benedetto", "Giuseppe", ""], ["Bellini", "Vito", ""], ["Zappella", "Giovanni", ""]]}, {"id": "2004.13587", "submitter": "Zhongchao Qian", "authors": "Zhongchao Qian, Tyler L. Hayes, Kushal Kafle, Christopher Kanan", "title": "Do We Need Fully Connected Output Layers in Convolutional Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, deep convolutional neural networks consist of a series of\nconvolutional and pooling layers followed by one or more fully connected (FC)\nlayers to perform the final classification. While this design has been\nsuccessful, for datasets with a large number of categories, the fully connected\nlayers often account for a large percentage of the network's parameters. For\napplications with memory constraints, such as mobile devices and embedded\nplatforms, this is not ideal. Recently, a family of architectures that involve\nreplacing the learned fully connected output layer with a fixed layer has been\nproposed as a way to achieve better efficiency. In this paper we examine this\nidea further and demonstrate that fixed classifiers offer no additional benefit\ncompared to simply removing the output layer along with its parameters. We\nfurther demonstrate that the typical approach of having a fully connected final\noutput layer is inefficient in terms of parameter count. We are able to achieve\ncomparable performance to a traditionally learned fully connected\nclassification output layer on the ImageNet-1K, CIFAR-100, Stanford Cars-196,\nand Oxford Flowers-102 datasets, while not having a fully connected output\nlayer at all.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:21:44 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 03:20:47 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Qian", "Zhongchao", ""], ["Hayes", "Tyler L.", ""], ["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "2004.13598", "submitter": "Amit Chaulwar", "authors": "Amit Chaulwar", "title": "Private Dataset Generation Using Privacy Preserving Collaborative\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With increasing usage of deep learning algorithms in many application, new\nresearch questions related to privacy and adversarial attacks are emerging.\nHowever, the deep learning algorithm improvement needs more and more data to be\nshared within research community. Methodologies like federated learning,\ndifferential privacy, additive secret sharing provides a way to train machine\nlearning models on edge without moving the data from the edge. However, it is\nvery computationally intensive and prone to adversarial attacks. Therefore,\nthis work introduces a privacy preserving FedCollabNN framework for training\nmachine learning models at edge, which is computationally efficient and robust\nagainst adversarial attacks. The simulation results using MNIST dataset\nindicates the effectiveness of the framework.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:35:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Chaulwar", "Amit", ""]]}, {"id": "2004.13611", "submitter": "Rachel Marceau West", "authors": "Devan V. Mehrotra and Rachel Marceau West", "title": "Survival Analysis Using a 5-Step Stratified Testing and Amalgamation\n  Routine in Randomized Clinical Trials", "comments": "40 pages; 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized clinical trials are often designed to assess whether a test\ntreatment prolongs survival relative to a control treatment. Increased patient\nheterogeneity, while desirable for generalizability of results, can weaken the\nability of common statistical approaches to detect treatment differences,\npotentially hampering the regulatory approval of safe and efficacious\ntherapies. A novel solution to this problem is proposed. A list of baseline\ncovariates that have the potential to be prognostic for survival under either\ntreatment is pre-specified in the analysis plan. At the analysis stage, using\nall observed survival times but blinded to patient-level treatment assignment,\n'noise' covariates are removed with elastic net Cox regression. The shortened\ncovariate list is used by a conditional inference tree algorithm to segment the\nheterogeneous trial population into subpopulations of prognostically\nhomogeneous patients (risk strata). After patient-level treatment unblinding, a\ntreatment comparison is done within each formed risk stratum and stratum-level\nresults are combined for overall statistical inference. The impressive\npower-boosting performance of our proposed 5-step stratified testing and\namalgamation routine (5-STAR), relative to that of the logrank test and other\ncommon approaches that do not leverage inherently structured patient\nheterogeneity, is illustrated using a hypothetical and two real datasets along\nwith simulation results. Furthermore, the importance of reporting stratum-level\ncomparative treatment effects (time ratios from accelerated failure time model\nfits in conjunction with model averaging and, as needed, hazard ratios from Cox\nproportional hazard model fits) is highlighted as a potential enabler of\npersonalized medicine. A fiveSTAR R package is available at\nhttps://github.com/rmarceauwest/fiveSTAR.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:44:41 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Mehrotra", "Devan V.", ""], ["West", "Rachel Marceau", ""]]}, {"id": "2004.13612", "submitter": "Calypso Herrera", "authors": "Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,\n  Josef Teichmann", "title": "Denise: Deep Robust Principal Component Analysis for Positive\n  Semidefinite Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust PCA of covariance matrices plays an essential role when isolating\nkey explanatory features. The currently available methods for performing such a\nlow-rank plus sparse decomposition are matrix specific, meaning, those\nalgorithms must re-run for every new matrix. Since these algorithms are\ncomputationally expensive, it is preferable to learn and store a function that\ninstantaneously performs this decomposition when evaluated. Therefore, we\nintroduce Denise, a deep learning-based algorithm for robust PCA of covariance\nmatrices, or more generally of symmetric positive semidefinite matrices, which\nlearns precisely such a function. Theoretical guarantees for Denise are\nprovided. These include a novel universal approximation theorem adapted to our\ngeometric deep learning problem, convergence to an optimal solution of the\nlearning problem and convergence of the training scheme. Our experiments show\nthat Denise matches state-of-the-art performance in terms of decomposition\nquality, while being approximately 2000x faster than the state-of-the-art, PCP,\nand 200x faster than the current speed optimized method, fast PCP.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:45:21 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 18:26:24 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 13:35:22 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Herrera", "Calypso", ""], ["Krach", "Florian", ""], ["Kratsios", "Anastasis", ""], ["Ruyssen", "Pierre", ""], ["Teichmann", "Josef", ""]]}, {"id": "2004.13617", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Natalie Frank, Mehryar Mohri", "title": "Adversarial Learning Guarantees for Linear Hypotheses and Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial or test time robustness measures the susceptibility of a\nclassifier to perturbations to the test input. While there has been a flurry of\nrecent work on designing defenses against such perturbations, the theory of\nadversarial robustness is not well understood. In order to make progress on\nthis, we focus on the problem of understanding generalization in adversarial\nsettings, via the lens of Rademacher complexity. We give upper and lower bounds\nfor the adversarial empirical Rademacher complexity of linear hypotheses with\nadversarial perturbations measured in $l_r$-norm for an arbitrary $r \\geq 1$.\nThis generalizes the recent result of [Yin et al.'19] that studies the case of\n$r = \\infty$, and provides a finer analysis of the dependence on the input\ndimensionality as compared to the recent work of [Khim and Loh'19] on linear\nhypothesis classes.\n  We then extend our analysis to provide Rademacher complexity lower and upper\nbounds for a single ReLU unit. Finally, we give adversarial Rademacher\ncomplexity bounds for feed-forward neural networks with one hidden layer.\nUnlike previous works we directly provide bounds on the adversarial Rademacher\ncomplexity of the given network, as opposed to a bound on a surrogate. A\nby-product of our analysis also leads to tighter bounds for the Rademacher\ncomplexity of linear hypotheses, for which we give a detailed analysis and\npresent a comparison with existing bounds.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:55:16 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Frank", "Natalie", ""], ["Mohri", "Mehryar", ""]]}, {"id": "2004.13649", "submitter": "Rob Fergus", "authors": "Ilya Kostrikov, Denis Yarats, Rob Fergus", "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement\n  Learning from Pixels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple data augmentation technique that can be applied to\nstandard model-free reinforcement learning algorithms, enabling robust learning\ndirectly from pixels without the need for auxiliary losses or pre-training. The\napproach leverages input perturbations commonly used in computer vision tasks\nto regularize the value function. Existing model-free approaches, such as Soft\nActor-Critic (SAC), are not able to train deep networks effectively from image\npixels. However, the addition of our augmentation method dramatically improves\nSAC's performance, enabling it to reach state-of-the-art performance on the\nDeepMind control suite, surpassing model-based (Dreamer, PlaNet, and SLAC)\nmethods and recently proposed contrastive learning (CURL). Our approach can be\ncombined with any model-free reinforcement learning algorithm, requiring only\nminor modifications. An implementation can be found at\nhttps://sites.google.com/view/data-regularized-q.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:48:16 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:51:10 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 13:47:47 GMT"}, {"version": "v4", "created": "Sun, 7 Mar 2021 16:37:37 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kostrikov", "Ilya", ""], ["Yarats", "Denis", ""], ["Fergus", "Rob", ""]]}, {"id": "2004.13657", "submitter": "Katya Kudashkina", "authors": "Katya Kudashkina, Valliappa Chockalingam, Graham W. Taylor, Michael\n  Bowling", "title": "Sample-Efficient Model-based Actor-Critic for an Interactive Dialogue\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-computer interactive systems that rely on machine learning are becoming\nparamount to the lives of millions of people who use digital assistants on a\ndaily basis. Yet, further advances are limited by the availability of data and\nthe cost of acquiring new samples. One way to address this problem is by\nimproving the sample efficiency of current approaches. As a solution path, we\npresent a model-based reinforcement learning algorithm for an interactive\ndialogue task. We build on commonly used actor-critic methods, adding an\nenvironment model and planner that augments a learning agent to learn the model\nof the environment dynamics. Our results show that, on a simulation that mimics\nthe interactive task, our algorithm requires 70 times fewer samples, compared\nto the baseline of commonly used model-free algorithm, and demonstrates 2~times\nbetter performance asymptotically. Moreover, we introduce a novel contribution\nof computing a soft planner policy and further updating a model-free policy\nyielding a less computationally expensive model-free agent as good as the\nmodel-based one. This model-based architecture serves as a foundation that can\nbe extended to other human-computer interactive tasks allowing further advances\nin this direction.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:00:59 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Kudashkina", "Katya", ""], ["Chockalingam", "Valliappa", ""], ["Taylor", "Graham W.", ""], ["Bowling", "Michael", ""]]}, {"id": "2004.13664", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Toru Lin, Kexin Yi, Daniel M. Bear, Daniel L. K. Yamins,\n  Jiajun Wu, Joshua B. Tenenbaum, Antonio Torralba", "title": "Visual Grounding of Learned Physical Models", "comments": "The second and the third authors contributed equally to this paper,\n  and are listed in alphabetical order. Project Page:\n  http://visual-physics-grounding.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans intuitively recognize objects' physical properties and predict their\nmotion, even when the objects are engaged in complicated interactions. The\nabilities to perform physical reasoning and to adapt to new environments, while\nintrinsic to humans, remain challenging to state-of-the-art computational\nmodels. In this work, we present a neural model that simultaneously reasons\nabout physics and makes future predictions based on visual and dynamics priors.\nThe visual prior predicts a particle-based representation of the system from\nvisual observations. An inference module operates on those particles,\npredicting and refining estimates of particle locations, object states, and\nphysical parameters, subject to the constraints imposed by the dynamics prior,\nwhich we refer to as visual grounding. We demonstrate the effectiveness of our\nmethod in environments involving rigid objects, deformable materials, and\nfluids. Experiments show that our model can infer the physical properties\nwithin a few observations, which allows the model to quickly adapt to unseen\nscenarios and make accurate predictions into the future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:06:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:13:21 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Li", "Yunzhu", ""], ["Lin", "Toru", ""], ["Yi", "Kexin", ""], ["Bear", "Daniel M.", ""], ["Yamins", "Daniel L. K.", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""]]}, {"id": "2004.13667", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata", "title": "Bayesian inference of infected patients in group testing with prevalence\n  estimation", "comments": null, "journal-ref": null, "doi": "10.7566/JPSJ.89.084001", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group testing is a method of identifying infected patients by performing\ntests on a pool of specimens collected from patients. For the case in which the\ntest returns a false result with finite probability, we propose Bayesian\ninference and a corresponding belief propagation (BP) algorithm to identify the\ninfected patients from the results of tests performed on the pool. We show that\nthe true-positive rate is improved by taking into account the credible interval\nof a point estimate of each patient. Further, the prevalence and the error\nprobability in the test are estimated by combining an expectation-maximization\nmethod with the BP algorithm. As another approach, we introduce a hierarchical\nBayes model to identify the infected patients and estimate the prevalence. By\ncomparing these methods, we formulate a guide for practical usage.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:11:43 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 02:28:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sakata", "Ayaka", ""]]}, {"id": "2004.13688", "submitter": "Shaan Desai", "authors": "Shaan Desai, Marios Mattheakis and Stephen Roberts", "title": "Variational Integrator Graph Networks for Learning Energy Conserving\n  Dynamical Systems", "comments": "updated version that includes an extensive ablation across\n  graph,non-graph methods as well as different integrators [under review]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances show that neural networks embedded with physics-informed\npriors significantly outperform vanilla neural networks in learning and\npredicting the long term dynamics of complex physical systems from noisy data.\nDespite this success, there has only been a limited study on how to optimally\ncombine physics priors to improve predictive performance. To tackle this\nproblem we unpack and generalize recent innovations into individual inductive\nbias segments. As such, we are able to systematically investigate all possible\ncombinations of inductive biases of which existing methods are a natural\nsubset. Using this framework we introduce Variational Integrator Graph Networks\n- a novel method that unifies the strengths of existing approaches by combining\nan energy constraint, high-order symplectic variational integrators, and graph\nneural networks. We demonstrate, across an extensive ablation, that the\nproposed unifying framework outperforms existing methods, for data-efficient\nlearning and in predictive accuracy, across both single and many-body problems\nstudied in recent literature. We empirically show that the improvements arise\nbecause high order variational integrators combined with a potential energy\nconstraint induce coupled learning of generalized position and momentum updates\nwhich can be formalized via the Partitioned Runge-Kutta method.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:42:47 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 16:06:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Desai", "Shaan", ""], ["Mattheakis", "Marios", ""], ["Roberts", "Stephen", ""]]}, {"id": "2004.13701", "submitter": "Nils Strodthoff", "authors": "Nils Strodthoff, Patrick Wagner, Tobias Schaeffter, Wojciech Samek", "title": "Deep Learning for ECG Analysis: Benchmarks and Insights from PTB-XL", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiography is a very common, non-invasive diagnostic procedure and\nits interpretation is increasingly supported by automatic interpretation\nalgorithms. The progress in the field of automatic ECG interpretation has up to\nnow been hampered by a lack of appropriate datasets for training as well as a\nlack of well-defined evaluation procedures to ensure comparability of different\nalgorithms. To alleviate these issues, we put forward first benchmarking\nresults for the recently published, freely accessible PTB-XL dataset, covering\na variety of tasks from different ECG statement prediction tasks over age and\ngender prediction to signal quality assessment. We find that convolutional\nneural networks, in particular resnet- and inception-based architectures, show\nthe strongest performance across all tasks outperforming feature-based\nalgorithms by a large margin. These results are complemented by deeper insights\ninto the classification algorithm in terms of hidden stratification, model\nuncertainty and an exploratory interpretability analysis. We also put forward\nbenchmarking results for the ICBEB2018 challenge ECG dataset and discuss\nprospects of transfer learning using classifiers pretrained on PTB-XL. With\nthis resource, we aim to establish the PTB-XL dataset as a resource for\nstructured benchmarking of ECG analysis algorithms and encourage other\nresearchers in the field to join these efforts.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:55:17 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Strodthoff", "Nils", ""], ["Wagner", "Patrick", ""], ["Schaeffter", "Tobias", ""], ["Samek", "Wojciech", ""]]}, {"id": "2004.13714", "submitter": "Divyam Aggarwal", "authors": "Divyam Aggarwal, Yash Kumar Singh, Dhish Kumar Saxena", "title": "On Learning Combinatorial Patterns to Assist Large-Scale Airline Crew\n  Pairing Optimization", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Airline Crew Pairing Optimization (CPO) aims at generating a set of legal\nflight sequences (crew pairings), to cover an airline's flight schedule, at\nminimum cost. It is usually performed using Column Generation (CG), a\nmathematical programming technique for guided search-space exploration. CG\nexploits the interdependencies between the current and the preceding\nCG-iteration for generating new variables (pairings) during the\noptimization-search. However, with the unprecedented scale and complexity of\nthe emergent flight networks, it has become imperative to learn higher-order\ninterdependencies among the flight-connection graphs, and utilize those to\nenhance the efficacy of the CPO. In first of its kind and what marks a\nsignificant departure from the state-of-the-art, this paper proposes a novel\nadaptation of the Variational Graph Auto-Encoder for learning plausible\ncombinatorial patterns among the flight-connection data obtained through the\nsearch-space exploration by an Airline Crew Pairing Optimizer, AirCROP\n(developed by the authors and validated by the research consortium's industrial\nsponsor, GE Aviation). The resulting flight-connection predictions are combined\non-the-fly using a novel heuristic to generate new pairings for the optimizer.\nThe utility of the proposed approach is demonstrated on large-scale (over 4200\nflights), real-world, complex flight-networks of US-based airlines,\ncharacterized by multiple hub-and-spoke subnetworks and several crew bases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:16:22 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 07:57:27 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 11:46:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Aggarwal", "Divyam", ""], ["Singh", "Yash Kumar", ""], ["Saxena", "Dhish Kumar", ""]]}, {"id": "2004.13715", "submitter": "Luca Belli", "authors": "Luca Belli, Sofia Ira Ktena, Alykhan Tejani, Alexandre Lung-Yut-Fon,\n  Frank Portman, Xiao Zhu, Yuanpu Xie, Akshay Gupta, Michael Bronstein, Amra\n  Deli\\'c, Gabriele Sottocornola, Walter Anelli, Nazareno Andrade, Jessie\n  Smith, Wenzhe Shi", "title": "Privacy-Aware Recommender Systems Challenge on Twitter's Home Timeline", "comments": "16 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems constitute the core engine of most social network\nplatforms nowadays, aiming to maximize user satisfaction along with other key\nbusiness objectives. Twitter is no exception. Despite the fact that Twitter\ndata has been extensively used to understand socioeconomic and political\nphenomena and user behaviour, the implicit feedback provided by users on Tweets\nthrough their engagements on the Home Timeline has only been explored to a\nlimited extent. At the same time, there is a lack of large-scale public social\nnetwork datasets that would enable the scientific community to both benchmark\nand build more powerful and comprehensive models that tailor content to user\ninterests. By releasing an original dataset of 160 million Tweets along with\nengagement information, Twitter aims to address exactly that. During this\nrelease, special attention is drawn on maintaining compliance with existing\nprivacy laws. Apart from user privacy, this paper touches on the key challenges\nfaced by researchers and professionals striving to predict user engagements. It\nfurther describes the key aspects of the RecSys 2020 Challenge that was\norganized by ACM RecSys in partnership with Twitter using this dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 23:54:33 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 13:26:49 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 13:25:23 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Belli", "Luca", ""], ["Ktena", "Sofia Ira", ""], ["Tejani", "Alykhan", ""], ["Lung-Yut-Fon", "Alexandre", ""], ["Portman", "Frank", ""], ["Zhu", "Xiao", ""], ["Xie", "Yuanpu", ""], ["Gupta", "Akshay", ""], ["Bronstein", "Michael", ""], ["Deli\u0107", "Amra", ""], ["Sottocornola", "Gabriele", ""], ["Anelli", "Walter", ""], ["Andrade", "Nazareno", ""], ["Smith", "Jessie", ""], ["Shi", "Wenzhe", ""]]}, {"id": "2004.13747", "submitter": "Timo Felser", "authors": "Timo Felser, Marco Trenti, Lorenzo Sestini, Alessio Gianelle, Davide\n  Zuliani, Donatella Lucchesi and Simone Montangero", "title": "Quantum-inspired Machine Learning on high-energy physics data", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG hep-ex physics.data-an quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor Networks, a numerical tool originally designed for simulating quantum\nmany-body systems, have recently been applied to solve Machine Learning\nproblems. Exploiting a tree tensor network, we apply a quantum-inspired machine\nlearning technique to a very important and challenging big data problem in high\nenergy physics: the analysis and classification of data produced by the Large\nHadron Collider at CERN. In particular, we present how to effectively classify\nso-called b-jets, jets originating from b-quarks from proton-proton collisions\nin the LHCb experiment, and how to interpret the classification results. We\nexploit the Tensor Network approach to select important features and adapt the\nnetwork geometry based on information acquired in the learning process.\nFinally, we show how to adapt the tree tensor network to achieve optimal\nprecision or fast response in time without the need of repeating the learning\nprocess. These results pave the way to the implementation of high-frequency\nreal-time applications, a key ingredient needed among others for current and\nfuture LHCb event classification able to trigger events at the tens of MHz\nscale.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 18:00:12 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 08:36:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Felser", "Timo", ""], ["Trenti", "Marco", ""], ["Sestini", "Lorenzo", ""], ["Gianelle", "Alessio", ""], ["Zuliani", "Davide", ""], ["Lucchesi", "Donatella", ""], ["Montangero", "Simone", ""]]}, {"id": "2004.13748", "submitter": "Sitan Chen", "authors": "Sitan Chen, Raghu Meka", "title": "Learning Polynomials of Few Relevant Dimensions", "comments": "64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial regression is a basic primitive in learning and statistics. In its\nmost basic form the goal is to fit a degree $d$ polynomial to a response\nvariable $y$ in terms of an $n$-dimensional input vector $x$. This is extremely\nwell-studied with many applications and has sample and runtime complexity\n$\\Theta(n^d)$. Can one achieve better runtime if the intrinsic dimension of the\ndata is much smaller than the ambient dimension $n$? Concretely, we are given\nsamples $(x,y)$ where $y$ is a degree at most $d$ polynomial in an unknown\n$r$-dimensional projection (the relevant dimensions) of $x$. This can be seen\nboth as a generalization of phase retrieval and as a special case of learning\nmulti-index models where the link function is an unknown low-degree polynomial.\nNote that without distributional assumptions, this is at least as hard as junta\nlearning.\n  In this work we consider the important case where the covariates are\nGaussian. We give an algorithm that learns the polynomial within accuracy\n$\\epsilon$ with sample complexity that is roughly $N = O_{r,d}(n\n\\log^2(1/\\epsilon) (\\log n)^d)$ and runtime $O_{r,d}(N n^2)$. Prior to our\nwork, no such results were known even for the case of $r=1$. We introduce a new\nfiltered PCA approach to get a warm start for the true subspace and use\ngeodesic SGD to boost to arbitrary accuracy; our techniques may be of\nindependent interest, especially for problems dealing with subspace recovery or\nanalyzing SGD on manifolds.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 18:00:18 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Chen", "Sitan", ""], ["Meka", "Raghu", ""]]}, {"id": "2004.13770", "submitter": "Michela Paganini", "authors": "Michela Paganini and Jessica Forde", "title": "Streamlining Tensor and Network Pruning in PyTorch", "comments": "5 pages, 1 figure, 5 code listings. Published as a workshop paper at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to contrast the explosion in size of state-of-the-art machine\nlearning models that can be attributed to the empirical advantages of\nover-parametrization, and due to the necessity of deploying fast, sustainable,\nand private on-device models on resource-constrained devices, the community has\nfocused on techniques such as pruning, quantization, and distillation as\ncentral strategies for model compression. Towards the goal of facilitating the\nadoption of a common interface for neural network pruning in PyTorch, this\ncontribution describes the recent addition of the PyTorch torch.nn.utils.prune\nmodule, which provides shared, open source pruning functionalities to lower the\ntechnical implementation barrier to reducing model size and capacity before,\nduring, and/or after training. We present the module's user interface,\nelucidate implementation details, illustrate example usage, and suggest ways to\nextend the contributed functionalities to new pruning methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 18:39:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Paganini", "Michela", ""], ["Forde", "Jessica", ""]]}, {"id": "2004.13781", "submitter": "Shu Cheng Li", "authors": "Shucheng Li, Lingfei Wu, Shiwei Feng, Fangli Xu, Fengyuan Xu and Sheng\n  Zhong", "title": "Graph-to-Tree Neural Networks for Learning Structured Input-Output\n  Translation with Applications to Semantic Parsing and Math Word Problem", "comments": "Long Paper in EMNLP 2020. 12 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Seq2Seq technique and its numerous variants achieve excellent\nperformance on many tasks such as neural machine translation, semantic parsing,\nand math word problem solving. However, these models either only consider input\nobjects as sequences while ignoring the important structural information for\nencoding, or they simply treat output objects as sequence outputs instead of\nstructural objects for decoding. In this paper, we present a novel\nGraph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder\nand a hierarchical tree decoder, that encodes an augmented graph-structured\ninput and decodes a tree-structured output. In particular, we investigated our\nmodel for solving two problems, neural semantic parsing and math word problem.\nOur extensive experiments demonstrate that our Graph2Tree model outperforms or\nmatches the performance of other state-of-the-art models on these tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:36:38 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:07:57 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Li", "Shucheng", ""], ["Wu", "Lingfei", ""], ["Feng", "Shiwei", ""], ["Xu", "Fangli", ""], ["Xu", "Fengyuan", ""], ["Zhong", "Sheng", ""]]}, {"id": "2004.13799", "submitter": "Michael McCoyd", "authors": "Michael McCoyd, Won Park, Steven Chen, Neil Shah, Ryan Roggenkemper,\n  Minjune Hwang, Jason Xinyu Liu and David Wagner", "title": "Minority Reports Defense: Defending Against Adversarial Patches", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning image classification is vulnerable to adversarial attack, even\nif the attacker changes just a small patch of the image. We propose a defense\nagainst patch attacks based on partially occluding the image around each\ncandidate patch location, so that a few occlusions each completely hide the\npatch. We demonstrate on CIFAR-10, Fashion MNIST, and MNIST that our defense\nprovides certified security against patch attacks of a certain size.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:11:18 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["McCoyd", "Michael", ""], ["Park", "Won", ""], ["Chen", "Steven", ""], ["Shah", "Neil", ""], ["Roggenkemper", "Ryan", ""], ["Hwang", "Minjune", ""], ["Liu", "Jason Xinyu", ""], ["Wagner", "David", ""]]}, {"id": "2004.13809", "submitter": "Aneta Polewko-Klim", "authors": "Aneta Polewko-Klim, Witold R. Rudnicki", "title": "Analysis of ensemble feature selection for correlated high-dimensional\n  RNA-Seq cancer data", "comments": "14 pages, 1 table, 29 figure, submitted to International Conference\n  on Computational Science, Amsterdam 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of diagnostic and prognostic molecular markers is important and\nactively pursued the research field in cancer research. For complex diseases,\nthis process is often performed using Machine Learning. The current study\ncompares two approaches for the discovery of relevant variables: by application\nof a single feature selection algorithm, versus by an ensemble of diverse\nalgorithms. These approaches are used to identify variables that are relevant\ndiscerning of four cancer types using RNA-seq profiles from the Cancer Genome\nAtlas. The comparison is carried out in two directions: evaluating the\npredictive performance of models and monitoring the stability of selected\nvariables. The most informative features are identified using a four feature\nselection algorithms, namely U-test, ReliefF, and two variants of the MDFS\nalgorithm. Discerning normal and tumor tissues is performed using the Random\nForest algorithm. The highest stability of the feature set was obtained when\nU-test was used. Unfortunately, models built on feature sets obtained from the\nensemble of feature selection algorithms were no better than for models\ndeveloped on feature sets obtained from individual algorithms. On the other\nhand, the feature selectors leading to the best classification results varied\nbetween data sets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:38:53 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Polewko-Klim", "Aneta", ""], ["Rudnicki", "Witold R.", ""]]}, {"id": "2004.13818", "submitter": "Long Xuan Ma", "authors": "Longxuan Ma and Wei-Nan Zhang and Mingda Li and Ting Liu", "title": "A Survey of Document Grounded Dialogue Systems (DGDS)", "comments": "30 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue system (DS) attracts great attention from industry and academia\nbecause of its wide application prospects. Researchers usually divide the DS\naccording to the function. However, many conversations require the DS to switch\nbetween different functions. For example, movie discussion can change from\nchit-chat to QA, the conversational recommendation can transform from chit-chat\nto recommendation, etc. Therefore, classification according to functions may\nnot be enough to help us appreciate the current development trend. We classify\nthe DS based on background knowledge. Specifically, study the latest DS based\non the unstructured document(s). We define Document Grounded Dialogue System\n(DGDS) as the DS that the dialogues are centering on the given document(s). The\nDGDS can be used in scenarios such as talking over merchandise against product\nManual, commenting on news reports, etc. We believe that extracting\nunstructured document(s) information is the future trend of the DS because a\ngreat amount of human knowledge lies in these document(s). The research of the\nDGDS not only possesses a broad application prospect but also facilitates AI to\nbetter understand human knowledge and natural language. We analyze the\nclassification, architecture, datasets, models, and future development trends\nof the DGDS, hoping to help researchers in this field.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:22:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ma", "Longxuan", ""], ["Zhang", "Wei-Nan", ""], ["Li", "Mingda", ""], ["Liu", "Ting", ""]]}, {"id": "2004.13824", "submitter": "Yiqun Mei", "authors": "Yiqun Mei, Yuchen Fan, Yulun Zhang, Jiahui Yu, Yuqian Zhou, Ding Liu,\n  Yun Fu, Thomas S. Huang and Humphrey Shi", "title": "Pyramid Attention Networks for Image Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-similarity refers to the image prior widely used in image restoration\nalgorithms that small but similar patterns tend to occur at different locations\nand scales. However, recent advanced deep convolutional neural network based\nmethods for image restoration do not take full advantage of self-similarities\nby relying on self-attention neural modules that only process information at\nthe same scale. To solve this problem, we present a novel Pyramid Attention\nmodule for image restoration, which captures long-range feature correspondences\nfrom a multi-scale feature pyramid. Inspired by the fact that corruptions, such\nas noise or compression artifacts, drop drastically at coarser image scales,\nour attention module is designed to be able to borrow clean signals from their\n\"clean\" correspondences at the coarser levels. The proposed pyramid attention\nmodule is a generic building block that can be flexibly integrated into various\nneural architectures. Its effectiveness is validated through extensive\nexperiments on multiple image restoration tasks: image denoising, demosaicing,\ncompression artifact reduction, and super resolution. Without any bells and\nwhistles, our PANet (pyramid attention module with simple network backbones)\ncan produce state-of-the-art results with superior accuracy and visual quality.\nOur code will be available at\nhttps://github.com/SHI-Labs/Pyramid-Attention-Networks\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 21:12:36 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 00:58:54 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:11:21 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 18:47:11 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Mei", "Yiqun", ""], ["Fan", "Yuchen", ""], ["Zhang", "Yulun", ""], ["Yu", "Jiahui", ""], ["Zhou", "Yuqian", ""], ["Liu", "Ding", ""], ["Fu", "Yun", ""], ["Huang", "Thomas S.", ""], ["Shi", "Humphrey", ""]]}, {"id": "2004.13828", "submitter": "Prabhakar Gupta", "authors": "Prabhakar Gupta and Anil Nelakanti", "title": "DeepSubQE: Quality estimation for subtitle translations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Quality estimation (QE) for tasks involving language data is hard owing to\nnumerous aspects of natural language like variations in paraphrasing, style,\ngrammar, etc. There can be multiple answers with varying levels of\nacceptability depending on the application at hand. In this work, we look at\nestimating quality of translations for video subtitles. We show how existing QE\nmethods are inadequate and propose our method DeepSubQE as a system to estimate\nquality of translation given subtitles data for a pair of languages. We rely on\nvarious data augmentation strategies for automated labelling and synthesis for\ntraining. We create a hybrid network which learns semantic and syntactic\nfeatures of bilingual data and compare it with only-LSTM and only-CNN networks.\nOur proposed network outperforms them by significant margin.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:41:15 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gupta", "Prabhakar", ""], ["Nelakanti", "Anil", ""]]}, {"id": "2004.13839", "submitter": "Louis Falissard", "authors": "Louis Falissard, Claire Morgand, Sylvie Roussel, Claire Imbaud, Walid\n  Ghosn, Karim Bounebache, Gr\\'egoire Rey", "title": "Neural translation and automated recognition of ICD10 medical entities\n  from natural language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of medical entities from natural language is an ubiquitous\nproblem in the medical field, with applications ranging from medical act coding\nto the analysis of electronic health data for public health. It is however a\ncomplex task usually requiring human expert intervention, thus making it\nexpansive and time consuming. The recent advances in artificial intelligence,\nspecifically the raise of deep learning methods, has enabled computers to make\nefficient decisions on a number of complex problems, with the notable example\nof neural sequence models and their powerful applications in natural language\nprocessing. They however require a considerable amount of data to learn from,\nwhich is typically their main limiting factor. However, the C\\'epiDc stores an\nexhaustive database of death certificates at the French national scale,\namounting to several millions of natural language examples provided with their\nassociated human coded medical entities available to the machine learning\npractitioner. This article investigates the applications of deep neural\nsequence models to the medical entity recognition from natural language\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 18:17:53 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 10:30:24 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Falissard", "Louis", ""], ["Morgand", "Claire", ""], ["Roussel", "Sylvie", ""], ["Imbaud", "Claire", ""], ["Ghosn", "Walid", ""], ["Bounebache", "Karim", ""], ["Rey", "Gr\u00e9goire", ""]]}, {"id": "2004.13840", "submitter": "Sileye Ba", "authors": "Lo Alla and Dione Cheikh Bamba and Nguer Elhadji Mamadou and Ba Sileye\n  O. Ba and Lo Moussa", "title": "Using LSTM to Translate French to Senegalese Local Languages: Wolof as a\n  Case Study", "comments": "4 pages, 2 tables, ICLR AfricaNLP2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a neural machine translation system for Wolof, a\nlow-resource Niger-Congo language. First we gathered a parallel corpus of 70000\naligned French-Wolof sentences. Then we developped a baseline LSTM based\nencoder-decoder architecture which was further extended to bidirectional LSTMs\nwith attention mechanisms. Our models are trained on a limited amount of\nparallel French-Wolof data of approximately 35000 parallel sentences.\nExperimental results on French-Wolof translation tasks show that our approach\nproduces promising translations in extremely low-resource conditions. The best\nmodel was able to achieve a good performance of 47% BLEU score.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 17:09:52 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Alla", "Lo", ""], ["Bamba", "Dione Cheikh", ""], ["Mamadou", "Nguer Elhadji", ""], ["Ba", "Ba Sileye O.", ""], ["Moussa", "Lo", ""]]}, {"id": "2004.13845", "submitter": "Yannis Papanikolaou", "authors": "Yannis Papanikolaou and Andrea Pierleoni", "title": "DARE: Data Augmented Relation Extraction with GPT-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world Relation Extraction (RE) tasks are challenging to deal with,\neither due to limited training data or class imbalance issues. In this work, we\npresent Data Augmented Relation Extraction(DARE), a simple method to augment\ntraining data by properly fine-tuning GPT-2 to generate examples for specific\nrelation types. The generated training data is then used in combination with\nthe gold dataset to train a BERT-based RE classifier. In a series of\nexperiments we show the advantages of our method, which leads in improvements\nof up to 11 F1 score points against a strong base-line. Also, DARE achieves new\nstate of the art in three widely used biomedical RE datasets surpassing the\nprevious best results by 4.7 F1 points on average.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:38:36 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Papanikolaou", "Yannis", ""], ["Pierleoni", "Andrea", ""]]}, {"id": "2004.13847", "submitter": "Adly Templeton", "authors": "Adly Templeton", "title": "Inherently Interpretable Sparse Word Embeddings through Sparse Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a powerful natural language processing technique, but\nthey are extremely difficult to interpret. In order to create more\ninterpretable word embeddings, we transform pretrained dense word embeddings\ninto sparse embeddings. These new embeddings are inherently interpretable: each\nof their dimensions are created from and represent a natural language word or\nspecific syntactic concept. We construct these embeddings through sparse\ncoding, where each vector in the basis set is itself a word embedding. We show\nthat models trained using these sparse embeddings can achieve good performance\nand are extremely interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:49:49 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Templeton", "Adly", ""]]}, {"id": "2004.13850", "submitter": "Lukas Stappen", "authors": "Lukas Stappen, Fabian Brunn, Bj\\\"orn Schuller", "title": "Cross-lingual Zero- and Few-shot Hate Speech Detection Utilising Frozen\n  Transformer Language Models and AXEL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting hate speech, especially in low-resource languages, is a non-trivial\nchallenge. To tackle this, we developed a tailored architecture based on\nfrozen, pre-trained Transformers to examine cross-lingual zero-shot and\nfew-shot learning, in addition to uni-lingual learning, on the HatEval\nchallenge data set. With our novel attention-based classification block AXEL,\nwe demonstrate highly competitive results on the English and Spanish subsets.\nWe also re-sample the English subset, enabling additional, meaningful\ncomparisons in the future.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:58:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Stappen", "Lukas", ""], ["Brunn", "Fabian", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "2004.13852", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Jun Ma, Xin Luna Dong", "title": "TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product\n  Categories", "comments": "Accepted to ACL 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting structured knowledge from product profiles is crucial for various\napplications in e-Commerce. State-of-the-art approaches for knowledge\nextraction were each designed for a single category of product, and thus do not\napply to real-life e-Commerce scenarios, which often contain thousands of\ndiverse categories. This paper proposes TXtract, a taxonomy-aware knowledge\nextraction model that applies to thousands of product categories organized in a\nhierarchical taxonomy. Through category conditional self-attention and\nmulti-task learning, our approach is both scalable, as it trains a single model\nfor thousands of categories, and effective, as it extracts category-specific\nattribute values. Experiments on products from a taxonomy with 4,000 categories\nshow that TXtract outperforms state-of-the-art approaches by up to 10% in F1\nand 15% in coverage across all categories.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 03:02:09 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 14:54:13 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Ma", "Jun", ""], ["Dong", "Xin Luna", ""]]}, {"id": "2004.13912", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Nicholas Frosst, Xuezhou Zhang, Rich Caruana and\n  Geoffrey E. Hinton", "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful black-box predictors that have\nachieved impressive performance on a wide variety of tasks. However, their\naccuracy comes at the cost of intelligibility: it is usually unclear how they\nmake their decisions. This hinders their applicability to high stakes\ndecision-making domains such as healthcare. We propose Neural Additive Models\n(NAMs) which combine some of the expressivity of DNNs with the inherent\nintelligibility of generalized additive models. NAMs learn a linear combination\nof neural networks that each attend to a single input feature. These networks\nare trained jointly and can learn arbitrarily complex relationships between\ntheir input feature and the output. Our experiments on regression and\nclassification datasets show that NAMs are more accurate than widely used\nintelligible models such as logistic regression and shallow decision trees.\nThey perform similarly to existing state-of-the-art generalized additive models\nin accuracy, but can be more easily applied to real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:28:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Frosst", "Nicholas", ""], ["Zhang", "Xuezhou", ""], ["Caruana", "Rich", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "2004.13918", "submitter": "Jun-Ho Choi", "authors": "Jun-Ho Choi, Jong-Seok Lee", "title": "EmbraceNet for Activity: A Deep Multimodal Fusion Architecture for\n  Activity Recognition", "comments": "Accepted in HASCA at ACM UbiComp/ISWC 2019, won the 2nd place in the\n  SHL Recognition Challenge 2019", "journal-ref": null, "doi": "10.1145/3341162.3344871", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition using multiple sensors is a challenging but\npromising task in recent decades. In this paper, we propose a deep multimodal\nfusion model for activity recognition based on the recently proposed feature\nfusion architecture named EmbraceNet. Our model processes each sensor data\nindependently, combines the features with the EmbraceNet architecture, and\npost-processes the fused feature to predict the activity. In addition, we\npropose additional processes to boost the performance of our model. We submit\nthe results obtained from our proposed model to the SHL recognition challenge\nwith the team name \"Yonsei-MCML.\"\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:54:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Choi", "Jun-Ho", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "2004.13930", "submitter": "Zhiyong Yang", "authors": "Zhiyong Yang, Qianqian Xu, Xiaochun Cao, Qingming Huang", "title": "Task-Feature Collaborative Learning with Application to Personalized\n  Attribute Prediction", "comments": "To appear in T-PAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective learning paradigm against insufficient training samples,\nMulti-Task Learning (MTL) encourages knowledge sharing across multiple related\ntasks so as to improve the overall performance. In MTL, a major challenge\nsprings from the phenomenon that sharing the knowledge with dissimilar and hard\ntasks, known as negative transfer, often results in a worsened performance.\nThough a substantial amount of studies have been carried out against the\nnegative transfer, most of the existing methods only model the transfer\nrelationship as task correlations, with the transfer across features and tasks\nleft unconsidered. Different from the existing methods, our goal is to\nalleviate negative transfer collaboratively across features and tasks. To this\nend, we propose a novel multi-task learning method called Task-Feature\nCollaborative Learning (TFCL). Specifically, we first propose a base model with\na heterogeneous block-diagonal structure regularizer to leverage the\ncollaborative grouping of features and tasks and suppressing inter-group\nknowledge sharing. We then propose an optimization method for the model.\nExtensive theoretical analysis shows that our proposed method has the following\nbenefits: (a) it enjoys the global convergence property and (b) it provides a\nblock-diagonal structure recovery guarantee. As a practical extension, we\nextend the base model by allowing overlapping features and differentiating the\nhard tasks. We further apply it to the personalized attribute prediction\nproblem with fine-grained modeling of user behaviors. Finally, experimental\nresults on both simulated dataset and real-world datasets demonstrate the\neffectiveness of our proposed method\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 02:32:04 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Yang", "Zhiyong", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "2004.13940", "submitter": "Parameswaran Raman", "authors": "Parameswaran Raman, S.V.N. Vishwanathan", "title": "DS-FACTO: Doubly Separable Factorization Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization Machines (FM) are powerful class of models that incorporate\nhigher-order interaction among features to add more expressive power to linear\nmodels. They have been used successfully in several real-world tasks such as\nclick-prediction, ranking and recommender systems. Despite using a low-rank\nrepresentation for the pairwise features, the memory overheads of using\nfactorization machines on large-scale real-world datasets can be prohibitively\nhigh. For instance on the criteo tera dataset, assuming a modest $128$\ndimensional latent representation and $10^{9}$ features, the memory requirement\nfor the model is in the order of $1$ TB. In addition, the data itself occupies\n$2.1$ TB. Traditional algorithms for FM which work on a single-machine are not\nequipped to handle this scale and therefore, using a distributed algorithm to\nparallelize the computation across a cluster is inevitable. In this work, we\npropose a hybrid-parallel stochastic optimization algorithm DS-FACTO, which\npartitions both the data as well as parameters of the factorization machine\nsimultaneously. Our solution is fully de-centralized and does not require the\nuse of any parameter servers. We present empirical results to analyze the\nconvergence behavior, predictive power and scalability of DS-FACTO.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 03:36:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Raman", "Parameswaran", ""], ["Vishwanathan", "S. V. N.", ""]]}, {"id": "2004.13954", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Haoyi Xiong, Dongrui Wu", "title": "Rethink the Connections among Generalization, Memorization and the\n  Spectral Bias of DNNs", "comments": "IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized deep neural networks (DNNs) with sufficient capacity to\nmemorize random noise can achieve excellent generalization performance,\nchallenging the bias-variance trade-off in classical learning theory. Recent\nstudies claimed that DNNs first learn simple patterns and then memorize noise;\nsome other works showed a phenomenon that DNNs have a spectral bias to learn\ntarget functions from low to high frequencies during training. However, we show\nthat the monotonicity of the learning bias does not always hold: under the\nexperimental setup of deep double descent, the high-frequency components of\nDNNs diminish in the late stage of training, leading to the second descent of\nthe test error. Besides, we find that the spectrum of DNNs can be applied to\nindicating the second descent of the test error, even though it is calculated\nfrom the training set only.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 04:24:25 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 11:18:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Xiao", ""], ["Xiong", "Haoyi", ""], ["Wu", "Dongrui", ""]]}, {"id": "2004.13965", "submitter": "Megha Khosla", "authors": "Vikram Waradpande, Daniel Kudenko, Megha Khosla", "title": "Graph-based State Representation for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep RL approaches build much of their success on the ability of the deep\nneural network to generate useful internal representations. Nevertheless, they\nsuffer from a high sample-complexity and starting with a good input\nrepresentation can have a significant impact on the performance. In this paper,\nwe exploit the fact that the underlying Markov decision process (MDP)\nrepresents a graph, which enables us to incorporate the topological information\nfor effective state representation learning.\n  Motivated by the recent success of node representations for several graph\nanalytical tasks we specifically investigate the capability of node\nrepresentation learning methods to effectively encode the topology of the\nunderlying MDP in Deep RL. To this end we perform a comparative analysis of\nseveral models chosen from 4 different classes of representation learning\nalgorithms for policy learning in grid-world navigation tasks, which are\nrepresentative of a large class of RL problems. We find that all embedding\nmethods outperform the commonly used matrix representation of grid-world\nenvironments in all of the studied cases. Moreoever, graph convolution based\nmethods are outperformed by simpler random walk based methods and graph linear\nautoencoders.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 05:43:15 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 15:31:22 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:49:34 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Waradpande", "Vikram", ""], ["Kudenko", "Daniel", ""], ["Khosla", "Megha", ""]]}, {"id": "2004.13970", "submitter": "Zekun Tong", "authors": "Zekun Tong, Yuxuan Liang, Changsheng Sun, David S. Rosenblum and\n  Andrew Lim", "title": "Directed Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have been widely used due to their\noutstanding performance in processing graph-structured data. However, the\nundirected graphs limit their application scope. In this paper, we extend\nspectral-based graph convolution to directed graphs by using first- and\nsecond-order proximity, which can not only retain the connection properties of\nthe directed graph, but also expand the receptive field of the convolution\noperation. A new GCN model, called DGCN, is then designed to learn\nrepresentations on the directed graph, leveraging both the first- and\nsecond-order proximity information. We empirically show the fact that GCNs\nworking only with DGCNs can encode more useful information from graph and help\nachieve better performance when generalized to other models. Moreover,\nextensive experiments on citation networks and co-purchase datasets demonstrate\nthe superiority of our model against the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:19:10 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Tong", "Zekun", ""], ["Liang", "Yuxuan", ""], ["Sun", "Changsheng", ""], ["Rosenblum", "David S.", ""], ["Lim", "Andrew", ""]]}, {"id": "2004.13972", "submitter": "Avishek Anand", "authors": "Jaspreet Singh, Zhenye Wang, Megha Khosla, and Avishek Anand", "title": "Valid Explanations for Learning to Rank Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-to-rank (LTR) is a class of supervised learning techniques that\napply to ranking problems dealing with a large number of features.\n  The popularity and widespread application of LTR models in prioritizing\ninformation in a variety of domains makes their scrutability vital in today's\nlandscape of fair and transparent learning systems. However, limited work\nexists that deals with interpreting the decisions of learning systems that\noutput rankings. In this paper we propose a model agnostic local explanation\nmethod that seeks to identify a small subset of input features as explanation\nto a ranking decision. We introduce new notions of validity and completeness of\nexplanations specifically for rankings, based on the presence or absence of\nselected features, as a way of measuring goodness. We devise a novel\noptimization problem to maximize validity directly and propose greedy\nalgorithms as solutions. In extensive quantitative experiments we show that our\napproach outperforms other model agnostic explanation approaches across\npointwise, pairwise and listwise LTR models in validity while not compromising\non completeness.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:21:56 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 13:31:40 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 15:46:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Singh", "Jaspreet", ""], ["Wang", "Zhenye", ""], ["Khosla", "Megha", ""], ["Anand", "Avishek", ""]]}, {"id": "2004.14016", "submitter": "Daisuke Kaji", "authors": "Daisuke Kaji, Kazuho Watanabe, Masahiro Kobayashi", "title": "Multi-Decoder RNN Autoencoder Based on Variational Bayes Method", "comments": "8 pages, 11 figures, accepted for publication in IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have wide applications and play an important role in\ndata analysis fields including time series data analysis. However, in time\nseries analysis, most of the algorithms used signal shape features or the\ninitial value of hidden variable of a neural network. Little has been discussed\non the methods based on the generative model of the time series. In this paper,\nwe propose a new clustering algorithm focusing on the generative process of the\nsignal with a recurrent neural network and the variational Bayes method. Our\nexperiments show that the proposed algorithm not only has a robustness against\nfor phase shift, amplitude and signal length variations but also provide a\nflexible clustering based on the property of the variational Bayes method.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:25:07 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kaji", "Daisuke", ""], ["Watanabe", "Kazuho", ""], ["Kobayashi", "Masahiro", ""]]}, {"id": "2004.14026", "submitter": "Jens Schreiber", "authors": "Stephan Deist, Jens Schreiber, Maarten Bieshaar and Bernhard Sick", "title": "Extended Coopetitive Soft Gating Ensemble", "comments": "14 pages; 15 figures; 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about an extension of a recent ensemble method called\nCoopetitive Soft Gating Ensemble (CSGE) and its application on power\nforecasting as well as motion primitive forecasting of cyclists. The CSGE has\nbeen used successfully in the field of wind power forecasting, outperforming\ncommon algorithms in this domain. The principal idea of the CSGE is to weight\nthe models regarding their observed performance during training on different\naspects. Several extensions are proposed to the original CSGE within this\narticle, making the ensemble even more flexible and powerful. The extended CSGE\n(XCSGE as we term it), is used to predict the power generation on both wind-\nand solar farms. Moreover, the XCSGE is applied to forecast the movement state\nof cyclists in the context of driver assistance systems. Both domains have\ndifferent requirements, are non-trivial problems, and are used to evaluate\nvarious facets of the novel XCSGE. The two problems differ fundamentally in the\nsize of the data sets and the number of features. Power forecasting is based on\nweather forecasts that are subject to fluctuations in their features. In the\nmovement primitive forecasting of cyclists, time delays contribute to the\ndifficulty of the prediction. The XCSGE reaches an improvement of the\nprediction performance of up to 11% for wind power forecasting and 30% for\nsolar power forecasting compared to the worst performing model. For the\nclassification of movement primitives of cyclists, the XCSGE reaches an\nimprovement of up to 28%. The evaluation includes a comparison with other\nstate-of-the-art ensemble methods. We can verify that the XCSGE results are\nsignificantly better using the Nemenyi post-hoc test.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:48:37 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Deist", "Stephan", ""], ["Schreiber", "Jens", ""], ["Bieshaar", "Maarten", ""], ["Sick", "Bernhard", ""]]}, {"id": "2004.14031", "submitter": "Md Ashad Alam PhD", "authors": "Md Ashad Alam, Chuan Qiu, Hui Shen, Yu-Ping Wang, and Hong-Wen Deng", "title": "A generalized kernel machine approach to identify higher-order composite\n  effects in multi-view datasets", "comments": "19 pages, 9 figures, and Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, a comprehensive study of multi-view datasets (e.g.,\nmulti-omics and imaging scans) has been a focus and forefront in biomedical\nresearch. State-of-the-art biomedical technologies are enabling us to collect\nmulti-view biomedical datasets for the study of complex diseases. While all the\nviews of data tend to explore complementary information of a disease,\nmulti-view data analysis with complex interactions is challenging for a deeper\nand holistic understanding of biological systems. In this paper, we propose a\nnovel generalized kernel machine approach to identify higher-order composite\neffects in multi-view biomedical datasets. This generalized semi-parametric (a\nmixed-effect linear model) approach includes the marginal and joint Hadamard\nproduct of features from different views of data. The proposed kernel machine\napproach considers multi-view data as predictor variables to allow more\nthorough and comprehensive modeling of a complex trait. The proposed method can\nbe applied to the study of any disease model, where multi-view datasets are\navailable. We applied our approach to both synthesized datasets and real\nmulti-view datasets from adolescence brain development and osteoporosis study,\nincluding an imaging scan dataset and five omics datasets. Our experiments\ndemonstrate that the proposed method can effectively identify higher-order\ncomposite effects and suggest that corresponding features (genes, region of\ninterests, and chemical taxonomies) function in a concerted effort. We show\nthat the proposed method is more generalizable than existing ones.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:56:02 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Alam", "Md Ashad", ""], ["Qiu", "Chuan", ""], ["Shen", "Hui", ""], ["Wang", "Yu-Ping", ""], ["Deng", "Hong-Wen", ""]]}, {"id": "2004.14034", "submitter": "Jens Schreiber", "authors": "Jens Schreiber, Bernhard Sick", "title": "Emerging Relation Network and Task Embedding for Multi-Task Regression\n  Problems", "comments": "8 pages;2 tables;5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (mtl) provides state-of-the-art results in many\napplications of computer vision and natural language processing. In contrast to\nsingle-task learning (stl), mtl allows for leveraging knowledge between related\ntasks improving prediction results on the main task (in contrast to an\nauxiliary task) or all tasks. However, there is a limited number of comparative\nstudies on applying mtl architectures for regression and time series problems\ntaking recent advances of mtl into account. An interesting, non-linear problem\nis the forecast of the expected power generation for renewable power plants.\nTherefore, this article provides a comparative study of the following recent\nand important mtl architectures: Hard parameter sharing, cross-stitch network,\nsluice network (sn). They are compared to a multi-layer perceptron model of\nsimilar size in an stl setting. Additionally, we provide a simple, yet\neffective approach to model task specific information through an embedding\nlayer in an multi-layer perceptron, referred to as task embedding. Further, we\nintroduce a new mtl architecture named emerging relation network (ern), which\ncan be considered as an extension of the sluice network. For a solar power\ndataset, the task embedding achieves the best mean improvement with 14.9%. The\nmean improvement of the ern and the sn on the solar dataset is of similar\nmagnitude with 14.7% and 14.8%. On a wind power dataset, only the ern achieves\na significant improvement of up to 7.7%. Results suggest that the ern is\nbeneficial when tasks are only loosely related and the prediction problem is\nmore non-linear. Contrary, the proposed task embedding is advantageous when\ntasks are strongly correlated. Further, the task embedding provides an\neffective approach with reduced computational effort compared to other mtl\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:02:24 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Schreiber", "Jens", ""], ["Sick", "Bernhard", ""]]}, {"id": "2004.14046", "submitter": "Wojciech Masarczyk", "authors": "Wojciech Masarczyk and Ivona Tautkute", "title": "Reducing catastrophic forgetting with learning on synthetic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a problem caused by neural networks' inability to\nlearn data in sequence. After learning two tasks in sequence, performance on\nthe first one drops significantly. This is a serious disadvantage that prevents\nmany deep learning applications to real-life problems where not all object\nclasses are known beforehand; or change in data requires adjustments to the\nmodel. To reduce this problem we investigate the use of synthetic data, namely\nwe answer a question: Is it possible to generate such data synthetically which\nlearned in sequence does not result in catastrophic forgetting? We propose a\nmethod to generate such data in two-step optimisation process via\nmeta-gradients. Our experimental results on Split-MNIST dataset show that\ntraining a model on such synthetic data in sequence does not result in\ncatastrophic forgetting. We also show that our method of generating data is\nrobust to different learning scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:45:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Masarczyk", "Wojciech", ""], ["Tautkute", "Ivona", ""]]}, {"id": "2004.14070", "submitter": "Siddharth Swaroop", "authors": "Pingbo Pan, Siddharth Swaroop, Alexander Immer, Runa Eschenhagen,\n  Richard E. Turner, Mohammad Emtiyaz Khan", "title": "Continual Deep Learning by Functional Regularisation of Memorable Past", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continually learning new skills is important for intelligent systems, yet\nstandard deep learning methods suffer from catastrophic forgetting of the past.\nRecent works address this with weight regularisation. Functional\nregularisation, although computationally expensive, is expected to perform\nbetter, but rarely does so in practice. In this paper, we fix this issue by\nusing a new functional-regularisation approach that utilises a few memorable\npast examples crucial to avoid forgetting. By using a Gaussian Process\nformulation of deep networks, our approach enables training in weight-space\nwhile identifying both the memorable past and a functional prior. Our method\nachieves state-of-the-art performance on standard benchmarks and opens a new\ndirection for life-long learning where regularisation and memory-based methods\nare naturally combined.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:47:54 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:30:05 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 16:47:20 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2021 09:48:17 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Pan", "Pingbo", ""], ["Swaroop", "Siddharth", ""], ["Immer", "Alexander", ""], ["Eschenhagen", "Runa", ""], ["Turner", "Richard E.", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2004.14088", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Junqi Zhang, Kun Bai, Conghui Zhu and Tiejun\n  Zhao", "title": "Demographics Should Not Be the Reason of Toxicity: Mitigating\n  Discrimination in Text Classifications with Instance Weighting", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent proliferation of the use of text classifications, researchers\nhave found that there are certain unintended biases in text classification\ndatasets. For example, texts containing some demographic identity-terms (e.g.,\n\"gay\", \"black\") are more likely to be abusive in existing abusive language\ndetection datasets. As a result, models trained with these datasets may\nconsider sentences like \"She makes me happy to be gay\" as abusive simply\nbecause of the word \"gay.\" In this paper, we formalize the unintended biases in\ntext classification datasets as a kind of selection bias from the\nnon-discrimination distribution to the discrimination distribution. Based on\nthis formalization, we further propose a model-agnostic debiasing training\nframework by recovering the non-discrimination distribution using instance\nweighting, which does not require any extra resources or annotations apart from\na pre-defined set of demographic identity-terms. Experiments demonstrate that\nour method can effectively alleviate the impacts of the unintended biases\nwithout significantly hurting models' generalization ability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:22:19 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 07:44:34 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:22:11 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Zhang", "Junqi", ""], ["Bai", "Kun", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2004.14111", "submitter": "Nathaniel Tye", "authors": "Nathaniel Joseph Tye, James Timothy Meech, Bilgesu Arif Bilgin,\n  Phillip Stanley-Marbell", "title": "A System for Generating Non-Uniform Random Variates using Graphene\n  Field-Effect Transistors", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": "10.1109/ASAP49362.2020.00026", "report-no": null, "categories": "cs.ET physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for hardware non-uniform random number generation\nbased on the transfer characteristics of graphene field-effect transistors\n(GFETs) which requires as few as two transistors and a resistor (or\ntransimpedance amplifier). The method could be integrated into a custom\ncomputing system to provide samples from arbitrary univariate distributions. We\nalso demonstrate the use of wavelet decomposition of the target distribution to\ndetermine GFET bias voltages in a multi-GFET array.\n  We implement the method by fabricating multiple GFETs and experimentally\nvalidating that their transfer characteristics exhibit the nonlinearity on\nwhich our method depends. We use the characterization data in simulations of a\nproposed architecture for generating samples from dynamically-selectable\nnon-uniform probability distributions.\n  Using a combination of experimental measurements of GFETs under a range of\nbiasing conditions and simulation of the GFET-based non-uniform random variate\ngenerator architecture, we demonstrate a speedup of Monte Carlo integration by\na factor of up to 2$\\times$. This speedup assumes the analog-to-digital\nconverters reading the outputs from the circuit can produce samples in the same\namount of time that it takes to perform memory accesses.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 10:09:05 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 10:36:25 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Tye", "Nathaniel Joseph", ""], ["Meech", "James Timothy", ""], ["Bilgin", "Bilgesu Arif", ""], ["Stanley-Marbell", "Phillip", ""]]}, {"id": "2004.14119", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Manaj Srivastava, Sanjay Krishna, David Akodes, Richard\n  Schwartz", "title": "Combining Word Embeddings and N-grams for Unsupervised Document\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based extractive document summarization relies on the quality of the\nsentence similarity graph. Bag-of-words or tf-idf based sentence similarity\nuses exact word matching, but fails to measure the semantic similarity between\nindividual words or to consider the semantic structure of sentences. In order\nto improve the similarity measure between sentences, we employ off-the-shelf\ndeep embedding features and tf-idf features, and introduce a new text\nsimilarity metric. An improved sentence similarity graph is built and used in a\nsubmodular objective function for extractive summarization, which consists of a\nweighted coverage term and a diversity term. A Transformer based compression\nmodel is developed for sentence compression to aid in document summarization.\nOur summarization approach is extractive and unsupervised. Experiments\ndemonstrate that our approach can outperform the tf-idf based approach and\nachieve state-of-the-art performance on the DUC04 dataset, and comparable\nperformance to the fully supervised learning methods on the CNN/DM and NYT\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:22:46 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Jiang", "Zhuolin", ""], ["Srivastava", "Manaj", ""], ["Krishna", "Sanjay", ""], ["Akodes", "David", ""], ["Schwartz", "Richard", ""]]}, {"id": "2004.14129", "submitter": "Xin Wang", "authors": "Evani Radiya-Dixit and Xin Wang", "title": "How fine can fine-tuning be? Learning efficient language models", "comments": "11 pages, 11 figures and 6 tables; accepted to the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art performance on language understanding tasks is now achieved\nwith increasingly large networks; the current record holder has billions of\nparameters. Given a language model pre-trained on massive unlabeled text\ncorpora, only very light supervised fine-tuning is needed to learn a task: the\nnumber of fine-tuning steps is typically five orders of magnitude lower than\nthe total parameter count. Does this mean that fine-tuning only introduces\nsmall differences from the pre-trained model in the parameter space? If so, can\none avoid storing and computing an entire model for each task? In this work, we\naddress these questions by using Bidirectional Encoder Representations from\nTransformers (BERT) as an example. As expected, we find that the fine-tuned\nmodels are close in parameter space to the pre-trained one, with the closeness\nvarying from layer to layer. We show that it suffices to fine-tune only the\nmost critical layers. Further, we find that there are surprisingly many good\nsolutions in the set of sparsified versions of the pre-trained model. As a\nresult, fine-tuning of huge language models can be achieved by simply setting a\ncertain number of entries in certain layers of the pre-trained parameters to\nzero, saving both task-specific parameter storage and computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:31:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Radiya-Dixit", "Evani", ""], ["Wang", "Xin", ""]]}, {"id": "2004.14143", "submitter": "Mahdi Rezaei", "authors": "Mahdi Rezaei and Mahsa Shahidi", "title": "Zero-Shot Learning and its Applications from Autonomous Vehicles to\n  COVID-19 Diagnosis: A Review", "comments": "Accepted in Journal of Intelligence-Based Medicine (Elsevier)", "journal-ref": "Journal of Intelligence-Based Medicine, Volumes 4, 2020", "doi": "10.1016/j.ibmed.2020.100005", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The challenge of learning a new concept, object, or a new medical disease\nrecognition without receiving any examples beforehand is called Zero-Shot\nLearning (ZSL). One of the major issues in deep learning based methodologies\nsuch as in Medical Imaging and other real-world applications is the requirement\nof large annotated datasets prepared by clinicians or experts to train the\nmodel. ZSL is known for having minimal human intervention by relying only on\npreviously known or trained concepts plus currently existing auxiliary\ninformation. This makes the ZSL applicable in many real-world scenarios, from\nunknown object detection in autonomous vehicles to medical imaging and\nunforeseen diseases such as COVID-19 Chest X-Ray (CXR) based diagnosis. We\nintroduce a novel and broaden solution called Few/one-shot learning, and\npresent the definition of the ZSL problem as an extreme case of the few-shot\nlearning. We review over fundamentals and the challenging steps of Zero-Shot\nLearning, including state-of-the-art categories of solutions, as well as our\nrecommended solution, motivations behind each approach, their advantages over\neach category to guide both clinicians and AI researchers to proceed with the\nbest techniques and practices based on their applications. We then review\nthrough different datasets inducing medical and non-medical images, the variety\nof splits, and the evaluation protocols proposed so far. Finally, we discuss\nthe recent applications and future directions of ZSL. We aim to convey a useful\nintuition through this paper towards the goal of handling complex learning\ntasks more similar to the way humans learn. We mainly focus on two applications\nin the current modern yet challenging era: coping with an early and fast\ndiagnosis of COVID-19 cases, and also encouraging the readers to develop other\nsimilar AI-based automated detection/recognition systems using ZSL.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:45:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 12:04:17 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 03:27:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rezaei", "Mahdi", ""], ["Shahidi", "Mahsa", ""]]}, {"id": "2004.14164", "submitter": "Xiaoqing Geng", "authors": "Xiaoqing Geng, Xiwen Chen, Kenny Q. Zhu, Libin Shen, Yinggong Zhao", "title": "MICK: A Meta-Learning Framework for Few-shot Relation Classification\n  with Small Training Data", "comments": null, "journal-ref": "CIKM 2020: The 29th ACM International Conference on Information\n  and Knowledge Management", "doi": "10.1145/3340531.3411858", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot relation classification seeks to classify incoming query instances\nafter meeting only few support instances. This ability is gained by training\nwith large amount of in-domain annotated data. In this paper, we tackle an even\nharder problem by further limiting the amount of data available at training\ntime. We propose a few-shot learning framework for relation classification,\nwhich is particularly powerful when the training data is very small. In this\nframework, models not only strive to classify query instances, but also seek\nunderlying knowledge about the support instances to obtain better instance\nrepresentations. The framework also includes a method for aggregating\ncross-domain knowledge into models by open-source task enrichment.\nAdditionally, we construct a brand new dataset: the TinyRel-CM dataset, a\nfew-shot relation classification dataset in health domain with purposely small\ntraining data and challenging relation classes. Experimental results\ndemonstrate that our framework brings performance gains for most underlying\nclassification models, outperforms the state-of-the-art results given small\ntraining data, and achieves competitive results with sufficiently large\ntraining data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 06:23:38 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 15:54:51 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Geng", "Xiaoqing", ""], ["Chen", "Xiwen", ""], ["Zhu", "Kenny Q.", ""], ["Shen", "Libin", ""], ["Zhao", "Yinggong", ""]]}, {"id": "2004.14171", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Ling Cai, Rui Zhu, Blake Regalia, Bo\n  Yan, Meilin Shi, Ni Lao", "title": "SE-KGE: A Location-Aware Knowledge Graph Embedding Model for Geographic\n  Question Answering and Spatial Semantic Lifting", "comments": "Accepted to Transactions in GIS", "journal-ref": "Transactions in GIS, 2020", "doi": "10.1111/TGIS.12629", "report-no": null, "categories": "cs.DB cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph (KG) embeddings is an emerging technique for a\nvariety of downstream tasks such as summarization, link prediction, information\nretrieval, and question answering. However, most existing KG embedding models\nneglect space and, therefore, do not perform well when applied to (geo)spatial\ndata and tasks. For those models that consider space, most of them primarily\nrely on some notions of distance. These models suffer from higher computational\ncomplexity during training while still losing information beyond the relative\ndistance between entities. In this work, we propose a location-aware KG\nembedding model called SE-KGE. It directly encodes spatial information such as\npoint coordinates or bounding boxes of geographic entities into the KG\nembedding space. The resulting model is capable of handling different types of\nspatial reasoning. We also construct a geographic knowledge graph as well as a\nset of geographic query-answer pairs called DBGeo to evaluate the performance\nof SE-KGE in comparison to multiple baselines. Evaluation results show that\nSE-KGE outperforms these baselines on the DBGeo dataset for geographic logic\nquery answering task. This demonstrates the effectiveness of our\nspatially-explicit model and the importance of considering the scale of\ndifferent geographic entities. Finally, we introduce a novel downstream task\ncalled spatial semantic lifting which links an arbitrary location in the study\narea to entities in the KG via some relations. Evaluation on DBGeo shows that\nour model outperforms the baseline by a substantial margin.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:46:31 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Cai", "Ling", ""], ["Zhu", "Rui", ""], ["Regalia", "Blake", ""], ["Yan", "Bo", ""], ["Shi", "Meilin", ""], ["Lao", "Ni", ""]]}, {"id": "2004.14180", "submitter": "Li Shen", "authors": "Congliang Chen, Li Shen, Haozhi Huang, and Wei Liu", "title": "Quantized Adam with Error Feedback", "comments": "Accepted to ACM Transactions on Intelligent Systems and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a distributed variant of adaptive stochastic\ngradient method for training deep neural networks in the parameter-server\nmodel. To reduce the communication cost among the workers and server, we\nincorporate two types of quantization schemes, i.e., gradient quantization and\nweight quantization, into the proposed distributed Adam. Besides, to reduce the\nbias introduced by quantization operations, we propose an error-feedback\ntechnique to compensate for the quantized gradient. Theoretically, in the\nstochastic nonconvex setting, we show that the distributed adaptive gradient\nmethod with gradient quantization and error-feedback converges to the\nfirst-order stationary point, and that the distributed adaptive gradient method\nwith weight quantization and error-feedback converges to the point related to\nthe quantized level under both the single-worker and multi-worker modes. At\nlast, we apply the proposed distributed adaptive gradient methods to train deep\nneural networks. Experimental results demonstrate the efficacy of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:21:54 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 04:41:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Chen", "Congliang", ""], ["Shen", "Li", ""], ["Huang", "Haozhi", ""], ["Liu", "Wei", ""]]}, {"id": "2004.14199", "submitter": "Mattia  Zorzi", "authors": "Mattia Zorzi", "title": "Autoregressive Identification of Kronecker Graphical Models", "comments": "Automatica (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem to estimate a Kronecker graphical model corresponding\nto an autoregressive Gaussian stochastic process. The latter is completely\ndescribed by the power spectral density function whose inverse has support\nwhich admits a Kronecker product decomposition. We propose a Bayesian approach\nto estimate such a model. We test the effectiveness of the proposed method by\nsome numerical experiments. We also apply the procedure to urban pollution\nmonitoring data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:44:26 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zorzi", "Mattia", ""]]}, {"id": "2004.14203", "submitter": "Diego Klabjan", "authors": "Diego Klabjan, Xiaofeng Zhu", "title": "Neural Network Retraining for Model Serving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose incremental (re)training of a neural network model to cope with a\ncontinuous flow of new data in inference during model serving. As such, this is\na life-long learning process. We address two challenges of life-long\nretraining: catastrophic forgetting and efficient retraining. If we combine all\npast and new data it can easily become intractable to retrain the neural\nnetwork model. On the other hand, if the model is retrained using only new\ndata, it can easily suffer catastrophic forgetting and thus it is paramount to\nstrike the right balance. Moreover, if we retrain all weights of the model\nevery time new data is collected, retraining tends to require too many\ncomputing resources. To solve these two issues, we propose a novel retraining\nmodel that can select important samples and important weights utilizing\nmulti-armed bandits. To further address forgetting, we propose a new\nregularization term focusing on synapse and neuron importance. We analyze\nmultiple datasets to document the outcome of the proposed retraining methods.\nVarious experiments demonstrate that our retraining methodologies mitigate the\ncatastrophic forgetting problem while boosting model performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:52:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Klabjan", "Diego", ""], ["Zhu", "Xiaofeng", ""]]}, {"id": "2004.14214", "submitter": "Eyy\\\"ub Sari", "authors": "Eyy\\\"ub Sari, Vahid Partovi Nia", "title": "Batch Normalization in Quantized Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementation of quantized neural networks on computing hardware leads to\nconsiderable speed up and memory saving. However, quantized deep networks are\ndifficult to train and batch~normalization (BatchNorm) layer plays an important\nrole in training full-precision and quantized networks. Most studies on\nBatchNorm are focused on full-precision networks, and there is little research\nin understanding BatchNorm affect in quantized training which we address here.\nWe show BatchNorm avoids gradient explosion which is counter-intuitive and\nrecently observed in numerical experiments by other researchers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:03:02 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Sari", "Eyy\u00fcb", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "2004.14227", "submitter": "Sanyou Wu", "authors": "Sanyou Wu, Xingdong Feng, Fan Zhou", "title": "Metric learning by Similarity Network for Deep Semi-Supervised Learning", "comments": "Published as a conference paper at FLINS/ISKE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep semi-supervised learning has been widely implemented in the real-world\ndue to the rapid development of deep learning. Recently, attention has shifted\nto the approaches such as Mean-Teacher to penalize the inconsistency between\ntwo perturbed input sets. Although these methods may achieve positive results,\nthey ignore the relationship information between data instances. To solve this\nproblem, we propose a novel method named Metric Learning by Similarity Network\n(MLSN), which aims to learn a distance metric adaptively on different domains.\nBy co-training with the classification network, similarity network can learn\nmore information about pairwise relationships and performs better on some\nempirical tasks than state-of-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:25:13 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wu", "Sanyou", ""], ["Feng", "Xingdong", ""], ["Zhou", "Fan", ""]]}, {"id": "2004.14230", "submitter": "Evgeny Mirkes", "authors": "Evgeny M. Mirkes, Jeza Allohibi, and Alexander N. Gorban", "title": "Fractional norms and quasinorms do not help to overcome the curse of\n  dimensionality", "comments": null, "journal-ref": "Entropy. 2020; 22(10):1105", "doi": "10.3390/e22101105", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality causes the well-known and widely discussed\nproblems for machine learning methods. There is a hypothesis that using of the\nManhattan distance and even fractional quasinorms lp (for p less than 1) can\nhelp to overcome the curse of dimensionality in classification problems. In\nthis study, we systematically test this hypothesis. We confirm that fractional\nquasinorms have a greater relative contrast or coefficient of variation than\nthe Euclidean norm l2, but we also demonstrate that the distance concentration\nshows qualitatively the same behaviour for all tested norms and quasinorms and\nthe difference between them decays as dimension tends to infinity. Estimation\nof classification quality for kNN based on different norms and quasinorms shows\nthat a greater relative contrast does not mean better classifier performance\nand the worst performance for different databases was shown by different norms\n(quasinorms). A systematic comparison shows that the difference of the\nperformance of kNN based on lp for p=2, 1, and 0.5 is statistically\ninsignificant.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:30:12 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Mirkes", "Evgeny M.", ""], ["Allohibi", "Jeza", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2004.14294", "submitter": "Jurek Leonhardt", "authors": "Jurek Leonhardt, Avishek Anand, Megha Khosla", "title": "Boilerplate Removal using a Neural Sequence Labeling Model", "comments": "WWW20 Demo paper", "journal-ref": null, "doi": "10.1145/3366424.3383547", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of main content from web pages is an important task for\nnumerous applications, ranging from usability aspects, like reader views for\nnews articles in web browsers, to information retrieval or natural language\nprocessing. Existing approaches are lacking as they rely on large amounts of\nhand-crafted features for classification. This results in models that are\ntailored to a specific distribution of web pages, e.g. from a certain time\nframe, but lack in generalization power. We propose a neural sequence labeling\nmodel that does not rely on any hand-crafted features but takes only the HTML\ntags and words that appear in a web page as input. This allows us to present a\nbrowser extension which highlights the content of arbitrary web pages directly\nwithin the browser using our model. In addition, we create a new, more current\ndataset to show that our model is able to adapt to changes in the structure of\nweb pages and outperform the state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:06:59 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Leonhardt", "Jurek", ""], ["Anand", "Avishek", ""], ["Khosla", "Megha", ""]]}, {"id": "2004.14308", "submitter": "Julien Horwood", "authors": "Julien Horwood and Emmanuel Noutahi", "title": "Molecular Design in Synthetically Accessible Chemical Space via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1021/acsomega.0c04153", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental goal of generative drug design is to propose optimized\nmolecules that meet predefined activity, selectivity, and pharmacokinetic\ncriteria. Despite recent progress, we argue that existing generative methods\nare limited in their ability to favourably shift the distributions of molecular\nproperties during optimization. We instead propose a novel Reinforcement\nLearning framework for molecular design in which an agent learns to directly\noptimize through a space of synthetically-accessible drug-like molecules. This\nbecomes possible by defining transitions in our Markov Decision Process as\nchemical reactions, and allows us to leverage synthetic routes as an inductive\nbias. We validate our method by demonstrating that it outperforms existing\nstate-of the art approaches in the optimization of pharmacologically-relevant\nobjectives, while results on multi-objective optimization tasks suggest\nincreased scalability to realistic pharmaceutical design problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:29:28 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 19:44:35 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Horwood", "Julien", ""], ["Noutahi", "Emmanuel", ""]]}, {"id": "2004.14309", "submitter": "Pierluca D'Oro", "authors": "Pierluca D'Oro, Wojciech Ja\\'skowski", "title": "How to Learn a Useful Critic? Model-based Action-Gradient-Estimator\n  Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic-policy actor-critic algorithms for continuous control improve\nthe actor by plugging its actions into the critic and ascending the\naction-value gradient, which is obtained by chaining the actor's Jacobian\nmatrix with the gradient of the critic with respect to input actions. However,\ninstead of gradients, the critic is, typically, only trained to accurately\npredict expected returns, which, on their own, are useless for policy\noptimization. In this paper, we propose MAGE, a model-based actor-critic\nalgorithm, grounded in the theory of policy gradients, which explicitly learns\nthe action-value gradient. MAGE backpropagates through the learned dynamics to\ncompute gradient targets in temporal difference learning, leading to a critic\ntailored for policy improvement. On a set of MuJoCo continuous-control tasks,\nwe demonstrate the efficiency of the algorithm in comparison to model-free and\nmodel-based state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:30:53 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:24:34 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["D'Oro", "Pierluca", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "2004.14340", "submitter": "Sidak Pal Singh", "authors": "Sidak Pal Singh, Dan Alistarh", "title": "WoodFisher: Efficient Second-Order Approximation for Neural Network\n  Compression", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Second-order information, in the form of Hessian- or Inverse-Hessian-vector\nproducts, is a fundamental tool for solving optimization problems. Recently,\nthere has been significant interest in utilizing this information in the\ncontext of deep neural networks; however, relatively little is known about the\nquality of existing approximations in this context. Our work examines this\nquestion, identifies issues with existing approaches, and proposes a method\ncalled WoodFisher to compute a faithful and efficient estimate of the inverse\nHessian.\n  Our main application is to neural network compression, where we build on the\nclassic Optimal Brain Damage/Surgeon framework. We demonstrate that WoodFisher\nsignificantly outperforms popular state-of-the-art methods for one-shot\npruning. Further, even when iterative, gradual pruning is considered, our\nmethod results in a gain in test accuracy over the state-of-the-art approaches,\nfor pruning popular neural networks (like ResNet-50, MobileNetV1) trained on\nstandard image classification datasets such as ImageNet ILSVRC. We examine how\nour method can be extended to take into account first-order information, as\nwell as illustrate its ability to automatically set layer-wise pruning\nthresholds and perform compression in the limited-data regime. The code is\navailable at the following link, https://github.com/IST-DASLab/WoodFisher.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:14:23 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 17:13:28 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 10:40:36 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 17:34:49 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 17:31:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Alistarh", "Dan", ""]]}, {"id": "2004.14356", "submitter": "Robert Stojnic", "authors": "Marcin Kardas, Piotr Czapla, Pontus Stenetorp, Sebastian Ruder,\n  Sebastian Riedel, Ross Taylor, Robert Stojnic", "title": "AxCell: Automatic Extraction of Results from Machine Learning Papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Tracking progress in machine learning has become increasingly difficult with\nthe recent explosion in the number of papers. In this paper, we present AxCell,\nan automatic machine learning pipeline for extracting results from papers.\nAxCell uses several novel components, including a table segmentation subtask,\nto learn relevant structural knowledge that aids extraction. When compared with\nexisting methods, our approach significantly improves the state of the art for\nresults extraction. We also release a structured, annotated dataset for\ntraining models for results extraction, and a dataset for evaluating the\nperformance of models on this task. Lastly, we show the viability of our\napproach enables it to be used for semi-automated results extraction in\nproduction, suggesting our improvements make this task practically viable for\nthe first time. Code is available on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:33:41 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kardas", "Marcin", ""], ["Czapla", "Piotr", ""], ["Stenetorp", "Pontus", ""], ["Ruder", "Sebastian", ""], ["Riedel", "Sebastian", ""], ["Taylor", "Ross", ""], ["Stojnic", "Robert", ""]]}, {"id": "2004.14427", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov and Vivek S. Borkar", "title": "Whittle index based Q-learning for restless bandits with average reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel reinforcement learning algorithm is introduced for multiarmed\nrestless bandits with average reward, using the paradigms of Q-learning and\nWhittle index. Specifically, we leverage the structure of the Whittle index\npolicy to reduce the search space of Q-learning, resulting in major\ncomputational gains. Rigorous convergence analysis is provided, supported by\nnumerical experiments. The numerical experiments show excellent empirical\nperformance of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:43:36 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 16:05:12 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Borkar", "Vivek S.", ""]]}, {"id": "2004.14441", "submitter": "Marco Scutari", "authors": "Tjebbe Bodewes and Marco Scutari", "title": "Learning Bayesian Networks from Incomplete Data with the Node-Average\n  Likelihood", "comments": "27 pages, 5 figures", "journal-ref": "Proceedings of Machine Learning Research (138, PGM 2020), 29-40", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian network (BN) structure learning from complete data has been\nextensively studied in the literature. However, fewer theoretical results are\navailable for incomplete data, and most are related to the\nExpectation-Maximisation (EM) algorithm. Balov (2013) proposed an alternative\napproach called Node-Average Likelihood (NAL) that is competitive with EM but\ncomputationally more efficient; and he proved its consistency and model\nidentifiability for discrete BNs.\n  In this paper, we give general sufficient conditions for the consistency of\nNAL; and we prove consistency and identifiability for conditional Gaussian BNs,\nwhich include discrete and Gaussian BNs as special cases. Furthermore, we\nconfirm our results and the results in Balov (2013) with an independent\nsimulation study. Hence we show that NAL has a much wider applicability than\noriginally implied in Balov (2013), and that it is competitive with EM for\nconditional Gaussian BNs as well.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 19:20:17 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 09:12:28 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 08:14:30 GMT"}, {"version": "v4", "created": "Thu, 13 May 2021 15:10:38 GMT"}, {"version": "v5", "created": "Thu, 22 Jul 2021 15:51:20 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bodewes", "Tjebbe", ""], ["Scutari", "Marco", ""]]}, {"id": "2004.14444", "submitter": "John Miller", "authors": "John Miller, Karl Krauth, Benjamin Recht, Ludwig Schmidt", "title": "The Effect of Natural Distribution Shift on Question Answering Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build four new test sets for the Stanford Question Answering Dataset\n(SQuAD) and evaluate the ability of question-answering systems to generalize to\nnew data. Our first test set is from the original Wikipedia domain and measures\nthe extent to which existing systems overfit the original test set. Despite\nseveral years of heavy test set re-use, we find no evidence of adaptive\noverfitting. The remaining three test sets are constructed from New York Times\narticles, Reddit posts, and Amazon product reviews and measure robustness to\nnatural distribution shifts. Across a broad range of models, we observe average\nperformance drops of 3.8, 14.0, and 17.4 F1 points, respectively. In contrast,\na strong human baseline matches or exceeds the performance of SQuAD models on\nthe original domain and exhibits little to no drop in new domains. Taken\ntogether, our results confirm the surprising resilience of the holdout method\nand emphasize the need to move towards evaluation metrics that incorporate\nrobustness to natural distribution shifts.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 19:34:19 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Miller", "John", ""], ["Krauth", "Karl", ""], ["Recht", "Benjamin", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "2004.14480", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Prasanna Sattigeri, Deepta Rajan and Bindya\n  Venkatesh", "title": "Calibrating Healthcare AI: Towards Reliable and Interpretable Deep\n  Predictive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide-spread adoption of representation learning technologies in clinical\ndecision making strongly emphasizes the need for characterizing model\nreliability and enabling rigorous introspection of model behavior. While the\nformer need is often addressed by incorporating uncertainty quantification\nstrategies, the latter challenge is addressed using a broad class of\ninterpretability techniques. In this paper, we argue that these two objectives\nare not necessarily disparate and propose to utilize prediction calibration to\nmeet both objectives. More specifically, our approach is comprised of a\ncalibration-driven learning method, which is also used to design an\ninterpretability technique based on counterfactual reasoning. Furthermore, we\nintroduce \\textit{reliability plots}, a holistic evaluation mechanism for model\nreliability. Using a lesion classification problem with dermoscopy images, we\ndemonstrate the effectiveness of our approach and infer interesting insights\nabout the model behavior.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 22:15:17 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Sattigeri", "Prasanna", ""], ["Rajan", "Deepta", ""], ["Venkatesh", "Bindya", ""]]}, {"id": "2004.14500", "submitter": "Jung Taehee", "authors": "Taehee Jung, Dongyeop Kang, Hua Cheng, Lucas Mentch, Thomas Schaaf", "title": "Posterior Calibrated Training on Sentence Classification Tasks", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most classification models work by first predicting a posterior probability\ndistribution over all classes and then selecting that class with the largest\nestimated probability. In many settings however, the quality of posterior\nprobability itself (e.g., 65% chance having diabetes), gives more reliable\ninformation than the final predicted class alone. When these methods are shown\nto be poorly calibrated, most fixes to date have relied on posterior\ncalibration, which rescales the predicted probabilities but often has little\nimpact on final classifications. Here we propose an end-to-end training\nprocedure called posterior calibrated (PosCal) training that directly optimizes\nthe objective while minimizing the difference between the predicted and\nempirical posterior probabilities.We show that PosCal not only helps reduce the\ncalibration error but also improve task performance by penalizing drops in\nperformance of both objectives. Our PosCal achieves about 2.5% of task\nperformance gain and 16.1% of calibration error reduction on GLUE (Wang et al.,\n2018) compared to the baseline. We achieved the comparable task performance\nwith 13.2% calibration error reduction on xSLUE (Kang and Hovy, 2019), but not\noutperforming the two-stage calibration baseline. PosCal training can be easily\nextendable to any types of classification tasks as a form of regularization\nterm. Also, PosCal has the advantage that it incrementally tracks needed\nstatistics for the calibration objective during the training process, making\nefficient use of large training sets.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 22:13:15 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 16:26:16 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Jung", "Taehee", ""], ["Kang", "Dongyeop", ""], ["Cheng", "Hua", ""], ["Mentch", "Lucas", ""], ["Schaaf", "Thomas", ""]]}, {"id": "2004.14528", "submitter": "Jugurta Montalv\\~ao", "authors": "Jugurta Montalv\\~ao, J\\^anio Canuto, Luiz Miranda", "title": "Bias-corrected estimator for intrinsic dimension and differential\n  entropy--a visual multiscale approach", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic dimension and differential entropy estimators are studied in this\npaper, including their systematic bias. A pragmatic approach for joint\nestimation and bias correction of these two fundamental measures is proposed.\nShared steps on both estimators are highlighted, along with their useful\nconsequences to data analysis. It is shown that both estimators can be\ncomplementary parts of a single approach, and that the simultaneous estimation\nof differential entropy and intrinsic dimension give meaning to each other,\nwhere estimates at different observation scales convey different perspectives\nof underlying manifolds. Experiments with synthetic and real datasets are\npresented to illustrate how to extract meaning from visual inspections, and how\nto compensate for biases.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 00:29:28 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Montalv\u00e3o", "Jugurta", ""], ["Canuto", "J\u00e2nio", ""], ["Miranda", "Luiz", ""]]}, {"id": "2004.14531", "submitter": "Xiaodong Li", "authors": "Lihua Lei, Xiaodong Li, and Xingmei Lou", "title": "Consistency of Spectral Clustering on Hierarchical Stochastic Block\n  Models", "comments": "34 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic network model, based on the Stochastic Block Model, to\nstudy the hierarchy of communities in real-world networks, under which the\nconnection probabilities are structured in a binary tree. Under the network\nmodel, we show that the eigenstructure of the expected unnormalized graph\nLaplacian reveals the community structure of the network as well as the\nhierarchy of communities in a recursive fashion. Inspired by the nice property\nof the population eigenstructure, we develop a recursive bi-partitioning\nalgorithm that divides the network into two communities based on the Fiedler\nvector of the unnormalized graph Laplacian and repeats the split until a\nstopping rule indicates no further community structures. We prove the weak and\nstrong consistency of our algorithm for sparse networks with the expected node\ndegree in $O(\\log n)$ order, based on newly developed theory on\n$\\ell_{2\\rightarrow\\infty}$ eigenspace perturbation, without knowing the total\nnumber of communities in advance. Unlike most of existing work, our theory\ncovers multi-scale networks where the connection probabilities may differ in\norder of magnitude, which comprise an important class of models that are\npractically relevant but technically challenging to deal with. Finally we\ndemonstrate the performance of our algorithm on synthetic data and real-world\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 01:08:59 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lei", "Lihua", ""], ["Li", "Xiaodong", ""], ["Lou", "Xingmei", ""]]}, {"id": "2004.14539", "submitter": "Zihang Meng", "authors": "Zihang Meng, Sathya N. Ravi, Vikas Singh", "title": "Physarum Powered Differentiable Linear Programming Layers and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a learning algorithm, which involves an internal call to an\noptimization routine such as a generalized eigenvalue problem, a cone\nprogramming problem or even sorting. Integrating such a method as a layer(s)\nwithin a trainable deep neural network (DNN) in an efficient and numerically\nstable way is not straightforward -- for instance, only recently, strategies\nhave emerged for eigendecomposition and differentiable sorting. We propose an\nefficient and differentiable solver for general linear programming problems\nwhich can be used in a plug and play manner within DNNs as a layer. Our\ndevelopment is inspired by a fascinating but not widely used link between\ndynamics of slime mold (physarum) and optimization schemes such as steepest\ndescent. We describe our development and show the use of our solver in a video\nsegmentation task and meta-learning for few-shot learning. We review the\nexisting results and provide a technical analysis describing its applicability\nfor our use cases. Our solver performs comparably with a customized projected\ngradient descent method on the first task and outperforms the differentiable\nCVXPY-SCS solver on the second task. Experiments show that our solver converges\nquickly without the need for a feasible initial point. Our proposal is easy to\nimplement and can easily serve as layers whenever a learning procedure needs a\nfast approximate solution to a LP, within a larger network.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 01:50:37 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 17:21:06 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Meng", "Zihang", ""], ["Ravi", "Sathya N.", ""], ["Singh", "Vikas", ""]]}, {"id": "2004.14545", "submitter": "Ning Xie", "authors": "Ning Xie, Gabrielle Ras, Marcel van Gerven, Derek Doran", "title": "Explainable Deep Learning: A Field Guide for the Uninitiated", "comments": "Survey paper on Explainable Deep Learning, 54 pages including\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) is an indispensable machine learning tool for\nachieving human-level performance on many learning tasks. Yet, due to its\nblack-box nature, it is inherently difficult to understand which aspects of the\ninput data drive the decisions of the network. There are various real-world\nscenarios in which humans need to make actionable decisions based on the output\nDNNs. Such decision support systems can be found in critical domains, such as\nlegislation, law enforcement, etc. It is important that the humans making\nhigh-level decisions can be sure that the DNN decisions are driven by\ncombinations of data features that are appropriate in the context of the\ndeployment of the decision support system and that the decisions made are\nlegally or ethically defensible. Due to the incredible pace at which DNN\ntechnology is being developed, the development of new methods and studies on\nexplaining the decision-making process of DNNs has blossomed into an active\nresearch field. A practitioner beginning to study explainable deep learning may\nbe intimidated by the plethora of orthogonal directions the field is taking.\nThis complexity is further exacerbated by the general confusion that exists in\ndefining what it means to be able to explain the actions of a deep learning\nsystem and to evaluate a system's \"ability to explain\". To alleviate this\nproblem, this article offers a \"field guide\" to deep learning explainability\nfor those uninitiated in the field. The field guide: i) Discusses the traits of\na deep learning system that researchers enhance in explainability research, ii)\nplaces explainability in the context of other related deep learning research\nareas, and iii) introduces three simple dimensions defining the space of\nfoundational methods that contribute to explainable deep learning. The guide is\ndesigned as an easy-to-digest starting point for those just embarking in the\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:09:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Xie", "Ning", ""], ["Ras", "Gabrielle", ""], ["van Gerven", "Marcel", ""], ["Doran", "Derek", ""]]}, {"id": "2004.14567", "submitter": "Max Pflueger", "authors": "Max Pflueger and Gaurav S. Sukhatme", "title": "Plan-Space State Embeddings for Improved Reinforcement Learning", "comments": "Submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot control problems are often structured with a policy function that maps\nstate values into control values, but in many dynamic problems the observed\nstate can have a difficult to characterize relationship with useful policy\nactions. In this paper we present a new method for learning state embeddings\nfrom plans or other forms of demonstrations such that the embedding space has a\nspecified geometric relationship with the demonstrations. We present a novel\nvariational framework for learning these embeddings that attempts to optimize\ntrajectory linearity in the learned embedding space. We show how these\nembedding spaces can then be used as an augmentation to the robot state in\nreinforcement learning problems. We use kinodynamic planning to generate\ntraining trajectories for some example environments, and then train embedding\nspaces for these environments. We show empirically that observing a system in\nthe learned embedding space improves the performance of policy gradient\nreinforcement learning algorithms, particularly by reducing the variance\nbetween training runs. Our technique is limited to environments where\ndemonstration data is available, but places no limits on how that data is\ncollected. Our embedding technique provides a way to transfer domain knowledge\nfrom existing technologies such as planning and control algorithms, into more\nflexible policy learning algorithms, by creating an abstract representation of\nthe robot state with meaningful geometry.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 03:38:14 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Pflueger", "Max", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2004.14584", "submitter": "Ragav Venkatesan", "authors": "Ragav Venkatesan, Gurumurthy Swaminathan, Xiong Zhou, Anna Luo", "title": "Out-of-the-box channel pruned networks", "comments": "Under review at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade convolutional neural networks have become gargantuan.\nPre-trained models, when used as initializers are able to fine-tune ever larger\nnetworks on small datasets. Consequently, not all the convolutional features\nthat these fine-tuned models detect are requisite for the end-task. Several\nworks of channel pruning have been proposed to prune away compute and memory\nfrom models that were trained already. Typically, these involve policies that\ndecide which and how many channels to remove from each layer leading to\nchannel-wise and/or layer-wise pruning profiles, respectively. In this paper,\nwe conduct several baseline experiments and establish that profiles from random\nchannel-wise pruning policies are as good as metric-based ones. We also\nestablish that there may exist profiles from some layer-wise pruning policies\nthat are measurably better than common baselines. We then demonstrate that the\ntop layer-wise pruning profiles found using an exhaustive random search from\none datatset are also among the top profiles for other datasets. This implies\nthat we could identify out-of-the-box layer-wise pruning profiles using\nbenchmark datasets and use these directly for new datasets. Furthermore, we\ndevelop a Reinforcement Learning (RL) policy-based search algorithm with a\ndirect objective of finding transferable layer-wise pruning profiles using many\nmodels for the same architecture. We use a novel reward formulation that drives\nthis RL search towards an expected compression while maximizing accuracy. Our\nresults show that our transferred RL-based profiles are as good or better than\nbest profiles found on the original dataset via exhaustive search. We then\ndemonstrate that if we found the profiles using a mid-sized dataset such as\nCifar10/100, we are able to transfer them to even a large dataset such as\nImagenet.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 04:40:47 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Venkatesan", "Ragav", ""], ["Swaminathan", "Gurumurthy", ""], ["Zhou", "Xiong", ""], ["Luo", "Anna", ""]]}, {"id": "2004.14593", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "A Triangular Network For Density Estimation", "comments": "Supplements like code at https://github.com/lixilinx/TriNet4PdfEst", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a triangular neural network implementation of neural autoregressive\nflow (NAF). Unlike many universal autoregressive density models, our design is\nhighly modular, parameter economy, computationally efficient, and applicable to\ndensity estimation of data with high dimensions. It achieves state-of-the-art\nbits-per-dimension indices on MNIST and CIFAR-10 (about 1.1 and 3.7,\nrespectively) in the category of general-purpose density estimators.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 06:01:40 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 05:12:09 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "2004.14615", "submitter": "Luc Le Magoarou", "authors": "Luc Le Magoarou (IRT b-com), St\\'ephane Paquelet (IRT b-com)", "title": "Online unsupervised deep unfolding for MIMO channel estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel estimation is a difficult problem in MIMO systems. Using a physical\nmodel allows to ease the problem, injecting a priori information based on the\nphysics of propagation. However, such models rest on simplifying assumptions\nand require to know precisely the system configuration, which is unrealistic.In\nthis paper, we propose to perform online learning for channel estimation in a\nmassive MIMO context, adding flexibility to physical models by unfolding a\nchannel estimation algorithm (matching pursuit) as a neural network. This leads\nto a computationally efficient neural network that can be trained online when\ninitialized with an imperfect model. The method allows a base station to\nautomatically correct its channel estimation algorithm based on incoming data,\nwithout the need for a separate offline training phase.It is applied to\nrealistic channels and shows great performance, achieving channel estimation\nerror almost as low as one would get with a perfectly calibrated system.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 07:32:58 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:12:15 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 13:59:48 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 07:56:36 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Magoarou", "Luc Le", "", "IRT b-com"], ["Paquelet", "St\u00e9phane", "", "IRT b-com"]]}, {"id": "2004.14637", "submitter": "Martin Hellkvist", "authors": "Martin Hellkvist and Ay\\c{c}a \\\"Oz\\c{c}elikkale and Anders Ahl\\'en", "title": "Generalization Error for Linear Regression under Distributed Learning", "comments": "Comments: updated typo in author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning facilitates the scaling-up of data processing by\ndistributing the computational burden over several nodes. Despite the vast\ninterest in distributed learning, generalization performance of such approaches\nis not well understood. We address this gap by focusing on a linear regression\nsetting. We consider the setting where the unknowns are distributed over a\nnetwork of nodes. We present an analytical characterization of the dependence\nof the generalization error on the partitioning of the unknowns over nodes. In\nparticular, for the overparameterized case, our results show that while the\nerror on training data remains in the same range as that of the centralized\nsolution, the generalization error of the distributed solution increases\ndramatically compared to that of the centralized solution when the number of\nunknowns estimated at any node is close to the number of observations. We\nfurther provide numerical examples to verify our analytical expressions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 08:49:46 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 05:23:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hellkvist", "Martin", ""], ["\u00d6z\u00e7elikkale", "Ay\u00e7a", ""], ["Ahl\u00e9n", "Anders", ""]]}, {"id": "2004.14660", "submitter": "Yici Chen", "authors": "Yici Chen, Kenichiro Tanaka", "title": "Maximum likelihood estimation of the Fisher-Bingham distribution via\n  efficient calculation of its normalizing constant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient numerical integration formula to compute the\nnormalizing constant of Fisher--Bingham distributions. This formula uses a\nnumerical integration formula with the continuous Euler transform to a\nFourier-type integral representation of the normalizing constant. As this\nmethod is fast and accurate, it can be applied to the calculation of the\nnormalizing constant of high-dimensional Fisher--Bingham distributions. More\nprecisely, the error decays exponentially with an increase in the integration\npoints, and the computation cost increases linearly with the dimensions. In\naddition, this formula is useful for calculating the gradient and Hessian\nmatrix of the normalizing constant. Therefore, we apply this formula to\nefficiently calculate the maximum likelihood estimation (MLE) of\nhigh-dimensional data. Finally, we apply the MLE to the hyperspherical\nvariational auto-encoder (S-VAE), a deep-learning-based generative model that\nrestricts the latent space to a unit hypersphere. We use the S-VAE trained with\nimages of handwritten numbers to estimate the distributions of each label. This\napplication is useful for adding new labels to the models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:47:10 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Chen", "Yici", ""], ["Tanaka", "Kenichiro", ""]]}, {"id": "2004.14681", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Alexander Rakhlin, Tuhin Sarkar", "title": "Learning nonlinear dynamical systems from a single trajectory", "comments": "To appear at L4DC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce algorithms for learning nonlinear dynamical systems of the form\n$x_{t+1}=\\sigma(\\Theta^{\\star}x_t)+\\varepsilon_t$, where $\\Theta^{\\star}$ is a\nweight matrix, $\\sigma$ is a nonlinear link function, and $\\varepsilon_t$ is a\nmean-zero noise process. We give an algorithm that recovers the weight matrix\n$\\Theta^{\\star}$ from a single trajectory with optimal sample complexity and\nlinear running time. The algorithm succeeds under weaker statistical\nassumptions than in previous work, and in particular i) does not require a\nbound on the spectral norm of the weight matrix $\\Theta^{\\star}$ (rather, it\ndepends on a generalization of the spectral radius) and ii) enjoys guarantees\nfor non-strictly-increasing link functions such as the ReLU. Our analysis has\ntwo key components: i) we give a general recipe whereby global stability for\nnonlinear dynamical systems can be used to certify that the state-vector\ncovariance is well-conditioned, and ii) using these tools, we extend well-known\nalgorithms for efficiently learning generalized linear models to the dependent\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 10:42:48 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""], ["Sarkar", "Tuhin", ""]]}, {"id": "2004.14705", "submitter": "Yuheng Jia", "authors": "Yuheng Jia, Hui Liu, Junhui Hou, Sam Kwong, Qingfu Zhang", "title": "Multi-View Spectral Clustering Tailored Tensor Low-Rank Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of multi-view spectral clustering (MVSC)\nbased on tensor low-rank modeling. Unlike the existing methods that all adopt\nan off-the-shelf tensor low-rank norm without considering the special\ncharacteristics of the tensor in MVSC, we design a novel structured tensor\nlow-rank norm tailored to MVSC. Specifically, we explicitly impose a symmetric\nlow-rank constraint and a structured sparse low-rank constraint on the frontal\nand horizontal slices of the tensor to characterize the intra-view and\ninter-view relationships, respectively. Moreover, the two constraints could be\njointly optimized to achieve mutual refinement. On the basis of the novel\ntensor low-rank norm, we formulate MVSC as a convex low-rank tensor recovery\nproblem, which is then efficiently solved with an augmented Lagrange multiplier\nbased method iteratively. Extensive experimental results on five benchmark\ndatasets show that the proposed method outperforms state-of-the-art methods to\na significant extent. Impressively, our method is able to produce perfect\nclustering. In addition, the parameters of our method can be easily tuned, and\nthe proposed model is robust to different datasets, demonstrating its potential\nin practice.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:52:12 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 13:35:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Jia", "Yuheng", ""], ["Liu", "Hui", ""], ["Hou", "Junhui", ""], ["Kwong", "Sam", ""], ["Zhang", "Qingfu", ""]]}, {"id": "2004.14717", "submitter": "Viacheslav Osaulenko", "authors": "Viacheslav Osaulenko", "title": "Binary autoencoder with random binary weights", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here is presented an analysis of an autoencoder with binary activations $\\{0,\n1\\}$ and binary $\\{0, 1\\}$ random weights. Such set up puts this model at the\nintersection of different fields: neuroscience, information theory, sparse\ncoding, and machine learning. It is shown that the sparse activation of the\nhidden layer arises naturally in order to preserve information between layers.\nFurthermore, with a large enough hidden layer, it is possible to get zero\nreconstruction error for any input just by varying the thresholds of neurons.\nThe model preserves the similarity of inputs at the hidden layer that is\nmaximal for the dense hidden layer activation. By analyzing the mutual\ninformation between layers it is shown that the difference between sparse and\ndense representations is related to a memory-computation trade-off. The model\nis similar to an olfactory perception system of a fruit fly, and the presented\ntheoretical results give useful insights toward understanding more complex\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:13:19 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Osaulenko", "Viacheslav", ""]]}, {"id": "2004.14723", "submitter": "Pierre Lison", "authors": "Pierre Lison, Aliaksandr Hubin, Jeremy Barnes, and Samia Touileb", "title": "Named Entity Recognition without Labelled Data: A Weak Supervision\n  Approach", "comments": "Accepted to ACL 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) performance often degrades rapidly when\napplied to target domains that differ from the texts observed during training.\nWhen in-domain labelled data is available, transfer learning techniques can be\nused to adapt existing NER models to the target domain. But what should one do\nwhen there is no hand-labelled data for the target domain? This paper presents\na simple but powerful approach to learn NER models in the absence of labelled\ndata through weak supervision. The approach relies on a broad spectrum of\nlabelling functions to automatically annotate texts from the target domain.\nThese annotations are then merged together using a hidden Markov model which\ncaptures the varying accuracies and confusions of the labelling functions. A\nsequence labelling model can finally be trained on the basis of this unified\nannotation. We evaluate the approach on two English datasets (CoNLL 2003 and\nnews articles from Reuters and Bloomberg) and demonstrate an improvement of\nabout 7 percentage points in entity-level $F_1$ scores compared to an\nout-of-domain neural NER model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:29:55 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lison", "Pierre", ""], ["Hubin", "Aliaksandr", ""], ["Barnes", "Jeremy", ""], ["Touileb", "Samia", ""]]}, {"id": "2004.14756", "submitter": "Matthew Mirman", "authors": "Matthew Mirman, Timon Gehr, Martin Vechev", "title": "Robustness Certification of Generative Models", "comments": "Prior version submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative neural networks can be used to specify continuous transformations\nbetween images via latent-space interpolation. However, certifying that all\nimages captured by the resulting path in the image manifold satisfy a given\nproperty can be very challenging. This is because this set is highly\nnon-convex, thwarting existing scalable robustness analysis methods, which are\noften based on convex relaxations. We present ApproxLine, a scalable\ncertification method that successfully verifies non-trivial specifications\ninvolving generative models and classifiers. ApproxLine can provide both sound\ndeterministic and probabilistic guarantees, by capturing either infinite\nnon-convex sets of neural network activation vectors or distributions over such\nsets. We show that ApproxLine is practically useful and can verify interesting\ninterpolations in the networks latent space.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:23:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Mirman", "Matthew", ""], ["Gehr", "Timon", ""], ["Vechev", "Martin", ""]]}, {"id": "2004.14758", "submitter": "Serhii Havrylov", "authors": "Serhii Havrylov, Ivan Titov", "title": "Preventing Posterior Collapse with Levenshtein Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are a standard framework for inducing latent\nvariable models that have been shown effective in learning text representations\nas well as in text generation. The key challenge with using VAEs is the {\\it\nposterior collapse} problem: learning tends to converge to trivial solutions\nwhere the generators ignore latent variables. In our Levenstein VAE, we propose\nto replace the evidence lower bound (ELBO) with a new objective which is simple\nto optimize and prevents posterior collapse. Intuitively, it corresponds to\ngenerating a sequence from the autoencoder and encouraging the model to predict\nan optimal continuation according to the Levenshtein distance (LD) with the\nreference sentence at each time step in the generated sequence. We motivate the\nmethod from the probabilistic perspective by showing that it is closely related\nto optimizing a bound on the intractable Kullback-Leibler divergence of an\nLD-based kernel density estimator from the model distribution. With this\nobjective, any generator disregarding latent variables will incur large\npenalties and hence posterior collapse does not happen. We relate our approach\nto policy distillation \\cite{RossGB11} and dynamic oracles \\cite{GoldbergN12}.\nBy considering Yelp and SNLI benchmarks, we show that Levenstein VAE produces\nmore informative latent representations than alternative approaches to\npreventing posterior collapse.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:27:26 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Havrylov", "Serhii", ""], ["Titov", "Ivan", ""]]}, {"id": "2004.14774", "submitter": "Qi She", "authors": "Qi She, Fan Feng, Qi Liu, Rosa H. M. Chan, Xinyue Hao, Chuanlin Lan,\n  Qihan Yang, Vincenzo Lomonaco, German I. Parisi, Heechul Bae, Eoin Brophy,\n  Baoquan Chen, Gabriele Graffieti, Vidit Goel, Hyonyoung Han, Sathursan\n  Kanagarajah, Somesh Kumar, Siew-Kei Lam, Tin Lun Lam, Liang Ma, Davide\n  Maltoni, Lorenzo Pellegrini, Duvindu Piyasena, Shiliang Pu, Debdoot Sheet,\n  Soonyong Song, Youngsung Son, Zhengwei Wang, Tomas E. Ward, Jianwen Wu,\n  Meiqing Wu, Di Xie, Yangsheng Xu, Lin Yang, Qiaoyong Zhong, Liguang Zhou", "title": "IROS 2019 Lifelong Robotic Vision Challenge -- Lifelong Object\n  Recognition Report", "comments": "9 pages, 11 figures, 3 tables, accepted into IEEE Robotics and\n  Automation Magazine. arXiv admin note: text overlap with arXiv:1911.06487", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report summarizes IROS 2019-Lifelong Robotic Vision Competition\n(Lifelong Object Recognition Challenge) with methods and results from the top\n$8$ finalists (out of over~$150$ teams). The competition dataset (L)ifel(O)ng\n(R)obotic V(IS)ion (OpenLORIS) - Object Recognition (OpenLORIS-object) is\ndesigned for driving lifelong/continual learning research and application in\nrobotic vision domain, with everyday objects in home, office, campus, and mall\nscenarios. The dataset explicitly quantifies the variants of illumination,\nobject occlusion, object size, camera-object distance/angles, and clutter\ninformation. Rules are designed to quantify the learning capability of the\nrobotic vision system when faced with the objects appearing in the dynamic\nenvironments in the contest. Individual reports, dataset information, rules,\nand released source code can be found at the project homepage:\n\"https://lifelong-robotic-vision.github.io/competition/\".\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:33:55 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["She", "Qi", ""], ["Feng", "Fan", ""], ["Liu", "Qi", ""], ["Chan", "Rosa H. M.", ""], ["Hao", "Xinyue", ""], ["Lan", "Chuanlin", ""], ["Yang", "Qihan", ""], ["Lomonaco", "Vincenzo", ""], ["Parisi", "German I.", ""], ["Bae", "Heechul", ""], ["Brophy", "Eoin", ""], ["Chen", "Baoquan", ""], ["Graffieti", "Gabriele", ""], ["Goel", "Vidit", ""], ["Han", "Hyonyoung", ""], ["Kanagarajah", "Sathursan", ""], ["Kumar", "Somesh", ""], ["Lam", "Siew-Kei", ""], ["Lam", "Tin Lun", ""], ["Ma", "Liang", ""], ["Maltoni", "Davide", ""], ["Pellegrini", "Lorenzo", ""], ["Piyasena", "Duvindu", ""], ["Pu", "Shiliang", ""], ["Sheet", "Debdoot", ""], ["Song", "Soonyong", ""], ["Son", "Youngsung", ""], ["Wang", "Zhengwei", ""], ["Ward", "Tomas E.", ""], ["Wu", "Jianwen", ""], ["Wu", "Meiqing", ""], ["Xie", "Di", ""], ["Xu", "Yangsheng", ""], ["Yang", "Lin", ""], ["Zhong", "Qiaoyong", ""], ["Zhou", "Liguang", ""]]}, {"id": "2004.14777", "submitter": "Lambert Leong", "authors": "Lambert T. Leong, Sean Wiere", "title": "Digit Recognition From Wrist Movements and Security Concerns with Smart\n  Wrist Wearable IOT Devices", "comments": "7 pages, 5 figures, 10 tables, in Proc Hawaii International\n  Conference on System Science (HICSS)", "journal-ref": null, "doi": "10.24251/HICSS.2020.790", "report-no": "978-0-9981331-3-3", "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a potential security vulnerability associated\nwith wrist wearable devices. Hardware components on common wearable devices\ninclude an accelerometer and gyroscope, among other sensors. We demonstrate\nthat an accelerometer and gyroscope can pick up enough unique wrist movement\ninformation to identify digits being written by a user. With a data set of 400\nwriting samples, of either the digit zero or the digit one, we constructed a\nmachine learning model to correctly identify the digit being written based on\nthe movements of the wrist. Our model's performance on an unseen test set\nresulted in an area under the receiver operating characteristic (AUROC) curve\nof 1.00. Loading our model onto our fabricated device resulted in 100% accuracy\nwhen predicting ten writing samples in real-time. The model's ability to\ncorrectly identify all digits via wrist movement and orientation changes raises\nsecurity concerns. Our results imply that nefarious individuals may be able to\ngain sensitive digit based information such as social security, credit card,\nand medical record numbers from wrist wearable devices.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 23:37:38 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Leong", "Lambert T.", ""], ["Wiere", "Sean", ""]]}, {"id": "2004.14823", "submitter": "Shangzhi Hong", "authors": "Shangzhi Hong, Yuqi Sun, Hanying Li, Henry S. Lynn", "title": "Multiple imputation using chained random forests: a preliminary study\n  based on the empirical distribution of out-of-bag prediction errors", "comments": "Initial version, 6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data are common in data analyses in biomedical fields, and imputation\nmethods based on random forests (RF) have become widely accepted, as the RF\nalgorithm can achieve high accuracy without the need for specification of data\ndistributions or relationships. However, the predictions from RF do not contain\ninformation about prediction uncertainty, which was unacceptable for multiple\nimputation. Available RF-based multiple imputation methods tried to do proper\nmultiple imputation either by sampling directly from observations under\npredicting nodes without accounting for the prediction error or by making\nnormality assumption about the prediction error distribution. In this study, a\nnovel RF-based multiple imputation method was proposed by constructing\nconditional distributions the empirical distribution of out-of-bag prediction\nerrors. The proposed method was compared with previous method with parametric\nassumptions about RF's prediction errors and predictive mean matching based on\nsimulation studies on data with presence of interaction term. The proposed\nnon-parametric method can deliver valid multiple imputation results. The\naccompanying R package for this study is publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:29:56 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Hong", "Shangzhi", ""], ["Sun", "Yuqi", ""], ["Li", "Hanying", ""], ["Lynn", "Henry S.", ""]]}, {"id": "2004.14826", "submitter": "Amir Hossein Kargaran", "authors": "Amir Hossein Kargaran, Mohammad Sadegh Akhondzadeh, Mohammad Reza\n  Heidarpour, Mohammad Hossein Manshaei, Kave Salamatian, Masoud Nejad Sattary", "title": "Wide-AdGraph: Detecting Ad Trackers with a Wide Dependency Chain Graph", "comments": "9 pages, 7 figures, To appear in the 13th ACM Web Science Conference\n  2021 (WebSci '21), June 2021", "journal-ref": null, "doi": "10.1145/3447535.3462549", "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Websites use third-party ads and tracking services to deliver targeted ads\nand collect information about users that visit them. These services put users'\nprivacy at risk, and that is why users' demand for blocking these services is\ngrowing. Most of the blocking solutions rely on crowd-sourced filter lists\nmanually maintained by a large community of users. In this work, we seek to\nsimplify the update of these filter lists by combining different websites\nthrough a large-scale graph connecting all resource requests made over a large\nset of sites. The features of this graph are extracted and used to train a\nmachine learning algorithm with the aim of detecting ads and tracking\nresources. As our approach combines different information sources, it is more\nrobust toward evasion techniques that use obfuscation or changing the usage\npatterns. We evaluate our work over the Alexa top-10K websites and find its\naccuracy to be 96.1% biased and 90.9% unbiased with high precision and recall.\nIt can also block new ads and tracking services, which would necessitate being\nblocked by further crowd-sourced existing filter lists. Moreover, the approach\nfollowed in this paper sheds light on the ecosystem of third-party tracking and\nadvertising.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:28:49 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 11:43:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kargaran", "Amir Hossein", ""], ["Akhondzadeh", "Mohammad Sadegh", ""], ["Heidarpour", "Mohammad Reza", ""], ["Manshaei", "Mohammad Hossein", ""], ["Salamatian", "Kave", ""], ["Sattary", "Masoud Nejad", ""]]}, {"id": "2004.14840", "submitter": "Georgios Paraskevopoulos", "authors": "Georgios Paraskevopoulos, Srinivas Parthasarathy, Aparna Khare, and\n  Shiva Sundaram", "title": "Multiresolution and Multimodal Speech Recognition with Transformers", "comments": "Accepted for ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an audio visual automatic speech recognition (AV-ASR)\nsystem using a Transformer-based architecture. We particularly focus on the\nscene context provided by the visual information, to ground the ASR. We extract\nrepresentations for audio features in the encoder layers of the transformer and\nfuse video features using an additional crossmodal multihead attention layer.\nAdditionally, we incorporate a multitask training criterion for multiresolution\nASR, where we train the model to generate both character and subword level\ntranscriptions.\n  Experimental results on the How2 dataset, indicate that multiresolution\ntraining can speed up convergence by around 50% and relatively improves word\nerror rate (WER) performance by upto 18% over subword prediction models.\nFurther, incorporating visual information improves performance with relative\ngains upto 3.76% over audio only models.\n  Our results are comparable to state-of-the-art Listen, Attend and Spell-based\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:32:11 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Paraskevopoulos", "Georgios", ""], ["Parthasarathy", "Srinivas", ""], ["Khare", "Aparna", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2004.14841", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM (UMR\\_8001)), G\\'erard Biau (LSTA),\n  S\\'ebastien da Veiga, Erwan Scornet (CMAP)", "title": "Interpretable Random Forests via Rule Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SIRUS (Stable and Interpretable RUle Set) for regression, a\nstable rule learning algorithm which takes the form of a short and simple list\nof rules. State-of-the-art learning algorithms are often referred to as \"black\nboxes\" because of the high number of operations involved in their prediction\nprocess. Despite their powerful predictivity, this lack of interpretability may\nbe highly restrictive for applications with critical decisions at stake. On the\nother hand, algorithms with a simple structure-typically decision trees, rule\nalgorithms, or sparse linear models-are well known for their instability. This\nundesirable feature makes the conclusions of the data analysis unreliable and\nturns out to be a strong operational limitation. This motivates the design of\nSIRUS, which combines a simple structure with a remarkable stable behavior when\ndata is perturbed. The algorithm is based on random forests, the predictive\naccuracy of which is preserved. We demonstrate the efficiency of the method\nboth empirically (through experiments) and theoretically (with the proof of its\nasymptotic stability). Our R/C++ software implementation sirus is available\nfrom CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:13:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:56:50 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 07:45:02 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 09:09:31 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["Biau", "G\u00e9rard", "", "LSTA"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "2004.14842", "submitter": "Dehua Chen", "authors": "Dehua Chen, Amir Jalilifard, Adriano Veloso, Nivio Ziviani", "title": "Modeling Pharmacological Effects with Multi-Relation Unsupervised Graph\n  Embedding", "comments": "Accepted at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pharmacological effect of a drug on cells, organs and systems refers to the\nspecific biochemical interaction produced by a drug substance, which is called\nits mechanism of action. Drug repositioning (or drug repurposing) is a\nfundamental problem for the identification of new opportunities for the use of\nalready approved or failed drugs. In this paper, we present a method based on a\nmulti-relation unsupervised graph embedding model that learns latent\nrepresentations for drugs and diseases so that the distance between these\nrepresentations reveals repositioning opportunities. Once representations for\ndrugs and diseases are obtained we learn the likelihood of new links (that is,\nnew indications) between drugs and diseases. Known drug indications are used\nfor learning a model that predicts potential indications. Compared with\nexisting unsupervised graph embedding methods our method shows superior\nprediction performance in terms of area under the ROC curve, and we present\nexamples of repositioning opportunities found on recent biomedical literature\nthat were also predicted by our method.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:51:25 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 23:30:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Dehua", ""], ["Jalilifard", "Amir", ""], ["Veloso", "Adriano", ""], ["Ziviani", "Nivio", ""]]}, {"id": "2004.14861", "submitter": "Nathan Inkawhich", "authors": "Nathan Inkawhich, Kevin J Liang, Binghui Wang, Matthew Inkawhich,\n  Lawrence Carin and Yiran Chen", "title": "Perturbing Across the Feature Hierarchy to Improve Standard and Strict\n  Blackbox Attack Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the blackbox transfer-based targeted adversarial attack threat\nmodel in the realm of deep neural network (DNN) image classifiers. Rather than\nfocusing on crossing decision boundaries at the output layer of the source\nmodel, our method perturbs representations throughout the extracted feature\nhierarchy to resemble other classes. We design a flexible attack framework that\nallows for multi-layer perturbations and demonstrates state-of-the-art targeted\ntransfer performance between ImageNet DNNs. We also show the superiority of our\nfeature space methods under a relaxation of the common assumption that the\nsource and target models are trained on the same dataset and label space, in\nsome instances achieving a $10\\times$ increase in targeted success rate\nrelative to other blackbox transfer methods. Finally, we analyze why the\nproposed methods outperform existing attack strategies and show an extension of\nthe method in the case when limited queries to the blackbox model are allowed.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:00:13 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Inkawhich", "Nathan", ""], ["Liang", "Kevin J", ""], ["Wang", "Binghui", ""], ["Inkawhich", "Matthew", ""], ["Carin", "Lawrence", ""], ["Chen", "Yiran", ""]]}, {"id": "2004.14862", "submitter": "Indranil SenGupta", "authors": "Humayra Shoshi and Indranil SenGupta", "title": "Hedging and machine learning driven crude oil data analysis using a\n  refined Barndorff-Nielsen and Shephard model", "comments": "27 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1911.13300", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a refined Barndorff-Nielsen and Shephard (BN-S) model is\nimplemented to find an optimal hedging strategy for commodity markets. The\nrefinement of the BN-S model is obtained with various machine and deep learning\nalgorithms. The refinement leads to the extraction of a deterministic parameter\nfrom the empirical data set. The problem is transformed to an appropriate\nclassification problem with a couple of different approaches: the volatility\napproach and the duration approach. The analysis is implemented to the Bakken\ncrude oil data and the aforementioned deterministic parameter is obtained for a\nwide range of data sets. With the implementation of this parameter in the\nrefined model, the resulting model performs much better than the classical BN-S\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:45:58 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 16:57:29 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 17:00:41 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Shoshi", "Humayra", ""], ["SenGupta", "Indranil", ""]]}, {"id": "2004.14884", "submitter": "Arthur Bra\\v{z}inskas", "authors": "Arthur Bra\\v{z}inskas, Mirella Lapata, Ivan Titov", "title": "Few-Shot Learning for Opinion Summarization", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization is the automatic creation of text reflecting subjective\ninformation expressed in multiple documents, such as user reviews of a product.\nThe task is practically important and has attracted a lot of attention.\nHowever, due to the high cost of summary production, datasets large enough for\ntraining supervised models are lacking. Instead, the task has been\ntraditionally approached with extractive methods that learn to select text\nfragments in an unsupervised or weakly-supervised way. Recently, it has been\nshown that abstractive summaries, potentially more fluent and better at\nreflecting conflicting information, can also be produced in an unsupervised\nfashion. However, these models, not being exposed to actual summaries, fail to\ncapture their essential properties. In this work, we show that even a handful\nof summaries is sufficient to bootstrap generation of the summary text with all\nexpected properties, such as writing style, informativeness, fluency, and\nsentiment preservation. We start by training a conditional Transformer language\nmodel to generate a new product review given other available reviews of the\nproduct. The model is also conditioned on review properties that are directly\nrelated to summaries; the properties are derived from reviews with no manual\neffort. In the second stage, we fine-tune a plug-in module that learns to\npredict property values on a handful of summaries. This lets us switch the\ngenerator to the summarization mode. We show on Amazon and Yelp datasets that\nour approach substantially outperforms previous extractive and abstractive\nmethods in automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:37:38 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 19:45:25 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 06:30:38 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Lapata", "Mirella", ""], ["Titov", "Ivan", ""]]}, {"id": "2004.14941", "submitter": "Ziv Goldfeld", "authors": "Ziv Goldfeld and Yury Polyanskiy", "title": "The Information Bottleneck Problem and Its Applications in Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference capabilities of machine learning (ML) systems skyrocketed in recent\nyears, now playing a pivotal role in various aspect of society. The goal in\nstatistical learning is to use data to obtain simple algorithms for predicting\na random variable $Y$ from a correlated observation $X$. Since the dimension of\n$X$ is typically huge, computationally feasible solutions should summarize it\ninto a lower-dimensional feature vector $T$, from which $Y$ is predicted. The\nalgorithm will successfully make the prediction if $T$ is a good proxy of $Y$,\ndespite the said dimensionality-reduction. A myriad of ML algorithms (mostly\nemploying deep learning (DL)) for finding such representations $T$ based on\nreal-world data are now available. While these methods are often effective in\npractice, their success is hindered by the lack of a comprehensive theory to\nexplain it. The information bottleneck (IB) theory recently emerged as a bold\ninformation-theoretic paradigm for analyzing DL systems. Adopting mutual\ninformation as the figure of merit, it suggests that the best representation\n$T$ should be maximally informative about $Y$ while minimizing the mutual\ninformation with $X$. In this tutorial we survey the information-theoretic\norigins of this abstract principle, and its recent impact on DL. For the\nlatter, we cover implications of the IB problem on DL theory, as well as\npractical algorithms inspired by it. Our goal is to provide a unified and\ncohesive description. A clear view of current knowledge is particularly\nimportant for further leveraging IB and other information-theoretic ideas to\nstudy DL models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:48:51 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 16:24:03 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Goldfeld", "Ziv", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "2004.14954", "submitter": "Guang Cheng", "authors": "Ruiqi Liu, Zuofeng Shang, Guang Cheng", "title": "On Deep Instrumental Variables Estimate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The endogeneity issue is fundamentally important as many empirical\napplications may suffer from the omission of explanatory variables, measurement\nerror, or simultaneous causality. Recently, \\cite{hllt17} propose a \"Deep\nInstrumental Variable (IV)\" framework based on deep neural networks to address\nendogeneity, demonstrating superior performances than existing approaches. The\naim of this paper is to theoretically understand the empirical success of the\nDeep IV. Specifically, we consider a two-stage estimator using deep neural\nnetworks in the linear instrumental variables model. By imposing a latent\nstructural assumption on the reduced form equation between endogenous variables\nand instrumental variables, the first-stage estimator can automatically capture\nthis latent structure and converge to the optimal instruments at the minimax\noptimal rate, which is free of the dimension of instrumental variables and thus\nmitigates the curse of dimensionality. Additionally, in comparison with\nclassical methods, due to the faster convergence rate of the first-stage\nestimator, the second-stage estimator has {a smaller (second order) estimation\nerror} and requires a weaker condition on the smoothness of the optimal\ninstruments. Given that the depth and width of the employed deep neural network\nare well chosen, we further show that the second-stage estimator achieves the\nsemiparametric efficiency bound. Simulation studies on synthetic data and\napplication to automobile market data confirm our theory.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:03:00 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Liu", "Ruiqi", ""], ["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "2004.14958", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka, Eneko\n  Agirre", "title": "A Call for More Rigor in Unsupervised Cross-lingual Learning", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review motivations, definition, approaches, and methodology for\nunsupervised cross-lingual learning and call for a more rigorous position in\neach of them. An existing rationale for such research is based on the lack of\nparallel data for many of the world's languages. However, we argue that a\nscenario without any parallel data and abundant monolingual data is unrealistic\nin practice. We also discuss different training signals that have been used in\nprevious work, which depart from the pure unsupervised setting. We then\ndescribe common methodological issues in tuning and evaluation of unsupervised\ncross-lingual models and present best practices. Finally, we provide a unified\noutlook for different types of research in this area (i.e., cross-lingual word\nembeddings, deep multilingual pretraining, and unsupervised machine\ntranslation) and argue for comparable evaluation of these models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:06:23 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Artetxe", "Mikel", ""], ["Ruder", "Sebastian", ""], ["Yogatama", "Dani", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "2004.14990", "submitter": "Kimin Lee", "authors": "Michael Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel,\n  and Aravind Srinivas", "title": "Reinforcement Learning with Augmented Data", "comments": "NeurIPS 2020 camera-ready version. First two authors contributed\n  equally, website: https://mishalaskin.github.io/rad code:\n  https://github.com/MishaLaskin/rad and\n  https://github.com/pokaxpoka/rad_procgen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from visual observations is a fundamental yet challenging problem in\nReinforcement Learning (RL). Although algorithmic advances combined with\nconvolutional neural networks have proved to be a recipe for success, current\nmethods are still lacking on two fronts: (a) data-efficiency of learning and\n(b) generalization to new environments. To this end, we present Reinforcement\nLearning with Augmented Data (RAD), a simple plug-and-play module that can\nenhance most RL algorithms. We perform the first extensive study of general\ndata augmentations for RL on both pixel-based and state-based inputs, and\nintroduce two new data augmentations - random translate and random amplitude\nscale. We show that augmentations such as random translate, crop, color jitter,\npatch cutout, random convolutions, and amplitude scale can enable simple RL\nalgorithms to outperform complex state-of-the-art methods across common\nbenchmarks. RAD sets a new state-of-the-art in terms of data-efficiency and\nfinal performance on the DeepMind Control Suite benchmark for pixel-based\ncontrol as well as OpenAI Gym benchmark for state-based control. We further\ndemonstrate that RAD significantly improves test-time generalization over\nexisting methods on several OpenAI ProcGen benchmarks. Our RAD module and\ntraining code are available at https://www.github.com/MishaLaskin/rad.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:35:32 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 17:16:13 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 17:02:23 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 17:13:45 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 06:04:50 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Laskin", "Michael", ""], ["Lee", "Kimin", ""], ["Stooke", "Adam", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""], ["Srinivas", "Aravind", ""]]}, {"id": "2004.14992", "submitter": "Nicola De Cao", "authors": "Nicola De Cao, Michael Schlichtkrull, Wilker Aziz, Ivan Titov", "title": "How do Decisions Emerge across Layers in Neural Models? Interpretation\n  with Differentiable Masking", "comments": "Accepted at the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP). Source code available at\n  https://github.com/nicola-decao/diffmask . 18 pages, 15 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods assess the contribution of inputs to the model\nprediction. One way to do so is erasure: a subset of inputs is considered\nirrelevant if it can be removed without affecting the prediction. Though\nconceptually simple, erasure's objective is intractable and approximate search\nremains expensive with modern deep NLP models. Erasure is also susceptible to\nthe hindsight bias: the fact that an input can be dropped does not mean that\nthe model `knows' it can be dropped. The resulting pruning is over-aggressive\nand does not reflect how the model arrives at the prediction. To deal with\nthese challenges, we introduce Differentiable Masking. DiffMask learns to\nmask-out subsets of the input while maintaining differentiability. The decision\nto include or disregard an input token is made with a simple model based on\nintermediate hidden layers of the analyzed model. First, this makes the\napproach efficient because we predict rather than search. Second, as with\nprobing classifiers, this reveals what the network `knows' at the corresponding\nlayers. This lets us not only plot attribution heatmaps but also analyze how\ndecisions are formed across network layers. We use DiffMask to study BERT\nmodels on sentiment classification and question answering.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:36:14 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 15:51:43 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 10:12:19 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["De Cao", "Nicola", ""], ["Schlichtkrull", "Michael", ""], ["Aziz", "Wilker", ""], ["Titov", "Ivan", ""]]}]