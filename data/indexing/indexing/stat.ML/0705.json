[{"id": "0705.0209", "submitter": "Nathalie Villa", "authors": "Fabrice Rossi (INRIA Rocquencourt / INRIA Sophia Antipolis), Nathalie\n  Villa (GRIMM)", "title": "Support vector machine for functional data classification", "comments": "13 pages", "journal-ref": "Neurocomputing / EEG Neurocomputing 69, 7-9 (2006) 730-742", "doi": "10.1016/j.neucom.2005.12.010", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": null, "abstract": "  In many applications, input data are sampled functions taking their values in\ninfinite dimensional spaces rather than standard vectors. This fact has complex\nconsequences on data analysis algorithms that motivate modifications of them.\nIn fact most of the traditional data analysis tools for regression,\nclassification and clustering have been adapted to functional inputs under the\ngeneral name of functional Data Analysis (FDA). In this paper, we investigate\nthe use of Support Vector Machines (SVMs) for functional data analysis and we\nfocus on the problem of curves discrimination. SVMs are large margin classifier\ntools based on implicit non linear mappings of the considered data into high\ndimensional spaces thanks to kernels. We show how to define simple kernels that\ntake into account the unctional nature of the data and lead to consistent\nclassification. Experiments conducted on real world data emphasize the benefit\nof taking into account some functional aspects of the problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 06:48:41 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Rossi", "Fabrice", "", "INRIA Rocquencourt / INRIA Sophia Antipolis"], ["Villa", "Nathalie", "", "GRIMM"]]}, {"id": "0705.1613", "submitter": "Dhafer Malouche DM", "authors": "Dhafer Malouche", "title": "Determining full conditional independence by low-order conditioning", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ193 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2009, Vol. 15, No. 4, 1179-1189", "doi": "10.3150/09-BEJ193", "report-no": "IMS-BEJ-BEJ193", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A concentration graph associated with a random vector is an undirected graph\nwhere each vertex corresponds to one random variable in the vector. The absence\nof an edge between any pair of vertices (or variables) is equivalent to full\nconditional independence between these two variables given all the other\nvariables. In the multivariate Gaussian case, the absence of an edge\ncorresponds to a zero coefficient in the precision matrix, which is the inverse\nof the covariance matrix. It is well known that this concentration graph\nrepresents some of the conditional independencies in the distribution of the\nassociated random vector. These conditional independencies correspond to the\n\"separations\" or absence of edges in that graph. In this paper we assume that\nthere are no other independencies present in the probability distribution than\nthose represented by the graph. This property is called the perfect\nMarkovianity of the probability distribution with respect to the associated\nconcentration graph. We prove in this paper that this particular concentration\ngraph, the one associated with a perfect Markov distribution, can be determined\nby only conditioning on a limited number of variables. We demonstrate that this\nnumber is equal to the maximum size of the minimal separators in the\nconcentration graph.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 09:59:53 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2009 14:24:07 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2009 07:00:47 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2010 07:45:38 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Malouche", "Dhafer", ""]]}, {"id": "0705.2363", "submitter": "Marten Wegkamp", "authors": "Marten Wegkamp", "title": "Lasso type classifiers with a reject option", "comments": "Published at http://dx.doi.org/10.1214/07-EJS058 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 155-168", "doi": "10.1214/07-EJS058", "report-no": "IMS-EJS-EJS_2007_58", "categories": "stat.ML", "license": null, "abstract": "  We consider the problem of binary classification where one can, for a\nparticular cost, choose not to classify an observation. We present a simple\nproof for the oracle inequality for the excess risk of structural risk\nminimizers using a lasso type penalty.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2007 14:23:17 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Wegkamp", "Marten", ""]]}, {"id": "0705.4230", "submitter": "Aiyou Chen", "authors": "Aiyou Chen, Peter J. Bickel", "title": "Efficient independent component analysis", "comments": "Published at http://dx.doi.org/10.1214/009053606000000939 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2825-2855", "doi": "10.1214/009053606000000939", "report-no": "IMS-AOS-AOS0205", "categories": "stat.ME math.ST stat.ML stat.TH", "license": null, "abstract": "  Independent component analysis (ICA) has been widely used for blind source\nseparation in many fields such as brain imaging analysis, signal processing and\ntelecommunication. Many statistical techniques based on M-estimates have been\nproposed for estimating the mixing matrix. Recently, several nonparametric\nmethods have been developed, but in-depth analysis of asymptotic efficiency has\nnot been available. We analyze ICA using semiparametric theories and propose a\nstraightforward estimate based on the efficient score function by using\nB-spline approximations. The estimate is asymptotically efficient under\nmoderate conditions and exhibits better performance than standard ICA methods\nin a variety of simulations.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2007 15:15:33 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2007 06:04:57 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Chen", "Aiyou", ""], ["Bickel", "Peter J.", ""]]}, {"id": "0705.4485", "submitter": "Edoardo Airoldi", "authors": "Edoardo M Airoldi, David M Blei, Stephen E Fienberg, Eric P Xing", "title": "Mixed membership stochastic blockmodels", "comments": "46 pages, 14 figures, 3 tables", "journal-ref": "Journal of Machine Learning Research, 9, 1981-2014.", "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST physics.soc-ph stat.ML stat.TH", "license": null, "abstract": "  Observations consisting of measurements on relationships for pairs of objects\narise in many settings, such as protein interaction and gene regulatory\nnetworks, collections of author-recipient email, and social networks. Analyzing\nsuch data with probabilisic models can be delicate because the simple\nexchangeability assumptions underlying many boilerplate models no longer hold.\nIn this paper, we describe a latent variable model of such data called the\nmixed membership stochastic blockmodel. This model extends blockmodels for\nrelational data to ones which capture mixed membership latent relational\nstructure, thus providing an object-specific low-dimensional representation. We\ndevelop a general variational inference algorithm for fast approximate\nposterior inference. We explore applications to social and protein interaction\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2007 23:22:59 GMT"}], "update_date": "2010-02-22", "authors_parsed": [["Airoldi", "Edoardo M", ""], ["Blei", "David M", ""], ["Fienberg", "Stephen E", ""], ["Xing", "Eric P", ""]]}]