[{"id": "2010.00029", "submitter": "Hong-Ye Hu", "authors": "Hong-Ye Hu, Dian Wu, Yi-Zhuang You, Bruno Olshausen, Yubei Chen", "title": "RG-Flow: A hierarchical and explainable flow model based on\n  renormalization group and sparse prior", "comments": "9 pages, 7 figures, with appendix and the newly added multi-scale\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models have become an important class of unsupervised\nlearning approaches. In this work, we incorporate the key idea of\nrenormalization group (RG) and sparse prior distribution to design a\nhierarchical flow-based generative model, called RG-Flow, which can separate\ninformation at different scales of images with disentangled representations at\neach scale. We demonstrate our method mainly on the CelebA dataset and show\nthat the disentangled representations at different scales enable semantic\nmanipulation and style mixing of the images. To visualize the latent\nrepresentations, we introduce receptive fields for flow-based models and find\nthat the receptive fields learned by RG-Flow are similar to those in\nconvolutional neural networks. In addition, we replace the widely adopted\nGaussian prior distribution by a sparse prior distribution to further enhance\nthe disentanglement of representations. From a theoretical perspective, the\nproposed method has $O(\\log L)$ complexity for image inpainting compared to\nprevious generative models with $O(L^2)$ complexity.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 18:04:04 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 18:27:26 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 00:59:10 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 20:27:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Hu", "Hong-Ye", ""], ["Wu", "Dian", ""], ["You", "Yi-Zhuang", ""], ["Olshausen", "Bruno", ""], ["Chen", "Yubei", ""]]}, {"id": "2010.00064", "submitter": "Ayush Jain", "authors": "Ayush Jain, Alon Orlitsky", "title": "Linear-Sample Learning of Low-Rank Distributions", "comments": "Accepted for Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many latent-variable applications, including community detection,\ncollaborative filtering, genomic analysis, and NLP, model data as generated by\nlow-rank matrices. Yet despite considerable research, except for very special\ncases, the number of samples required to efficiently recover the underlying\nmatrices has not been known. We determine the onset of learning in several\ncommon latent-variable settings. For all of them, we show that learning\n$k\\times k$, rank-$r$, matrices to normalized $L_{1}$ distance $\\epsilon$\nrequires $\\Omega(\\frac{kr}{\\epsilon^2})$ samples, and propose an algorithm that\nuses ${\\cal O}(\\frac{kr}{\\epsilon^2}\\log^2\\frac r\\epsilon)$ samples, a number\nlinear in the high dimension, and nearly linear in the, typically low, rank.\nThe algorithm improves on existing spectral techniques and runs in polynomial\ntime. The proofs establish new results on the rapid convergence of the spectral\ndistance between the model and observation matrices, and may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 19:10:32 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""]]}, {"id": "2010.00071", "submitter": "Guneet Singh Dhillon", "authors": "Guneet S. Dhillon, Nicholas Carlini", "title": "Erratum Concerning the Obfuscated Gradients Attack on Stochastic\n  Activation Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Activation Pruning (SAP) (Dhillon et al., 2018) is a defense to\nadversarial examples that was attacked and found to be broken by the\n\"Obfuscated Gradients\" paper (Athalye et al., 2018). We discover a flaw in the\nre-implementation that artificially weakens SAP. When SAP is applied properly,\nthe proposed attack is not effective. However, we show that a new use of the\nBPDA attack technique can still reduce the accuracy of SAP to 0.1%.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 19:26:11 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Dhillon", "Guneet S.", ""], ["Carlini", "Nicholas", ""]]}, {"id": "2010.00073", "submitter": "Dheeraj Baby", "authors": "Dheeraj Baby and Yu-Xiang Wang", "title": "Adaptive Online Estimation of Piecewise Polynomial Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the framework of non-stationary stochastic optimization [Besbes\net al, 2015] with squared error losses and noisy gradient feedback where the\ndynamic regret of an online learner against a time varying comparator sequence\nis studied. Motivated from the theory of non-parametric regression, we\nintroduce a new variational constraint that enforces the comparator sequence to\nbelong to a discrete $k^{th}$ order Total Variation ball of radius $C_n$. This\nvariational constraint models comparators that have piece-wise polynomial\nstructure which has many relevant practical applications [Tibshirani, 2014]. By\nestablishing connections to the theory of wavelet based non-parametric\nregression, we design a polynomial time algorithm that achieves the nearly\noptimal dynamic regret of $\\tilde{O}(n^{\\frac{1}{2k+3}}C_n^{\\frac{2}{2k+3}})$.\nThe proposed policy is adaptive to the unknown radius $C_n$. Further, we show\nthat the same policy is minimax optimal for several other non-parametric\nfamilies of interest.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 19:30:28 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Baby", "Dheeraj", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2010.00081", "submitter": "Ahmadreza Moradipari", "authors": "Ahmadreza Moradipari, Christos Thrampoulidis, Mahnoosh Alizadeh", "title": "Stage-wise Conservative Linear Bandits", "comments": "28 pages, 5 figures", "journal-ref": "Thirty-fourth Conference on Neural Information Processing Systems,\n  NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stage-wise conservative linear stochastic bandits: an instance of\nbandit optimization, which accounts for (unknown) safety constraints that\nappear in applications such as online advertising and medical trials. At each\nstage, the learner must choose actions that not only maximize cumulative reward\nacross the entire time horizon but further satisfy a linear baseline constraint\nthat takes the form of a lower bound on the instantaneous reward. For this\nproblem, we present two novel algorithms, stage-wise conservative linear\nThompson Sampling (SCLTS) and stage-wise conservative linear UCB (SCLUCB), that\nrespect the baseline constraints and enjoy probabilistic regret bounds of order\nO(\\sqrt{T} \\log^{3/2}T) and O(\\sqrt{T} \\log T), respectively. Notably, the\nproposed algorithms can be adjusted with only minor modifications to tackle\ndifferent problem variations, such as constraints with bandit-feedback, or an\nunknown sequence of baseline actions. We discuss these and other improvements\nover the state-of-the-art. For instance, compared to existing solutions, we\nshow that SCLTS plays the (non-optimal) baseline action at most O(\\log{T})\ntimes (compared to O(\\sqrt{T})). Finally, we make connections to another\nstudied form of safety constraints that takes the form of an upper bound on the\ninstantaneous reward. While this incurs additional complexity to the learning\nprocess as the optimal action is not guaranteed to belong to the safe set at\neach round, we show that SCLUCB can properly adjust in this setting via a\nsimple modification.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 19:51:37 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Moradipari", "Ahmadreza", ""], ["Thrampoulidis", "Christos", ""], ["Alizadeh", "Mahnoosh", ""]]}, {"id": "2010.00116", "submitter": "Li Xiao", "authors": "Li Xiao, Biao Cai, Gang Qu, Julia M. Stephen, Tony W. Wilson, Vince D.\n  Calhoun, and Yu-Ping Wang", "title": "Distance Correlation Based Brain Functional Connectivity Estimation and\n  Non-Convex Multi-Task Learning for Developmental fMRI Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional magnetic resonance imaging (rs-fMRI)-derived\nfunctional connectivity patterns have been extensively utilized to delineate\nglobal functional organization of the human brain in health, development, and\nneuropsychiatric disorders. In this paper, we investigate how functional\nconnectivity in males and females differs in an age prediction framework. We\nfirst estimate functional connectivity between regions-of-interest (ROIs) using\ndistance correlation instead of Pearson's correlation. Distance correlation, as\na multivariate statistical method, explores spatial relations of voxel-wise\ntime courses within individual ROIs and measures both linear and nonlinear\ndependence, capturing more complex information of between-ROI interactions.\nThen, a novel non-convex multi-task learning (NC-MTL) model is proposed to\nstudy age-related gender differences in functional connectivity, where age\nprediction for each gender group is viewed as one task. Specifically, in the\nproposed NC-MTL model, we introduce a composite regularizer with a combination\nof non-convex $\\ell_{2,1-2}$ and $\\ell_{1-2}$ regularization terms for\nselecting both common and task-specific features. Finally, we validate the\nproposed NC-MTL model along with distance correlation based functional\nconnectivity on rs-fMRI of the Philadelphia Neurodevelopmental Cohort for\npredicting ages of both genders. The experimental results demonstrate that the\nproposed NC-MTL model outperforms other competing MTL models in age prediction,\nas well as characterizing developmental gender differences in functional\nconnectivity patterns.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 21:48:52 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Xiao", "Li", ""], ["Cai", "Biao", ""], ["Qu", "Gang", ""], ["Stephen", "Julia M.", ""], ["Wilson", "Tony W.", ""], ["Calhoun", "Vince D.", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "2010.00130", "submitter": "Sergi Abadal", "authors": "Sergi Abadal, Akshay Jain, Robert Guirado, Jorge L\\'opez-Alonso,\n  Eduard Alarc\\'on", "title": "Computing Graph Neural Networks: A Survey from Algorithms to\n  Accelerators", "comments": "35 pages, 9 figures, 8 tables, 188 references", "journal-ref": "ACM Computing Surveys, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have exploded onto the machine learning scene in\nrecent years owing to their capability to model and learn from graph-structured\ndata. Such an ability has strong implications in a wide variety of fields whose\ndata is inherently relational, for which conventional neural networks do not\nperform well. Indeed, as recent reviews can attest, research in the area of\nGNNs has grown rapidly and has lead to the development of a variety of GNN\nalgorithm variants as well as to the exploration of groundbreaking applications\nin chemistry, neurology, electronics, or communication networks, among others.\nAt the current stage of research, however, the efficient processing of GNNs is\nstill an open challenge for several reasons. Besides of their novelty, GNNs are\nhard to compute due to their dependence on the input graph, their combination\nof dense and very sparse operations, or the need to scale to huge graphs in\nsome applications. In this context, this paper aims to make two main\ncontributions. On the one hand, a review of the field of GNNs is presented from\nthe perspective of computing. This includes a brief tutorial on the GNN\nfundamentals, an overview of the evolution of the field in the last decade, and\na summary of operations carried out in the multiple phases of different GNN\nalgorithm variants. On the other hand, an in-depth analysis of current software\nand hardware acceleration schemes is provided, from which a hardware-software,\ngraph-aware, and communication-centric vision for GNN accelerators is\ndistilled.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 22:29:27 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 19:46:45 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 09:39:35 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Abadal", "Sergi", ""], ["Jain", "Akshay", ""], ["Guirado", "Robert", ""], ["L\u00f3pez-Alonso", "Jorge", ""], ["Alarc\u00f3n", "Eduard", ""]]}, {"id": "2010.00137", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Jianfeng Lu, Andrej Risteski", "title": "Efficient sampling from the Bingham distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a algorithm for exact sampling from the Bingham distribution\n$p(x)\\propto \\exp(x^\\top A x)$ on the sphere $\\mathcal S^{d-1}$ with expected\nruntime of $\\operatorname{poly}(d, \\lambda_{\\max}(A)-\\lambda_{\\min}(A))$. The\nalgorithm is based on rejection sampling, where the proposal distribution is a\npolynomial approximation of the pdf, and can be sampled from by explicitly\nevaluating integrals of polynomials over the sphere. Our algorithm gives exact\nsamples, assuming exact computation of an inverse function of a polynomial.\nThis is in contrast with Markov Chain Monte Carlo algorithms, which are not\nknown to enjoy rapid mixing on this problem, and only give approximate samples.\n  As a direct application, we use this to sample from the posterior\ndistribution of a rank-1 matrix inference problem in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 22:48:03 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Lu", "Jianfeng", ""], ["Risteski", "Andrej", ""]]}, {"id": "2010.00145", "submitter": "Renyuan Xu", "authors": "Xin Guo, Renyuan Xu and Thaleia Zariphopoulou", "title": "Entropy Regularization for Mean Field Games with Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularization has been extensively adopted to improve the\nefficiency, the stability, and the convergence of algorithms in reinforcement\nlearning. This paper analyzes both quantitatively and qualitatively the impact\nof entropy regularization for Mean Field Game (MFG) with learning in a finite\ntime horizon. Our study provides a theoretical justification that entropy\nregularization yields time-dependent policies and, furthermore, helps\nstabilizing and accelerating convergence to the game equilibrium. In addition,\nthis study leads to a policy-gradient algorithm for exploration in MFG. Under\nthis algorithm, agents are able to learn the optimal exploration scheduling,\nwith stable and fast convergence to the game equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 23:27:11 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Guo", "Xin", ""], ["Xu", "Renyuan", ""], ["Zariphopoulou", "Thaleia", ""]]}, {"id": "2010.00161", "submitter": "Olusola Odeyomi", "authors": "Olusola T. Odeyomi", "title": "Unknown Delay for Adversarial Bandit Setting with Multiple Play", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unknown delays in adversarial multi-armed\nbandit (MAB) with multiple play. Existing work on similar game setting focused\non only the case where the learner selects an arm in each round. However, there\nare lots of applications in robotics where a learner needs to select more than\none arm per round. It is therefore worthwhile to investigate the effect of\ndelay when multiple arms are chosen. The multiple arms chosen per round in this\nsetting are such that they experience the same amount of delay. There can be an\naggregation of feedback losses from different combinations of arms selected at\ndifferent rounds, and the learner is faced with the challenge of associating\nthe feedback losses to the arms producing them. To address this problem, this\npaper proposes a delayed exponential, exploitation and exploration for multiple\nplay (DEXP3.M) algorithm. The regret bound is only slightly worse than the\nregret of DEXP3 already proposed for the single play setting with unknown\ndelay.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 01:07:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Odeyomi", "Olusola T.", ""]]}, {"id": "2010.00163", "submitter": "Yayi Zou", "authors": "Yayi Zou, Zhiwei Qin", "title": "Value-based Bayesian Meta-reinforcement Learning and Traffic Signal\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods for traffic signal control has gained\nincreasing interests recently and achieved better performances compared with\ntraditional transportation methods. However, reinforcement learning based\nmethods usually requires heavy training data and computational resources which\nlargely limit its application in real-world traffic signal control. This makes\nmeta-learning, which enables data-efficient and fast-adaptation training by\nleveraging the knowledge of previous learning experiences, catches attentions\nin traffic signal control. In this paper, we propose a novel value-based\nBayesian meta-reinforcement learning framework BM-DQN to robustly speed up the\nlearning process in new scenarios by utilizing well-trained prior knowledge\nlearned from existing scenarios. This framework based on our proposed\nfast-adaptation variation to Gradient-EM Bayesian Meta-learning and the fast\nupdate advantage of DQN, which allows fast adaptation to new scenarios with\ncontinual learning ability and robustness to uncertainty. The experiments on 2D\nnavigation and traffic signal control show that our proposed framework adapts\nmore quickly and robustly in new scenarios than previous methods, and\nspecifically, much better continual learning ability in heterogeneous\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 01:15:17 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zou", "Yayi", ""], ["Qin", "Zhiwei", ""]]}, {"id": "2010.00202", "submitter": "Rel Guzman", "authors": "Rel Guzman, Rafael Oliveira, and Fabio Ramos", "title": "Heteroscedastic Bayesian Optimisation for Stochastic Model Predictive\n  Control", "comments": "Paper to appear at the IEEE Robotics and Automation Letters (RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model predictive control (MPC) has been successful in applications involving\nthe control of complex physical systems. This class of controllers leverages\nthe information provided by an approximate model of the system's dynamics to\nsimulate the effect of control actions. MPC methods also present a few\nhyper-parameters which may require a relatively expensive tuning process by\ndemanding interactions with the physical system. Therefore, we investigate\nfine-tuning MPC methods in the context of stochastic MPC, which presents extra\nchallenges due to the randomness of the controller's actions. In these\nscenarios, performance outcomes present noise, which is not homogeneous across\nthe domain of possible hyper-parameter settings, but which varies in an\ninput-dependent way. To address these issues, we propose a Bayesian\noptimisation framework that accounts for heteroscedastic noise to tune\nhyper-parameters in control problems. Empirical results on benchmark continuous\ncontrol tasks and a physical robot support the proposed framework's suitability\nrelative to baselines, which do not take heteroscedasticity into account.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 05:31:41 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 03:01:52 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Guzman", "Rel", ""], ["Oliveira", "Rafael", ""], ["Ramos", "Fabio", ""]]}, {"id": "2010.00261", "submitter": "Abdulkadir Celikkanat", "authors": "Abdulkadir \\c{C}elikkanat and Apostolos N. Papadopoulos and Fragkiskos\n  D. Malliaros", "title": "${\\rm N{\\small ode}S{\\small ig}}$: Random Walk Diffusion meets Hashing\n  for Scalable Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning node representations is a crucial task with a plethora of\ninterdisciplinary applications. Nevertheless, as the size of the networks\nincreases, most widely used models face computational challenges to scale to\nlarge networks. While there is a recent effort towards designing algorithms\nthat solely deal with scalability issues, most of them behave poorly in terms\nof accuracy on downstream tasks. In this paper, we aim at studying models that\nbalance the trade-off between efficiency and accuracy. In particular, we\npropose ${\\rm N{\\small ode}S{\\small ig}}$, a scalable embedding model that\ncomputes binary node representations. ${\\rm N{\\small ode}S{\\small ig}}$\nexploits random walk diffusion probabilities via stable random projection\nhashing, towards efficiently computing embeddings in the Hamming space. Our\nextensive experimental evaluation on various graphs has demonstrated that the\nproposed model achieves a good balance between accuracy and efficiency compared\nto well-known baseline models on two downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 09:07:37 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Papadopoulos", "Apostolos N.", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "2010.00262", "submitter": "Joe Watson", "authors": "Joe Watson, Abraham Imohiosen, Jan Peters", "title": "Active Inference or Control as Inference? A Unifying View", "comments": "International Workshop on Active Inference 2020 (IWAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active inference (AI) is a persuasive theoretical framework from\ncomputational neuroscience that seeks to describe action and perception as\ninference-based computation. However, this framework has yet to provide\npractical sensorimotor control algorithms that are competitive with alternative\napproaches. In this work, we frame active inference through the lens of control\nas inference (CaI), a body of work that presents trajectory optimization as\ninference. From the wider view of `probabilistic numerics', CaI offers\nprincipled, numerically robust optimal control solvers that provide uncertainty\nquantification, and can scale to nonlinear problems with approximate inference.\nWe show that AI may be framed as partially-observed CaI when the cost function\nis defined specifically in the observation states.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 09:08:45 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Watson", "Joe", ""], ["Imohiosen", "Abraham", ""], ["Peters", "Jan", ""]]}, {"id": "2010.00282", "submitter": "David Tolpin", "authors": "David Tolpin, Yuan Zhou, Tom Rainforth, Hongseok Yang", "title": "Probabilistic Programs with Stochastic Conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of conditioning probabilistic programs on distributions\nof observable variables. Probabilistic programs are usually conditioned on\nsamples from the joint data distribution, which we refer to as deterministic\nconditioning. However, in many real-life scenarios, the observations are given\nas marginal distributions, summary statistics, or samplers. Conventional\nprobabilistic programming systems lack adequate means for modeling and\ninference in such scenarios. We propose a generalization of deterministic\nconditioning to stochastic conditioning, that is, conditioning on the marginal\ndistribution of a variable taking a particular form. To this end, we first\ndefine the formal notion of stochastic conditioning and discuss its key\nproperties. We then show how to perform inference in the presence of stochastic\nconditioning. We demonstrate potential usage of stochastic conditioning on\nseveral case studies which involve various kinds of stochastic conditioning and\nare difficult to solve otherwise. Although we present stochastic conditioning\nin the context of probabilistic programming, our formalization is general and\napplicable to other settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 10:17:52 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 22:01:19 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 12:41:46 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Tolpin", "David", ""], ["Zhou", "Yuan", ""], ["Rainforth", "Tom", ""], ["Yang", "Hongseok", ""]]}, {"id": "2010.00284", "submitter": "David Tolpin", "authors": "David Tolpin, Yuan Zhou, Hongseok Yang", "title": "Bayesian Policy Search for Stochastic Domains", "comments": "International Conference on Probabilistic Programming (PROBPROG),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI planning can be cast as inference in probabilistic models, and\nprobabilistic programming was shown to be capable of policy search in partially\nobservable domains. Prior work introduces policy search through Markov chain\nMonte Carlo in deterministic domains, as well as adapts black-box variational\ninference to stochastic domains, however not in the strictly Bayesian sense. In\nthis work, we cast policy search in stochastic domains as a Bayesian inference\nproblem and provide a scheme for encoding such problems as nested probabilistic\nprograms. We argue that probabilistic programs for policy search in stochastic\ndomains should involve nested conditioning, and provide an adaption of\nLightweight Metropolis-Hastings (LMH) for robust inference in such programs. We\napply the proposed scheme to stochastic domains and show that policies of\nsimilar quality are learned, despite a simpler and more general inference\nalgorithm. We believe that the proposed variant of LMH is novel and applicable\nto a wider class of probabilistic programs with nested conditioning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 10:22:15 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Tolpin", "David", ""], ["Zhou", "Yuan", ""], ["Yang", "Hongseok", ""]]}, {"id": "2010.00297", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Universal time-series forecasting with mixture predictors", "comments": "This is the author's version of the book published by Springer under\n  the same name. The final authenticated version is available online at:\n  https://doi.org/10.1007/978-3-030-54304-4 . Further updates and corrections\n  may be made here", "journal-ref": null, "doi": "10.1007/978-3-030-54304-4", "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book is devoted to the problem of sequential probability forecasting,\nthat is, predicting the probabilities of the next outcome of a growing sequence\nof observations given the past. This problem is considered in a very general\nsetting that unifies commonly used probabilistic and non-probabilistic\nsettings, trying to make as few as possible assumptions on the mechanism\ngenerating the observations. A common form that arises in various formulations\nof this problem is that of mixture predictors, which are formed as a\ncombination of a finite or infinite set of other predictors attempting to\ncombine their predictive powers. The main subject of this book are such mixture\npredictors, and the main results demonstrate the universality of this method in\na very general probabilistic setting, but also show some of its limitations.\nWhile the problems considered are motivated by practical applications,\ninvolving, for example, financial, biological or behavioural data, this\nmotivation is left implicit and all the results exposed are theoretical.\n  The book targets graduate students and researchers interested in the problem\nof sequential prediction, and, more generally, in theoretical analysis of\nproblems in machine learning and non-parametric statistics, as well as\nmathematical and philosophical foundations of these fields.\n  The material in this volume is presented in a way that presumes familiarity\nwith basic concepts of probability and statistics, up to and including\nprobability distributions over spaces of infinite sequences. Familiarity with\nthe literature on learning or stochastic processes is not required.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 10:56:23 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "2010.00351", "submitter": "Dong-Hee Kim", "authors": "Dongkyu Kim and Dong-Hee Kim", "title": "Emergence of a finite-size-scaling function in the supervised learning\n  of the Ising phase transition", "comments": null, "journal-ref": "J. Stat. Mech. (2021) 023202", "doi": "10.1088/1742-5468/abdc18", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the connection between the supervised learning of the binary\nphase classification in the ferromagnetic Ising model and the standard\nfinite-size-scaling theory of the second-order phase transition. Proposing a\nminimal one-free-parameter neural network model, we analytically formulate the\nsupervised learning problem for the canonical ensemble being used as a training\ndata set. We show that just one free parameter is capable enough to describe\nthe data-driven emergence of the universal finite-size-scaling function in the\nnetwork output that is observed in a large neural network, theoretically\nvalidating its critical point prediction for unseen test data from different\nunderlying lattices yet in the same universality class of the Ising\ncriticality. We also numerically demonstrate the interpretation with the\nproposed one-parameter model by providing an example of finding a critical\npoint with the learning of the Landau mean-field free energy being applied to\nthe real data set from the uncorrelated random scale-free graph with a large\ndegree exponent.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:34:12 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 03:02:59 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Kim", "Dongkyu", ""], ["Kim", "Dong-Hee", ""]]}, {"id": "2010.00359", "submitter": "Hongjin He", "authors": "Chenjian Pan and Chen Ling and Hongjin He and Liqun Qi and Yanwei Xu", "title": "Low-Rank and Sparse Enhanced Tucker Decomposition for Tensor Completion", "comments": "15 pages and 17 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion refers to the task of estimating the missing data from an\nincomplete measurement or observation, which is a core problem frequently\narising from the areas of big data analysis, computer vision, and network\nengineering. Due to the multidimensional nature of high-order tensors, the\nmatrix approaches, e.g., matrix factorization and direct matricization of\ntensors, are often not ideal for tensor completion and recovery. In this paper,\nwe introduce a unified low-rank and sparse enhanced Tucker decomposition model\nfor tensor completion. Our model possesses a sparse regularization term to\npromote a sparse core tensor of the Tucker decomposition, which is beneficial\nfor tensor data compression. Moreover, we enforce low-rank regularization terms\non factor matrices of the Tucker decomposition for inducing the low-rankness of\nthe tensor with a cheap computational cost. Numerically, we propose a\ncustomized ADMM with enough easy subproblems to solve the underlying model. It\nis remarkable that our model is able to deal with different types of real-world\ndata sets, since it exploits the potential periodicity and inherent correlation\nproperties appeared in tensors. A series of computational experiments on\nreal-world data sets, including internet traffic data sets, color images, and\nface recognition, demonstrate that our model performs better than many existing\nstate-of-the-art matricization and tensorization approaches in terms of\nachieving higher recovery accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:45:39 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 06:41:00 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 03:18:17 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Pan", "Chenjian", ""], ["Ling", "Chen", ""], ["He", "Hongjin", ""], ["Qi", "Liqun", ""], ["Xu", "Yanwei", ""]]}, {"id": "2010.00373", "submitter": "Chen Zeno", "authors": "Chen Zeno, Itay Golan, Elad Hoffer and Daniel Soudry", "title": "Task Agnostic Continual Learning Using Online Variational Bayes with\n  Fixed-Point Updates", "comments": "The arXiv paper \"Task Agnostic Continual Learning Using Online\n  Variational Bayes\" is a preliminary pre-print of this paper. The main\n  differences between the versions are: 1. We develop new algorithmic framework\n  (FOO-VB). 2. We add multivariate Gaussian and matrix variate Gaussian\n  versions of the algorithm. 3. We demonstrate the new algorithm performance in\n  task agnostic scenarios", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Catastrophic forgetting is the notorious vulnerability of neural\nnetworks to the changes in the data distribution during learning. This\nphenomenon has long been considered a major obstacle for using learning agents\nin realistic continual learning settings. A large body of continual learning\nresearch assumes that task boundaries are known during training. However, only\na few works consider scenarios in which task boundaries are unknown or not well\ndefined -- task agnostic scenarios. The optimal Bayesian solution for this\nrequires an intractable online Bayes update to the weights posterior.\nContributions: We aim to approximate the online Bayes update as accurately as\npossible. To do so, we derive novel fixed-point equations for the online\nvariational Bayes optimization problem, for multivariate Gaussian parametric\ndistributions. By iterating the posterior through these fixed-point equations,\nwe obtain an algorithm (FOO-VB) for continual learning which can handle\nnon-stationary data distribution using a fixed architecture and without using\nexternal memory (i.e. without access to previous data). We demonstrate that our\nmethod (FOO-VB) outperforms existing methods in task agnostic scenarios. FOO-VB\nPytorch implementation will be available online.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:10:35 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zeno", "Chen", ""], ["Golan", "Itay", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "2010.00378", "submitter": "Angelica I. Aviles-Rivero", "authors": "Angelica I Aviles-Rivero, Philip Sellars, Carola-Bibiane Sch\\\"onlieb,\n  Nicolas Papadakis", "title": "GraphXCOVID: Explainable Deep Graph Diffusion Pseudo-Labelling for\n  Identifying COVID-19 on Chest X-rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can one learn to diagnose COVID-19 under extreme minimal supervision? Since\nthe outbreak of the novel COVID-19 there has been a rush for developing\nArtificial Intelligence techniques for expert-level disease identification on\nChest X-ray data. In particular, the use of deep supervised learning has become\nthe go-to paradigm. However, the performance of such models is heavily\ndependent on the availability of a large and representative labelled dataset.\nThe creation of which is a heavily expensive and time consuming task, and\nespecially imposes a great challenge for a novel disease. Semi-supervised\nlearning has shown the ability to match the incredible performance of\nsupervised models whilst requiring a small fraction of the labelled examples.\nThis makes the semi-supervised paradigm an attractive option for identifying\nCOVID-19. In this work, we introduce a graph based deep semi-supervised\nframework for classifying COVID-19 from chest X-rays. Our framework introduces\nan optimisation model for graph diffusion that reinforces the natural relation\namong the tiny labelled set and the vast unlabelled data. We then connect the\ndiffusion prediction output as pseudo-labels that are used in an iterative\nscheme in a deep net. We demonstrate, through our experiments, that our model\nis able to outperform the current leading supervised model with a tiny fraction\nof the labelled examples. Finally, we provide attention maps to accommodate the\nradiologist's mental model, better fitting their perceptual and cognitive\nabilities. These visualisation aims to assist the radiologist in judging\nwhether the diagnostic is correct or not, and in consequence to accelerate the\ndecision.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:38:24 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 18:30:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Aviles-Rivero", "Angelica I", ""], ["Sellars", "Philip", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""], ["Papadakis", "Nicolas", ""]]}, {"id": "2010.00380", "submitter": "Pierre De Handschutter", "authors": "Pierre De Handschutter, Nicolas Gillis, Xavier Siebert", "title": "Deep matrix factorizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained low-rank matrix approximations have been known for decades as\npowerful linear dimensionality reduction techniques to be able to extract the\ninformation contained in large data sets in a relevant way. However, such\nlow-rank approaches are unable to mine complex, interleaved features that\nunderlie hierarchical semantics. Recently, deep matrix factorization (deep MF)\nwas introduced to deal with the extraction of several layers of features and\nhas been shown to reach outstanding performances on unsupervised tasks. Deep MF\nwas motivated by the success of deep learning, as it is conceptually close to\nsome neural networks paradigms. In this paper, we present the main models,\nalgorithms, and applications of deep MF through a comprehensive literature\nreview. We also discuss theoretical questions and perspectives of research.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:19:01 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 07:31:30 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["De Handschutter", "Pierre", ""], ["Gillis", "Nicolas", ""], ["Siebert", "Xavier", ""]]}, {"id": "2010.00381", "submitter": "Ercument Ilhan", "authors": "Ercument Ilhan, Jeremy Gow and Diego Perez-Liebana", "title": "Student-Initiated Action Advising via Advice Novelty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action advising is a budget-constrained knowledge exchange mechanism between\nteacher-student peers that can help tackle exploration and sample inefficiency\nproblems in deep reinforcement learning (RL). Most recently, student-initiated\ntechniques that utilise state novelty and uncertainty estimations have obtained\npromising results. However, the approaches built on these estimations have some\npotential weaknesses. First, they assume that the convergence of the student's\nRL model implies less need for advice. This can be misleading in scenarios with\nteacher absence early on where the student is likely to learn suboptimally by\nitself; yet also ignore the teacher's assistance later. Secondly, the delays\nbetween encountering states and having them to take effect in the RL model\nupdates in presence of the experience replay dynamics cause a feedback lag in\nwhat the student actually needs advice for. We propose a student-initiated\nalgorithm that alleviates these by employing Random Network Distillation (RND)\nto measure the novelty of a piece of advice. Furthermore, we perform RND\nupdates only for the advised states to ensure that the student's own learning\ndoes not impair its ability to leverage the teacher. Experiments in GridWorld\nand MinAtar show that our approach performs on par with the state-of-the-art\nand demonstrates significant advantages in the scenarios where the existing\nmethods are prone to fail.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:20:28 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 08:49:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ilhan", "Ercument", ""], ["Gow", "Jeremy", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2010.00387", "submitter": "Paul Scherer", "authors": "Paul Scherer, Maja Tr\\c{e}bacz, Nikola Simidjievski, Zohreh Shams,\n  Helena Andres Terre, Pietro Li\\`o, Mateja Jamnik", "title": "Incorporating network based protein complex discovery into automated\n  model construction", "comments": "7 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a method for gene expression based analysis of cancer phenotypes\nincorporating network biology knowledge through unsupervised construction of\ncomputational graphs. The structural construction of the computational graphs\nis driven by the use of topological clustering algorithms on protein-protein\nnetworks which incorporate inductive biases stemming from network biology\nresearch in protein complex discovery. This structurally constrains the\nhypothesis space over the possible computational graph factorisation whose\nparameters can then be learned through supervised or unsupervised task\nsettings. The sparse construction of the computational graph enables the\ndifferential protein complex activity analysis whilst also interpreting the\nindividual contributions of genes/proteins involved in each individual protein\ncomplex. In our experiments analysing a variety of cancer phenotypes, we show\nthat the proposed methods outperform SVM, Fully-Connected MLP, and\nRandomly-Connected MLPs in all tasks. Our work introduces a scalable method for\nincorporating large interaction networks as prior knowledge to drive the\nconstruction of powerful computational models amenable to introspective study.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:46:33 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Scherer", "Paul", ""], ["Tr\u0229bacz", "Maja", ""], ["Simidjievski", "Nikola", ""], ["Shams", "Zohreh", ""], ["Terre", "Helena Andres", ""], ["Li\u00f2", "Pietro", ""], ["Jamnik", "Mateja", ""]]}, {"id": "2010.00401", "submitter": "Aniruddh Herle Mr.", "authors": "Aniruddh Herle, Janamejaya Channegowda, Dinakar Prabhu", "title": "Quasar Detection using Linear Support Vector Machine with Learning From\n  Mistakes Methodology", "comments": "Published in 2020 IEEE International Conference on Electronics,\n  Computing and Communication Technologies (CONECCT)", "journal-ref": null, "doi": "10.1109/CONECCT50063.2020.9198529", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Astronomy requires the collection and assimilation of vast\nvolumes of data. The data handling and processing problem has become severe as\nthe sheer volume of data produced by scientific instruments each night grows\nexponentially. This problem becomes extensive for conventional methods of\nprocessing the data, which was mostly manual, but is the perfect setting for\nthe use of Machine Learning approaches. While building classifiers for\nAstronomy, the cost of losing a rare object like supernovae or quasars to\ndetection losses is far more severe than having many false positives, given the\nrarity and scientific value of these objects. In this paper, a Linear Support\nVector Machine (LSVM) is explored to detect Quasars, which are extremely bright\nobjects in which a supermassive black hole is surrounded by a luminous\naccretion disk. In Astronomy, it is vital to correctly identify quasars, as\nthey are very rare in nature. Their rarity creates a class-imbalance problem\nthat needs to be taken into consideration. The class-imbalance problem and high\ncost of misclassification are taken into account while designing the\nclassifier. To achieve this detection, a novel classifier is explored, and its\nperformance is evaluated. It was observed that LSVM along with Ensemble Bagged\nTrees (EBT) achieved a 10x reduction in the False Negative Rate, using the\nLearning from Mistakes methodology.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:41:51 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 13:59:59 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Herle", "Aniruddh", ""], ["Channegowda", "Janamejaya", ""], ["Prabhu", "Dinakar", ""]]}, {"id": "2010.00402", "submitter": "Ines Chami", "authors": "Ines Chami, Albert Gu, Vaggos Chatziafratis and Christopher R\\'e", "title": "From Trees to Continuous Embeddings and Back: Hyperbolic Hierarchical\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity-based Hierarchical Clustering (HC) is a classical unsupervised\nmachine learning algorithm that has traditionally been solved with heuristic\nalgorithms like Average-Linkage. Recently, Dasgupta reframed HC as a discrete\noptimization problem by introducing a global cost function measuring the\nquality of a given tree. In this work, we provide the first continuous\nrelaxation of Dasgupta's discrete optimization problem with provable quality\nguarantees. The key idea of our method, HypHC, is showing a direct\ncorrespondence from discrete trees to continuous representations (via the\nhyperbolic embeddings of their leaf nodes) and back (via a decoding algorithm\nthat maps leaf embeddings to a dendrogram), allowing us to search the space of\ndiscrete binary trees with continuous optimization. Building on analogies\nbetween trees and hyperbolic space, we derive a continuous analogue for the\nnotion of lowest common ancestor, which leads to a continuous relaxation of\nDasgupta's discrete objective. We can show that after decoding, the global\nminimizer of our continuous relaxation yields a discrete tree with a (1 +\nepsilon)-factor approximation for Dasgupta's optimal tree, where epsilon can be\nmade arbitrarily small and controls optimization challenges. We experimentally\nevaluate HypHC on a variety of HC benchmarks and find that even approximate\nsolutions found with gradient descent have superior clustering quality than\nagglomerative heuristics or other gradient based algorithms. Finally, we\nhighlight the flexibility of HypHC using end-to-end training in a downstream\nclassification task.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:43:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Chami", "Ines", ""], ["Gu", "Albert", ""], ["Chatziafratis", "Vaggos", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2010.00406", "submitter": "Aaron Defazio", "authors": "Aaron Defazio", "title": "Momentum via Primal Averaging: Theoretical Insights and Learning Rate\n  Schedules for Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Momentum methods are now used pervasively within the machine learning\ncommunity for training non-convex models such as deep neural networks.\nEmpirically, they out perform traditional stochastic gradient descent (SGD)\napproaches. In this work we develop a Lyapunov analysis of SGD with momentum\n(SGD+M), by utilizing a equivalent rewriting of the method known as the\nstochastic primal averaging (SPA) form. This analysis is much tighter than\nprevious theory in the non-convex case, and due to this we are able to give\nprecise insights into when SGD+M may out-perform SGD, and what hyper-parameter\nschedules will work and why.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:46:32 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:05:04 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 19:49:57 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 17:53:38 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Defazio", "Aaron", ""]]}, {"id": "2010.00417", "submitter": "Agustin Castellano", "authors": "Agustin Castellano, Juan Bazerque, Enrique Mallada", "title": "Learning to be safe, in finite time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to put forward the concept that learning to take safe actions\nin unknown environments, even with probability one guarantees, can be achieved\nwithout the need for an unbounded number of exploratory trials, provided that\none is willing to relax its optimality requirements mildly. We focus on the\ncanonical multi-armed bandit problem and seek to study the\nexploration-preservation trade-off intrinsic within safe learning. More\nprecisely, by defining a handicap metric that counts the number of unsafe\nactions, we provide an algorithm for discarding unsafe machines (or actions),\nwith probability one, that achieves constant handicap. Our algorithm is rooted\nin the classical sequential probability ratio test, redefined here for\ncontinuing tasks. Under standard assumptions on sufficient exploration, our\nrule provably detects all unsafe machines in an (expected) finite number of\nrounds. The analysis also unveils a trade-off between the number of rounds\nneeded to secure the environment and the probability of discarding safe\nmachines. Our decision rule can wrap around any other algorithm to optimize a\nspecific auxiliary goal since it provides a safe environment to search for\n(approximately) optimal policies. Simulations corroborate our theoretical\nfindings and further illustrate the aforementioned trade-offs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 14:03:34 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 14:44:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Castellano", "Agustin", ""], ["Bazerque", "Juan", ""], ["Mallada", "Enrique", ""]]}, {"id": "2010.00435", "submitter": "Dong Quan Nguyen", "authors": "Dong Quan Ngoc Nguyen, Lin Xing, and Lizhen Lin", "title": "Community detection, pattern recognition, and hypergraph-based learning:\n  approaches using metric geometry and persistent homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph data appear and are hidden in many places in the modern age. They\nare data structure that can be used to model many real data examples since\ntheir structures contain information about higher order relations among data\npoints. One of the main contributions of our paper is to introduce a new\ntopological structure to hypergraph data which bears a resemblance to a usual\nmetric space structure. Using this new topological space structure of\nhypergraph data, we propose several approaches to study community detection\nproblem, detecting persistent features arising from homological structure of\nhypergraph data. Also based on the topological space structure of hypergraph\ndata introduced in our paper, we introduce a modified nearest neighbors methods\nwhich is a generalization of the classical nearest neighbors methods from\nmachine learning. Our modified nearest neighbors methods have an advantage of\nbeing very flexible and applicable even for discrete structures as in\nhypergraphs. We then apply our modified nearest neighbors methods to study sign\nprediction problem in hypegraph data constructed using our method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:20:12 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Nguyen", "Dong Quan Ngoc", ""], ["Xing", "Lin", ""], ["Lin", "Lizhen", ""]]}, {"id": "2010.00438", "submitter": "Puning Zhao", "authors": "Puning Zhao, Lifeng Lai", "title": "Analysis of KNN Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the $\\ell_1$ and $\\ell_\\infty$ convergence rates of k nearest\nneighbor density estimation method. Our analysis includes two different cases\ndepending on whether the support set is bounded or not. In the first case, the\nprobability density function has a bounded support and is bounded away from\nzero. We show that kNN density estimation is minimax optimal under both\n$\\ell_1$ and $\\ell_\\infty$ criteria, if the support set is known. If the\nsupport set is unknown, then the convergence rate of $\\ell_1$ error is not\naffected, while $\\ell_\\infty$ error does not converge. In the second case, the\nprobability density function can approach zero and is smooth everywhere.\nMoreover, the Hessian is assumed to decay with the density values. For this\ncase, our result shows that the $\\ell_\\infty$ error of kNN density estimation\nis nearly minimax optimal. The $\\ell_1$ error does not reach the minimax lower\nbound, but is better than kernel density estimation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 03:33:17 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zhao", "Puning", ""], ["Lai", "Lifeng", ""]]}, {"id": "2010.00439", "submitter": "Chris Wendler", "authors": "Chris Wendler, Andisheh Amrollahi, Bastian Seifert, Andreas Krause,\n  Markus P\\\"uschel", "title": "Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases", "comments": null, "journal-ref": "Proc. AAAI, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning on discrete domains, such as learning\npreference functions in recommender systems or auctions, can be reduced to\nestimating a set function that is sparse in the Fourier domain. In this work,\nwe present a new family of algorithms for learning Fourier-sparse set\nfunctions. They require at most $nk - k \\log_2 k + k$ queries (set function\nevaluations), under mild conditions on the Fourier coefficients, where $n$ is\nthe size of the ground set and $k$ the number of non-zero Fourier coefficients.\nIn contrast to other work that focused on the orthogonal Walsh-Hadamard\ntransform, our novel algorithms operate with recently introduced non-orthogonal\nFourier transforms that offer different notions of Fourier-sparsity. These\nnaturally arise when modeling, e.g., sets of items forming substitutes and\ncomplements. We demonstrate effectiveness on several real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 14:31:59 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:07:10 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 12:26:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wendler", "Chris", ""], ["Amrollahi", "Andisheh", ""], ["Seifert", "Bastian", ""], ["Krause", "Andreas", ""], ["P\u00fcschel", "Markus", ""]]}, {"id": "2010.00462", "submitter": "Ly Antoine PhD", "authors": "Antoine Ly, Benno Uthayasooriyar, Tingting Wang", "title": "A survey on natural language processing (nlp) and applications in\n  insurance", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text is the most widely used means of communication today. This data is\nabundant but nevertheless complex to exploit within algorithms. For years,\nscientists have been trying to implement different techniques that enable\ncomputers to replicate some mechanisms of human reading. During the past five\nyears, research disrupted the capacity of the algorithms to unleash the value\nof text data. It brings today, many opportunities for the insurance\nindustry.Understanding those methods and, above all, knowing how to apply them\nis a major challenge and key to unleash the value of text data that have been\nstored for many years. Processing language with computer brings many new\nopportunities especially in the insurance sector where reports are central in\nthe information used by insurers. SCOR's Data Analytics team has been working\non the implementation of innovative tools or products that enable the use of\nthe latest research on text analysis. Understanding text mining techniques in\ninsurance enhances the monitoring of the underwritten risks and many processes\nthat finally benefit policyholders.This article proposes to explain\nopportunities that Natural Language Processing (NLP) are providing to\ninsurance. It details different methods used today in practice traces back the\nstory of them. We also illustrate the implementation of certain methods using\nopen source libraries and python codes that we have developed to facilitate the\nuse of these techniques.After giving a general overview on the evolution of\ntext mining during the past few years,we share about how to conduct a full\nstudy with text mining and share some examples to serve those models into\ninsurance products or services. Finally, we explained in more details every\nstep that composes a Natural Language Processing study to ensure the reader can\nhave a deep understanding on the implementation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 14:56:18 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Ly", "Antoine", ""], ["Uthayasooriyar", "Benno", ""], ["Wang", "Tingting", ""]]}, {"id": "2010.00467", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, Jun Zhu", "title": "Bag of Tricks for Adversarial Training", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is one of the most effective strategies for\npromoting model robustness. However, recent benchmarks show that most of the\nproposed improvements on AT are less effective than simply early stopping the\ntraining procedure. This counter-intuitive fact motivates us to investigate the\nimplementation details of tens of AT methods. Surprisingly, we find that the\nbasic settings (e.g., weight decay, training schedule, etc.) used in these\nmethods are highly inconsistent. In this work, we provide comprehensive\nevaluations on CIFAR-10, focusing on the effects of mostly overlooked training\ntricks and hyperparameters for adversarially trained models. Our empirical\nobservations suggest that adversarial robustness is much more sensitive to some\nbasic training settings than we thought. For example, a slightly different\nvalue of weight decay can reduce the model robust accuracy by more than 7%,\nwhich is probable to override the potential promotion induced by the proposed\nmethods. We conclude a baseline training setting and re-implement previous\ndefenses to achieve new state-of-the-art results. These facts also appeal to\nmore concerns on the overlooked confounders when benchmarking defenses.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:03:51 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 16:36:29 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 09:34:21 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Pang", "Tianyu", ""], ["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2010.00475", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, Xavier\n  Serra", "title": "FSD50K: an Open Dataset of Human-Labeled Sound Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most existing datasets for sound event recognition (SER) are relatively small\nand/or domain-specific, with the exception of AudioSet, based on a massive\namount of audio tracks from YouTube videos and encompassing over 500 classes of\neveryday sounds. However, AudioSet is not an open dataset---its release\nconsists of pre-computed audio features (instead of waveforms), which limits\nthe adoption of some SER methods. Downloading the original audio tracks is also\nproblematic due to constituent YouTube videos gradually disappearing and usage\nrights issues, which casts doubts over the suitability of this resource for\nsystems' benchmarking. To provide an alternative benchmark dataset and thus\nfoster SER research, we introduce FSD50K, an open dataset containing over 51k\naudio clips totalling over 100h of audio manually labeled using 200 classes\ndrawn from the AudioSet Ontology. The audio clips are licensed under Creative\nCommons licenses, making the dataset freely distributable (including\nwaveforms). We provide a detailed description of the FSD50K creation process,\ntailored to the particularities of Freesound data, including challenges\nencountered and solutions adopted. We include a comprehensive dataset\ncharacterization along with discussion of limitations and key factors to allow\nits audio-informed usage. Finally, we conduct sound event classification\nexperiments to provide baseline systems as well as insight on the main factors\nto consider when splitting Freesound audio data for SER. Our goal is to develop\na dataset to be widely adopted by the community as a new open benchmark for SER\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:07:25 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Favory", "Xavier", ""], ["Pons", "Jordi", ""], ["Font", "Frederic", ""], ["Serra", "Xavier", ""]]}, {"id": "2010.00482", "submitter": "Arash Mahyari", "authors": "Arash Mahyari, Peter Pirolli", "title": "Physical Exercise Recommendation and Success Prediction Using\n  Interconnected Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unhealthy behaviors, e.g., physical inactivity and unhealthful food choice,\nare the primary healthcare cost drivers in developed countries. Pervasive\ncomputational, sensing, and communication technology provided by smartphones\nand smartwatches have made it possible to support individuals in their everyday\nlives to develop healthier lifestyles. In this paper, we propose an exercise\nrecommendation system that also predicts individual success rates. The system,\nconsisting of two inter-connected recurrent neural networks (RNNs), uses the\nhistory of workouts to recommend the next workout activity for each individual.\nThe system then predicts the probability of successful completion of the\npredicted activity by the individual. The prediction accuracy of this\ninterconnected-RNN model is assessed on previously published data from a\nfour-week mobile health experiment and is shown to improve upon previous\npredictions from a computational cognitive model.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:22:59 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 20:04:20 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Mahyari", "Arash", ""], ["Pirolli", "Peter", ""]]}, {"id": "2010.00500", "submitter": "Justyna P. Zwolak", "authors": "Justyna P. Zwolak, Sandesh S. Kalantre, Thomas McJunkin, Brian J.\n  Weber, Jacob M. Taylor", "title": "Ray-based classification framework for high-dimensional data", "comments": null, "journal-ref": "Proceedings of the Machine Learning and the Physical Sciences\n  Workshop at NeurIPS 2020, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mes-hall cs.CV quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classification of arbitrary structures in high dimensions may require\ncomplete quantitative information, for simple geometrical structures,\nlow-dimensional qualitative information about the boundaries defining the\nstructures can suffice. Rather than using dense, multi-dimensional data, we\npropose a deep neural network (DNN) classification framework that utilizes a\nminimal collection of one-dimensional representations, called \\emph{rays}, to\nconstruct the \"fingerprint\" of the structure(s) based on substantially reduced\ninformation. We empirically study this framework using a synthetic dataset of\ndouble and triple quantum dot devices and apply it to the classification\nproblem of identifying the device state. We show that the performance of the\nray-based classifier is already on par with traditional 2D images for low\ndimensional systems, while significantly cutting down the data acquisition\ncost.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:46:29 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zwolak", "Justyna P.", ""], ["Kalantre", "Sandesh S.", ""], ["McJunkin", "Thomas", ""], ["Weber", "Brian J.", ""], ["Taylor", "Jacob M.", ""]]}, {"id": "2010.00509", "submitter": "Sarah Alnegheimish", "authors": "Sarah Alnegheimish, Najat Alrashed, Faisal Aleissa, Shahad Althobaiti,\n  Dongyu Liu, Mansour Alsaleh and Kalyan Veeramachaneni", "title": "Cardea: An Open Automated Machine Learning Framework for Electronic\n  Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An estimated 180 papers focusing on deep learning and EHR were published\nbetween 2010 and 2018. Despite the common workflow structure appearing in these\npublications, no trusted and verified software framework exists, forcing\nresearchers to arduously repeat previous work. In this paper, we propose\nCardea, an extensible open-source automated machine learning framework\nencapsulating common prediction problems in the health domain and allows users\nto build predictive models with their own data. This system relies on two\ncomponents: Fast Healthcare Interoperability Resources (FHIR) -- a standardized\ndata structure for electronic health systems -- and several AUTOML frameworks\nfor automated feature engineering, model selection, and tuning. We augment\nthese components with an adaptive data assembler and comprehensive data- and\nmodel- auditing capabilities. We demonstrate our framework via 5 prediction\ntasks on MIMIC-III and Kaggle datasets, which highlight Cardea's human\ncompetitiveness, flexibility in problem definition, extensive feature\ngeneration capability, adaptable automatic data assembler, and its usability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:58:13 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Alnegheimish", "Sarah", ""], ["Alrashed", "Najat", ""], ["Aleissa", "Faisal", ""], ["Althobaiti", "Shahad", ""], ["Liu", "Dongyu", ""], ["Alsaleh", "Mansour", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "2010.00521", "submitter": "Litu Rout", "authors": "Litu Rout", "title": "Why Adversarial Interaction Creates Non-Homogeneous Patterns: A\n  Pseudo-Reaction-Diffusion Model for Turing Instability", "comments": "35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long after Turing's seminal Reaction-Diffusion (RD) model, the elegance of\nhis fundamental equations alleviated much of the skepticism surrounding pattern\nformation. Though Turing model is a simplification and an idealization, it is\none of the best-known theoretical models to explain patterns as a reminiscent\nof those observed in nature. Over the years, concerted efforts have been made\nto align theoretical models to explain patterns in real systems. The apparent\ndifficulty in identifying the specific dynamics of the RD system makes the\nproblem particularly challenging. Interestingly, we observe Turing-like\npatterns in a system of neurons with adversarial interaction. In this study, we\nestablish the involvement of Turing instability to create such patterns. By\ntheoretical and empirical studies, we present a pseudo-reaction-diffusion model\nto explain the mechanism that may underlie these phenomena. While supervised\nlearning attains homogeneous equilibrium, this paper suggests that the\nintroduction of an adversary helps break this homogeneity to create\nnon-homogeneous patterns at equilibrium. Further, we prove that randomly\ninitialized gradient descent with over-parameterization can converge\nexponentially fast to an $\\epsilon$-stationary point even under adversarial\ninteraction. In addition, different from sole supervision, we show that the\nsolutions obtained under adversarial interaction are not limited to a tiny\nsubspace around initialization.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:09:22 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 10:29:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rout", "Litu", ""]]}, {"id": "2010.00522", "submitter": "Litu Rout", "authors": "Litu Rout", "title": "Understanding the Role of Adversarial Regularization in Supervised\n  Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite numerous attempts sought to provide empirical evidence of adversarial\nregularization outperforming sole supervision, the theoretical understanding of\nsuch phenomena remains elusive. In this study, we aim to resolve whether\nadversarial regularization indeed performs better than sole supervision at a\nfundamental level. To bring this insight into fruition, we study vanishing\ngradient issue, asymptotic iteration complexity, gradient flow and provable\nconvergence in the context of sole supervision and adversarial regularization.\nThe key ingredient is a theoretical justification supported by empirical\nevidence of adversarial acceleration in gradient descent. In addition,\nmotivated by a recently introduced unit-wise capacity based generalization\nbound, we analyze the generalization error in adversarial framework. Guided by\nour observation, we cast doubts on the ability of this measure to explain\ngeneralization. We therefore leave as open questions to explore new measures\nthat can explain generalization behavior in adversarial learning. Furthermore,\nwe observe an intriguing phenomenon in the neural embedded vector space while\ncontrasting adversarial learning with sole supervision.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:10:05 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Rout", "Litu", ""]]}, {"id": "2010.00525", "submitter": "David Lipshutz", "authors": "David Lipshutz, Yanis Bahroun, Siavash Golkar, Anirvan M. Sengupta,\n  Dmitri B. Chklovskii", "title": "A biologically plausible neural network for multi-channel Canonical\n  Correlation Analysis", "comments": "46 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical pyramidal neurons receive inputs from multiple distinct neural\npopulations and integrate these inputs in separate dendritic compartments. We\nexplore the possibility that cortical microcircuits implement Canonical\nCorrelation Analysis (CCA), an unsupervised learning method that projects the\ninputs onto a common subspace so as to maximize the correlations between the\nprojections. To this end, we seek a multi-channel CCA algorithm that can be\nimplemented in a biologically plausible neural network. For biological\nplausibility, we require that the network operates in the online setting and\nits synaptic update rules are local. Starting from a novel CCA objective\nfunction, we derive an online optimization algorithm whose optimization steps\ncan be implemented in a single-layer neural network with multi-compartmental\nneurons and local non-Hebbian learning rules. We also derive an extension of\nour online CCA algorithm with adaptive output rank and output whitening.\nInterestingly, the extension maps onto a neural network whose neural\narchitecture and synaptic updates resemble neural circuitry and synaptic\nplasticity observed experimentally in cortical pyramidal neurons.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:17:53 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 22:27:18 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 16:52:07 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 16:18:09 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Lipshutz", "David", ""], ["Bahroun", "Yanis", ""], ["Golkar", "Siavash", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2010.00539", "submitter": "Quanquan Gu", "authors": "Spencer Frei and Yuan Cao and Quanquan Gu", "title": "Agnostic Learning of Halfspaces with Gradient Descent via Soft Margins", "comments": "25 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the properties of gradient descent on convex surrogates for the\nzero-one loss for the agnostic learning of linear halfspaces. If $\\mathsf{OPT}$\nis the best classification error achieved by a halfspace, by appealing to the\nnotion of soft margins we are able to show that gradient descent finds\nhalfspaces with classification error $\\tilde O(\\mathsf{OPT}^{1/2}) +\n\\varepsilon$ in $\\mathrm{poly}(d,1/\\varepsilon)$ time and sample complexity for\na broad class of distributions that includes log-concave isotropic\ndistributions as a subclass. Along the way we answer a question recently posed\nby Ji et al. (2020) on how the tail behavior of a loss function can affect\nsample complexity and runtime guarantees for gradient descent.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:48:33 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 02:20:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Frei", "Spencer", ""], ["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2010.00540", "submitter": "Michael Everett", "authors": "Michael Everett, Golnaz Habibi, Jonathan P. How", "title": "Robustness Analysis of Neural Networks via Efficient Partitioning with\n  Applications in Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) are now routinely implemented on systems that must\noperate in uncertain environments, but the tools for formally analyzing how\nthis uncertainty propagates to NN outputs are not yet commonplace. Computing\ntight bounds on NN output sets (given an input set) provides a measure of\nconfidence associated with the NN decisions and is essential to deploy NNs on\nsafety-critical systems. Recent works approximate the propagation of sets\nthrough nonlinear activations or partition the uncertainty set to provide a\nguaranteed outer bound on the set of possible NN outputs. However, the bound\nlooseness causes excessive conservatism and/or the computation is too slow for\nonline analysis. This paper unifies propagation and partition approaches to\nprovide a family of robustness analysis algorithms that give tighter bounds\nthan existing works for the same amount of computation time (or reduced\ncomputational effort for a desired accuracy level). Moreover, we provide new\npartitioning techniques that are aware of their current bound estimates and\ndesired boundary shape (e.g., lower bounds, weighted $\\ell_\\infty$-ball, convex\nhull), leading to further improvements in the computation-tightness tradeoff.\nThe paper demonstrates the tighter bounds and reduced conservatism of the\nproposed robustness analysis framework with examples from model-free RL and\nforward kinematics learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:51:36 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:41:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Everett", "Michael", ""], ["Habibi", "Golnaz", ""], ["How", "Jonathan P.", ""]]}, {"id": "2010.00554", "submitter": "Brian McWilliams", "authors": "Ian Gemp, Brian McWilliams, Claire Vernade, Thore Graepel", "title": "EigenGame: PCA as a Nash Equilibrium", "comments": "Published as a conference paper at International Conference on\n  Learning Representations (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel view on principal component analysis (PCA) as a\ncompetitive game in which each approximate eigenvector is controlled by a\nplayer whose goal is to maximize their own utility function. We analyze the\nproperties of this PCA game and the behavior of its gradient based updates. The\nresulting algorithm -- which combines elements from Oja's rule with a\ngeneralized Gram-Schmidt orthogonalization -- is naturally decentralized and\nhence parallelizable through message passing. We demonstrate the scalability of\nthe algorithm with experiments on large image datasets and neural network\nactivations. We discuss how this new view of PCA as a differentiable game can\nlead to further algorithmic developments and insights.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:12:33 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 20:43:46 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Gemp", "Ian", ""], ["McWilliams", "Brian", ""], ["Vernade", "Claire", ""], ["Graepel", "Thore", ""]]}, {"id": "2010.00567", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz", "title": "Deep learning for time series classification", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series analysis is a field of data science which is interested in\nanalyzing sequences of numerical values ordered in time. Time series are\nparticularly interesting because they allow us to visualize and understand the\nevolution of a process over time. Their analysis can reveal trends,\nrelationships and similarities across the data. There exists numerous fields\ncontaining data in the form of time series: health care (electrocardiogram,\nblood sugar, etc.), activity recognition, remote sensing, finance (stock market\nprice), industry (sensors), etc. Time series classification consists of\nconstructing algorithms dedicated to automatically label time series data. The\nsequential aspect of time series data requires the development of algorithms\nthat are able to harness this temporal property, thus making the existing\noff-the-shelf machine learning models for traditional tabular data suboptimal\nfor solving the underlying task. In this context, deep learning has emerged in\nrecent years as one of the most effective methods for tackling the supervised\nclassification task, particularly in the field of computer vision. The main\nobjective of this thesis was to study and develop deep neural networks\nspecifically constructed for the classification of time series data. We thus\ncarried out the first large scale experimental study allowing us to compare the\nexisting deep methods and to position them compared other non-deep learning\nbased state-of-the-art methods. Subsequently, we made numerous contributions in\nthis area, notably in the context of transfer learning, data augmentation,\nensembling and adversarial attacks. Finally, we have also proposed a novel\narchitecture, based on the famous Inception network (Google), which ranks among\nthe most efficient to date.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:38:40 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Fawaz", "Hassan Ismail", ""]]}, {"id": "2010.00577", "submitter": "Michael Sejr Schlichtkrull", "authors": "Michael Sejr Schlichtkrull, Nicola De Cao, Ivan Titov", "title": "Interpreting Graph Neural Networks for NLP With Differentiable Edge\n  Masking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have become a popular approach to integrating\nstructural inductive biases into NLP models. However, there has been little\nwork on interpreting them, and specifically on understanding which parts of the\ngraphs (e.g. syntactic trees or co-reference structures) contribute to a\nprediction. In this work, we introduce a post-hoc method for interpreting the\npredictions of GNNs which identifies unnecessary edges. Given a trained GNN\nmodel, we learn a simple classifier that, for every edge in every layer,\npredicts if that edge can be dropped. We demonstrate that such a classifier can\nbe trained in a fully differentiable fashion, employing stochastic gates and\nencouraging sparsity through the expected $L_0$ norm. We use our technique as\nan attribution method to analyze GNN models for two tasks -- question answering\nand semantic role labeling -- providing insights into the information flow in\nthese models. We show that we can drop a large proportion of edges without\ndeteriorating the performance of the model, while we can analyse the remaining\nedges for interpreting model predictions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:51:19 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 10:17:42 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Schlichtkrull", "Michael Sejr", ""], ["De Cao", "Nicola", ""], ["Titov", "Ivan", ""]]}, {"id": "2010.00578", "submitter": "Yuandong Tian", "authors": "Yuandong Tian and Lantao Yu and Xinlei Chen and Surya Ganguli", "title": "Understanding Self-supervised Learning with Dual Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel theoretical framework to understand contrastive\nself-supervised learning (SSL) methods that employ dual pairs of deep ReLU\nnetworks (e.g., SimCLR). First, we prove that in each SGD update of SimCLR with\nvarious loss functions, including simple contrastive loss, soft Triplet loss\nand InfoNCE loss, the weights at each layer are updated by a \\emph{covariance\noperator} that specifically amplifies initial random selectivities that vary\nacross data samples but survive averages over data augmentations. To further\nstudy what role the covariance operator plays and which features are learned in\nsuch a process, we model data generation and augmentation processes through a\n\\emph{hierarchical latent tree model} (HLTM) and prove that the hidden neurons\nof deep ReLU networks can learn the latent variables in HLTM, despite the fact\nthat the network receives \\emph{no direct supervision} from these unobserved\nlatent variables. This leads to a provable emergence of hierarchical features\nthrough the amplification of initially random selectivities through contrastive\nSSL. Extensive numerical studies justify our theoretical findings. Code is\nreleased in https://github.com/facebookresearch/luckmatters/tree/master/ssl.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:51:49 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 17:42:46 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:13:52 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 18:52:22 GMT"}, {"version": "v5", "created": "Wed, 2 Dec 2020 18:34:58 GMT"}, {"version": "v6", "created": "Mon, 15 Feb 2021 04:51:42 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tian", "Yuandong", ""], ["Yu", "Lantao", ""], ["Chen", "Xinlei", ""], ["Ganguli", "Surya", ""]]}, {"id": "2010.00581", "submitter": "Kamal Ndousse", "authors": "Kamal Ndousse, Douglas Eck, Sergey Levine, Natasha Jaques", "title": "Emergent Social Learning via Multi-agent Reinforcement Learning", "comments": "14 pages, 19 figures. To be published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social learning is a key component of human and animal intelligence. By\ntaking cues from the behavior of experts in their environment, social learners\ncan acquire sophisticated behavior and rapidly adapt to new circumstances. This\npaper investigates whether independent reinforcement learning (RL) agents in a\nmulti-agent environment can learn to use social learning to improve their\nperformance. We find that in most circumstances, vanilla model-free RL agents\ndo not use social learning. We analyze the reasons for this deficiency, and\nshow that by imposing constraints on the training environment and introducing a\nmodel-based auxiliary loss we are able to obtain generalized social learning\npolicies which enable agents to: i) discover complex skills that are not\nlearned from single-agent training, and ii) adapt online to novel environments\nby taking cues from experts present in the new environment. In contrast, agents\ntrained with model-free RL or imitation learning generalize poorly and do not\nsucceed in the transfer tasks. By mixing multi-agent and solo training, we can\nobtain agents that use social learning to gain skills that they can deploy when\nalone, even out-performing agents trained alone from the start.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:54:14 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:02:43 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 21:18:59 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ndousse", "Kamal", ""], ["Eck", "Douglas", ""], ["Levine", "Sergey", ""], ["Jaques", "Natasha", ""]]}, {"id": "2010.00587", "submitter": "Quanquan Gu", "authors": "Jiafan He and Dongruo Zhou and Quanquan Gu", "title": "Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs", "comments": "37 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reinforcement learning problem for discounted Markov Decision\nProcesses (MDPs) under the tabular setting. We propose a model-based algorithm\nnamed UCBVI-$\\gamma$, which is based on the \\emph{optimism in the face of\nuncertainty principle} and the Bernstein-type bonus. We show that\nUCBVI-$\\gamma$ achieves an $\\tilde{O}\\big({\\sqrt{SAT}}/{(1-\\gamma)^{1.5}}\\big)$\nregret, where $S$ is the number of states, $A$ is the number of actions,\n$\\gamma$ is the discount factor and $T$ is the number of steps. In addition, we\nconstruct a class of hard MDPs and show that for any algorithm, the expected\nregret is at least $\\tilde{\\Omega}\\big({\\sqrt{SAT}}/{(1-\\gamma)^{1.5}}\\big)$.\nOur upper bound matches the minimax lower bound up to logarithmic factors,\nwhich suggests that UCBVI-$\\gamma$ is nearly minimax optimal for discounted\nMDPs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:57:47 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:34:04 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["He", "Jiafan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2010.00636", "submitter": "Roi Weiss", "authors": "L\\'aszl\\'o Gy\\\"orfi and Roi Weiss", "title": "Universal consistency and rates of convergence of multiclass prototype\n  algorithms in metric spaces", "comments": "To appear in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study universal consistency and convergence rates of simple\nnearest-neighbor prototype rules for the problem of multiclass classification\nin metric paces. We first show that a novel data-dependent partitioning rule,\nnamed Proto-NN, is universally consistent in any metric space that admits a\nuniversally consistent rule. Proto-NN is a significant simplification of\nOptiNet, a recently proposed compression-based algorithm that, to date, was the\nonly algorithm known to be universally consistent in such a general setting.\nPractically, Proto-NN is simpler to implement and enjoys reduced computational\ncomplexity.\n  We then proceed to study convergence rates of the excess error probability.\nWe first obtain rates for the standard $k$-NN rule under a margin condition and\na new generalized-Lipschitz condition. The latter is an extension of a recently\nproposed modified-Lipschitz condition from $\\mathbb R^d$ to metric spaces.\nSimilarly to the modified-Lipschitz condition, the new condition avoids any\nboundness assumptions on the data distribution. While obtaining rates for\nProto-NN is left open, we show that a second prototype rule that hybridizes\nbetween $k$-NN and Proto-NN achieves the same rates as $k$-NN while enjoying\nsimilar computational advantages as Proto-NN. However, as $k$-NN, this hybrid\nrule is not consistent in general.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 18:23:22 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 16:43:31 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Gy\u00f6rfi", "L\u00e1szl\u00f3", ""], ["Weiss", "Roi", ""]]}, {"id": "2010.00654", "submitter": "Zhisheng Xiao", "authors": "Zhisheng Xiao, Karsten Kreis, Jan Kautz, Arash Vahdat", "title": "VAEBM: A Symbiosis between Variational Autoencoders and Energy-based\n  Models", "comments": "ICLR 2021 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) have recently been successful in representing\ncomplex distributions of small images. However, sampling from them requires\nexpensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high\ndimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate\nsamples quickly and are equipped with a latent space that enables fast\ntraversal of the data manifold. However, VAEs tend to assign high probability\ndensity to regions in data space outside the actual data distribution and often\nfail at generating sharp images. In this paper, we propose VAEBM, a symbiotic\ncomposition of a VAE and an EBM that offers the best of both worlds. VAEBM\ncaptures the overall mode structure of the data distribution using a\nstate-of-the-art VAE and it relies on its EBM component to explicitly exclude\nnon-data-like regions from the model and refine the image samples. Moreover,\nthe VAE component in VAEBM allows us to speed up MCMC updates by\nreparameterizing them in the VAE's latent space. Our experimental results show\nthat VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on\nseveral benchmark image datasets by a large margin. It can generate\nhigh-quality images as large as 256$\\times$256 pixels with short MCMC chains.\nWe also demonstrate that VAEBM provides complete mode coverage and performs\nwell in out-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 19:28:28 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 16:41:47 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Xiao", "Zhisheng", ""], ["Kreis", "Karsten", ""], ["Kautz", "Jan", ""], ["Vahdat", "Arash", ""]]}, {"id": "2010.00661", "submitter": "Md Hasan Shahriar", "authors": "Nur Imtiazul Haque, Md Hasan Shahriar, Md Golam Dastgir, Anjan\n  Debnath, Imtiaz Parvez, Arif Sarwat, Mohammad Ashiqur Rahman", "title": "Machine Learning in Generation, Detection, and Mitigation of\n  Cyberattacks in Smart Grid: A Survey", "comments": "6 pages, 4 figures, accepted in 2020 North American Power Symposium\n  (NAPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid (SG) is a complex cyber-physical system that utilizes modern cyber\nand physical equipment to run at an optimal operating point. Cyberattacks are\nthe principal threats confronting the usage and advancement of the\nstate-of-the-art systems. The advancement of SG has added a wide range of\ntechnologies, equipment, and tools to make the system more reliable, efficient,\nand cost-effective. Despite attaining these goals, the threat space for the\nadversarial attacks has also been expanded because of the extensive\nimplementation of the cyber networks. Due to the promising computational and\nreasoning capability, machine learning (ML) is being used to exploit and defend\nthe cyberattacks in SG by the attackers and system operators, respectively. In\nthis paper, we perform a comprehensive summary of cyberattacks generation,\ndetection, and mitigation schemes by reviewing state-of-the-art research in the\nSG domain. Additionally, we have summarized the current research in a\nstructured way using tabular format. We also present the shortcomings of the\nexisting works and possible future research direction based on our\ninvestigation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:16:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Haque", "Nur Imtiazul", ""], ["Shahriar", "Md Hasan", ""], ["Dastgir", "Md Golam", ""], ["Debnath", "Anjan", ""], ["Parvez", "Imtiaz", ""], ["Sarwat", "Arif", ""], ["Rahman", "Mohammad Ashiqur", ""]]}, {"id": "2010.00679", "submitter": "Li Jing", "authors": "Li Jing, Jure Zbontar, Yann LeCun", "title": "Implicit Rank-Minimizing Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important component of autoencoders is the method by which the information\ncapacity of the latent representation is minimized or limited. In this work,\nthe rank of the covariance matrix of the codes is implicitly minimized by\nrelying on the fact that gradient descent learning in multi-layer linear\nnetworks leads to minimum-rank solutions. By inserting a number of extra linear\nlayers between the encoder and the decoder, the system spontaneously learns\nrepresentations with a low effective dimension. The model, dubbed Implicit\nRank-Minimizing Autoencoder (IRMAE), is simple, deterministic, and learns\ncompact latent spaces. We demonstrate the validity of the method on several\nimage generation and representation learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 20:48:52 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 15:36:27 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Jing", "Li", ""], ["Zbontar", "Jure", ""], ["LeCun", "Yann", ""]]}, {"id": "2010.00712", "submitter": "Jinjie Zhang", "authors": "Jinjie Zhang, Rayan Saab", "title": "Faster Binary Embeddings for Preserving Euclidean Distances", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast, distance-preserving, binary embedding algorithm to\ntransform a high-dimensional dataset $\\mathcal{T}\\subseteq\\mathbb{R}^n$ into\nbinary sequences in the cube $\\{\\pm 1\\}^m$. When $\\mathcal{T}$ consists of\nwell-spread (i.e., non-sparse) vectors, our embedding method applies a stable\nnoise-shaping quantization scheme to $A x$ where $A\\in\\mathbb{R}^{m\\times n}$\nis a sparse Gaussian random matrix. This contrasts with most binary embedding\nmethods, which usually use $x\\mapsto \\mathrm{sign}(Ax)$ for the embedding.\nMoreover, we show that Euclidean distances among the elements of $\\mathcal{T}$\nare approximated by the $\\ell_1$ norm on the images of $\\{\\pm 1\\}^m$ under a\nfast linear transformation. This again contrasts with standard methods, where\nthe Hamming distance is used instead. Our method is both fast and memory\nefficient, with time complexity $O(m)$ and space complexity $O(m)$. Further, we\nprove that the method is accurate and its associated error is comparable to\nthat of a continuous valued Johnson-Lindenstrauss embedding plus a quantization\nerror that admits a polynomial decay as the embedding dimension $m$ increases.\nThus the length of the binary codes required to achieve a desired accuracy is\nquite small, and we show it can even be compressed further without compromising\nthe accuracy. To illustrate our results, we test the proposed method on natural\nimages and show that it achieves strong performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 22:41:41 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 01:30:22 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Zhang", "Jinjie", ""], ["Saab", "Rayan", ""]]}, {"id": "2010.00718", "submitter": "Byron Jaeger", "authors": "Byron C. Jaeger, Nicholas J. Tierney, Noah R. Simon", "title": "When to Impute? Imputation before and during cross-validation", "comments": "11 pages (main text, not including references), 6 tables, and 4\n  figures. Code to replicate manuscript available at\n  https://github.com/bcjaeger/Imputation-and-CV", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-validation (CV) is a technique used to estimate generalization error\nfor prediction models. For pipeline modeling algorithms (i.e. modeling\nprocedures with multiple steps), it has been recommended the entire sequence of\nsteps be carried out during each replicate of CV to mimic the application of\nthe entire pipeline to an external testing set. While theoretically sound,\nfollowing this recommendation can lead to high computational costs when a\npipeline modeling algorithm includes computationally expensive operations, e.g.\nimputation of missing values. There is a general belief that unsupervised\nvariable selection (i.e. ignoring the outcome) can be applied before conducting\nCV without incurring bias, but there is less consensus for unsupervised\nimputation of missing values. We empirically assessed whether conducting\nunsupervised imputation prior to CV would result in biased estimates of\ngeneralization error or result in poorly selected tuning parameters and thus\ndegrade the external performance of downstream models. Results show that\ndespite optimistic bias, the reduced variance of imputation before CV compared\nto imputation during each replicate of CV leads to a lower overall root mean\nsquared error for estimation of the true external R-squared and the performance\nof models tuned using CV with imputation before versus during each replication\nis minimally different. In conclusion, unsupervised imputation before CV\nappears valid in certain settings and may be a helpful strategy that enables\nanalysts to use more flexible imputation techniques without incurring high\ncomputational costs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 23:04:16 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Jaeger", "Byron C.", ""], ["Tierney", "Nicholas J.", ""], ["Simon", "Noah R.", ""]]}, {"id": "2010.00724", "submitter": "Amir Shahmoradi", "authors": "Amir Shahmoradi, Fatemeh Bagheri, Joshua Alexander Osborne", "title": "Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations\n  and visualizations via ParaMonte::Python library", "comments": "to be submitted to JOSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS astro-ph.IM q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial\nand MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for\nsampling mathematical objective functions, in particular, the posterior\ndistributions of parameters in Bayesian modeling and analysis in data science,\nMachine Learning, and scientific inference in general. In addition to providing\naccess to fast high-performance serial/parallel Monte Carlo and MCMC sampling\nroutines, the ParaMonte::Python library provides extensive post-processing and\nvisualization tools that aim to automate and streamline the process of model\ncalibration and uncertainty quantification in Bayesian data analysis.\nFurthermore, the automatically-enabled restart functionality of\nParaMonte::Python samplers ensure seamless fully-deterministic into-the-future\nrestart of Monte Carlo simulations, should any interruptions happen. The\nParaMonte::Python library is MIT-licensed and is permanently maintained on\nGitHub at\nhttps://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 23:26:42 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Shahmoradi", "Amir", ""], ["Bagheri", "Fatemeh", ""], ["Osborne", "Joshua Alexander", ""]]}, {"id": "2010.00743", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Kyle Istvan, Ghada Zamzmi", "title": "Cell Complex Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell complexes are topological spaces constructed from simple blocks called\ncells. They generalize graphs, simplicial complexes, and polyhedral complexes\nthat form important domains for practical applications. They also provide a\ncombinatorial formalism that allows the inclusion of complicated relationships\nof restrictive structures such as graphs and meshes. In this paper, we propose\n\\textbf{Cell Complexes Neural Networks (CXNs)}, a general, combinatorial and\nunifying construction for performing neural network-type computations on cell\ncomplexes. We introduce an inter-cellular message passing scheme on cell\ncomplexes that takes the topology of the underlying space into account and\ngeneralizes message passing scheme to graphs. Finally, we introduce a unified\ncell complex encoder-decoder framework that enables learning representation of\ncells for a given complex inside the Euclidean spaces. In particular, we show\nhow our cell complex autoencoder construction can give, in the special case\n\\textbf{cell2vec}, a generalization for node2vec.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 01:38:12 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 06:35:37 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2021 17:11:18 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 03:50:54 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Hajij", "Mustafa", ""], ["Istvan", "Kyle", ""], ["Zamzmi", "Ghada", ""]]}, {"id": "2010.00753", "submitter": "Kate Donahue", "authors": "Kate Donahue and Jon Kleinberg", "title": "Model-sharing Games: Analyzing Federated Learning Under Voluntary\n  Participation", "comments": "Accepted at AAAI 2021. Supplemental code at\n  https://github.com/kpdonahue/model_sharing_games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a setting where agents, each with access to their own\ndata source, combine models from local data to create a global model. If agents\nare drawing their data from different distributions, though, federated learning\nmight produce a biased global model that is not optimal for each agent. This\nmeans that agents face a fundamental question: should they choose the global\nmodel or their local model? We show how this situation can be naturally\nanalyzed through the framework of coalitional game theory.\n  We propose the following game: there are heterogeneous players with different\nmodel parameters governing their data distribution and different amounts of\ndata they have noisily drawn from their own distribution. Each player's goal is\nto obtain a model with minimal expected mean squared error (MSE) on their own\ndistribution. They have a choice of fitting a model based solely on their own\ndata, or combining their learned parameters with those of some subset of the\nother players. Combining models reduces the variance component of their error\nthrough access to more data, but increases the bias because of the\nheterogeneity of distributions.\n  Here, we derive exact expected MSE values for problems in linear regression\nand mean estimation. We then analyze the resulting game in the framework of\nhedonic game theory; we study how players might divide into coalitions, where\neach set of players within a coalition jointly construct model(s). We analyze\nthree methods of federation, modeling differing degrees of customization. In\nuniform federation, the agents collectively produce a single model. In\ncoarse-grained federation, each agent can weight the global model together with\ntheir local model. In fine-grained federation, each agent can flexibly combine\nmodels from all other agents in the federation. For each method, we analyze the\nstable partitions of players into coalitions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 02:36:23 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 13:53:39 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 14:41:56 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Donahue", "Kate", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2010.00788", "submitter": "Santiago Gonzalez", "authors": "Santiago Gonzalez and Risto Miikkulainen", "title": "Effective Regularization Through Loss-Function Metalearning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loss-function metalearning can be used to discover novel, customized loss\nfunctions for deep neural networks, resulting in improved performance, faster\ntraining, and improved data utilization. A likely explanation is that such\nfunctions discourage overfitting, leading to effective regularization. This\npaper theoretically demonstrates that this is indeed the case: decomposition of\nlearning rules makes it possible to characterize the training dynamics and show\nthat loss functions evolved through TaylorGLO regularize both in the beginning\nand end of learning, and maintain an invariant in between. The invariant can be\nutilized to make the metalearning process more efficient in practice, and the\nregularization can train networks that are robust against adversarial attacks.\nLoss-function optimization can thus be seen as a well-founded new aspect of\nmetalearning in neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 05:22:21 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gonzalez", "Santiago", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2010.00792", "submitter": "Katsuhiko Ishiguro", "authors": "Katsuhiko Ishiguro, Kazuya Ujihara, Ryohto Sawada, Hirotaka Akita,\n  Masaaki Kotera", "title": "Data Transfer Approaches to Improve Seq-to-Seq Retrosynthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrosynthesis is a problem to infer reactant compounds to synthesize a given\nproduct compound through chemical reactions. Recent studies on retrosynthesis\nfocus on proposing more sophisticated prediction models, but the dataset to\nfeed the models also plays an essential role in achieving the best generalizing\nmodels. Generally, a dataset that is best suited for a specific task tends to\nbe small. In such a case, it is the standard solution to transfer knowledge\nfrom a large or clean dataset in the same domain. In this paper, we conduct a\nsystematic and intensive examination of data transfer approaches on end-to-end\ngenerative models, in application to retrosynthesis. Experimental results show\nthat typical data transfer methods can improve test prediction scores of an\noff-the-shelf Transformer baseline model. Especially, the pre-training plus\nfine-tuning approach boosts the accuracy scores of the baseline, achieving the\nnew state-of-the-art. In addition, we conduct a manual inspection for the\nerroneous prediction results. The inspection shows that the pre-training plus\nfine-tuning models can generate chemically appropriate or sensible proposals in\nalmost all cases.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 05:27:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Ishiguro", "Katsuhiko", ""], ["Ujihara", "Kazuya", ""], ["Sawada", "Ryohto", ""], ["Akita", "Hirotaka", ""], ["Kotera", "Masaaki", ""]]}, {"id": "2010.00821", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Yao Rong, Thomas Motz, Michael Scheidt, Andreas Hartel,\n  Andreas Koch, Enkelejda Kasneci", "title": "Explainable Online Validation of Machine Learning Models for Practical\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reformulation of the regression and classification, which aims\nto validate the result of a machine learning algorithm. Our reformulation\nsimplifies the original problem and validates the result of the machine\nlearning algorithm using the training data. Since the validation of machine\nlearning algorithms must always be explainable, we perform our experiments with\nthe kNN algorithm as well as with an algorithm based on conditional\nprobabilities, which is proposed in this work. For the evaluation of our\napproach, three publicly available data sets were used and three classification\nand two regression problems were evaluated. The presented algorithm based on\nconditional probabilities is also online capable and requires only a fraction\nof memory compared to the kNN algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 07:38:31 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 14:20:29 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 12:26:28 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Rong", "Yao", ""], ["Motz", "Thomas", ""], ["Scheidt", "Michael", ""], ["Hartel", "Andreas", ""], ["Koch", "Andreas", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2010.00827", "submitter": "Quanquan Gu", "authors": "Weitong Zhang and Dongruo Zhou and Lihong Li and Quanquan Gu", "title": "Neural Thompson Sampling", "comments": "32 pages, 2 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling (TS) is one of the most effective algorithms for solving\ncontextual multi-armed bandit problems. In this paper, we propose a new\nalgorithm, called Neural Thompson Sampling, which adapts deep neural networks\nfor both exploration and exploitation. At the core of our algorithm is a novel\nposterior distribution of the reward, where its mean is the neural network\napproximator, and its variance is built upon the neural tangent features of the\ncorresponding neural network. We prove that, provided the underlying reward\nfunction is bounded, the proposed algorithm is guaranteed to achieve a\ncumulative regret of $\\mathcal{O}(T^{1/2})$, which matches the regret of other\ncontextual bandit algorithms in terms of total round number $T$. Experimental\ncomparisons with other benchmark bandit algorithms on various data sets\ncorroborate our theory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 07:44:09 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Zhang", "Weitong", ""], ["Zhou", "Dongruo", ""], ["Li", "Lihong", ""], ["Gu", "Quanquan", ""]]}, {"id": "2010.00844", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Robert Burduk", "title": "Linear Classifier Combination via Multiple Potential Functions", "comments": null, "journal-ref": "Pattern Recognition, 107681 (2020)", "doi": "10.1016/j.patcog.2020.107681", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vital aspect of the classification based model construction process is the\ncalibration of the scoring function. One of the weaknesses of the calibration\nprocess is that it does not take into account the information about the\nrelative positions of the recognized objects in the feature space. To alleviate\nthis limitation, in this paper, we propose a novel concept of calculating a\nscoring function based on the distance of the object from the decision boundary\nand its distance to the class centroid. An important property is that the\nproposed score function has the same nature for all linear base classifiers,\nwhich means that outputs of these classifiers are equally represented and have\nthe same meaning. The proposed approach is compared with other ensemble\nalgorithms and experiments on multiple Keel datasets demonstrate the\neffectiveness of our method. To discuss the results of our experiments, we use\nmultiple classification performance measures and statistical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:11:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Trajdos", "Pawel", ""], ["Burduk", "Robert", ""]]}, {"id": "2010.00848", "submitter": "Franck Iutzeler", "authors": "Franck Iutzeler (DAO), J\\'er\\^ome Malick (DAO)", "title": "Nonsmoothness in Machine Learning: specific structure, proximal\n  identification, and applications", "comments": null, "journal-ref": "Set-Valued and Variational Analysis, Springer, 2020, 28 (4),\n  pp.661-678", "doi": null, "report-no": null, "categories": "math.OC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonsmoothness is often a curse for optimization; but it is sometimes a\nblessing, in particular for applications in machine learning. In this paper, we\npresent the specific structure of nonsmooth optimization problems appearing in\nmachine learning and illustrate how to leverage this structure in practice, for\ncompression, acceleration, or dimension reduction. We pay a special attention\nto the presentation to make it concise and easily accessible, with both simple\nexamples and general results.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:27:02 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 16:54:14 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Iutzeler", "Franck", "", "DAO"], ["Malick", "J\u00e9r\u00f4me", "", "DAO"]]}, {"id": "2010.00855", "submitter": "Arun Konagurthu", "authors": "Dinithi Sumanaweera, Lloyd Allison and Arun S. Konagurthu", "title": "Bridging the Gaps in Statistical Models of Protein Alignment", "comments": "Main text: 15 pages, 4 Figs Supplementary text: 12 pages, 6 Figs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work demonstrates how a complete statistical model quantifying the\nevolution of pairs of aligned proteins can be constructed from a\ntime-parameterised substitution matrix and a time-parameterised 3-state\nalignment machine. All parameters of such a model can be inferred from any\nbenchmark data-set of aligned protein sequences. This allows us to examine nine\nwell-known substitution matrices on six benchmarks curated using various\nstructural alignment methods; any matrix that does not explicitly model a\n\"time\"-dependent Markov process is converted to a corresponding base-matrix\nthat does. In addition, a new optimal matrix is inferred for each of the six\nbenchmarks. Using Minimum Message Length (MML) inference, all 15 matrices are\ncompared in terms of measuring the Shannon information content of each\nbenchmark. This has resulted in a new and clear overall best performed\ntime-dependent Markov matrix, MMLSUM, and its associated 3-state machine, whose\nproperties we have analysed in this work. For standard use, the MMLSUM series\nof (log-odds) \\textit{scoring} matrices derived from the above Markov matrix,\nare available at https://lcb.infotech.monash.edu.au/mmlsum.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:36:24 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Sumanaweera", "Dinithi", ""], ["Allison", "Lloyd", ""], ["Konagurthu", "Arun S.", ""]]}, {"id": "2010.00879", "submitter": "Ryo Karakida", "authors": "Ryo Karakida and Kazuki Osawa", "title": "Understanding Approximate Fisher Information for Fast Convergence of\n  Natural Gradient Descent in Wide Neural Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Gradient Descent (NGD) helps to accelerate the convergence of\ngradient descent dynamics, but it requires approximations in large-scale deep\nneural networks because of its high computational cost. Empirical studies have\nconfirmed that some NGD methods with approximate Fisher information converge\nsufficiently fast in practice. Nevertheless, it remains unclear from the\ntheoretical perspective why and under what conditions such heuristic\napproximations work well. In this work, we reveal that, under specific\nconditions, NGD with approximate Fisher information achieves the same fast\nconvergence to global minima as exact NGD. We consider deep neural networks in\nthe infinite-width limit, and analyze the asymptotic training dynamics of NGD\nin function space via the neural tangent kernel. In the function space, the\ntraining dynamics with the approximate Fisher information are identical to\nthose with the exact Fisher information, and they converge quickly. The fast\nconvergence holds in layer-wise approximations; for instance, in block diagonal\napproximation where each block corresponds to a layer as well as in block\ntri-diagonal and K-FAC approximations. We also find that a unit-wise\napproximation achieves the same fast convergence under some assumptions. All of\nthese different approximations have an isotropic gradient in the function\nspace, and this plays a fundamental role in achieving the same convergence\nproperties in training. Thus, the current study gives a novel and unified\ntheoretical foundation with which to understand NGD methods in deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 09:12:07 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:30:22 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 06:36:00 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Karakida", "Ryo", ""], ["Osawa", "Kazuki", ""]]}, {"id": "2010.00885", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Optimization Landscapes of Wide Deep Neural Networks Are Benign", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the optimization landscapes of deep learning with wide networks.\nWe highlight the importance of constraints for such networks and show that\nconstraint -- as well as unconstraint -- empirical-risk minimization over such\nnetworks has no confined points, that is, suboptimal parameters that are\ndifficult to escape from. Hence, our theories substantiate the common belief\nthat wide neural networks are not only highly expressive but also comparably\neasy to optimize.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 09:34:32 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 10:11:53 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "2010.00892", "submitter": "Robert M. Gower", "authors": "Robert M. Gower, Mark Schmidt, Francis Bach, Peter Richtarik", "title": "Variance-Reduced Methods for Machine Learning", "comments": "16 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization lies at the heart of machine learning, and its\ncornerstone is stochastic gradient descent (SGD), a method introduced over 60\nyears ago. The last 8 years have seen an exciting new development: variance\nreduction (VR) for stochastic optimization methods. These VR methods excel in\nsettings where more than one pass through the training data is allowed,\nachieving a faster convergence than SGD in theory as well as practice. These\nspeedups underline the surge of interest in VR methods and the fast-growing\nbody of work on this topic. This review covers the key principles and main\ndevelopments behind VR methods for optimization with finite data sets and is\naimed at non-expert readers. We focus mainly on the convex setting, and leave\npointers to readers interested in extensions for minimizing non-convex\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 09:45:43 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gower", "Robert M.", ""], ["Schmidt", "Mark", ""], ["Bach", "Francis", ""], ["Richtarik", "Peter", ""]]}, {"id": "2010.00904", "submitter": "Nicola De Cao", "authors": "Nicola De Cao, Gautier Izacard, Sebastian Riedel, Fabio Petroni", "title": "Autoregressive Entity Retrieval", "comments": "Accepted (spotlight) at International Conference on Learning\n  Representations (ICLR) 2021. Code at\n  https://github.com/facebookresearch/GENRE. 20 pages, 9 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entities are at the center of how we represent and aggregate knowledge. For\ninstance, Encyclopedias such as Wikipedia are structured by entities (e.g., one\nper Wikipedia article). The ability to retrieve such entities given a query is\nfundamental for knowledge-intensive tasks such as entity linking and\nopen-domain question answering. Current approaches can be understood as\nclassifiers among atomic labels, one for each entity. Their weight vectors are\ndense entity representations produced by encoding entity meta information such\nas their descriptions. This approach has several shortcomings: (i) context and\nentity affinity is mainly captured through a vector dot product, potentially\nmissing fine-grained interactions; (ii) a large memory footprint is needed to\nstore dense representations when considering large entity sets; (iii) an\nappropriately hard set of negative data has to be subsampled at training time.\nIn this work, we propose GENRE, the first system that retrieves entities by\ngenerating their unique names, left to right, token-by-token in an\nautoregressive fashion. This mitigates the aforementioned technical issues\nsince: (i) the autoregressive formulation directly captures relations between\ncontext and entity name, effectively cross encoding both; (ii) the memory\nfootprint is greatly reduced because the parameters of our encoder-decoder\narchitecture scale with vocabulary size, not entity count; (iii) the softmax\nloss is computed without subsampling negative data. We experiment with more\nthan 20 datasets on entity disambiguation, end-to-end entity linking and\ndocument retrieval tasks, achieving new state-of-the-art or very competitive\nresults while using a tiny fraction of the memory footprint of competing\nsystems. Finally, we demonstrate that new entities can be added by simply\nspecifying their names. Code and pre-trained models at\nhttps://github.com/facebookresearch/GENRE.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 10:13:31 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 15:20:52 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 07:21:07 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["De Cao", "Nicola", ""], ["Izacard", "Gautier", ""], ["Riedel", "Sebastian", ""], ["Petroni", "Fabio", ""]]}, {"id": "2010.00917", "submitter": "Uri Stemmer", "authors": "Haim Kaplan, Yishay Mansour, Uri Stemmer", "title": "The Sparse Vector Technique, Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit one of the most basic and widely applicable techniques in the\nliterature of differential privacy - the sparse vector technique [Dwork et al.,\nSTOC 2009]. This simple algorithm privately tests whether the value of a given\nquery on a database is close to what we expect it to be. It allows to ask an\nunbounded number of queries as long as the answer is close to what we expect,\nand halts following the first query for which this is not the case.\n  We suggest an alternative, equally simple, algorithm that can continue\ntesting queries as long as any single individual does not contribute to the\nanswer of too many queries whose answer deviates substantially form what we\nexpect. Our analysis is subtle and some of its ingredients may be more widely\napplicable. In some cases our new algorithm allows to privately extract much\nmore information from the database than the original.\n  We demonstrate this by applying our algorithm to the shifting heavy-hitters\nproblem: On every time step, each of $n$ users gets a new input, and the task\nis to privately identify all the current heavy-hitters. That is, on time step\n$i$, the goal is to identify all data elements $x$ such that many of the users\nhave $x$ as their current input. We present an algorithm for this problem with\nimproved error guarantees over what can be obtained using existing techniques.\nSpecifically, the error of our algorithm depends on the maximal number of times\nthat a single user holds a heavy-hitter as input, rather than the total number\nof times in which a heavy-hitter exists.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 10:50:52 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 14:15:59 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Stemmer", "Uri", ""]]}, {"id": "2010.00921", "submitter": "Maximus Mutschler", "authors": "Maximus Mutschler and Andreas Zell", "title": "A straightforward line search approach on the expected empirical loss\n  for stochastic deep learning problems", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in deep learning is that the optimal step sizes for\nupdate steps of stochastic gradient descent are unknown. In traditional\noptimization, line searches are used to determine good step sizes, however, in\ndeep learning, it is too costly to search for good step sizes on the expected\nempirical loss due to noisy losses. This empirical work shows that it is\npossible to approximate the expected empirical loss on vertical cross sections\nfor common deep learning tasks considerably cheaply. This is achieved by\napplying traditional one-dimensional function fitting to measured noisy losses\nof such cross sections. The step to a minimum of the resulting approximation is\nthen used as step size for the optimization. This approach leads to a robust\nand straightforward optimization method which performs well across datasets and\narchitectures without the need of hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 11:04:02 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Mutschler", "Maximus", ""], ["Zell", "Andreas", ""]]}, {"id": "2010.00929", "submitter": "Boris Joukovsky", "authors": "Huynh Van Luong, Boris Joukovsky, Yonina C. Eldar, Nikos Deligiannis", "title": "A Deep-Unfolded Reference-Based RPCA Network For Video\n  Foreground-Background Separation", "comments": "5 pages, accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolded neural networks are designed by unrolling the iterations of\noptimization algorithms. They can be shown to achieve faster convergence and\nhigher accuracy than their optimization counterparts. This paper proposes a new\ndeep-unfolding-based network design for the problem of Robust Principal\nComponent Analysis (RPCA) with application to video foreground-background\nseparation. Unlike existing designs, our approach focuses on modeling the\ntemporal correlation between the sparse representations of consecutive video\nframes. To this end, we perform the unfolding of an iterative algorithm for\nsolving reweighted $\\ell_1$-$\\ell_1$ minimization; this unfolding leads to a\ndifferent proximal operator (a.k.a. different activation function) adaptively\nlearned per neuron. Experimentation using the moving MNIST dataset shows that\nthe proposed network outperforms a recently proposed state-of-the-art RPCA\nnetwork in the task of video foreground-background separation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 11:40:09 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Van Luong", "Huynh", ""], ["Joukovsky", "Boris", ""], ["Eldar", "Yonina C.", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2010.00950", "submitter": "Jakob Raymaekers", "authors": "Jakob Raymaekers and Ruben H. Zamar", "title": "Regularized K-means through hard-thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a framework of regularized $K$-means methods based on direct\npenalization of the size of the cluster centers. Different penalization\nstrategies are considered and compared through simulation and theoretical\nanalysis. Based on the results, we propose HT $K$-means, which uses an $\\ell_0$\npenalty to induce sparsity in the variables. Different techniques for selecting\nthe tuning parameter are discussed and compared. The proposed method stacks up\nfavorably with the most popular regularized $K$-means methods in an extensive\nsimulation study. Finally, HT $K$-means is applied to several real data\nexamples. Graphical displays are presented and used in these examples to gain\nmore insight into the datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 12:29:32 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Raymaekers", "Jakob", ""], ["Zamar", "Ruben H.", ""]]}, {"id": "2010.00951", "submitter": "T. Konstantin Rusch", "authors": "T. Konstantin Rusch, Siddhartha Mishra", "title": "Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and\n  (gradient) stable architecture for learning long time dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circuits of biological neurons, such as in the functional parts of the brain\ncan be modeled as networks of coupled oscillators. Inspired by the ability of\nthese systems to express a rich set of outputs while keeping (gradients of)\nstate variables bounded, we propose a novel architecture for recurrent neural\nnetworks. Our proposed RNN is based on a time-discretization of a system of\nsecond-order ordinary differential equations, modeling networks of controlled\nnonlinear oscillators. We prove precise bounds on the gradients of the hidden\nstates, leading to the mitigation of the exploding and vanishing gradient\nproblem for this RNN. Experiments show that the proposed RNN is comparable in\nperformance to the state of the art on a variety of benchmarks, demonstrating\nthe potential of this architecture to provide stable and accurate RNNs for\nprocessing complex sequential data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 12:35:04 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 19:12:57 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Rusch", "T. Konstantin", ""], ["Mishra", "Siddhartha", ""]]}, {"id": "2010.00977", "submitter": "David W. Romero", "authors": "David W. Romero, Jean-Baptiste Cordonnier", "title": "Group Equivariant Stand-Alone Self-Attention For Vision", "comments": "Proceedings of the 9th International Conference on Learning\n  Representations (ICLR), 2021", "journal-ref": "Proceedings of the International Conference on Learning\n  Representations, 2021", "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a general self-attention formulation to impose group equivariance\nto arbitrary symmetry groups. This is achieved by defining positional encodings\nthat are invariant to the action of the group considered. Since the group acts\non the positional encoding directly, group equivariant self-attention networks\n(GSA-Nets) are steerable by nature. Our experiments on vision benchmarks\ndemonstrate consistent improvements of GSA-Nets over non-equivariant\nself-attention networks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:16:00 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 19:19:38 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Romero", "David W.", ""], ["Cordonnier", "Jean-Baptiste", ""]]}, {"id": "2010.00979", "submitter": "Henry Moss", "authors": "Henry B. Moss, Daniel Beck, Javier Gonzalez, David S. Leslie, Paul\n  Rayson", "title": "BOSS: Bayesian Optimization over String Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a Bayesian optimization (BO) method which acts directly\nover raw strings, proposing the first uses of string kernels and genetic\nalgorithms within BO loops. Recent applications of BO over strings have been\nhindered by the need to map inputs into a smooth and unconstrained latent\nspace. Learning this projection is computationally and data-intensive. Our\napproach instead builds a powerful Gaussian process surrogate model based on\nstring kernels, naturally supporting variable length inputs, and performs\nefficient acquisition function maximization for spaces with syntactical\nconstraints. Experiments demonstrate considerably improved optimization over\nexisting approaches across a broad range of constraints, including the popular\nsetting where syntax is governed by a context-free grammar.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:18:27 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Moss", "Henry B.", ""], ["Beck", "Daniel", ""], ["Gonzalez", "Javier", ""], ["Leslie", "David S.", ""], ["Rayson", "Paul", ""]]}, {"id": "2010.00985", "submitter": "Jing Lu Dr", "authors": "Hu Liu, Jing Lu, Xiwei Zhao, Sulong Xu, Hao Peng, Yutong Liu, Zehua\n  Zhang, Jian Li, Junsheng Jin, Yongjun Bao, Weipeng Yan", "title": "Kalman Filtering Attention for User Behavior Modeling in CTR Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is one of the fundamental tasks for\ne-commerce search engines. As search becomes more personalized, it is necessary\nto capture the user interest from rich behavior data. Existing user behavior\nmodeling algorithms develop different attention mechanisms to emphasize\nquery-relevant behaviors and suppress irrelevant ones. Despite being\nextensively studied, these attentions still suffer from two limitations. First,\nconventional attentions mostly limit the attention field only to a single\nuser's behaviors, which is not suitable in e-commerce where users often hunt\nfor new demands that are irrelevant to any historical behaviors. Second, these\nattentions are usually biased towards frequent behaviors, which is unreasonable\nsince high frequency does not necessarily indicate great importance. To tackle\nthe two limitations, we propose a novel attention mechanism, termed Kalman\nFiltering Attention (KFAtt), that considers the weighted pooling in attention\nas a maximum a posteriori (MAP) estimation. By incorporating a priori, KFAtt\nresorts to global statistics when few user behaviors are relevant. Moreover, a\nfrequency capping mechanism is incorporated to correct the bias towards\nfrequent behaviors. Offline experiments on both benchmark and a 10 billion\nscale real production dataset, together with an Online A/B test, show that\nKFAtt outperforms all compared state-of-the-arts. KFAtt has been deployed in\nthe ranking system of a leading e commerce website, serving the main traffic of\nhundreds of millions of active users everyday.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:30:26 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 06:48:43 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Liu", "Hu", ""], ["Lu", "Jing", ""], ["Zhao", "Xiwei", ""], ["Xu", "Sulong", ""], ["Peng", "Hao", ""], ["Liu", "Yutong", ""], ["Zhang", "Zehua", ""], ["Li", "Jian", ""], ["Jin", "Junsheng", ""], ["Bao", "Yongjun", ""], ["Yan", "Weipeng", ""]]}, {"id": "2010.00989", "submitter": "Chengjin Xu", "authors": "Chengjin Xu, Mojtaba Nayyeri, Yung-Yu Chen, Jens Lehmann", "title": "Knowledge Graph Embeddings in Geometric Algebras", "comments": "This paper is accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embedding aims at embedding entities and relations in a\nKG into a lowdimensional latent representation space. Existing KG embedding\napproaches model entities andrelations in a KG by utilizing real-valued ,\ncomplex-valued, or hypercomplex-valued (Quaternionor Octonion) representations,\nall of which are subsumed into a geometric algebra. In this work,we introduce a\nnovel geometric algebra-based KG embedding framework, GeomE, which uti-lizes\nmultivector representations and the geometric product to model entities and\nrelations. Ourframework subsumes several state-of-the-art KG embedding\napproaches and is advantageouswith its ability of modeling various key relation\npatterns, including (anti-)symmetry, inversionand composition, rich\nexpressiveness with higher degree of freedom as well as good general-ization\ncapacity. Experimental results on multiple benchmark knowledge graphs show that\ntheproposed approach outperforms existing state-of-the-art models for link\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:36:24 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 14:30:10 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 00:03:21 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 18:59:42 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Xu", "Chengjin", ""], ["Nayyeri", "Mojtaba", ""], ["Chen", "Yung-Yu", ""], ["Lehmann", "Jens", ""]]}, {"id": "2010.00990", "submitter": "Teddy Furon", "authors": "Teddy Furon", "title": "Note: An alternative proof of the vulnerability of $k$-NN classifiers in\n  high intrinsic dimensionality regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This document proposes an alternative proof of the result contained in\narticle \"High intrinsic dimensionality facilitates adversarial attack:\nTheoretical evidence\", Amsaleg et a.. The proof is simpler to understand (I\nbelieve) and leads to a more precise statement about the asymptotical\ndistribution of the relative amount of perturbation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:36:29 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Furon", "Teddy", ""]]}, {"id": "2010.01003", "submitter": "Awni Hannun", "authors": "Awni Hannun, Vineel Pratap, Jacob Kahn, Wei-Ning Hsu", "title": "Differentiable Weighted Finite-State Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for automatic differentiation with weighted\nfinite-state transducers (WFSTs) allowing them to be used dynamically at\ntraining time. Through the separation of graphs from operations on graphs, this\nframework enables the exploration of new structured loss functions which in\nturn eases the encoding of prior knowledge into learning algorithms. We show\nhow the framework can combine pruning and back-off in transition models with\nvarious sequence-level loss functions. We also show how to learn over the\nlatent decomposition of phrases into word pieces. Finally, to demonstrate that\nWFSTs can be used in the interior of a deep neural network, we propose a\nconvolutional WFST layer which maps lower-level representations to higher-level\nrepresentations and can be used as a drop-in replacement for a traditional\nconvolution. We validate these algorithms with experiments in handwriting\nrecognition and speech recognition.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:52:24 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Hannun", "Awni", ""], ["Pratap", "Vineel", ""], ["Kahn", "Jacob", ""], ["Hsu", "Wei-Ning", ""]]}, {"id": "2010.01011", "submitter": "Emilie Chouzenoux", "authors": "Jyoti Maggu and Angshul Majumdar and Emilie Chouzenoux and Giovanni\n  Chierchia", "title": "Deep Convolutional Transform Learning -- Extended version", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a new unsupervised representation learning technique\ncalled Deep Convolutional Transform Learning (DCTL). By stacking convolutional\ntransforms, our approach is able to learn a set of independent kernels at\ndifferent layers. The features extracted in an unsupervised manner can then be\nused to perform machine learning tasks, such as classification and clustering.\nThe learning technique relies on a well-sounded alternating proximal\nminimization scheme with established convergence guarantees. Our experimental\nresults show that the proposed DCTL technique outperforms its shallow version\nCTL, on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:03:19 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Maggu", "Jyoti", ""], ["Majumdar", "Angshul", ""], ["Chouzenoux", "Emilie", ""], ["Chierchia", "Giovanni", ""]]}, {"id": "2010.01014", "submitter": "Bastian Alt", "authors": "Bastian Alt, Matthias Schultheis, Heinz Koeppl", "title": "POMDPs in Continuous Time and Discrete Spaces", "comments": "published at Conference on Neural Information Processing Systems\n  (NeurIPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many processes, such as discrete event systems in engineering or population\ndynamics in biology, evolve in discrete space and continuous time. We consider\nthe problem of optimal decision making in such discrete state and action space\nsystems under partial observability. This places our work at the intersection\nof optimal filtering and optimal control. At the current state of research, a\nmathematical description for simultaneous decision making and filtering in\ncontinuous time with finite state and action spaces is still missing. In this\npaper, we give a mathematical description of a continuous-time partial\nobservable Markov decision process (POMDP). By leveraging optimal filtering\ntheory we derive a Hamilton-Jacobi-Bellman (HJB) type equation that\ncharacterizes the optimal solution. Using techniques from deep learning we\napproximately solve the resulting partial integro-differential equation. We\npresent (i) an approach solving the decision problem offline by learning an\napproximation of the value function and (ii) an online algorithm which provides\na solution in belief space using deep reinforcement learning. We show the\napplicability on a set of toy examples which pave the way for future methods\nproviding solutions for high dimensional problems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:04:32 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 08:37:02 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 12:57:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Alt", "Bastian", ""], ["Schultheis", "Matthias", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2010.01017", "submitter": "Qinbin Li", "authors": "Qinbin Li, Bingsheng He, Dawn Song", "title": "Practical One-Shot Federated Learning for Cross-Silo Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables multiple parties to collaboratively learn a model\nwithout exchanging their data. While most existing federated learning\nalgorithms need many rounds to converge, one-shot federated learning (i.e.,\nfederated learning with a single communication round) is a promising approach\nto make federated learning applicable in cross-silo setting in practice.\nHowever, existing one-shot algorithms only support specific models and do not\nprovide any privacy guarantees, which significantly limit the applications in\npractice. In this paper, we propose a practical one-shot federated learning\nalgorithm named FedKT. By utilizing the knowledge transfer technique, FedKT can\nbe applied to any classification models and can flexibly achieve differential\nprivacy guarantees. Our experiments on various tasks show that FedKT can\nsignificantly outperform the other state-of-the-art federated learning\nalgorithms with a single communication round.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:09:10 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 13:25:47 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Li", "Qinbin", ""], ["He", "Bingsheng", ""], ["Song", "Dawn", ""]]}, {"id": "2010.01037", "submitter": "Sanjukta Krishnagopal", "authors": "Sanjukta Krishnagopal and Jacob Bedrossian", "title": "Encoded Prior Sliced Wasserstein AutoEncoder for learning latent\n  manifold representations", "comments": "8 pages, 4 figures in the main text, Submitted to The International\n  Conference on Learning Representations (ICLR)2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While variational autoencoders have been successful generative models for a\nvariety of tasks, the use of conventional Gaussian or Gaussian mixture priors\nare limited in their ability to capture topological or geometric properties of\ndata in the latent representation. In this work, we introduce an Encoded Prior\nSliced Wasserstein AutoEncoder (EPSWAE) wherein an additional prior-encoder\nnetwork learns an unconstrained prior to match the encoded data manifold. The\nautoencoder and prior-encoder networks are iteratively trained using the Sliced\nWasserstein Distance (SWD), which efficiently measures the distance between two\n$\\textit{arbitrary}$ sampleable distributions without being constrained to a\nspecific form as in the KL divergence, and without requiring expensive\nadversarial training. Additionally, we enhance the conventional SWD by\nintroducing a nonlinear shearing, i.e., averaging over random\n$\\textit{nonlinear}$ transformations, to better capture differences between two\ndistributions. The prior is further encouraged to encode the data manifold by\nuse of a structural consistency term that encourages isometry between feature\nspace and latent space. Lastly, interpolation along $\\textit{geodesics}$ on the\nlatent space representation of the data manifold generates samples that lie on\nthe manifold and hence is advantageous compared with standard Euclidean\ninterpolation. To this end, we introduce a graph-based algorithm for\nidentifying network-geodesics in latent space from samples of the prior that\nmaximize the density of samples along the path while minimizing total energy.\nWe apply our framework to 3D-spiral, MNIST, and CelebA datasets, and show that\nits latent representations and interpolations are comparable to the state of\nthe art on equivalent architectures.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:58:54 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Krishnagopal", "Sanjukta", ""], ["Bedrossian", "Jacob", ""]]}, {"id": "2010.01039", "submitter": "Grzegorz G{\\l}uch", "authors": "Grzegorz G{\\l}uch, R\\\"udiger Urbanke", "title": "Query complexity of adversarial attacks", "comments": "32 pages, 2 figures Generalized the results. Adversarial examples no\n  longer need to be in the support of the data distribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two main attack models considered in the adversarial robustness\nliterature: black-box and white-box. We consider these threat models as two\nends of a fine-grained spectrum, indexed by the number of queries the adversary\ncan ask. Using this point of view we investigate how many queries the adversary\nneeds to make to design an attack that is comparable to the best possible\nattack in the white-box model. We give a lower bound on that number of queries\nin terms of entropy of decision boundaries of the classifier. Using this result\nwe analyze two classical learning algorithms on two synthetic tasks for which\nwe prove meaningful security guarantees. The obtained bounds suggest that some\nlearning algorithms are inherently more robust against query-bounded\nadversaries than others.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:01:29 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 14:38:56 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["G\u0142uch", "Grzegorz", ""], ["Urbanke", "R\u00fcdiger", ""]]}, {"id": "2010.01040", "submitter": "Samuel Coward", "authors": "Samuel Coward, Erik Visse-Martindale, Chithrupa Ramesh", "title": "Attention-Based Clustering: Learning a Kernel from Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, no data point stands alone. We believe that context is\nan underappreciated concept in many machine learning methods. We propose\nAttention-Based Clustering (ABC), a neural architecture based on the attention\nmechanism, which is designed to learn latent representations that adapt to\ncontext within an input set, and which is inherently agnostic to input sizes\nand number of clusters. By learning a similarity kernel, our method directly\ncombines with any out-of-the-box kernel-based clustering approach. We present\ncompetitive results for clustering Omniglot characters and include analytical\nevidence of the effectiveness of an attention-based approach for clustering.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:06:06 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Coward", "Samuel", ""], ["Visse-Martindale", "Erik", ""], ["Ramesh", "Chithrupa", ""]]}, {"id": "2010.01045", "submitter": "Marwa Kechaou", "authors": "Marwa Kechaou, Romain H\\'erault, Mokhtar Z. Alaya and Gilles Gasso", "title": "Open Set Domain Adaptation using Optimal Transport", "comments": "Accepted at ECML-PKDD 2020, Acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a 2-step optimal transport approach that performs a mapping from a\nsource distribution to a target distribution. Here, the target has the\nparticularity to present new classes not present in the source domain. The\nfirst step of the approach aims at rejecting the samples issued from these new\nclasses using an optimal transport plan. The second step solves the target\n(class ratio) shift still as an optimal transport problem. We develop a dual\napproach to solve the optimization problem involved at each step and we prove\nthat our results outperform recent state-of-the-art performances. We further\napply the approach to the setting where the source and target distributions\npresent both a label-shift and an increasing covariate (features) shift to show\nits robustness.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:20:05 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Kechaou", "Marwa", ""], ["H\u00e9rault", "Romain", ""], ["Alaya", "Mokhtar Z.", ""], ["Gasso", "Gilles", ""]]}, {"id": "2010.01047", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil Seth, Christopher L Buckley", "title": "Relaxing the Constraints on Predictive Coding Models", "comments": "02/10/20 initial upload; 10/10/20 minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding is an influential theory of cortical function which posits\nthat the principal computation the brain performs, which underlies both\nperception and learning, is the minimization of prediction errors. While\nmotivated by high-level notions of variational inference, detailed\nneurophysiological models of cortical microcircuits which can implements its\ncomputations have been developed. Moreover, under certain conditions,\npredictive coding has been shown to approximate the backpropagation of error\nalgorithm, and thus provides a relatively biologically plausible\ncredit-assignment mechanism for training deep networks. However, standard\nimplementations of the algorithm still involve potentially neurally implausible\nfeatures such as identical forward and backward weights, backward nonlinear\nderivatives, and 1-1 error unit connectivity. In this paper, we show that these\nfeatures are not integral to the algorithm and can be removed either directly\nor through learning additional sets of parameters with Hebbian update rules\nwithout noticeable harm to learning performance. Our work thus relaxes current\nconstraints on potential microcircuit designs and hopefully opens up new\nregions of the design-space for neuromorphic implementations of predictive\ncoding.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:21:37 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 14:09:12 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2010.01048", "submitter": "Jie Ding", "authors": "Gen Li, Yuantao Gu, Jie Ding", "title": "The Efficacy of $L_1$ Regularization in Two-Layer Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial problem in neural networks is to select the most appropriate number\nof hidden neurons and obtain tight statistical risk bounds. In this work, we\npresent a new perspective towards the bias-variance tradeoff in neural\nnetworks. As an alternative to selecting the number of neurons, we\ntheoretically show that $L_1$ regularization can control the generalization\nerror and sparsify the input dimension. In particular, with an appropriate\n$L_1$ regularization on the output layer, the network can produce a statistical\nrisk that is near minimax optimal. Moreover, an appropriate $L_1$\nregularization on the input layer leads to a risk bound that does not involve\nthe input data dimension. Our analysis is based on a new amalgamation of\ndimension-based and norm-based complexity analysis to bound the generalization\nerror. A consequent observation from our results is that an excessively large\nnumber of neurons do not necessarily inflate generalization errors under a\nsuitable regularization.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:23:22 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Li", "Gen", ""], ["Gu", "Yuantao", ""], ["Ding", "Jie", ""]]}, {"id": "2010.01051", "submitter": "Sungbin Lim", "authors": "Minsuk Shin, Hyungjoo Cho, Sungbin Lim", "title": "Neural Bootstrapper", "comments": "15 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrapping has been a primary tool for uncertainty quantification, and its\ntheoretical and computational properties have been investigated in the field of\nstatistics and machine learning. However, due to its nature of repetitive\ncomputations, the computational burden required to bootstrap neural networks is\npainfully heavy, and this fact seriously hurdles the practical use of these\nprocedures on the uncertainty estimation of modern deep learning. To overcome\nthis computational bottleneck, we propose a procedure called Neural\nBootstrapper (NeuBoots) that constructs a generator of bootstrapped networks.\nUnlike the standard bootstrap, the proposed NeuBoots can be computed on a\nsingle loss function from a single training. It thus avoids repetitive training\ninherited in the standard bootstrap, which significantly improves the\nefficiency of the bootstrap computation. We theoretically show that the\nNeuBoots asymptotically approximates the standard bootstrap distribution, and\nour empirical examples also support this assertion. Consequently, we apply the\nNeuBoots to uncertainty quantification tasks in machine learning, and these\ninclude prediction calibrations, semantic segmentation tasks, detection of\nout-of-distribution samples, and active learning. Our empirical results show\nthat the NeuBoots performs better than the state-of-the-art procedures in the\nuncertainty quantification, under a much less computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:30:04 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 02:37:47 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Shin", "Minsuk", ""], ["Cho", "Hyungjoo", ""], ["Lim", "Sungbin", ""]]}, {"id": "2010.01052", "submitter": "Jaume Banus", "authors": "Jaume Banus and Maxime Sermesant and Oscar Camara and Marco Lorenzi", "title": "Joint data imputation and mechanistic modelling for simulating\n  heart-brain interactions in incomplete datasets", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59725-2_46", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of mechanistic models in clinical studies is limited by the lack of\nmulti-modal patients data representing different anatomical and physiological\nprocesses. For example, neuroimaging datasets do not provide a sufficient\nrepresentation of heart features for the modeling of cardiovascular factors in\nbrain disorders. To tackle this problem we introduce a probabilistic framework\nfor joint cardiac data imputation and personalisation of cardiovascular\nmechanistic models, with application to brain studies with incomplete heart\ndata. Our approach is based on a variational framework for the joint inference\nof an imputation model of cardiac information from the available features,\nalong with a Gaussian Process emulator that can faithfully reproduce\npersonalised cardiovascular dynamics. Experimental results on UK Biobank show\nthat our model allows accurate imputation of missing cardiac features in\ndatasets containing minimal heart information, e.g. systolic and diastolic\nblood pressures only, while jointly estimating the emulated parameters of the\nlumped model. This allows a novel exploration of the heart-brain joint\nrelationship through simulation of realistic cardiac dynamics corresponding to\ndifferent conditions of brain anatomy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:31:36 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:24:02 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 12:36:31 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Banus", "Jaume", ""], ["Sermesant", "Maxime", ""], ["Camara", "Oscar", ""], ["Lorenzi", "Marco", ""]]}, {"id": "2010.01062", "submitter": "Luisa Zintgraf", "authors": "Luisa Zintgraf, Leo Feng, Cong Lu, Maximilian Igl, Kristian\n  Hartikainen, Katja Hofmann, Shimon Whiteson", "title": "Exploration in Approximate Hyper-State Space for Meta Reinforcement\n  Learning", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To rapidly learn a new task, it is often essential for agents to explore\nefficiently -- especially when performance matters from the first timestep. One\nway to learn such behaviour is via meta-learning. Many existing methods however\nrely on dense rewards for meta-training, and can fail catastrophically if the\nrewards are sparse. Without a suitable reward signal, the need for exploration\nduring meta-training is exacerbated. To address this, we propose HyperX, which\nuses novel reward bonuses for meta-training to explore in approximate\nhyper-state space (where hyper-states represent the environment state and the\nagent's task belief). We show empirically that HyperX meta-learns better\ntask-exploration and adapts more successfully to new tasks than existing\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:43:31 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:37:11 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 21:43:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zintgraf", "Luisa", ""], ["Feng", "Leo", ""], ["Lu", "Cong", ""], ["Igl", "Maximilian", ""], ["Hartikainen", "Kristian", ""], ["Hofmann", "Katja", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2010.01079", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama and Shunya Noda", "title": "On Statistical Discrimination as a Failure of Social Learning: A\n  Multi-Armed Bandit Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.GT econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze statistical discrimination in hiring markets using a multi-armed\nbandit model. Myopic firms face workers arriving with heterogeneous observable\ncharacteristics. The association between the worker's skill and characteristics\nis unknown ex ante; thus, firms need to learn it. Laissez-faire causes\nperpetual underestimation: minority workers are rarely hired, and therefore,\nunderestimation towards them tends to persist. Even a slight population-ratio\nimbalance frequently produces perpetual underestimation. We propose two policy\nsolutions: a novel subsidy rule (the hybrid mechanism) and the Rooney Rule. Our\nresults indicate that temporary affirmative actions effectively mitigate\ndiscrimination caused by insufficient data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:20:14 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 16:19:24 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 03:10:18 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 01:36:11 GMT"}, {"version": "v5", "created": "Wed, 7 Jul 2021 00:06:04 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Komiyama", "Junpei", ""], ["Noda", "Shunya", ""]]}, {"id": "2010.01084", "submitter": "Wei Deng", "authors": "Wei Deng and Qi Feng and Georgios Karagiannis and Guang Lin and Faming\n  Liang", "title": "Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC\n  via Variance Reduction", "comments": "Accepted by ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replica exchange stochastic gradient Langevin dynamics (reSGLD) has shown\npromise in accelerating the convergence in non-convex learning; however, an\nexcessively large correction for avoiding biases from noisy energy estimators\nhas limited the potential of the acceleration. To address this issue, we study\nthe variance reduction for noisy energy estimators, which promotes much more\neffective swaps. Theoretically, we provide a non-asymptotic analysis on the\nexponential acceleration for the underlying continuous-time Markov jump\nprocess; moreover, we consider a generalized Girsanov theorem which includes\nthe change of Poisson measure to overcome the crude discretization based on the\nGr\\\"{o}wall's inequality and yields a much tighter error in the 2-Wasserstein\n($\\mathcal{W}_2$) distance. Numerically, we conduct extensive experiments and\nobtain the state-of-the-art results in optimization and uncertainty estimates\nfor synthetic experiments and image data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:23:35 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 16:24:47 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Deng", "Wei", ""], ["Feng", "Qi", ""], ["Karagiannis", "Georgios", ""], ["Lin", "Guang", ""], ["Liang", "Faming", ""]]}, {"id": "2010.01092", "submitter": "Chaoyue Liu", "authors": "Chaoyue Liu, Libin Zhu, Mikhail Belkin", "title": "On the linearity of large non-linear models: when and why the tangent\n  kernel is constant", "comments": "accepted as Spotlight in NeurIPS 2020; made correction to proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to shed light on the remarkable phenomenon of\ntransition to linearity of certain neural networks as their width approaches\ninfinity. We show that the transition to linearity of the model and,\nequivalently, constancy of the (neural) tangent kernel (NTK) result from the\nscaling properties of the norm of the Hessian matrix of the network as a\nfunction of the network width. We present a general framework for understanding\nthe constancy of the tangent kernel via Hessian scaling applicable to the\nstandard classes of neural networks. Our analysis provides a new perspective on\nthe phenomenon of constant tangent kernel, which is different from the widely\naccepted \"lazy training\". Furthermore, we show that the transition to linearity\nis not a general property of wide neural networks and does not hold when the\nlast layer of the network is non-linear. It is also not necessary for\nsuccessful optimization by gradient descent.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 16:44:45 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 15:26:37 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 02:48:39 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Liu", "Chaoyue", ""], ["Zhu", "Libin", ""], ["Belkin", "Mikhail", ""]]}, {"id": "2010.01112", "submitter": "Lanqing Li", "authors": "Lanqing Li, Rui Yang, Dijun Luo", "title": "FOCAL: Efficient Fully-Offline Meta-Reinforcement Learning via Distance\n  Metric Learning and Behavior Regularization", "comments": "23 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the offline meta-reinforcement learning (OMRL) problem, a paradigm\nwhich enables reinforcement learning (RL) algorithms to quickly adapt to unseen\ntasks without any interactions with the environments, making RL truly practical\nin many real-world applications. This problem is still not fully understood,\nfor which two major challenges need to be addressed. First, offline RL usually\nsuffers from bootstrapping errors of out-of-distribution state-actions which\nleads to divergence of value functions. Second, meta-RL requires efficient and\nrobust task inference learned jointly with control policy. In this work, we\nenforce behavior regularization on learned policy as a general approach to\noffline RL, combined with a deterministic context encoder for efficient task\ninference. We propose a novel negative-power distance metric on bounded context\nembedding space, whose gradients propagation is detached from the Bellman\nbackup. We provide analysis and insight showing that some simple design choices\ncan yield substantial improvements over recent approaches involving meta-RL and\ndistance metric learning. To the best of our knowledge, our method is the first\nmodel-free and end-to-end OMRL algorithm, which is computationally efficient\nand demonstrated to outperform prior algorithms on several meta-RL benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 17:13:39 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 03:53:09 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 09:23:00 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 09:06:50 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Lanqing", ""], ["Yang", "Rui", ""], ["Luo", "Dijun", ""]]}, {"id": "2010.01118", "submitter": "Henry Moss", "authors": "Henry B. Moss, Ryan-Rhys Griffiths", "title": "Gaussian Process Molecule Property Prediction with FlowMO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FlowMO: an open-source Python library for molecular property\nprediction with Gaussian Processes. Built upon GPflow and RDKit, FlowMO enables\nthe user to make predictions with well-calibrated uncertainty estimates, an\noutput central to active learning and molecular design applications. Gaussian\nProcesses are particularly attractive for modelling small molecular datasets, a\ncharacteristic of many real-world virtual screening campaigns where\nhigh-quality experimental data is scarce. Computational experiments across\nthree small datasets demonstrate comparable predictive performance to deep\nlearning methods but with superior uncertainty calibration.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 17:25:08 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 08:23:55 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Moss", "Henry B.", ""], ["Griffiths", "Ryan-Rhys", ""]]}, {"id": "2010.01149", "submitter": "Andrew Beam", "authors": "David Bellamy and Leo Celi and Andrew L. Beam", "title": "Evaluating Progress on Machine Learning for Longitudinal Electronic\n  Healthcare Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Large Scale Visual Recognition Challenge based on the well-known Imagenet\ndataset catalyzed an intense flurry of progress in computer vision. Benchmark\ntasks have propelled other sub-fields of machine learning forward at an equally\nimpressive pace, but in healthcare it has primarily been image processing\ntasks, such as in dermatology and radiology, that have experienced similar\nbenchmark-driven progress. In the present study, we performed a comprehensive\nreview of benchmarks in medical machine learning for structured data,\nidentifying one based on the Medical Information Mart for Intensive Care\n(MIMIC-III) that allows the first direct comparison of predictive performance\nand thus the evaluation of progress on four clinical prediction tasks:\nmortality, length of stay, phenotyping, and patient decompensation. We find\nthat little meaningful progress has been made over a 3 year period on these\ntasks, despite significant community engagement. Through our meta-analysis, we\nfind that the performance of deep recurrent models is only superior to logistic\nregression on certain tasks. We conclude with a synthesis of these results,\npossible explanations, and a list of desirable qualities for future benchmarks\nin medical machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 18:06:12 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bellamy", "David", ""], ["Celi", "Leo", ""], ["Beam", "Andrew L.", ""]]}, {"id": "2010.01155", "submitter": "Viraj Mehta", "authors": "Frederic Koehler, Viraj Mehta, Andrej Risteski", "title": "Representational aspects of depth and conditioning in normalizing flows", "comments": "Appeared in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are among the most popular paradigms in generative\nmodeling, especially for images, primarily because we can efficiently evaluate\nthe likelihood of a data point. This is desirable both for evaluating the fit\nof a model, and for ease of training, as maximizing the likelihood can be done\nby gradient descent. However, training normalizing flows comes with\ndifficulties as well: models which produce good samples typically need to be\nextremely deep -- which comes with accompanying vanishing/exploding gradient\nproblems. A very related problem is that they are often poorly conditioned:\nsince they are parametrized as invertible maps from $\\mathbb{R}^d \\to\n\\mathbb{R}^d$, and typical training data like images intuitively is\nlower-dimensional, the learned maps often have Jacobians that are close to\nbeing singular.\n  In our paper, we tackle representational aspects around depth and\nconditioning of normalizing flows: both for general invertible architectures,\nand for a particular common architecture, affine couplings. We prove that\n$\\Theta(1)$ affine coupling layers suffice to exactly represent a permutation\nor $1 \\times 1$ convolution, as used in GLOW, showing that representationally\nthe choice of partition is not a bottleneck for depth. We also show that\nshallow affine coupling networks are universal approximators in Wasserstein\ndistance if ill-conditioning is allowed, and experimentally investigate related\nphenomena involving padding. Finally, we show a depth lower bound for general\nflow architectures with few neurons per layer and bounded Lipschitz constant.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 18:15:45 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 23:48:35 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Koehler", "Frederic", ""], ["Mehta", "Viraj", ""], ["Risteski", "Andrej", ""]]}, {"id": "2010.01171", "submitter": "Brendon G. Anderson", "authors": "Brendon G. Anderson, Somayeh Sojoudi", "title": "Data-Driven Assessment of Deep Neural Networks with Random Input\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using deep neural networks to operate safety-critical systems, assessing\nthe sensitivity of the network outputs when subject to uncertain inputs is of\nparamount importance. Such assessment is commonly done using reachability\nanalysis or robustness certification. However, certification techniques\ntypically ignore localization information, while reachable set methods can fail\nto issue robustness guarantees. Furthermore, many advanced methods are either\ncomputationally intractable in practice or restricted to very specific models.\nIn this paper, we develop a data-driven optimization-based method capable of\nsimultaneously certifying the safety of network outputs and localizing them.\nThe proposed method provides a unified assessment framework, as it subsumes\nstate-of-the-art reachability analysis and robustness certification. The method\napplies to deep neural networks of all sizes and structures, and to random\ninput uncertainty with a general distribution. We develop sufficient conditions\nfor the convexity of the underlying optimization, and for the number of data\nsamples to certify and localize the outputs with overwhelming probability. We\nexperimentally demonstrate the efficacy and tractability of the method on a\ndeep ReLU network.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:13:35 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Anderson", "Brendon G.", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2010.01179", "submitter": "Ralph Abboud", "authors": "Ralph Abboud, \\.Ismail \\.Ilkan Ceylan, Martin Grohe, Thomas\n  Lukasiewicz", "title": "The Surprising Power of Graph Neural Networks with Random Node\n  Initialization", "comments": "Proceedings of the Thirtieth International Joint Conference on\n  Artificial Intelligence (IJCAI-21). Code and data available at\n  http://www.github.com/ralphabb/GNN-RNI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are effective models for representation learning\non relational data. However, standard GNNs are limited in their expressive\npower, as they cannot distinguish graphs beyond the capability of the\nWeisfeiler-Leman graph isomorphism heuristic. In order to break this\nexpressiveness barrier, GNNs have been enhanced with random node initialization\n(RNI), where the idea is to train and run the models with randomized initial\nnode features. In this work, we analyze the expressive power of GNNs with RNI,\nand prove that these models are universal, a first such result for GNNs not\nrelying on computationally demanding higher-order properties. This universality\nresult holds even with partially randomized initial node features, and\npreserves the invariance properties of GNNs in expectation. We then empirically\nanalyze the effect of RNI on GNNs, based on carefully constructed datasets. Our\nempirical findings support the superior performance of GNNs with RNI over\nstandard GNNs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:53:05 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 14:52:04 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abboud", "Ralph", ""], ["Ceylan", "\u0130smail \u0130lkan", ""], ["Grohe", "Martin", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2010.01183", "submitter": "Sukru Yagiz Olmez", "authors": "S. Yagiz Olmez, Amirhossein Taghvaei and Prashant G. Mehta", "title": "Deep FPF: Gain function approximation in high-dimensional setting", "comments": "To be presented at 59th IEEE Conference on Decision and Control, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach to approximate the gain function\nof the feedback particle filter (FPF). The exact gain function is the solution\nof a Poisson equation involving a probability-weighted Laplacian. The numerical\nproblem is to approximate the exact gain function using only finitely many\nparticles sampled from the probability distribution.\n  Inspired by the recent success of the deep learning methods, we represent the\ngain function as a gradient of the output of a neural network. Thereupon\nconsidering a certain variational formulation of the Poisson equation, an\noptimization problem is posed for learning the weights of the neural network. A\nstochastic gradient algorithm is described for this purpose.\n  The proposed approach has two significant properties/advantages: (i) The\nstochastic optimization algorithm allows one to process, in parallel, only a\nbatch of samples (particles) ensuring good scaling properties with the number\nof particles; (ii) The remarkable representation power of neural networks means\nthat the algorithm is potentially applicable and useful to solve\nhigh-dimensional problems. We numerically establish these two properties and\nprovide extensive comparison to the existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:17:21 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Olmez", "S. Yagiz", ""], ["Taghvaei", "Amirhossein", ""], ["Mehta", "Prashant G.", ""]]}, {"id": "2010.01184", "submitter": "Felipe Maia Polo", "authors": "Felipe Maia Polo, Renato Vicente", "title": "Covariate Shift Adaptation in High-Dimensional and Divergent\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world applications of supervised learning methods, training and test\nsets are often sampled from the distinct distributions and we must resort to\ndomain adaptation techniques. One special class of techniques is Covariate\nShift Adaptation, which allows practitioners to obtain good generalization\nperformance in the distribution of interest when domains differ only by the\nmarginal distribution of features. Traditionally, Covariate Shift Adaptation is\nimplemented using Importance Weighting which may fail in high-dimensional\nsettings due to small Effective Sample Sizes (ESS). In this paper, we propose\n(i) a connection between ESS, high-dimensional settings and generalization\nbounds and (ii) a simple, general and theoretically sound approach to combine\nfeature selection and Covariate Shift Adaptation. The new approach yields good\nperformance with improved ESS.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:22:59 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 19:27:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Polo", "Felipe Maia", ""], ["Vicente", "Renato", ""]]}, {"id": "2010.01185", "submitter": "Gergely Flamich", "authors": "Gergely Flamich and Marton Havasi and Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Compressing Images by Encoding Their Latent Representations with\n  Relative Entropy Coding", "comments": "Accepted at the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.IV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) have seen widespread use in learned image\ncompression. They are used to learn expressive latent representations on which\ndownstream compression methods can operate with high efficiency. Recently\nproposed 'bits-back' methods can indirectly encode the latent representation of\nimages with codelength close to the relative entropy between the latent\nposterior and the prior. However, due to the underlying algorithm, these\nmethods can only be used for lossless compression, and they only achieve their\nnominal efficiency when compressing multiple images simultaneously; they are\ninefficient for compressing single images. As an alternative, we propose a\nnovel method, Relative Entropy Coding (REC), that can directly encode the\nlatent representation with codelength close to the relative entropy for single\nimages, supported by our empirical results obtained on the Cifar10, ImageNet32\nand Kodak datasets. Moreover, unlike previous bits-back methods, REC is\nimmediately applicable to lossy compression, where it is competitive with the\nstate-of-the-art on the Kodak dataset.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:23:22 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 12:04:25 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 13:59:03 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2021 13:38:10 GMT"}, {"version": "v5", "created": "Thu, 4 Mar 2021 09:57:29 GMT"}, {"version": "v6", "created": "Mon, 19 Apr 2021 09:38:22 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Flamich", "Gergely", ""], ["Havasi", "Marton", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2010.01189", "submitter": "Laetitia Shao", "authors": "La\\\"etitia Shao, Max Moroz, Elad Eban, Yair Movshovitz-Attias", "title": "Neighbourhood Distillation: On the benefits of non end-to-end\n  distillation", "comments": "16 pages, 8 figures. Update acknowledgements and fix typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training with back propagation is the standard method for training\ndeep neural networks. However, as networks become deeper and bigger, end-to-end\ntraining becomes more challenging: highly non-convex models gets stuck easily\nin local optima, gradients signals are prone to vanish or explode during\nback-propagation, training requires computational resources and time. In this\nwork, we propose to break away from the end-to-end paradigm in the context of\nKnowledge Distillation. Instead of distilling a model end-to-end, we propose to\nsplit it into smaller sub-networks - also called neighbourhoods - that are then\ntrained independently. We empirically show that distilling networks in a non\nend-to-end fashion can be beneficial in a diverse range of use cases. First, we\nshow that it speeds up Knowledge Distillation by exploiting parallelism and\ntraining on smaller networks. Second, we show that independently distilled\nneighbourhoods may be efficiently re-used for Neural Architecture Search.\nFinally, because smaller networks model simpler functions, we show that they\nare easier to train with synthetic data than their deeper counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:35:02 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 22:13:34 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Shao", "La\u00ebtitia", ""], ["Moroz", "Max", ""], ["Eban", "Elad", ""], ["Movshovitz-Attias", "Yair", ""]]}, {"id": "2010.01197", "submitter": "Xing Wang", "authors": "Xing Wang, Yijun Wang, Bin Weng, Aleksandr Vinel", "title": "Stock2Vec: A Hybrid Deep Learning Framework for Stock Market Prediction\n  with Representation Learning and Temporal Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have proposed to develop a global hybrid deep learning framework to\npredict the daily prices in the stock market. With representation learning, we\nderived an embedding called Stock2Vec, which gives us insight for the\nrelationship among different stocks, while the temporal convolutional layers\nare used for automatically capturing effective temporal patterns both within\nand across series. Evaluated on S&P 500, our hybrid framework integrates both\nadvantages and achieves better performance on the stock price prediction task\nthan several popular benchmarked models.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:54:30 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Xing", ""], ["Wang", "Yijun", ""], ["Weng", "Bin", ""], ["Vinel", "Aleksandr", ""]]}, {"id": "2010.01207", "submitter": "Xin Zhang", "authors": "Xin Zhang, Yanhua Li, Ziming Zhang, Zhi-Li Zhang", "title": "$f$-GAIL: Learning $f$-Divergence for Generative Adversarial Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to learn a policy from expert demonstrations\nthat minimizes the discrepancy between the learner and expert behaviors.\nVarious imitation learning algorithms have been proposed with different\npre-determined divergences to quantify the discrepancy. This naturally gives\nrise to the following question: Given a set of expert demonstrations, which\ndivergence can recover the expert policy more accurately with higher data\nefficiency? In this work, we propose $f$-GAIL, a new generative adversarial\nimitation learning (GAIL) model, that automatically learns a discrepancy\nmeasure from the $f$-divergence family as well as a policy capable of producing\nexpert-like behaviors. Compared with IL baselines with various predefined\ndivergence measures, $f$-GAIL learns better policies with higher data\nefficiency in six physics-based control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 21:39:56 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 05:29:20 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhang", "Xin", ""], ["Li", "Yanhua", ""], ["Zhang", "Ziming", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "2010.01213", "submitter": "Thomas Oliver", "authors": "Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver", "title": "Machine-Learning the Sato--Tate Conjecture", "comments": "21 pages, 1 table, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply some of the latest techniques from machine-learning to the\narithmetic of hyperelliptic curves. More precisely we show that, with\nimpressive accuracy and confidence (between 99 and 100 percent precision), and\nin very short time (matter of seconds on an ordinary laptop), a Bayesian\nclassifier can distinguish between Sato-Tate groups given a small number of\nEuler factors for the L-function. Our observations are in keeping with the\nSato-Tate conjecture for curves of low genus. For elliptic curves, this amounts\nto distinguishing generic curves (with Sato-Tate group SU(2)) from those with\ncomplex multiplication. In genus 2, a principal component analysis is observed\nto separate the generic Sato-Tate group USp(4) from the non-generic groups.\nFurthermore in this case, for which there are many more non-generic\npossibilities than in the case of elliptic curves, we demonstrate an accurate\ncharacterisation of several Sato-Tate groups with the same identity component.\nThroughout, our observations are verified using known results from the\nliterature and the data available in the LMFDB. The results in this paper\nsuggest that a machine can be trained to learn the Sato-Tate distributions and\nmay be able to classify curves much more efficiently than the methods available\nin the literature.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 21:57:47 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 15:36:25 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["He", "Yang-Hui", ""], ["Lee", "Kyu-Hwan", ""], ["Oliver", "Thomas", ""]]}, {"id": "2010.01243", "submitter": "Yae Jee Cho", "authors": "Yae Jee Cho and Jianyu Wang and Gauri Joshi", "title": "Client Selection in Federated Learning: Convergence Analysis and\n  Power-of-Choice Selection Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed optimization paradigm that enables a\nlarge number of resource-limited client nodes to cooperatively train a model\nwithout data sharing. Several works have analyzed the convergence of federated\nlearning by accounting of data heterogeneity, communication and computation\nlimitations, and partial client participation. However, they assume unbiased\nclient participation, where clients are selected at random or in proportion of\ntheir data sizes. In this paper, we present the first convergence analysis of\nfederated optimization for biased client selection strategies, and quantify how\nthe selection bias affects convergence speed. We reveal that biasing client\nselection towards clients with higher local loss achieves faster error\nconvergence. Using this insight, we propose Power-of-Choice, a communication-\nand computation-efficient client selection framework that can flexibly span the\ntrade-off between convergence speed and solution bias. Our experiments\ndemonstrate that Power-of-Choice strategies converge up to 3 $\\times$ faster\nand give $10$% higher test accuracy than the baseline random selection.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 01:04:17 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Cho", "Yae Jee", ""], ["Wang", "Jianyu", ""], ["Joshi", "Gauri", ""]]}, {"id": "2010.01247", "submitter": "Zhun Deng", "authors": "Zhun Deng, Cynthia Dwork, Jialiang Wang, Linjun Zhang", "title": "Interpreting Robust Optimization via Adversarial Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust optimization has been widely used in nowadays data science, especially\nin adversarial training. However, little research has been done to quantify how\nrobust optimization changes the optimizers and the prediction losses comparing\nto standard training. In this paper, inspired by the influence function in\nrobust statistics, we introduce the Adversarial Influence Function (AIF) as a\ntool to investigate the solution produced by robust optimization. The proposed\nAIF enjoys a closed-form and can be calculated efficiently. To illustrate the\nusage of AIF, we apply it to study model sensitivity -- a quantity defined to\ncapture the change of prediction losses on the natural data after implementing\nrobust optimization. We use AIF to analyze how model complexity and randomized\nsmoothing affect the model sensitivity with respect to specific models. We\nfurther derive AIF for kernel regressions, with a particular application to\nneural tangent kernels, and experimentally demonstrate the effectiveness of the\nproposed AIF. Lastly, the theories of AIF will be extended to distributional\nrobust optimization.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 01:19:10 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Deng", "Zhun", ""], ["Dwork", "Cynthia", ""], ["Wang", "Jialiang", ""], ["Zhang", "Linjun", ""]]}, {"id": "2010.01250", "submitter": "Zhichao Huang", "authors": "Zhichao Huang, Yaowei Huang, Tong Zhang", "title": "CorrAttack: Black-box Adversarial Attack with Structured Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for score-based adversarial attack, where the\nattacker queries the loss-oracle of the target model. Our method employs a\nparameterized search space with a structure that captures the relationship of\nthe gradient of the loss function. We show that searching over the structured\nspace can be approximated by a time-varying contextual bandits problem, where\nthe attacker takes feature of the associated arm to make modifications of the\ninput, and receives an immediate reward as the reduction of the loss function.\nThe time-varying contextual bandits problem can then be solved by a Bayesian\noptimization procedure, which can take advantage of the features of the\nstructured action space. The experiments on ImageNet and the Google Cloud\nVision API demonstrate that the proposed method achieves the state of the art\nsuccess rates and query efficiencies for both undefended and defended models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 01:44:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Huang", "Zhichao", ""], ["Huang", "Yaowei", ""], ["Zhang", "Tong", ""]]}, {"id": "2010.01262", "submitter": "Samuel Lavoie-Marchildon", "authors": "Samuel Lavoie, Faruk Ahmed, Aaron Courville", "title": "Integrating Categorical Semantics into Unsupervised Domain Translation", "comments": "22 pages. In submission to the International Conference on Learning\n  Representation (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While unsupervised domain translation (UDT) has seen a lot of success\nrecently, we argue that mediating its translation via categorical semantic\nfeatures could broaden its applicability. In particular, we demonstrate that\ncategorical semantics improves the translation between perceptually different\ndomains sharing multiple object categories. We propose a method to learn, in an\nunsupervised manner, categorical semantic features (such as object labels) that\nare invariant of the source and target domains. We show that conditioning the\nstyle encoder of unsupervised domain translation methods on the learned\ncategorical semantics leads to a translation preserving the digits on\nMNIST$\\leftrightarrow$SVHN and to a more realistic stylization on\nSketches$\\to$Reals.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 02:40:46 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 22:10:11 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Lavoie", "Samuel", ""], ["Ahmed", "Faruk", ""], ["Courville", "Aaron", ""]]}, {"id": "2010.01264", "submitter": "Enmao Diao", "authors": "Enmao Diao, Jie Ding, Vahid Tarokh", "title": "HeteroFL: Computation and Communication Efficient Federated Learning for\n  Heterogeneous Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a method of training machine learning models on\nprivate data distributed over a large number of possibly heterogeneous clients\nsuch as mobile phones and IoT devices. In this work, we propose a new federated\nlearning framework named HeteroFL to address heterogeneous clients equipped\nwith very different computation and communication capabilities. Our solution\ncan enable the training of heterogeneous local models with varying computation\ncomplexities and still produce a single global inference model. For the first\ntime, our method challenges the underlying assumption of existing work that\nlocal models have to share the same architecture as the global model. We\ndemonstrate several strategies to enhance FL training and conduct extensive\nempirical evaluations, including five computation complexity levels of three\nmodel architecture on three datasets. We show that adaptively distributing\nsubnetworks according to clients' capabilities is both computation and\ncommunication efficient.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 02:55:33 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 02:23:35 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2010.01265", "submitter": "Chuheng Zhang", "authors": "Chuheng Zhang, Yuanqi Li, Xi Chen, Yifei Jin, Pingzhong Tang, Jian Li", "title": "DoubleEnsemble: A New Ensemble Method Based on Sample Reweighting and\n  Feature Selection for Financial Data Analysis", "comments": "This paper was published in ICDM 2020. We have fixed several typos\n  and polished the writing in this revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models (such as deep neural networks and boosting\ndecision tree models) have become increasingly popular in financial market\nprediction, due to their superior capacity to extract complex non-linear\npatterns. However, since financial datasets have very low signal-to-noise ratio\nand are non-stationary, complex models are often very prone to overfitting and\nsuffer from instability issues. Moreover, as various machine learning and data\nmining tools become more widely used in quantitative trading, many trading\nfirms have been producing an increasing number of features (aka factors).\nTherefore, how to automatically select effective features becomes an imminent\nproblem. To address these issues, we propose DoubleEnsemble, an ensemble\nframework leveraging learning trajectory based sample reweighting and shuffling\nbased feature selection. Specifically, we identify the key samples based on the\ntraining dynamics on each sample and elicit key features based on the ablation\nimpact of each feature via shuffling. Our model is applicable to a wide range\nof base models, capable of extracting complex patterns, while mitigating the\noverfitting and instability issues for financial market prediction. We conduct\nextensive experiments, including price prediction for cryptocurrencies and\nstock trading, using both DNN and gradient boosting decision tree as base\nmodels. Our experiment results demonstrate that DoubleEnsemble achieves a\nsuperior performance compared with several baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 02:57:10 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 02:35:02 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 12:10:40 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhang", "Chuheng", ""], ["Li", "Yuanqi", ""], ["Chen", "Xi", ""], ["Jin", "Yifei", ""], ["Tang", "Pingzhong", ""], ["Li", "Jian", ""]]}, {"id": "2010.01267", "submitter": "Yi Xu", "authors": "Yi Xu, Asaf Noy, Ming Lin, Qi Qian, Hao Li, Rong Jin", "title": "WeMix: How to Better Utilize Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a widely used training trick in deep learning to improve\nthe network generalization ability. Despite many encouraging results, several\nrecent studies did point out limitations of the conventional data augmentation\nscheme in certain scenarios, calling for a better theoretical understanding of\ndata augmentation. In this work, we develop a comprehensive analysis that\nreveals pros and cons of data augmentation. The main limitation of data\naugmentation arises from the data bias, i.e. the augmented data distribution\ncan be quite different from the original one. This data bias leads to a\nsuboptimal performance of existing data augmentation methods. To this end, we\ndevelop two novel algorithms, termed \"AugDrop\" and \"MixLoss\", to correct the\ndata bias in the data augmentation. Our theoretical analysis shows that both\nalgorithms are guaranteed to improve the effect of data augmentation through\nthe bias correction, which is further validated by our empirical studies.\nFinally, we propose a generic algorithm \"WeMix\" by combining AugDrop and\nMixLoss, whose effectiveness is observed from extensive empirical evaluations.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 03:12:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Xu", "Yi", ""], ["Noy", "Asaf", ""], ["Lin", "Ming", ""], ["Qian", "Qi", ""], ["Li", "Hao", ""], ["Jin", "Rong", ""]]}, {"id": "2010.01274", "submitter": "Andreas Munk", "authors": "Andreas Munk, William Harvey, Frank Wood", "title": "Assisting the Adversary to Improve GAN Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some of the most popular methods for improving the stability and performance\nof GANs involve constraining or regularizing the discriminator. In this paper\nwe consider a largely overlooked regularization technique which we refer to as\nthe Adversary's Assistant (AdvAs). We motivate this using a different\nperspective to that of prior work. Specifically, we consider a common mismatch\nbetween theoretical analysis and practice: analysis often assumes that the\ndiscriminator reaches its optimum on each iteration. In practice, this is\nessentially never true, often leading to poor gradient estimates for the\ngenerator. To address this, AdvAs is a theoretically motivated penalty imposed\non the generator based on the norm of the gradients used to train the\ndiscriminator. This encourages the generator to move towards points where the\ndiscriminator is optimal. We demonstrate the effect of applying AdvAs to\nseveral GAN objectives, datasets and network architectures. The results\nindicate a reduction in the mismatch between theory and practice and that AdvAs\ncan lead to improvement of GAN training, as measured by FID scores.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 04:20:45 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 00:17:09 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Munk", "Andreas", ""], ["Harvey", "William", ""], ["Wood", "Frank", ""]]}, {"id": "2010.01278", "submitter": "Quanquan Gu", "authors": "Jinghui Chen and Yu Cheng and Zhe Gan and Quanquan Gu and Jingjing Liu", "title": "Efficient Robust Training via Backward Smoothing", "comments": "12 pages, 11 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is so far the most effective strategy in defending\nagainst adversarial examples. However, it suffers from high computational cost\ndue to the iterative adversarial attacks in each training step. Recent studies\nshow that it is possible to achieve Fast Adversarial Training by performing a\nsingle-step attack with random initialization. Yet, it remains a mystery why\nrandom initialization helps. Besides, such an approach still lags behind\nstate-of-the-art adversarial training algorithms on both stability and model\nrobustness. In this work, we develop a new understanding towards Fast\nAdversarial Training, by viewing random initialization as performing randomized\nsmoothing for better optimization of the inner maximization problem. From this\nperspective, we show that the smoothing effect by random initialization is not\nsufficient under the adversarial perturbation constraint. A new initialization\nstrategy, backward smoothing, is proposed to address this issue and\nsignificantly improves both stability and model robustness over single-step\nrobust training methods.Experiments on multiple benchmarks demonstrate that our\nmethod achieves similar model robustness as the original TRADES method, while\nusing much less training time ($\\sim$3x improvement with the same training\nschedule).\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 04:37:33 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Jinghui", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Gu", "Quanquan", ""], ["Liu", "Jingjing", ""]]}, {"id": "2010.01279", "submitter": "Quanquan Gu", "authors": "Boxi Wu and Jinghui Chen and Deng Cai and Xiaofei He and Quanquan Gu", "title": "Do Wider Neural Networks Really Help Adversarial Robustness?", "comments": "18 pages, 3 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is currently the most powerful defense against\nadversarial examples. Previous empirical results suggest that adversarial\ntraining requires wider networks for better performances. Yet, it remains\nelusive how does neural network width affect model robustness. In this paper,\nwe carefully examine the relation between network width and model robustness.\nWe present an intriguing phenomenon that the increased network width may not\nhelp robustness. Specifically, we show that the model robustness is closely\nrelated to both natural accuracy and perturbation stability, a new metric\nproposed in our paper to characterize the model's stability under adversarial\nperturbations. While better natural accuracy can be achieved on wider neural\nnetworks, the perturbation stability actually becomes worse, leading to a\npotentially worse overall model robustness. To understand the origin of this\nphenomenon, we further relate the perturbation stability with the network's\nlocal Lipschitznesss. By leveraging recent results on neural tangent kernels,\nwe show that larger network width naturally leads to worse perturbation\nstability. This suggests that to fully unleash the power of wide model\narchitecture, practitioners should adopt a larger regularization parameter for\ntraining wider networks. Experiments on benchmark datasets confirm that this\nstrategy could indeed alleviate the perturbation stability issue and improve\nthe state-of-the-art robust models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 04:46:17 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:58:37 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wu", "Boxi", ""], ["Chen", "Jinghui", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""], ["Gu", "Quanquan", ""]]}, {"id": "2010.01285", "submitter": "Xuanli He", "authors": "Lingjuan Lyu, Xuanli He, Yitong Li", "title": "Differentially Private Representation for NLP: Formal Guarantee and An\n  Empirical Study on Privacy and Fairness", "comments": "accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated that hidden representation learned by a deep model\ncan encode private information of the input, hence can be exploited to recover\nsuch information with reasonable accuracy. To address this issue, we propose a\nnovel approach called Differentially Private Neural Representation (DPNR) to\npreserve the privacy of the extracted representation from text. DPNR utilises\nDifferential Privacy (DP) to provide a formal privacy guarantee. Further, we\nshow that masking words via dropout can further enhance privacy. To maintain\nutility of the learned representation, we integrate DP-noisy representation\ninto a robust training process to derive a robust target model, which also\nhelps for model fairness over various demographic variables. Experimental\nresults on benchmark datasets under various parameter settings demonstrate that\nDPNR largely reduces privacy leakage without significantly sacrificing the main\ntask performance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 05:58:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Lyu", "Lingjuan", ""], ["He", "Xuanli", ""], ["Li", "Yitong", ""]]}, {"id": "2010.01298", "submitter": "Peter Karkus", "authors": "Peter Karkus, Mehdi Mirza, Arthur Guez, Andrew Jaegle, Timothy\n  Lillicrap, Lars Buesing, Nicolas Heess, Theophane Weber", "title": "Beyond Tabula-Rasa: a Modular Reinforcement Learning Approach for\n  Physically Embedded 3D Sokoban", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent robots need to achieve abstract objectives using concrete,\nspatiotemporally complex sensory information and motor control. Tabula rasa\ndeep reinforcement learning (RL) has tackled demanding tasks in terms of either\nvisual, abstract, or physical reasoning, but solving these jointly remains a\nformidable challenge. One recent, unsolved benchmark task that integrates these\nchallenges is Mujoban, where a robot needs to arrange 3D warehouses generated\nfrom 2D Sokoban puzzles. We explore whether integrated tasks like Mujoban can\nbe solved by composing RL modules together in a sense-plan-act hierarchy, where\nmodules have well-defined roles similarly to classic robot architectures.\nUnlike classic architectures that are typically model-based, we use only\nmodel-free modules trained with RL or supervised learning. We find that our\nmodular RL approach dramatically outperforms the state-of-the-art monolithic RL\nagent on Mujoban. Further, learned modules can be reused when, e.g., using a\ndifferent robot platform to solve the same task. Together our results give\nstrong evidence for the importance of research into modular RL designs. Project\nwebsite: https://sites.google.com/view/modular-rl/\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 07:48:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Karkus", "Peter", ""], ["Mirza", "Mehdi", ""], ["Guez", "Arthur", ""], ["Jaegle", "Andrew", ""], ["Lillicrap", "Timothy", ""], ["Buesing", "Lars", ""], ["Heess", "Nicolas", ""], ["Weber", "Theophane", ""]]}, {"id": "2010.01311", "submitter": "Lucas Egidio", "authors": "Lucas N. Egidio, Anders Hansson, Bo Wahlberg", "title": "Learning the Step-size Policy for the Limited-Memory\n  Broyden-Fletcher-Goldfarb-Shanno Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of how to learn a step-size policy for the\nLimited-Memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm. This is a\nlimited computational memory quasi-Newton method widely used for deterministic\nunconstrained optimization but currently avoided in large-scale problems for\nrequiring step sizes to be provided at each iteration. Existing methodologies\nfor the step size selection for L-BFGS use heuristic tuning of design\nparameters and massive re-evaluations of the objective function and gradient to\nfind appropriate step-lengths. We propose a neural network architecture with\nlocal information of the current iterate as the input. The step-length policy\nis learned from data of similar optimization problems, avoids additional\nevaluations of the objective function, and guarantees that the output step\nremains inside a pre-defined interval. The corresponding training procedure is\nformulated as a stochastic optimization problem using the backpropagation\nthrough time algorithm. The performance of the proposed method is evaluated on\nthe training of classifiers for the MNIST database for handwritten digits and\nfor CIFAR-10. The results show that the proposed algorithm outperforms\nheuristically tuned optimizers such as ADAM, RMSprop, L-BFGS with a\nbacktracking line search, and L-BFGS with a constant step size. The numerical\nresults also show that a learned policy can be used as a warm-start to train\nnew policies for different problems after a few additional training steps,\nhighlighting its potential use in multiple large-scale optimization problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 09:34:03 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 23:22:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Egidio", "Lucas N.", ""], ["Hansson", "Anders", ""], ["Wahlberg", "Bo", ""]]}, {"id": "2010.01319", "submitter": "Lorenc Kapllani M.Sc.", "authors": "Lorenc Kapllani and Long Teng", "title": "Deep Learning algorithms for solving high dimensional nonlinear Backward\n  Stochastic Differential Equations", "comments": "21 pages, 5 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study deep learning-based schemes for solving high dimensional nonlinear\nbackward stochastic differential equations (BSDEs). First we show how to\nimprove the performances of the proposed scheme in [W. E and J. Han and A.\nJentzen, Commun. Math. Stat., 5 (2017), pp.349-380] regarding computational\ntime by using a single neural network architecture instead of the stacked deep\nneural networks. Furthermore, those schemes can be stuck in poor local minima\nor diverges, especially for a complex solution structure and longer terminal\ntime. To solve this problem, we investigate to reformulate the problem by\nincluding local losses and exploit the Long Short Term Memory (LSTM) networks\nwhich are a type of recurrent neural networks (RNN). Finally, in order to study\nnumerical convergence and thus illustrate the improved performances with the\nproposed methods, we provide numerical results for several 100-dimensional\nnonlinear BSDEs including nonlinear pricing problems in finance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 10:18:58 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 11:53:21 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Kapllani", "Lorenc", ""], ["Teng", "Long", ""]]}, {"id": "2010.01333", "submitter": "Lianmeng Jiao", "authors": "Lianmeng Jiao, Thierry Denoeux, Zhun-ga Liu, Quan Pan", "title": "EGMM: an Evidential Version of the Gaussian Mixture Model for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian mixture model (GMM) provides a convenient yet principled\nframework for clustering, with properties suitable for statistical inference.\nIn this paper, we propose a new model-based clustering algorithm, called EGMM\n(evidential GMM), in the theoretical framework of belief functions to better\ncharacterize cluster-membership uncertainty. With a mass function representing\nthe cluster membership of each object, the evidential Gaussian mixture\ndistribution composed of the components over the powerset of the desired\nclusters is proposed to model the entire dataset. The parameters in EGMM are\nestimated by a specially designed Expectation-Maximization (EM) algorithm. A\nvalidity index allowing automatic determination of the proper number of\nclusters is also provided. The proposed EGMM is as convenient as the classical\nGMM, but can generate a more informative evidential partition for the\nconsidered dataset. Experiments with synthetic and real datasets demonstrate\nthe good performance of the proposed method as compared with some other\nprototype-based and model-based clustering techniques.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 11:59:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Jiao", "Lianmeng", ""], ["Denoeux", "Thierry", ""], ["Liu", "Zhun-ga", ""], ["Pan", "Quan", ""]]}, {"id": "2010.01356", "submitter": "Brett Daley", "authors": "Brett Daley and Christopher Amato", "title": "Expectigrad: Fast Stochastic Optimization with Robust Convergence\n  Properties", "comments": "18 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many popular adaptive gradient methods such as Adam and RMSProp rely on an\nexponential moving average (EMA) to normalize their stepsizes. While the EMA\nmakes these methods highly responsive to new gradient information, recent\nresearch has shown that it also causes divergence on at least one convex\noptimization problem. We propose a novel method called Expectigrad, which\nadjusts stepsizes according to a per-component unweighted mean of all\nhistorical gradients and computes a bias-corrected momentum term jointly\nbetween the numerator and denominator. We prove that Expectigrad cannot diverge\non every instance of the optimization problem known to cause Adam to diverge.\nWe also establish a regret bound in the general stochastic nonconvex setting\nthat suggests Expectigrad is less susceptible to gradient variance than\nexisting methods are. Testing Expectigrad on several high-dimensional machine\nlearning tasks, we find it often performs favorably to state-of-the-art methods\nwith little hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 13:34:27 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Daley", "Brett", ""], ["Amato", "Christopher", ""]]}, {"id": "2010.01359", "submitter": "Francesco Crecchi", "authors": "Francesco Crecchi, Cyril de Bodt, Michel Verleysen, John A. Lee and\n  Davide Bacciu", "title": "Perplexity-free Parametric t-SNE", "comments": "ESANN 2020 proceedings, European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning. Online event, 2-4\n  October 2020, i6doc.com publ., ISBN 978-2-87587-074-2. Available from\n  http://www.i6doc.com/en/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm is a\nubiquitously employed dimensionality reduction (DR) method. Its non-parametric\nnature and impressive efficacy motivated its parametric extension. It is\nhowever bounded to a user-defined perplexity parameter, restricting its DR\nquality compared to recently developed multi-scale perplexity-free approaches.\nThis paper hence proposes a multi-scale parametric t-SNE scheme, relieved from\nthe perplexity tuning and with a deep neural network implementing the mapping.\nIt produces reliable embeddings with out-of-sample extensions, competitive with\nthe best perplexity adjustments in terms of neighborhood preservation on\nmultiple data sets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 13:47:01 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Crecchi", "Francesco", ""], ["de Bodt", "Cyril", ""], ["Verleysen", "Michel", ""], ["Lee", "John A.", ""], ["Bacciu", "Davide", ""]]}, {"id": "2010.01369", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "Computational Separation Between Convolutional and Fully-Connected\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) exhibit unmatched performance in a\nmultitude of computer vision tasks. However, the advantage of using\nconvolutional networks over fully-connected networks is not understood from a\ntheoretical perspective. In this work, we show how convolutional networks can\nleverage locality in the data, and thus achieve a computational advantage over\nfully-connected networks. Specifically, we show a class of problems that can be\nefficiently solved using convolutional networks trained with gradient-descent,\nbut at the same time is hard to learn using a polynomial-size fully-connected\nnetwork.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 14:24:59 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "2010.01374", "submitter": "Gellert Weisz", "authors": "Gell\\'ert Weisz, Philip Amortila, Csaba Szepesv\\'ari", "title": "Exponential Lower Bounds for Planning in MDPs With Linearly-Realizable\n  Optimal Action-Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of local planning in fixed-horizon and discounted\nMarkov Decision Processes (MDPs) with linear function approximation and a\ngenerative model under the assumption that the optimal action-value function\nlies in the span of a feature map that is available to the planner. Previous\nwork has left open the question of whether there exist sound planners that need\nonly poly(H,d) queries regardless of the MDP, where H is the horizon and d is\nthe dimensionality of the features. We answer this question in the negative: we\nshow that any sound planner must query at least $\\min(\\exp({\\Omega}(d)),\n{\\Omega}(2^H))$ samples in the fized-horizon setting and $\\exp({\\Omega}(d))$\nsamples in the discounted setting. We also show that for any ${\\delta}>0$, the\nleast-squares value iteration algorithm with $O(H^5d^{H+1}/{\\delta}^2)$ queries\ncan compute a ${\\delta}$-optimal policy in the fixed-horizon setting. We\ndiscuss implications and remaining open questions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 15:19:26 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 22:44:00 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Amortila", "Philip", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2010.01376", "submitter": "Zhenyu Liao", "authors": "Zhenyu Liao, Romain Couillet, Michael W. Mahoney", "title": "Sparse Quantized Spectral Clustering", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR 2021),\n  https://openreview.net/forum?id=pBqLS-7KYAF", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large data matrix, sparsifying, quantizing, and/or performing other\nentry-wise nonlinear operations can have numerous benefits, ranging from\nspeeding up iterative algorithms for core numerical linear algebra problems to\nproviding nonlinear filters to design state-of-the-art neural network models.\nHere, we exploit tools from random matrix theory to make precise statements\nabout how the eigenspectrum of a matrix changes under such nonlinear\ntransformations. In particular, we show that very little change occurs in the\ninformative eigenstructure even under drastic sparsification/quantization, and\nconsequently that very little downstream performance loss occurs with very\naggressively sparsified or quantized spectral clustering. We illustrate how\nthese results depend on the nonlinearity, we characterize a phase transition\nbeyond which spectral clustering becomes possible, and we show when such\nnonlinear transformations can introduce spurious non-informative eigenvectors.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 15:58:07 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2010.01381", "submitter": "Jing Shi", "authors": "Jing Shi, Jing Bi, Yingru Liu, Chenliang Xu", "title": "Cubic Spline Smoothing Compensation for Irregularly Sampled Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The marriage of recurrent neural networks and neural ordinary differential\nnetworks (ODE-RNN) is effective in modeling irregularly-observed sequences.\nWhile ODE produces the smooth hidden states between observation intervals, the\nRNN will trigger a hidden state jump when a new observation arrives, thus cause\nthe interpolation discontinuity problem. To address this issue, we propose the\ncubic spline smoothing compensation, which is a stand-alone module upon either\nthe output or the hidden state of ODE-RNN and can be trained end-to-end. We\nderive its analytical solution and provide its theoretical interpolation error\nbound. Extensive experiments indicate its merits over both ODE-RNN and cubic\nspline interpolation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 16:15:22 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shi", "Jing", ""], ["Bi", "Jing", ""], ["Liu", "Yingru", ""], ["Xu", "Chenliang", ""]]}, {"id": "2010.01388", "submitter": "Mikhail Hushchyn", "authors": "Mikhail Hushchyn, Kenenbek Arzymatov, Denis Derkach", "title": "Online Neural Networks for Change-Point Detection", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Moments when a time series changes its behaviour are called change points.\nDetection of such points is a well-known problem, which can be found in many\napplications: quality monitoring of industrial processes, failure detection in\ncomplex systems, health monitoring, speech recognition and video analysis.\nOccurrence of change point implies that the state of the system is altered and\nits timely detection might help to prevent unwanted consequences. In this\npaper, we present two online change-point detection approaches based on neural\nnetworks. These algorithms demonstrate linear computational complexity and are\nsuitable for change-point detection in large time series. We compare them with\nthe best known algorithms on various synthetic and real world data sets.\nExperiments show that the proposed methods outperform known approaches.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 16:55:59 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hushchyn", "Mikhail", ""], ["Arzymatov", "Kenenbek", ""], ["Derkach", "Denis", ""]]}, {"id": "2010.01404", "submitter": "Masahiro Kato", "authors": "Masahiro Kato and Kei Nakagawa", "title": "Direct Expected Quadratic Utility Maximization for Mean-Variance\n  Controlled Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk management is critical in decision-making, and mean-variance (MV)\ntrade-off is one of the most common criteria. However, in reinforcement\nlearning (RL) under a dynamic environment, MV control is not as easy as that\nunder a static environment owing to computational difficulties. For MV\ncontrolled RL, this paper proposes direct expected quadratic utility\nmaximization (EQUM), where a mean-variance efficient agent is given as its\nsolution. This approach does not only avoid computational difficulties but also\nimproves empirical performances. In experiments, we demonstrate the\neffectiveness of the proposed EQUM with benchmark settings.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 18:17:34 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 20:49:23 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kato", "Masahiro", ""], ["Nakagawa", "Kei", ""]]}, {"id": "2010.01405", "submitter": "Zhiyan Ding", "authors": "Zhiyan Ding and Qin Li and Jianfeng Lu and Stephen J. Wright", "title": "Random Coordinate Langevin Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Langevin Monte Carlo (LMC) is a popular Markov chain Monte Carlo sampling\nmethod. One drawback is that it requires the computation of the full gradient\nat each iteration, an expensive operation if the dimension of the problem is\nhigh. We propose a new sampling method: Random Coordinate LMC (RC-LMC). At each\niteration, a single coordinate is randomly selected to be updated by a multiple\nof the partial derivative along this direction plus noise, and all other\ncoordinates remain untouched. We investigate the total complexity of RC-LMC and\ncompare it with the classical LMC for log-concave probability distributions.\nWhen the gradient of the log-density is Lipschitz, RC-LMC is less expensive\nthan the classical LMC if the log-density is highly skewed for high dimensional\nproblems, and when both the gradient and the Hessian of the log-density are\nLipschitz, RC-LMC is always cheaper than the classical LMC, by a factor\nproportional to the square root of the problem dimension. In the latter case,\nour estimate of complexity is sharp with respect to the dimension.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 18:18:11 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ding", "Zhiyan", ""], ["Li", "Qin", ""], ["Lu", "Jianfeng", ""], ["Wright", "Stephen J.", ""]]}, {"id": "2010.01412", "submitter": "Hossein Mobahi", "authors": "Pierre Foret, Ariel Kleiner, Hossein Mobahi, Behnam Neyshabur", "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's heavily overparameterized models, the value of the training loss\nprovides few guarantees on model generalization ability. Indeed, optimizing\nonly the training loss value, as is commonly done, can easily lead to\nsuboptimal model quality. Motivated by prior work connecting the geometry of\nthe loss landscape and generalization, we introduce a novel, effective\nprocedure for instead simultaneously minimizing loss value and loss sharpness.\nIn particular, our procedure, Sharpness-Aware Minimization (SAM), seeks\nparameters that lie in neighborhoods having uniformly low loss; this\nformulation results in a min-max optimization problem on which gradient descent\ncan be performed efficiently. We present empirical results showing that SAM\nimproves model generalization across a variety of benchmark datasets (e.g.,\nCIFAR-10, CIFAR-100, ImageNet, finetuning tasks) and models, yielding novel\nstate-of-the-art performance for several. Additionally, we find that SAM\nnatively provides robustness to label noise on par with that provided by\nstate-of-the-art procedures that specifically target learning with noisy\nlabels. We open source our code at\n\\url{https://github.com/google-research/sam}.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 19:02:10 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:49:36 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 16:44:25 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Foret", "Pierre", ""], ["Kleiner", "Ariel", ""], ["Mobahi", "Hossein", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "2010.01430", "submitter": "Alexey Zakharov", "authors": "Alexey Zakharov, Matthew Crosby, Zafeirios Fountas", "title": "Episodic Memory for Learning Subjective-Timescale Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based learning, an agent's model is commonly defined over\ntransitions between consecutive states of an environment even though planning\noften requires reasoning over multi-step timescales, with intermediate states\neither unnecessary, or worse, accumulating prediction error. In contrast,\nintelligent behaviour in biological organisms is characterised by the ability\nto plan over varying temporal scales depending on the context. Inspired by the\nrecent works on human time perception, we devise a novel approach to learning a\ntransition dynamics model, based on the sequences of episodic memories that\ndefine the agent's subjective timescale - over which it learns world dynamics\nand over which future planning is performed. We implement this in the framework\nof active inference and demonstrate that the resulting subjective-timescale\nmodel (STM) can systematically vary the temporal extent of its predictions\nwhile preserving the same computational efficiency. Additionally, we show that\nSTM predictions are more likely to introduce future salient events (for example\nnew objects coming into view), incentivising exploration of new areas of the\nenvironment. As a result, STM produces more informative action-conditioned\nroll-outs that assist the agent in making better decisions. We validate\nsignificant improvement in our STM agent's performance in the Animal-AI\nenvironment against a baseline system, trained using the environment's\nobjective-timescale dynamics.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 21:55:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zakharov", "Alexey", ""], ["Crosby", "Matthew", ""], ["Fountas", "Zafeirios", ""]]}, {"id": "2010.01449", "submitter": "Jun-Kun Wang", "authors": "Jun-Kun Wang and Jacob Abernethy", "title": "Quickly Finding a Benign Region via Heavy Ball Momentum in Non-Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Heavy Ball Method, proposed by Polyak over five decades ago, is a\nfirst-order method for optimizing continuous functions. While its stochastic\ncounterpart has proven extremely popular in training deep networks, there are\nalmost no known functions where deterministic Heavy Ball is provably faster\nthan the simple and classical gradient descent algorithm in non-convex\noptimization. The success of Heavy Ball has thus far eluded theoretical\nunderstanding. Our goal is to address this gap, and in the present work we\nidentify two non-convex problems where we provably show that the Heavy Ball\nmomentum helps the iterate to enter a benign region that contains a global\noptimal point faster. We show that Heavy Ball exhibits simple dynamics that\nclearly reveal the benefit of using a larger value of momentum parameter for\nthe problems. The first of these optimization problems is the phase retrieval\nproblem, which has useful applications in physical science. The second of these\noptimization problems is the cubic-regularized minimization, a critical\nsubroutine required by Nesterov-Polyak cubic-regularized method to find\nsecond-order stationary points in general smooth non-convex problems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 00:07:06 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 20:06:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Jun-Kun", ""], ["Abernethy", "Jacob", ""]]}, {"id": "2010.01473", "submitter": "Mahyar Khayatkhoei", "authors": "Mahyar Khayatkhoei, Ahmed Elgammal", "title": "Spatial Frequency Bias in Convolutional Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the success of Generative Adversarial Networks (GANs) on natural images\nquickly propels them into various real-life applications across different\ndomains, it becomes more and more important to clearly understand their\nlimitations. Specifically, understanding GANs' capability across the full\nspectrum of spatial frequencies, i.e. beyond the low-frequency dominant\nspectrum of natural images, is critical for assessing the reliability of GAN\ngenerated data in any detail-sensitive application (e.g. denoising, filling and\nsuper-resolution in medical and satellite images). In this paper, we show that\nthe ability of convolutional GANs to learn a distribution is significantly\naffected by the spatial frequency of the underlying carrier signal, that is,\nGANs have a bias against learning high spatial frequencies. Crucially, we show\nthat this bias is not merely a result of the scarcity of high frequencies in\nnatural images, rather, it is a systemic bias hindering the learning of high\nfrequencies regardless of their prominence in a dataset. Furthermore, we\nexplain why large-scale GANs' ability to generate fine details on natural\nimages does not exclude them from the adverse effects of this bias. Finally, we\npropose a method for manipulating this bias with minimal computational\noverhead. This method can be used to explicitly direct computational resources\ntowards any specific spatial frequency of interest in a dataset, extending the\nflexibility of GANs.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 03:05:29 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 01:16:58 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 08:43:19 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Khayatkhoei", "Mahyar", ""], ["Elgammal", "Ahmed", ""]]}, {"id": "2010.01488", "submitter": "Sai Raam Venkatraman", "authors": "Sai Raam Venkatraman, Ankit Anand, S. Balasubramanian, R. Raghunatha\n  Sarma", "title": "Learning Compositional Structures for Deep Learning: Why\n  Routing-by-agreement is Necessary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A formal description of the compositionality of neural networks is associated\ndirectly with the formal grammar-structure of the objects it seeks to\nrepresent. This formal grammar-structure specifies the kind of components that\nmake up an object, and also the configurations they are allowed to be in. In\nother words, objects can be described as a parse-tree of its components -- a\nstructure that can be seen as a candidate for building connection-patterns\namong neurons in neural networks. We present a formal grammar description of\nconvolutional neural networks and capsule networks that shows how capsule\nnetworks can enforce such parse-tree structures, while CNNs do not.\nSpecifically, we show that the entropy of routing coefficients in the dynamic\nrouting algorithm controls this ability. Thus, we introduce the entropy of\nrouting weights as a loss function for better compositionality among capsules.\nWe show by experiments, on data with a compositional structure, that the use of\nthis loss enables capsule networks to better detect changes in\ncompositionality. Our experiments show that as the entropy of the routing\nweights increases, the ability to detect changes in compositionality reduces.\nWe see that, without routing, capsule networks perform similar to convolutional\nneural networks in that both these models perform badly at detecting changes in\ncompositionality. Our results indicate that routing is an important part of\ncapsule networks -- effectively answering recent work that has questioned its\nnecessity. We also, by experiments on SmallNORB, CIFAR-10, and FashionMNIST,\nshow that this loss keeps the accuracy of capsule network models comparable to\nmodels that do not use it .\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 05:50:51 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 04:45:11 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Venkatraman", "Sai Raam", ""], ["Anand", "Ankit", ""], ["Balasubramanian", "S.", ""], ["Sarma", "R. Raghunatha", ""]]}, {"id": "2010.01523", "submitter": "Tonghan Wang", "authors": "Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson,\n  Chongjie Zhang", "title": "RODE: Learning Roles to Decompose Multi-Agent Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role-based learning holds the promise of achieving scalable multi-agent\nlearning by decomposing complex tasks using roles. However, it is largely\nunclear how to efficiently discover such a set of roles. To solve this problem,\nwe propose to first decompose joint action spaces into restricted role action\nspaces by clustering actions according to their effects on the environment and\nother agents. Learning a role selector based on action effects makes role\ndiscovery much easier because it forms a bi-level learning hierarchy -- the\nrole selector searches in a smaller role space and at a lower temporal\nresolution, while role policies learn in significantly reduced primitive\naction-observation spaces. We further integrate information about action\neffects into the role policies to boost learning efficiency and policy\ngeneralization. By virtue of these advances, our method (1) outperforms the\ncurrent state-of-the-art MARL algorithms on 10 of the 14 scenarios that\ncomprise the challenging StarCraft II micromanagement benchmark and (2)\nachieves rapid transfer to new environments with three times the number of\nagents. Demonstrative videos are available at\nhttps://sites.google.com/view/rode-marl .\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 09:20:59 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Tonghan", ""], ["Gupta", "Tarun", ""], ["Mahajan", "Anuj", ""], ["Peng", "Bei", ""], ["Whiteson", "Shimon", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2010.01546", "submitter": "Amit Bleiweiss", "authors": "Shmulik Markovich-Golan, Barak Battash, Amit Bleiweiss", "title": "Feature Whitening via Gradient Transformation for Improved Convergence", "comments": "NeurIPS 2020 Workshop Beyond Backpropagation - Novel Ideas for\n  Training Neural Architectures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature whitening is a known technique for speeding up training of DNN. Under\ncertain assumptions, whitening the activations reduces the Fisher information\nmatrix to a simple identity matrix, in which case stochastic gradient descent\nis equivalent to the faster natural gradient descent. Due to the additional\ncomplexity resulting from transforming the layer inputs and their corresponding\ngradients in the forward and backward propagation, and from repeatedly\ncomputing the Eigenvalue decomposition (EVD), this method is not commonly used\nto date. In this work, we address the complexity drawbacks of feature\nwhitening. Our contribution is twofold. First, we derive an equivalent method,\nwhich replaces the sample transformations by a transformation to the weight\ngradients, applied to every batch of B samples. The complexity is reduced by a\nfactor of S=(2B), where S denotes the feature dimension of the layer output. As\nthe batch size increases with distributed training, the benefit of using the\nproposed method becomes more compelling. Second, motivated by the theoretical\nrelation between the condition number of the sample covariance matrix and the\nconvergence speed, we derive an alternative sub-optimal algorithm which\nrecursively reduces the condition number of the latter matrix. Compared to EVD,\ncomplexity is reduced by a factor of the input feature dimension M. We\nexemplify the proposed algorithms with ResNet-based networks for image\nclassification demonstrated on the CIFAR and Imagenet datasets. Parallelizing\nthe proposed algorithms is straightforward and we implement a distributed\nversion thereof. Improved convergence, in terms of speed and attained accuracy,\ncan be observed in our experiments.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 11:30:20 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 08:35:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Markovich-Golan", "Shmulik", ""], ["Battash", "Barak", ""], ["Bleiweiss", "Amit", ""]]}, {"id": "2010.01550", "submitter": "Ali Caner T\\\"urkmen", "authors": "Ali Caner Turkmen, Tim Januschowski, Yuyang Wang and Ali Taylan Cemgil", "title": "Intermittent Demand Forecasting with Renewal Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intermittency is a common and challenging problem in demand forecasting. We\nintroduce a new, unified framework for building intermittent demand forecasting\nmodels, which incorporates and allows to generalize existing methods in several\ndirections. Our framework is based on extensions of well-established\nmodel-based methods to discrete-time renewal processes, which can\nparsimoniously account for patterns such as aging, clustering and\nquasi-periodicity in demand arrivals. The connection to discrete-time renewal\nprocesses allows not only for a principled extension of Croston-type models,\nbut also for an natural inclusion of neural network based models---by replacing\nexponential smoothing with a recurrent neural network. We also demonstrate that\nmodeling continuous-time demand arrivals, i.e., with a temporal point process,\nis possible via a trivial extension of our framework. This leads to more\nflexible modeling in scenarios where data of individual purchase orders are\ndirectly available with granular timestamps. Complementing this theoretical\nadvancement, we demonstrate the efficacy of our framework for forecasting\npractice via an extensive empirical study on standard intermittent demand data\nsets, in which we report predictive accuracy in a variety of scenarios that\ncompares favorably to the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 11:32:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Turkmen", "Ali Caner", ""], ["Januschowski", "Tim", ""], ["Wang", "Yuyang", ""], ["Cemgil", "Ali Taylan", ""]]}, {"id": "2010.01590", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison, Adam X. Yang, Sebastian W. Ober", "title": "Deep kernel processes", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define deep kernel processes in which positive definite Gram matrices are\nprogressively transformed by nonlinear kernel functions and by sampling from\n(inverse) Wishart distributions. Remarkably, we find that deep Gaussian\nprocesses (DGPs), Bayesian neural networks (BNNs), infinite BNNs, and infinite\nBNNs with bottlenecks can all be written as deep kernel processes. For DGPs the\nequivalence arises because the Gram matrix formed by the inner product of\nfeatures is Wishart distributed, and as we show, standard isotropic kernels can\nbe written entirely in terms of this Gram matrix -- we do not need knowledge of\nthe underlying features. We define a tractable deep kernel process, the deep\ninverse Wishart process, and give a doubly-stochastic inducing-point\nvariational inference scheme that operates on the Gram matrices, not on the\nfeatures, as in DGPs. We show that the deep inverse Wishart process gives\nsuperior performance to DGPs and infinite BNNs on standard fully-connected\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 14:31:18 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 12:23:26 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Aitchison", "Laurence", ""], ["Yang", "Adam X.", ""], ["Ober", "Sebastian W.", ""]]}, {"id": "2010.01596", "submitter": "Yang Jiao", "authors": "Yang Jiao, Kai Yang, Shaoyu Dou, Pan Luo, Sijia Liu, Dongjin Song", "title": "TimeAutoML: Autonomous Representation Learning for Multivariate\n  Irregularly Sampled Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) data are becoming increasingly ubiquitous in\ndiverse domains, e.g., IoT systems, health informatics, and 5G networks. To\nobtain an effective representation of MTS data, it is not only essential to\nconsider unpredictable dynamics and highly variable lengths of these data but\nalso important to address the irregularities in the sampling rates of MTS.\nExisting parametric approaches rely on manual hyperparameter tuning and may\ncost a huge amount of labor effort. Therefore, it is desirable to learn the\nrepresentation automatically and efficiently. To this end, we propose an\nautonomous representation learning approach for multivariate time series\n(TimeAutoML) with irregular sampling rates and variable lengths. As opposed to\nprevious works, we first present a representation learning pipeline in which\nthe configuration and hyperparameter optimization are fully automatic and can\nbe tailored for various tasks, e.g., anomaly detection, clustering, etc. Next,\na negative sample generation approach and an auxiliary classification task are\ndeveloped and integrated within TimeAutoML to enhance its representation\ncapability. Extensive empirical studies on real-world datasets demonstrate that\nthe proposed TimeAutoML outperforms competing approaches on various tasks by a\nlarge margin. In fact, it achieves the best anomaly detection performance among\nall comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20%\nperformance improvement in terms of AUC score.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 15:01:46 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Jiao", "Yang", ""], ["Yang", "Kai", ""], ["Dou", "Shaoyu", ""], ["Luo", "Pan", ""], ["Liu", "Sijia", ""], ["Song", "Dongjin", ""]]}, {"id": "2010.01604", "submitter": "Qinghua Liu", "authors": "Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin", "title": "A Sharp Analysis of Model-based Reinforcement Learning with Self-Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based algorithms -- algorithms that explore the environment through\nbuilding and utilizing an estimated model -- are widely used in reinforcement\nlearning practice and theoretically shown to achieve optimal sample efficiency\nfor single-agent reinforcement learning in Markov Decision Processes (MDPs).\nHowever, for multi-agent reinforcement learning in Markov games, the current\nbest known sample complexity for model-based algorithms is rather suboptimal\nand compares unfavorably against recent model-free approaches. In this paper,\nwe present a sharp analysis of model-based self-play algorithms for multi-agent\nMarkov games. We design an algorithm -- Optimistic Nash Value Iteration\n(Nash-VI) for two-player zero-sum Markov games that is able to output an\n$\\epsilon$-approximate Nash policy in $\\tilde{\\mathcal{O}}(H^3SAB/\\epsilon^2)$\nepisodes of game playing, where $S$ is the number of states, $A,B$ are the\nnumber of actions for the two players respectively, and $H$ is the horizon\nlength. This significantly improves over the best known model-based guarantee\nof $\\tilde{\\mathcal{O}}(H^4S^2AB/\\epsilon^2)$, and is the first that matches\nthe information-theoretic lower bound $\\Omega(H^3S(A+B)/\\epsilon^2)$ except for\na $\\min\\{A,B\\}$ factor. In addition, our guarantee compares favorably against\nthe best known model-free algorithm if $\\min \\{A,B\\}=o(H^3)$, and outputs a\nsingle Markov policy while existing sample-efficient model-free algorithms\noutput a nested mixture of Markov policies that is in general non-Markov and\nrather inconvenient to store and execute. We further adapt our analysis to\ndesigning a provably efficient task-agnostic algorithm for zero-sum Markov\ngames, and designing the first line of provably sample-efficient algorithms for\nmulti-player general-sum Markov games.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 15:27:39 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 03:38:01 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liu", "Qinghua", ""], ["Yu", "Tiancheng", ""], ["Bai", "Yu", ""], ["Jin", "Chi", ""]]}, {"id": "2010.01618", "submitter": "Jun-Kun Wang", "authors": "Jun-Kun Wang and Chi-Heng Lin and Jacob Abernethy", "title": "A Modular Analysis of Provable Acceleration via Polyak's Momentum:\n  Training a Wide ReLU Network and a Deep Linear Network", "comments": "Accepted at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating a so-called \"momentum\" dynamic in gradient descent methods is\nwidely used in neural net training as it has been broadly observed that, at\nleast empirically, it often leads to significantly faster convergence. At the\nsame time, there are very few theoretical guarantees in the literature to\nexplain this apparent acceleration effect. Even for the classical strongly\nconvex quadratic problems, several existing results only show Polyak's momentum\nhas an accelerated linear rate asymptotically. In this paper, we first revisit\nthe quadratic problems and show a non-asymptotic accelerated linear rate of\nPolyak's momentum. Then, we provably show that Polyak's momentum achieves\nacceleration for training a one-layer wide ReLU network and a deep linear\nnetwork, which are perhaps the two most popular canonical models for studying\noptimization and deep learning in the literature. Prior work Du at al. 2019 and\nWu et al. 2019 showed that using vanilla gradient descent, and with an use of\nover-parameterization, the error decays as $(1- \\Theta(\\frac{1}{ \\kappa'}))^t$\nafter $t$ iterations, where $\\kappa'$ is the condition number of a Gram Matrix.\nOur result shows that with the appropriate choice of parameters Polyak's\nmomentum has a rate of $(1-\\Theta(\\frac{1}{\\sqrt{\\kappa'}}))^t$. For the deep\nlinear network, prior work Hu et al. 2020 showed that vanilla gradient descent\nhas a rate of $(1-\\Theta(\\frac{1}{\\kappa}))^t$, where $\\kappa$ is the condition\nnumber of a data matrix. Our result shows an acceleration rate $(1-\n\\Theta(\\frac{1}{\\sqrt{\\kappa}}))^t$ is achievable by Polyak's momentum. All the\nresults in this work are obtained from a modular analysis, which can be of\nindependent interest. This work establishes that momentum does indeed speed up\nneural net training.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 16:16:22 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 19:52:12 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 19:04:36 GMT"}, {"version": "v4", "created": "Sun, 4 Apr 2021 17:35:36 GMT"}, {"version": "v5", "created": "Mon, 7 Jun 2021 14:43:44 GMT"}, {"version": "v6", "created": "Thu, 10 Jun 2021 22:08:06 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wang", "Jun-Kun", ""], ["Lin", "Chi-Heng", ""], ["Abernethy", "Jacob", ""]]}, {"id": "2010.01632", "submitter": "Li Wang", "authors": "Li Wang, Leihong Zhang, Chungen Shen and Ren-cang Li", "title": "Orthogonal Multi-view Analysis by Successive Approximations via\n  Eigenvectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework for multi-view subspace learning to learn\nindividual orthogonal projections for all views. The framework integrates the\ncorrelations within multiple views, supervised discriminant capacity, and\ndistance preservation in a concise and compact way. It not only includes\nseveral existing models as special cases, but also inspires new novel models.\nTo demonstrate its versatility to handle different learning scenarios, we\nshowcase three new multi-view discriminant analysis models and two new\nmulti-view multi-label classification ones under this framework. An efficient\nnumerical method based on successive approximations via eigenvectors is\npresented to solve the associated optimization problem. The method is built\nupon an iterative Krylov subspace method which can easily scale up for\nhigh-dimensional datasets. Extensive experiments are conducted on various\nreal-world datasets for multi-view discriminant analysis and multi-view\nmulti-label classification. The experimental results demonstrate that the\nproposed models are consistently competitive to and often better than the\ncompared methods that do not learn orthogonal projections.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 17:16:15 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Li", ""], ["Zhang", "Leihong", ""], ["Shen", "Chungen", ""], ["Li", "Ren-cang", ""]]}, {"id": "2010.01637", "submitter": "Jun-Kun Wang", "authors": "Jun-Kun Wang and Jacob Abernethy", "title": "Understanding How Over-Parametrization Leads to Acceleration: A case of\n  learning a single teacher neuron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parametrization has become a popular technique in deep learning. It is\nobserved that by over-parametrization, a larger neural network needs a fewer\ntraining iterations than a smaller one to achieve a certain level of\nperformance -- namely, over-parametrization leads to acceleration in\noptimization. However, despite that over-parametrization is widely used\nnowadays, little theory is available to explain the acceleration due to\nover-parametrization. In this paper, we propose understanding it by studying a\nsimple problem first. Specifically, we consider the setting that there is a\nsingle teacher neuron with quadratic activation, where over-parametrization is\nrealized by having multiple student neurons learn the data generated from the\nteacher neuron. We provably show that over-parametrization helps the iterate\ngenerated by gradient descent to enter the neighborhood of a global optimal\nsolution that achieves zero testing error faster. On the other hand, we also\npoint out an issue regarding the necessity of over-parametrization and study\nhow the scaling of the output neurons affects the convergence time.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 17:27:44 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 18:41:22 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Wang", "Jun-Kun", ""], ["Abernethy", "Jacob", ""]]}, {"id": "2010.01652", "submitter": "Honghao Wei", "authors": "Honghao Wei and Lei Ying", "title": "FORK: A Forward-Looking Actor For Model-Free Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new type of Actor, named forward-looking Actor or\nFORK for short, for Actor-Critic algorithms. FORK can be easily integrated into\na model-free Actor-Critic algorithm. Our experiments on six Box2D and MuJoCo\nenvironments with continuous state and action spaces demonstrate significant\nperformance improvement FORK can bring to the state-of-the-art algorithms. A\nvariation of FORK can further solve Bipedal-WalkerHardcore in as few as four\nhours using a single GPU.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 18:51:55 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 06:33:06 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Wei", "Honghao", ""], ["Ying", "Lei", ""]]}, {"id": "2010.01654", "submitter": "Ning Ning", "authors": "Ning Ning", "title": "Multivariate Quantile Bayesian Structural Time Series (MQBSTS) Model", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the multivariate quantile Bayesian structural time\nseries (MQBSTS) model for the joint quantile time series forecast, which is the\nfirst such model for correlated multivariate time series to the author's best\nknowledge. The MQBSTS model also enables quantile based feature selection in\nits regression component where each time series has its own pool of\ncontemporaneous external time series predictors, which is the first time that a\nfully data-driven quantile feature selection technique applicable to time\nseries data to the author's best knowledge. Different from most machine\nlearning algorithms, the MQBSTS model has very few hyper-parameters to tune,\nrequires small datasets to train, converges fast, and is executable on ordinary\npersonal computers. Extensive examinations on simulated data and empirical data\nconfirmed that the MQBSTS model has superior performance in feature selection,\nparameter estimation, and forecast.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 18:56:34 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ning", "Ning", ""]]}, {"id": "2010.01659", "submitter": "Kleanthis Malialis", "authors": "Kleanthis Malialis and Christos G. Panayiotou and Marios M. Polycarpou", "title": "Data-efficient Online Classification with Siamese Networks and Active\n  Learning", "comments": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, UK, 2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206730", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  An ever increasing volume of data is nowadays becoming available in a\nstreaming manner in many application areas, such as, in critical infrastructure\nsystems, finance and banking, security and crime and web analytics. To meet\nthis new demand, predictive models need to be built online where learning\noccurs on-the-fly. Online learning poses important challenges that affect the\ndeployment of online classification systems to real-life problems. In this\npaper we investigate learning from limited labelled, nonstationary and\nimbalanced data in online classification. We propose a learning method that\nsynergistically combines siamese neural networks and active learning. The\nproposed method uses a multi-sliding window approach to store data, and\nmaintains separate and balanced queues for each class. Our study shows that the\nproposed method is robust to data nonstationarity and imbalance, and\nsignificantly outperforms baselines and state-of-the-art algorithms in terms of\nboth learning speed and performance. Importantly, it is effective even when\nonly 1% of the labels of the arriving instances are available.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 19:07:19 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Malialis", "Kleanthis", ""], ["Panayiotou", "Christos G.", ""], ["Polycarpou", "Marios M.", ""]]}, {"id": "2010.01705", "submitter": "Vasilis Kontonis", "authors": "Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis, Christos Tzamos,\n  Nikos Zarifis", "title": "A Polynomial Time Algorithm for Learning Halfspaces with Tsybakov Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of PAC learning homogeneous halfspaces in the presence\nof Tsybakov noise. In the Tsybakov noise model, the label of every sample is\nindependently flipped with an adversarially controlled probability that can be\narbitrarily close to $1/2$ for a fraction of the samples. {\\em We give the\nfirst polynomial-time algorithm for this fundamental learning problem.} Our\nalgorithm learns the true halfspace within any desired accuracy $\\epsilon$ and\nsucceeds under a broad family of well-behaved distributions including\nlog-concave distributions. Prior to our work, the only previous algorithm for\nthis problem required quasi-polynomial runtime in $1/\\epsilon$.\n  Our algorithm employs a recently developed reduction \\cite{DKTZ20b} from\nlearning to certifying the non-optimality of a candidate halfspace. This prior\nwork developed a quasi-polynomial time certificate algorithm based on\npolynomial regression. {\\em The main technical contribution of the current\npaper is the first polynomial-time certificate algorithm.} Starting from a\nnon-trivial warm-start, our algorithm performs a novel \"win-win\" iterative\nprocess which, at each step, either finds a valid certificate or improves the\nangle between the current halfspace and the true one. Our warm-start algorithm\nfor isotropic log-concave distributions involves a number of analytic tools\nthat may be of broader interest. These include a new efficient method for\nreweighting the distribution in order to recenter it and a novel\ncharacterization of the spectrum of the degree-$2$ Chow parameters.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:19:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Kontonis", "Vasilis", ""], ["Tzamos", "Christos", ""], ["Zarifis", "Nikos", ""]]}, {"id": "2010.01707", "submitter": "Jiayu Li", "authors": "Bo Peng, Jiayu Li, Selahattin Akkas, Fugang Wang, Takuya Araki, Ohno\n  Yoshiyuki, Judy Qiu", "title": "Rank Position Forecasting in Car Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting is challenging since uncertainty resulted from exogenous factors\nexists. This work investigates the rank position forecasting problem in car\nracing, which predicts the rank positions at the future laps for cars. Among\nthe many factors that bring changes to the rank positions, pit stops are\ncritical but irregular and rare. We found existing methods, including\nstatistical models, machine learning regression models, and state-of-the-art\ndeep forecasting model based on encoder-decoder architecture, all have\nlimitations in the forecasting. By elaborative analysis of pit stops events, we\npropose a deep model, RankNet, with the cause effects decomposition that\nmodeling the rank position sequence and pit stop events separately. It also\nincorporates probabilistic forecasting to model the uncertainty inside each\nsub-model. Through extensive experiments, RankNet demonstrates a strong\nperformance improvement over the baselines, e.g., MAE improves more than 10%\nconsistently, and is also more stable when adapting to unseen new data. Details\nof model optimization, performance profiling are presented. It is promising to\nprovide useful forecasting tools for the car racing analysis and shine a light\non solutions to similar challenging issues in general forecasting problems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:27:41 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 22:21:04 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Peng", "Bo", ""], ["Li", "Jiayu", ""], ["Akkas", "Selahattin", ""], ["Wang", "Fugang", ""], ["Araki", "Takuya", ""], ["Yoshiyuki", "Ohno", ""], ["Qiu", "Judy", ""]]}, {"id": "2010.01711", "submitter": "Shiva Navabi", "authors": "Shiva Navabi, Osonde A. Osoba", "title": "A Generative Machine Learning Approach to Policy Optimization in\n  Pursuit-Evasion Games", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a pursuit-evasion game [11] played between two agents, 'Blue'\n(the pursuer) and 'Red' (the evader), over $T$ time steps. Red aims to attack\nBlue's territory. Blue's objective is to intercept Red by time $T$ and thereby\nlimit the success of Red's attack. Blue must plan its pursuit trajectory by\nchoosing parameters that determine its course of movement (speed and angle in\nour setup) such that it intercepts Red by time $T$. We show that Blue's\npath-planning problem in pursuing Red, can be posed as a sequential decision\nmaking problem under uncertainty. Blue's unawareness of Red's action policy\nrenders the analytic dynamic programming approach intractable for finding the\noptimal action policy for Blue. In this work, we are interested in exploring\ndata-driven approaches to the policy optimization problem that Blue faces. We\napply generative machine learning (ML) approaches to learn optimal action\npolicies for Blue. This highlights the ability of generative ML model to learn\nthe relevant implicit representations for the dynamics of simulated\npursuit-evasion games. We demonstrate the effectiveness of our modeling\napproach via extensive statistical assessments. This work can be viewed as a\npreliminary step towards further adoption of generative modeling approaches for\naddressing policy optimization problems that arise in the context of\nmulti-agent learning and planning [1].\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:43:44 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 19:26:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Navabi", "Shiva", ""], ["Osoba", "Osonde A.", ""]]}, {"id": "2010.01732", "submitter": "Ian Manchester", "authors": "Max Revay, Ruigang Wang, Ian R. Manchester", "title": "Lipschitz Bounded Equilibrium Networks", "comments": "Conference submission, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces new parameterizations of equilibrium neural networks,\ni.e. networks defined by implicit equations. This model class includes standard\nmultilayer and residual networks as special cases. The new parameterization\nadmits a Lipschitz bound during training via unconstrained optimization: no\nprojections or barrier functions are required. Lipschitz bounds are a common\nproxy for robustness and appear in many generalization bounds. Furthermore,\ncompared to previous works we show well-posedness (existence of solutions)\nunder less restrictive conditions on the network weights and more natural\nassumptions on the activation functions: that they are monotone and slope\nrestricted. These results are proved by establishing novel connections with\nconvex optimization, operator splitting on non-Euclidean spaces, and\ncontracting neural ODEs. In image classification experiments we show that the\nLipschitz bounds are very accurate and improve robustness to adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 01:00:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Revay", "Max", ""], ["Wang", "Ruigang", ""], ["Manchester", "Ian R.", ""]]}, {"id": "2010.01741", "submitter": "Shu Hu", "authors": "Shu Hu, Yiming Ying, Xin Wang, Siwei Lyu", "title": "Learning by Minimizing the Sum of Ranked Range", "comments": "Accepted by Thirty-fourth Conference on Neural Information Processing\n  Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In forming learning objectives, one oftentimes needs to aggregate a set of\nindividual values to a single output. Such cases occur in the aggregate loss,\nwhich combines individual losses of a learning model over each training sample,\nand in the individual loss for multi-label learning, which combines prediction\nscores over all class labels. In this work, we introduce the sum of ranked\nrange (SoRR) as a general approach to form learning objectives. A ranked range\nis a consecutive sequence of sorted values of a set of real numbers. The\nminimization of SoRR is solved with the difference of convex algorithm (DCA).\nWe explore two applications in machine learning of the minimization of the SoRR\nframework, namely the AoRR aggregate loss for binary classification and the\nTKML individual loss for multi-label/multi-class classification. Our empirical\nresults highlight the effectiveness of the proposed optimization framework and\ndemonstrate the applicability of proposed losses using synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 01:58:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hu", "Shu", ""], ["Ying", "Yiming", ""], ["Wang", "Xin", ""], ["Lyu", "Siwei", ""]]}, {"id": "2010.01748", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Hongyi Guo, Zhaowei Zhu, Yang Liu", "title": "Policy Learning Using Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing policy learning solutions require the learning agents to\nreceive high-quality supervision signals, e.g., rewards in reinforcement\nlearning (RL) or high-quality expert's demonstrations in behavioral cloning\n(BC). These quality supervisions are either infeasible or prohibitively\nexpensive to obtain in practice. We aim for a unified framework that leverages\nthe weak supervisions to perform policy learning efficiently. To handle this\nproblem, we treat the \"weak supervisions\" as imperfect information coming from\na peer agent, and evaluate the learning agent's policy based on a \"correlated\nagreement\" with the peer agent's policy (instead of simple agreements). Our way\nof leveraging peer agent's information offers us a family of solutions that\nlearn effectively from weak supervisions with theoretical guarantees. Extensive\nevaluations on tasks including RL with noisy reward, BC with weak\ndemonstrations and standard policy co-training (RL + BC) show that the proposed\napproach leads to substantial improvements, especially when the complexity or\nthe noise of the learning environments grows.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 02:26:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 20:42:38 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Wang", "Jingkang", ""], ["Guo", "Hongyi", ""], ["Zhu", "Zhaowei", ""], ["Liu", "Yang", ""]]}, {"id": "2010.01761", "submitter": "Yufan Zhou", "authors": "Yufan Zhou, Changyou Chen, Jinhui Xu", "title": "Learning Manifold Implicitly via Explicit Heat-Kernel Learning", "comments": "Accepted by NeurIPS 2020. Some typos have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning is a fundamental problem in machine learning with numerous\napplications. Most of the existing methods directly learn the low-dimensional\nembedding of the data in some high-dimensional space, and usually lack the\nflexibility of being directly applicable to down-stream applications. In this\npaper, we propose the concept of implicit manifold learning, where manifold\ninformation is implicitly obtained by learning the associated heat kernel. A\nheat kernel is the solution of the corresponding heat equation, which describes\nhow \"heat\" transfers on the manifold, thus containing ample geometric\ninformation of the manifold. We provide both practical algorithm and\ntheoretical analysis of our framework. The learned heat kernel can be applied\nto various kernel-based machine learning models, including deep generative\nmodels (DGM) for data generation and Stein Variational Gradient Descent for\nBayesian inference. Extensive experiments show that our framework can achieve\nstate-of-the-art results compared to existing methods for the two tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:39:58 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 00:36:25 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 00:12:39 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhou", "Yufan", ""], ["Chen", "Changyou", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.01762", "submitter": "Zejiang Shen", "authors": "Zejiang Shen, Jian Zhao, Melissa Dell, Yaoliang Yu, Weining Li", "title": "OLALA: Object-Level Active Learning for Efficient Document Layout\n  Annotation", "comments": "12 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document images often have intricate layout structures, with numerous content\nregions (e.g. texts, figures, tables) densely arranged on each page. This makes\nthe manual annotation of layout datasets expensive and inefficient. These\ncharacteristics also challenge existing active learning methods, as image-level\nscoring and selection suffer from the overexposure of common objects.Inspired\nby recent progresses in semi-supervised learning and self-training, we propose\nan Object-Level Active Learning framework for efficient document layout\nAnnotation, OLALA. In this framework, only regions with the most ambiguous\nobject predictions within an image are selected for annotators to label,\noptimizing the use of the annotation budget. For unselected predictions, the\nsemi-automatic correction algorithm is proposed to identify certain errors\nbased on prior knowledge of layout structures and rectifies them with minor\nsupervision. Additionally, we carefully design a perturbation-based object\nscoring function for document images. It governs the object selection process\nvia evaluating prediction ambiguities, and considers both the positions and\ncategories of predicted layout objects. Extensive experiments show that OLALA\ncan significantly boost model performance and improve annotation efficiency,\ngiven the same labeling budget. Code for this paper can be accessed via\nhttps://github.com/lolipopshock/detectron2_al.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:48:07 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 04:41:03 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 19:32:25 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Shen", "Zejiang", ""], ["Zhao", "Jian", ""], ["Dell", "Melissa", ""], ["Yu", "Yaoliang", ""], ["Li", "Weining", ""]]}, {"id": "2010.01764", "submitter": "Yu Wang", "authors": "Shayne Longpre and Yu Wang and Christopher DuBois", "title": "How Effective is Task-Agnostic Data Augmentation for Pretrained\n  Transformers?", "comments": "2 tables; 1 figure; EMNLP Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-agnostic forms of data augmentation have proven widely effective in\ncomputer vision, even on pretrained models. In NLP similar results are reported\nmost commonly for low data regimes, non-pretrained models, or situationally for\npretrained models. In this paper we ask how effective these techniques really\nare when applied to pretrained transformers. Using two popular varieties of\ntask-agnostic data augmentation (not tailored to any particular task), Easy\nData Augmentation (Wei and Zou, 2019) and Back-Translation (Sennrichet al.,\n2015), we conduct a systematic examination of their effects across 5\nclassification tasks, 6 datasets, and 3 variants of modern pretrained\ntransformers, including BERT, XLNet, and RoBERTa. We observe a negative result,\nfinding that techniques which previously reported strong improvements for\nnon-pretrained models fail to consistently improve performance for pretrained\ntransformers, even when training data is limited. We hope this empirical\nanalysis helps inform practitioners where data augmentation techniques may\nconfer improvements.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:55:15 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Longpre", "Shayne", ""], ["Wang", "Yu", ""], ["DuBois", "Christopher", ""]]}, {"id": "2010.01766", "submitter": "Ruizhi Liao", "authors": "Ruizhi Liao, Daniel Moyer, Polina Golland, William M. Wells", "title": "DEMI: Discriminative Estimator of Mutual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating mutual information between continuous random variables is often\nintractable and extremely challenging for high-dimensional data. Recent\nprogress has leveraged neural networks to optimize variational lower bounds on\nmutual information. Although showing promise for this difficult problem, the\nvariational methods have been theoretically and empirically proven to have\nserious statistical limitations: 1) many methods struggle to produce accurate\nestimates when the underlying mutual information is either low or high; 2) the\nresulting estimators may suffer from high variance. Our approach is based on\ntraining a classifier that provides the probability that a data sample pair is\ndrawn from the joint distribution rather than from the product of its marginal\ndistributions. Moreover, we establish a direct connection between mutual\ninformation and the average log odds estimate produced by the classifier on a\ntest set, leading to a simple and accurate estimator of mutual information. We\nshow theoretically that our method and other variational approaches are\nequivalent when they achieve their optimum, while our method sidesteps the\nvariational bound. Empirical results demonstrate high accuracy of our approach\nand the advantages of our estimator in the context of representation learning.\nOur demo is available at https://github.com/RayRuizhiLiao/demi_mi_estimator.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 04:19:27 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 02:59:02 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Liao", "Ruizhi", ""], ["Moyer", "Daniel", ""], ["Golland", "Polina", ""], ["Wells", "William M.", ""]]}, {"id": "2010.01777", "submitter": "Yao Ma", "authors": "Yao Ma, Xiaorui Liu, Tong Zhao, Yozen Liu, Jiliang Tang, Neil Shah", "title": "A Unified View on Graph Neural Networks as Graph Signal Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have risen to prominence in learning\nrepresentations for graph structured data. A single GNN layer typically\nconsists of a feature transformation and a feature aggregation operation. The\nformer normally uses feed-forward networks to transform features, while the\nlatter aggregates the transformed features over the graph. Numerous recent\nworks have proposed GNN models with different designs in the aggregation\noperation. In this work, we establish mathematically that the aggregation\nprocesses in a group of representative GNN models including GCN, GAT, PPNP, and\nAPPNP can be regarded as (approximately) solving a graph denoising problem with\na smoothness assumption. Such a unified view across GNNs not only provides a\nnew perspective to understand a variety of aggregation operations but also\nenables us to develop a unified graph neural network framework UGNN. To\ndemonstrate its promising potential, we instantiate a novel GNN model,\nADA-UGNN, derived from UGNN, to handle graphs with adaptive smoothness across\nnodes. Comprehensive experiments show the effectiveness of ADA-UGNN.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 04:57:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ma", "Yao", ""], ["Liu", "Xiaorui", ""], ["Zhao", "Tong", ""], ["Liu", "Yozen", ""], ["Tang", "Jiliang", ""], ["Shah", "Neil", ""]]}, {"id": "2010.01787", "submitter": "Khai Nguyen", "authors": "Khai Nguyen and Son Nguyen and Nhat Ho and Tung Pham and Hung Bui", "title": "Improving Relational Regularized Autoencoders with Spherical Sliced\n  Fused Gromov Wasserstein", "comments": "39 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational regularized autoencoder (RAE) is a framework to learn the\ndistribution of data by minimizing a reconstruction loss together with a\nrelational regularization on the latent space. A recent attempt to reduce the\ninner discrepancy between the prior and aggregated posterior distributions is\nto incorporate sliced fused Gromov-Wasserstein (SFG) between these\ndistributions. That approach has a weakness since it treats every slicing\ndirection similarly, meanwhile several directions are not useful for the\ndiscriminative task. To improve the discrepancy and consequently the relational\nregularization, we propose a new relational discrepancy, named spherical sliced\nfused Gromov Wasserstein (SSFG), that can find an important area of projections\ncharacterized by a von Mises-Fisher distribution. Then, we introduce two\nvariants of SSFG to improve its performance. The first variant, named mixture\nspherical sliced fused Gromov Wasserstein (MSSFG), replaces the vMF\ndistribution by a mixture of von Mises-Fisher distributions to capture multiple\nimportant areas of directions that are far from each other. The second variant,\nnamed power spherical sliced fused Gromov Wasserstein (PSSFG), replaces the vMF\ndistribution by a power spherical distribution to improve the sampling time in\nhigh dimension settings. We then apply the new discrepancies to the RAE\nframework to achieve its new variants. Finally, we conduct extensive\nexperiments to show that the new proposed autoencoders have favorable\nperformance in learning latent manifold structure, image generation, and\nreconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 05:26:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Khai", ""], ["Nguyen", "Son", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""]]}, {"id": "2010.01792", "submitter": "Sheikh Shams Azam", "authors": "Sheikh Shams Azam, Taejin Kim, Seyyedali Hosseinalipour, Christopher\n  Brinton, Carlee Joe-Wong, Saurabh Bagchi", "title": "Towards Generalized and Distributed Privacy-Preserving Representation\n  Learning", "comments": "18 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving representation learning (PPRL) aims to learn a data\nencoding that obfuscates sensitive information and retains target information.\nWe develop the Exclusion-Inclusion Generative Adversarial Network (EIGAN),\nwhich generalizes existing adversarial PPRL approaches to account for multiple,\npotentially overlapping ally and adversary objectives in a dataset. We further\nextend EIGAN to the case where the data is distributed and cannot be centrally\naggregated for training due to privacy constraints. In doing so, we introduce\nD-EIGAN, the first distributed PPRL method, which decentralizes EIGAN training\nbased on federated learning with fractional parameter sharing. We theoretically\nanalyze the convergence of EIGAN and behavior of adversaries under the optimal\nEIGAN and D-EIGAN encoders, considering the impact of dependencies among target\nand sensitive objectives on the encoder performance. Our experiments\ndemonstrate the advantages of EIGAN encodings in terms of accuracy, robustness,\nand scalability; EIGAN outperforms the previous state-of-the-art in centralized\nPPRL by a significant margin (47%). The experiments further reveal that\nD-EIGAN's performance is consistent with that of EIGAN under different node\ndata distributions and is resilient to communication constraints.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 05:43:47 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 22:30:21 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 01:59:04 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Azam", "Sheikh Shams", ""], ["Kim", "Taejin", ""], ["Hosseinalipour", "Seyyedali", ""], ["Brinton", "Christopher", ""], ["Joe-Wong", "Carlee", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2010.01795", "submitter": "Isha Garg", "authors": "Isha Garg, Sayeed Shafayet Chowdhury and Kaushik Roy", "title": "DCT-SNN: Using DCT to Distribute Spatial Information over Time for\n  Learning Low-Latency Spiking Neural Networks", "comments": "The first two authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) offer a promising alternative to traditional\ndeep learning frameworks, since they provide higher computational efficiency\ndue to event-driven information processing. SNNs distribute the analog values\nof pixel intensities into binary spikes over time. However, the most widely\nused input coding schemes, such as Poisson based rate-coding, do not leverage\nthe additional temporal learning capability of SNNs effectively. Moreover,\nthese SNNs suffer from high inference latency which is a major bottleneck to\ntheir deployment. To overcome this, we propose a scalable time-based encoding\nscheme that utilizes the Discrete Cosine Transform (DCT) to reduce the number\nof timesteps required for inference. DCT decomposes an image into a weighted\nsum of sinusoidal basis images. At each time step, the Hadamard product of the\nDCT coefficients and a single frequency base, taken in order, is given to an\naccumulator that generates spikes upon crossing a threshold. We use the\nproposed scheme to learn DCT-SNN, a low-latency deep SNN with\nleaky-integrate-and-fire neurons, trained using surrogate gradient descent\nbased backpropagation. We achieve top-1 accuracy of 89.94%, 68.3% and 52.43% on\nCIFAR-10, CIFAR-100 and TinyImageNet, respectively using VGG architectures.\nNotably, DCT-SNN performs inference with 2-14X reduced latency compared to\nother state-of-the-art SNNs, while achieving comparable accuracy to their\nstandard deep learning counterparts. The dimension of the transform allows us\nto control the number of timesteps required for inference. Additionally, we can\ntrade-off accuracy with latency in a principled manner by dropping the highest\nfrequency components during inference.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 05:55:34 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Garg", "Isha", ""], ["Chowdhury", "Sayeed Shafayet", ""], ["Roy", "Kaushik", ""]]}, {"id": "2010.01799", "submitter": "Hoki Kim", "authors": "Hoki Kim, Woojin Lee, Jaewook Lee", "title": "Understanding Catastrophic Overfitting in Single-step Adversarial\n  Training", "comments": "Accepted to AAAI 2021. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although fast adversarial training has demonstrated both robustness and\nefficiency, the problem of \"catastrophic overfitting\" has been observed. This\nis a phenomenon in which, during single-step adversarial training, the robust\naccuracy against projected gradient descent (PGD) suddenly decreases to 0%\nafter a few epochs, whereas the robust accuracy against fast gradient sign\nmethod (FGSM) increases to 100%. In this paper, we demonstrate that\ncatastrophic overfitting is very closely related to the characteristic of\nsingle-step adversarial training which uses only adversarial examples with the\nmaximum perturbation, and not all adversarial examples in the adversarial\ndirection, which leads to decision boundary distortion and a highly curved loss\nsurface. Based on this observation, we propose a simple method that not only\nprevents catastrophic overfitting, but also overrides the belief that it is\ndifficult to prevent multi-step adversarial attacks with single-step\nadversarial training.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 06:13:35 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 08:41:08 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kim", "Hoki", ""], ["Lee", "Woojin", ""], ["Lee", "Jaewook", ""]]}, {"id": "2010.01804", "submitter": "Maosen Li", "authors": "Maosen Li, Siheng Chen, Ya Zhang, Ivor W. Tsang", "title": "Graph Cross Networks with Vertex Infomax Pooling", "comments": null, "journal-ref": "Neurips 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel graph cross network (GXN) to achieve comprehensive feature\nlearning from multiple scales of a graph. Based on trainable hierarchical\nrepresentations of a graph, GXN enables the interchange of intermediate\nfeatures across scales to promote information flow. Two key ingredients of GXN\ninclude a novel vertex infomax pooling (VIPool), which creates multiscale\ngraphs in a trainable manner, and a novel feature-crossing layer, enabling\nfeature interchange across scales. The proposed VIPool selects the most\ninformative subset of vertices based on the neural estimation of mutual\ninformation between vertex features and neighborhood features. The intuition\nbehind is that a vertex is informative when it can maximally reflect its\nneighboring information. The proposed feature-crossing layer fuses intermediate\nfeatures between two scales for mutual enhancement by improving information\nflow and enriching multiscale features at hidden layers. The cross shape of the\nfeature-crossing layer distinguishes GXN from many other multiscale\narchitectures. Experimental results show that the proposed GXN improves the\nclassification accuracy by 2.12% and 1.15% on average for graph classification\nand vertex classification, respectively. Based on the same network, the\nproposed VIPool consistently outperforms other graph-pooling methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 06:34:23 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 12:46:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Maosen", ""], ["Chen", "Siheng", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2010.01818", "submitter": "Tommaso Cesari", "authors": "Riccardo Della Vecchia (BIDSA), Tommaso Cesari (TSE)", "title": "An Efficient Algorithm for Cooperative Semi-Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of asynchronous online combinatorial optimization on\na network of communicating agents. At each time step, some of the agents are\nstochastically activated, requested to make a prediction, and the system pays\nthe corresponding loss. Then, neighbors of active agents receive semi-bandit\nfeedback and exchange some succinct local information. The goal is to minimize\nthe network regret, defined as the difference between the cumulative loss of\nthe predictions of active agents and that of the best action in hindsight,\nselected from a combinatorial decision set. The main challenge in such a\ncontext is to control the computational complexity of the resulting algorithm\nwhile retaining minimax optimal regret guarantees. We introduce Coop-FTPL, a\ncooperative version of the well-known Follow The Perturbed Leader algorithm,\nthat implements a new loss estimation procedure generalizing the Geometric\nResampling of Neu and Bart{\\'o}k [2013] to our setting. Assuming that the\nelements of the decision set are k-dimensional binary vectors with at most m\nnon-zero entries and $\\alpha$ 1 is the independence number of the network, we\nshow that the expected regret of our algorithm after T time steps is of order Q\nmkT log(k)(k$\\alpha$ 1 /Q + m), where Q is the total activation probability\nmass. Furthermore, we prove that this is only $\\sqrt$ k log k-away from the\nbest achievable rate and that Coop-FTPL has a state-of-the-art T 3/2 worst-case\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:08:26 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 08:55:30 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Della Vecchia", "Riccardo", "", "BIDSA"], ["Cesari", "Tommaso", "", "TSE"]]}, {"id": "2010.01819", "submitter": "Xuming Ran", "authors": "Xuming Ran, Mingkun Xu, Qi Xu, Huihui Zhou, Quanying Liu", "title": "Bigeminal Priors Variational auto-encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational auto-encoders (VAEs) are an influential and generally-used class\nof likelihood-based generative models in unsupervised learning. The\nlikelihood-based generative models have been reported to be highly robust to\nthe out-of-distribution (OOD) inputs and can be a detector by assuming that the\nmodel assigns higher likelihoods to the samples from the in-distribution (ID)\ndataset than an OOD dataset. However, recent works reported a phenomenon that\nVAE recognizes some OOD samples as ID by assigning a higher likelihood to the\nOOD inputs compared to the one from ID. In this work, we introduce a new model,\nnamely Bigeminal Priors Variational auto-encoder (BPVAE), to address this\nphenomenon. The BPVAE aims to enhance the robustness of the VAEs by combing the\npower of VAE with the two independent priors that belong to the training\ndataset and simple dataset, which complexity is lower than the training\ndataset, respectively. BPVAE learns two datasets'features, assigning a higher\nlikelihood for the training dataset than the simple dataset. In this way, we\ncan use BPVAE's density estimate for detecting the OOD samples. Quantitative\nexperimental results suggest that our model has better generalization\ncapability and stronger robustness than the standard VAEs, proving the\neffectiveness of the proposed approach of hybrid learning by collaborative\npriors. Overall, this work paves a new avenue to potentially overcome the OOD\nproblem via multiple latent priors modeling.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:10:52 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ran", "Xuming", ""], ["Xu", "Mingkun", ""], ["Xu", "Qi", ""], ["Zhou", "Huihui", ""], ["Liu", "Quanying", ""]]}, {"id": "2010.01823", "submitter": "Duy Vo Nguyen Le", "authors": "Vo Nguyen Le Duy, Shogo Iwazaki, Ichiro Takeuchi", "title": "Quantifying Statistical Significance of Neural Network\n  Representation-Driven Hypotheses by Selective Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, various approaches have been developed to explain and\ninterpret deep neural network (DNN) representations, but it has been pointed\nout that these representations are sometimes unstable and not reproducible. In\nthis paper, we interpret these representations as hypotheses driven by DNN\n(called DNN-driven hypotheses) and propose a method to quantify the reliability\nof these hypotheses in statistical hypothesis testing framework. To this end,\nwe introduce Selective Inference (SI) framework, which has received much\nattention in the past few years as a new statistical inference framework for\ndata-driven hypotheses. The basic idea of SI is to make conditional inferences\non the selected hypotheses under the condition that they are selected. In order\nto use SI framework for DNN representations, we develop a new SI algorithm\nbased on homotopy method which enables us to derive the exact (non-asymptotic)\nconditional sampling distribution of the DNN-driven hypotheses. We conduct\nexperiments on both synthetic and real-world datasets, through which we offer\nevidence that our proposed method can successfully control the false positive\nrate, has decent performance in terms of computational efficiency, and provides\ngood results in practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:16:40 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Iwazaki", "Shogo", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2010.01825", "submitter": "Yoav Levine", "authors": "Yoav Levine, Barak Lenz, Opher Lieber, Omri Abend, Kevin Leyton-Brown,\n  Moshe Tennenholtz, Yoav Shoham", "title": "PMI-Masking: Principled masking of correlated spans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Masking tokens uniformly at random constitutes a common flaw in the\npretraining of Masked Language Models (MLMs) such as BERT. We show that such\nuniform masking allows an MLM to minimize its training objective by latching\nonto shallow local signals, leading to pretraining inefficiency and suboptimal\ndownstream performance. To address this flaw, we propose PMI-Masking, a\nprincipled masking strategy based on the concept of Pointwise Mutual\nInformation (PMI), which jointly masks a token n-gram if it exhibits high\ncollocation over the corpus. PMI-Masking motivates, unifies, and improves upon\nprior more heuristic approaches that attempt to address the drawback of random\nuniform token masking, such as whole-word masking, entity/phrase masking, and\nrandom-span masking. Specifically, we show experimentally that PMI-Masking\nreaches the performance of prior masking approaches in half the training time,\nand consistently improves performance at the end of training.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 07:19:52 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Levine", "Yoav", ""], ["Lenz", "Barak", ""], ["Lieber", "Opher", ""], ["Abend", "Omri", ""], ["Leyton-Brown", "Kevin", ""], ["Tennenholtz", "Moshe", ""], ["Shoham", "Yoav", ""]]}, {"id": "2010.01844", "submitter": "Nadja Klein Prof. Dr.", "authors": "Nadja Klein, Michael Stanley Smith, David J. Nott", "title": "Deep Distributional Time Series Models and the Probabilistic Forecasting\n  of Intraday Electricity Prices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) with rich feature vectors of past values can\nprovide accurate point forecasts for series that exhibit complex serial\ndependence. We propose two approaches to constructing deep time series\nprobabilistic models based on a variant of RNN called an echo state network\n(ESN). The first is where the output layer of the ESN has stochastic\ndisturbances and a shrinkage prior for additional regularization. The second\napproach employs the implicit copula of an ESN with Gaussian disturbances,\nwhich is a deep copula process on the feature space. Combining this copula with\na non-parametrically estimated marginal distribution produces a deep\ndistributional time series model. The resulting probabilistic forecasts are\ndeep functions of the feature vector and also marginally calibrated. In both\napproaches, Bayesian Markov chain Monte Carlo methods are used to estimate the\nmodels and compute forecasts. The proposed models are suitable for the complex\ntask of forecasting intraday electricity prices. Using data from the Australian\nNational Electricity Market, we show that our deep time series models provide\naccurate short term probabilistic price forecasts, with the copula model\ndominating. Moreover, the models provide a flexible framework for incorporating\nprobabilistic forecasts of electricity demand as additional features, which\nincreases upper tail forecast accuracy from the copula model significantly.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:02:29 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 11:17:24 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Klein", "Nadja", ""], ["Smith", "Michael Stanley", ""], ["Nott", "David J.", ""]]}, {"id": "2010.01845", "submitter": "Francisco Ruiz", "authors": "Francisco J. R. Ruiz, Michalis K. Titsias, Taylan Cemgil, Arnaud\n  Doucet", "title": "Unbiased Gradient Estimation for Variational Auto-Encoders using Coupled\n  Markov Chains", "comments": null, "journal-ref": "Conference on Uncertainty in Artificial Intelligence (UAI, 2021)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational auto-encoder (VAE) is a deep latent variable model that has\ntwo neural networks in an autoencoder-like architecture; one of them\nparameterizes the model's likelihood. Fitting its parameters via maximum\nlikelihood (ML) is challenging since the computation of the marginal likelihood\ninvolves an intractable integral over the latent space; thus the VAE is trained\ninstead by maximizing a variational lower bound. Here, we develop a ML training\nscheme for VAEs by introducing unbiased estimators of the log-likelihood\ngradient. We obtain the estimators by augmenting the latent space with a set of\nimportance samples, similarly to the importance weighted auto-encoder (IWAE),\nand then constructing a Markov chain Monte Carlo coupling procedure on this\naugmented space. We provide the conditions under which the estimators can be\ncomputed in finite time and with finite variance. We show experimentally that\nVAEs fitted with unbiased estimators exhibit better predictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:11:55 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 15:37:29 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ruiz", "Francisco J. R.", ""], ["Titsias", "Michalis K.", ""], ["Cemgil", "Taylan", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2010.01848", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Prateek Jain, Praneeth Netrapalli, Sewoong\n  Oh", "title": "Projection Efficient Subgradient Method and Optimal Nonsmooth\n  Frank-Wolfe Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical setting of optimizing a nonsmooth Lipschitz\ncontinuous convex function over a convex constraint set, when having access to\na (stochastic) first-order oracle (FO) for the function and a projection oracle\n(PO) for the constraint set. It is well known that to achieve\n$\\epsilon$-suboptimality in high-dimensions, $\\Theta(\\epsilon^{-2})$ FO calls\nare necessary. This is achieved by the projected subgradient method (PGD).\nHowever, PGD also entails $O(\\epsilon^{-2})$ PO calls, which may be\ncomputationally costlier than FO calls (e.g. nuclear norm constraints).\nImproving this PO calls complexity of PGD is largely unexplored, despite the\nfundamental nature of this problem and extensive literature. We present first\nsuch improvement. This only requires a mild assumption that the objective\nfunction, when extended to a slightly larger neighborhood of the constraint\nset, still remains Lipschitz and accessible via FO. In particular, we introduce\nMOPES method, which carefully combines Moreau-Yosida smoothing and accelerated\nfirst-order schemes. This is guaranteed to find a feasible\n$\\epsilon$-suboptimal solution using only $O(\\epsilon^{-1})$ PO calls and\noptimal $O(\\epsilon^{-2})$ FO calls. Further, instead of a PO if we only have a\nlinear minimization oracle (LMO, a la Frank-Wolfe) to access the constraint\nset, an extension of our method, MOLES, finds a feasible $\\epsilon$-suboptimal\nsolution using $O(\\epsilon^{-2})$ LMO calls and FO calls---both match known\nlower bounds, resolving a question left open since White (1993). Our\nexperiments confirm that these methods achieve significant speedups over the\nstate-of-the-art, for a problem with costly PO and LMO calls.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:16:56 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""], ["Oh", "Sewoong", ""]]}, {"id": "2010.01851", "submitter": "David Holzm\\\"uller", "authors": "David Holzm\\\"uller", "title": "On the Universality of the Double Descent Peak in Ridgeless Regression", "comments": "Accepted at ICLR 2021. 9 pages + 34 pages appendix. Changes in v5:\n  Added link to repository with generated data. Experimental results can be\n  reproduced using the code at\n  https://github.com/dholzmueller/universal_double_descent", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a non-asymptotic distribution-independent lower bound for the\nexpected mean squared generalization error caused by label noise in ridgeless\nlinear regression. Our lower bound generalizes a similar known result to the\noverparameterized (interpolating) regime. In contrast to most previous works,\nour analysis applies to a broad class of input distributions with almost surely\nfull-rank feature matrices, which allows us to cover various types of\ndeterministic or random feature maps. Our lower bound is asymptotically sharp\nand implies that in the presence of label noise, ridgeless linear regression\ndoes not perform well around the interpolation threshold for any of these\nfeature maps. We analyze the imposed assumptions in detail and provide a theory\nfor analytic (random) feature maps. Using this theory, we can show that our\nassumptions are satisfied for input distributions with a (Lebesgue) density and\nfeature maps given by random deep neural networks with analytic activation\nfunctions like sigmoid, tanh, softplus or GELU. As further examples, we show\nthat feature maps from random Fourier features and polynomial kernels also\nsatisfy our assumptions. We complement our theory with further experimental and\nanalytic results.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:30:25 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 16:09:03 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:56:02 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 17:15:33 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 10:33:56 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Holzm\u00fcller", "David", ""]]}, {"id": "2010.01856", "submitter": "Vitaly Kurin", "authors": "Vitaly Kurin, Maximilian Igl, Tim Rockt\\\"aschel, Wendelin Boehmer,\n  Shimon Whiteson", "title": "My Body is a Cage: the Role of Morphology in Graph-Based Incompatible\n  Control", "comments": "ICLR 2021 Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask Reinforcement Learning is a promising way to obtain models with\nbetter performance, generalisation, data efficiency, and robustness. Most\nexisting work is limited to compatible settings, where the state and action\nspace dimensions are the same across tasks. Graph Neural Networks (GNN) are one\nway to address incompatible environments, because they can process graphs of\narbitrary size. They also allow practitioners to inject biases encoded in the\nstructure of the input graph. Existing work in graph-based continuous control\nuses the physical morphology of the agent to construct the input graph, i.e.,\nencoding limb features as node labels and using edges to connect the nodes if\ntheir corresponded limbs are physically connected. In this work, we present a\nseries of ablations on existing methods that show that morphological\ninformation encoded in the graph does not improve their performance. Motivated\nby the hypothesis that any benefits GNNs extract from the graph structure are\noutweighed by difficulties they create for message passing, we also propose\nAmorpheus, a transformer-based approach. Further results show that, while\nAmorpheus ignores the morphological information that GNNs encode, it\nnonetheless substantially outperforms GNN-based methods that use the\nmorphological information to define the message-passing scheme.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:37:11 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 09:48:02 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kurin", "Vitaly", ""], ["Igl", "Maximilian", ""], ["Rockt\u00e4schel", "Tim", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2010.01874", "submitter": "Gilles Stoltz", "authors": "H\\'edi Hadiji (LMO, CELESTE), S\\'ebastien Gerchinovitz (IMT),\n  Jean-Michel Loubes (IMT), Gilles Stoltz (LMO, CELESTE)", "title": "Diversity-Preserving K-Armed Bandits, Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the bandit-based framework for diversity-preserving\nrecommendations introduced by Celis et al. (2019), who approached it mainly by\na reduction to the setting of linear bandits. We design a UCB algorithm using\nthe specific structure of the setting and show that it enjoys a bounded\ndistribution-dependent regret in the natural cases when the optimal mixed\nactions put some probability mass on all actions (i.e., when diversity is\ndesirable). Simulations illustrate this fact. We also provide regret lower\nbounds and briefly discuss distribution-free regret bounds.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:22:31 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hadiji", "H\u00e9di", "", "LMO, CELESTE"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Stoltz", "Gilles", "", "LMO, CELESTE"]]}, {"id": "2010.01875", "submitter": "Lei Feng", "authors": "Lei Feng, Senlin Shu, Nan Lu, Bo Han, Miao Xu, Gang Niu, Bo An,\n  Masashi Sugiyama", "title": "Pointwise Binary Classification with Pairwise Confidence Comparisons", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To alleviate the data requirement for training effective binary classifiers\nin binary classification, many weakly supervised learning settings have been\nproposed. Among them, some consider using pairwise but not pointwise labels,\nwhen pointwise labels are not accessible due to privacy, confidentiality, or\nsecurity reasons. However, as a pairwise label denotes whether or not two data\npoints share a pointwise label, it cannot be easily collected if either point\nis equally likely to be positive or negative. Thus, in this paper, we propose a\nnovel setting called pairwise comparison (Pcomp) classification, where we have\nonly pairs of unlabeled data that we know one is more likely to be positive\nthan the other. Firstly, we give a Pcomp data generation process, derive an\nunbiased risk estimator (URE) with theoretical guarantee, and further improve\nURE using correction functions. Secondly, we link Pcomp classification to\nnoisy-label learning to develop a progressive URE and improve it by imposing\nconsistency regularization. Finally, we demonstrate by experiments the\neffectiveness of our methods, which suggests Pcomp is a valuable and\npractically useful type of pairwise supervision besides the pairwise label.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:23:58 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 15:26:43 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 15:08:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Feng", "Lei", ""], ["Shu", "Senlin", ""], ["Lu", "Nan", ""], ["Han", "Bo", ""], ["Xu", "Miao", ""], ["Niu", "Gang", ""], ["An", "Bo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2010.01916", "submitter": "Uchenna Akujuobi", "authors": "Uchenna Akujuobi, Jun Chen, Mohamed Elhoseiny, Michael Spranger,\n  Xiangliang Zhang", "title": "Temporal Positive-unlabeled Learning for Biomedical Hypothesis\n  Generation via Risk Estimation", "comments": "Accepted for Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the relationships between biomedical terms like viruses, drugs,\nand symptoms is essential in the fight against diseases. Many attempts have\nbeen made to introduce the use of machine learning to the scientific process of\nhypothesis generation(HG), which refers to the discovery of meaningful implicit\nconnections between biomedical terms. However, most existing methods fail to\ntruly capture the temporal dynamics of scientific term relations and also\nassume unobserved connections to be irrelevant (i.e., in a positive-negative\n(PN) learning setting). To break these limits, we formulate this HG problem as\nfuture connectivity prediction task on a dynamic attributed graph via\npositive-unlabeled (PU) learning. Then, the key is to capture the temporal\nevolution of node pair (term pair) relations from just the positive and\nunlabeled data. We propose a variational inference model to estimate the\npositive prior, and incorporate it in the learning of node pair embeddings,\nwhich are then used for link prediction. Experiment results on real-world\nbiomedical term relationship datasets and case study analyses on a COVID-19\ndataset validate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 10:58:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Akujuobi", "Uchenna", ""], ["Chen", "Jun", ""], ["Elhoseiny", "Mohamed", ""], ["Spranger", "Michael", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2010.01917", "submitter": "Omer Achrack", "authors": "Omer Achrack, Raizy Kellerman, Ouriel Barzilay", "title": "Multi-Loss Sub-Ensembles for Accurate Classification with Uncertainty\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have made a revolution in numerous fields during\nthe last decade. However, in tasks with high safety requirements, such as\nmedical or autonomous driving applications, providing an assessment of the\nmodels reliability can be vital. Uncertainty estimation for DNNs has been\naddressed using Bayesian methods, providing mathematically founded models for\nreliability assessment. These model are computationally expensive and generally\nimpractical for many real-time use cases. Recently, non-Bayesian methods were\nproposed to tackle uncertainty estimation more efficiently. We propose an\nefficient method for uncertainty estimation in DNNs achieving high accuracy. We\nsimulate the notion of multi-task learning on single-task problems by producing\nparallel predictions from similar models differing by their loss. This\nmulti-loss approach allows one-phase training for single-task learning with\nuncertainty estimation. We keep our inference time relatively low by leveraging\nthe advantage proposed by the Deep-Sub-Ensembles method. The novelty of this\nwork resides in the proposed accurate variational inference with a simple and\nconvenient training procedure, while remaining competitive in terms of\ncomputational time. We conduct experiments on SVHN, CIFAR10, CIFAR100 as well\nas Image-Net using different architectures. Our results show improved accuracy\non the classification task and competitive results on several uncertainty\nmeasures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 10:59:11 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 12:41:52 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Achrack", "Omer", ""], ["Kellerman", "Raizy", ""], ["Barzilay", "Ouriel", ""]]}, {"id": "2010.01921", "submitter": "Muhammad Firmansyah Kasim", "authors": "Muhammad F. Kasim, Sam M. Vinko", "title": "$\\xi$-torch: differentiable scientific computing library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Physics-informed learning has shown to have a better generalization than\nlearning without physical priors.\n  However, training physics-informed deep neural networks requires some aspect\nof physical simulations to be written in a differentiable manner.\n  Unfortunately, some operations and functionals commonly used in physical\nsimulations are scattered, hard to integrate, and lack higher order derivatives\nwhich are needed in physical simulations.\n  In this work, we present $\\xi$-torch, a library of differentiable functionals\nfor scientific simulations.\n  Example functionals are a root finder and an initial value problem solver,\namong others.\n  The gradient of functionals in $\\xi$-torch are written based on their\nanalytical expression to improve numerical stability and reduce memory\nrequirements.\n  $\\xi$-torch also provides second and higher order derivatives of the\nfunctionals which are rarely available in existing packages.\n  We show two applications of this library in optimizing parameters in physics\nsimulations.\n  The library and all test cases in this work can be found at\nhttps://github.com/xitorch/xitorch/ and the documentation at\nhttps://xitorch.readthedocs.io.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 11:14:31 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Kasim", "Muhammad F.", ""], ["Vinko", "Sam M.", ""]]}, {"id": "2010.01930", "submitter": "Peter Jung", "authors": "Freya Behrens, Jonathan Sauder and Peter Jung", "title": "Neurally Augmented ALISTA", "comments": "10pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-established that many iterative sparse reconstruction algorithms\ncan be unrolled to yield a learnable neural network for improved empirical\nperformance. A prime example is learned ISTA (LISTA) where weights, step sizes\nand thresholds are learned from training data. Recently, Analytic LISTA\n(ALISTA) has been introduced, combining the strong empirical performance of a\nfully learned approach like LISTA, while retaining theoretical guarantees of\nclassical compressed sensing algorithms and significantly reducing the number\nof parameters to learn. However, these parameters are trained to work in\nexpectation, often leading to suboptimal reconstruction of individual targets.\nIn this work we therefore introduce Neurally Augmented ALISTA, in which an LSTM\nnetwork is used to compute step sizes and thresholds individually for each\ntarget vector during reconstruction. This adaptive approach is theoretically\nmotivated by revisiting the recovery guarantees of ALISTA. We show that our\napproach further improves empirical performance in sparse reconstruction, in\nparticular outperforming existing algorithms by an increasing margin as the\ncompression ratio becomes more challenging.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 11:39:49 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Behrens", "Freya", ""], ["Sauder", "Jonathan", ""], ["Jung", "Peter", ""]]}, {"id": "2010.01932", "submitter": "David Sigtermans", "authors": "David Sigtermans", "title": "Is Information Theory Inherently a Theory of Causation?", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory gives rise to a novel method for causal skeleton discovery\nby expressing associations between variables as tensors. This tensor-based\napproach reduces the dimensionality of the data needed to test for conditional\nindependence, e.g., for systems comprising three variables, the causal skeleton\ncan be determined using pair-wise determined tensors. To arrive at this result,\nan additional information measure, path information, is proposed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 11:41:27 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:01:22 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 18:41:07 GMT"}, {"version": "v4", "created": "Sat, 7 Nov 2020 21:35:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Sigtermans", "David", ""]]}, {"id": "2010.01935", "submitter": "Nicolas Gillis", "authors": "Le Thi Khanh Hien, Nicolas Gillis", "title": "Algorithms for Nonnegative Matrix Factorization with the\n  Kullback-Leibler Divergence", "comments": "31 pages, Accepted in the Journal of Scientific Computing", "journal-ref": "Journal of Scientific Computing 87, 93, 2021", "doi": "10.1007/s10915-021-01504-0", "report-no": null, "categories": "math.OC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is a standard linear dimensionality\nreduction technique for nonnegative data sets. In order to measure the\ndiscrepancy between the input data and the low-rank approximation, the\nKullback-Leibler (KL) divergence is one of the most widely used objective\nfunction for NMF. It corresponds to the maximum likehood estimator when the\nunderlying statistics of the observed data sample follows a Poisson\ndistribution, and KL NMF is particularly meaningful for count data sets, such\nas documents or images. In this paper, we first collect important properties of\nthe KL objective function that are essential to study the convergence of KL NMF\nalgorithms. Second, together with reviewing existing algorithms for solving KL\nNMF, we propose three new algorithms that guarantee the non-increasingness of\nthe objective function. We also provide a global convergence guarantee for one\nof our proposed algorithms. Finally, we conduct extensive numerical experiments\nto provide a comprehensive picture of the performances of the KL NMF\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 11:51:39 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 07:27:02 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Hien", "Le Thi Khanh", ""], ["Gillis", "Nicolas", ""]]}, {"id": "2010.01979", "submitter": "Zhijie Deng", "authors": "Zhijie Deng, Hao Zhang, Xiao Yang, Yinpeng Dong, Jun Zhu", "title": "BayesAdapter: Being Bayesian, Inexpensively and Reliably, via Bayesian\n  Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their theoretical appealingness, Bayesian neural networks (BNNs) are\nleft behind in real-world adoption, due to persistent concerns on their\nscalability, accessibility, and reliability. In this work, we aim to relieve\nthese concerns by developing the BayesAdapter framework for learning\nvariational BNNs. In particular, we propose to adapt the pre-trained\ndeterministic NNs to be BNNs via cost-effective Bayesian fine-tuning. To make\nBayesAdapter more practical, we technically contribute 1) a modularized,\nuser-friendly implementation for the learning of variational BNNs under two\nrepresentative variational distributions, 2) a generally applicable strategy\nfor reducing the gradient variance in stochastic variational inference, 3) an\nexplanation for the unreliability issue of BNNs' uncertainty estimates, and a\ncorresponding prescription. Through extensive experiments on diverse\nbenchmarks, we show that BayesAdapter can consistently induce posteriors with\nhigher quality than the from-scratch variational inference and other\ncompetitive baselines, especially in large-scale settings, yet significantly\nreducing training overheads.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:13:21 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 08:25:28 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 08:22:35 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2021 09:43:56 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Deng", "Zhijie", ""], ["Zhang", "Hao", ""], ["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Zhu", "Jun", ""]]}, {"id": "2010.01986", "submitter": "Wanzheng Zhu", "authors": "Wanzheng Zhu, Chao Zhang, Shuochao Yao, Xiaobin Gao, Jiawei Han", "title": "A Spherical Hidden Markov Model for Semantics-Rich Human Mobility\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of modeling human mobility from semantic trace data,\nwherein each GPS record in a trace is associated with a text message that\ndescribes the user's activity. Existing methods fall short in unveiling human\nmovement regularities, because they either do not model the text data at all or\nsuffer from text sparsity severely. We propose SHMM, a multi-modal spherical\nhidden Markov model for semantics-rich human mobility modeling. Under the\nhidden Markov assumption, SHMM models the generation process of a given trace\nby jointly considering the observed location, time, and text at each step of\nthe trace. The distinguishing characteristic of SHMM is the text modeling part.\nWe use fixed-size vector representations to encode the semantics of the text\nmessages, and model the generation of the l2-normalized text embeddings on a\nunit sphere with the von Mises-Fisher (vMF) distribution. Compared with other\nalternatives like multi-variate Gaussian, our choice of the vMF distribution\nnot only incurs much fewer parameters, but also better leverages the\ndiscriminative power of text embeddings in a directional metric space. The\nparameter inference for the vMF distribution is non-trivial since it involves\nfunctional inversion of ratios of Bessel functions. We theoretically prove\nthat: 1) the classical Expectation-Maximization algorithm can work with vMF\ndistributions; and 2) while closed-form solutions are hard to be obtained for\nthe M-step, Newton's method is guaranteed to converge to the optimal solution\nwith quadratic convergence rate. We have performed extensive experiments on\nboth synthetic and real-life data. The results on synthetic data verify our\ntheoretical analysis; while the results on real-life data demonstrate that SHMM\nlearns meaningful semantics-rich mobility models, outperforms state-of-the-art\nmobility models for next location prediction, and incurs lower training cost.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:18:38 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhu", "Wanzheng", ""], ["Zhang", "Chao", ""], ["Yao", "Shuochao", ""], ["Gao", "Xiaobin", ""], ["Han", "Jiawei", ""]]}, {"id": "2010.01992", "submitter": "Quentin Bouniot", "authors": "Quentin Bouniot, Ievgen Redko, Romaric Audigier, Ang\\'elique Loesch,\n  Yevhenii Zotkin, Amaury Habrard", "title": "Towards Better Understanding Meta-learning Methods through Multi-task\n  Representation Learning Theory", "comments": "21 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the framework of multi-task representation (MTR)\nlearning where the goal is to use source tasks to learn a representation that\nreduces the sample complexity of solving a target task. We start by reviewing\nrecent advances in MTR theory and show that they can provide novel insights for\npopular meta-learning algorithms when analyzed within this framework. In\nparticular, we highlight a fundamental difference between gradient-based and\nmetric-based algorithms and put forward a theoretical analysis to explain it.\nFinally, we use the derived insights to improve the generalization capacity of\nmeta-learning methods via a new spectral-based regularization term and confirm\nits efficiency through experimental studies on classic few-shot classification\nand continual learning benchmarks. To the best of our knowledge, this is the\nfirst contribution that puts the most recent learning bounds of MTR theory into\npractice of training popular meta-learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:24:43 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 15:58:27 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bouniot", "Quentin", ""], ["Redko", "Ievgen", ""], ["Audigier", "Romaric", ""], ["Loesch", "Ang\u00e9lique", ""], ["Zotkin", "Yevhenii", ""], ["Habrard", "Amaury", ""]]}, {"id": "2010.01997", "submitter": "Sourav Mukherjee", "authors": "Sourav Mukherjee, Tim Oates, Vince DiMascio, Huguens Jean, Rob Ares,\n  David Widmark, Jaclyn Harder", "title": "Immigration Document Classification and Automated Response Generation", "comments": "To appear in ICDM 2020 workshop: MLLD-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of organizing supporting documents\nvital to U.S. work visa petitions, as well as responding to Requests For\nEvidence (RFE) issued by the U.S.~Citizenship and Immigration Services (USCIS).\nTypically, both processes require a significant amount of repetitive manual\neffort. To reduce the burden of mechanical work, we apply machine learning\nmethods to automate these processes, with humans in the loop to review and edit\noutput for submission. In particular, we use an ensemble of image and text\nclassifiers to categorize supporting documents. We also use a text classifier\nto automatically identify the types of evidence being requested in an RFE, and\nused the identified types in conjunction with response templates and extracted\nfields to assemble draft responses. Empirical results suggest that our approach\nachieves considerable accuracy while significantly reducing processing time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 23:45:44 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Mukherjee", "Sourav", ""], ["Oates", "Tim", ""], ["DiMascio", "Vince", ""], ["Jean", "Huguens", ""], ["Ares", "Rob", ""], ["Widmark", "David", ""], ["Harder", "Jaclyn", ""]]}, {"id": "2010.02002", "submitter": "Priyadarshini Kumari", "authors": "Priyadarshini Kumari and Subhasis Chaudhuri", "title": "Boosted Semantic Embedding based Discriminative Feature Generation for\n  Texture Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning discriminative features is crucial for various robotic applications\nsuch as object detection and classification. In this paper, we present a\ngeneral framework for the analysis of the discriminative properties of haptic\nsignals. Our focus is on two crucial components of a robotic perception system:\ndiscriminative feature extraction and metric-based feature transformation to\nenhance the separability of haptic signals in the projected space. We propose a\nset of hand-crafted haptic features (generated only from acceleration data),\nwhich enables discrimination of real-world textures. Since the Euclidean space\ndoes not reflect the underlying pattern in the data, we propose to learn an\nappropriate transformation function to project the feature onto the new space\nand apply different pattern recognition algorithms for texture classification\nand discrimination tasks. Unlike other existing methods, we use a triplet-based\nmethod for improved discrimination in the embedded space. We further\ndemonstrate how to build a haptic vocabulary by selecting a compact set of the\nmost distinct and representative signals in the embedded space. The\nexperimental results show that the proposed features augmented with learned\nembedding improves the performance of semantic discrimination tasks such as\nclassification and clustering and outperforms the related state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:38:23 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 07:12:00 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kumari", "Priyadarshini", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "2010.02004", "submitter": "Emanuele La Malfa", "authors": "Emanuele La Malfa, Min Wu, Luca Laurenti, Benjie Wang, Anthony\n  Hartshorn, Marta Kwiatkowska", "title": "Assessing Robustness of Text Classification through Maximal Safe Radius\n  Computation", "comments": "12 pages + appendix", "journal-ref": "EMNLP-Findings2020", "doi": "10.18653/v1/2020.findings-emnlp.266", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network NLP models are vulnerable to small modifications of the input\nthat maintain the original meaning but result in a different prediction. In\nthis paper, we focus on robustness of text classification against word\nsubstitutions, aiming to provide guarantees that the model prediction does not\nchange if a word is replaced with a plausible alternative, such as a synonym.\nAs a measure of robustness, we adopt the notion of the maximal safe radius for\na given input text, which is the minimum distance in the embedding space to the\ndecision boundary. Since computing the exact maximal safe radius is not\nfeasible in practice, we instead approximate it by computing a lower and upper\nbound. For the upper bound computation, we employ Monte Carlo Tree Search in\nconjunction with syntactic filtering to analyse the effect of single and\nmultiple word substitutions. The lower bound computation is achieved through an\nadaptation of the linear bounding techniques implemented in tools CNN-Cert and\nPOPQORN, respectively for convolutional and recurrent network models. We\nevaluate the methods on sentiment analysis and news classification models for\nfour datasets (IMDB, SST, AG News and NEWS) and a range of embeddings, and\nprovide an analysis of robustness trends. We also apply our framework to\ninterpretability analysis and compare it with LIME.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 09:46:32 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 08:50:10 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["La Malfa", "Emanuele", ""], ["Wu", "Min", ""], ["Laurenti", "Luca", ""], ["Wang", "Benjie", ""], ["Hartshorn", "Anthony", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2010.02006", "submitter": "Han Wu", "authors": "Han Wu, Wenjie Ruan, Jiangtao Wang, Dingchang Zheng, Bei Liu, Yayuan\n  Gen, Xiangfei Chai, Jian Chen, Kunwei Li, Shaolin Li, and Sumi Helal", "title": "Interpretable Machine Learning for COVID-19: An Empirical Study on\n  Severity Prediction Task", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The black-box nature of machine learning models hinders the deployment of\nsome high-accuracy models in medical diagnosis. It is risky to put one's life\nin the hands of models that medical researchers do not fully understand.\nHowever, through model interpretation, black-box models can promptly reveal\nsignificant biomarkers that medical practitioners may have overlooked due to\nthe surge of infected patients in the COVID-19 pandemic.\n  This research leverages a database of 92 patients with confirmed SARS-CoV-2\nlaboratory tests between 18th Jan. 2020 and 5th Mar. 2020, in Zhuhai, China, to\nidentify biomarkers indicative of severity prediction. Through the\ninterpretation of four machine learning models, decision tree, random forests,\ngradient boosted trees, and neural networks using permutation feature\nimportance, Partial Dependence Plot (PDP), Individual Conditional Expectation\n(ICE), Accumulated Local Effects (ALE), Local Interpretable Model-agnostic\nExplanations (LIME), and Shapley Additive Explanation (SHAP), we identify an\nincrease in N-Terminal pro-Brain Natriuretic Peptide (NTproBNP), C-Reaction\nProtein (CRP), and lactic dehydrogenase (LDH), a decrease in lymphocyte (LYM)\nis associated with severe infection and an increased risk of death, which is\nconsistent with recent medical research on COVID-19 and other research using\ndedicated models. We further validate our methods on a large open dataset with\n5644 confirmed patients from the Hospital Israelita Albert Einstein, at S\\~ao\nPaulo, Brazil from Kaggle, and unveil leukocytes, eosinophils, and platelets as\nthree indicative biomarkers for COVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:13:41 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 14:39:16 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 17:37:42 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 20:13:44 GMT"}, {"version": "v5", "created": "Sun, 7 Feb 2021 20:16:09 GMT"}, {"version": "v6", "created": "Fri, 30 Apr 2021 10:31:05 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Wu", "Han", ""], ["Ruan", "Wenjie", ""], ["Wang", "Jiangtao", ""], ["Zheng", "Dingchang", ""], ["Liu", "Bei", ""], ["Gen", "Yayuan", ""], ["Chai", "Xiangfei", ""], ["Chen", "Jian", ""], ["Li", "Kunwei", ""], ["Li", "Shaolin", ""], ["Helal", "Sumi", ""]]}, {"id": "2010.02014", "submitter": "Ioannis Gatopoulos", "authors": "Ioannis Gatopoulos and Jakub M. Tomczak", "title": "Self-Supervised Variational Auto-Encoders", "comments": "19 pages, 14 figures, 2 tables", "journal-ref": null, "doi": "10.3390/e23060747", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation, compression and data generation are crucial tasks in\nartificial intelligence. Variational Auto-Encoders (VAEs) constitute a single\nframework to achieve these goals. Here, we present a novel class of generative\nmodels, called self-supervised Variational Auto-Encoder (selfVAE), that\nutilizes deterministic and discrete variational posteriors. This class of\nmodels allows to perform both conditional and unconditional sampling, while\nsimplifying the objective function. First, we use a single self-supervised\ntransformation as a latent variable, where a transformation is either\ndownscaling or edge detection. Next, we consider a hierarchical architecture,\ni.e., multiple transformations, and we show its benefits compared to the VAE.\nThe flexibility of selfVAE in data reconstruction finds a particularly\ninteresting use case in data compression tasks, where we can trade-off memory\nfor better data quality, and vice-versa. We present performance of our approach\non three benchmark image data (Cifar10, Imagenette64, and CelebA).\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:42:28 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 08:20:15 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gatopoulos", "Ioannis", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "2010.02024", "submitter": "Guoxian Yu", "authors": "Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang\n  Zhang", "title": "Deep Incomplete Multi-View Multiple Clusterings", "comments": "10 pages, ICDM2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering aims at exploiting information from multiple\nheterogeneous views to promote clustering. Most previous works search for only\none optimal clustering based on the predefined clustering criterion, but\ndevising such a criterion that captures what users need is difficult. Due to\nthe multiplicity of multi-view data, we can have meaningful alternative\nclusterings. In addition, the incomplete multi-view data problem is ubiquitous\nin real world but has not been studied for multiple clusterings. To address\nthese issues, we introduce a deep incomplete multi-view multiple clusterings\n(DiMVMC) framework, which achieves the completion of data view and multiple\nshared representations simultaneously by optimizing multiple groups of decoder\ndeep networks. In addition, it minimizes a redundancy term to simultaneously\n%uses Hilbert-Schmidt Independence Criterion (HSIC) to control the diversity\namong these representations and among parameters of different networks. Next,\nit generates an individual clustering from each of these shared\nrepresentations. Experiments on benchmark datasets confirm that DiMVMC\noutperforms the state-of-the-art competitors in generating multiple clusterings\nwith high diversity and quality.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:01:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wei", "Shaowei", ""], ["Wang", "Jun", ""], ["Yu", "Guoxian", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2010.02029", "submitter": "Quan Zhang", "authors": "Quan Zhang, Huangjie Zheng, Mingyuan Zhou", "title": "MCMC-Interactive Variational Inference", "comments": "25 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging well-established MCMC strategies, we propose MCMC-interactive\nvariational inference (MIVI) to not only estimate the posterior in a time\nconstrained manner, but also facilitate the design of MCMC transitions.\nConstructing a variational distribution followed by a short Markov chain that\nhas parameters to learn, MIVI takes advantage of the complementary properties\nof variational inference and MCMC to encourage mutual improvement. On one hand,\nwith the variational distribution locating high posterior density regions, the\nMarkov chain is optimized within the variational inference framework to\nefficiently target the posterior despite a small number of transitions. On the\nother hand, the optimized Markov chain with considerable flexibility guides the\nvariational distribution towards the posterior and alleviates its\nunderestimation of uncertainty. Furthermore, we prove the optimized Markov\nchain in MIVI admits extrapolation, which means its marginal distribution gets\ncloser to the true posterior as the chain grows. Therefore, the Markov chain\ncan be used separately as an efficient MCMC scheme. Experiments show that MIVI\nnot only accurately and efficiently approximates the posteriors but also\nfacilitates designs of stochastic gradient MCMC and Gibbs sampling transitions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 17:43:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Quan", ""], ["Zheng", "Huangjie", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2010.02035", "submitter": "Aksel Wilhelm Wold Eide", "authors": "Aksel Wilhelm Wold Eide, Eilif Solberg, Ingebj{\\o}rg K{\\aa}sen", "title": "Sample weighting as an explanation for mode collapse in generative\n  adversarial networks", "comments": "41 pages, 21 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks were introduced with a logistic MiniMax cost\nformulation, which normally fails to train due to saturation, and a\nNon-Saturating reformulation. While addressing the saturation problem, NS-GAN\nalso inverts the generator's sample weighting, implicitly shifting emphasis\nfrom higher-scoring to lower-scoring samples when updating parameters. We\npresent both theory and empirical results suggesting that this makes NS-GAN\nprone to mode dropping. We design MM-nsat, which preserves MM-GAN sample\nweighting while avoiding saturation by rescaling the MM-GAN minibatch gradient\nsuch that its magnitude approximates NS-GAN's gradient magnitude. MM-nsat has\nqualitatively different training dynamics, and on MNIST and CIFAR-10 it is\nstronger in terms of mode coverage, stability and FID. While the empirical\nresults for MM-nsat are promising and favorable also in comparison with the\nLS-GAN and Hinge-GAN formulations, our main contribution is to show how and why\nNS-GAN's sample weighting causes mode dropping and training collapse.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:13:45 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Eide", "Aksel Wilhelm Wold", ""], ["Solberg", "Eilif", ""], ["K\u00e5sen", "Ingebj\u00f8rg", ""]]}, {"id": "2010.02037", "submitter": "Mike Wu", "authors": "Mike Wu, Milan Mosse, Chengxu Zhuang, Daniel Yamins, Noah Goodman", "title": "Conditional Negative Sampling for Contrastive Learning of Visual\n  Representations", "comments": "8 pages, 4 pages supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent methods for learning unsupervised visual representations, dubbed\ncontrastive learning, optimize the noise-contrastive estimation (NCE) bound on\nmutual information between two views of an image. NCE uses randomly sampled\nnegative examples to normalize the objective. In this paper, we show that\nchoosing difficult negatives, or those more similar to the current instance,\ncan yield stronger representations. To do this, we introduce a family of mutual\ninformation estimators that sample negatives conditionally -- in a \"ring\"\naround each positive. We prove that these estimators lower-bound mutual\ninformation, with higher bias but lower variance than NCE. Experimentally, we\nfind our approach, applied on top of existing models (IR, CMC, and MoCo)\nimproves accuracy by 2-5% points in each case, measured by linear evaluation on\nfour standard image datasets. Moreover, we find continued benefits when\ntransferring features to a variety of new image distributions from the\nMeta-Dataset collection and to a variety of downstream tasks such as object\ndetection, instance segmentation, and keypoint detection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:17:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wu", "Mike", ""], ["Mosse", "Milan", ""], ["Zhuang", "Chengxu", ""], ["Yamins", "Daniel", ""], ["Goodman", "Noah", ""]]}, {"id": "2010.02038", "submitter": "Mike Wu", "authors": "Mike Wu, Noah Goodman", "title": "A Simple Framework for Uncertainty in Contrastive Learning", "comments": "8 pages main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive approaches to representation learning have recently shown great\npromise. In contrast to generative approaches, these contrastive models learn a\ndeterministic encoder with no notion of uncertainty or confidence. In this\npaper, we introduce a simple approach based on \"contrasting distributions\" that\nlearns to assign uncertainty for pretrained contrastive representations. In\nparticular, we train a deep network from a representation to a distribution in\nrepresentation space, whose variance can be used as a measure of confidence. In\nour experiments, we show that this deep uncertainty model can be used (1) to\nvisually interpret model behavior, (2) to detect new noise in the input to\ndeployed models, (3) to detect anomalies, where we outperform 10 baseline\nmethods across 11 tasks with improvements of up to 14% absolute, and (4) to\nclassify out-of-distribution examples where our fully unsupervised model is\ncompetitive with supervised methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:17:42 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""]]}, {"id": "2010.02054", "submitter": "Yi-Fu Wu", "authors": "Zhixuan Lin, Yi-Fu Wu, Skand Peri, Bofeng Fu, Jindong Jiang, Sungjin\n  Ahn", "title": "Improving Generative Imagination in Object-Centric World Models", "comments": "Accepted in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable recent advances in object-centric generative world models\nraise a few questions. First, while many of the recent achievements are\nindispensable for making a general and versatile world model, it is quite\nunclear how these ingredients can be integrated into a unified framework.\nSecond, despite using generative objectives, abilities for object detection and\ntracking are mainly investigated, leaving the crucial ability of temporal\nimagination largely under question. Third, a few key abilities for more\nfaithful temporal imagination such as multimodal uncertainty and\nsituation-awareness are missing. In this paper, we introduce Generative\nStructured World Models (G-SWM). The G-SWM achieves the versatile world\nmodeling not only by unifying the key properties of previous models in a\nprincipled framework but also by achieving two crucial new abilities,\nmultimodal uncertainty and situation-awareness. Our thorough investigation on\nthe temporal generation ability in comparison to the previous models\ndemonstrates that G-SWM achieves the versatility with the best or comparable\nperformance for all experiment settings including a few complex settings that\nhave not been tested before.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:43:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Lin", "Zhixuan", ""], ["Wu", "Yi-Fu", ""], ["Peri", "Skand", ""], ["Fu", "Bofeng", ""], ["Jiang", "Jindong", ""], ["Ahn", "Sungjin", ""]]}, {"id": "2010.02068", "submitter": "Bo Lin", "authors": "Bo Lin, Bissan Ghaddar, Jatin Nathwani", "title": "Deep Reinforcement Learning for Electric Vehicle Routing Problem with\n  Time Windows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen a rapid penetration of electric vehicles (EV) in the\nmarket, more and more logistics and transportation companies start to deploy\nEVs for service provision. In order to model the operations of a commercial EV\nfleet, we utilize the EV routing problem with time windows (EVRPTW). In this\nresearch, we propose an end-to-end deep reinforcement learning framework to\nsolve the EVRPTW. In particular, we develop an attention model incorporating\nthe pointer network and a graph embedding technique to parameterize a\nstochastic policy for solving the EVRPTW. The model is then trained using\npolicy gradient with rollout baseline. Our numerical studies show that the\nproposed model is able to efficiently solve EVRPTW instances of large sizes\nthat are not solvable with any existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:06:02 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 01:14:31 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 18:51:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lin", "Bo", ""], ["Ghaddar", "Bissan", ""], ["Nathwani", "Jatin", ""]]}, {"id": "2010.02075", "submitter": "Zhan Shi", "authors": "Zhan Shi, Chirag Sakhuja, Milad Hashemi, Kevin Swersky, Calvin Lin", "title": "Learned Hardware/Software Co-Design of Neural Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep learning has grown at an exponential rate, giving rise to\nnumerous specialized hardware and software systems for deep learning. Because\nthe design space of deep learning software stacks and hardware accelerators is\ndiverse and vast, prior work considers software optimizations separately from\nhardware architectures, effectively reducing the search space. Unfortunately,\nthis bifurcated approach means that many profitable design points are never\nexplored. This paper instead casts the problem as hardware/software co-design,\nwith the goal of automatically identifying desirable points in the joint design\nspace. The key to our solution is a new constrained Bayesian optimization\nframework that avoids invalid solutions by exploiting the highly constrained\nfeatures of this design space, which are semi-continuous/semi-discrete. We\nevaluate our optimization framework by applying it to a variety of neural\nmodels, improving the energy-delay product by 18% (ResNet) and 40% (DQN) over\nhand-tuned state-of-the-art systems, as well as demonstrating strong results on\nother neural network architectures, such as MLPs and Transformers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:12:52 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shi", "Zhan", ""], ["Sakhuja", "Chirag", ""], ["Hashemi", "Milad", ""], ["Swersky", "Kevin", ""], ["Lin", "Calvin", ""]]}, {"id": "2010.02089", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Bo Chang, Xuefei Zhang, Qiaozhu Mei", "title": "CopulaGNN: Towards Integrating Representational and Correlational Roles\n  of Graphs in Graph Neural Networks", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data are ubiquitous. However, graphs encode diverse types of\ninformation and thus play different roles in data representation. In this\npaper, we distinguish the \\textit{representational} and the\n\\textit{correlational} roles played by the graphs in node-level prediction\ntasks, and we investigate how Graph Neural Network (GNN) models can effectively\nleverage both types of information. Conceptually, the representational\ninformation provides guidance for the model to construct better node features;\nwhile the correlational information indicates the correlation between node\noutcomes conditional on node features. Through a simulation study, we find that\nmany popular GNN models are incapable of effectively utilizing the\ncorrelational information. By leveraging the idea of the copula, a principled\nway to describe the dependence among multivariate random variables, we offer a\ngeneral solution. The proposed Copula Graph Neural Network (CopulaGNN) can take\na wide range of GNN models as base models and utilize both representational and\ncorrelational information stored in the graphs. Experimental results on two\ntypes of regression tasks verify the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:20:04 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 21:54:58 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Ma", "Jiaqi", ""], ["Chang", "Bo", ""], ["Zhang", "Xuefei", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2010.02114", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Amrith Setlur, Eduard Hovy, Zachary C. Lipton", "title": "Explaining The Efficacy of Counterfactually Augmented Data", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In attempts to produce ML models less reliant on spurious patterns in NLP\ndatasets, researchers have recently proposed curating counterfactually\naugmented data (CAD) via a human-in-the-loop process in which given some\ndocuments and their (initial) labels, humans must revise the text to make a\ncounterfactual label applicable. Importantly, edits that are not necessary to\nflip the applicable label are prohibited. Models trained on the augmented data\nappear, empirically, to rely less on semantically irrelevant words and to\ngeneralize better out of domain. While this work draws loosely on causal\nthinking, the underlying causal model (even at an abstract level) and the\nprinciples underlying the observed out-of-domain improvements remain unclear.\nIn this paper, we introduce a toy analog based on linear Gaussian models,\nobserving interesting relationships between causal models, measurement noise,\nout-of-domain generalization, and reliance on spurious signals. Our analysis\nprovides some insights that help to explain the efficacy of CAD. Moreover, we\ndevelop the hypothesis that while adding noise to causal features should\ndegrade both in-domain and out-of-domain performance, adding noise to\nnon-causal features should lead to relative improvements in out-of-domain\nperformance. This idea inspires a speculative test for determining whether a\nfeature attribution technique has identified the causal spans. If adding noise\n(e.g., by random word flips) to the highlighted spans degrades both in-domain\nand out-of-domain performance on a battery of challenge datasets, but adding\nnoise to the complement gives improvements out-of-domain, it suggests we have\nidentified causal spans. We present a large-scale empirical study comparing\nspans edited to create CAD to those selected by attention and saliency maps.\nAcross numerous domains and models, we find that the hypothesized phenomenon is\npronounced for CAD.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:57:07 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:21:13 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 02:02:40 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 01:46:15 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Setlur", "Amrith", ""], ["Hovy", "Eduard", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2010.02125", "submitter": "Yura Perugachi-Diaz", "authors": "Yura Perugachi-Diaz, Jakub M. Tomczak, Sandjai Bhulai", "title": "Invertible DenseNets", "comments": "Accepted at 3rd Symposium on Advances in Approximate Bayesian\n  Inference (AABI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Invertible Dense Networks (i-DenseNets), a more parameter\nefficient alternative to Residual Flows. The method relies on an analysis of\nthe Lipschitz continuity of the concatenation in DenseNets, where we enforce\nthe invertibility of the network by satisfying the Lipschitz constraint.\nAdditionally, we extend this method by proposing a learnable concatenation,\nwhich not only improves the model performance but also indicates the importance\nof the concatenated representation. We demonstrate the performance of\ni-DenseNets and Residual Flows on toy, MNIST, and CIFAR10 data. Both\ni-DenseNets outperform Residual Flows evaluated in negative log-likelihood, on\nall considered datasets under an equal parameter budget.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 16:11:39 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 17:53:32 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 18:33:17 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Perugachi-Diaz", "Yura", ""], ["Tomczak", "Jakub M.", ""], ["Bhulai", "Sandjai", ""]]}, {"id": "2010.02178", "submitter": "Bilal Alsallakh", "authors": "Bilal Alsallakh and Narine Kokhlikyan and Vivek Miglani and Jun Yuan\n  and Orion Reblitz-Richardson", "title": "Mind the Pad -- CNNs can Develop Blind Spots", "comments": "Appendix E available at\n  https://drive.google.com/file/d/1bIvRQJIBwJbKTfpg0hNaFX2ThuuDO8PU/view?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how feature maps in convolutional networks are susceptible to spatial\nbias. Due to a combination of architectural choices, the activation at certain\nlocations is systematically elevated or weakened. The major source of this bias\nis the padding mechanism. Depending on several aspects of convolution\narithmetic, this mechanism can apply the padding unevenly, leading to\nasymmetries in the learned weights. We demonstrate how such bias can be\ndetrimental to certain tasks such as small object detection: the activation is\nsuppressed if the stimulus lies in the impacted area, leading to blind spots\nand misdetection. We propose solutions to mitigate spatial bias and demonstrate\nhow they can improve model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:24:48 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Alsallakh", "Bilal", ""], ["Kokhlikyan", "Narine", ""], ["Miglani", "Vivek", ""], ["Yuan", "Jun", ""], ["Reblitz-Richardson", "Orion", ""]]}, {"id": "2010.02193", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, Jimmy Ba", "title": "Mastering Atari with Discrete World Models", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents need to generalize from past experience to achieve goals\nin complex environments. World models facilitate such generalization and allow\nlearning behaviors from imagined outcomes to increase sample-efficiency. While\nlearning world models from image inputs has recently become feasible for some\ntasks, modeling Atari games accurately enough to derive successful behaviors\nhas remained an open challenge for many years. We introduce DreamerV2, a\nreinforcement learning agent that learns behaviors purely from predictions in\nthe compact latent space of a powerful world model. The world model uses\ndiscrete representations and is trained separately from the policy. DreamerV2\nconstitutes the first agent that achieves human-level performance on the Atari\nbenchmark of 55 tasks by learning behaviors inside a separately trained world\nmodel. With the same computational budget and wall-clock time, Dreamer V2\nreaches 200M frames and surpasses the final performance of the top single-GPU\nagents IQN and Rainbow. DreamerV2 is also applicable to tasks with continuous\nactions, where it learns an accurate world model of a complex humanoid robot\nand solves stand-up and walking from only pixel inputs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:52:14 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 18:57:03 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 22:35:05 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hafner", "Danijar", ""], ["Lillicrap", "Timothy", ""], ["Norouzi", "Mohammad", ""], ["Ba", "Jimmy", ""]]}, {"id": "2010.02255", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Jane X. Wang, Pablo Sprechmann, Francesco Visin,\n  Alexandre Galashov, Steven Kapturowski, Diana L. Borsa, Nicolas Heess, Andre\n  Barreto, Razvan Pascanu", "title": "Temporal Difference Uncertainties as a Signal for Exploration", "comments": "9 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An effective approach to exploration in reinforcement learning is to rely on\nan agent's uncertainty over the optimal policy, which can yield near-optimal\nexploration strategies in tabular settings. However, in non-tabular settings\nthat involve function approximators, obtaining accurate uncertainty estimates\nis almost as challenging a problem. In this paper, we highlight that value\nestimates are easily biased and temporally inconsistent. In light of this, we\npropose a novel method for estimating uncertainty over the value function that\nrelies on inducing a distribution over temporal difference errors. This\nexploration signal controls for state-action transitions so as to isolate\nuncertainty in value that is due to uncertainty over the agent's parameters.\nBecause our measure of uncertainty conditions on state-action transitions, we\ncannot act on this measure directly. Instead, we incorporate it as an intrinsic\nreward and treat exploration as a separate learning problem, induced by the\nagent's temporal difference uncertainties. We introduce a distinct exploration\npolicy that learns to collect data with high estimated uncertainty, which gives\nrise to a curriculum that smoothly changes throughout learning and vanishes in\nthe limit of perfect value estimates. We evaluate our method on hard\nexploration tasks, including Deep Sea and Atari 2600 environments and find that\nour proposed form of exploration facilitates both diverse and deep exploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:11:22 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 09:21:25 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Wang", "Jane X.", ""], ["Sprechmann", "Pablo", ""], ["Visin", "Francesco", ""], ["Galashov", "Alexandre", ""], ["Kapturowski", "Steven", ""], ["Borsa", "Diana L.", ""], ["Heess", "Nicolas", ""], ["Barreto", "Andre", ""], ["Pascanu", "Razvan", ""]]}, {"id": "2010.02264", "submitter": "Aarshvi Gajjar", "authors": "Aarshvi Gajjar, Cameron Musco", "title": "Subspace Embeddings Under Nonlinear Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider low-distortion embeddings for subspaces under \\emph{entrywise\nnonlinear transformations}. In particular we seek embeddings that preserve the\nnorm of all vectors in a space $S = \\{y: y = f(x)\\text{ for }x \\in Z\\}$, where\n$Z$ is a $k$-dimensional subspace of $\\mathbb{R}^n$ and $f(x)$ is a nonlinear\nactivation function applied entrywise to $x$. When $f$ is the identity, and so\n$S$ is just a $k$-dimensional subspace, it is known that, with high\nprobability, a random embedding into $O(k/\\epsilon^2)$ dimensions preserves the\nnorm of all $y \\in S$ up to $(1\\pm \\epsilon)$ relative error. Such embeddings\nare known as \\emph{subspace embeddings}, and have found widespread use in\ncompressed sensing and approximation algorithms. We give the first\nlow-distortion embeddings for a wide class of nonlinear functions $f$. In\nparticular, we give additive $\\epsilon$ error embeddings into $O(\\frac{k\\log\n(n/\\epsilon)}{\\epsilon^2})$ dimensions for a class of nonlinearities that\nincludes the popular Sigmoid SoftPlus, and Gaussian functions. We strengthen\nthis result to give relative error embeddings under some further restrictions,\nwhich are satisfied e.g., by the Tanh, SoftSign, Exponential Linear Unit, and\nmany other `soft' step functions and rectifying units. Understanding embeddings\nfor subspaces under nonlinear transformations is a key step towards extending\nrandom sketching and compressing sensing techniques for linear problems to\nnonlinear ones. We discuss example applications of our results to improved\nbounds for compressed sensing via generative neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 18:18:04 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Gajjar", "Aarshvi", ""], ["Musco", "Cameron", ""]]}, {"id": "2010.02302", "submitter": "Aleksandr Ermolov", "authors": "Aleksandr Ermolov, Nicu Sebe", "title": "Latent World Models For Intrinsically Motivated Exploration", "comments": "NeurIPS 2020 Spotlight; Code is publicly available at\n  https://github.com/htdt/lwm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider partially observable environments with sparse\nrewards. We present a self-supervised representation learning method for\nimage-based observations, which arranges embeddings respecting temporal\ndistance of observations. This representation is empirically robust to\nstochasticity and suitable for novelty detection from the error of a predictive\nforward model. We consider episodic and life-long uncertainties to guide the\nexploration. We propose to estimate the missing information about the\nenvironment with the world model, which operates in the learned latent space.\nAs a motivation of the method, we analyse the exploration problem in a tabular\nPartially Observable Labyrinth. We demonstrate the method on image-based hard\nexploration environments from the Atari benchmark and report significant\nimprovement with respect to prior work. The source code of the method and all\nthe experiments is available at https://github.com/htdt/lwm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 19:47:04 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ermolov", "Aleksandr", ""], ["Sebe", "Nicu", ""]]}, {"id": "2010.02310", "submitter": "Lucas Deecke", "authors": "Lucas Deecke, Lukas Ruff, Robert A. Vandermeulen, Hakan Bilen", "title": "Deep Anomaly Detection by Residual Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep anomaly detection is a difficult task since, in high dimensions, it is\nhard to completely characterize a notion of \"differentness\" when given only\nexamples of normality. In this paper we propose a novel approach to deep\nanomaly detection based on augmenting large pretrained networks with residual\ncorrections that adjusts them to the task of anomaly detection. Our method\ngives rise to a highly parameter-efficient learning mechanism, enhances\ndisentanglement of representations in the pretrained model, and outperforms all\nexisting anomaly detection methods including other baselines utilizing\npretrained networks. On the CIFAR-10 one-versus-rest benchmark, for example,\nour technique raises the state of the art from 96.1 to 99.0 mean AUC.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 20:02:58 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Deecke", "Lucas", ""], ["Ruff", "Lukas", ""], ["Vandermeulen", "Robert A.", ""], ["Bilen", "Hakan", ""]]}, {"id": "2010.02311", "submitter": "Amina Mollaysa", "authors": "Amina Mollaysa, Brooks Paige, Alexandros Kalousis", "title": "Goal-directed Generation of Discrete Structures with Conditional\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances, goal-directed generation of structured discrete data\nremains challenging. For problems such as program synthesis (generating source\ncode) and materials design (generating molecules), finding examples which\nsatisfy desired constraints or exhibit desired properties is difficult. In\npractice, expensive heuristic search or reinforcement learning algorithms are\noften employed. In this paper we investigate the use of conditional generative\nmodels which directly attack this inverse problem, by modeling the distribution\nof discrete structures given properties of interest. Unfortunately, maximum\nlikelihood training of such models often fails with the samples from the\ngenerative model inadequately respecting the input properties. To address this,\nwe introduce a novel approach to directly optimize a reinforcement learning\nobjective, maximizing an expected reward. We avoid high-variance score-function\nestimators that would otherwise be required by sampling from an approximation\nto the normalized rewards, allowing simple Monte Carlo estimation of model\ngradients. We test our methodology on two tasks: generating molecules with\nuser-defined properties and identifying short python expressions which evaluate\nto a given target value. In both cases, we find improvements over maximum\nlikelihood estimation and other baselines.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 20:03:13 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:15:31 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Mollaysa", "Amina", ""], ["Paige", "Brooks", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2010.02347", "submitter": "Zhaowei Zhu", "authors": "Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, Yang Liu", "title": "Learning with Instance-Dependent Label Noise: A Sample Sieve Approach", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-annotated labels are often prone to noise, and the presence of such\nnoise will degrade the performance of the resulting deep neural network (DNN)\nmodels. Much of the literature (with several recent exceptions) of learning\nwith noisy labels focuses on the case when the label noise is independent of\nfeatures. Practically, annotations errors tend to be instance-dependent and\noften depend on the difficulty levels of recognizing a certain task. Applying\nexisting results from instance-independent settings would require a significant\namount of estimation of noise rates. Therefore, providing theoretically\nrigorous solutions for learning with instance-dependent label noise remains a\nchallenge. In this paper, we propose CORES$^{2}$ (COnfidence REgularized Sample\nSieve), which progressively sieves out corrupted examples. The implementation\nof CORES$^{2}$ does not require specifying noise rates and yet we are able to\nprovide theoretical guarantees of CORES$^{2}$ in filtering out the corrupted\nexamples. This high-quality sample sieve allows us to treat clean examples and\nthe corrupted ones separately in training a DNN solution, and such a separation\nis shown to be advantageous in the instance-dependent noise setting. We\ndemonstrate the performance of CORES$^{2}$ on CIFAR10 and CIFAR100 datasets\nwith synthetic instance-dependent label noise and Clothing1M with real-world\nhuman noise. As of independent interests, our sample sieve provides a generic\nmachinery for anatomizing noisy datasets and provides a flexible interface for\nvarious robust training techniques to further improve the performance. Code is\navailable at https://github.com/UCSC-REAL/cores.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 21:44:09 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 22:01:05 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Cheng", "Hao", ""], ["Zhu", "Zhaowei", ""], ["Li", "Xingyu", ""], ["Gong", "Yifei", ""], ["Sun", "Xing", ""], ["Liu", "Yang", ""]]}, {"id": "2010.02383", "submitter": "Dilip Arumugam", "authors": "Dilip Arumugam and Benjamin Van Roy", "title": "Randomized Value Functions via Posterior State-Abstraction Sampling", "comments": "Accepted to the Workshop on Biological and Artificial Reinforcement\n  Learning (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State abstraction has been an essential tool for dramatically improving the\nsample efficiency of reinforcement-learning algorithms. Indeed, by exposing and\naccentuating various types of latent structure within the environment,\ndifferent classes of state abstraction have enabled improved theoretical\nguarantees and empirical performance. When dealing with state abstractions that\ncapture structure in the value function, however, a standard assumption is that\nthe true abstraction has been supplied or unrealistically computed a priori,\nleaving open the question of how to efficiently uncover such latent structure\nwhile jointly seeking out optimal behavior. Taking inspiration from the bandit\nliterature, we propose that an agent seeking out latent task structure must\nexplicitly represent and maintain its uncertainty over that structure as part\nof its overall uncertainty about the environment. We introduce a practical\nalgorithm for doing this using two posterior distributions over state\nabstractions and abstract-state values. In empirically validating our approach,\nwe find that substantial performance gains lie in the multi-task setting where\ntasks share a common, low-dimensional representation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:04:18 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 17:33:59 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Arumugam", "Dilip", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2010.02411", "submitter": "Abd AlRahman AlMomani", "authors": "Abd AlRahman AlMomani and Erik Bollt", "title": "ERFit: Entropic Regression Fit Matlab Package, for Data-Driven System\n  Identification of Underlying Dynamic Equations", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven sparse system identification becomes the general framework for a\nwide range of problems in science and engineering. It is a problem of growing\nimportance in applied machine learning and artificial intelligence algorithms.\nIn this work, we developed the Entropic Regression Software Package (ERFit), a\nMATLAB package for sparse system identification using the entropic regression\nmethod. The code requires minimal supervision, with a wide range of options\nthat make it adapt easily to different problems in science and engineering. The\nERFit is available at https://github.com/almomaa/ERFit-Package\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:07:15 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["AlMomani", "Abd AlRahman", ""], ["Bollt", "Erik", ""]]}, {"id": "2010.02415", "submitter": "Frederik Wenkel M.Sc.", "authors": "Alexander Tong, Frederik Wenkel, Kincaid MacDonald, Smita\n  Krishnaswamy, Guy Wolf", "title": "Data-Driven Learning of Geometric Scattering Networks", "comments": "16 pages, 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new graph neural network (GNN) module, based on a relaxation of\nrecently proposed geometric scattering transforms, which consist of a cascade\nof graph wavelet filters. Our learnable geometric scattering (LEGS) module\nenables adaptive tuning of these wavelets to encourage band-pass features to\nemerge in learned representations. The incorporation of our LEGS-module in GNNs\nenables the learning of longer-range graph relations compared to many popular\nGNN architectures, which often rely on encoding graph structure via smoothness\nor similarity between neighbors. Further, its wavelet priors result in\nsimplified architectures with significantly fewer learned parameters compared\nto competing GNNs. We demonstrate the predictive performance of LEGS-based\nnetworks on graph classification benchmarks, as well as the descriptive quality\nof their learned features in biochemical graph data exploration tasks. Our\nresults show that LEGS-based networks match or outperforms popular GNNs, as\nwell as the original geometric scattering construction, on many datasets, in\nparticular in biochemical domains, while retaining certain mathematical\nproperties of handcrafted (nonlearned) geometric scattering.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:20:27 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 13:03:54 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Tong", "Alexander", ""], ["Wenkel", "Frederik", ""], ["MacDonald", "Kincaid", ""], ["Krishnaswamy", "Smita", ""], ["Wolf", "Guy", ""]]}, {"id": "2010.02424", "submitter": "Nick Terry", "authors": "Nick Terry and Youngjun Choe", "title": "Splitting Gaussian Process Regression for Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes offer a flexible kernel method for regression. While\nGaussian processes have many useful theoretical properties and have proven\npractically useful, they suffer from poor scaling in the number of\nobservations. In particular, the cubic time complexity of updating standard\nGaussian process models make them generally unsuitable for application to\nstreaming data. We propose an algorithm for sequentially partitioning the input\nspace and fitting a localized Gaussian process to each disjoint region. The\nalgorithm is shown to have superior time and space complexity to existing\nmethods, and its sequential nature permits application to streaming data. The\nalgorithm constructs a model for which the time complexity of updating is\ntightly bounded above by a pre-specified parameter. To the best of our\nknowledge, the model is the first local Gaussian process regression model to\nachieve linear memory complexity. Theoretical continuity properties of the\nmodel are proven. We demonstrate the efficacy of the resulting model on\nmulti-dimensional regression tasks for streaming data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:37:13 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Terry", "Nick", ""], ["Choe", "Youngjun", ""]]}, {"id": "2010.02425", "submitter": "Robert Vandermeulen", "authors": "Robert A. Vandermeulen", "title": "Improving Nonparametric Density Estimation with Tensor Decompositions", "comments": "20 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While nonparametric density estimators often perform well on low dimensional\ndata, their performance can suffer when applied to higher dimensional data,\nowing presumably to the curse of dimensionality. One technique for avoiding\nthis is to assume no dependence between features and that the data are sampled\nfrom a separable density. This allows one to estimate each marginal\ndistribution independently thereby avoiding the slow rates associated with\nestimating the full joint density. This is a strategy employed in naive Bayes\nmodels and is analogous to estimating a rank-one tensor. In this paper we\ninvestigate whether these improvements can be extended to other simplified\ndependence assumptions which we model via nonnegative tensor decompositions. In\nour central theoretical results we prove that restricting estimation to\nlow-rank nonnegative PARAFAC or Tucker decompositions removes the\ndimensionality exponent on bin width rates for multidimensional histograms.\nThese results are validated experimentally with high statistical significance\nvia direct application of existing nonnegative tensor factorization to\nhistogram estimators.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:39:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Vandermeulen", "Robert A.", ""]]}, {"id": "2010.02459", "submitter": "Michael Kleinman", "authors": "Michael Kleinman, Alessandro Achille, Daksh Idnani, Jonathan C. Kao", "title": "Usable Information and Evolution of Optimal Representations During\n  Training", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of usable information contained in the representation\nlearned by a deep network, and use it to study how optimal representations for\nthe task emerge during training. We show that the implicit regularization\ncoming from training with Stochastic Gradient Descent with a high learning-rate\nand small batch size plays an important role in learning minimal sufficient\nrepresentations for the task. In the process of arriving at a minimal\nsufficient representation, we find that the content of the representation\nchanges dynamically during training. In particular, we find that semantically\nmeaningful but ultimately irrelevant information is encoded in the early\ntransient dynamics of training, before being later discarded. In addition, we\nevaluate how perturbing the initial part of training impacts the learning\ndynamics and the resulting representations. We show these effects on both\nperceptual decision-making tasks inspired by neuroscience literature, as well\nas on standard image classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 03:50:19 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 17:51:26 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kleinman", "Michael", ""], ["Achille", "Alessandro", ""], ["Idnani", "Daksh", ""], ["Kao", "Jonathan C.", ""]]}, {"id": "2010.02469", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Francis K.C. Hui, David I. Warton, and Trevor\n  Hastie", "title": "Generalized Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmeasured or latent variables are often the cause of correlations between\nmultivariate measurements and are studied in a variety of fields such as\npsychology, ecology, and medicine. For Gaussian measurements, there are\nclassical tools such as factor analysis or principal component analysis with a\nwell-established theory and fast algorithms. Generalized Linear Latent Variable\nmodels (GLLVM) generalize such factor models to non-Gaussian responses.\nHowever, current algorithms for estimating model parameters in GLLVMs require\nintensive computation and do not scale to large datasets with thousands of\nobservational units or responses. In this article, we propose a new approach\nfor fitting GLLVMs to such high-volume, high-dimensional datasets. We\napproximate the likelihood using penalized quasi-likelihood and use a Newton\nmethod and Fisher scoring to learn the model parameters. Our method greatly\nreduces the computation time and can be easily parallelized, enabling\nfactorization at unprecedented scale using commodity hardware. We illustrate\napplication of our method on a dataset of 48,000 observational units with over\n2,000 observed species in each unit, finding that most of the variability can\nbe explained with a handful of factors.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 04:28:19 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Hui", "Francis K. C.", ""], ["Warton", "David I.", ""], ["Hastie", "Trevor", ""]]}, {"id": "2010.02477", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Yeunju Choi, Hyungjun Lim, Hoirin Kim", "title": "A Unified Deep Learning Framework for Short-Duration Speaker\n  Verification in Adverse Environments", "comments": "19 pages, 10 figures, 13 tables", "journal-ref": "in IEEE Access, vol. 8, pp. 175448-175466, 2020", "doi": "10.1109/ACCESS.2020.3025941", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification (SV) has recently attracted considerable research\ninterest due to the growing popularity of virtual assistants. At the same time,\nthere is an increasing requirement for an SV system: it should be robust to\nshort speech segments, especially in noisy and reverberant environments. In\nthis paper, we consider one more important requirement for practical\napplications: the system should be robust to an audio stream containing long\nnon-speech segments, where a voice activity detection (VAD) is not applied. To\nmeet these two requirements, we introduce feature pyramid module (FPM)-based\nmulti-scale aggregation (MSA) and self-adaptive soft VAD (SAS-VAD). We present\nthe FPM-based MSA to deal with short speech segments in noisy and reverberant\nenvironments. Also, we use the SAS-VAD to increase the robustness to long\nnon-speech segments. To further improve the robustness to acoustic distortions\n(i.e., noise and reverberation), we apply a masking-based speech enhancement\n(SE) method. We combine SV, VAD, and SE models in a unified deep learning\nframework and jointly train the entire network in an end-to-end manner. To the\nbest of our knowledge, this is the first work combining these three models in a\ndeep learning framework. We conduct experiments on Korean indoor (KID) and\nVoxCeleb datasets, which are corrupted by noise and reverberation. The results\nshow that the proposed method is effective for SV in the challenging conditions\nand performs better than the baseline i-vector and deep speaker embedding\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 04:51:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Jung", "Youngmoon", ""], ["Choi", "Yeunju", ""], ["Lim", "Hyungjun", ""], ["Kim", "Hoirin", ""]]}, {"id": "2010.02501", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Shankar Krishnan, Hossein Mobahi", "title": "A Unifying View on Implicit Bias in Training Linear Neural Networks", "comments": "36 pages, 6 figures; to appear at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the implicit bias of gradient flow (i.e., gradient descent with\ninfinitesimal step size) on linear neural network training. We propose a tensor\nformulation of neural networks that includes fully-connected, diagonal, and\nconvolutional networks as special cases, and investigate the linear version of\nthe formulation called linear tensor networks. With this formulation, we can\ncharacterize the convergence direction of the network parameters as singular\nvectors of a tensor defined by the network. For $L$-layer linear tensor\nnetworks that are orthogonally decomposable, we show that gradient flow on\nseparable classification finds a stationary point of the $\\ell_{2/L}$\nmax-margin problem in a \"transformed\" input space defined by the network. For\nunderdetermined regression, we prove that gradient flow finds a global minimum\nwhich minimizes a norm-like function that interpolates between weighted\n$\\ell_1$ and $\\ell_2$ norms in the transformed input space. Our theorems\nsubsume existing results in the literature while removing standard convergence\nassumptions. We also provide experiments that corroborate our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 06:08:35 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 00:38:18 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Yun", "Chulhee", ""], ["Krishnan", "Shankar", ""], ["Mobahi", "Hossein", ""]]}, {"id": "2010.02506", "submitter": "Wei Fan", "authors": "Wei Fan, Kunpeng Liu, Hao Liu, Yong Ge, Hui Xiong, Yanjie Fu", "title": "Interactive Reinforcement Learning for Feature Selection with Decision\n  Tree in the Loop", "comments": "arXiv admin note: substantial text overlap with arXiv:2008.12001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of balancing effectiveness and efficiency in automated\nfeature selection. After exploring many feature selection methods, we observe a\ncomputational dilemma: 1) traditional feature selection is mostly efficient,\nbut difficult to identify the best subset; 2) the emerging reinforced feature\nselection automatically navigates to the best subset, but is usually\ninefficient. Can we bridge the gap between effectiveness and efficiency under\nautomation? Motivated by this dilemma, we aim to develop a novel feature space\nnavigation method. In our preliminary work, we leveraged interactive\nreinforcement learning to accelerate feature selection by external\ntrainer-agent interaction. In this journal version, we propose a novel\ninteractive and closed-loop architecture to simultaneously model interactive\nreinforcement learning (IRL) and decision tree feedback (DTF). Specifically,\nIRL is to create an interactive feature selection loop and DTF is to feed\nstructured feature knowledge back to the loop. First, the tree-structured\nfeature hierarchy from decision tree is leveraged to improve state\nrepresentation. In particular, we represent the selected feature subset as an\nundirected graph of feature-feature correlations and a directed tree of\ndecision features. We propose a new embedding method capable of empowering\ngraph convolutional network to jointly learn state representation from both the\ngraph and the tree. Second, the tree-structured feature hierarchy is exploited\nto develop a new reward scheme. In particular, we personalize reward assignment\nof agents based on decision tree feature importance. In addition, observing\nagents' actions can be feedback, we devise another reward scheme, to weigh and\nassign reward based on the feature selected frequency ratio in historical\naction records. Finally, we present extensive experiments on real-world\ndatasets to show the improved performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 18:09:57 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Fan", "Wei", ""], ["Liu", "Kunpeng", ""], ["Liu", "Hao", ""], ["Ge", "Yong", ""], ["Xiong", "Hui", ""], ["Fu", "Yanjie", ""]]}, {"id": "2010.02508", "submitter": "Ryan Campbell", "authors": "Ryan Campbell, Chris Finlay, Adam M Oberman", "title": "Adversarial Boot Camp: label free certified robustness in one epoch", "comments": "13 pages, 5 figures, 5 tables. Under review as a conference paper at\n  ICLR 2021. arXiv admin note: substantial text overlap with arXiv:2006.06061", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial attacks. One approach\nto addressing this vulnerability is certification, which focuses on models that\nare guaranteed to be robust for a given perturbation size. A drawback of recent\ncertified models is that they are stochastic: they require multiple\ncomputationally expensive model evaluations with random noise added to a given\ninput. In our work, we present a deterministic certification approach which\nresults in a certifiably robust model. This approach is based on an equivalence\nbetween training with a particular regularized loss, and the expected values of\nGaussian averages. We achieve certified models on ImageNet-1k by retraining a\nmodel with this loss for one epoch without the use of label information.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:47:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Campbell", "Ryan", ""], ["Finlay", "Chris", ""], ["Oberman", "Adam M", ""]]}, {"id": "2010.02519", "submitter": "Jikai Jin", "authors": "Bohang Zhang and Jikai Jin and Cong Fang and Liwei Wang", "title": "Improved Analysis of Clipping Algorithms for Non-convex Optimization", "comments": "41 pages, 12 figures, to appear in NeurIPS 2020. arXiv admin note:\n  text overlap with arXiv:1905.11881 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient clipping is commonly used in training deep neural networks partly\ndue to its practicability in relieving the exploding gradient problem.\nRecently, \\citet{zhang2019gradient} show that clipped (stochastic) Gradient\nDescent (GD) converges faster than vanilla GD/SGD via introducing a new\nassumption called $(L_0, L_1)$-smoothness, which characterizes the violent\nfluctuation of gradients typically encountered in deep neural networks.\nHowever, their iteration complexities on the problem-dependent parameters are\nrather pessimistic, and theoretical justification of clipping combined with\nother crucial techniques, e.g. momentum acceleration, are still lacking. In\nthis paper, we bridge the gap by presenting a general framework to study the\nclipping algorithms, which also takes momentum methods into consideration. We\nprovide convergence analysis of the framework in both deterministic and\nstochastic setting, and demonstrate the tightness of our results by comparing\nthem with existing lower bounds. Our results imply that the efficiency of\nclipping methods will not degenerate even in highly non-smooth regions of the\nlandscape. Experiments confirm the superiority of clipping-based methods in\ndeep learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 14:36:59 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 03:04:32 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Zhang", "Bohang", ""], ["Jin", "Jikai", ""], ["Fang", "Cong", ""], ["Wang", "Liwei", ""]]}, {"id": "2010.02539", "submitter": "Guoxian Yu", "authors": "Yuanlin Yang, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang\n  Zhang", "title": "Multi-typed Objects Multi-view Multi-instance Multi-label Learning", "comments": "ICDM2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-typed objects Multi-view Multi-instance Multi-label Learning (M4L)\ndeals with interconnected multi-typed objects (or bags) that are made of\ndiverse instances, represented with heterogeneous feature views and annotated\nwith a set of non-exclusive but semantically related labels. M4L is more\ngeneral and powerful than the typical Multi-view Multi-instance Multi-label\nLearning (M3L), which only accommodates single-typed bags and lacks the power\nto jointly model the naturally interconnected multi-typed objects in the\nphysical world. To combat with this novel and challenging learning task, we\ndevelop a joint matrix factorization based solution (M4L-JMF). Particularly,\nM4L-JMF firstly encodes the diverse attributes and multiple\ninter(intra)-associations among multi-typed bags into respective data matrices,\nand then jointly factorizes these matrices into low-rank ones to explore the\ncomposite latent representation of each bag and its instances (if any). In\naddition, it incorporates a dispatch and aggregation term to distribute the\nlabels of bags to individual instances and reversely aggregate the labels of\ninstances to their affiliated bags in a coherent manner. Experimental results\non benchmark datasets show that M4L-JMF achieves significantly better results\nthan simple adaptions of existing M3L solutions on this novel problem.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 08:00:02 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Yang", "Yuanlin", ""], ["Yu", "Guoxian", ""], ["Wang", "Jun", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2010.02554", "submitter": "Pablo Moreno-Mu\\~noz", "authors": "Pablo Moreno-Mu\\~noz, Antonio Art\\'es-Rodr\\'iguez and Mauricio A.\n  \\'Alvarez", "title": "Recyclable Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new framework for recycling independent variational\napproximations to Gaussian processes. The main contribution is the construction\nof variational ensembles given a dictionary of fitted Gaussian processes\nwithout revisiting any subset of observations. Our framework allows for\nregression, classification and heterogeneous tasks, i.e. mix of continuous and\ndiscrete variables over the same input domain. We exploit infinite-dimensional\nintegral operators based on the Kullback-Leibler divergence between stochastic\nprocesses to re-combine arbitrary amounts of variational sparse approximations\nwith different complexity, likelihood model and location of the pseudo-inputs.\nExtensive results illustrate the usability of our framework in large-scale\ndistributed experiments, also compared with the exact inference models in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:01:55 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "2010.02558", "submitter": "Sekitoshi Kanai", "authors": "Sekitoshi Kanai, Masanori Yamada, Shin'ya Yamaguchi, Hiroshi\n  Takahashi, Yasutoshi Ida", "title": "Constraining Logits by Bounded Function for Adversarial Robustness", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for improving adversarial robustness by addition of a new\nbounded function just before softmax. Recent studies hypothesize that small\nlogits (inputs of softmax) by logit regularization can improve adversarial\nrobustness of deep learning. Following this hypothesis, we analyze norms of\nlogit vectors at the optimal point under the assumption of universal\napproximation and explore new methods for constraining logits by addition of a\nbounded function before softmax. We theoretically and empirically reveal that\nsmall logits by addition of a common activation function, e.g., hyperbolic\ntangent, do not improve adversarial robustness since input vectors of the\nfunction (pre-logit vectors) can have large norms. From the theoretical\nfindings, we develop the new bounded function. The addition of our function\nimproves adversarial robustness because it makes logit and pre-logit vectors\nhave small norms. Since our method only adds one activation function before\nsoftmax, it is easy to combine our method with adversarial training. Our\nexperiments demonstrate that our method is comparable to logit regularization\nmethods in terms of accuracies on adversarially perturbed datasets without\nadversarial training. Furthermore, it is superior or comparable to logit\nregularization methods and a recent defense method (TRADES) when using\nadversarial training.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:04:58 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kanai", "Sekitoshi", ""], ["Yamada", "Masanori", ""], ["Yamaguchi", "Shin'ya", ""], ["Takahashi", "Hiroshi", ""], ["Ida", "Yasutoshi", ""]]}, {"id": "2010.02574", "submitter": "Sonja Kuhnt", "authors": "Dominik Kirchhoff, Sonja Kuhnt", "title": "Gaussian Process Models with Low-Rank Correlation Matrices for Both\n  Continuous and Categorical Inputs", "comments": "19 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method that uses low-rank approximations of cross-correlation\nmatrices in mixed continuous and categorical Gaussian Process models. This new\nmethod -- called Low-Rank Correlation (LRC) -- offers the ability to flexibly\nadapt the number of parameters to the problem at hand by choosing an\nappropriate rank of the approximation. Furthermore, we present a systematic\napproach of defining test functions that can be used for assessing the accuracy\nof models or optimization methods that are concerned with both continuous and\ncategorical inputs. We compare LRC to existing approaches of modeling the\ncross-correlation matrix. It turns out that the new approach performs well in\nterms of estimation of cross-correlations and response surface prediction.\nTherefore, LRC is a flexible and useful addition to existing methods,\nespecially for increasing numbers of combinations of levels of the categorical\ninputs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:38:35 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kirchhoff", "Dominik", ""], ["Kuhnt", "Sonja", ""]]}, {"id": "2010.02576", "submitter": "Alexander Mey", "authors": "Alexander Mey", "title": "A Note on High-Probability versus In-Expectation Guarantees of\n  Generalization Bounds in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical machine learning theory often tries to give generalization\nguarantees of machine learning models. Those models naturally underlie some\nfluctuation, as they are based on a data sample. If we were unlucky, and\ngathered a sample that is not representative of the underlying distribution,\none cannot expect to construct a reliable machine learning model. Following\nthat, statements made about the performance of machine learning models have to\ntake the sampling process into account. The two common approaches for that are\nto generate statements that hold either in high-probability, or in-expectation,\nover the random sampling process. In this short note we show how one may\ntransform one statement to another. As a technical novelty we address the case\nof unbounded loss function, where we use a fairly new assumption, called the\nwitness condition.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 09:41:35 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Mey", "Alexander", ""]]}, {"id": "2010.02610", "submitter": "Sebastian Bobadilla-Suarez", "authors": "Sebastian Bobadilla-Suarez, Matt Jones, Bradley C. Love", "title": "Robust priors for regularized regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Induction benefits from useful priors. Penalized regression approaches, like\nridge regression, shrink weights toward zero but zero association is usually\nnot a sensible prior. Inspired by simple and robust decision heuristics humans\nuse, we constructed non-zero priors for penalized regression models that\nprovide robust and interpretable solutions across several tasks. Our approach\nenables estimates from a constrained model to serve as a prior for a more\ngeneral model, yielding a principled way to interpolate between models of\ndiffering complexity. We successfully applied this approach to a number of\ndecision and classification problems, as well as analyzing simulated brain\nimaging data. Models with robust priors had excellent worst-case performance.\nSolutions followed from the form of the heuristic that was used to derive the\nprior. These new algorithms can serve applications in data analysis and machine\nlearning, as well as help in understanding how people transition from novice to\nexpert performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 10:43:14 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 11:27:31 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bobadilla-Suarez", "Sebastian", ""], ["Jones", "Matt", ""], ["Love", "Bradley C.", ""]]}, {"id": "2010.02637", "submitter": "Xinwei Shen", "authors": "Xinwei Shen, Furui Liu, Hanze Dong, Qing Lian, Zhitang Chen, and Tong\n  Zhang", "title": "Disentangled Generative Causal Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Disentangled gEnerative cAusal Representation (DEAR)\nlearning method. Unlike existing disentanglement methods that enforce\nindependence of the latent variables, we consider the general case where the\nunderlying factors of interests can be causally correlated. We show that\nprevious methods with independent priors fail to disentangle causally\ncorrelated factors. Motivated by this finding, we propose a new disentangled\nlearning method called DEAR that enables causal controllable generation and\ncausal representation learning. The key ingredient of this new formulation is\nto use a structural causal model (SCM) as the prior for a bidirectional\ngenerative model. The prior is then trained jointly with a generator and an\nencoder using a suitable GAN loss incorporated with supervision. We provide\ntheoretical justification on the identifiability and asymptotic consistency of\nthe proposed method, which guarantees disentangled causal representation\nlearning under appropriate conditions. We conduct extensive experiments on both\nsynthesized and real data sets to demonstrate the effectiveness of DEAR in\ncausal controllable generation, and the benefits of the learned representations\nfor downstream tasks in terms of sample efficiency and distributional\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 11:38:41 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 03:05:47 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Shen", "Xinwei", ""], ["Liu", "Furui", ""], ["Dong", "Hanze", ""], ["Lian", "Qing", ""], ["Chen", "Zhitang", ""], ["Zhang", "Tong", ""]]}, {"id": "2010.02675", "submitter": "Marcel Wien\\\"obst", "authors": "Marcel Wien\\\"obst and Maciej Li\\'skiewicz", "title": "Recovering Causal Structures from Low-Order Conditional Independencies", "comments": null, "journal-ref": "Published in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI'20) New York, New York USA, pp. 10302-10309,\n  AAAI Press, 2020", "doi": "10.1609/aaai.v34i06.6593", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the common obstacles for learning causal models from data is that\nhigh-order conditional independence (CI) relationships between random variables\nare difficult to estimate. Since CI tests with conditioning sets of low order\ncan be performed accurately even for a small number of observations, a\nreasonable approach to determine casual structures is to base merely on the\nlow-order CIs. Recent research has confirmed that, e.g. in the case of sparse\ntrue causal models, structures learned even from zero- and first-order\nconditional independencies yield good approximations of the models. However, a\nchallenging task here is to provide methods that faithfully explain a given set\nof low-order CIs. In this paper, we propose an algorithm which, for a given set\nof conditional independencies of order less or equal to $k$, where $k$ is a\nsmall fixed number, computes a faithful graphical representation of the given\nset. Our results complete and generalize the previous work on learning from\npairwise marginal independencies. Moreover, they enable to improve upon the 0-1\ngraph model which, e.g. is heavily used in the estimation of genome networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:47:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wien\u00f6bst", "Marcel", ""], ["Li\u015bkiewicz", "Maciej", ""]]}, {"id": "2010.02681", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Zhenyu Liao, and Johan A.K. Suykens", "title": "Kernel regression in high dimensions: Refined analysis beyond double\n  descent", "comments": "This paper was accepted by AISTATS-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a precise characterization of generalization\nproperties of high dimensional kernel ridge regression across the under- and\nover-parameterized regimes, depending on whether the number of training data n\nexceeds the feature dimension d. By establishing a bias-variance decomposition\nof the expected excess risk, we show that, while the bias is (almost)\nindependent of d and monotonically decreases with n, the variance depends on n,\nd and can be unimodal or monotonically decreasing under different\nregularization schemes. Our refined analysis goes beyond the double descent\ntheory by showing that, depending on the data eigen-profile and the level of\nregularization, the kernel regression risk curve can be a double-descent-like,\nbell-shaped, or monotonic function of n. Experiments on synthetic and real data\nare conducted to support our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:59:59 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 01:49:15 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Liu", "Fanghui", ""], ["Liao", "Zhenyu", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2010.02709", "submitter": "Agustinus Kristiadi", "authors": "Agustinus Kristiadi, Matthias Hein, Philipp Hennig", "title": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their\n  Asymptotic Overconfidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian treatment can mitigate overconfidence in ReLU nets around the\ntraining data. But far away from them, ReLU Bayesian neural networks (BNNs) can\nstill underestimate uncertainty and thus be asymptotically overconfident. This\nissue arises since the output variance of a BNN with finitely many features is\nquadratic in the distance from the data region. Meanwhile, Bayesian linear\nmodels with ReLU features converge, in the infinite-width limit, to a\nparticular Gaussian process (GP) with a variance that grows cubically so that\nno asymptotic overconfidence can occur. While this may seem of mostly\ntheoretical interest, in this work, we show that it can be used concretely to\nthe benefit of BNNs. We extend finite ReLU BNNs with infinite ReLU features via\nthe GP and show that the resulting model is asymptotically maximally uncertain\nfar away from the data while the BNNs' predictive power is unaffected near the\ndata. Although the resulting model approximates a full GP posterior, thanks to\nits structure, it can be applied post-hoc to any pre-trained ReLU BNN at a low\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 13:32:18 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 16:22:21 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["Hein", "Matthias", ""], ["Hennig", "Philipp", ""]]}, {"id": "2010.02742", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota, Nafisur Rahman, Shahid Saleem Mohammed, Jeffrey\n  Galitz, Ming Liu", "title": "Wound and episode level readmission risk or weeks to readmit: Why do\n  patients get readmitted? How long does it take for a patient to get\n  readmitted?", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Affordable care Act of 2010 had introduced Readmission reduction program\nin 2012 to reduce avoidable re-admissions to control rising healthcare costs.\nWound care impacts 15 of medicare beneficiaries making it one of the major\ncontributors of medicare health care cost. Health plans have been exploring\nproactive health care services that can focus on preventing wound recurrences\nand re-admissions to control the wound care costs. With rising costs of Wound\ncare industry, it has become of paramount importance to reduce wound\nrecurrences & patient re-admissions. What factors are responsible for a Wound\nto recur which ultimately lead to hospitalization or re-admission? Is there a\nway to identify the patients at risk of re-admission before the occurrence\nusing data driven analysis? Patient re-admission risk management has become\ncritical for patients suffering from chronic wounds such as diabetic ulcers,\npressure ulcers, and vascular ulcers. Understanding the risk & the factors that\ncause patient readmission can help care providers and patients avoid wound\nrecurrences. Our work focuses on identifying patients who are at high risk of\nre-admission & determining the time period with in which a patient might get\nre-admitted. Frequent re-admissions add financial stress to the patient &\nHealth plan and deteriorate the quality of life of the patient. Having this\ninformation can allow a provider to set up preventive measures that can delay,\nif not prevent, patients' re-admission. On a combined wound & episode-level\ndata set of patient's wound care information, our extended autoprognosis\nachieves a recall of 92 and a precision of 92 for the predicting a patient's\nre-admission risk. For new patient class, precision and recall are as high as\n91 and 98, respectively. We are also able to predict the patient's discharge\nevent for a re-admission event to occur through our model with a MAE of 2.3\nweeks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 12:49:42 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Rahman", "Nafisur", ""], ["Mohammed", "Shahid Saleem", ""], ["Galitz", "Jeffrey", ""], ["Liu", "Ming", ""]]}, {"id": "2010.02759", "submitter": "Antonio Paiva", "authors": "Antonio R. Paiva and Giovanni Pilloni", "title": "Inferring Microbial Biomass Yield and Cell Weight using Probabilistic\n  Macrochemical Modeling", "comments": "Main article (13 pages, 7 figures, 2 tables); supplementary material\n  (3 pages, 1 figures, 1 code listing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growth rates and biomass yields are key descriptors used in microbiology\nstudies to understand how microbial species respond to changes in the\nenvironment. Of these, biomass yield estimates are typically obtained using\ncell counts and measurements of the feed substrate. These quantities are\nperturbed with measurement noise however. Perhaps most crucially, estimating\nbiomass from cell counts, as needed to assess yields, relies on an assumed cell\nweight. Noise and discrepancies on these assumptions can lead to significant\nchanges in conclusions regarding the microbes' response. This article proposes\na methodology to address these challenges using probabilistic macrochemical\nmodels of microbial growth. It is shown that a model can be developed to fully\nuse the experimental data, relax assumptions and greatly improve robustness to\na priori estimates of the cell weight, and provides uncertainty estimates of\nkey parameters. This methodology is demonstrated in the context of a specific\ncase study and the estimation characteristics are validated in several\nscenarios using synthetically generated microbial growth data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:23:21 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 18:17:12 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 19:42:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Paiva", "Antonio R.", ""], ["Pilloni", "Giovanni", ""]]}, {"id": "2010.02772", "submitter": "Yangsibo Huang", "authors": "Yangsibo Huang, Zhao Song, Kai Li, Sanjeev Arora", "title": "InstaHide: Instance-hiding Schemes for Private Distributed Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  How can multiple distributed entities collaboratively train a shared deep net\non their private data while preserving privacy? This paper introduces\nInstaHide, a simple encryption of training images, which can be plugged into\nexisting distributed deep learning pipelines. The encryption is efficient and\napplying it during training has minor effect on test accuracy.\n  InstaHide encrypts each training image with a \"one-time secret key\" which\nconsists of mixing a number of randomly chosen images and applying a random\npixel-wise mask. Other contributions of this paper include: (a) Using a large\npublic dataset (e.g. ImageNet) for mixing during its encryption, which improves\nsecurity. (b) Experimental results to show effectiveness in preserving privacy\nagainst known attacks with only minor effects on accuracy. (c) Theoretical\nanalysis showing that successfully attacking privacy requires attackers to\nsolve a difficult computational problem. (d) Demonstrating that use of the\npixel-wise mask is important for security, since Mixup alone is shown to be\ninsecure to some some efficient attacks. (e) Release of a challenge dataset\nhttps://github.com/Hazelsuko07/InstaHide_Challenge\n  Our code is available at https://github.com/Hazelsuko07/InstaHide\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:43:23 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:54:19 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Huang", "Yangsibo", ""], ["Song", "Zhao", ""], ["Li", "Kai", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.02784", "submitter": "Zehui Dai", "authors": "Zehui Dai, Cheng Peng, Huajie Chen, and Yadong Ding", "title": "A Multi-Task Incremental Learning Framework with Category Name Embedding\n  for Aspect-Category Sentiment Analysis", "comments": "EMNLP 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (T)ACSA tasks, including aspect-category sentiment analysis (ACSA) and\ntargeted aspect-category sentiment analysis (TACSA), aims at identifying\nsentiment polarity on predefined categories. Incremental learning on new\ncategories is necessary for (T)ACSA real applications. Though current\nmulti-task learning models achieve good performance in (T)ACSA tasks, they\nsuffer from catastrophic forgetting problems in (T)ACSA incremental learning\ntasks. In this paper, to make multi-task learning feasible for incremental\nlearning, we proposed Category Name Embedding network (CNE-net). We set both\nencoder and decoder shared among all categories to weaken the catastrophic\nforgetting problem. Besides the origin input sentence, we applied another input\nfeature, i.e., category name, for task discrimination. Our model achieved\nstate-of-the-art on two (T)ACSA benchmark datasets. Furthermore, we proposed a\ndataset for (T)ACSA incremental learning and achieved the best performance\ncompared with other strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:52:54 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Dai", "Zehui", ""], ["Peng", "Cheng", ""], ["Chen", "Huajie", ""], ["Ding", "Yadong", ""]]}, {"id": "2010.02804", "submitter": "Manuel Mager", "authors": "Manuel Mager, \\\"Ozlem \\c{C}etino\\u{g}lu and Katharina Kann", "title": "Tackling the Low-resource Challenge for Canonical Segmentation", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Canonical morphological segmentation consists of dividing words into their\nstandardized morphemes. Here, we are interested in approaches for the task when\ntraining data is limited. We compare model performance in a simulated\nlow-resource setting for the high-resource languages German, English, and\nIndonesian to experiments on new datasets for the truly low-resource languages\nPopoluca and Tepehua. We explore two new models for the task, borrowing from\nthe closely related area of morphological generation: an LSTM pointer-generator\nand a sequence-to-sequence model with hard monotonic attention trained with\nimitation learning. We find that, in the low-resource setting, the novel\napproaches outperform existing ones on all languages by up to 11.4% accuracy.\nHowever, while accuracy in emulated low-resource scenarios is over 50% for all\nlanguages, for the truly low-resource languages Popoluca and Tepehua, our best\nmodel only obtains 37.4% and 28.4% accuracy, respectively. Thus, we conclude\nthat canonical segmentation is still a challenging task for low-resource\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:15:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Mager", "Manuel", ""], ["\u00c7etino\u011flu", "\u00d6zlem", ""], ["Kann", "Katharina", ""]]}, {"id": "2010.02888", "submitter": "Kavya Ravichandran", "authors": "Maryam Aliakbarpour, Amartya Shankha Biswas, Kavya Ravichandran,\n  Ronitt Rubinfeld", "title": "Testing Tail Weight of a Distribution Via Hazard Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the shape of a distribution of data is of interest to people in\na great variety of fields, as it may affect the types of algorithms used for\nthat data. Given samples from a distribution, we seek to understand how many\nelements appear infrequently, that is, to characterize the tail of the\ndistribution. We develop an algorithm based on a careful bucketing scheme that\ndistinguishes heavy-tailed distributions from non-heavy-tailed ones via a\ndefinition based on the hazard rate under some natural smoothness and ordering\nassumptions. We verify our theoretical results empirically.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 17:13:14 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Aliakbarpour", "Maryam", ""], ["Biswas", "Amartya Shankha", ""], ["Ravichandran", "Kavya", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "2010.02917", "submitter": "Jyoti Aneja", "authors": "Jyoti Aneja, Alexander Schwing, Jan Kautz, Arash Vahdat", "title": "NCP-VAE: Variational Autoencoders with Noise Contrastive Priors", "comments": "22 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are one of the powerful likelihood-based\ngenerative models with applications in various domains. However, they struggle\nto generate high-quality images, especially when samples are obtained from the\nprior without any tempering. One explanation for VAEs' poor generative quality\nis the prior hole problem: the prior distribution fails to match the aggregate\napproximate posterior. Due to this mismatch, there exist areas in the latent\nspace with high density under the prior that do not correspond to any encoded\nimage. Samples from those areas are decoded to corrupted images. To tackle this\nissue, we propose an energy-based prior defined by the product of a base prior\ndistribution and a reweighting factor, designed to bring the base closer to the\naggregate posterior. We train the reweighting factor by noise contrastive\nestimation, and we generalize it to hierarchical VAEs with many latent variable\ngroups. Our experiments confirm that the proposed noise contrastive priors\nimprove the generative performance of state-of-the-art VAEs by a large margin\non the MNIST, CIFAR-10, CelebA 64, and CelebA HQ 256 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 17:59:02 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Aneja", "Jyoti", ""], ["Schwing", "Alexander", ""], ["Kautz", "Jan", ""], ["Vahdat", "Arash", ""]]}, {"id": "2010.02921", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "Attention augmented differentiable forest for tabular data", "comments": "8 pages,4 figures. arXiv admin note: text overlap with\n  arXiv:2003.00223", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable forest is an ensemble of decision trees with full\ndifferentiability. Its simple tree structure is easy to use and explain. With\nfull differentiability, it would be trained in the end-to-end learning\nframework with gradient-based optimization method. In this paper, we propose\ntree attention block(TAB) in the framework of differentiable forest. TAB block\nhas two operations, squeeze and regulate. The squeeze operation would extract\nthe characteristic of each tree. The regulate operation would learn nonlinear\nrelations between these trees. So TAB block would learn the importance of each\ntree and adjust its weight to improve accuracy. Our experiment on large tabular\ndataset shows attention augmented differentiable forest would get comparable\naccuracy with gradient boosted decision trees(GBDT), which is the\nstate-of-the-art algorithm for tabular datasets. And on some datasets, our\nmodel has higher accuracy than best GBDT libs (LightGBM, Catboost, and\nXGBoost). Differentiable forest model supports batch training and batch size is\nmuch smaller than the size of training set. So on larger data sets, its memory\nusage is much lower than GBDT model. The source codes are available at\nhttps://github.com/closest-git/QuantumForest.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 11:42:33 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2010.02968", "submitter": "Georgios Papayiannis", "authors": "Georgios I. Papayiannis, Stelios Psarakis, Athanasios N. Yannacopoulos", "title": "Statistical monitoring of functional data using the notion of Fr\\'echet\n  mean combined with the framework of the deformation models", "comments": "31 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to investigate possible advances obtained by the\nimplementation of the framework of Fr\\'echet mean and the generalized sense of\nmean that it offers, in the field of statistical process monitoring and\ncontrol. In particular, the case of non-linear profiles which are described by\ndata in functional form is considered and a framework combining the notion of\nFr\\'echet mean and deformation models is developed. The proposed monitoring\napproach is implemented to the intra-day air pollution monitoring task in the\ncity of Athens where the capabilities and advantages of the method are\nillustrated.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 18:49:51 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Papayiannis", "Georgios I.", ""], ["Psarakis", "Stelios", ""], ["Yannacopoulos", "Athanasios N.", ""]]}, {"id": "2010.03002", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Marek \\'Smieja, Marcin Sendera, {\\L}ukasz Struski,\n  Jacek Tabor, Przemys{\\l}aw Spurek", "title": "Flow-based Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose OneFlow - a flow-based one-class classifier for anomaly (outliers)\ndetection that finds a minimal volume bounding region. Contrary to\ndensity-based methods, OneFlow is constructed in such a way that its result\ntypically does not depend on the structure of outliers. This is caused by the\nfact that during training the gradient of the cost function is propagated only\nover the points located near to the decision boundary (behavior similar to the\nsupport vectors in SVM). The combination of flow models and Bernstein quantile\nestimator allows OneFlow to find a parametric form of bounding region, which\ncan be useful in various applications including describing shapes from 3D point\nclouds. Experiments show that the proposed model outperforms related methods on\nreal-world anomaly detection problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 20:09:11 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 08:41:06 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["\u015amieja", "Marek", ""], ["Sendera", "Marcin", ""], ["Struski", "\u0141ukasz", ""], ["Tabor", "Jacek", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "2010.03029", "submitter": "Paul Westermann", "authors": "Paul Westermann and Ralph Evins", "title": "Using Bayesian deep learning approaches for uncertainty-aware building\n  energy surrogate models", "comments": "Submitted to Energy and AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast machine learning-based surrogate models are trained to emulate slow,\nhigh-fidelity engineering simulation models to accelerate engineering design\ntasks. This introduces uncertainty as the surrogate is only an approximation of\nthe original model.\n  Bayesian methods can quantify that uncertainty, and deep learning models\nexist that follow the Bayesian paradigm. These models, namely Bayesian neural\nnetworks and Gaussian process models, enable us to give predictions together\nwith an estimate of the model's uncertainty. As a result we can derive\nuncertainty-aware surrogate models that can automatically suspect unseen design\nsamples that cause large emulation errors. For these samples, the high-fidelity\nmodel can be queried instead. This outlines how the Bayesian paradigm allows us\nto hybridize fast, but approximate, and slow, but accurate models.\n  In this paper, we train two types of Bayesian models, dropout neural networks\nand stochastic variational Gaussian Process models, to emulate a complex high\ndimensional building energy performance simulation problem. The surrogate model\nprocesses 35 building design parameters (inputs) to estimate 12 different\nperformance metrics (outputs). We benchmark both approaches, prove their\naccuracy to be competitive, and show that errors can be reduced by up to 30%\nwhen the 10% of samples with the highest uncertainty are transferred to the\nhigh-fidelity model.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 15:04:18 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Westermann", "Paul", ""], ["Evins", "Ralph", ""]]}, {"id": "2010.03104", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin and David Simchi-Levi and\n  Yunzong Xu", "title": "Instance-Dependent Complexity of Contextual Bandits and Reinforcement\n  Learning: A Disagreement-Based Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical multi-armed bandit problem, instance-dependent algorithms\nattain improved performance on \"easy\" problems with a gap between the best and\nsecond-best arm. Are similar guarantees possible for contextual bandits? While\npositive results are known for certain special cases, there is no general\ntheory characterizing when and how instance-dependent regret bounds for\ncontextual bandits can be achieved for rich, general classes of policies. We\nintroduce a family of complexity measures that are both sufficient and\nnecessary to obtain instance-dependent regret bounds. We then introduce new\noracle-efficient algorithms which adapt to the gap whenever possible, while\nalso attaining the minimax rate in the worst case. Finally, we provide\nstructural results that tie together a number of complexity measures previously\nproposed throughout contextual bandits, reinforcement learning, and active\nlearning and elucidate their role in determining the optimal instance-dependent\nregret. In a large-scale empirical evaluation, we find that our approach often\ngives superior results for challenging exploration problems.\n  Turning our focus to reinforcement learning with function approximation, we\ndevelop new oracle-efficient algorithms for reinforcement learning with rich\nobservations that obtain optimal gap-dependent sample complexity.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 01:33:06 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""], ["Simchi-Levi", "David", ""], ["Xu", "Yunzong", ""]]}, {"id": "2010.03106", "submitter": "Kevin Tian", "authors": "Yin Tat Lee, Ruoqi Shen, Kevin Tian", "title": "Structured Logconcave Sampling with a Restricted Gaussian Oracle", "comments": "56 pages. The results of Section 5 of this paper, as well as an\n  empirical evaluation, appeared earlier as arXiv:2006.05976. Updated version\n  polishes exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms for sampling several structured logconcave families to\nhigh accuracy. We further develop a reduction framework, inspired by proximal\npoint methods in convex optimization, which bootstraps samplers for regularized\ndensities to improve dependences on problem conditioning. A key ingredient in\nour framework is the notion of a \"restricted Gaussian oracle\" (RGO) for $g:\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$, which is a sampler for distributions\nwhose negative log-likelihood sums a quadratic and $g$. By combining our\nreduction framework with our new samplers, we obtain the following bounds for\nsampling structured distributions to total variation distance $\\epsilon$. For\ncomposite densities $\\exp(-f(x) - g(x))$, where $f$ has condition number\n$\\kappa$ and convex (but possibly non-smooth) $g$ admits an RGO, we obtain a\nmixing time of $O(\\kappa d \\log^3\\frac{\\kappa d}{\\epsilon})$, matching the\nstate-of-the-art non-composite bound; no composite samplers with better mixing\nthan general-purpose logconcave samplers were previously known. For logconcave\nfinite sums $\\exp(-F(x))$, where $F(x) = \\frac{1}{n}\\sum_{i \\in [n]} f_i(x)$\nhas condition number $\\kappa$, we give a sampler querying $\\widetilde{O}(n +\n\\kappa\\max(d, \\sqrt{nd}))$ gradient oracles to $\\{f_i\\}_{i \\in [n]}$; no\nhigh-accuracy samplers with nontrivial gradient query complexity were\npreviously known. For densities with condition number $\\kappa$, we give an\nalgorithm obtaining mixing time $O(\\kappa d \\log^2\\frac{\\kappa d}{\\epsilon})$,\nimproving the prior state-of-the-art by a logarithmic factor with a\nsignificantly simpler analysis; we also show a zeroth-order algorithm attains\nthe same query complexity.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 01:43:07 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 20:17:48 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 02:19:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lee", "Yin Tat", ""], ["Shen", "Ruoqi", ""], ["Tian", "Kevin", ""]]}, {"id": "2010.03111", "submitter": "Eric Lock", "authors": "Eric F. Lock", "title": "Bayesian Distance Weighted Discrimination", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance weighted discrimination (DWD) is a linear discrimination method that\nis particularly well-suited for classification tasks with high-dimensional\ndata. The DWD coefficients minimize an intuitive objective function, which can\nsolved very efficiently using state-of-the-art optimization techniques.\nHowever, DWD has not yet been cast into a model-based framework for statistical\ninference. In this article we show that DWD identifies the mode of a proper\nBayesian posterior distribution, that results from a particular link function\nfor the class probabilities and a shrinkage-inducing proper prior distribution\non the coefficients. We describe a relatively efficient Markov chain Monte\nCarlo (MCMC) algorithm to simulate from the true posterior under this Bayesian\nframework. We show that the posterior is asymptotically normal and derive the\nmean and covariance matrix of its limiting distribution. Through several\nsimulation studies and an application to breast cancer genomics we demonstrate\nhow the Bayesian approach to DWD can be used to (1) compute well-calibrated\nposterior class probabilities, (2) assess uncertainty in the DWD coefficients\nand resulting sample scores, (3) improve power via semi-supervised analysis\nwhen not all class labels are available, and (4) automatically determine a\npenalty tuning parameter within the model-based framework. R code to perform\nBayesian DWD is available at https://github.com/lockEF/BayesianDWD .\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 02:15:04 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Lock", "Eric F.", ""]]}, {"id": "2010.03130", "submitter": "Xueqin Wang", "authors": "Jin Zhu, Wangwei Wu, Yuting Zhang, Shiyun Lin, Yukang Jiang, Ruixian\n  Liu, Xueqin Wang", "title": "Computational analysis of pathological image enables interpretable\n  prediction for microsatellite instability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Microsatellite instability (MSI) is associated with several tumor types and\nits status has become increasingly vital in guiding patient treatment\ndecisions. However, in clinical practice, distinguishing MSI from its\ncounterpart is challenging since the diagnosis of MSI requires additional\ngenetic or immunohistochemical tests. In this study, interpretable pathological\nimage analysis strategies are established to help medical experts to\nautomatically identify MSI. The strategies only require ubiquitous Haematoxylin\nand eosin-stained whole-slide images and can achieve decent performance in the\nthree cohorts collected from The Cancer Genome Atlas. The strategies provide\ninterpretability in two aspects. On the one hand, the image-level\ninterpretability is achieved by generating localization heat maps of important\nregions based on the deep learning network; on the other hand, the\nfeature-level interpretability is attained through feature importance and\npathological feature interaction analysis. More interestingly, both from the\nimage-level and feature-level interpretability, color features and texture\ncharacteristics are shown to contribute the most to the MSI predictions.\nTherefore, the classification models under the proposed strategies can not only\nserve as an efficient tool for predicting the MSI status of patients, but also\nprovide more insights to pathologists with clinical understanding.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 03:05:05 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Zhu", "Jin", ""], ["Wu", "Wangwei", ""], ["Zhang", "Yuting", ""], ["Lin", "Shiyun", ""], ["Jiang", "Yukang", ""], ["Liu", "Ruixian", ""], ["Wang", "Xueqin", ""]]}, {"id": "2010.03133", "submitter": "Zhiyu Zhang", "authors": "Zhiyu Zhang, Ioannis Paschalidis", "title": "Provable Hierarchical Imitation Learning via EM", "comments": "To appear in AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to recent empirical successes, the options framework for hierarchical\nreinforcement learning is gaining increasing popularity. Rather than learning\nfrom rewards which suffers from the curse of dimensionality, we consider\nlearning an options-type hierarchical policy from expert demonstrations. Such a\nproblem is referred to as hierarchical imitation learning. Converting this\nproblem to parameter inference in a latent variable model, we theoretically\ncharacterize the EM approach proposed by Daniel et al. (2016). The population\nlevel algorithm is analyzed as an intermediate step, which is nontrivial due to\nthe samples being correlated. If the expert policy can be parameterized by a\nvariant of the options framework, then under regularity conditions, we prove\nthat the proposed algorithm converges with high probability to a norm ball\naround the true parameter. To our knowledge, this is the first performance\nguarantee for an hierarchical imitation learning algorithm that only observes\nprimitive state-action pairs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 03:21:57 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 04:01:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Zhiyu", ""], ["Paschalidis", "Ioannis", ""]]}, {"id": "2010.03161", "submitter": "Weichao Mao", "authors": "Weichao Mao, Kaiqing Zhang, Ruihao Zhu, David Simchi-Levi, Tamer\n  Ba\\c{s}ar", "title": "Model-Free Non-Stationary RL: Near-Optimal Regret and Applications in\n  Multi-Agent RL and Inventory Control", "comments": "A preliminary version of this work has appeared in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider model-free reinforcement learning (RL) in non-stationary Markov\ndecision processes. Both the reward functions and the state transition\nfunctions are allowed to vary arbitrarily over time as long as their cumulative\nvariations do not exceed certain variation budgets. We propose Restarted\nQ-Learning with Upper Confidence Bounds (RestartQ-UCB), the first model-free\nalgorithm for non-stationary RL, and show that it outperforms existing\nsolutions in terms of dynamic regret. Specifically, RestartQ-UCB with\nFreedman-type bonus terms achieves a dynamic regret bound of\n$\\widetilde{O}(S^{\\frac{1}{3}} A^{\\frac{1}{3}} \\Delta^{\\frac{1}{3}} H\nT^{\\frac{2}{3}})$, where $S$ and $A$ are the numbers of states and actions,\nrespectively, $\\Delta>0$ is the variation budget, $H$ is the number of time\nsteps per episode, and $T$ is the total number of time steps. We further\npresent a parameter-free algorithm named Double-Restart Q-UCB that does not\nrequire prior knowledge of the variation budget. We show that our algorithms\nare \\emph{nearly optimal} by establishing an information-theoretical lower\nbound of $\\Omega(S^{\\frac{1}{3}} A^{\\frac{1}{3}} \\Delta^{\\frac{1}{3}}\nH^{\\frac{2}{3}} T^{\\frac{2}{3}})$, the first lower bound in non-stationary RL.\nNumerical experiments validate the advantages of RestartQ-UCB in terms of both\ncumulative rewards and computational efficiency. We demonstrate the power of\nour results in examples of multi-agent RL and inventory control across related\nproducts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 04:55:56 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 22:42:44 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 05:58:24 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mao", "Weichao", ""], ["Zhang", "Kaiqing", ""], ["Zhu", "Ruihao", ""], ["Simchi-Levi", "David", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2010.03171", "submitter": "Xingchen Ma", "authors": "Xingchen Ma, Matthew B. Blaschko", "title": "Additive Tree-Structured Conditional Parameter Spaces in Bayesian\n  Optimization: A Novel Covariance Function and a Fast Implementation", "comments": "Code available at https://github.com/maxc01/addtree. arXiv admin\n  note: substantial text overlap with arXiv:2006.11771", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3026019", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a sample-efficient global optimization\nalgorithm for black-box functions which are expensive to evaluate. Existing\nliterature on model based optimization in conditional parameter spaces are\nusually built on trees. In this work, we generalize the additive assumption to\ntree-structured functions and propose an additive tree-structured covariance\nfunction, showing improved sample-efficiency, wider applicability and greater\nflexibility. Furthermore, by incorporating the structure information of\nparameter spaces and the additive assumption in the BO loop, we develop a\nparallel algorithm to optimize the acquisition function and this optimization\ncan be performed in a low dimensional space. We demonstrate our method on an\noptimization benchmark function, on a neural network compression problem, on\npruning pre-trained VGG16 and ResNet50 models as well as on searching\nactivation functions of ResNet20. Experimental results show our approach\nsignificantly outperforms the current state of the art for conditional\nparameter optimization including SMAC, TPE and Jenatton et al. (2017).\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:08:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Ma", "Xingchen", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "2010.03227", "submitter": "Karen Seidel", "authors": "Ardalan Khazraei, Timo K\\\"otzing, Karen Seidel", "title": "Learning Half-Spaces and other Concept Classes in the Limit with\n  Iterative Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to model an efficient learning paradigm, iterative learning\nalgorithms access data one by one, updating the current hypothesis without\nregress to past data. Past research on iterative learning analyzed for example\nmany important additional requirements and their impact on iterative learners.\nIn this paper, our results are twofold. First, we analyze the relative learning\npower of various settings of iterative learning, including learning from text\nand from informant, as well as various further restrictions, for example we\nshow that strongly non-U-shaped learning is restrictive for iterative learning\nfrom informant. Second, we investigate the learnability of the concept class of\nhalf-spaces and provide a constructive iterative algorithm to learn the set of\nhalf-spaces from informant.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:20:50 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 10:57:50 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Khazraei", "Ardalan", ""], ["K\u00f6tzing", "Timo", ""], ["Seidel", "Karen", ""]]}, {"id": "2010.03228", "submitter": "Souradip Chakraborty Mr", "authors": "Souradip Chakraborty, Ekansh Verma, Saswata Sahoo, Jyotishka Datta", "title": "FairMixRep : Self-supervised Robust Representation Learning for\n  Heterogeneous Data with Fairness constraints", "comments": "This paper has been accepted at the ICDM'2020 DLC Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation Learning in a heterogeneous space with mixed variables of\nnumerical and categorical types has interesting challenges due to its complex\nfeature manifold. Moreover, feature learning in an unsupervised setup, without\nclass labels and a suitable learning loss function, adds to the problem\ncomplexity. Further, the learned representation and subsequent predictions\nshould not reflect discriminatory behavior towards certain sensitive groups or\nattributes. The proposed feature map should preserve maximum variations present\nin the data and needs to be fair with respect to the sensitive variables. We\npropose, in the first phase of our work, an efficient encoder-decoder framework\nto capture the mixed-domain information. The second phase of our work focuses\non de-biasing the mixed space representations by adding relevant fairness\nconstraints. This ensures minimal information loss between the representations\nbefore and after the fairness-preserving projections. Both the information\ncontent and the fairness aspect of the final representation learned has been\nvalidated through several metrics where it shows excellent performance. Our\nwork (FairMixRep) addresses the problem of Mixed Space Fair Representation\nlearning from an unsupervised perspective and learns a Universal representation\nthat is timely, unique, and a novel research contribution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:23:02 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 06:12:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Chakraborty", "Souradip", ""], ["Verma", "Ekansh", ""], ["Sahoo", "Saswata", ""], ["Datta", "Jyotishka", ""]]}, {"id": "2010.03242", "submitter": "Marin Bilo\\v{s}", "authors": "Marin Bilo\\v{s}, Stephan G\\\"unnemann", "title": "Scalable Normalizing Flows for Permutation Invariant Densities", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling sets is an important problem in machine learning since this type of\ndata can be found in many domains. A promising approach defines a family of\npermutation invariant densities with continuous normalizing flows. This allows\nus to maximize the likelihood directly and sample new realizations with ease.\nIn this work, we demonstrate how calculating the trace, a crucial step in this\nmethod, raises issues that occur both during training and inference, limiting\nits practicality. We propose an alternative way of defining permutation\nequivariant transformations that give closed form trace. This leads not only to\nimprovements while training, but also to better final performance. We\ndemonstrate the benefits of our approach on point processes and general set\nmodeling.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:51:30 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 10:50:02 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bilo\u0161", "Marin", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2010.03268", "submitter": "Davood Zabihzadeh", "authors": "Davood Zabihzadeh, Amar Tuama, Ali Karami-Mollaee", "title": "Low-Rank Robust Online Distance/Similarity Learning based on the\n  Rescaled Hinge Loss", "comments": "An Online Distance-Similarity learning approach in noisy environment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge in metric learning is scalability to both size and\ndimension of input data. Online metric learning algorithms are proposed to\naddress this challenge. Existing methods are commonly based on (Passive\nAggressive) PA approach. Hence, they can rapidly process large volumes of data\nwith an adaptive learning rate. However, these algorithms are based on the\nHinge loss and so are not robust against outliers and label noise. Also,\nexisting online methods usually assume training triplets or pairwise\nconstraints are exist in advance. However, many datasets in real-world\napplications are in the form of input data and their associated labels. We\naddress these challenges by formulating the online Distance-Similarity learning\nproblem with the robust Rescaled hinge loss function. The proposed model is\nrather general and can be applied to any PA-based online Distance-Similarity\nalgorithm. Also, we develop an efficient robust one-pass triplet construction\nalgorithm. Finally, to provide scalability in high dimensional DML\nenvironments, the low-rank version of the proposed methods is presented that\nnot only reduces the computational cost significantly but also keeps the\npredictive performance of the learned metrics. Also, it provides a\nstraightforward extension of our methods for deep Distance-Similarity learning.\nWe conduct several experiments on datasets from various applications. The\nresults confirm that the proposed methods significantly outperform\nstate-of-the-art online DML methods in the presence of label noise and outliers\nby a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 08:38:34 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 09:30:36 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zabihzadeh", "Davood", ""], ["Tuama", "Amar", ""], ["Karami-Mollaee", "Ali", ""]]}, {"id": "2010.03281", "submitter": "Taehwan Kwon", "authors": "Taehwan Kwon", "title": "Variational Intrinsic Control Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit variational intrinsic control (VIC), an\nunsupervised reinforcement learning method for finding the largest set of\nintrinsic options available to an agent. In the original work by Gregor et al.\n(2016), two VIC algorithms were proposed: one that represents the options\nexplicitly, and the other that does it implicitly. We show that the intrinsic\nreward used in the latter is subject to bias in stochastic environments,\ncausing convergence to suboptimal solutions. To correct this behavior and\nachieve the maximal empowerment, we propose two methods respectively based on\nthe transitional probability model and Gaussian mixture model. We substantiate\nour claims through rigorous mathematical derivations and experimental analyses.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 09:00:48 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:49:17 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Kwon", "Taehwan", ""]]}, {"id": "2010.03316", "submitter": "Philipp Benz", "authors": "Philipp Benz, Chaoning Zhang, In So Kweon", "title": "Batch Normalization Increases Adversarial Vulnerability: Disentangling\n  Usefulness and Robustness of Model Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization (BN) has been widely used in modern deep neural networks\n(DNNs) due to fast convergence. BN is observed to increase the model accuracy\nwhile at the cost of adversarial robustness. We conjecture that the increased\nadversarial vulnerability is caused by BN shifting the model to rely more on\nnon-robust features (NRFs). Our exploration finds that other normalization\ntechniques also increase adversarial vulnerability and our conjecture is also\nsupported by analyzing the model corruption robustness and feature\ntransferability. With a classifier DNN defined as a feature set $F$ we propose\na framework for disentangling $F$ robust usefulness into $F$ usefulness and $F$\nrobustness. We adopt a local linearity based metric, termed LIGS, to define and\nquantify $F$ robustness. Measuring the $F$ robustness with the LIGS provides\ndirect insight on the feature robustness shift independent of usefulness.\nMoreover, the LIGS trend during the whole training stage sheds light on the\norder of learned features, i.e. from RFs (robust features) to NRFs, or vice\nversa. Our work analyzes how BN and other factors influence the DNN from the\nfeature perspective. Prior works mainly adopt accuracy to evaluate their\ninfluence regarding $F$ usefulness, while we believe evaluating $F$ robustness\nis equally important, for which our work fills the gap.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 10:24:33 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Benz", "Philipp", ""], ["Zhang", "Chaoning", ""], ["Kweon", "In So", ""]]}, {"id": "2010.03322", "submitter": "KeKe Li", "authors": "Li Keke and Zhang Ke and Liu Qiang and Yang Xinmin", "title": "Training GANs with predictive projection centripetal acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although remarkable successful in practice, training generative adversarial\nnetworks(GANs) is still quite difficult and iteratively prone to cyclic\nbehaviors, as GANs need to solve a non-convex non-concave min-max game using a\ngradient descent ascent (GDA) method. Motivated by the ideas of simultaneous\ncentripetal acceleration (SCA) and modified predictive methods (MPM), we\npropose a novel predictive projection centripetal acceleration (PPCA) methods\nto alleviate the cyclic behaviors. Besides, under suitable assumptions, we show\nthat the difference between the signed vector of partial derivatives at t + 1\nand t is orthogonal to the signed vector of partial derivatives at t for GDA,\nand the last-iterate exponential convergence on the bilinear game. Finally,\nnumerical simulations are conducted by PPCA in GANs setting, and the results\nillustrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 10:48:18 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 17:43:39 GMT"}], "update_date": "2020-10-10", "authors_parsed": [["Keke", "Li", ""], ["Ke", "Zhang", ""], ["Qiang", "Liu", ""], ["Xinmin", "Yang", ""]]}, {"id": "2010.03374", "submitter": "Peter Yatsyshin Dr", "authors": "Peter Yatsyshin, Serafim Kalliadasis and Andrew B. Duncan", "title": "Physics-constrained Bayesian inference of state functions in classical\n  density-functional theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel data-driven approach to the inverse problem of classical\nstatistical mechanics: given experimental data on the collective motion of a\nclassical many-body system, how does one characterise the free energy landscape\nof that system? By combining non-parametric Bayesian inference with\nphysically-motivated constraints, we develop an efficient learning algorithm\nwhich automates the construction of approximate free energy functionals. In\ncontrast to optimisation-based machine learning approaches, which seek to\nminimise a cost function, the central idea of the proposed Bayesian inference\nis to propagate a set of prior assumptions through the model, derived from\nphysical principles. The experimental data is used to probabilistically weigh\nthe possible model predictions. This naturally leads to humanly interpretable\nalgorithms with full uncertainty quantification of predictions. In our case,\nthe output of the learning algorithm is a probability distribution over a\nfamily of free energy functionals, consistent with the observed particle data.\nWe find that surprisingly small data samples contain sufficient information for\ninferring highly accurate analytic expressions of the underlying free energy\nfunctionals, making our algorithm highly data efficient. We consider excluded\nvolume particle interactions, which are ubiquitous in nature, whilst being\nhighly challenging for modelling in terms of free energy. To validate our\napproach we consider the paradigmatic case of one-dimensional fluid and develop\ninference algorithms for the canonical and grand-canonical\nstatistical-mechanical ensembles. Extensions to higher-dimensional systems are\nconceptually straightforward, whilst standard coarse-graining techniques allow\none to easily incorporate attractive interactions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 12:43:42 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 17:50:19 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 17:20:40 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 10:28:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Yatsyshin", "Peter", ""], ["Kalliadasis", "Serafim", ""], ["Duncan", "Andrew B.", ""]]}, {"id": "2010.03459", "submitter": "Benoit Gaujac", "authors": "Benoit Gaujac and Ilya Feige and David Barber", "title": "Learning disentangled representations with the Wasserstein Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled representation learning has undoubtedly benefited from objective\nfunction surgery. However, a delicate balancing act of tuning is still required\nin order to trade off reconstruction fidelity versus disentanglement. Building\non previous successes of penalizing the total correlation in the latent\nvariables, we propose TCWAE (Total Correlation Wasserstein Autoencoder).\nWorking in the WAE paradigm naturally enables the separation of the\ntotal-correlation term, thus providing disentanglement control over the learned\nrepresentation, while offering more flexibility in the choice of reconstruction\ncost. We propose two variants using different KL estimators and perform\nextensive quantitative comparisons on data sets with known generative factors,\nshowing competitive results relative to state-of-the-art techniques. We further\nstudy the trade off between disentanglement and reconstruction on\nmore-difficult data sets with unknown generative factors, where the flexibility\nof the WAE paradigm in the reconstruction term improves reconstructions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:52:06 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Gaujac", "Benoit", ""], ["Feige", "Ilya", ""], ["Barber", "David", ""]]}, {"id": "2010.03460", "submitter": "Marco Mondelli", "authors": "Marco Mondelli and Ramji Venkataramanan", "title": "Approximate Message Passing with Spectral Initialization for Generalized\n  Linear Models", "comments": "38 pages, 5 figures, AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a signal from measurements obtained via\na generalized linear model. We focus on estimators based on approximate message\npassing (AMP), a family of iterative algorithms with many appealing features:\nthe performance of AMP in the high-dimensional limit can be succinctly\ncharacterized under suitable model assumptions; AMP can also be tailored to the\nempirical distribution of the signal entries, and for a wide class of\nestimation problems, AMP is conjectured to be optimal among all polynomial-time\nalgorithms.\n  However, a major issue of AMP is that in many models (such as phase\nretrieval), it requires an initialization correlated with the ground-truth\nsignal and independent from the measurement matrix. Assuming that such an\ninitialization is available is typically not realistic. In this paper, we solve\nthis problem by proposing an AMP algorithm initialized with a spectral\nestimator. With such an initialization, the standard AMP analysis fails since\nthe spectral estimator depends in a complicated way on the design matrix. Our\nmain contribution is a rigorous characterization of the performance of AMP with\nspectral initialization in the high-dimensional limit. The key technical idea\nis to define and analyze a two-phase artificial AMP algorithm that first\nproduces the spectral estimator, and then closely approximates the iterates of\nthe true AMP. We also provide numerical results that demonstrate the validity\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:52:35 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 09:43:24 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Mondelli", "Marco", ""], ["Venkataramanan", "Ramji", ""]]}, {"id": "2010.03467", "submitter": "Benoit Gaujac", "authors": "Benoit Gaujac and Ilya Feige and David Barber", "title": "Learning Deep-Latent Hierarchies by Stacking Wasserstein Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models with hierarchical-latent-variable structures provide\nstate-of-the-art results amongst non-autoregressive, unsupervised density-based\nmodels. However, the most common approach to training such models based on\nVariational Autoencoders (VAEs) often fails to leverage deep-latent\nhierarchies; successful approaches require complex inference and optimisation\nschemes. Optimal Transport is an alternative, non-likelihood-based framework\nfor training generative models with appealing theoretical properties, in\nprinciple allowing easier training convergence between distributions. In this\nwork we propose a novel approach to training models with deep-latent\nhierarchies based on Optimal Transport, without the need for highly bespoke\nmodels and inference networks. We show that our method enables the generative\nmodel to fully leverage its deep-latent hierarchy, avoiding the well known\n\"latent variable collapse\" issue of VAEs; therefore, providing qualitatively\nbetter sample generations as well as more interpretable latent representation\nthan the original Wasserstein Autoencoder with Maximum Mean Discrepancy\ndivergence.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 15:04:20 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Gaujac", "Benoit", ""], ["Feige", "Ilya", ""], ["Barber", "David", ""]]}, {"id": "2010.03485", "submitter": "Feras Saad", "authors": "Feras A. Saad, Martin C. Rinard, Vikash K. Mansinghka", "title": "SPPL: Probabilistic Programming with Fast Exact Symbolic Inference", "comments": null, "journal-ref": "Proceedings of the 42nd ACM SIGPLAN International Conference on\n  Programming Language Design and Implementation (PLDI '21), June 20-25, 2021,\n  Virtual, Canada. ACM, New York, NY, USA", "doi": "10.1145/3453483.3454078", "report-no": null, "categories": "cs.PL cs.LG cs.SC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic\nprogramming language that automatically delivers exact solutions to a broad\nrange of probabilistic inference queries. SPPL translates probabilistic\nprograms into sum-product expressions, a new symbolic representation and\nassociated semantic domain that extends standard sum-product networks to\nsupport mixed-type distributions, numeric transformations, logical formulas,\nand pointwise and set-valued constraints. We formalize SPPL via a novel\ntranslation strategy from probabilistic programs to sum-product expressions and\ngive sound exact algorithms for conditioning on and computing probabilities of\nevents. SPPL imposes a collection of restrictions on probabilistic programs to\nensure they can be translated into sum-product expressions, which allow the\nsystem to leverage new techniques for improving the scalability of translation\nand inference by automatically exploiting probabilistic structure. We implement\na prototype of SPPL with a modular architecture and evaluate it on benchmarks\nthe system targets, showing that it obtains up to 3500x speedups over\nstate-of-the-art symbolic systems on tasks such as verifying the fairness of\ndecision tree classifiers, smoothing hidden Markov models, conditioning\ntransformed random variables, and computing rare event probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 15:42:37 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 07:29:46 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 12:21:13 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Saad", "Feras A.", ""], ["Rinard", "Martin C.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "2010.03522", "submitter": "Mike Huisman", "authors": "Mike Huisman and Jan N. van Rijn and Aske Plaat", "title": "A Survey of Deep Meta-Learning", "comments": "Published in the AI Review (AIRE) Journal (2021)", "journal-ref": null, "doi": "10.1007/s10462-021-10004-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can achieve great successes when presented with large\ndata sets and sufficient computational resources. However, their ability to\nlearn new concepts quickly is limited. Meta-learning is one approach to address\nthis issue, by enabling the network to learn how to learn. The field of Deep\nMeta-Learning advances at great speed, but lacks a unified, in-depth overview\nof current techniques. With this work, we aim to bridge this gap. After\nproviding the reader with a theoretical foundation, we investigate and\nsummarize key methods, which are categorized into i)~metric-, ii)~model-, and\niii)~optimization-based techniques. In addition, we identify the main open\nchallenges, such as performance evaluations on heterogeneous benchmarks, and\nreduction of the computational costs of meta-learning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:09:02 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 13:33:40 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Huisman", "Mike", ""], ["van Rijn", "Jan N.", ""], ["Plaat", "Aske", ""]]}, {"id": "2010.03531", "submitter": "Omar Darwiche Domingues", "authors": "Omar Darwiche Domingues, Pierre M\\'enard, Emilie Kaufmann, Michal\n  Valko", "title": "Episodic Reinforcement Learning in Finite MDPs: Minimax Lower Bounds\n  Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose new problem-independent lower bounds on the sample\ncomplexity and regret in episodic MDPs, with a particular focus on the\nnon-stationary case in which the transition kernel is allowed to change in each\nstage of the episode. Our main contribution is a novel lower bound of\n$\\Omega((H^3SA/\\epsilon^2)\\log(1/\\delta))$ on the sample complexity of an\n$(\\varepsilon,\\delta)$-PAC algorithm for best policy identification in a\nnon-stationary MDP. This lower bound relies on a construction of \"hard MDPs\"\nwhich is different from the ones previously used in the literature. Using this\nsame class of MDPs, we also provide a rigorous proof of the\n$\\Omega(\\sqrt{H^3SAT})$ regret bound for non-stationary MDPs. Finally, we\ndiscuss connections to PAC-MDP lower bounds.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:23:01 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Domingues", "Omar Darwiche", ""], ["M\u00e9nard", "Pierre", ""], ["Kaufmann", "Emilie", ""], ["Valko", "Michal", ""]]}, {"id": "2010.03561", "submitter": "Ushnish Sengupta", "authors": "Ushnish Sengupta, Matt Amos, J. Scott Hosking, Carl Edward Rasmussen,\n  Matthew Juniper, Paul J. Young", "title": "Ensembling geophysical models with Bayesian Neural Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS) 2020", "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of geophysical models improve projection accuracy and express\nuncertainties. We develop a novel data-driven ensembling strategy for combining\ngeophysical models using Bayesian Neural Networks, which infers\nspatiotemporally varying model weights and bias while accounting for\nheteroscedastic uncertainties in the observations. This produces more accurate\nand uncertainty-aware projections without sacrificing interpretability. Applied\nto the prediction of total column ozone from an ensemble of 15\nchemistry-climate models, we find that the Bayesian neural network ensemble\n(BayNNE) outperforms existing ensembling methods, achieving a 49.4% reduction\nin RMSE for temporal extrapolation, and a 67.4% reduction in RMSE for polar\ndata voids, compared to a weighted mean. Uncertainty is also\nwell-characterized, with 90.6% of the data points in our extrapolation\nvalidation dataset lying within 2 standard deviations and 98.5% within 3\nstandard deviations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:32:32 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Sengupta", "Ushnish", ""], ["Amos", "Matt", ""], ["Hosking", "J. Scott", ""], ["Rasmussen", "Carl Edward", ""], ["Juniper", "Matthew", ""], ["Young", "Paul J.", ""]]}, {"id": "2010.03569", "submitter": "Adi Suresh", "authors": "Anders Andreassen, Shih-Chieh Hsu, Benjamin Nachman, Natchanon\n  Suaysom, and Adi Suresh", "title": "Parameter Estimation using Neural Networks in the Presence of Detector\n  Effects", "comments": "16 pages, 13 figures, 4 tables; v3: Updated to journal version", "journal-ref": "Phys. Rev. D 103, 036001 (2021)", "doi": "10.1103/PhysRevD.103.036001", "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histogram-based template fits are the main technique used for estimating\nparameters of high energy physics Monte Carlo generators. Parametrized neural\nnetwork reweighting can be used to extend this fitting procedure to many\ndimensions and does not require binning. If the fit is to be performed using\nreconstructed data, then expensive detector simulations must be used for\ntraining the neural networks. We introduce a new two-level fitting approach\nthat only requires one dataset with detector simulation and then a set of\nadditional generation-level datasets without detector effects included. This\nSimulation-level fit based on Reweighting Generator-level events with Neural\nnetworks (SRGN) is demonstrated using simulated datasets for a variety of\nexamples including a simple Gaussian random variable, parton shower tuning, and\nthe top quark mass extraction.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:00:01 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 02:48:37 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 00:01:15 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Andreassen", "Anders", ""], ["Hsu", "Shih-Chieh", ""], ["Nachman", "Benjamin", ""], ["Suaysom", "Natchanon", ""], ["Suresh", "Adi", ""]]}, {"id": "2010.03587", "submitter": "Zengyi Li", "authors": "Zengyi Li, Yubei Chen, Friedrich T. Sommer", "title": "A Neural Network MCMC sampler that maximizes Proposal Entropy", "comments": "conference submission preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) methods sample from unnormalized probability\ndistributions and offer guarantees of exact sampling. However, in the\ncontinuous case, unfavorable geometry of the target distribution can greatly\nlimit the efficiency of MCMC methods. Augmenting samplers with neural networks\ncan potentially improve their efficiency. Previous neural network based\nsamplers were trained with objectives that either did not explicitly encourage\nexploration, or used a L2 jump objective which could only be applied to well\nstructured distributions. Thus it seems promising to instead maximize the\nproposal entropy for adapting the proposal to distributions of any shape. To\nallow direct optimization of the proposal entropy, we propose a neural network\nMCMC sampler that has a flexible and tractable proposal distribution.\nSpecifically, our network architecture utilizes the gradient of the target\ndistribution for generating proposals. Our model achieves significantly higher\nefficiency than previous neural network MCMC techniques in a variety of\nsampling tasks. Further, the sampler is applied on training of a convergent\nenergy-based model of natural images. The adaptive sampler achieves unbiased\nsampling with significantly higher proposal entropy than Langevin dynamics\nsampler.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:01:38 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Li", "Zengyi", ""], ["Chen", "Yubei", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2010.03593", "submitter": "Sven Gowal", "authors": "Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli", "title": "Uncovering the Limits of Adversarial Training against Norm-Bounded\n  Adversarial Examples", "comments": "Fixed minor formatting issues and added link to models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training and its variants have become de facto standards for\nlearning robust deep neural networks. In this paper, we explore the landscape\naround adversarial training in a bid to uncover its limits. We systematically\nstudy the effect of different training losses, model sizes, activation\nfunctions, the addition of unlabeled data (through pseudo-labeling) and other\nfactors on adversarial robustness. We discover that it is possible to train\nrobust models that go well beyond state-of-the-art results by combining larger\nmodels, Swish/SiLU activations and model weight averaging. We demonstrate large\nimprovements on CIFAR-10 and CIFAR-100 against $\\ell_\\infty$ and $\\ell_2$\nnorm-bounded perturbations of size $8/255$ and $128/255$, respectively. In the\nsetting with additional unlabeled data, we obtain an accuracy under attack of\n65.88% against $\\ell_\\infty$ perturbations of size $8/255$ on CIFAR-10 (+6.35%\nwith respect to prior art). Without additional data, we obtain an accuracy\nunder attack of 57.20% (+3.46%). To test the generality of our findings and\nwithout any additional modifications, we obtain an accuracy under attack of\n80.53% (+7.62%) against $\\ell_2$ perturbations of size $128/255$ on CIFAR-10,\nand of 36.88% (+8.46%) against $\\ell_\\infty$ perturbations of size $8/255$ on\nCIFAR-100. All models are available at\nhttps://github.com/deepmind/deepmind-research/tree/master/adversarial_robustness.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:19:09 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 16:28:20 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 08:08:12 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Gowal", "Sven", ""], ["Qin", "Chongli", ""], ["Uesato", "Jonathan", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "2010.03594", "submitter": "Leonardo Banchi", "authors": "Leonardo Banchi, Quntao Zhuang, Stefano Pirandola", "title": "Quantum-enhanced barcode decoding and pattern recognition", "comments": "17 pages, 4 figures", "journal-ref": "Phys. Rev. Applied 14, 064026 (2020)", "doi": "10.1103/PhysRevApplied.14.064026", "report-no": null, "categories": "quant-ph cs.LG physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum hypothesis testing is one of the most fundamental problems in quantum\ninformation theory, with crucial implications in areas like quantum sensing,\nwhere it has been used to prove quantum advantage in a series of binary\nphotonic protocols, e.g., for target detection or memory cell readout. In this\nwork, we generalize this theoretical model to the multi-partite setting of\nbarcode decoding and pattern recognition. We start by defining a digital image\nas an array or grid of pixels, each pixel corresponding to an ensemble of\nquantum channels. Specializing each pixel to a black and white alphabet, we\nnaturally define an optical model of barcode. In this scenario, we show that\nthe use of quantum entangled sources, combined with suitable measurements and\ndata processing, greatly outperforms classical coherent-state strategies for\nthe tasks of barcode data decoding and classification of black and white\npatterns. Moreover, introducing relevant bounds, we show that the problem of\npattern recognition is significantly simpler than barcode decoding, as long as\nthe minimum Hamming distance between images from different classes is large\nenough. Finally, we theoretically demonstrate the advantage of using quantum\nsensors for pattern recognition with the nearest neighbor classifier, a\nsupervised learning algorithm, and numerically verify this prediction for\nhandwritten digit classification.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 18:19:31 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 07:40:30 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Banchi", "Leonardo", ""], ["Zhuang", "Quntao", ""], ["Pirandola", "Stefano", ""]]}, {"id": "2010.03622", "submitter": "Colin Wei", "authors": "Colin Wei, Kendrick Shen, Yining Chen, Tengyu Ma", "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled\n  Data", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-training algorithms, which train a model to fit pseudolabels predicted\nby another previously-learned model, have been very successful for learning\nwith unlabeled data using neural networks. However, the current theoretical\nunderstanding of self-training only applies to linear models. This work\nprovides a unified theoretical analysis of self-training with deep networks for\nsemi-supervised learning, unsupervised domain adaptation, and unsupervised\nlearning. At the core of our analysis is a simple but realistic \"expansion\"\nassumption, which states that a low probability subset of the data must expand\nto a neighborhood with large probability relative to the subset. We also assume\nthat neighborhoods of examples in different classes have minimal overlap. We\nprove that under these assumptions, the minimizers of population objectives\nbased on self-training and input-consistency regularization will achieve high\naccuracy with respect to ground-truth labels. By using off-the-shelf\ngeneralization bounds, we immediately convert this result to sample complexity\nguarantees for neural nets that are polynomial in the margin and Lipschitzness.\nOur results help explain the empirical successes of recently proposed\nself-training algorithms which use input consistency regularization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 19:43:55 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 07:28:39 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 08:52:36 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 05:03:07 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wei", "Colin", ""], ["Shen", "Kendrick", ""], ["Chen", "Yining", ""], ["Ma", "Tengyu", ""]]}, {"id": "2010.03633", "submitter": "Gard Spreemann", "authors": "Stefania Ebli, Micha\\\"el Defferrard, Gard Spreemann", "title": "Simplicial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present simplicial neural networks (SNNs), a generalization of graph\nneural networks to data that live on a class of topological spaces called\nsimplicial complexes. These are natural multi-dimensional extensions of graphs\nthat encode not only pairwise relationships but also higher-order interactions\nbetween vertices - allowing us to consider richer data, including vector fields\nand $n$-fold collaboration networks. We define an appropriate notion of\nconvolution that we leverage to construct the desired convolutional neural\nnetworks. We test the SNNs on the task of imputing missing data on coauthorship\ncomplexes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:15:01 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:24:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ebli", "Stefania", ""], ["Defferrard", "Micha\u00ebl", ""], ["Spreemann", "Gard", ""]]}, {"id": "2010.03635", "submitter": "Aleksandar Stanic", "authors": "Aleksandar Stani\\'c, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Hierarchical Relational Inference", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common-sense physical reasoning in the real world requires learning about the\ninteractions of objects and their dynamics. The notion of an abstract object,\nhowever, encompasses a wide variety of physical objects that differ greatly in\nterms of the complex behaviors they support. To address this, we propose a\nnovel approach to physical reasoning that models objects as hierarchies of\nparts that may locally behave separately, but also act more globally as a\nsingle whole. Unlike prior approaches, our method learns in an unsupervised\nfashion directly from raw visual images to discover objects, parts, and their\nrelations. It explicitly distinguishes multiple levels of abstraction and\nimproves over a strong baseline at modeling synthetic and real-world videos.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:19:10 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 22:14:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Stani\u0107", "Aleksandar", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2010.03647", "submitter": "Xiaohan Zhang Dr", "authors": "Xiaohan Zhang", "title": "Actor-Critic Algorithm for High-dimensional Partial Differential\n  Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a deep learning model to effectively solve high-dimensional\nnonlinear parabolic partial differential equations (PDE). We follow Feynman-Kac\nformula to reformulate PDE into the equivalent stochastic control problem\ngoverned by a Backward Stochastic Differential Equation (BSDE) system. The\nMarkovian property of the BSDE is utilized in designing our neural network\narchitecture, which is inspired by the Actor-Critic algorithm usually applied\nfor deep Reinforcement Learning. Compared to the State-of-the-Art model, we\nmake several improvements including 1) largely reduced trainable parameters, 2)\nfaster convergence rate and 3) fewer hyperparameters to tune. We demonstrate\nthose improvements by solving a few well-known classes of PDEs such as\nHamilton-Jacobian-Bellman equation, Allen-Cahn equation and Black-Scholes\nequation with dimensions on the order of 100.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:53:24 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zhang", "Xiaohan", ""]]}, {"id": "2010.03648", "submitter": "Nikunj Saunshi", "authors": "Nikunj Saunshi, Sadhika Malladi, Sanjeev Arora", "title": "A Mathematical Exploration of Why Language Models Help Solve Downstream\n  Tasks", "comments": "This version is the camera-ready version for ICLR 2021. Main changes\n  include a detailed discussion about natural tasks, more detailed proof sketch\n  and updated experimental evaluations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive language models, pretrained using large text corpora to do\nwell on next word prediction, have been successful at solving many downstream\ntasks, even with zero-shot usage. However, there is little theoretical\nunderstanding of this success. This paper initiates a mathematical study of\nthis phenomenon for the downstream task of text classification by considering\nthe following questions: (1) What is the intuitive connection between the\npretraining task of next word prediction and text classification? (2) How can\nwe mathematically formalize this connection and quantify the benefit of\nlanguage modeling? For (1), we hypothesize, and verify empirically, that\nclassification tasks of interest can be reformulated as sentence completion\ntasks, thus making language modeling a meaningful pretraining task. With a\nmathematical formalization of this hypothesis, we make progress towards (2) and\nshow that language models that are $\\epsilon$-optimal in cross-entropy\n(log-perplexity) learn features that can linearly solve such classification\ntasks with $\\mathcal{O}(\\sqrt{\\epsilon})$ error, thus demonstrating that doing\nwell on language modeling can be beneficial for downstream tasks. We\nexperimentally verify various assumptions and theoretical findings, and also\nuse insights from the analysis to design a new objective function that performs\nwell on some classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:56:40 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 17:59:14 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Saunshi", "Nikunj", ""], ["Malladi", "Sadhika", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.03710", "submitter": "Yihuang Kang", "authors": "Sheng-Tai Huang, Yihuang Kang, Shao-Min Hung, Bowen Kuo, I-Ling Cheng", "title": "Topic Diffusion Discovery Based on Deep Non-negative Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers have been overwhelmed by the explosion of research articles\npublished by various research communities. Many research scholarly websites,\nsearch engines, and digital libraries have been created to help researchers\nidentify potential research topics and keep up with recent progress on research\nof interests. However, it is still difficult for researchers to keep track of\nthe research topic diffusion and evolution without spending a large amount of\ntime reviewing numerous relevant and irrelevant articles. In this paper, we\nconsider a novel topic diffusion discovery technique. Specifically, we propose\nusing a Deep Non-negative Autoencoder with information divergence measurement\nthat monitors evolutionary distance of the topic diffusion to understand how\nresearch topics change with time. The experimental results show that the\nproposed approach is able to identify the evolution of research topics as well\nas to discover topic diffusions in online fashions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 00:58:10 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huang", "Sheng-Tai", ""], ["Kang", "Yihuang", ""], ["Hung", "Shao-Min", ""], ["Kuo", "Bowen", ""], ["Cheng", "I-Ling", ""]]}, {"id": "2010.03729", "submitter": "Jason Miller", "authors": "Jason Miller, Sui Tang, Ming Zhong, Mauro Maggioni", "title": "Learning Theory for Inferring Interaction Kernels in Second-Order\n  Interacting Agent Systems", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the complex interactions of systems of particles or agents is a\nfundamental scientific and mathematical problem that is studied in diverse\nfields, ranging from physics and biology, to economics and machine learning. In\nthis work, we describe a very general second-order, heterogeneous,\nmultivariable, interacting agent model, with an environment, that encompasses a\nwide variety of known systems. We describe an inference framework that uses\nnonparametric regression and approximation theory based techniques to\nefficiently derive estimators of the interaction kernels which drive these\ndynamical systems. We develop a complete learning theory which establishes\nstrong consistency and optimal nonparametric min-max rates of convergence for\nthe estimators, as well as provably accurate predicted trajectories. The\nestimators exploit the structure of the equations in order to overcome the\ncurse of dimensionality and we describe a fundamental coercivity condition on\nthe inverse problem which ensures that the kernels can be learned and relates\nto the minimal singular value of the learning matrix. The numerical algorithm\npresented to build the estimators is parallelizable, performs well on\nhigh-dimensional problems, and is demonstrated on complex dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 02:07:53 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Miller", "Jason", ""], ["Tang", "Sui", ""], ["Zhong", "Ming", ""], ["Maggioni", "Mauro", ""]]}, {"id": "2010.03733", "submitter": "Span Spanbauer", "authors": "Span Spanbauer, Luke Sciarappa", "title": "Neural Group Actions", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm for designing Neural Group Actions, collections of\ndeep neural network architectures which model symmetric transformations\nsatisfying the laws of a given finite group. This generalizes involutive neural\nnetworks $\\mathcal{N}$, which satisfy $\\mathcal{N}(\\mathcal{N}(x))=x$ for any\ndata $x$, the group law of $\\mathbb{Z}_2$. We show how to optionally enforce an\nadditional constraint that the group action be volume-preserving. We\nconjecture, by analogy to a universality result for involutive neural networks,\nthat generative models built from Neural Group Actions are universal\napproximators for collections of probabilistic transitions adhering to the\ngroup laws. We demonstrate experimentally that a Neural Group Action for the\nquaternion group $Q_8$ can learn how a set of nonuniversal quantum gates\nsatisfying the $Q_8$ group laws act on single qubit quantum states.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 02:27:05 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Spanbauer", "Span", ""], ["Sciarappa", "Luke", ""]]}, {"id": "2010.03744", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna Gottipati, Yashaswi Pathak, Rohan Nuttall, Sahir, Raviteja\n  Chunduru, Ahmed Touati, Sriram Ganapathi Subramanian, Matthew E. Taylor,\n  Sarath Chandar", "title": "Maximum Reward Formulation In Reinforcement Learning", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms typically deal with maximizing the\nexpected cumulative return (discounted or undiscounted, finite or infinite\nhorizon). However, several crucial applications in the real world, such as drug\ndiscovery, do not fit within this framework because an RL agent only needs to\nidentify states (molecules) that achieve the highest reward within a trajectory\nand does not need to optimize for the expected cumulative return. In this work,\nwe formulate an objective function to maximize the expected maximum reward\nalong a trajectory, derive a novel functional form of the Bellman equation,\nintroduce the corresponding Bellman operators, and provide a proof of\nconvergence. Using this formulation, we achieve state-of-the-art results on the\ntask of molecule generation that mimics a real-world drug discovery pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 03:07:31 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Gottipati", "Sai Krishna", ""], ["Pathak", "Yashaswi", ""], ["Nuttall", "Rohan", ""], ["Sahir", "", ""], ["Chunduru", "Raviteja", ""], ["Touati", "Ahmed", ""], ["Subramanian", "Sriram Ganapathi", ""], ["Taylor", "Matthew E.", ""], ["Chandar", "Sarath", ""]]}, {"id": "2010.03753", "submitter": "Saeid Naderiparizi", "authors": "Saeid Naderiparizi, Kenny Chiu, Benjamin Bloem-Reddy, Frank Wood", "title": "Uncertainty in Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the effects of architecture and training objective choice on\namortized posterior predictive inference in probabilistic conditional\ngenerative models. We aim this work to be a counterpoint to a recent trend in\nthe literature that stresses achieving good samples when the amount of\nconditioning data is large. We instead focus our attention on the case where\nthe amount of conditioning data is small. We highlight specific architecture\nand objective choices that we find lead to qualitative and quantitative\nimprovement to posterior inference in this low data regime. Specifically we\nexplore the effects of choices of pooling operator and variational family on\nposterior quality in neural processes. Superior posterior predictive samples\ndrawn from our novel neural process architectures are demonstrated via image\ncompletion/in-painting experiments.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 04:10:05 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Naderiparizi", "Saeid", ""], ["Chiu", "Kenny", ""], ["Bloem-Reddy", "Benjamin", ""], ["Wood", "Frank", ""]]}, {"id": "2010.03757", "submitter": "Gregor Von Laszewski PhD", "authors": "Geoffrey C. Fox, Gregor von Laszewski, Fugang Wang, and Saumyadipta\n  Pyne", "title": "AICov: An Integrative Deep Learning Framework for COVID-19 Forecasting\n  with Population Covariates", "comments": "25 pages, 4 tabkes, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic has profound global consequences on health, economic,\nsocial, political, and almost every major aspect of human life. Therefore, it\nis of great importance to model COVID-19 and other pandemics in terms of the\nbroader social contexts in which they take place. We present the architecture\nof AICov, which provides an integrative deep learning framework for COVID-19\nforecasting with population covariates, some of which may serve as putative\nrisk factors. We have integrated multiple different strategies into AICov,\nincluding the ability to use deep learning strategies based on LSTM and even\nmodeling. To demonstrate our approach, we have conducted a pilot that\nintegrates population covariates from multiple sources. Thus, AICov not only\nincludes data on COVID-19 cases and deaths but, more importantly, the\npopulation's socioeconomic, health and behavioral risk factors at a local\nlevel. The compiled data are fed into AICov, and thus we obtain improved\nprediction by integration of the data to our model as compared to one that only\nuses case and death data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 04:41:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Fox", "Geoffrey C.", ""], ["von Laszewski", "Gregor", ""], ["Wang", "Fugang", ""], ["Pyne", "Saumyadipta", ""]]}, {"id": "2010.03792", "submitter": "Masahiro Kato", "authors": "Masahiro Kato and Shota Yasui and Kenichiro McAlinn", "title": "The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive\n  Experiments and a Paradox Concerning Logging Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The doubly robust (DR) estimator, which consists of two nuisance parameters,\nthe conditional mean outcome and the logging policy (the probability of\nchoosing an action), is crucial in causal inference. This paper proposes a DR\nestimator for dependent samples obtained from adaptive experiments. To obtain\nan asymptotically normal semiparametric estimator from dependent samples with\nnon-Donsker nuisance estimators, we propose adaptive-fitting as a variant of\nsample-splitting. We also report an empirical paradox that our proposed DR\nestimator tends to show better performances compared to other estimators\nutilizing the true logging policy. While a similar phenomenon is known for\nestimators with i.i.d. samples, traditional explanations based on asymptotic\nefficiency cannot elucidate our case with dependent samples. We confirm this\nhypothesis through simulation studies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 06:42:48 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 14:10:11 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 17:07:15 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 19:40:40 GMT"}, {"version": "v5", "created": "Fri, 18 Jun 2021 22:17:48 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Kato", "Masahiro", ""], ["Yasui", "Shota", ""], ["McAlinn", "Kenichiro", ""]]}, {"id": "2010.03799", "submitter": "Dylan Foster", "authors": "Zakaria Mhammedi and Dylan J. Foster and Max Simchowitz and Dipendra\n  Misra and Wen Sun and Akshay Krishnamurthy and Alexander Rakhlin and John\n  Langford", "title": "Learning the Linear Quadratic Regulator from Nonlinear Observations", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new problem setting for continuous control called the LQR with\nRich Observations, or RichLQR. In our setting, the environment is summarized by\na low-dimensional continuous latent state with linear dynamics and quadratic\ncosts, but the agent operates on high-dimensional, nonlinear observations such\nas images from a camera. To enable sample-efficient learning, we assume that\nthe learner has access to a class of decoder functions (e.g., neural networks)\nthat is flexible enough to capture the mapping from observations to latent\nstates. We introduce a new algorithm, RichID, which learns a near-optimal\npolicy for the RichLQR with sample complexity scaling only with the dimension\nof the latent state space and the capacity of the decoder function class.\nRichID is oracle-efficient and accesses the decoder class only through calls to\na least-squares regression oracle. Our results constitute the first provable\nsample complexity guarantee for continuous control with an unknown nonlinearity\nin the system model and general function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:02:47 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Foster", "Dylan J.", ""], ["Simchowitz", "Max", ""], ["Misra", "Dipendra", ""], ["Sun", "Wen", ""], ["Krishnamurthy", "Akshay", ""], ["Rakhlin", "Alexander", ""], ["Langford", "John", ""]]}, {"id": "2010.03807", "submitter": "J. Emmanuel Johnson", "authors": "Valero Laparra, J. Emmanuel Johnson, Gustau Camps-Valls, Raul\n  Santos-Rodr\\'iguez, Jesus Malo", "title": "Information Theory Measures via Multidimensional Gaussianization", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory is an outstanding framework to measure uncertainty,\ndependence and relevance in data and systems. It has several desirable\nproperties for real world applications: it naturally deals with multivariate\ndata, it can handle heterogeneous data types, and the measures can be\ninterpreted in physical units. However, it has not been adopted by a wider\naudience because obtaining information from multidimensional data is a\nchallenging problem due to the curse of dimensionality. Here we propose an\nindirect way of computing information based on a multivariate Gaussianization\ntransform. Our proposal mitigates the difficulty of multivariate density\nestimation by reducing it to a composition of tractable (marginal) operations\nand simple linear transformations, which can be interpreted as a particular\ndeep neural network. We introduce specific Gaussianization-based methodologies\nto estimate total correlation, entropy, mutual information and Kullback-Leibler\ndivergence. We compare them to recent estimators showing the accuracy on\nsynthetic data generated from different multivariate distributions. We made the\ntools and datasets publicly available to provide a test-bed to analyze future\nmethodologies. Results show that our proposal is superior to previous\nestimators particularly in high-dimensional scenarios; and that it leads to\ninteresting insights in neuroscience, geoscience, computer vision, and machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:22:16 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:23:45 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Laparra", "Valero", ""], ["Johnson", "J. Emmanuel", ""], ["Camps-Valls", "Gustau", ""], ["Santos-Rodr\u00edguez", "Raul", ""], ["Malo", "Jesus", ""]]}, {"id": "2010.03857", "submitter": "Raisa Dzhamtyrova PhD", "authors": "Raisa Dzhamtyrova, Carsten Maple", "title": "Anomaly detection with superexperts under delayed feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing connectivity of data and cyber-physical systems has resulted\nin a growing number of cyber-attacks. Real-time detection of such attacks,\nthrough the identification of anomalous activity, is required so that\nmitigation and contingent actions can be effectively and rapidly deployed. We\npropose a new approach for aggregating unsupervised anomaly detection\nalgorithms and incorporating feedback when it becomes available. We apply this\napproach to open-source real datasets and show that both aggregating models,\nwhich we call experts, and incorporating feedback significantly improve the\nperformance. An important property of the proposed approaches is their\ntheoretical guarantees that they perform close to the best superexpert, which\ncan switch between the best performing experts, in terms of the cumulative\naverage losses.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:24:55 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:57:31 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Dzhamtyrova", "Raisa", ""], ["Maple", "Carsten", ""]]}, {"id": "2010.03918", "submitter": "Micha\\\"el Perrot", "authors": "Micha\\\"el Perrot and Pascal Mattia Esser and Debarghya Ghoshdastidar", "title": "Near-Optimal Comparison Based Clustering", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of clustering is to group similar objects into meaningful\npartitions. This process is well understood when an explicit similarity measure\nbetween the objects is given. However, far less is known when this information\nis not readily available and, instead, one only observes ordinal comparisons\nsuch as \"object i is more similar to j than to k.\" In this paper, we tackle\nthis problem using a two-step procedure: we estimate a pairwise similarity\nmatrix from the comparisons before using a clustering method based on\nsemi-definite programming (SDP). We theoretically show that our approach can\nexactly recover a planted clustering using a near-optimal number of passive\ncomparisons. We empirically validate our theoretical findings and demonstrate\nthe good behaviour of our method on real data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 12:03:13 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 12:51:45 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Perrot", "Micha\u00ebl", ""], ["Esser", "Pascal Mattia", ""], ["Ghoshdastidar", "Debarghya", ""]]}, {"id": "2010.03955", "submitter": "Kemal David Yenicelik", "authors": "David Yenicelik", "title": "Parameter Optimization using high-dimensional Bayesian Optimization", "comments": "ETH Zurich Bachelor Thesis Submission August 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, I explore the possibilities of conducting Bayesian\noptimization techniques in high dimensional domains. Although high dimensional\ndomains can be defined to be between hundreds and thousands of dimensions, we\nwill primarily focus on problem settings that occur between two and 20\ndimensions. As such, we focus on solutions to practical problems, such as\ntuning the parameters for an electron accelerator, or for even simpler tasks\nthat can be run and optimized just in time with a standard laptop at hand. Our\nmain contributions are 1.) comparing how the log-likelihood affects the\nangle-difference in the real projection matrix, and the found matrix matrix,\n2.) an extensive analysis of current popular methods including strengths and\nshortcomings, 3.) a short analysis on how dimensionality reduction techniques\ncan be used for feature selection, and 4.) a novel algorithm called \"BORING\",\nwhich allows for a simple fallback mechanism if the matrix identification\nfails, as well as taking into consideration \"passive\" subspaces which provide\nsmall perturbations of the function at hand. The main features of BORING are\n1.) the possibility to identify the subspace (unlike most other optimization\nalgorithms), and 2.) to provide a much lower penalty to identify the subspace\nif identification fails, as optimization is still the primary goal.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:13:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Yenicelik", "David", ""]]}, {"id": "2010.03956", "submitter": "Shengyi Huang", "authors": "Shengyi Huang, Santiago Onta\\~n\\'on", "title": "Action Guidance: Getting the Best of Sparse Rewards and Shaped Rewards\n  for Real-time Strategy Games", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training agents using Reinforcement Learning in games with sparse rewards is\na challenging problem, since large amounts of exploration are required to\nretrieve even the first reward. To tackle this problem, a common approach is to\nuse reward shaping to help exploration. However, an important drawback of\nreward shaping is that agents sometimes learn to optimize the shaped reward\ninstead of the true objective. In this paper, we present a novel technique that\nwe call action guidance that successfully trains agents to eventually optimize\nthe true objective in games with sparse rewards while maintaining most of the\nsample efficiency that comes with reward shaping. We evaluate our approach in a\nsimplified real-time strategy (RTS) game simulator called $\\mu$RTS.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:43:06 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huang", "Shengyi", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2010.04003", "submitter": "Thang Doan", "authors": "Thang Doan, Mehdi Bennani, Bogdan Mazoure, Guillaume Rabusseau, Pierre\n  Alquier", "title": "A Theoretical Analysis of Catastrophic Forgetting through the NTK\n  Overlap Matrix", "comments": "Accepted to AISTATS 2021. Keywords: continual learning, catastrophic\n  forgetting, NTK regime, orthgonal gradient descent", "journal-ref": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) is a setting in which an agent has to learn from an\nincoming stream of data during its entire lifetime. Although major advances\nhave been made in the field, one recurring problem which remains unsolved is\nthat of Catastrophic Forgetting (CF). While the issue has been extensively\nstudied empirically, little attention has been paid from a theoretical angle.\nIn this paper, we show that the impact of CF increases as two tasks\nincreasingly align. We introduce a measure of task similarity called the NTK\noverlap matrix which is at the core of CF. We analyze common projected gradient\nalgorithms and demonstrate how they mitigate forgetting. Then, we propose a\nvariant of Orthogonal Gradient Descent (OGD) which leverages structure of the\ndata through Principal Component Analysis (PCA). Experiments support our\ntheoretical findings and show how our method can help reduce CF on classical CL\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 17:35:31 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 15:31:16 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Doan", "Thang", ""], ["Bennani", "Mehdi", ""], ["Mazoure", "Bogdan", ""], ["Rabusseau", "Guillaume", ""], ["Alquier", "Pierre", ""]]}, {"id": "2010.04010", "submitter": "Mack Sweeney", "authors": "Mack Sweeney, Matthew van Adelsberg, Kathryn Laskey, Carlotta\n  Domeniconi", "title": "Effects of Model Misspecification on Bayesian Bandits: Case Studies in\n  UX Optimization", "comments": "10 pages, 4 figures, accepted at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian bandits using Thompson Sampling have seen increasing success in\nrecent years. Yet existing value models (of rewards) are misspecified on many\nreal-world problem. We demonstrate this on the User Experience Optimization\n(UXO) problem, providing a novel formulation as a restless, sleeping bandit\nwith unobserved confounders plus optional stopping. Our case studies show how\ncommon misspecifications can lead to sub-optimal rewards, and we provide model\nextensions to address these, along with a scientific model building process\npractitioners can adopt or adapt to solve their own unique problems. To our\nknowledge, this is the first study showing the effects of overdispersion on\nbandit explore/exploit efficacy, tying the common notions of under- and\nover-confidence to over- and under-exploration, respectively. We also present\nthe first model to exploit cointegration in a restless bandit, demonstrating\nthat finite regret and fast and consistent optional stopping are possible by\nmoving beyond simpler windowing, discounting, and drift models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 14:34:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Sweeney", "Mack", ""], ["van Adelsberg", "Matthew", ""], ["Laskey", "Kathryn", ""], ["Domeniconi", "Carlotta", ""]]}, {"id": "2010.04015", "submitter": "Salar Fattahi", "authors": "Salar Fattahi", "title": "Learning Partially Observed Linear Dynamical Systems from Logarithmic\n  Number of Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of learning partially observed linear\ndynamical systems from a single sample trajectory. A major practical challenge\nin the existing system identification methods is the undesirable dependency of\ntheir required sample size on the system dimension: roughly speaking, they\npresume and rely on sample sizes that scale linearly with respect to the system\ndimension. Evidently, in high-dimensional regime where the system dimension is\nlarge, it may be costly, if not impossible, to collect as many samples from the\nunknown system. In this paper, we will remedy this undesirable dependency on\nthe system dimension by introducing an $\\ell_1$-regularized estimation method\nthat can accurately estimate the Markov parameters of the system, provided that\nthe number of samples scale logarithmically with the system dimension. Our\nresult significantly improves the sample complexity of learning partially\nobserved linear dynamical systems: it shows that the Markov parameters of the\nsystem can be learned in the high-dimensional setting, where the number of\nsamples is significantly smaller than the system dimension. Traditionally, the\n$\\ell_1$-regularized estimators have been used to promote sparsity in the\nestimated parameters. By resorting to the notion of \"weak sparsity\", we show\nthat, irrespective of the true sparsity of the system, a similar regularized\nestimator can be used to reduce the sample complexity of learning partially\nobserved linear systems, provided that the true system is inherently stable.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 14:23:48 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Fattahi", "Salar", ""]]}, {"id": "2010.04044", "submitter": "Tullio Mancini", "authors": "Tullio Mancini, Hector Calvo-Pardo, and Jose Olmo", "title": "Prediction intervals for Deep Neural Networks", "comments": "35 pages, 3 Figures, and 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to propose a suitable method for constructing\nprediction intervals for the output of neural network models. To do this, we\nadapt the extremely randomized trees method originally developed for random\nforests to construct ensembles of neural networks. The extra-randomness\nintroduced in the ensemble reduces the variance of the predictions and yields\ngains in out-of-sample accuracy. An extensive Monte Carlo simulation exercise\nshows the good performance of this novel method for constructing prediction\nintervals in terms of coverage probability and mean square prediction error.\nThis approach is superior to state-of-the-art methods extant in the literature\nsuch as the widely used MC dropout and bootstrap procedures. The out-of-sample\naccuracy of the novel algorithm is further evaluated using experimental\nsettings already adopted in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:11:28 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 09:16:19 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Mancini", "Tullio", ""], ["Calvo-Pardo", "Hector", ""], ["Olmo", "Jose", ""]]}, {"id": "2010.04050", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Gilles Barthe, Bernhard Sch\\\"olkopf, Isabel\n  Valera", "title": "A survey of algorithmic recourse: definitions, formulations, solutions,\n  and prospects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly used to inform decision-making in sensitive\nsituations where decisions have consequential effects on individuals' lives. In\nthese settings, in addition to requiring models to be accurate and robust,\nsocially relevant values such as fairness, privacy, accountability, and\nexplainability play an important role for the adoption and impact of said\ntechnologies. In this work, we focus on algorithmic recourse, which is\nconcerned with providing explanations and recommendations to individuals who\nare unfavourably treated by automated decision-making systems. We first perform\nan extensive literature review, and align the efforts of many authors by\npresenting unified definitions, formulations, and solutions to recourse. Then,\nwe provide an overview of the prospective research directions towards which the\ncommunity may engage, challenging existing assumptions and making explicit\nconnections to other ethical challenges such as security, privacy, and\nfairness.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:15:34 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 18:44:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Valera", "Isabel", ""]]}, {"id": "2010.04051", "submitter": "Niccol\\`o Dalmasso", "authors": "Niccol\\`o Dalmasso, Galen Vincent, Dorit Hammerling, Ann B. Lee", "title": "HECT: High-Dimensional Ensemble Consistency Testing for Climate Models", "comments": "Accepted at the Tackling Climate Change with Machine Learning\n  workshop at NeurIPS 2020, 6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate models play a crucial role in understanding the effect of\nenvironmental and man-made changes on climate to help mitigate climate risks\nand inform governmental decisions. Large global climate models such as the\nCommunity Earth System Model (CESM), developed by the National Center for\nAtmospheric Research, are very complex with millions of lines of code\ndescribing interactions of the atmosphere, land, oceans, and ice, among other\ncomponents. As development of the CESM is constantly ongoing, simulation\noutputs need to be continuously controlled for quality. To be able to\ndistinguish a \"climate-changing\" modification of the code base from a true\nclimate-changing physical process or intervention, there needs to be a\nprincipled way of assessing statistical reproducibility that can handle both\nspatial and temporal high-dimensional simulation outputs. Our proposed work\nuses probabilistic classifiers like tree-based algorithms and deep neural\nnetworks to perform a statistically rigorous goodness-of-fit test of\nhigh-dimensional spatio-temporal data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:16:16 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 22:48:17 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dalmasso", "Niccol\u00f2", ""], ["Vincent", "Galen", ""], ["Hammerling", "Dorit", ""], ["Lee", "Ann B.", ""]]}, {"id": "2010.04052", "submitter": "Kushal Tirumala", "authors": "R. Bathwal, P. Chitta, K. Tirumala, V. Varadarajan", "title": "Ensemble Machine Learning Methods for Modeling COVID19 Deaths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a hybrid of machine learning and epidemiological approaches, we propose\na novel data-driven approach in predicting US COVID-19 deaths at a county\nlevel. The model gives a more complete description of the daily death\ndistribution, outputting quantile-estimates instead of mean deaths, where the\nmodel's objective is to minimize the pinball loss on deaths reported by the New\nYork Times coronavirus county dataset. The resulting quantile estimates\naccurately forecast deaths at an individual-county level for a variable-length\nforecast period, and the approach generalizes well across different forecast\nperiod lengths. We won the Caltech-run modeling competition out of 50+ teams,\nand our aggregate is competitive with the best COVID-19 modeling systems (on\nroot mean squared error).\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 13:34:12 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bathwal", "R.", ""], ["Chitta", "P.", ""], ["Tirumala", "K.", ""], ["Varadarajan", "V.", ""]]}, {"id": "2010.04053", "submitter": "Simon Caton", "authors": "Simon Caton and Christian Haas", "title": "Fairness in Machine Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Machine Learning technologies become increasingly used in contexts that\naffect citizens, companies as well as researchers need to be confident that\ntheir application of these methods will not have unexpected social\nimplications, such as bias towards gender, ethnicity, and/or people with\ndisabilities. There is significant literature on approaches to mitigate bias\nand promote fairness, yet the area is complex and hard to penetrate for\nnewcomers to the domain. This article seeks to provide an overview of the\ndifferent schools of thought and approaches to mitigating (social) biases and\nincrease fairness in the Machine Learning literature. It organises approaches\ninto the widely accepted framework of pre-processing, in-processing, and\npost-processing methods, subcategorizing into a further 11 method areas.\nAlthough much of the literature emphasizes binary classification, a discussion\nof fairness in regression, recommender systems, unsupervised learning, and\nnatural language processing is also provided along with a selection of\ncurrently available open source libraries. The article concludes by summarising\nopen challenges articulated as four dilemmas for fairness research.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 21:01:34 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Caton", "Simon", ""], ["Haas", "Christian", ""]]}, {"id": "2010.04056", "submitter": "Hu Zhao", "authors": "Hu Zhao, Florian Amann, Julia Kowalski", "title": "Emulator-based global sensitivity analysis for flow-like landslide\n  run-out models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landslide run-out modeling involves various uncertainties originating from\nmodel input data. It is therefore desirable to assess the model's sensitivity.\nA global sensitivity analysis that is capable of exploring the entire input\nspace and accounts for all interactions, often remains limited due to\ncomputational challenges resulting from a large number of necessary model runs.\nWe address this research gap by integrating Gaussian process emulation into\nlandslide run-out modeling and apply it to the open-source simulation tool\nr.avaflow. The feasibility and efficiency of our approach is illustrated based\non the 2017 Bondo landslide event. The sensitivity of aggregated model outputs,\nsuch as the apparent friction angle, impact area, as well as spatially resolved\nmaximum flow height and velocity, to the dry-Coulomb friction coefficient,\nturbulent friction coefficient and the release volume are studied. The results\nof first-order effects are consistent with previous results of common\none-at-a-time sensitivity analyses. In addition to that, our approach allows to\nrigorously investigate interactions. Strong interactions are detected on the\nmargins of the flow path where the expectation and variation of maximum flow\nheight and velocity are small. The interactions generally become weak with\nincreasing variation of maximum flow height and velocity. Besides, there are\nstronger interactions between the two friction coefficients than between the\nrelease volume and each friction coefficient. In the future, it is promising to\nextend the approach for other computationally expensive tasks like uncertainty\nquantification, model calibration, and smart early warning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:21:52 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zhao", "Hu", ""], ["Amann", "Florian", ""], ["Kowalski", "Julia", ""]]}, {"id": "2010.04091", "submitter": "Yu Heng Hung", "authors": "Yu-Heng Hung, Ping-Chun Hsieh, Xi Liu and P. R. Kumar", "title": "Reward-Biased Maximum Likelihood Estimation for Linear Stochastic\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modifying the reward-biased maximum likelihood method originally proposed in\nthe adaptive control literature, we propose novel learning algorithms to handle\nthe explore-exploit trade-off in linear bandits problems as well as generalized\nlinear bandits problems. We develop novel index policies that we prove achieve\norder-optimality, and show that they achieve empirical performance competitive\nwith the state-of-the-art benchmark methods in extensive experiments. The new\npolicies achieve this with low computation time per pull for linear bandits,\nand thereby resulting in both favorable regret as well as computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 16:17:53 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Hung", "Yu-Heng", ""], ["Hsieh", "Ping-Chun", ""], ["Liu", "Xi", ""], ["Kumar", "P. R.", ""]]}, {"id": "2010.04109", "submitter": "David W. Zhang", "authors": "David W. Zhang, Gertjan J. Burghouts, Cees G.M. Snoek", "title": "Set Prediction without Imposing Structure as Conditional Density\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Set prediction is about learning to predict a collection of unordered\nvariables with unknown interrelations. Training such models with set losses\nimposes the structure of a metric space over sets. We focus on stochastic and\nunderdefined cases, where an incorrectly chosen loss function leads to\nimplausible predictions. Example tasks include conditional point-cloud\nreconstruction and predicting future states of molecules. In this paper, we\npropose an alternative to training via set losses by viewing learning as\nconditional density estimation. Our learning framework fits deep energy-based\nmodels and approximates the intractable likelihood with gradient-guided\nsampling. Furthermore, we propose a stochastically augmented prediction\nalgorithm that enables multiple predictions, reflecting the possible variations\nin the target set. We empirically demonstrate on a variety of datasets the\ncapability to learn multi-modal densities and produce different plausible\npredictions. Our approach is competitive with previous set prediction models on\nstandard benchmarks. More importantly, it extends the family of addressable\ntasks beyond those that have unambiguous predictions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 16:49:16 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 17:22:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhang", "David W.", ""], ["Burghouts", "Gertjan J.", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "2010.04114", "submitter": "Yang Li", "authors": "Yang Li, Jinqiao Duan and Xianbin Liu", "title": "A Machine Learning Framework for Computing the Most Probable Paths of\n  Stochastic Dynamical Systems", "comments": "22 pages, 13 figures", "journal-ref": "Phys. Rev. E 103, 012124 (2021)", "doi": "10.1103/PhysRevE.103.012124", "report-no": null, "categories": "math.DS math.PR math.ST nlin.CD physics.comp-ph stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of transition phenomena between metastable states induced by\nnoise plays a fundamental role in a broad range of nonlinear systems. The\ncomputation of the most probable paths is a key issue to understand the\nmechanism of transition behaviors. Shooting method is a common technique for\nthis purpose to solve the Euler-Lagrange equation for the associated action\nfunctional, while losing its efficacy in high-dimensional systems. In the\npresent work, we develop a machine learning framework to compute the most\nprobable paths in the sense of Onsager-Machlup action functional theory.\nSpecifically, we reformulate the boundary value problem of Hamiltonian system\nand design a neural network to remedy the shortcomings of shooting method. The\nsuccessful applications of our algorithms to several prototypical examples\ndemonstrate its efficacy and accuracy for stochastic systems with both\n(Gaussian) Brownian noise and (non-Gaussian) L\\'evy noise. This novel approach\nis effective in exploring the internal mechanisms of rare events triggered by\nrandom fluctuations in various scientific fields.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 20:01:37 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 02:36:29 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Yang", ""], ["Duan", "Jinqiao", ""], ["Liu", "Xianbin", ""]]}, {"id": "2010.04153", "submitter": "Matteo Aldeghi", "authors": "Florian H\\\"ase and Matteo Aldeghi and Riley J. Hickman and Lo\\\"ic M.\n  Roch and Melodie Christensen and Elena Liles and Jason E. Hein and Al\\'an\n  Aspuru-Guzik", "title": "Olympus: a benchmarking framework for noisy optimization and experiment\n  planning", "comments": "15 pages, 4 figures, 4 tables (with SI: 22 pages, 11 figures, 15\n  tables). Changes: minor fixes to text and references. Two paragraphs added in\n  Sec. III", "journal-ref": "Mach. Learn.: Sci. Technol. 2 (2021) 035021", "doi": "10.1088/2632-2153/abedc8", "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research challenges encountered across science, engineering, and economics\ncan frequently be formulated as optimization tasks. In chemistry and materials\nscience, recent growth in laboratory digitization and automation has sparked\ninterest in optimization-guided autonomous discovery and closed-loop\nexperimentation. Experiment planning strategies based on off-the-shelf\noptimization algorithms can be employed in fully autonomous research platforms\nto achieve desired experimentation goals with the minimum number of trials.\nHowever, the experiment planning strategy that is most suitable to a scientific\ndiscovery task is a priori unknown while rigorous comparisons of different\nstrategies are highly time and resource demanding. As optimization algorithms\nare typically benchmarked on low-dimensional synthetic functions, it is unclear\nhow their performance would translate to noisy, higher-dimensional experimental\ntasks encountered in chemistry and materials science. We introduce Olympus, a\nsoftware package that provides a consistent and easy-to-use framework for\nbenchmarking optimization algorithms against realistic experiments emulated via\nprobabilistic deep-learning models. Olympus includes a collection of\nexperimentally derived benchmark sets from chemistry and materials science and\na suite of experiment planning strategies that can be easily accessed via a\nuser-friendly python interface. Furthermore, Olympus facilitates the\nintegration, testing, and sharing of custom algorithms and user-defined\ndatasets. In brief, Olympus mitigates the barriers associated with benchmarking\noptimization algorithms on realistic experimental scenarios, promoting data\nsharing and the creation of a standard framework for evaluating the performance\nof experiment planning strategies\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 17:51:51 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 14:37:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["H\u00e4se", "Florian", ""], ["Aldeghi", "Matteo", ""], ["Hickman", "Riley J.", ""], ["Roch", "Lo\u00efc M.", ""], ["Christensen", "Melodie", ""], ["Liles", "Elena", ""], ["Hein", "Jason E.", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "2010.04157", "submitter": "Sitan Chen", "authors": "Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau", "title": "Online and Distribution-Free Robustness: Regression and Contextual\n  Bandits with Huber Contamination", "comments": "66 pages, 1 figure, v3: refined exposition and improved rates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we revisit two classic high-dimensional online learning\nproblems, namely linear regression and contextual bandits, from the perspective\nof adversarial robustness. Existing works in algorithmic robust statistics make\nstrong distributional assumptions that ensure that the input data is evenly\nspread out or comes from a nice generative model. Is it possible to achieve\nstrong robustness guarantees even without distributional assumptions\naltogether, where the sequence of tasks we are asked to solve is adaptively and\nadversarially chosen?\n  We answer this question in the affirmative for both linear regression and\ncontextual bandits. In fact our algorithms succeed where conventional methods\nfail. In particular we show strong lower bounds against Huber regression and\nmore generally any convex M-estimator. Our approach is based on a novel\nalternating minimization scheme that interleaves ordinary least-squares with a\nsimple convex program that finds the optimal reweighting of the distribution\nunder a spectral constraint. Our results obtain essentially optimal dependence\non the contamination level $\\eta$, reach the optimal breakdown point, and\nnaturally apply to infinite dimensional settings where the feature vectors are\nrepresented implicitly via a kernel map.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 17:59:05 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 02:12:07 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 22:54:35 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chen", "Sitan", ""], ["Koehler", "Frederic", ""], ["Moitra", "Ankur", ""], ["Yau", "Morris", ""]]}, {"id": "2010.04196", "submitter": "Charles Onu", "authors": "Charles C. Onu, Jacob E. Miller, Doina Precup", "title": "A Fully Tensorized Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful tools for sequential modeling,\nbut typically require significant overparameterization and regularization to\nachieve optimal performance. This leads to difficulties in the deployment of\nlarge RNNs in resource-limited settings, while also introducing complications\nin hyperparameter selection and training. To address these issues, we introduce\na \"fully tensorized\" RNN architecture which jointly encodes the separate weight\nmatrices within each recurrent cell using a lightweight tensor-train (TT)\nfactorization. This approach represents a novel form of weight sharing which\nreduces model size by several orders of magnitude, while still maintaining\nsimilar or better performance compared to standard RNNs. Experiments on image\nclassification and speaker verification tasks demonstrate further benefits for\nreducing inference times and stabilizing model training and hyperparameter\nselection.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 18:24:12 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 00:25:13 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Onu", "Charles C.", ""], ["Miller", "Jacob E.", ""], ["Precup", "Doina", ""]]}, {"id": "2010.04216", "submitter": "Oriol Barbany Mayor", "authors": "Oriol Barbany Mayor", "title": "Affine-Invariant Robust Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of adversarial robustness has attracted significant attention in\nmachine learning. Contrary to the common approach of training models that are\naccurate in average case, it aims at training models that are accurate for\nworst case inputs, hence it yields more robust and reliable models. Put\ndifferently, it tries to prevent an adversary from fooling a model. The study\nof adversarial robustness is largely focused on $\\ell_p-$bounded adversarial\nperturbations, i.e. modifications of the inputs, bounded in some $\\ell_p$ norm.\nNevertheless, it has been shown that state-of-the-art models are also\nvulnerable to other more natural perturbations such as affine transformations,\nwhich were already considered in machine learning within data augmentation.\nThis project reviews previous work in spatial robustness methods and proposes\nevolution strategies as zeroth order optimization algorithms to find the worst\naffine transforms for each input. The proposed method effectively yields robust\nmodels and allows introducing non-parametric adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 18:59:19 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Mayor", "Oriol Barbany", ""]]}, {"id": "2010.04244", "submitter": "Huozhi Zhou", "authors": "Huozhi Zhou, Jinglin Chen, Lav R. Varshney, and Ashish Jagmohan", "title": "Nonstationary Reinforcement Learning with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reinforcement learning (RL) in episodic Markov decision processes\n(MDPs) with linear function approximation under drifting environment.\nSpecifically, both the reward and state transition functions can evolve over\ntime, as long as their respective total variations, quantified by suitable\nmetrics, do not exceed certain \\textit{variation budgets}. We first develop the\n$\\texttt{LSVI-UCB-Restart}$ algorithm, an optimistic modification of\nleast-squares value iteration combined with periodic restart, and establish its\ndynamic regret bound when variation budgets are known. We then propose a\nparameter-free algorithm, $\\texttt{Ada-LSVI-UCB-Restart}$, that works without\nknowing the variation budgets, but with a slightly worse dynamic regret bound.\nWe also derive the first minimax dynamic regret lower bound for nonstationary\nMDPs to show that our proposed algorithms are near-optimal. As a byproduct, we\nestablish a minimax regret lower bound for linear MDPs, which is unsolved by\n\\cite{jin2020provably}. In addition, we provide numerical experiments to\ndemonstrate the effectiveness of our proposed algorithms. As far as we know,\nthis is the first dynamic regret analysis in nonstationary reinforcement\nlearning with function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 20:07:44 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 04:56:38 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Zhou", "Huozhi", ""], ["Chen", "Jinglin", ""], ["Varshney", "Lav R.", ""], ["Jagmohan", "Ashish", ""]]}, {"id": "2010.04261", "submitter": "Xingyu Zhu", "authors": "Yikai Wu, Xingyu Zhu, Chenwei Wu, Annie Wang, Rong Ge", "title": "Dissecting Hessian: Understanding Common Structure of Hessian in Neural\n  Networks", "comments": "60 pages, 30 figures. Main text: 10 pages, 7 figures. First two\n  authors have equal contribution and are in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hessian captures important properties of the deep neural network loss\nlandscape. Previous works have observed low rank structure in the Hessians of\nneural networks. We make several new observations about the top eigenspace of\nlayer-wise Hessian: top eigenspaces for different models have surprisingly high\noverlap, and top eigenvectors form low rank matrices when they are reshaped\ninto the same shape as the corresponding weight matrix. Towards formally\nexplaining such structures of the Hessian, we show that the new eigenspace\nstructure can be explained by approximating the Hessian using Kronecker\nfactorization; we also prove the low rank structure for random data at random\ninitialization for over-parametrized two-layer neural nets. Our new\nunderstanding can explain why some of these structures become weaker when the\nnetwork is trained with batch normalization. The Kronecker factorization also\nleads to better explicit generalization bounds.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 21:18:11 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 18:02:21 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 08:44:47 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 15:39:47 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 15:27:49 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wu", "Yikai", ""], ["Zhu", "Xingyu", ""], ["Wu", "Chenwei", ""], ["Wang", "Annie", ""], ["Ge", "Rong", ""]]}, {"id": "2010.04290", "submitter": "Alaa Maalouf", "authors": "Alaa Maalouf and Harry Lang and Daniela Rus and Dan Feldman", "title": "Deep Learning Meets Projective Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach for compressing NLP networks is to encode the embedding\nlayer as a matrix $A\\in\\mathbb{R}^{n\\times d}$, compute its rank-$j$\napproximation $A_j$ via SVD, and then factor $A_j$ into a pair of matrices that\ncorrespond to smaller fully-connected layers to replace the original embedding\nlayer. Geometrically, the rows of $A$ represent points in $\\mathbb{R}^d$, and\nthe rows of $A_j$ represent their projections onto the $j$-dimensional subspace\nthat minimizes the sum of squared distances (\"errors\") to the points. In\npractice, these rows of $A$ may be spread around $k>1$ subspaces, so factoring\n$A$ based on a single subspace may lead to large errors that turn into large\ndrops in accuracy.\n  Inspired by \\emph{projective clustering} from computational geometry, we\nsuggest replacing this subspace by a set of $k$ subspaces, each of dimension\n$j$, that minimizes the sum of squared distances over every point (row in $A$)\nto its \\emph{closest} subspace. Based on this approach, we provide a novel\narchitecture that replaces the original embedding layer by a set of $k$ small\nlayers that operate in parallel and are then recombined with a single\nfully-connected layer.\n  Extensive experimental results on the GLUE benchmark yield networks that are\nboth more accurate and smaller compared to the standard matrix factorization\n(SVD). For example, we further compress DistilBERT by reducing the size of the\nembedding layer by $40\\%$ while incurring only a $0.5\\%$ average drop in\naccuracy over all nine GLUE tasks, compared to a $2.8\\%$ drop using the\nexisting SVD approach. On RoBERTa we achieve $43\\%$ compression of the\nembedding layer with less than a $0.8\\%$ average drop in accuracy as compared\nto a $3\\%$ drop previously. Open code for reproducing and extending our results\nis provided.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:47:48 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Maalouf", "Alaa", ""], ["Lang", "Harry", ""], ["Rus", "Daniela", ""], ["Feldman", "Dan", ""]]}, {"id": "2010.04296", "submitter": "Manuel W\\\"uthrich", "authors": "Ossama Ahmed and Frederik Tr\\\"auble and Anirudh Goyal and Alexander\n  Neitz and Yoshua Bengio and Bernhard Sch\\\"olkopf and Manuel W\\\"uthrich and\n  Stefan Bauer", "title": "CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and\n  Transfer Learning", "comments": "The first two authors contributed equally, the last two authors\n  avised jointly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent successes of reinforcement learning (RL), it remains a\nchallenge for agents to transfer learned skills to related environments. To\nfacilitate research addressing this problem, we propose CausalWorld, a\nbenchmark for causal structure and transfer learning in a robotic manipulation\nenvironment. The environment is a simulation of an open-source robotic\nplatform, hence offering the possibility of sim-to-real transfer. Tasks consist\nof constructing 3D shapes from a given set of blocks - inspired by how children\nlearn to build complex structures. The key strength of CausalWorld is that it\nprovides a combinatorial family of such tasks with common causal structure and\nunderlying factors (including, e.g., robot and object masses, colors, sizes).\nThe user (or the agent) may intervene on all causal variables, which allows for\nfine-grained control over how similar different tasks (or task distributions)\nare. One can thus easily define training and evaluation distributions of a\ndesired difficulty level, targeting a specific form of generalization (e.g.,\nonly changes in appearance or object mass). Further, this common\nparametrization facilitates defining curricula by interpolating between an\ninitial and a target task. While users may define their own task distributions,\nwe present eight meaningful distributions as concrete benchmarks, ranging from\nsimple to very challenging, all of which require long-horizon planning as well\nas precise low-level motor control. Finally, we provide baseline results for a\nsubset of these tasks on distinct training curricula and corresponding\nevaluation protocols, verifying the feasibility of the tasks in this benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 23:01:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 16:05:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Ahmed", "Ossama", ""], ["Tr\u00e4uble", "Frederik", ""], ["Goyal", "Anirudh", ""], ["Neitz", "Alexander", ""], ["Bengio", "Yoshua", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["W\u00fcthrich", "Manuel", ""], ["Bauer", "Stefan", ""]]}, {"id": "2010.04305", "submitter": "Barinder Thind", "authors": "Barinder Thind, Kevin Multani, Jiguo Cao", "title": "Neural Networks as Functional Classifiers", "comments": "28 pages, 4 figures, submitted to CSDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been considerable innovation in the world of\npredictive methodologies. This is evident by the relative domination of machine\nlearning approaches in various classification competitions. While these\nalgorithms have excelled at multivariate problems, they have remained dormant\nin the realm of functional data analysis. We extend notable deep learning\nmethodologies to the domain of functional data for the purpose of\nclassification problems. We highlight the effectiveness of our method in a\nnumber of classification applications such as classification of spectrographic\ndata. Moreover, we demonstrate the performance of our classifier through\nsimulation studies in which we compare our approach to the functional linear\nmodel and other conventional classification methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 00:11:01 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Thind", "Barinder", ""], ["Multani", "Kevin", ""], ["Cao", "Jiguo", ""]]}, {"id": "2010.04315", "submitter": "Anthony Tompkins", "authors": "Anthony Tompkins, Rafael Oliveira, Fabio Ramos", "title": "Sparse Spectrum Warped Input Measures for Nonstationary Kernel Learning", "comments": "Accepted version for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a general form of explicit, input-dependent, measure-valued\nwarpings for learning nonstationary kernels. While stationary kernels are\nubiquitous and simple to use, they struggle to adapt to functions that vary in\nsmoothness with respect to the input. The proposed learning algorithm warps\ninputs as conditional Gaussian measures that control the smoothness of a\nstandard stationary kernel. This construction allows us to capture\nnon-stationary patterns in the data and provides intuitive inductive bias. The\nresulting method is based on sparse spectrum Gaussian processes, enabling\nclosed-form solutions, and is extensible to a stacked construction to capture\nmore complex patterns. The method is extensively validated alongside related\nalgorithms on synthetic and real world datasets. We demonstrate a remarkable\nefficiency in the number of parameters of the warping functions in learning\nproblems with both small and large data regimes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 01:10:08 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Tompkins", "Anthony", ""], ["Oliveira", "Rafael", ""], ["Ramos", "Fabio", ""]]}, {"id": "2010.04326", "submitter": "Richmond Addo Danquah", "authors": "Richmond Addo Danquah", "title": "Handling Imbalanced Data: A Case Study for Binary Class Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For several years till date, the major issues in terms of solving for\nclassification problems are the issues of Imbalanced data. Because majority of\nthe machine learning algorithms by default assumes all data are balanced, the\nalgorithms do not take into consideration the distribution of the data sample\nclass. The results tend to be unsatisfactory and skewed towards the majority\nsample class distribution. This implies that the consequences as a result of\nusing a model built using an Imbalanced data without handling for the Imbalance\nin the data could be misleading both in practice and theory. Most researchers\nhave focused on the application of Synthetic Minority Oversampling Technique\n(SMOTE) and Adaptive Synthetic (ADASYN) Sampling Approach in handling data\nImbalance independently in their works and have failed to better explain the\nalgorithms behind these techniques with computed examples. This paper focuses\non both synthetic oversampling techniques and manually computes synthetic data\npoints to enhance easy comprehension of the algorithms. We analyze the\napplication of these synthetic oversampling techniques on binary classification\nproblems with different Imbalanced ratios and sample sizes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 02:04:14 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Danquah", "Richmond Addo", ""]]}, {"id": "2010.04360", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Yusuke Tanaka", "title": "Few-shot Learning for Spatial Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a few-shot learning method for spatial regression. Although\nGaussian processes (GPs) have been successfully used for spatial regression,\nthey require many observations in the target task to achieve a high predictive\nperformance. Our model is trained using spatial datasets on various attributes\nin various regions, and predicts values on unseen attributes in unseen regions\ngiven a few observed data. With our model, a task representation is inferred\nfrom given small data using a neural network. Then, spatial values are\npredicted by neural networks with a GP framework, in which task-specific\nproperties are controlled by the task representations. The GP framework allows\nus to analytically obtain predictions that are adapted to small data. By using\nthe adapted predictions in the objective function, we can train our model\nefficiently and effectively so that the test predictive performance improves\nwhen adapted to newly given small data. In our experiments, we demonstrate that\nthe proposed method achieves better predictive performance than existing\nmeta-learning methods using spatial datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:05:01 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Tanaka", "Yusuke", ""]]}, {"id": "2010.04430", "submitter": "Manuel Gomez Rodriguez", "authors": "Utkarsh Upadhyay and Graham Lancashire and Christoph Moser and Manuel\n  Gomez-Rodriguez", "title": "Large-scale randomized experiment reveals machine learning helps people\n  learn and remember more effectively", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has typically focused on developing models and algorithms\nthat would ultimately replace humans at tasks where intelligence is required.\nIn this work, rather than replacing humans, we focus on unveiling the potential\nof machine learning to improve how people learn and remember factual material.\nTo this end, we perform a large-scale randomized controlled trial with\nthousands of learners from a popular learning app in the area of mobility.\nAfter controlling for the length and frequency of study, we find that learners\nwhose study sessions are optimized using machine learning remember the content\nover $\\sim$67% longer than those whose study sessions are generated using two\nalternative heuristics. Our randomized controlled trial also reveals that the\nlearners whose study sessions are optimized using machine learning are\n$\\sim$50% more likely to return to the app within 4-7 days.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 08:30:15 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Upadhyay", "Utkarsh", ""], ["Lancashire", "Graham", ""], ["Moser", "Christoph", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2010.04438", "submitter": "Harris Chan", "authors": "Harris Chan, Jamie Kiros, William Chan", "title": "Multichannel Generative Language Model: Learning All Possible\n  Factorizations Within and Across Channels", "comments": "10 pages (+3 appendix), 11 figures, 5 tables. Accepted to Findings of\n  EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A channel corresponds to a viewpoint or transformation of an underlying\nmeaning. A pair of parallel sentences in English and French express the same\nunderlying meaning, but through two separate channels corresponding to their\nlanguages. In this work, we present the Multichannel Generative Language Model\n(MGLM). MGLM is a generative joint distribution model over channels. MGLM\nmarginalizes over all possible factorizations within and across all channels.\nMGLM endows flexible inference, including unconditional generation, conditional\ngeneration (where 1 channel is observed and other channels are generated), and\npartially observed generation (where incomplete observations are spread across\nall the channels). We experiment with the Multi30K dataset containing English,\nFrench, Czech, and German. We demonstrate experiments with unconditional,\nconditional, and partially conditional generation. We provide qualitative\nsamples sampled unconditionally from the generative joint distribution. We also\nquantitatively analyze the quality-diversity trade-offs and find MGLM\noutperforms traditional bilingual discriminative models.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 08:52:24 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chan", "Harris", ""], ["Kiros", "Jamie", ""], ["Chan", "William", ""]]}, {"id": "2010.04440", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac, Reda Ouhamma, Odalric-Ambrym Maillard, Philippe\n  Preux", "title": "Learning Value Functions in Deep Policy Gradients using Residual\n  Variance", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Policy gradient algorithms have proven to be successful in diverse decision\nmaking and control tasks. However, these methods suffer from high sample\ncomplexity and instability issues. In this paper, we address these challenges\nby providing a different approach for training the critic in the actor-critic\nframework. Our work builds on recent studies indicating that traditional\nactor-critic algorithms do not succeed in fitting the true value function,\ncalling for the need to identify a better objective for the critic. In our\nmethod, the critic uses a new state-value (resp. state-action-value) function\napproximation that learns the value of the states (resp. state-action pairs)\nrelative to their mean value rather than the absolute value as in conventional\nactor-critic. We prove the theoretical consistency of the new gradient\nestimator and observe dramatic empirical improvement across a variety of\ncontinuous control tasks and algorithms. Furthermore, we validate our method in\ntasks with sparse rewards, where we provide experimental evidence and\ntheoretical insights.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 08:57:06 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 18:05:34 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 18:51:46 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Ouhamma", "Reda", ""], ["Maillard", "Odalric-Ambrym", ""], ["Preux", "Philippe", ""]]}, {"id": "2010.04456", "submitter": "Vincent Le-Guen", "authors": "Vincent Le Guen, Yuan Yin, J\\'er\\'emie Dona, Ibrahim Ayed, Emmanuel de\n  B\\'ezenac, Nicolas Thome, Patrick Gallinari", "title": "Augmenting Physical Models with Deep Networks for Complex Dynamics\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forecasting complex dynamical phenomena in settings where only partial\nknowledge of their dynamics is available is a prevalent problem across various\nscientific fields. While purely data-driven approaches are arguably\ninsufficient in this context, standard physical modeling based approaches tend\nto be over-simplistic, inducing non-negligible errors. In this work, we\nintroduce the APHYNITY framework, a principled approach for augmenting\nincomplete physical dynamics described by differential equations with deep\ndata-driven models. It consists in decomposing the dynamics into two\ncomponents: a physical component accounting for the dynamics for which we have\nsome prior knowledge, and a data-driven component accounting for errors of the\nphysical model. The learning problem is carefully formulated such that the\nphysical model explains as much of the data as possible, while the data-driven\ncomponent only describes information that cannot be captured by the physical\nmodel, no more, no less. This not only provides the existence and uniqueness\nfor this decomposition, but also ensures interpretability and benefits\ngeneralization. Experiments made on three important use cases, each\nrepresentative of a different family of phenomena, i.e. reaction-diffusion\nequations, wave equations and the non-linear damped pendulum, show that\nAPHYNITY can efficiently leverage approximate physical models to accurately\nforecast the evolution of the system and correctly identify relevant physical\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:31:03 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 08:49:33 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 18:18:27 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Guen", "Vincent Le", ""], ["Yin", "Yuan", ""], ["Dona", "J\u00e9r\u00e9mie", ""], ["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Thome", "Nicolas", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2010.04486", "submitter": "Pierangelo Lombardo", "authors": "Pierangelo Lombardo, Alessio Boiardi, Luca Colombo, Angelo Schiavone,\n  Nicol\\`o Tamagnone", "title": "Top-Rank-Focused Adaptive Vote Collection for the Evaluation of\n  Domain-Specific Semantic Models", "comments": "This is a pre-print of an article published in the proceedings of the\n  2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "journal-ref": "Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP) (pp. 3081-3093)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of domain-specific applications of semantic models, boosted by the\nrecent achievements of unsupervised embedding learning algorithms, demands\ndomain-specific evaluation datasets. In many cases, content-based recommenders\nbeing a prime example, these models are required to rank words or texts\naccording to their semantic relatedness to a given concept, with particular\nfocus on top ranks. In this work, we give a threefold contribution to address\nthese requirements: (i) we define a protocol for the construction, based on\nadaptive pairwise comparisons, of a relatedness-based evaluation dataset\ntailored on the available resources and optimized to be particularly accurate\nin top-rank evaluation; (ii) we define appropriate metrics, extensions of\nwell-known ranking correlation coefficients, to evaluate a semantic model via\nthe aforementioned dataset by taking into account the greater significance of\ntop ranks. Finally, (iii) we define a stochastic transitivity model to simulate\nsemantic-driven pairwise comparisons, which confirms the effectiveness of the\nproposed dataset construction protocol.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 10:20:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lombardo", "Pierangelo", ""], ["Boiardi", "Alessio", ""], ["Colombo", "Luca", ""], ["Schiavone", "Angelo", ""], ["Tamagnone", "Nicol\u00f2", ""]]}, {"id": "2010.04512", "submitter": "Namid Stillman Dr.", "authors": "Namid Stillman, Igor Balazs, Sabine Hauert", "title": "Model Exploration with Cost-Aware Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension to active learning routines in which non-constant\ncosts are explicitly considered. This work considers both known and unknown\ncosts and introduces the term \\epsilon-frugal for learners that do not only\nconsider minimizing total costs but are also able to explore high cost regions\nof the sample space. We demonstrate our extension on a well-known machine\nlearning dataset and find that out \\epsilon-frugal learners outperform both\nlearners with known costs and random sampling.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 11:48:39 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Stillman", "Namid", ""], ["Balazs", "Igor", ""], ["Hauert", "Sabine", ""]]}, {"id": "2010.04535", "submitter": "Ryan Henderson", "authors": "Ryan Henderson, Djork-Arn\\'e Clevert, Floriane Montanari", "title": "Gini in a Bottleneck: Sparse Molecular Representations for Graph\n  Convolutional Neural Networks", "comments": "Accepted to Machine Learning for Molecules Workshop @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the nature of deep learning approaches, it is inherently difficult to\nunderstand which aspects of a molecular graph drive the predictions of the\nnetwork. As a mitigation strategy, we constrain certain weights in a multi-task\ngraph convolutional neural network according to the Gini index to maximize the\n\"inequality\" of the learned representations. We show that this constraint does\nnot degrade evaluation metrics for some targets, and allows us to combine the\noutputs of the graph convolutional operation in a visually interpretable way.\nWe then perform a proof-of-concept experiment on quantum chemistry targets on\nthe public QM9 dataset, and a larger experiment on ADMET targets on proprietary\ndrug-like molecules. Since a benchmark of explainability in the latter case is\ndifficult, we informally surveyed medicinal chemists within our organization to\ncheck for agreement between regions of the molecule they and the model\nidentified as relevant to the properties in question.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 12:55:17 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 11:01:05 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 10:46:31 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Henderson", "Ryan", ""], ["Clevert", "Djork-Arn\u00e9", ""], ["Montanari", "Floriane", ""]]}, {"id": "2010.04554", "submitter": "Huiting Hong", "authors": "Yucheng Lin, Huiting Hong, Xiaoqing Yang, Xiaodi Yang, Pinghua Gong,\n  Jieping Ye", "title": "Meta Graph Attention on Heterogeneous Graph with Node-Edge Co-evolution", "comments": "11pages, 4figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have become an important tool for modeling structured\ndata. In many real-world systems, intricate hidden information may exist, e.g.,\nheterogeneity in nodes/edges, static node/edge attributes, and spatiotemporal\nnode/edge features. However, most existing methods only take part of the\ninformation into consideration. In this paper, we present the Co-evolved Meta\nGraph Neural Network (CoMGNN), which applies meta graph attention to\nheterogeneous graphs with co-evolution of node and edge states. We further\npropose a spatiotemporal adaption of CoMGNN (ST-CoMGNN) for modeling\nspatiotemporal patterns on nodes and edges. We conduct experiments on two\nlarge-scale real-world datasets. Experimental results show that our models\nsignificantly outperform the state-of-the-art methods, demonstrating the\neffectiveness of encoding diverse information from different aspects.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 13:19:39 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lin", "Yucheng", ""], ["Hong", "Huiting", ""], ["Yang", "Xiaoqing", ""], ["Yang", "Xiaodi", ""], ["Gong", "Pinghua", ""], ["Ye", "Jieping", ""]]}, {"id": "2010.04558", "submitter": "Devanshu Arya", "authors": "Devanshu Arya, Deepak K. Gupta, Stevan Rudinac and Marcel Worring", "title": "HyperSAGE: Generalizing Inductive Representation Learning on Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are the most ubiquitous form of structured data representation used in\nmachine learning. They model, however, only pairwise relations between nodes\nand are not designed for encoding the higher-order relations found in many\nreal-world datasets. To model such complex relations, hypergraphs have proven\nto be a natural representation. Learning the node representations in a\nhypergraph is more complex than in a graph as it involves information\npropagation at two levels: within every hyperedge and across the hyperedges.\nMost current approaches first transform a hypergraph structure to a graph for\nuse in existing geometric deep learning algorithms. This transformation leads\nto information loss, and sub-optimal exploitation of the hypergraph's\nexpressive power. We present HyperSAGE, a novel hypergraph learning framework\nthat uses a two-level neural message passing strategy to accurately and\nefficiently propagate information through hypergraphs. The flexible design of\nHyperSAGE facilitates different ways of aggregating neighborhood information.\nUnlike the majority of related work which is transductive, our approach,\ninspired by the popular GraphSAGE method, is inductive. Thus, it can also be\nused on previously unseen nodes, facilitating deployment in problems such as\nevolving or partially observed hypergraphs. Through extensive experimentation,\nwe show that HyperSAGE outperforms state-of-the-art hypergraph learning methods\non representative benchmark datasets. We also demonstrate that the higher\nexpressive power of HyperSAGE makes it more stable in learning node\nrepresentations as compared to the alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 13:28:06 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Arya", "Devanshu", ""], ["Gupta", "Deepak K.", ""], ["Rudinac", "Stevan", ""], ["Worring", "Marcel", ""]]}, {"id": "2010.04589", "submitter": "Xinyu Dong", "authors": "Xinyu Dong, Jianyuan Deng, Sina Rashidian, Kayley Abell-Hart, Wei Hou,\n  Richard N Rosenthal, Mary Saltz, Joel Saltz, Fusheng Wang", "title": "Identifying Risk of Opioid Use Disorder for Patients Taking Opioid\n  Medications with Deep Learning", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The United States is experiencing an opioid epidemic, and there were more\nthan 10 million opioid misusers aged 12 or older each year. Identifying\npatients at high risk of Opioid Use Disorder (OUD) can help to make early\nclinical interventions to reduce the risk of OUD. Our goal is to predict OUD\npatients among opioid prescription users through analyzing electronic health\nrecords with machine learning and deep learning methods. This will help us to\nbetter understand the diagnoses of OUD, providing new insights on opioid\nepidemic. Electronic health records of patients who have been prescribed with\nmedications containing active opioid ingredients were extracted from Cerner\nHealth Facts database between January 1, 2008 and December 31, 2017. Long\nShort-Term Memory (LSTM) models were applied to predict opioid use disorder\nrisk in the future based on recent five encounters, and compared to Logistic\nRegression, Random Forest, Decision Tree and Dense Neural Network. Prediction\nperformance was assessed using F-1 score, precision, recall, and AUROC. Our\ntemporal deep learning model provided promising prediction results which\noutperformed other methods, with a F1 score of 0.8023 and AUCROC of 0.9369. The\nmodel can identify OUD related medications and vital signs as important\nfeatures for the prediction. LSTM based temporal deep learning model is\neffective on predicting opioid use disorder using a patient past history of\nelectronic health records, with minimal domain knowledge. It has potential to\nimprove clinical decision support for early intervention and prevention to\ncombat the opioid epidemic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:18:07 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Dong", "Xinyu", ""], ["Deng", "Jianyuan", ""], ["Rashidian", "Sina", ""], ["Abell-Hart", "Kayley", ""], ["Hou", "Wei", ""], ["Rosenthal", "Richard N", ""], ["Saltz", "Mary", ""], ["Saltz", "Joel", ""], ["Wang", "Fusheng", ""]]}, {"id": "2010.04591", "submitter": "Alexandre Tartakovsky", "authors": "Tong Ma and David Alonso Barajas-Solano and Ramakrishna Tipireddy and\n  Alexandre M. Tartakovsky", "title": "Physics-Informed Gaussian Process Regression for Probabilistic States\n  Estimation and Forecasting in Power Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time state estimation and forecasting is critical for efficient\noperation of power grids. In this paper, a physics-informed Gaussian process\nregression (PhI-GPR) method is presented and used for probabilistic forecasting\nand estimating the phase angle, angular speed, and wind mechanical power of a\nthree-generator power grid system using sparse measurements. In standard\ndata-driven Gaussian process regression (GPR), parameterized models for the\nprior statistics are fit by maximizing the marginal likelihood of observed\ndata, whereas in PhI-GPR, we compute the prior statistics by solving stochastic\nequations governing power grid dynamics. The short-term forecast of a power\ngrid system dominated by wind generation is complicated by the stochastic\nnature of the wind and the resulting uncertain mechanical wind power. Here, we\nassume that the power-grid dynamic is governed by the swing equations, and we\ntreat the unknown terms in the swing equations (specifically, the mechanical\nwind power) as random processes, which turns these equations into stochastic\ndifferential equations. We solve these equations for the mean and variance of\nthe power grid system using the Monte Carlo simulations method. We demonstrate\nthat the proposed PhI-GPR method can accurately forecast and estimate both\nobserved and unobserved states, including the mean behavior and associated\nuncertainty. For observed states, we show that PhI-GPR provides a forecast\ncomparable to the standard data-driven GPR, with both forecasts being\nsignificantly more accurate than the autoregressive integrated moving average\n(ARIMA) forecast. We also show that the ARIMA forecast is much more sensitive\nto observation frequency and measurement errors than the PhI-GPR forecast.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:18:31 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Ma", "Tong", ""], ["Barajas-Solano", "David Alonso", ""], ["Tipireddy", "Ramakrishna", ""], ["Tartakovsky", "Alexandre M.", ""]]}, {"id": "2010.04592", "submitter": "Joshua Robinson", "authors": "Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, Stefanie Jegelka", "title": "Contrastive Learning with Hard Negative Samples", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can you sample good negative examples for contrastive learning? We argue\nthat, as with metric learning, contrastive learning of representations benefits\nfrom hard negative samples (i.e., points that are difficult to distinguish from\nan anchor point). The key challenge toward using hard negatives is that\ncontrastive methods must remain unsupervised, making it infeasible to adopt\nexisting negative sampling strategies that use true similarity information. In\nresponse, we develop a new family of unsupervised sampling methods for\nselecting hard negative samples where the user can control the hardness. A\nlimiting case of this sampling results in a representation that tightly\nclusters each class, and pushes different classes as far apart as possible. The\nproposed method improves downstream performance across multiple modalities,\nrequires only few additional lines of code to implement, and introduces no\ncomputational overhead.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:18:53 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 22:19:30 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Robinson", "Joshua", ""], ["Chuang", "Ching-Yao", ""], ["Sra", "Suvrit", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2010.04627", "submitter": "Matthew Kusner", "authors": "Valentina Zantedeschi, Matt J. Kusner, Vlad Niculae", "title": "Learning Binary Decision Trees by Argmin Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning binary decision trees that partition data\nfor some downstream task. We propose to learn discrete parameters (i.e., for\ntree traversals and node pruning) and continuous parameters (i.e., for tree\nsplit functions and prediction functions) simultaneously using argmin\ndifferentiation. We do so by sparsely relaxing a mixed-integer program for the\ndiscrete parameters, to allow gradients to pass through the program to\ncontinuous parameters. We derive customized algorithms to efficiently compute\nthe forward and backward passes. This means that our tree learning procedure\ncan be used as an (implicit) layer in arbitrary deep networks, and can be\noptimized with arbitrary loss functions. We demonstrate that our approach\nproduces binary trees that are competitive with existing single tree and\nensemble approaches, in both supervised and unsupervised settings. Further,\napart from greedy approaches (which do not have competitive accuracies), our\nmethod is faster to train than all other tree-learning baselines we compare\nwith. The code for reproducing the results is available at\nhttps://github.com/vzantedeschi/LatentTrees.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:11:28 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 14:35:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Kusner", "Matt J.", ""], ["Niculae", "Vlad", ""]]}, {"id": "2010.04642", "submitter": "Loic Landrieu", "authors": "Thomas Chaton, Nicolas Chaulet, Sofiane Horache, Loic Landrieu", "title": "Torch-Points3D: A Modular Multi-Task Frameworkfor Reproducible Deep\n  Learning on 3D Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Torch-Points3D, an open-source framework designed to facilitate\nthe use of deep networks on3D data. Its modular design, efficient\nimplementation, and user-friendly interfaces make it a relevant tool for\nresearch and productization alike. Beyond multiple quality-of-life features,\nour goal is to standardize a higher level of transparency and reproducibility\nin 3D deep learning research, and to lower its barrier to entry. In this paper,\nwe present the design principles of Torch-Points3D, as well as extensive\nbenchmarks of multiple state-of-the-art algorithms and inference schemes across\nseveral datasets and tasks. The modularity of Torch-Points3D allows us to\ndesign fair and rigorous experimental protocols in which all methods are\nevaluated in the same conditions. The Torch-Points3D repository\n:https://github.com/nicolas-chaulet/torch-points3d\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:34:32 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chaton", "Thomas", ""], ["Chaulet", "Nicolas", ""], ["Horache", "Sofiane", ""], ["Landrieu", "Loic", ""]]}, {"id": "2010.04651", "submitter": "Lorenzo Tomaselli", "authors": "Lorenzo Tomaselli, Coty Jen, Ann B. Lee", "title": "Wildfire Smoke and Air Quality: How Machine Learning Can Guide Forest\n  Management", "comments": "Spotlight talk at the Tackling Climate Change with Machine Learning\n  workshop at NeurIPS 2020 (Proposals Track), 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prescribed burns are currently the most effective method of reducing the risk\nof widespread wildfires, but a largely missing component in forest management\nis knowing which fuels one can safely burn to minimize exposure to toxic smoke.\nHere we show how machine learning, such as spectral clustering and manifold\nlearning, can provide interpretable representations and powerful tools for\ndifferentiating between smoke types, hence providing forest managers with vital\ninformation on effective strategies to reduce climate-induced wildfires while\nminimizing production of harmful smoke.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:49:38 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 02:23:52 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Tomaselli", "Lorenzo", ""], ["Jen", "Coty", ""], ["Lee", "Ann B.", ""]]}, {"id": "2010.04653", "submitter": "Byung-Jun Yoon", "authors": "Byung-Jun Yoon, Xiaoning Qian, Edward R. Dougherty", "title": "Quantifying the multi-objective cost of uncertainty", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2021.3085486", "report-no": null, "categories": "math.OC cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various real-world applications involve modeling complex systems with immense\nuncertainty and optimizing multiple objectives based on the uncertain model.\nQuantifying the impact of the model uncertainty on the given operational\nobjectives is critical for designing optimal experiments that can most\neffectively reduce the uncertainty that affect the objectives pertinent to the\napplication at hand. In this paper, we propose the concept of mean\nmulti-objective cost of uncertainty (multi-objective MOCU) that can be used for\nobjective-based quantification of uncertainty for complex uncertain systems\nconsidering multiple operational objectives. We provide several illustrative\nexamples that demonstrate the concept and strengths of the proposed\nmulti-objective MOCU. Furthermore, we present a real-world example based on the\nmammalian cell cycle network to demonstrate how the multi-objective MOCU can be\nused for quantifying the operational impact of model uncertainty when there are\nmultiple, possibly competing, objectives.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 22:35:02 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 03:11:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yoon", "Byung-Jun", ""], ["Qian", "Xiaoning", ""], ["Dougherty", "Edward R.", ""]]}, {"id": "2010.04683", "submitter": "Jovita Lukasik", "authors": "Jovita Lukasik and David Friede and Arber Zela and Frank Hutter and\n  Margret Keuper", "title": "Smooth Variational Graph Embeddings for Efficient Neural Architecture\n  Search", "comments": "8 pages, 3 figures, 5 tables. Camera-Ready Version for IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has recently been addressed from various\ndirections, including discrete, sampling-based methods and efficient\ndifferentiable approaches. While the former are notoriously expensive, the\nlatter suffer from imposing strong constraints on the search space.\nArchitecture optimization from a learned embedding space for example through\ngraph neural network based variational autoencoders builds a middle ground and\nleverages advantages from both sides. Such approaches have recently shown good\nperformance on several benchmarks. Yet, their stability and predictive power\nheavily depends on their capacity to reconstruct networks from the embedding\nspace. In this paper, we propose a two-sided variational graph autoencoder,\nwhich allows to smoothly encode and accurately reconstruct neural architectures\nfrom various search spaces. We evaluate the proposed approach on neural\narchitectures defined by the ENAS approach, the NAS-Bench-101 and the\nNAS-Bench-201 search space and show that our smooth embedding space allows to\ndirectly extrapolate the performance prediction to architectures outside the\nseen domain (e.g. with more operations). Thus, it facilitates to predict good\nnetwork architectures even without expensive Bayesian optimization or\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:05:41 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 14:50:56 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 12:44:54 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Lukasik", "Jovita", ""], ["Friede", "David", ""], ["Zela", "Arber", ""], ["Hutter", "Frank", ""], ["Keuper", "Margret", ""]]}, {"id": "2010.04703", "submitter": "Bryan Graham", "authors": "Bryan S. Graham", "title": "Sparse network asymptotics for logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a bipartite network where $N$ consumers choose to buy or not to buy\n$M$ different products. This paper considers the properties of the logistic\nregression of the $N\\times M$ array of i-buys-j purchase decisions,\n$\\left[Y_{ij}\\right]_{1\\leq i\\leq N,1\\leq j\\leq M}$, onto known functions of\nconsumer and product attributes under asymptotic sequences where (i) both $N$\nand $M$ grow large and (ii) the average number of products purchased per\nconsumer is finite in the limit. This latter assumption implies that the\nnetwork of purchases is sparse: only a (very) small fraction of all possible\npurchases are actually made (concordant with many real-world settings). Under\nsparse network asymptotics, the first and last terms in an extended\nHoeffding-type variance decomposition of the score of the logit composite\nlog-likelihood are of equal order. In contrast, under dense network\nasymptotics, the last term is asymptotically negligible. Asymptotic normality\nof the logistic regression coefficients is shown using a martingale central\nlimit theorem (CLT) for triangular arrays. Unlike in the dense case, the\nnormality result derived here also holds under degeneracy of the network\ngraphon. Relatedly, when there happens to be no dyadic dependence in the\ndataset in hand, it specializes to recently derived results on the behavior of\nlogistic regression with rare events and iid data. Sparse network asymptotics\nmay lead to better inference in practice since they suggest variance estimators\nwhich (i) incorporate additional sources of sampling variation and (ii) are\nvalid under varying degrees of dyadic dependence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:46:29 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Graham", "Bryan S.", ""]]}, {"id": "2010.04705", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "Algorithmic Frameworks for the Detection of High Density Anomalies", "comments": "10 pages, 9 figures, 6 tables. Accepted for presentation at IEEE SSCI\n  CIDM 2020 (Symposium on Computational Intelligence in Data Mining)", "journal-ref": null, "doi": "10.1109/SSCI47803.2020.9308417", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores the concept of high-density anomalies. As opposed to the\ntraditional concept of anomalies as isolated occurrences, high-density\nanomalies are deviant cases positioned in the most normal regions of the data\nspace. Such anomalies are relevant for various practical use cases, such as\nmisbehavior detection and data quality analysis. Effective methods for\nidentifying them are particularly important when analyzing very large or noisy\nsets, for which traditional anomaly detection algorithms will return many false\npositives. In order to be able to identify high-density anomalies, this study\nintroduces several non-parametric algorithmic frameworks for unsupervised\ndetection. These frameworks are able to leverage existing underlying anomaly\ndetection algorithms and offer different solutions for the balancing problem\ninherent in this detection task. The frameworks are evaluated with both\nsynthetic and real-world datasets, and are compared with existing baseline\nalgorithms for detecting traditional anomalies. The Iterative Partial Push\n(IPP) framework proves to yield the best detection results.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:48:02 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 07:49:39 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2010.04715", "submitter": "Eric Zelikman", "authors": "Eric Zelikman, Sharon Zhou, Jeremy Irvin, Cooper Raterink, Hao Sheng,\n  Anand Avati, Jack Kelly, Ram Rajagopal, Andrew Y. Ng, David Gagne", "title": "Short-Term Solar Irradiance Forecasting Using Calibrated Probabilistic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancing probabilistic solar forecasting methods is essential to supporting\nthe integration of solar energy into the electricity grid. In this work, we\ndevelop a variety of state-of-the-art probabilistic models for forecasting\nsolar irradiance. We investigate the use of post-hoc calibration techniques for\nensuring well-calibrated probabilistic predictions. We train and evaluate the\nmodels using public data from seven stations in the SURFRAD network, and\ndemonstrate that the best model, NGBoost, achieves higher performance at an\nintra-hourly resolution than the best benchmark solar irradiance forecasting\nmodel across all stations. Further, we show that NGBoost with CRUDE post-hoc\ncalibration achieves comparable performance to a numerical weather prediction\nmodel on hourly-resolution forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:57:59 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 16:03:02 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zelikman", "Eric", ""], ["Zhou", "Sharon", ""], ["Irvin", "Jeremy", ""], ["Raterink", "Cooper", ""], ["Sheng", "Hao", ""], ["Avati", "Anand", ""], ["Kelly", "Jack", ""], ["Rajagopal", "Ram", ""], ["Ng", "Andrew Y.", ""], ["Gagne", "David", ""]]}, {"id": "2010.04742", "submitter": "Tymoteusz Tula", "authors": "T. Tula, G. M\\\"oller, J. Quintanilla, S. R. Giblin, A. D. Hillier, E.\n  E. McCabe, S. Ramos, D. S. Barker, S. Gibson", "title": "Machine Learning approach to muon spectroscopy analysis", "comments": "11 pages, 7 figures, to be submitted to the Journal of Physics:\n  Condensed Matter special issue on \"Machine Learning in Condensed Matter\n  Physics\"", "journal-ref": null, "doi": "10.1088/1361-648X/abe39e", "report-no": null, "categories": "cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Artificial Intelligence techniques have proved to be very\nsuccessful when applied to problems in physical sciences. Here we apply an\nunsupervised Machine Learning (ML) algorithm called Principal Component\nAnalysis (PCA) as a tool to analyse the data from muon spectroscopy\nexperiments. Specifically, we apply the ML technique to detect phase\ntransitions in various materials. The measured quantity in muon spectroscopy is\nan asymmetry function, which may hold information about the distribution of the\nintrinsic magnetic field in combination with the dynamics of the sample. Sharp\nchanges of shape of asymmetry functions - measured at different temperatures -\nmight indicate a phase transition. Existing methods of processing the muon\nspectroscopy data are based on regression analysis, but choosing the right\nfitting function requires knowledge about the underlying physics of the probed\nmaterial. Conversely, Principal Component Analysis focuses on small differences\nin the asymmetry curves and works without any prior assumptions about the\nstudied samples. We discovered that the PCA method works well in detecting\nphase transitions in muon spectroscopy experiments and can serve as an\nalternative to current analysis, especially if the physics of the studied\nmaterial are not entirely known. Additionally, we found out that our ML\ntechnique seems to work best with large numbers of measurements, regardless of\nwhether the algorithm takes data only for a single material or whether the\nanalysis is performed simultaneously for many materials with different physical\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 18:01:11 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 18:00:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Tula", "T.", ""], ["M\u00f6ller", "G.", ""], ["Quintanilla", "J.", ""], ["Giblin", "S. R.", ""], ["Hillier", "A. D.", ""], ["McCabe", "E. E.", ""], ["Ramos", "S.", ""], ["Barker", "D. S.", ""], ["Gibson", "S.", ""]]}, {"id": "2010.04805", "submitter": "Alex Luedtke", "authors": "Sijia Li, Xiudi Li, Alex Luedtke", "title": "Discussion of Kallus (2020) and Mo, Qi, and Liu (2020): New Objectives\n  for Policy Learning", "comments": "Submitted to the Journal of the American Statistical Association as\n  an invited discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the thought-provoking new objective functions for policy learning\nthat were proposed in \"More efficient policy learning via optimal retargeting\"\nby Nathan Kallus and \"Learning optimal distributionally robust individualized\ntreatment rules\" by Weibin Mo, Zhengling Qi, and Yufeng Liu. We show that it is\nimportant to take the curvature of the value function into account when working\nwithin the retargeting framework, and we introduce two ways to do so. We also\ndescribe more efficient approaches for leveraging calibration data when\nlearning distributionally robust policies.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 21:05:01 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Sijia", ""], ["Li", "Xiudi", ""], ["Luedtke", "Alex", ""]]}, {"id": "2010.04819", "submitter": "Zhun Deng", "authors": "Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, James Zou", "title": "How Does Mixup Help With Robustness and Generalization?", "comments": "Accepted by ICLR 2021, and selected as spotlight (top 6% of\n  submissions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixup is a popular data augmentation technique based on taking convex\ncombinations of pairs of examples and their labels. This simple technique has\nbeen shown to substantially improve both the robustness and the generalization\nof the trained model. However, it is not well-understood why such improvement\noccurs. In this paper, we provide theoretical analysis to demonstrate how using\nMixup in training helps model robustness and generalization. For robustness, we\nshow that minimizing the Mixup loss corresponds to approximately minimizing an\nupper bound of the adversarial loss. This explains why models obtained by Mixup\ntraining exhibits robustness to several kinds of adversarial attacks such as\nFast Gradient Sign Method (FGSM). For generalization, we prove that Mixup\naugmentation corresponds to a specific type of data-adaptive regularization\nwhich reduces overfitting. Our analysis provides new insights and a framework\nto understand Mixup.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 21:38:14 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 03:03:27 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 20:22:55 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 19:43:43 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zhang", "Linjun", ""], ["Deng", "Zhun", ""], ["Kawaguchi", "Kenji", ""], ["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "2010.04831", "submitter": "Shib Sankar Dasgupta", "authors": "Shib Sankar Dasgupta, Michael Boratko, Dongxu Zhang, Luke Vilnis,\n  Xiang Lorraine Li, Andrew McCallum", "title": "Improving Local Identifiability in Probabilistic Box Embeddings", "comments": "Accepted at NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric embeddings have recently received attention for their natural\nability to represent transitive asymmetric relations via containment. Box\nembeddings, where objects are represented by n-dimensional hyperrectangles, are\na particularly promising example of such an embedding as they are closed under\nintersection and their volume can be calculated easily, allowing them to\nnaturally represent calibrated probability distributions. The benefits of\ngeometric embeddings also introduce a problem of local identifiability,\nhowever, where whole neighborhoods of parameters result in equivalent loss\nwhich impedes learning. Prior work addressed some of these issues by using an\napproximation to Gaussian convolution over the box parameters, however, this\nintersection operation also increases the sparsity of the gradient. In this\nwork, we model the box parameters with min and max Gumbel distributions, which\nwere chosen such that space is still closed under the operation of the\nintersection. The calculation of the expected intersection volume involves all\nparameters, and we demonstrate experimentally that this drastically improves\nthe ability of such models to learn.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:34:12 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 01:39:49 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Dasgupta", "Shib Sankar", ""], ["Boratko", "Michael", ""], ["Zhang", "Dongxu", ""], ["Vilnis", "Luke", ""], ["Li", "Xiang Lorraine", ""], ["McCallum", "Andrew", ""]]}, {"id": "2010.04838", "submitter": "Max Benedikt Paulus", "authors": "Max B. Paulus, Chris J. Maddison, Andreas Krause", "title": "Rao-Blackwellizing the Straight-Through Gumbel-Softmax Gradient\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient estimation in models with discrete latent variables is a challenging\nproblem, because the simplest unbiased estimators tend to have high variance.\nTo counteract this, modern estimators either introduce bias, rely on multiple\nfunction evaluations, or use learned, input-dependent baselines. Thus, there is\na need for estimators that require minimal tuning, are computationally cheap,\nand have low mean squared error. In this paper, we show that the variance of\nthe straight-through variant of the popular Gumbel-Softmax estimator can be\nreduced through Rao-Blackwellization without increasing the number of function\nevaluations. This provably reduces the mean squared error. We empirically\ndemonstrate that this leads to variance reduction, faster convergence, and\ngenerally improved performance in two unsupervised latent variable models.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 22:54:38 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Paulus", "Max B.", ""], ["Maddison", "Chris J.", ""], ["Krause", "Andreas", ""]]}, {"id": "2010.04840", "submitter": "Jiahao Chen", "authors": "Leo de Castro and Jiahao Chen and Antigoni Polychroniadou", "title": "CryptoCredit: Securely Training Fair Models", "comments": "8 pages", "journal-ref": "Proceedings of the 1st ACM International Conference on AI in\n  Finance (ICAIF '20), October 15-16, 2020, New York, NY, USA", "doi": "10.1145/3383455.3422567", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing models for regulated decision making, sensitive features like\nage, race and gender cannot be used and must be obscured from model developers\nto prevent bias. However, the remaining features still need to be tested for\ncorrelation with sensitive features, which can only be done with the knowledge\nof those features. We resolve this dilemma using a fully homomorphic encryption\nscheme, allowing model developers to train linear regression and logistic\nregression models and test them for possible bias without ever revealing the\nsensitive features in the clear. We demonstrate how it can be applied to\nleave-one-out regression testing, and show using the adult income data set that\nour method is practical to run.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 23:05:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["de Castro", "Leo", ""], ["Chen", "Jiahao", ""], ["Polychroniadou", "Antigoni", ""]]}, {"id": "2010.04855", "submitter": "Rahul Singh", "authors": "Rahul Singh, Liyuan Xu, Arthur Gretton", "title": "Reproducing Kernel Methods for Nonparametric and Semiparametric\n  Treatment Effects", "comments": "Formerly \"Kernel Methods for Policy Evaluation: Treatment Effects,\n  Mediation Analysis, and Off-Policy Planning\" (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of reproducing kernel ridge estimators for nonparametric\nand semiparametric policy evaluation. The framework includes (i) treatment\neffects of the population, of subpopulations, and of alternative populations;\n(ii) the decomposition of a total effect into a direct effect and an indirect\neffect (mediated by a particular mechanism); and (iii) effects of sequences of\ntreatments. Treatment and covariates may be discrete or continuous, and low,\nhigh, or infinite dimensional. We consider estimation of means, increments, and\ndistributions of counterfactual outcomes. Each estimator is an inner product in\na reproducing kernel Hilbert space (RKHS), with a one line, closed form\nsolution. For the nonparametric case, we prove uniform consistency and provide\nfinite sample rates of convergence. For the semiparametric case, we prove root\nn consistency, Gaussian approximation, and semiparametric efficiency by finite\nsample arguments. We evaluate our estimators in simulations then estimate\ncontinuous, heterogeneous, incremental, and mediated treatment effects of the\nUS Jobs Corps training program for disadvantaged youth.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 00:53:11 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 15:29:08 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 16:14:00 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Singh", "Rahul", ""], ["Xu", "Liyuan", ""], ["Gretton", "Arthur", ""]]}, {"id": "2010.04862", "submitter": "Dong Wang", "authors": "Dong Wang", "title": "Remarks on Optimal Scores for Speaker Recognition", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we first establish the theory of optimal scores for speaker\nrecognition. Our analysis shows that the minimum Bayes risk (MBR) decisions for\nboth the speaker identification and speaker verification tasks can be based on\na normalized likelihood (NL). When the underlying generative model is a linear\nGaussian, the NL score is mathematically equivalent to the PLDA likelihood\nratio, and the empirical scores based on cosine distance and Euclidean distance\ncan be seen as approximations of this linear Gaussian NL score under some\nconditions. We discuss a number of properties of the NL score and perform a\nsimple simulation experiment to demonstrate the properties of the NL score.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 01:28:24 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 03:33:49 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Dong", ""]]}, {"id": "2010.04875", "submitter": "Alex Williams", "authors": "Alex H. Williams, Anthony Degleris, Yixin Wang, Scott W. Linderman", "title": "Point process models for sequence detection in high-dimensional neural\n  spike trains", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse sequences of neural spikes are posited to underlie aspects of working\nmemory, motor production, and learning. Discovering these sequences in an\nunsupervised manner is a longstanding problem in statistical neuroscience.\nPromising recent work utilized a convolutive nonnegative matrix factorization\nmodel to tackle this challenge. However, this model requires spike times to be\ndiscretized, utilizes a sub-optimal least-squares criterion, and does not\nprovide uncertainty estimates for model predictions or estimated parameters. We\naddress each of these shortcomings by developing a point process model that\ncharacterizes fine-scale sequences at the level of individual spikes and\nrepresents sequence occurrences as a small number of marked events in\ncontinuous time. This ultra-sparse representation of sequence events opens new\npossibilities for spike train modeling. For example, we introduce learnable\ntime warping parameters to model sequences of varying duration, which have been\nexperimentally observed in neural circuits. We demonstrate these advantages on\nexperimental recordings from songbird higher vocal center and rodent\nhippocampus.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 02:21:44 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Williams", "Alex H.", ""], ["Degleris", "Anthony", ""], ["Wang", "Yixin", ""], ["Linderman", "Scott W.", ""]]}, {"id": "2010.04890", "submitter": "Yuanlu Bai", "authors": "Yuanlu Bai, Zhiyuan Huang, Henry Lam, Ding Zhao", "title": "Rare-Event Simulation for Neural Network and Random Forest Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study rare-event simulation for a class of problems where the target\nhitting sets of interest are defined via modern machine learning tools such as\nneural networks and random forests. This problem is motivated from fast\nemerging studies on the safety evaluation of intelligent systems, robustness\nquantification of learning models, and other potential applications to\nlarge-scale simulation in which machine learning tools can be used to\napproximate complex rare-event set boundaries. We investigate an importance\nsampling scheme that integrates the dominating point machinery in large\ndeviations and sequential mixed integer programming to locate the underlying\ndominating points. Our approach works for a range of neural network\narchitectures including fully connected layers, rectified linear units,\nnormalization, pooling and convolutional layers, and random forests built from\nstandard decision trees. We provide efficiency guarantees and numerical\ndemonstration of our approach using a classification model in the UCI Machine\nLearning Repository.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 03:27:09 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bai", "Yuanlu", ""], ["Huang", "Zhiyuan", ""], ["Lam", "Henry", ""], ["Zhao", "Ding", ""]]}, {"id": "2010.04895", "submitter": "Yingxia Shao", "authors": "Xingyu Yao, Yingxia Shao, Bin Cui, Lei Chen", "title": "UniNet: Scalable Network Representation Learning with\n  Metropolis-Hastings Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) technique has been successfully adopted\nin various data mining and machine learning applications. Random walk based NRL\nis one popular paradigm, which uses a set of random walks to capture the\nnetwork structural information, and then employs word2vec models to learn the\nlow-dimensional representations. However, until now there is lack of a\nframework, which unifies existing random walk based NRL models and supports to\nefficiently learn from large networks. The main obstacle comes from the diverse\nrandom walk models and the inefficient sampling method for the random walk\ngeneration. In this paper, we first introduce a new and efficient edge sampler\nbased on Metropolis-Hastings sampling technique, and theoretically show the\nconvergence property of the edge sampler to arbitrary discrete probability\ndistributions. Then we propose a random walk model abstraction, in which users\ncan easily define different transition probability by specifying dynamic edge\nweights and random walk states. The abstraction is efficiently supported by our\nedge sampler, since our sampler can draw samples from unnormalized probability\ndistribution in constant time complexity. Finally, with the new edge sampler\nand random walk model abstraction, we carefully implement a scalable NRL\nframework called UniNet. We conduct comprehensive experiments with five random\nwalk based NRL models over eleven real-world datasets, and the results clearly\ndemonstrate the efficiency of UniNet over billion-edge networks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 04:06:20 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 09:46:37 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Yao", "Xingyu", ""], ["Shao", "Yingxia", ""], ["Cui", "Bin", ""], ["Chen", "Lei", ""]]}, {"id": "2010.04912", "submitter": "Xiao-Shan Gao", "authors": "Lijia Yu and Xiao-Shan Gao", "title": "Improve the Robustness and Accuracy of Deep Neural Network with\n  $L_{2,\\infty}$ Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the robustness and accuracy of the deep neural network (DNN)\nwas enhanced by introducing the $L_{2,\\infty}$ normalization of the weight\nmatrices of the DNN with Relu as the activation function. It is proved that the\n$L_{2,\\infty}$ normalization leads to large dihedral angles between two\nadjacent faces of the polyhedron graph of the DNN function and hence smoother\nDNN functions, which reduces over-fitting. A measure is proposed for the\nrobustness of a classification DNN, which is the average radius of the maximal\nrobust spheres with the sample data as centers. A lower bound for the\nrobustness measure is given in terms of the $L_{2,\\infty}$ norm. Finally, an\nupper bound for the Rademacher complexity of DNN with $L_{2,\\infty}$\nnormalization is given. An algorithm is given to train a DNN with the\n$L_{2,\\infty}$ normalization and experimental results are used to show that the\n$L_{2,\\infty}$ normalization is effective to improve the robustness and\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 05:45:45 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yu", "Lijia", ""], ["Gao", "Xiao-Shan", ""]]}, {"id": "2010.04917", "submitter": "Biwei Huang", "authors": "Feng Xie, Ruichu Cai, Biwei Huang, Clark Glymour, Zhifeng Hao, Kun\n  Zhang", "title": "Generalized Independent Noise Condition for Estimating Latent Variable\n  Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery aims to recover causal structures or models underlying the\nobserved data. Despite its success in certain domains, most existing methods\nfocus on causal relations between observed variables, while in many scenarios\nthe observed ones may not be the underlying causal variables (e.g., image\npixels), but are generated by latent causal variables or confounders that are\ncausally related. To this end, in this paper, we consider Linear, Non-Gaussian\nLatent variable Models (LiNGLaMs), in which latent confounders are also\ncausally related, and propose a Generalized Independent Noise (GIN) condition\nto estimate such latent variable graphs. Specifically, for two observed random\nvectors $\\mathbf{Y}$ and $\\mathbf{Z}$, GIN holds if and only if\n$\\omega^{\\intercal}\\mathbf{Y}$ and $\\mathbf{Z}$ are statistically independent,\nwhere $\\omega$ is a parameter vector characterized from the cross-covariance\nbetween $\\mathbf{Y}$ and $\\mathbf{Z}$. From the graphical view, roughly\nspeaking, GIN implies that causally earlier latent common causes of variables\nin $\\mathbf{Y}$ d-separate $\\mathbf{Y}$ from $\\mathbf{Z}$. Interestingly, we\nfind that the independent noise condition, i.e., if there is no confounder,\ncauses are independent from the error of regressing the effect on the causes,\ncan be seen as a special case of GIN. Moreover, we show that GIN helps locate\nlatent variables and identify their causal structure, including causal\ndirections. We further develop a recursive learning algorithm to achieve these\ngoals. Experimental results on synthetic and real-world data demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 06:11:06 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:21:06 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Xie", "Feng", ""], ["Cai", "Ruichu", ""], ["Huang", "Biwei", ""], ["Glymour", "Clark", ""], ["Hao", "Zhifeng", ""], ["Zhang", "Kun", ""]]}, {"id": "2010.04925", "submitter": "Yaowei Zheng", "authors": "Yaowei Zheng, Richong Zhang, Yongyi Mao", "title": "Regularizing Neural Networks via Adversarial Model Perturbation", "comments": "16 pages, 13 figures, accepted to CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective regularization techniques are highly desired in deep learning for\nalleviating overfitting and improving generalization. This work proposes a new\nregularization scheme, based on the understanding that the flat local minima of\nthe empirical risk cause the model to generalize better. This scheme is\nreferred to as adversarial model perturbation (AMP), where instead of directly\nminimizing the empirical risk, an alternative \"AMP loss\" is minimized via SGD.\nSpecifically, the AMP loss is obtained from the empirical risk by applying the\n\"worst\" norm-bounded perturbation on each point in the parameter space.\nComparing with most existing regularization schemes, AMP has strong theoretical\njustifications, in that minimizing the AMP loss can be shown theoretically to\nfavour flat local minima of the empirical risk. Extensive experiments on\nvarious modern deep architectures establish AMP as a new state of the art among\nregularization schemes. Our code is available at\nhttps://github.com/hiyouga/AMP-Regularizer.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 07:01:00 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 14:02:46 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 13:53:27 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 04:26:26 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zheng", "Yaowei", ""], ["Zhang", "Richong", ""], ["Mao", "Yongyi", ""]]}, {"id": "2010.04937", "submitter": "Jikai Jin", "authors": "Jikai Jin", "title": "On The Convergence of First Order Methods for Quasar-Convex Optimization", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the success of deep learning has inspired many researchers\nto study the optimization of general smooth non-convex functions. However,\nrecent works have established pessimistic worst-case complexities for this\nclass functions, which is in stark contrast with their superior performance in\nreal-world applications (e.g. training deep neural networks). On the other\nhand, it is found that many popular non-convex optimization problems enjoy\ncertain structured properties which bear some similarities to convexity. In\nthis paper, we study the class of \\textit{quasar-convex functions} to close the\ngap between theory and practice. We study the convergence of first order\nmethods in a variety of different settings and under different optimality\ncriterions. We prove complexity upper bounds that are similar to standard\nresults established for convex functions and much better that state-of-the-art\nconvergence rates of non-convex functions. Overall, this paper suggests that\n\\textit{quasar-convexity} allows efficient optimization procedures, and we are\nlooking forward to seeing more problems that demonstrate similar properties in\npractice.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 08:16:32 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:25:51 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 11:58:31 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Jin", "Jikai", ""]]}, {"id": "2010.04948", "submitter": "Haiqin Yang", "authors": "Xixian Chen, Haiqin Yang, Shenglin Zhao, Michael R. Lyu, and Irwin\n  King", "title": "Making Online Sketching Hashing Even Faster", "comments": "12 pages, 5 figures", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-dependent hashing methods have demonstrated good performance in various\nmachine learning applications to learn a low-dimensional representation from\nthe original data. However, they still suffer from several obstacles: First,\nmost of existing hashing methods are trained in a batch mode, yielding\ninefficiency for training streaming data. Second, the computational cost and\nthe memory consumption increase extraordinarily in the big data setting, which\nperplexes the training procedure. Third, the lack of labeled data hinders the\nimprovement of the model performance. To address these difficulties, we utilize\nonline sketching hashing (OSH) and present a FasteR Online Sketching Hashing\n(FROSH) algorithm to sketch the data in a more compact form via an independent\ntransformation. We provide theoretical justification to guarantee that our\nproposed FROSH consumes less time and achieves a comparable sketching precision\nunder the same memory cost of OSH. We also extend FROSH to its distributed\nimplementation, namely DFROSH, to further reduce the training time cost of\nFROSH while deriving the theoretical bound of the sketching precision. Finally,\nwe conduct extensive experiments on both synthetic and real datasets to\ndemonstrate the attractive merits of FROSH and DFROSH.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 08:50:53 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Xixian", ""], ["Yang", "Haiqin", ""], ["Zhao", "Shenglin", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2010.04966", "submitter": "Haiqin Yang", "authors": "Xixian Chen, Haiqin Yang, Shenglin Zhao, Michael R. Lyu, and Irwin\n  King", "title": "Effective Data-aware Covariance Estimator from Compressed Data", "comments": "12 pages, 5 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating covariance matrix from massive high-dimensional and distributed\ndata is significant for various real-world applications. In this paper, we\npropose a data-aware weighted sampling based covariance matrix estimator,\nnamely DACE, which can provide an unbiased covariance matrix estimation and\nattain more accurate estimation under the same compression ratio. Moreover, we\nextend our proposed DACE to tackle multiclass classification problems with\ntheoretical justification and conduct extensive experiments on both synthetic\nand real-world datasets to demonstrate the superior performance of our DACE.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 10:10:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Xixian", ""], ["Yang", "Haiqin", ""], ["Zhao", "Shenglin", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2010.04992", "submitter": "Ehsan Mokhtarian", "authors": "Ehsan Mokhtarian, Sina Akbari, AmirEmad Ghassami, Negar Kiyavash", "title": "A Recursive Markov Boundary-Based Approach to Causal Structure Learning", "comments": "29 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based methods are one of the main approaches for causal structure\nlearning that are particularly valued as they are asymptotically guaranteed to\nfind a structure that is Markov equivalent to the causal graph of the system.\nOn the other hand, they may require an exponentially large number of\nconditional independence (CI) tests in the number of variables of the system.\nIn this paper, we propose a novel recursive constraint-based method for causal\nstructure learning that significantly reduces the required number of CI tests\ncompared to the existing literature. The idea of the proposed approach is to\nuse Markov boundary information to identify a specific variable that can be\nremoved from the set of variables without affecting the statistical\ndependencies among the other variables. Having identified such a variable, we\ndiscover its neighborhood, remove that variable from the set of variables, and\nrecursively learn the causal structure over the remaining variables. We further\nprovide a lower bound on the number of CI tests required by any\nconstraint-based method. Comparing this lower bound to our achievable bound\ndemonstrates the efficiency of the proposed approach. Our experimental results\nshow that the proposed algorithm outperforms state-of-the-art both on synthetic\nand real-world structures.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 13:26:22 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 23:05:04 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 02:37:14 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Mokhtarian", "Ehsan", ""], ["Akbari", "Sina", ""], ["Ghassami", "AmirEmad", ""], ["Kiyavash", "Negar", ""]]}, {"id": "2010.05045", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, Quanshi Zhang", "title": "Interpreting Multivariate Shapley Interactions in DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to explain deep neural networks (DNNs) from the perspective\nof multivariate interactions. In this paper, we define and quantify the\nsignificance of interactions among multiple input variables of the DNN. Input\nvariables with strong interactions usually form a coalition and reflect\nprototype features, which are memorized and used by the DNN for inference. We\ndefine the significance of interactions based on the Shapley value, which is\ndesigned to assign the attribution value of each input variable to the\ninference. We have conducted experiments with various DNNs. Experimental\nresults have demonstrated the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 17:02:51 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 05:51:48 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 15:14:41 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 09:12:47 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zhang", "Hao", ""], ["Xie", "Yichen", ""], ["Zheng", "Longjie", ""], ["Zhang", "Die", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2010.05063", "submitter": "Yaoyao Liu", "authors": "Yaoyao Liu, Bernt Schiele, Qianru Sun", "title": "Adaptive Aggregation Networks for Class-Incremental Learning", "comments": "Accepted to CVPR 2021. Code:\n  https://github.com/yaoyao-liu/class-incremental-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Class-Incremental Learning (CIL) aims to learn a classification model with\nthe number of classes increasing phase-by-phase. An inherent problem in CIL is\nthe stability-plasticity dilemma between the learning of old and new classes,\ni.e., high-plasticity models easily forget old classes, but high-stability\nmodels are weak to learn new classes. We alleviate this issue by proposing a\nnovel network architecture called Adaptive Aggregation Networks (AANets), in\nwhich we explicitly build two types of residual blocks at each residual level\n(taking ResNet as the baseline architecture): a stable block and a plastic\nblock. We aggregate the output feature maps from these two blocks and then feed\nthe results to the next-level blocks. We adapt the aggregation weights in order\nto balance these two types of blocks, i.e., to balance stability and\nplasticity, dynamically. We conduct extensive experiments on three CIL\nbenchmarks: CIFAR-100, ImageNet-Subset, and ImageNet, and show that many\nexisting CIL methods can be straightforwardly incorporated into the\narchitecture of AANets to boost their performances.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 18:24:24 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 12:19:15 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 22:09:07 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Liu", "Yaoyao", ""], ["Schiele", "Bernt", ""], ["Sun", "Qianru", ""]]}, {"id": "2010.05074", "submitter": "Marios Mattheakis M", "authors": "Alessandro Paticchio, Tommaso Scarlatti, Marios Mattheakis, Pavlos\n  Protopapas, Marco Brambilla", "title": "Semi-supervised Neural Networks solve an inverse problem for modeling\n  Covid-19 spread", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the dynamics of COVID-19 is of paramount importance to understanding\nthe efficiency of restrictive measures and develop strategies to defend against\nupcoming contagion waves. In this work, we study the spread of COVID-19 using a\nsemi-supervised neural network and assuming a passive part of the population\nremains isolated from the virus dynamics. We start with an unsupervised neural\nnetwork that learns solutions of differential equations for different modeling\nparameters and initial conditions. A supervised method then solves the inverse\nproblem by estimating the optimal conditions that generate functions to fit the\ndata for those infected by, recovered from, and deceased due to COVID-19. This\nsemi-supervised approach incorporates real data to determine the evolution of\nthe spread, the passive population, and the basic reproduction number for\ndifferent countries.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 19:33:53 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Paticchio", "Alessandro", ""], ["Scarlatti", "Tommaso", ""], ["Mattheakis", "Marios", ""], ["Protopapas", "Pavlos", ""], ["Brambilla", "Marco", ""]]}, {"id": "2010.05077", "submitter": "Nisan Chiprut", "authors": "Nisan Chiprut, Amir Globerson, Ami Wiesel", "title": "Maximin Optimization for Binary Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider regression problems with binary weights. Such optimization\nproblems are ubiquitous in quantized learning models and digital communication\nsystems. A natural approach is to optimize the corresponding Lagrangian using\nvariants of the gradient ascent-descent method. Such maximin techniques are\nstill poorly understood even in the concave-convex case. The non-convex binary\nconstraints may lead to spurious local minima. Interestingly, we prove that\nthis approach is optimal in linear regression with low noise conditions as well\nas robust regression with a small number of outliers. Practically, the method\nalso performs well in regression with cross entropy loss, as well as non-convex\nmulti-layer neural networks. Taken together our approach highlights the\npotential of saddle-point optimization for learning constrained models.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 19:47:40 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 13:09:01 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 00:35:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chiprut", "Nisan", ""], ["Globerson", "Amir", ""], ["Wiesel", "Ami", ""]]}, {"id": "2010.05080", "submitter": "Nika Haghtalab", "authors": "Maria-Florina Balcan, Nika Haghtalab", "title": "Noise in Classification", "comments": "Chapter 16 of the book Beyond the Worst-Case Analysis of Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter considers the computational and statistical aspects of learning\nlinear thresholds in presence of noise. When there is no noise, several\nalgorithms exist that efficiently learn near-optimal linear thresholds using a\nsmall amount of data. However, even a small amount of adversarial noise makes\nthis problem notoriously hard in the worst-case. We discuss approaches for\ndealing with these negative results by exploiting natural assumptions on the\ndata-generating process.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 19:52:26 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 15:42:05 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Haghtalab", "Nika", ""]]}, {"id": "2010.05109", "submitter": "Xuping Tian", "authors": "Hailiang Liu and Xuping Tian", "title": "AEGD: Adaptive Gradient Decent with Energy", "comments": "23 pages, 7 figures, submitted to Journal of Machine Learning\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose AEGD, a new algorithm for first-order\ngradient-based optimization of stochastic objective functions, based on\nadaptive updates of quadratic energy. As long as an objective function is\nbounded from below, AEGD can be applied, and it is shown to be unconditionally\nenergy stable, irrespective of the step size. In addition, AEGD enjoys tight\nconvergence rates, yet allows a large step size. The method is straightforward\nto implement and requires little tuning of hyper-parameters. Experimental\nresults demonstrate that AEGD works well for various optimization problems: it\nis robust with respect to initial data, capable of making rapid initial\nprogress, shows comparable and most times better generalization performance\nthan SGD with momentum for deep neural networks. The implementation of the\nalgorithm can be found at https://github.com/txping/AEGD.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 22:17:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Liu", "Hailiang", ""], ["Tian", "Xuping", ""]]}, {"id": "2010.05113", "submitter": "Phuc Le Khac", "authors": "Phuc H. Le-Khac, Graham Healy, Alan F. Smeaton", "title": "Contrastive Representation Learning: A Framework and Review", "comments": "28 pages, 9 figures, update with the accepted version in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3031549", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contrastive Learning has recently received interest due to its success in\nself-supervised representation learning in the computer vision domain. However,\nthe origins of Contrastive Learning date as far back as the 1990s and its\ndevelopment has spanned across many fields and domains including Metric\nLearning and natural language processing. In this paper we provide a\ncomprehensive literature review and we propose a general Contrastive\nRepresentation Learning framework that simplifies and unifies many different\ncontrastive learning methods. We also provide a taxonomy for each of the\ncomponents of contrastive learning in order to summarise it and distinguish it\nfrom other forms of machine learning. We then discuss the inductive biases\nwhich are present in any contrastive learning system and we analyse our\nframework under different views from various sub-fields of Machine Learning.\nExamples of how contrastive learning has been applied in computer vision,\nnatural language processing, audio processing, and others, as well as in\nReinforcement Learning are also presented. Finally, we discuss the challenges\nand some of the most promising future research directions ahead.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 22:46:25 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 21:52:21 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Le-Khac", "Phuc H.", ""], ["Healy", "Graham", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2010.05119", "submitter": "Ad\\'in Ram\\'irez Rivera", "authors": "Ad\\'in Ram\\'irez Rivera, Adil Khan, Imad E. I. Bekkouch, Taimoor S.\n  Sheikh", "title": "Anomaly Detection based on Zero-Shot Outlier Synthesis and Hierarchical\n  Feature Distillation", "comments": "To appear in IEEE Trans. on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3027667", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection suffers from unbalanced data since anomalies are quite\nrare. Synthetically generated anomalies are a solution to such ill or not fully\ndefined data. However, synthesis requires an expressive representation to\nguarantee the quality of the generated data. In this paper, we propose a\ntwo-level hierarchical latent space representation that distills inliers'\nfeature-descriptors (through autoencoders) into more robust representations\nbased on a variational family of distributions (through a variational\nautoencoder) for zero-shot anomaly generation. From the learned latent\ndistributions, we select those that lie on the outskirts of the training data\nas synthetic-outlier generators. And, we synthesize from them, i.e., generate\nnegative samples without seen them before, to train binary classifiers. We\nfound that the use of the proposed hierarchical structure for feature\ndistillation and fusion creates robust and general representations that allow\nus to synthesize pseudo outlier samples. And in turn, train robust binary\nclassifiers for true outlier detection (without the need for actual outliers\nduring training). We demonstrate the performance of our proposal on several\nbenchmarks for anomaly detection.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 23:34:02 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Rivera", "Ad\u00edn Ram\u00edrez", ""], ["Khan", "Adil", ""], ["Bekkouch", "Imad E. I.", ""], ["Sheikh", "Taimoor S.", ""]]}, {"id": "2010.05125", "submitter": "Keji Han", "authors": "Keji Han and Yun Li", "title": "Is It Time to Redefine the Classification Task for Deep Neural Networks?", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) is demonstrated to be vulnerable to the\nadversarial example, which is generated by adding small adversarial\nperturbation into the original legitimate example to cause the wrong outputs of\nDNNs. Nowadays, most works focus on the robustness of the deep model, while few\nworks pay attention to the robustness of the learning task itself defined on\nDNNs. So we redefine this issue as the robustness of deep neural learning\nsystem. A deep neural learning system consists of the deep model and the\nlearning task defined on the deep model. Moreover, the deep model is usually a\ndeep neural network, involving the model architecture, data, training loss and\ntraining algorithm. We speculate that the vulnerability of the deep learning\nsystem also roots in the learning task itself. This paper defines the\ninterval-label classification task for the deep classification system, whose\nlabels are predefined non-overlapping intervals, instead of a fixed value (hard\nlabel) or probability vector (soft label). The experimental results demonstrate\nthat the interval-label classification task is more robust than the traditional\nclassification task while retaining accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 01:06:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Han", "Keji", ""], ["Li", "Yun", ""]]}, {"id": "2010.05154", "submitter": "Rohan Ramanath", "authors": "Rohan Ramanath, Konstantin Salomatin, Jeffrey D. Gee, Kirill Talanine,\n  Onkar Dalal, Gungor Polatkan, Sara Smoot, Deepak Kumar", "title": "Lambda Learner: Fast Incremental Learning on Data Streams", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining, 2021", "doi": "10.1145/3447548.3467172", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most well-established applications of machine learning is in\ndeciding what content to show website visitors. When observation data comes\nfrom high-velocity, user-generated data streams, machine learning methods\nperform a balancing act between model complexity, training time, and\ncomputational costs. Furthermore, when model freshness is critical, the\ntraining of models becomes time-constrained. Parallelized batch offline\ntraining, although horizontally scalable, is often not time-considerate or\ncost-effective. In this paper, we propose Lambda Learner, a new framework for\ntraining models by incremental updates in response to mini-batches from data\nstreams. We show that the resulting model of our framework closely estimates a\nperiodically updated model trained on offline data and outperforms it when\nmodel updates are time-sensitive. We provide theoretical proof that the\nincremental learning updates improve the loss-function over a stale batch\nmodel. We present a large-scale deployment on the sponsored content platform\nfor a large social network, serving hundreds of millions of users across\ndifferent channels (e.g., desktop, mobile). We address challenges and\ncomplexities from both algorithms and infrastructure perspectives, and\nillustrate the system details for computation, storage, and streaming\nproduction of training data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 04:00:34 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 14:27:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ramanath", "Rohan", ""], ["Salomatin", "Konstantin", ""], ["Gee", "Jeffrey D.", ""], ["Talanine", "Kirill", ""], ["Dalal", "Onkar", ""], ["Polatkan", "Gungor", ""], ["Smoot", "Sara", ""], ["Kumar", "Deepak", ""]]}, {"id": "2010.05155", "submitter": "Anima Majumder", "authors": "Anima Majumder, Samrat Dutta, Swagat Kumar, Laxmidhar Behera", "title": "A Method for Handling Multi-class Imbalanced Data by Geometry based\n  Information Sampling and Class Prioritized Synthetic Data Generation (GICaPS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks into the problem of handling imbalanced data in a\nmulti-label classification problem. The problem is solved by proposing two\nnovel methods that primarily exploit the geometric relationship between the\nfeature vectors. The first one is an undersampling algorithm that uses angle\nbetween feature vectors to select more informative samples while rejecting the\nless informative ones. A suitable criterion is proposed to define the\ninformativeness of a given sample. The second one is an oversampling algorithm\nthat uses a generative algorithm to create new synthetic data that respects all\nclass boundaries. This is achieved by finding \\emph{no man's land} based on\nEuclidean distance between the feature vectors. The efficacy of the proposed\nmethods is analyzed by solving a generic multi-class recognition problem based\non mixture of Gaussians. The superiority of the proposed algorithms is\nestablished through comparison with other state-of-the-art methods, including\nSMOTE and ADASYN, over ten different publicly available datasets exhibiting\nhigh-to-extreme data imbalance. These two methods are combined into a single\ndata processing framework and is labeled as ``GICaPS'' to highlight the role of\ngeometry-based information (GI) sampling and Class-Prioritized Synthesis (CaPS)\nin dealing with multi-class data imbalance problem, thereby making a novel\ncontribution in this field.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 04:04:26 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Majumder", "Anima", ""], ["Dutta", "Samrat", ""], ["Kumar", "Swagat", ""], ["Behera", "Laxmidhar", ""]]}, {"id": "2010.05166", "submitter": "Ashkan Rezaei", "authors": "Ashkan Rezaei, Anqi Liu, Omid Memarrast, Brian Ziebart", "title": "Robust Fairness under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making predictions that are fair with regard to protected group membership\n(race, gender, age, etc.) has become an important requirement for\nclassification algorithms. Existing techniques derive a fair model from sampled\nlabeled data relying on the assumption that training and testing data are\nidentically and independently drawn (iid) from the same distribution. In\npractice, distribution shift can and does occur between training and testing\ndatasets as the characteristics of individuals interacting with the machine\nlearning system change. We investigate fairness under covariate shift, a\nrelaxation of the iid assumption in which the inputs or covariates change while\nthe conditional label distribution remains the same. We seek fair decisions\nunder these assumptions on target data with unknown labels. We propose an\napproach that obtains the predictor that is robust to the worst-case in terms\nof target performance while satisfying target fairness requirements and\nmatching statistical properties of the source data. We demonstrate the benefits\nof our approach on benchmark prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 04:42:01 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 20:27:13 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 06:46:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Rezaei", "Ashkan", ""], ["Liu", "Anqi", ""], ["Memarrast", "Omid", ""], ["Ziebart", "Brian", ""]]}, {"id": "2010.05170", "submitter": "Licong Lin", "authors": "Licong Lin, Edgar Dobriban", "title": "What causes the test error? Going beyond bias-variance via ANOVA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning methods are often overparametrized, allowing\nadaptation to the data at a fine level. This can seem puzzling; in the worst\ncase, such models do not need to generalize. This puzzle inspired a great\namount of work, arguing when overparametrization reduces test error, in a\nphenomenon called \"double descent\". Recent work aimed to understand in greater\ndepth why overparametrization is helpful for generalization. This leads to\ndiscovering the unimodality of variance as a function of the level of\nparametrization, and to decomposing the variance into that arising from label\nnoise, initialization, and randomness in the training data to understand the\nsources of the error.\n  In this work we develop a deeper understanding of this area. Specifically, we\npropose using the analysis of variance (ANOVA) to decompose the variance in the\ntest error in a symmetric way, for studying the generalization performance of\ncertain two-layer linear and non-linear networks. The advantage of the analysis\nof variance is that it reveals the effects of initialization, label noise, and\ntraining data more clearly than prior approaches. Moreover, we also study the\nmonotonicity and unimodality of the variance components. While prior work\nstudied the unimodality of the overall variance, we study the properties of\neach term in variance decomposition.\n  One key insight is that in typical settings, the interaction between training\nsamples and initialization can dominate the variance; surprisingly being larger\nthan their marginal effect. Also, we characterize \"phase transitions\" where the\nvariance changes from unimodal to monotone. On a technical level, we leverage\nadvanced deterministic equivalent techniques for Haar random matrices, that --\nto our knowledge -- have not yet been used in the area. We also verify our\nresults in numerical simulations and on empirical data examples.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 05:21:13 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 10:55:36 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 06:46:33 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Lin", "Licong", ""], ["Dobriban", "Edgar", ""]]}, {"id": "2010.05241", "submitter": "Alexander Gorban", "authors": "Bogdan Grechuk, Alexander N. Gorban, Ivan Y. Tyukin", "title": "General stochastic separation theorems with optimal bounds", "comments": "Numerical examples and illustrations are added, minor corrections\n  extended discussion and the bibliography", "journal-ref": "Neural Networks, Volume 138, 2021, Pages 33-56", "doi": "10.1016/j.neunet.2021.01.034", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phenomenon of stochastic separability was revealed and used in machine\nlearning to correct errors of Artificial Intelligence (AI) systems and analyze\nAI instabilities. In high-dimensional datasets under broad assumptions each\npoint can be separated from the rest of the set by simple and robust Fisher's\ndiscriminant (is Fisher separable). Errors or clusters of errors can be\nseparated from the rest of the data. The ability to correct an AI system also\nopens up the possibility of an attack on it, and the high dimensionality\ninduces vulnerabilities caused by the same stochastic separability that holds\nthe keys to understanding the fundamentals of robustness and adaptivity in\nhigh-dimensional data-driven AI. To manage errors and analyze vulnerabilities,\nthe stochastic separation theorems should evaluate the probability that the\ndataset will be Fisher separable in given dimensionality and for a given class\nof distributions. Explicit and optimal estimates of these separation\nprobabilities are required, and this problem is solved in present work. The\ngeneral stochastic separation theorems with optimal probability estimates are\nobtained for important classes of distributions: log-concave distribution,\ntheir convex combinations and product distributions. The standard i.i.d.\nassumption was significantly relaxed. These theorems and estimates can be used\nboth for correction of high-dimensional data driven AI systems and for analysis\nof their vulnerabilities. The third area of application is the emergence of\nmemories in ensembles of neurons, the phenomena of grandmother's cells and\nsparse coding in the brain, and explanation of unexpected effectiveness of\nsmall neural ensembles in high-dimensional brain.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 13:12:41 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 19:10:17 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Grechuk", "Bogdan", ""], ["Gorban", "Alexander N.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2010.05244", "submitter": "Jiyang Xie", "authors": "Jiyang Xie and Zhanyu Ma and Guoqiang Zhang and Jing-Hao Xue and\n  Zheng-Hua Tan and Jun Guo", "title": "Advanced Dropout: A Model-free Methodology for Bayesian Dropout\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to lack of data, overfitting ubiquitously exists in real-world\napplications of deep neural networks (DNNs). In this paper, we propose advanced\ndropout, a model-free methodology, to mitigate overfitting and improve the\nperformance of DNNs. The advanced dropout technique applies a model-free and\neasily implemented distribution with a parametric prior, and adaptively adjusts\ndropout rate. Specifically, the distribution parameters are optimized by\nstochastic gradient variational Bayes (SGVB) inference in order to carry out an\nend-to-end training of DNNs. We evaluate the effectiveness of the advanced\ndropout against nine dropout techniques on five widely used datasets in\ncomputer vision. The advanced dropout outperforms all the referred techniques\nby 0.83% on average for all the datasets. An ablation study is conducted to\nanalyze the effectiveness of each component. Meanwhile, convergence of dropout\nrate and ability to prevent overfitting are discussed in terms of\nclassification performance. Moreover, we extend the application of the advanced\ndropout to uncertainty inference and network pruning, and we find that the\nadvanced dropout is superior to the corresponding referred methods. The\nadvanced dropout improves classification accuracies by 4% in uncertainty\ninference and by 0.2% and 0.5% when pruning more than 90% of nodes and 99.8% of\nparameters, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 13:19:58 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xie", "Jiyang", ""], ["Ma", "Zhanyu", ""], ["Zhang", "Guoqiang", ""], ["Xue", "Jing-Hao", ""], ["Tan", "Zheng-Hua", ""], ["Guo", "Jun", ""]]}, {"id": "2010.05250", "submitter": "Jian Liang", "authors": "Jian Liang, Yuren Cao, Shuang Li, Bing Bai, Hao Li, Fei Wang, Kun Bai", "title": "Domain Agnostic Learning for Unbiased Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication is the task of confirming the matching relationship between a\ndata instance and a given identity. Typical examples of authentication problems\ninclude face recognition and person re-identification. Data-driven\nauthentication could be affected by undesired biases, i.e., the models are\noften trained in one domain (e.g., for people wearing spring outfits) while\napplied in other domains (e.g., they change the clothes to summer outfits).\nPrevious works have made efforts to eliminate domain-difference. They typically\nassume domain annotations are provided, and all the domains share classes.\nHowever, for authentication, there could be a large number of domains shared by\ndifferent identities/classes, and it is impossible to annotate these domains\nexhaustively. It could make domain-difference challenging to model and\neliminate. In this paper, we propose a domain-agnostic method that eliminates\ndomain-difference without domain labels. We alternately perform latent domain\ndiscovery and domain-difference elimination until our model no longer detects\ndomain-difference. In our approach, the latent domains are discovered by\nlearning the heterogeneous predictive relationships between inputs and outputs.\nThen domain-difference is eliminated in both class-dependent and\nclass-independent spaces to improve robustness of elimination. We further\nextend our method to a meta-learning framework to pursue more thorough\ndomain-difference elimination. Comprehensive empirical evaluation results are\nprovided to demonstrate the effectiveness and superiority of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 14:05:16 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 09:13:33 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liang", "Jian", ""], ["Cao", "Yuren", ""], ["Li", "Shuang", ""], ["Bai", "Bing", ""], ["Li", "Hao", ""], ["Wang", "Fei", ""], ["Bai", "Kun", ""]]}, {"id": "2010.05263", "submitter": "Xiao Wang", "authors": "Xiao Wang, Qi Lei and Ioannis Panageas", "title": "Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet\n  Log-Sobolev", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is a fundamental and arguably very important task with numerous\napplications in Machine Learning. One approach to sample from a high\ndimensional distribution $e^{-f}$ for some function $f$ is the Langevin\nAlgorithm (LA). Recently, there has been a lot of progress in showing fast\nconvergence of LA even in cases where $f$ is non-convex, notably [53], [39] in\nwhich the former paper focuses on functions $f$ defined in $\\mathbb{R}^n$ and\nthe latter paper focuses on functions with symmetries (like matrix completion\ntype objectives) with manifold structure. Our work generalizes the results of\n[53] where $f$ is defined on a manifold $M$ rather than $\\mathbb{R}^n$. From\ntechnical point of view, we show that KL decreases in a geometric rate whenever\nthe distribution $e^{-f}$ satisfies a log-Sobolev inequality on $M$.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 15:02:12 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 18:06:06 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Xiao", ""], ["Lei", "Qi", ""], ["Panageas", "Ioannis", ""]]}, {"id": "2010.05270", "submitter": "Vivek Mahato", "authors": "Vivek Mahato, P\\'adraig Cunningham", "title": "A Case-Study on the Impact of Dynamic Time Warping in Time Series\n  Regression", "comments": "3nd ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal\n  Data (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is well understood that Dynamic Time Warping (DTW) is effective in\nrevealing similarities between time series that do not align perfectly. In this\npaper, we illustrate this on spectroscopy time-series data. We show that DTW is\neffective in improving accuracy on a regression task when only a single\nwavelength is considered. When combined with k-Nearest Neighbour, DTW has the\nadded advantage that it can reveal similarities and differences between samples\nat the level of the time-series. However, in the problem, we consider here data\nis available across a spectrum of wavelengths. If aggregate statistics (means,\nvariances) are used across many wavelengths the benefits of DTW are no longer\napparent. We present this as another example of a situation where big data\ntrumps sophisticated models in Machine Learning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 15:21:21 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Mahato", "Vivek", ""], ["Cunningham", "P\u00e1draig", ""]]}, {"id": "2010.05273", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, Afshin\n  Rostamizadeh", "title": "Federated Learning via Posterior Averaging: A New Perspective and\n  Practical Algorithms", "comments": "ICLR 2021. Code: https://github.com/alshedivat/fedpa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is typically approached as an optimization problem, where\nthe goal is to minimize a global loss function by distributing computation\nacross client devices that possess local data and specify different parts of\nthe global objective. We present an alternative perspective and formulate\nfederated learning as a posterior inference problem, where the goal is to infer\na global posterior distribution by having client devices each infer the\nposterior of their local data. While exact inference is often intractable, this\nperspective provides a principled way to search for global optima in federated\nsettings. Further, starting with the analysis of federated quadratic\nobjectives, we develop a computation- and communication-efficient approximate\nposterior inference algorithm -- federated posterior averaging (FedPA). Our\nalgorithm uses MCMC for approximate inference of local posteriors on the\nclients and efficiently communicates their statistics to the server, where the\nlatter uses them to refine a global estimate of the posterior mode. Finally, we\nshow that FedPA generalizes federated averaging (FedAvg), can similarly benefit\nfrom adaptive optimizers, and yields state-of-the-art results on four realistic\nand challenging benchmarks, converging faster, to better optima.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 15:55:45 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 04:09:49 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 05:44:11 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 01:50:00 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Gillenwater", "Jennifer", ""], ["Xing", "Eric", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "2010.05295", "submitter": "Leonardo Zepeda-N\\'u\\~nez", "authors": "Yifan Peng, Lin Lin, Lexing Ying and Leonardo Zepeda-N\\'u\\~nez", "title": "Efficient Long-Range Convolutions for Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient treatment of long-range interactions for point clouds is a\nchallenging problem in many scientific machine learning applications. To\nextract global information, one usually needs a large window size, a large\nnumber of layers, and/or a large number of channels. This can often\nsignificantly increase the computational cost. In this work, we present a novel\nneural network layer that directly incorporates long-range information for a\npoint cloud. This layer, dubbed the long-range convolutional (LRC)-layer,\nleverages the convolutional theorem coupled with the non-uniform Fourier\ntransform. In a nutshell, the LRC-layer mollifies the point cloud to an\nadequately sized regular grid, computes its Fourier transform, multiplies the\nresult by a set of trainable Fourier multipliers, computes the inverse Fourier\ntransform, and finally interpolates the result back to the point cloud. The\nresulting global all-to-all convolution operation can be performed in\nnearly-linear time asymptotically with respect to the number of input points.\nThe LRC-layer is a particularly powerful tool when combined with local\nconvolution as together they offer efficient and seamless treatment of both\nshort and long range interactions. We showcase this framework by introducing a\nneural network architecture that combines LRC-layers with short-range\nconvolutional layers to accurately learn the energy and force associated with a\n$N$-body potential. We also exploit the induced two-level decomposition and\npropose an efficient strategy to train the combined architecture with a reduced\nnumber of samples.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 17:42:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Peng", "Yifan", ""], ["Lin", "Lin", ""], ["Ying", "Lexing", ""], ["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""]]}, {"id": "2010.05306", "submitter": "Elina Robeva", "authors": "Yiheng Liu, Elina Robeva, and Huanqing Wang", "title": "Learning Linear Non-Gaussian Graphical Models with Multidirected Edges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new method to learn the underlying acyclic mixed\ngraph of a linear non-Gaussian structural equation model given observational\ndata. We build on an algorithm proposed by Wang and Drton, and we show that one\ncan augment the hidden variable structure of the recovered model by learning\n{\\em multidirected edges} rather than only directed and bidirected ones.\nMultidirected edges appear when more than two of the observed variables have a\nhidden common cause. We detect the presence of such hidden causes by looking at\nhigher order cumulants and exploiting the multi-trek rule. Our method recovers\nthe correct structure when the underlying graph is a bow-free acyclic mixed\ngraph with potential multi-directed edges.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 18:10:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Liu", "Yiheng", ""], ["Robeva", "Elina", ""], ["Wang", "Huanqing", ""]]}, {"id": "2010.05311", "submitter": "Zhong Zheng", "authors": "Yucheng Yang, Zhong Zheng, Weinan E", "title": "Interpretable Neural Networks for Panel Data Analysis in Economics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.AI cs.LG econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability and transparency are preventing economists from\nusing advanced tools like neural networks in their empirical research. In this\npaper, we propose a class of interpretable neural network models that can\nachieve both high prediction accuracy and interpretability. The model can be\nwritten as a simple function of a regularized number of interpretable features,\nwhich are outcomes of interpretable functions encoded in the neural network.\nResearchers can design different forms of interpretable functions based on the\nnature of their tasks. In particular, we encode a class of interpretable\nfunctions named persistent change filters in the neural network to study time\nseries cross-sectional data. We apply the model to predicting individual's\nmonthly employment status using high-dimensional administrative data. We\nachieve an accuracy of 94.5% in the test set, which is comparable to the best\nperformed conventional machine learning methods. Furthermore, the\ninterpretability of the model allows us to understand the mechanism that\nunderlies the prediction: an individual's employment status is closely related\nto whether she pays different types of insurances. Our work is a useful step\ntowards overcoming the black-box problem of neural networks, and provide a new\ntool for economists to study administrative and proprietary big data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 18:40:22 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 10:49:54 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 14:57:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yang", "Yucheng", ""], ["Zheng", "Zhong", ""], ["E", "Weinan", ""]]}, {"id": "2010.05316", "submitter": "Zeno Sch\\\"atzle", "authors": "Zeno Sch\\\"atzle, Jan Hermann, Frank No\\'e", "title": "Convergence to the fixed-node limit in deep variational Monte Carlo", "comments": "This article may be downloaded for personal use only. Any other use\n  requires prior permission of the author and AIP Publishing. This article\n  appeared in J. Chem. Phys., vol. 154, no. 12, p. 124108, Mar. 2021 and may be\n  found at https://doi.org/10.1063/5.0032836", "journal-ref": null, "doi": "10.1063/5.0032836", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational quantum Monte Carlo (QMC) is an ab-initio method for solving the\nelectronic Schr\\\"odinger equation that is exact in principle, but limited by\nthe flexibility of the available ansatzes in practice. The recently introduced\ndeep QMC approach, specifically two deep-neural-network ansatzes PauliNet and\nFermiNet, allows variational QMC to reach the accuracy of diffusion QMC, but\nlittle is understood about the convergence behavior of such ansatzes. Here, we\nanalyze how deep variational QMC approaches the fixed-node limit with\nincreasing network size. First, we demonstrate that a deep neural network can\novercome the limitations of a small basis set and reach the mean-field\ncomplete-basis-set limit. Moving to electron correlation, we then perform an\nextensive hyperparameter scan of a deep Jastrow factor for LiH and H$_4$ and\nfind that variational energies at the fixed-node limit can be obtained with a\nsufficiently large network. Finally, we benchmark mean-field and many-body\nansatzes on H$_2$O, increasing the fraction of recovered fixed-node correlation\nenergy of single-determinant Slater--Jastrow-type ansatzes by half an order of\nmagnitude compared to previous variational QMC results and demonstrate that a\nsingle-determinant Slater--Jastrow--backflow version of the ansatz overcomes\nthe fixed-node limitations. This analysis helps understanding the superb\naccuracy of deep variational ansatzes in comparison to the traditional trial\nwavefunctions at the respective level of theory, and will guide future\nimprovements of the neural network architectures in deep QMC.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 18:50:14 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 10:46:25 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Sch\u00e4tzle", "Zeno", ""], ["Hermann", "Jan", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2010.05321", "submitter": "Viet Anh Nguyen", "authors": "Viet Anh Nguyen and Xuhui Zhang and Jose Blanchet and Angelos\n  Georghiou", "title": "Distributionally Robust Parametric Maximum Likelihood Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the parameter estimation problem of a probabilistic generative\nmodel prescribed using a natural exponential family of distributions. For this\nproblem, the typical maximum likelihood estimator usually overfits under\nlimited training sample size, is sensitive to noise and may perform poorly on\ndownstream predictive tasks. To mitigate these issues, we propose a\ndistributionally robust maximum likelihood estimator that minimizes the\nworst-case expected log-loss uniformly over a parametric Kullback-Leibler ball\naround a parametric nominal distribution. Leveraging the analytical expression\nof the Kullback-Leibler divergence between two distributions in the same\nnatural exponential family, we show that the min-max estimation problem is\ntractable in a broad setting, including the robust training of generalized\nlinear models. Our novel robust estimator also enjoys statistical consistency\nand delivers promising empirical results in both regression and classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 19:05:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Zhang", "Xuhui", ""], ["Blanchet", "Jose", ""], ["Georghiou", "Angelos", ""]]}, {"id": "2010.05328", "submitter": "Carsten Botts", "authors": "Carsten H. Botts", "title": "Three-Dimensional Swarming Using Cyclic Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we simulate an ensemble of cooperating, mobile sensing agents\nthat implement the cyclic stochastic optimization (CSO) algorithm in an attempt\nto survey and track multiple targets. In the CSO algorithm proposed, each agent\nuses its sensed measurements, its shared information, and its predictions of\nothers' future motion to decide on its next action. This decision is selected\nto minimize a loss function that decreases as the uncertainty in the targets'\nstate estimates decreases. Only noisy measurements of this loss function are\navailable to each agent, and in this study, each agent attempts to minimize\nthis function by calculating its stochastic gradient. This paper examines, via\nsimulation-based experiments, the implications and applicability of CSO\nconvergence in three dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 19:43:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Botts", "Carsten H.", ""]]}, {"id": "2010.05373", "submitter": "Viet Anh Nguyen", "authors": "Viet Anh Nguyen and Fan Zhang and Jose Blanchet and Erick Delage and\n  Yinyu Ye", "title": "Distributionally Robust Local Non-parametric Conditional Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional estimation given specific covariate values (i.e., local\nconditional estimation or functional estimation) is ubiquitously useful with\napplications in engineering, social and natural sciences. Existing data-driven\nnon-parametric estimators mostly focus on structured homogeneous data (e.g.,\nweakly independent and stationary data), thus they are sensitive to adversarial\nnoise and may perform poorly under a low sample size. To alleviate these\nissues, we propose a new distributionally robust estimator that generates\nnon-parametric local estimates by minimizing the worst-case conditional\nexpected loss over all adversarial distributions in a Wasserstein ambiguity\nset. We show that despite being generally intractable, the local estimator can\nbe efficiently found via convex optimization under broadly applicable settings,\nand it is robust to the corruption and heterogeneity of the data. Experiments\nwith synthetic and MNIST datasets show the competitive performance of this new\nclass of estimators.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 00:11:17 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Zhang", "Fan", ""], ["Blanchet", "Jose", ""], ["Delage", "Erick", ""], ["Ye", "Yinyu", ""]]}, {"id": "2010.05375", "submitter": "Daniel Chicharro", "authors": "Daniel Chicharro, Michel Besserve, Stefano Panzeri", "title": "Causal learning with sufficient statistics: an information bottleneck\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The inference of causal relationships using observational data from partially\nobserved multivariate systems with hidden variables is a fundamental question\nin many scientific domains. Methods extracting causal information from\nconditional independencies between variables of a system are common tools for\nthis purpose, but are limited in the lack of independencies. To surmount this\nlimitation, we capitalize on the fact that the laws governing the generative\nmechanisms of a system often result in substructures embodied in the generative\nfunctional equation of a variable, which act as sufficient statistics for the\ninfluence that other variables have on it. These functional sufficient\nstatistics constitute intermediate hidden variables providing new conditional\nindependencies to be tested. We propose to use the Information Bottleneck\nmethod, a technique commonly applied for dimensionality reduction, to find\nunderlying sufficient sets of statistics. Using these statistics we formulate\nnew additional rules of causal orientation that provide causal information not\nobtainable from standard structure learning algorithms, which exploit only\nconditional independencies between observable variables. We validate the use of\nsufficient statistics for structure learning both with simulated systems built\nto contain specific sufficient statistics and with benchmark data from\nregulatory rules previously and independently proposed to model biological\nsignal transduction networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 00:20:01 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chicharro", "Daniel", ""], ["Besserve", "Michel", ""], ["Panzeri", "Stefano", ""]]}, {"id": "2010.05387", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata", "title": "Meta-Active Learning for Node Response Prediction in Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is an important approach to improve machine learning\nperformance with a limited number of observations for target tasks. However,\nwhen observations are unbalancedly obtained, it is difficult to improve the\nperformance even with meta-learning methods. In this paper, we propose an\nactive learning method for meta-learning on node response prediction tasks in\nattributed graphs, where nodes to observe are selected to improve performance\nwith as few observed nodes as possible. With the proposed method, we use models\nbased on graph convolutional neural networks for both predicting node responses\nand selecting nodes, by which we can predict responses and select nodes even\nfor graphs with unseen response variables. The response prediction model is\ntrained by minimizing the expected test error. The node selection model is\ntrained by maximizing the expected error reduction with reinforcement learning.\nWe demonstrate the effectiveness of the proposed method with 11 types of road\ncongestion prediction tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 01:24:18 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Iwata", "Tomoharu", ""]]}, {"id": "2010.05430", "submitter": "Jian Liang", "authors": "Jian Liang, Kun Chen, Ming Lin, Changshui Zhang, Fei Wang", "title": "Robust Finite Mixture Regression for Heterogeneous Targets", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery, volume 32, pages 1509 to\n  1560, year 2018", "doi": "10.1007/s10618-018-0564-z", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite Mixture Regression (FMR) refers to the mixture modeling scheme which\nlearns multiple regression models from the training data set. Each of them is\nin charge of a subset. FMR is an effective scheme for handling sample\nheterogeneity, where a single regression model is not enough for capturing the\ncomplexities of the conditional distribution of the observed samples given the\nfeatures. In this paper, we propose an FMR model that 1) finds sample clusters\nand jointly models multiple incomplete mixed-type targets simultaneously, 2)\nachieves shared feature selection among tasks and cluster components, and 3)\ndetects anomaly tasks or clustered structure among tasks, and accommodates\noutlier samples. We provide non-asymptotic oracle performance bounds for our\nmodel under a high-dimensional learning framework. The proposed model is\nevaluated on both synthetic and real-world data sets. The results show that our\nmodel can achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 03:27:07 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Liang", "Jian", ""], ["Chen", "Kun", ""], ["Lin", "Ming", ""], ["Zhang", "Changshui", ""], ["Wang", "Fei", ""]]}, {"id": "2010.05496", "submitter": "HyeonJun Kim", "authors": "HyeonJun Kim", "title": "Feature Extraction of Text for Deep Learning Algorithms: Application on\n  Fake News Detection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Feature extraction is an important process of machine learning and deep\nlearning, as the process make algorithms function more efficiently, and also\naccurate. In natural language processing used in deception detection such as\nfake news detection, several ways of feature extraction in statistical aspect\nhad been introduced (e.g. N-gram). In this research, it will be shown that by\nusing deep learning algorithms and alphabet frequencies of the original text of\na news without any information about the sequence of the alphabet can actually\nbe used to classify fake news and trustworthy ones in high accuracy (85\\%). As\nthis pre-processing method makes the data notably compact but also include the\nfeature that is needed for the classifier, it seems that alphabet frequencies\ncontains some useful features for understanding complex context or meaning of\nthe original text.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 07:43:01 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 11:32:14 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kim", "HyeonJun", ""]]}, {"id": "2010.05516", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Timo Sztyler, Mathias Niepert", "title": "Explaining Neural Matrix Factorization with Gradient Rollback", "comments": "35th AAAI Conference on Artificial Intelligence, 2021. Includes\n  Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the predictions of neural black-box models is an important\nproblem, especially when such models are used in applications where user trust\nis crucial. Estimating the influence of training examples on a learned neural\nmodel's behavior allows us to identify training examples most responsible for a\ngiven prediction and, therefore, to faithfully explain the output of a\nblack-box model. The most generally applicable existing method is based on\ninfluence functions, which scale poorly for larger sample sizes and models.\n  We propose gradient rollback, a general approach for influence estimation,\napplicable to neural models where each parameter update step during gradient\ndescent touches a smaller number of parameters, even if the overall number of\nparameters is large. Neural matrix factorization models trained with gradient\ndescent are part of this model class. These models are popular and have found a\nwide range of applications in industry. Especially knowledge graph embedding\nmethods, which belong to this class, are used extensively. We show that\ngradient rollback is highly efficient at both training and test time. Moreover,\nwe show theoretically that the difference between gradient rollback's influence\napproximation and the true influence on a model's behavior is smaller than\nknown bounds on the stability of stochastic gradient descent. This establishes\nthat gradient rollback is robustly estimating example influence. We also\nconduct experiments which show that gradient rollback provides faithful\nexplanations for knowledge base completion and recommender datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 08:15:54 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 07:27:32 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 08:50:56 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 07:01:30 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Lawrence", "Carolin", ""], ["Sztyler", "Timo", ""], ["Niepert", "Mathias", ""]]}, {"id": "2010.05545", "submitter": "Jost Tobias Springenberg", "authors": "Jost Tobias Springenberg, Nicolas Heess, Daniel Mankowitz, Josh Merel,\n  Arunkumar Byravan, Abbas Abdolmaleki, Jackie Kay, Jonas Degrave, Julian\n  Schrittwieser, Yuval Tassa, Jonas Buchli, Dan Belov, Martin Riedmiller", "title": "Local Search for Policy Iteration in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for local, regularized, policy improvement in\nreinforcement learning (RL) that allows us to formulate model-based and\nmodel-free variants in a single framework. Our algorithm can be interpreted as\na natural extension of work on KL-regularized RL and introduces a form of tree\nsearch for continuous action spaces. We demonstrate that additional computation\nspent on model-based policy improvement during learning can improve data\nefficiency, and confirm that model-based policy improvement during action\nselection can also be beneficial. Quantitatively, our algorithm improves data\nefficiency on several continuous control benchmarks (when a model is learned in\nparallel), and it provides significant improvements in wall-clock time in\nhigh-dimensional domains (when a ground truth model is available). The unified\nframework also helps us to better understand the space of model-based and\nmodel-free algorithms. In particular, we demonstrate that some benefits\nattributed to model-based RL can be obtained without a model, simply by\nutilizing more computation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 09:02:48 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Springenberg", "Jost Tobias", ""], ["Heess", "Nicolas", ""], ["Mankowitz", "Daniel", ""], ["Merel", "Josh", ""], ["Byravan", "Arunkumar", ""], ["Abdolmaleki", "Abbas", ""], ["Kay", "Jackie", ""], ["Degrave", "Jonas", ""], ["Schrittwieser", "Julian", ""], ["Tassa", "Yuval", ""], ["Buchli", "Jonas", ""], ["Belov", "Dan", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2010.05563", "submitter": "Junchi Yu", "authors": "Junchi Yu, Tingyang Xu, Yu Rong, Yatao Bian, Junzhou Huang, Ran He", "title": "Graph Information Bottleneck for Subgraph Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the input graph and its label/property, several key problems of graph\nlearning, such as finding interpretable subgraphs, graph denoising and graph\ncompression, can be attributed to the fundamental problem of recognizing a\nsubgraph of the original one. This subgraph shall be as informative as\npossible, yet contains less redundant and noisy structure. This problem setting\nis closely related to the well-known information bottleneck (IB) principle,\nwhich, however, has less been studied for the irregular graph data and graph\nneural networks (GNNs). In this paper, we propose a framework of Graph\nInformation Bottleneck (GIB) for the subgraph recognition problem in deep graph\nlearning. Under this framework, one can recognize the maximally informative yet\ncompressive subgraph, named IB-subgraph. However, the GIB objective is\nnotoriously hard to optimize, mostly due to the intractability of the mutual\ninformation of irregular graph data and the unstable optimization process. In\norder to tackle these challenges, we propose: i) a GIB objective based-on a\nmutual information estimator for the irregular graph data; ii) a bi-level\noptimization scheme to maximize the GIB objective; iii) a connectivity loss to\nstabilize the optimization process. We evaluate the properties of the\nIB-subgraph in three application scenarios: improvement of graph\nclassification, graph interpretation and graph denoising. Extensive experiments\ndemonstrate that the information-theoretic IB-subgraph enjoys superior graph\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 09:32:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yu", "Junchi", ""], ["Xu", "Tingyang", ""], ["Rong", "Yu", ""], ["Bian", "Yatao", ""], ["Huang", "Junzhou", ""], ["He", "Ran", ""]]}, {"id": "2010.05595", "submitter": "Matteo Boschini", "authors": "Pietro Buzzega, Matteo Boschini, Angelo Porrello, Simone Calderara", "title": "Rethinking Experience Replay: a Bag of Tricks for Continual Learning", "comments": "8 pages, 6 figures. Accepted at the 25th International Conference on\n  Pattern Recognition (ICPR 2020), Milan, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Continual Learning, a Neural Network is trained on a stream of data whose\ndistribution shifts over time. Under these assumptions, it is especially\nchallenging to improve on classes appearing later in the stream while remaining\naccurate on previous ones. This is due to the infamous problem of catastrophic\nforgetting, which causes a quick performance degradation when the classifier\nfocuses on learning new categories. Recent literature proposed various\napproaches to tackle this issue, often resorting to very sophisticated\ntechniques. In this work, we show that naive rehearsal can be patched to\nachieve similar performance. We point out some shortcomings that restrain\nExperience Replay (ER) and propose five tricks to mitigate them. Experiments\nshow that ER, thus enhanced, displays an accuracy gain of 51.2 and 26.9\npercentage points on the CIFAR-10 and CIFAR-100 datasets respectively (memory\nbuffer size 1000). As a result, it surpasses current state-of-the-art\nrehearsal-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 10:59:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Buzzega", "Pietro", ""], ["Boschini", "Matteo", ""], ["Porrello", "Angelo", ""], ["Calderara", "Simone", ""]]}, {"id": "2010.05619", "submitter": "Carel F.W. Peeters", "authors": "Carel F.W. Peeters, Anders Ellern Bilgrau, Wessel N. van Wieringen", "title": "rags2ridges: A One-Stop-Shop for Graphical Modeling of High-Dimensional\n  Precision Matrices", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graphical model is an undirected network representing the conditional\nindependence properties between random variables. Graphical modeling has become\npart and parcel of systems or network approaches to multivariate data, in\nparticular when the variable dimension exceeds the observation dimension.\nrags2ridges is an R package for graphical modeling of high-dimensional\nprecision matrices. It provides a modular framework for the extraction,\nvisualization, and analysis of Gaussian graphical models from high-dimensional\ndata. Moreover, it can handle the incorporation of prior information as well as\nmultiple heterogeneous data classes. As such, it provides a one-stop-shop for\ngraphical modeling of high-dimensional precision matrices. The functionality of\nthe package is illustrated with an example dataset pertaining to blood-based\nmetabolite measurements in persons suffering from Alzheimer's Disease.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 11:43:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Peeters", "Carel F. W.", ""], ["Bilgrau", "Anders Ellern", ""], ["van Wieringen", "Wessel N.", ""]]}, {"id": "2010.05620", "submitter": "Ofir Lindenbaum", "authors": "Ofir Lindenbaum, Moshe Salhov, Amir Averbuch, Yuval Kluger", "title": "$\\ell_0$-based Sparse Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Canonical Correlation Analysis (CCA) models are powerful for studying the\nassociations between two sets of variables. The canonically correlated\nrepresentations, termed \\textit{canonical variates} are widely used in\nunsupervised learning to analyze unlabeled multi-modal registered datasets.\nDespite their success, CCA models may break (or overfit) if the number of\nvariables in either of the modalities exceeds the number of samples. Moreover,\noften a significant fraction of the variables measures modality-specific\ninformation, and thus removing them is beneficial for identifying the\n\\textit{canonically correlated variates}. Here, we propose $\\ell_0$-CCA, a\nmethod for learning correlated representations based on sparse subsets of\nvariables from two observed modalities. Sparsity is obtained by multiplying the\ninput variables by stochastic gates, whose parameters are learned together with\nthe CCA weights via an $\\ell_0$-regularized correlation loss. We further\npropose $\\ell_0$-Deep CCA for solving the problem of non-linear sparse CCA by\nmodeling the correlated representations using deep nets. We demonstrate the\nefficacy of the method using several synthetic and real examples. Most notably,\nby gating nuisance input variables, our approach improves the extracted\nrepresentations compared to other linear, non-linear and sparse CCA-based\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 11:44:15 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 14:47:45 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Lindenbaum", "Ofir", ""], ["Salhov", "Moshe", ""], ["Averbuch", "Amir", ""], ["Kluger", "Yuval", ""]]}, {"id": "2010.05627", "submitter": "Pan Zhou", "authors": "Pan Zhou, Jiashi Feng, Chao Ma, Caiming Xiong, Steven HOI, Weinan E", "title": "Towards Theoretically Understanding Why SGD Generalizes Better Than ADAM\n  in Deep Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not clear yet why ADAM-alike adaptive gradient algorithms suffer from\nworse generalization performance than SGD despite their faster training speed.\nThis work aims to provide understandings on this generalization gap by\nanalyzing their local convergence behaviors. Specifically, we observe the heavy\ntails of gradient noise in these algorithms. This motivates us to analyze these\nalgorithms through their Levy-driven stochastic differential equations (SDEs)\nbecause of the similar convergence behaviors of an algorithm and its SDE. Then\nwe establish the escaping time of these SDEs from a local basin. The result\nshows that (1) the escaping time of both SGD and ADAM~depends on the Radon\nmeasure of the basin positively and the heaviness of gradient noise negatively;\n(2) for the same basin, SGD enjoys smaller escaping time than ADAM, mainly\nbecause (a) the geometry adaptation in ADAM~via adaptively scaling each\ngradient coordinate well diminishes the anisotropic structure in gradient noise\nand results in larger Radon measure of a basin; (b) the exponential gradient\naverage in ADAM~smooths its gradient and leads to lighter gradient noise tails\nthan SGD. So SGD is more locally unstable than ADAM~at sharp minima defined as\nthe minima whose local basins have small Radon measure, and can better escape\nfrom them to flatter ones with larger Radon measure. As flat minima here which\noften refer to the minima at flat or asymmetric basins/valleys often generalize\nbetter than sharp ones~\\cite{keskar2016large,he2019asymmetric}, our result\nexplains the better generalization performance of SGD over ADAM. Finally,\nexperimental results confirm our heavy-tailed gradient noise assumption and\ntheoretical affirmation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:00:26 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhou", "Pan", ""], ["Feng", "Jiashi", ""], ["Ma", "Chao", ""], ["Xiong", "Caiming", ""], ["HOI", "Steven", ""], ["E", "Weinan", ""]]}, {"id": "2010.05635", "submitter": "Nikolaos Nikolaou", "authors": "Nikolaos Nikolaou and Konstantinos Sechidis", "title": "Inferring Causal Direction from Observational Data: A Complexity\n  Approach", "comments": "9 Pages, 2 figures, Presented in Machine Learning for Pharma and\n  Healthcare Applications ECML PKDD 2020 Workshop (PharML 2020)", "journal-ref": "Machine Learning for Pharma and Healthcare Applications ECML PKDD\n  2020 Workshop (PharML 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of causal structure learning from observational data lies a\ndeceivingly simple question: given two statistically dependent random\nvariables, which one has a causal effect on the other? This is impossible to\nanswer using statistical dependence testing alone and requires that we make\nadditional assumptions. We propose several fast and simple criteria for\ndistinguishing cause and effect in pairs of discrete or continuous random\nvariables. The intuition behind them is that predicting the effect variable\nusing the cause variable should be `simpler' than the reverse -- different\nnotions of `simplicity' giving rise to different criteria. We demonstrate the\naccuracy of the criteria on synthetic data generated under a broad family of\ncausal mechanisms and types of noise.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:10:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nikolaou", "Nikolaos", ""], ["Sechidis", "Konstantinos", ""]]}, {"id": "2010.05681", "submitter": "Ioana Giurgiu", "authors": "Nuno Mota Goncalves, Ioana Giurgiu, Anika Schumann", "title": "From Time Series to Euclidean Spaces: On Spatial Transformations for\n  Temporal Clustering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised clustering of temporal data is both challenging and crucial in\nmachine learning. In this paper, we show that neither traditional clustering\nmethods, time series specific or even deep learning-based alternatives\ngeneralise well when both varying sampling rates and high dimensionality are\npresent in the input data. We propose a novel approach to temporal clustering,\nin which we (1) transform the input time series into a distance-based projected\nrepresentation by using similarity measures suitable for dealing with temporal\ndata,(2) feed these projections into a multi-layer CNN-GRU autoencoder to\ngenerate meaningful domain-aware latent representations, which ultimately (3)\nallow for a natural separation of clusters beneficial for most important\ntraditional clustering algorithms. We evaluate our approach on time series\ndatasets from various domains and show that it not only outperforms existing\nmethods in all cases, by up to 32%, but is also robust and incurs negligible\ncomputation overheads.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 09:08:16 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Goncalves", "Nuno Mota", ""], ["Giurgiu", "Ioana", ""], ["Schumann", "Anika", ""]]}, {"id": "2010.05744", "submitter": "Federico Amato", "authors": "Federico Amato, Fabian Guignard, Philippe Jacquet and Mikhail Kanevski", "title": "On Feature Selection Using Anisotropic General Regression Neural Network", "comments": null, "journal-ref": "ESANN 2020 proceedings, European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning. Online event, 2-4\n  October 2020, i6doc.com publ., ISBN 978-2-87587-074-2. Available from\n  http://www.i6doc.com/en/", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of irrelevant features in the input dataset tends to reduce the\ninterpretability and predictive quality of machine learning models. Therefore,\nthe development of feature selection methods to recognize irrelevant features\nis a crucial topic in machine learning. Here we show how the General Regression\nNeural Network used with an anisotropic Gaussian Kernel can be used to perform\nfeature selection. A number of numerical experiments are conducted using\nsimulated data to study the robustness of the proposed methodology and its\nsensitivity to sample size. Finally, a comparison with four other feature\nselection methods is performed on several real world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:35:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Amato", "Federico", ""], ["Guignard", "Fabian", ""], ["Jacquet", "Philippe", ""], ["Kanevski", "Mikhail", ""]]}, {"id": "2010.05761", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski", "title": "The Risks of Invariant Risk Minimization", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariant Causal Prediction (Peters et al., 2016) is a technique for\nout-of-distribution generalization which assumes that some aspects of the data\ndistribution vary across the training set but that the underlying causal\nmechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant\nRisk Minimization (IRM), an objective based on this idea for learning deep,\ninvariant features of data which are a complex function of latent variables;\nmany alternatives have subsequently been suggested. However, formal guarantees\nfor all of these works are severely lacking. In this paper, we present the\nfirst analysis of classification under the IRM objective--as well as these\nrecently proposed alternatives--under a fairly natural and general model. In\nthe linear case, we show simple conditions under which the optimal solution\nsucceeds or, more often, fails to recover the optimal invariant predictor. We\nfurthermore present the very first results in the non-linear regime: we\ndemonstrate that IRM can fail catastrophically unless the test data are\nsufficiently similar to the training distribution--this is precisely the issue\nthat it was intended to solve. Thus, in this setting we find that IRM and its\nalternatives fundamentally do not improve over standard Empirical Risk\nMinimization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 14:54:32 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 16:23:24 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Ravikumar", "Pradeep", ""], ["Risteski", "Andrej", ""]]}, {"id": "2010.05767", "submitter": "Jan Robine", "authors": "Jan Robine, Tobias Uelwer, Stefan Harmeling", "title": "Smaller World Models for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample efficiency remains a fundamental issue of reinforcement learning.\nModel-based algorithms try to make better use of data by simulating the\nenvironment with a model. We propose a new neural network architecture for\nworld models based on a vector quantized-variational autoencoder (VQ-VAE) to\nencode observations and a convolutional LSTM to predict the next embedding\nindices. A model-free PPO agent is trained purely on simulated experience from\nthe world model. We adopt the setup introduced by Kaiser et al. (2020), which\nonly allows 100K interactions with the real environment. We apply our method on\n36 Atari environments and show that we reach comparable performance to their\nSimPLe algorithm, while our model is significantly smaller.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 15:02:41 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 12:02:16 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Robine", "Jan", ""], ["Uelwer", "Tobias", ""], ["Harmeling", "Stefan", ""]]}, {"id": "2010.05774", "submitter": "Sagar Samtani", "authors": "Sagar Samtani, Hongyi Zhu, Balaji Padmanabhan, Yidong Chai, Hsinchun\n  Chen", "title": "Deep Learning for Information Systems Research", "comments": "56 pages total, 1 page title and authors, 42 pages main text, 13\n  pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has rapidly emerged as a key disruptive\ntechnology in the 21st century. At the heart of modern AI lies Deep Learning\n(DL), an emerging class of algorithms that has enabled today's platforms and\norganizations to operate at unprecedented efficiency, effectiveness, and scale.\nDespite significant interest, IS contributions in DL have been limited, which\nwe argue is in part due to issues with defining, positioning, and conducting DL\nresearch. Recognizing the tremendous opportunity here for the IS community,\nthis work clarifies, streamlines, and presents approaches for IS scholars to\nmake timely and high-impact contributions. Related to this broader goal, this\npaper makes five timely contributions. First, we systematically summarize the\nmajor components of DL in a novel Deep Learning for Information Systems\nResearch (DL-ISR) schematic that illustrates how technical DL processes are\ndriven by key factors from an application environment. Second, we present a\nnovel Knowledge Contribution Framework (KCF) to help IS scholars position their\nDL contributions for maximum impact. Third, we provide ten guidelines to help\nIS scholars generate rigorous and relevant DL-ISR in a systematic, high-quality\nfashion. Fourth, we present a review of prevailing journal and conference\nvenues to examine how IS scholars have leveraged DL for various research\ninquiries. Finally, we provide a unique perspective on how IS scholars can\nformulate DL-ISR inquiries by carefully considering the interplay of business\nfunction(s), application areas(s), and the KCF. This perspective intentionally\nemphasizes inter-disciplinary, intra-disciplinary, and cross-IS tradition\nperspectives. Taken together, these contributions provide IS scholars a timely\nframework to advance the scale, scope, and impact of deep learning research.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 15:23:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Samtani", "Sagar", ""], ["Zhu", "Hongyi", ""], ["Padmanabhan", "Balaji", ""], ["Chai", "Yidong", ""], ["Chen", "Hsinchun", ""]]}, {"id": "2010.05778", "submitter": "Todd Murphey", "authors": "Giorgos Mamakoukas, Maria L. Castano, Xiaobo Tan, Todd D. Murphey", "title": "Derivative-Based Koopman Operators for Real-Time Control of Robotic\n  Systems", "comments": null, "journal-ref": "IEEE Transactions on Robotics, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA cs.RO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a generalizable methodology for data-driven\nidentification of nonlinear dynamics that bounds the model error in terms of\nthe prediction horizon and the magnitude of the derivatives of the system\nstates. Using higher-order derivatives of general nonlinear dynamics that need\nnot be known, we construct a Koopman operator-based linear representation and\nutilize Taylor series accuracy analysis to derive an error bound. The resulting\nerror formula is used to choose the order of derivatives in the basis functions\nand obtain a data-driven Koopman model using a closed-form expression that can\nbe computed in real time. Using the inverted pendulum system, we illustrate the\nrobustness of the error bounds given noisy measurements of unknown dynamics,\nwhere the derivatives are estimated numerically. When combined with control,\nthe Koopman representation of the nonlinear system has marginally better\nperformance than competing nonlinear modeling methods, such as SINDy and NARX.\nIn addition, as a linear model, the Koopman approach lends itself readily to\nefficient control design tools, such as LQR, whereas the other modeling\napproaches require nonlinear control methods. The efficacy of the approach is\nfurther demonstrated with simulation and experimental results on the control of\na tail-actuated robotic fish. Experimental results show that the proposed\ndata-driven control approach outperforms a tuned PID (Proportional Integral\nDerivative) controller and that updating the data-driven model online\nsignificantly improves performance in the presence of unmodeled fluid\ndisturbance. This paper is complemented with a video:\nhttps://youtu.be/9_wx0tdDta0.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 15:15:13 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 14:28:22 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Mamakoukas", "Giorgos", ""], ["Castano", "Maria L.", ""], ["Tan", "Xiaobo", ""], ["Murphey", "Todd D.", ""]]}, {"id": "2010.05780", "submitter": "Chad M. Topaz", "authors": "Lu Xian, Henry Adams, Chad M. Topaz, Lori Ziegelmeier", "title": "Capturing Dynamics of Time-Varying Data via Topology", "comments": "35 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to understanding complex data is to study its shape through the\nlens of algebraic topology. While the early development of topological data\nanalysis focused primarily on static data, in recent years, theoretical and\napplied studies have turned to data that varies in time. A time-varying\ncollection of metric spaces as formed, for example, by a moving school of fish\nor flock of birds, can contain a vast amount of information. There is often a\nneed to simplify or summarize the dynamic behavior. We provide an introduction\nto topological summaries of time-varying metric spaces including vineyards\n[19], crocker plots [56], and multiparameter rank functions [37]. We then\nintroduce a new tool to summarize time-varying metric spaces: a crocker stack.\nCrocker stacks are convenient for visualization, amenable to machine learning,\nand satisfy a desirable continuity property which we prove. We demonstrate the\nutility of crocker stacks for a parameter identification task involving an\ninfluential model of biological aggregations [58]. Altogether, we aim to bring\nthe broader applied mathematics community up-to-date on topological summaries\nof time-varying metric spaces.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:07:40 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 14:10:20 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Xian", "Lu", ""], ["Adams", "Henry", ""], ["Topaz", "Chad M.", ""], ["Ziegelmeier", "Lori", ""]]}, {"id": "2010.05820", "submitter": "Arijit Sehanobish", "authors": "Arijit Sehanobish, Neal Ravindra, David van Dijk", "title": "Permutation invariant networks to learn Wasserstein metrics", "comments": "Fix typos, Accepted as a spotlight at Topological Data Analysis and\n  Beyond Workshop at Neurips 2020. Added more experiments and results. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the space of probability measures on a metric space equipped\nwith a Wasserstein distance is one of the fundamental questions in mathematical\nanalysis. The Wasserstein metric has received a lot of attention in the machine\nlearning community especially for its principled way of comparing\ndistributions. In this work, we use a permutation invariant network to map\nsamples from probability measures into a low-dimensional space such that the\nEuclidean distance between the encoded samples reflects the Wasserstein\ndistance between probability measures. We show that our network can generalize\nto correctly compute distances between unseen densities. We also show that\nthese networks can learn the first and the second moments of probability\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:15:35 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 17:30:42 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 17:54:38 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 21:18:54 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sehanobish", "Arijit", ""], ["Ravindra", "Neal", ""], ["van Dijk", "David", ""]]}, {"id": "2010.05843", "submitter": "Yu Bai", "authors": "Yu Bai, Minshuo Chen, Pan Zhou, Tuo Zhao, Jason D. Lee, Sham Kakade,\n  Huan Wang, Caiming Xiong", "title": "How Important is the Train-Validation Split in Meta-Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning aims to perform fast adaptation on a new task through learning\na \"prior\" from multiple existing tasks. A common practice in meta-learning is\nto perform a train-validation split (\\emph{train-val method}) where the prior\nadapts to the task on one split of the data, and the resulting predictor is\nevaluated on another split. Despite its prevalence, the importance of the\ntrain-validation split is not well understood either in theory or in practice,\nparticularly in comparison to the more direct \\emph{train-train method}, which\nuses all the per-task data for both training and evaluation.\n  We provide a detailed theoretical study on whether and when the\ntrain-validation split is helpful in the linear centroid meta-learning problem.\nIn the agnostic case, we show that the expected loss of the train-val method is\nminimized at the optimal prior for meta testing, and this is not the case for\nthe train-train method in general without structural assumptions on the data.\nIn contrast, in the realizable case where the data are generated from linear\nmodels, we show that both the train-val and train-train losses are minimized at\nthe optimal prior in expectation. Further, perhaps surprisingly, our main\nresult shows that the train-train method achieves a \\emph{strictly better}\nexcess loss in this realizable case, even when the regularization parameter and\nsplit ratio are optimally tuned for both methods. Our results highlight that\nsample splitting may not always be preferable, especially when the data is\nrealizable by the model. We validate our theories by experimentally showing\nthat the train-train method can indeed outperform the train-val method, on both\nsimulations and real meta-learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:48:42 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:07:48 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bai", "Yu", ""], ["Chen", "Minshuo", ""], ["Zhou", "Pan", ""], ["Zhao", "Tuo", ""], ["Lee", "Jason D.", ""], ["Kakade", "Sham", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""]]}, {"id": "2010.05893", "submitter": "Daniel Levy", "authors": "Daniel Levy, Yair Carmon, John C. Duchi and Aaron Sidford", "title": "Large-Scale Methods for Distributionally Robust Optimization", "comments": "63 pages, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze algorithms for distributionally robust optimization of\nconvex losses with conditional value at risk (CVaR) and $\\chi^2$ divergence\nuncertainty sets. We prove that our algorithms require a number of gradient\nevaluations independent of training set size and number of parameters, making\nthem suitable for large-scale applications. For $\\chi^2$ uncertainty sets these\nare the first such guarantees in the literature, and for CVaR our guarantees\nscale linearly in the uncertainty level rather than quadratically as in\nprevious work. We also provide lower bounds proving the worst-case optimality\nof our algorithms for CVaR and a penalized version of the $\\chi^2$ problem. Our\nprimary technical contributions are novel bounds on the bias of batch robust\nrisk estimation and the variance of a multilevel Monte Carlo gradient estimator\ndue to [Blanchet & Glynn, 2015]. Experiments on MNIST and ImageNet confirm the\ntheoretical scaling of our algorithms, which are 9--36 times more efficient\nthan full-batch methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:41:44 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 03:05:30 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Levy", "Daniel", ""], ["Carmon", "Yair", ""], ["Duchi", "John C.", ""], ["Sidford", "Aaron", ""]]}, {"id": "2010.05895", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R\n  Narayanan, Xiaoning Qian", "title": "BayReL: Bayesian Relational Learning for Multi-omics Data Integration", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG q-bio.MN stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-throughput molecular profiling technologies have produced\nhigh-dimensional multi-omics data, enabling systematic understanding of living\nsystems at the genome scale. Studying molecular interactions across different\ndata types helps reveal signal transduction mechanisms across different classes\nof molecules. In this paper, we develop a novel Bayesian representation\nlearning method that infers the relational interactions across multi-omics data\ntypes. Our method, Bayesian Relational Learning (BayReL) for multi-omics data\nintegration, takes advantage of a priori known relationships among the same\nclass of molecules, modeled as a graph at each corresponding view, to learn\nview-specific latent variables as well as a multi-partite graph that encodes\nthe interactions across views. Our experiments on several real-world datasets\ndemonstrate enhanced performance of BayReL in inferring meaningful interactions\ncompared to existing baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:43:07 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:34:30 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 07:22:40 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Hasanzadeh", "Arman", ""], ["Duffield", "Nick", ""], ["Narayanan", "Krishna R", ""], ["Qian", "Xiaoning", ""]]}, {"id": "2010.05899", "submitter": "Paria Rashidinejad", "authors": "Paria Rashidinejad, Jiantao Jiao, Stuart Russell", "title": "SLIP: Learning to Predict in Unknown Dynamical Systems with Long-Term\n  Memory", "comments": "47 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient and practical (polynomial time) algorithm for online\nprediction in unknown and partially observed linear dynamical systems (LDS)\nunder stochastic noise. When the system parameters are known, the optimal\nlinear predictor is the Kalman filter. However, the performance of existing\npredictive models is poor in important classes of LDS that are only marginally\nstable and exhibit long-term forecast memory. We tackle this problem through\nbounding the generalized Kolmogorov width of the Kalman filter model by\nspectral methods and conducting tight convex relaxation. We provide a\nfinite-sample analysis, showing that our algorithm competes with Kalman filter\nin hindsight with only logarithmic regret. Our regret analysis relies on\nMendelson's small-ball method, providing sharp error bounds without\nconcentration, boundedness, or exponential forgetting assumptions. We also give\nexperimental results demonstrating that our algorithm outperforms\nstate-of-the-art methods. Our theoretical and experimental results shed light\non the conditions required for efficient probably approximately correct (PAC)\nlearning of the Kalman filter from partially observed data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:50:21 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Rashidinejad", "Paria", ""], ["Jiao", "Jiantao", ""], ["Russell", "Stuart", ""]]}, {"id": "2010.05979", "submitter": "Sahar Tavakoli", "authors": "Sahar Tavakoli", "title": "Signal classification using weighted orthogonal regression method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new classifier based on the intrinsic properties of the data\nis proposed. Classification is an essential task in data mining-based\napplications. The classification problem will be challenging when the size of\nthe training set is not sufficient to compare to the dimension of the problem.\nThis paper proposes a new classification method that exploits the intrinsic\nstructure of each class through the corresponding Eigen components. Each\ncomponent contributes to the learned span of each class by specific weight. The\nweight is determined by the associated eigenvalue. This approach results in\nreliable learning robust in the case of facing a classification problem with\nlimited training data. The proposed method involves the obtained Eigenvectors\nby SVD of data from each class to select the bases for each subspace. Moreover,\nit considers an efficient weighting for the decision-making criterion to\ndiscriminate two classes. In addition to high performance on artificial data,\nthis method has increased the best result of international competition.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:12:14 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Tavakoli", "Sahar", ""]]}, {"id": "2010.06022", "submitter": "Andr\\'as Gy\\\"orgy", "authors": "Andr\\'as Gy\\\"orgy, Pooria Joulani", "title": "Adapting to Delays and Data in Adversarial Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the adversarial multi-armed bandit problem under delayed\nfeedback. We analyze variants of the Exp3 algorithm that tune their step-size\nusing only information (about the losses and delays) available at the time of\nthe decisions, and obtain regret guarantees that adapt to the observed (rather\nthan the worst-case) sequences of delays and/or losses. First, through a\nremarkably simple proof technique, we show that with proper tuning of the step\nsize, the algorithm achieves an optimal (up to logarithmic factors) regret of\norder $\\sqrt{\\log(K)(TK + D)}$ both in expectation and in high probability,\nwhere $K$ is the number of arms, $T$ is the time horizon, and $D$ is the\ncumulative delay. The high-probability version of the bound, which is the first\nhigh-probability delay-adaptive bound in the literature, crucially depends on\nthe use of implicit exploration in estimating the losses. Then, following\nZimmert and Seldin [2019], we extend these results so that the algorithm can\n\"skip\" rounds with large delays, resulting in regret bounds of order\n$\\sqrt{TK\\log(K)} + |R| + \\sqrt{D_{\\bar{R}}\\log(K)}$, where $R$ is an arbitrary\nset of rounds (which are skipped) and $D_{\\bar{R}}$ is the cumulative delay of\nthe feedback for other rounds. Finally, we present another, data-adaptive\n(AdaGrad-style) version of the algorithm for which the regret adapts to the\nobserved (delayed) losses instead of only adapting to the cumulative delay\n(this algorithm requires an a priori upper bound on the maximum delay, or the\nadvance knowledge of the delay for each decision when it is made). The\nresulting bound can be orders of magnitude smaller on benign problems, and it\ncan be shown that the delay only affects the regret through the loss of the\nbest arm.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 20:53:52 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Joulani", "Pooria", ""]]}, {"id": "2010.06026", "submitter": "Lev Utkin", "authors": "Andrei V. Konstantinov and Lev V. Utkin", "title": "A Generalized Stacking for Implementing Ensembles of Gradient Boosting\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradient boosting machine is one of the powerful tools for solving\nregression problems. In order to cope with its shortcomings, an approach for\nconstructing ensembles of gradient boosting models is proposed. The main idea\nbehind the approach is to use the stacking algorithm in order to learn a\nsecond-level meta-model which can be regarded as a model for implementing\nvarious ensembles of gradient boosting models. First, the linear regression of\nthe gradient boosting models is considered as a simplest realization of the\nmeta-model under condition that the linear model is differentiable with respect\nto its coefficients (weights). Then it is shown that the proposed approach can\nbe simply extended on arbitrary differentiable combination models, for example,\non neural networks which are differentiable and can implement arbitrary\nfunctions of gradient boosting models. Various numerical examples illustrate\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 21:05:45 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Konstantinov", "Andrei V.", ""], ["Utkin", "Lev V.", ""]]}, {"id": "2010.06053", "submitter": "Zhao Song", "authors": "Yangsibo Huang, Zhao Song, Danqi Chen, Kai Li, Sanjeev Arora", "title": "TextHide: Tackling Data Privacy in Language Understanding Tasks", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  An unsolved challenge in distributed or federated learning is to effectively\nmitigate privacy risks without slowing down training or reducing accuracy. In\nthis paper, we propose TextHide aiming at addressing this challenge for natural\nlanguage understanding tasks. It requires all participants to add a simple\nencryption step to prevent an eavesdropping attacker from recovering private\ntext data. Such an encryption step is efficient and only affects the task\nperformance slightly. In addition, TextHide fits well with the popular\nframework of fine-tuning pre-trained language models (e.g., BERT) for any\nsentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and\nour experiments show that TextHide can effectively defend attacks on shared\ngradients or representations and the averaged accuracy reduction is only\n$1.9\\%$. We also present an analysis of the security of TextHide using a\nconjecture about the computational intractability of a mathematical problem.\n  Our code is available at https://github.com/Hazelsuko07/TextHide\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 22:22:15 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Huang", "Yangsibo", ""], ["Song", "Zhao", ""], ["Chen", "Danqi", ""], ["Li", "Kai", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.06076", "submitter": "George Monta\\~nez", "authors": "Daniel Bashir, George D. Montanez, Sonia Sehra, Pedro Sandoval Segura,\n  Julius Lauw", "title": "An Information-Theoretic Perspective on Overfitting and Underfitting", "comments": "Accepted for presentation at The 33rd Australasian Joint Conference\n  on Artificial Intelligence (AJCAI 2020), November 29-30, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-theoretic framework for understanding overfitting\nand underfitting in machine learning and prove the formal undecidability of\ndetermining whether an arbitrary classification algorithm will overfit a\ndataset. Measuring algorithm capacity via the information transferred from\ndatasets to models, we consider mismatches between algorithm capacities and\ndatasets to provide a signature for when a model can overfit or underfit a\ndataset. We present results upper-bounding algorithm capacity, establish its\nrelationship to quantities in the algorithmic search framework for machine\nlearning, and relate our work to recent information-theoretic approaches to\ngeneralization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 23:24:47 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 19:22:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bashir", "Daniel", ""], ["Montanez", "George D.", ""], ["Sehra", "Sonia", ""], ["Segura", "Pedro Sandoval", ""], ["Lauw", "Julius", ""]]}, {"id": "2010.06080", "submitter": "Xueying Liu", "authors": "Xueying Liu, Jeremy Carter, Brad Ray and George Mohler", "title": "Point Process Modeling of Drug Overdoses with Heterogeneous and Missing\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opioid overdose rates have increased in the United States over the past\ndecade and reflect a major public health crisis. Modeling and prediction of\ndrug and opioid hotspots, where a high percentage of events fall in a small\npercentage of space-time, could help better focus limited social and health\nservices. In this work we present a spatial-temporal point process model for\ndrug overdose clustering. The data input into the model comes from two\nheterogeneous sources: 1) high volume emergency medical calls for service (EMS)\nrecords containing location and time, but no information on the type of\nnon-fatal overdose and 2) fatal overdose toxicology reports from the coroner\ncontaining location and high-dimensional information from the toxicology screen\non the drugs present at the time of death. We first use non-negative matrix\nfactorization to cluster toxicology reports into drug overdose categories and\nwe then develop an EM algorithm for integrating the two heterogeneous data\nsets, where the mark corresponding to overdose category is inferred for the EMS\ndata and the high volume EMS data is used to more accurately predict drug\noverdose death hotspots. We apply the algorithm to drug overdose data from\nIndianapolis, showing that the point process defined on the integrated data\noutperforms point processes that use only homogeneous EMS (AUC improvement .72\nto .8) or coroner data (AUC improvement .81 to .85).We also investigate the\nextent to which overdoses are contagious, as a function of the type of\noverdose, while controlling for exogenous fluctuations in the background rate\nthat might also contribute to clustering. We find that drug and opioid overdose\ndeaths exhibit significant excitation, with branching ratio ranging from .72 to\n.98.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 23:47:55 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Liu", "Xueying", ""], ["Carter", "Jeremy", ""], ["Ray", "Brad", ""], ["Mohler", "George", ""]]}, {"id": "2010.06099", "submitter": "Felipe Farias Mr.", "authors": "Felipe Farias, Teresa Ludermir, Carmelo Bastos-Filho", "title": "Similarity Based Stratified Splitting: an approach to train better\n  classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Similarity-Based Stratified Splitting (SBSS) technique, which\nuses both the output and input space information to split the data. The splits\nare generated using similarity functions among samples to place similar samples\nin different splits. This approach allows for a better representation of the\ndata in the training phase. This strategy leads to a more realistic performance\nestimation when used in real-world applications. We evaluate our proposal in\ntwenty-two benchmark datasets with classifiers such as Multi-Layer Perceptron,\nSupport Vector Machine, Random Forest and K-Nearest Neighbors, and five\nsimilarity functions Cityblock, Chebyshev, Cosine, Correlation, and Euclidean.\nAccording to the Wilcoxon Sign-Rank test, our approach consistently\noutperformed ordinary stratified 10-fold cross-validation in 75\\% of the\nassessed scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 01:07:48 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Farias", "Felipe", ""], ["Ludermir", "Teresa", ""], ["Bastos-Filho", "Carmelo", ""]]}, {"id": "2010.06101", "submitter": "Jie Mei", "authors": "Jie Mei, Christian Desrosiers, Johannes Frasnelli", "title": "Machine learning for the diagnosis of Parkinson's disease: A systematic\n  review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Diagnosis of Parkinson's disease (PD) is commonly based on medical\nobservations and assessment of clinical signs, including the characterization\nof a variety of motor symptoms. However, traditional diagnostic approaches may\nsuffer from subjectivity as they rely on the evaluation of movements that are\nsometimes subtle to human eyes and therefore difficult to classify, leading to\npossible misclassification. In the meantime, early non-motor symptoms of PD may\nbe mild and can be caused by many other conditions. Therefore, these symptoms\nare often overlooked, making diagnosis of PD at an early stage challenging. To\naddress these difficulties and to refine the diagnosis and assessment\nprocedures of PD, machine learning methods have been implemented for the\nclassification of PD and healthy controls or patients with similar clinical\npresentations (e.g., movement disorders or other Parkinsonian syndromes). To\nprovide a comprehensive overview of data modalities and machine learning\nmethods that have been used in the diagnosis and differential diagnosis of PD,\nin this study, we conducted a systematic literature review of studies published\nuntil February 14, 2020, using the PubMed and IEEE Xplore databases. A total of\n209 studies were included, extracted for relevant information and presented in\nthis systematic review, with an investigation of their aims, sources of data,\ntypes of data, machine learning methods and associated outcomes. These studies\ndemonstrate a high potential for adaptation of machine learning methods and\nnovel biomarkers in clinical decision making, leading to increasingly\nsystematic, informed diagnosis of PD.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 01:14:04 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Mei", "Jie", ""], ["Desrosiers", "Christian", ""], ["Frasnelli", "Johannes", ""]]}, {"id": "2010.06121", "submitter": "Han Xu", "authors": "Han Xu, Xiaorui Liu, Yaxin Li, Anil K. Jain, Jiliang Tang", "title": "To be Robust or to be Fair: Towards Fairness in Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training algorithms have been proved to be reliable to improve\nmachine learning models' robustness against adversarial examples. However, we\nfind that adversarial training algorithms tend to introduce severe disparity of\naccuracy and robustness between different groups of data. For instance, a PGD\nadversarially trained ResNet18 model on CIFAR-10 has 93% clean accuracy and 67%\nPGD l-infty-8 robust accuracy on the class \"automobile\" but only 65% and 17% on\nthe class \"cat\". This phenomenon happens in balanced datasets and does not\nexist in naturally trained models when only using clean samples. In this work,\nwe empirically and theoretically show that this phenomenon can happen under\ngeneral adversarial training algorithms which minimize DNN models' robust\nerrors. Motivated by these findings, we propose a Fair-Robust-Learning (FRL)\nframework to mitigate this unfairness problem when doing adversarial defenses.\nExperimental results validate the effectiveness of FRL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 02:21:54 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 23:32:55 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Xu", "Han", ""], ["Liu", "Xiaorui", ""], ["Li", "Yaxin", ""], ["Jain", "Anil K.", ""], ["Tang", "Jiliang", ""]]}, {"id": "2010.06154", "submitter": "Hongyang Zhang", "authors": "Maria-Florina Balcan and Avrim Blum and Dravyansh Sharma and Hongyang\n  Zhang", "title": "On the Power of Abstention and Data-Driven Decision Making for\n  Adversarial Robustness", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally define a feature-space attack where the adversary can perturb\ndatapoints by arbitrary amounts but in restricted directions. By restricting\nthe attack to a small random subspace, our model provides a clean abstraction\nfor non-Lipschitz networks which map small input movements to large feature\nmovements. We prove that classifiers with the ability to abstain are provably\nmore powerful than those that cannot in this setting. Specifically, we show\nthat no matter how well-behaved the natural data is, any classifier that cannot\nabstain will be defeated by such an adversary. However, by allowing abstention,\nwe give a parameterized algorithm with provably good performance against such\nan adversary when classes are reasonably well-separated in feature space and\nthe dimension of the feature space is high. We further use a data-driven method\nto set our algorithm parameters to optimize over the accuracy vs. abstention\ntrade-off with strong theoretical guarantees. Our theory has direct\napplications to the technique of contrastive learning, where we empirically\ndemonstrate the ability of our algorithms to obtain high robust accuracy with\nonly small amounts of abstention in both supervised and self-supervised\nsettings. Our results provide a first formal abstention-based gap, and a first\nprovable optimization for the induced trade-off in an adversarial defense\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 03:56:39 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 04:19:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Blum", "Avrim", ""], ["Sharma", "Dravyansh", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2010.06175", "submitter": "Xin Xing", "authors": "Xin Xing, Yu Gui, Chenguang Dai, and Jun S. Liu", "title": "Neural Gaussian Mirror for Controlled Feature Selection in Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become increasingly popular and achieved\noutstanding performance in predictive tasks. However, the DNN framework itself\ncannot inform the user which features are more or less relevant for making the\nprediction, which limits its applicability in many scientific fields. We\nintroduce neural Gaussian mirrors (NGMs), in which mirrored features are\ncreated, via a structured perturbation based on a kernel-based conditional\ndependence measure, to help evaluate feature importance. We design two\nmodifications of the DNN architecture for incorporating mirrored features and\nproviding mirror statistics to measure feature importance. As shown in\nsimulated and real data examples, the proposed method controls the feature\nselection error rate at a predefined level and maintains a high selection power\neven with the presence of highly correlated features.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 04:30:53 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Xing", "Xin", ""], ["Gui", "Yu", ""], ["Dai", "Chenguang", ""], ["Liu", "Jun S.", ""]]}, {"id": "2010.06192", "submitter": "Jian Zhang", "authors": "Pedram Zamirai, Jian Zhang, Christopher R. Aberger, Christopher De Sa", "title": "Revisiting BFloat16 Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art generic low-precision training algorithms use a mix of\n16-bit and 32-bit precision, creating the folklore that 16-bit hardware compute\nunits alone are not enough to maximize model accuracy. As a result, deep\nlearning accelerators are forced to support both 16-bit and 32-bit\nfloating-point units (FPUs), which is more costly than only using 16-bit FPUs\nfor hardware design. We ask: can we train deep learning models only with 16-bit\nfloating-point units, while still matching the model accuracy attained by\n32-bit training? Towards this end, we study 16-bit-FPU training on the widely\nadopted BFloat16 unit. While these units conventionally use nearest rounding to\ncast output to 16-bit precision, we show that nearest rounding for model weight\nupdates often cancels small updates, which degrades the convergence and model\naccuracy. Motivated by this, we study two simple techniques well-established in\nnumerical analysis, stochastic rounding and Kahan summation, to remedy the\nmodel accuracy degradation in 16-bit-FPU training. We demonstrate that these\ntwo techniques can enable up to 7% absolute validation accuracy gain in\n16-bit-FPU training. This leads to 0.1% lower to 0.2% higher validation\naccuracy compared to 32-bit training across seven deep learning applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 05:38:07 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 06:24:07 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zamirai", "Pedram", ""], ["Zhang", "Jian", ""], ["Aberger", "Christopher R.", ""], ["De Sa", "Christopher", ""]]}, {"id": "2010.06219", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil Seth, Christopher L Buckley", "title": "Investigating the Scalability and Biological Plausibility of the\n  Activation Relaxation Algorithm", "comments": "13/10/20 initial upload", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Activation Relaxation (AR) algorithm provides a simple\nand robust approach for approximating the backpropagation of error algorithm\nusing only local learning rules. Unlike competing schemes, it converges to the\nexact backpropagation gradients, and utilises only a single type of\ncomputational unit and a single backwards relaxation phase. We have previously\nshown that the algorithm can be further simplified and made more biologically\nplausible by (i) introducing a learnable set of backwards weights, which\novercomes the weight-transport problem, and (ii) avoiding the computation of\nnonlinear derivatives at each neuron. However, tthe efficacy of these\nsimplifications has, so far, only been tested on simple multi-layer-perceptron\n(MLP) networks. Here, we show that these simplifications still maintain\nperformance using more complex CNN architectures and challenging datasets,\nwhich have proven difficult for other biologically-plausible schemes to scale\nto. We also investigate whether another biologically implausible assumption of\nthe original AR algorithm -- the frozen feedforward pass -- can be relaxed\nwithout damaging performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 08:02:38 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2010.06247", "submitter": "Sandra Nestler", "authors": "Sandra Nestler, Christian Keup, David Dahmen, Matthieu Gilson, Holger\n  Rauhut and Moritz Helias", "title": "Unfolding recurrence by Green's functions for optimized reservoir\n  computing", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020), 17380--17390", "doi": null, "report-no": null, "categories": "cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical networks are strongly recurrent, and neurons have intrinsic temporal\ndynamics. This sets them apart from deep feed-forward networks. Despite the\ntremendous progress in the application of feed-forward networks and their\ntheoretical understanding, it remains unclear how the interplay of recurrence\nand non-linearities in recurrent cortical networks contributes to their\nfunction. The purpose of this work is to present a solvable recurrent network\nmodel that links to feed forward networks. By perturbative methods we transform\nthe time-continuous, recurrent dynamics into an effective feed-forward\nstructure of linear and non-linear temporal kernels. The resulting analytical\nexpressions allow us to build optimal time-series classifiers from random\nreservoir networks. Firstly, this allows us to optimize not only the readout\nvectors, but also the input projection, demonstrating a strong potential\nperformance gain. Secondly, the analysis exposes how the second order stimulus\nstatistics is a crucial element that interacts with the non-linearity of the\ndynamics and boosts performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 09:17:10 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 07:08:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Nestler", "Sandra", ""], ["Keup", "Christian", ""], ["Dahmen", "David", ""], ["Gilson", "Matthieu", ""], ["Rauhut", "Holger", ""], ["Helias", "Moritz", ""]]}, {"id": "2010.06313", "submitter": "Xi Lin", "authors": "Xi Lin, Zhiyuan Yang, Qingfu Zhang, Sam Kwong", "title": "Controllable Pareto Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-task learning (MTL) system aims at solving multiple related tasks at\nthe same time. With a fixed model capacity, the tasks would be conflicted with\neach other, and the system usually has to make a trade-off among learning all\nof them together. For many real-world applications where the trade-off has to\nbe made online, multiple models with different preferences over tasks have to\nbe trained and stored. This work proposes a novel controllable Pareto\nmulti-task learning framework, to enable the system to make real-time trade-off\ncontrol among different tasks with a single model. To be specific, we formulate\nthe MTL as a preference-conditioned multiobjective optimization problem, with a\nparametric mapping from preferences to the corresponding trade-off solutions. A\nsingle hypernetwork-based multi-task neural network is built to learn all tasks\nwith different trade-off preferences among them, where the hypernetwork\ngenerates the model parameters conditioned on the preference. For inference,\nMTL practitioners can easily control the model performance based on different\ntrade-off preferences in real-time. Experiments on different applications\ndemonstrate that the proposed model is efficient for solving various MTL\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 11:53:55 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 02:14:57 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lin", "Xi", ""], ["Yang", "Zhiyuan", ""], ["Zhang", "Qingfu", ""], ["Kwong", "Sam", ""]]}, {"id": "2010.06324", "submitter": "Dan Andrei Calian", "authors": "Dan A. Calian and Daniel J. Mankowitz and Tom Zahavy and Zhongwen Xu\n  and Junhyuk Oh and Nir Levine and Timothy Mann", "title": "Balancing Constraints and Rewards with Meta-Gradient D4PG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying Reinforcement Learning (RL) agents to solve real-world applications\noften requires satisfying complex system constraints. Often the constraint\nthresholds are incorrectly set due to the complex nature of a system or the\ninability to verify the thresholds offline (e.g, no simulator or reasonable\noffline evaluation procedure exists). This results in solutions where a task\ncannot be solved without violating the constraints. However, in many real-world\ncases, constraint violations are undesirable yet they are not catastrophic,\nmotivating the need for soft-constrained RL approaches. We present a\nsoft-constrained RL approach that utilizes meta-gradients to find a good\ntrade-off between expected return and minimizing constraint violations. We\ndemonstrate the effectiveness of this approach by showing that it consistently\noutperforms the baselines across four different MuJoCo domains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 12:15:23 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 17:27:30 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Calian", "Dan A.", ""], ["Mankowitz", "Daniel J.", ""], ["Zahavy", "Tom", ""], ["Xu", "Zhongwen", ""], ["Oh", "Junhyuk", ""], ["Levine", "Nir", ""], ["Mann", "Timothy", ""]]}, {"id": "2010.06392", "submitter": "Athanasios N. Nikolakopoulos", "authors": "Vassilis Kalantzis, Georgios Kollias, Shashanka Ubaru, Athanasios N.\n  Nikolakopoulos, Lior Horesh, Kenneth L. Clarkson", "title": "Projection techniques to update the truncated SVD of evolving matrices", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.IR cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper considers the problem of updating the rank-k truncated Singular\nValue Decomposition (SVD) of matrices subject to the addition of new rows\nand/or columns over time. Such matrix problems represent an important\ncomputational kernel in applications such as Latent Semantic Indexing and\nRecommender Systems. Nonetheless, the proposed framework is purely algebraic\nand targets general updating problems. The algorithm presented in this paper\nundertakes a projection view-point and focuses on building a pair of subspaces\nwhich approximate the linear span of the sought singular vectors of the updated\nmatrix. We discuss and analyze two different choices to form the projection\nsubspaces. Results on matrices from real applications suggest that the proposed\nalgorithm can lead to higher accuracy, especially for the singular triplets\nassociated with the largest modulus singular values. Several practical details\nand key differences with other approaches are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 13:46:08 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Kalantzis", "Vassilis", ""], ["Kollias", "Georgios", ""], ["Ubaru", "Shashanka", ""], ["Nikolakopoulos", "Athanasios N.", ""], ["Horesh", "Lior", ""], ["Clarkson", "Kenneth L.", ""]]}, {"id": "2010.06408", "submitter": "Andrew DiLernia", "authors": "Andrew DiLernia, Karina Quevedo, Jazmin Camchong, Kelvin Lim, Wei Pan,\n  and Lin Zhang", "title": "Penalized model-based clustering of fMRI data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional magnetic resonance imaging (fMRI) data have become increasingly\navailable and are useful for describing functional connectivity (FC), the\nrelatedness of neuronal activity in regions of the brain. This FC of the brain\nprovides insight into certain neurodegenerative diseases and psychiatric\ndisorders, and thus is of clinical importance. To help inform physicians\nregarding patient diagnoses, unsupervised clustering of subjects based on FC is\ndesired, allowing the data to inform us of groupings of patients based on\nshared features of connectivity. Since heterogeneity in FC is present even\nbetween patients within the same group, it is important to allow subject-level\ndifferences in connectivity, while still pooling information across patients\nwithin each group to describe group-level FC. To this end, we propose a random\ncovariance clustering model (RCCM) to concurrently cluster subjects based on\ntheir FC networks, estimate the unique FC networks of each subject, and to\ninfer shared network features. Although current methods exist for estimating FC\nor clustering subjects using fMRI data, our novel contribution is to cluster or\ngroup subjects based on similar FC of the brain while simultaneously providing\ngroup- and subject-level FC network estimates. The competitive performance of\nRCCM relative to other methods is demonstrated through simulations in various\nsettings, achieving both improved clustering of subjects and estimation of FC\nnetworks. Utility of the proposed method is demonstrated with application to a\nresting-state fMRI data set collected on 43 healthy controls and 61\nparticipants diagnosed with schizophrenia.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:08:02 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["DiLernia", "Andrew", ""], ["Quevedo", "Karina", ""], ["Camchong", "Jazmin", ""], ["Lim", "Kelvin", ""], ["Pan", "Wei", ""], ["Zhang", "Lin", ""]]}, {"id": "2010.06417", "submitter": "Hamed Vaheb", "authors": "Hamed Vaheb", "title": "Asset Price Forecasting using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis serves three primary purposes, first of which is to forecast two\nstocks, i.e. Goldman Sachs (GS) and General Electric (GE). In order to forecast\nstock prices, we used a long short-term memory (LSTM) model in which we\ninputted the prices of two other stocks that lie in rather close correlation\nwith GS. Other models such as ARIMA were used as benchmark. Empirical results\nmanifest the practical challenges when using LSTM for forecasting stocks. One\nof the main upheavals was a recurring lag which we called \"forecasting lag\".\n  The second purpose is to develop a more general and objective perspective on\nthe task of time series forecasting so that it could be applied to assist in an\narbitrary that of forecasting by ANNs. Thus, attempts are made for\ndistinguishing previous works by certain criteria (introduced by a review paper\nwritten by Ahmed Tealab) so as to summarise those including effective\ninformation. The summarised information is then unified and expressed through a\ncommon terminology that can be applied to different steps of a time series\nforecasting task.\n  The last but not least purpose of this thesis is to elaborate on a\nmathematical framework on which ANNs are based. We are going to use the\nframework introduced in the book \"Neural Networks in Mathematical Framework\" by\nAnthony L. Caterini in which the structure of a generic neural network is\nintroduced and the gradient descent algorithm (which incorporates\nbackpropagation) is introduced in terms of their described framework. In the\nend, we use this framework for a specific architecture, which is recurrent\nneural networks on which we concentrated and our implementations are based. The\nbook proves its theorems mostly for classification case. Instead, we proved\ntheorems for regression case, which is the case of our problem.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 07:07:04 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:29:29 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 09:14:21 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Vaheb", "Hamed", ""]]}, {"id": "2010.06420", "submitter": "Sebastien Gadat", "authors": "S\\'ebastien Gadat, Fabien Panloup, Cl\\'ement Pellegrini", "title": "On the cost of Bayesian posterior mean strategy for log-concave models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of computing Bayesian estimators\nusing Langevin Monte-Carlo type approximation. The novelty of this paper is to\nconsider together the statistical and numerical counterparts (in a general\nlog-concave setting). More precisely, we address the following question: given\n$n$ observations in $\\mathbb{R}^q$ distributed under an unknown probability\n$\\mathbb{P}_{\\theta^\\star}$ with $\\theta^\\star \\in \\mathbb{R}^d$ , what is the\noptimal numerical strategy and its cost for the approximation of $\\theta^\\star$\nwith the Bayesian posterior mean? To answer this question, we establish some\nquantitative statistical bounds related to the underlying Poincar\\'e constant\nof the model and establish new results about the numerical approximation of\nGibbs measures by Cesaro averages of Euler schemes of (over-damped) Langevin\ndiffusions. These last results include in particular some quantitative controls\nin the weakly convex case based on new bounds on the solution of the related\nPoisson equation of the diffusion.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 04:51:10 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Gadat", "S\u00e9bastien", ""], ["Panloup", "Fabien", ""], ["Pellegrini", "Cl\u00e9ment", ""]]}, {"id": "2010.06430", "submitter": "Alexandros Rekkas", "authors": "Alexandros Rekkas, David van Klaveren, Patrick B. Ryan, Ewout W.\n  Steyerberg, David M. Kent, Peter R. Rijnbeek", "title": "A standardized framework for risk-based assessment of treatment effect\n  heterogeneity in observational healthcare databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aim: One of the aims of the Observation Health Data Sciences and Informatics\n(OHDSI) initiative is population-level treatment effect estimation in large\nobservational databases. Since treatment effects are well-known to vary across\ngroups of patients with different baseline risk, we aimed to extend the OHDSI\nmethods library with a framework for risk-based assessment of treatment effect\nheterogeneity.\n  Materials and Methods: The proposed framework consists of five steps: 1)\ndefinition of the problem, i.e. the population, the treatment, the comparator\nand the outcome(s) of interest; 2) identification of relevant databases; 3)\ndevelopment of a prediction model for the outcome(s) of interest; 4) estimation\nof propensity scores within strata of predicted risk and estimation of relative\nand absolute treatment effect within strata of predicted risk; 5) evaluation\nand presentation of results.\n  Results: We demonstrate our framework by evaluating heterogeneity of the\neffect of angiotensin-converting enzyme (ACE) inhibitors versus beta blockers\non a set of 9 outcomes of interest across three observational databases. With\nincreasing risk of acute myocardial infarction we observed increasing absolute\nbenefits, i.e. from -0.03% to 0.54% in the lowest to highest risk groups.\nCough-related absolute harms decreased from 4.1% to 2.6%.\n  Conclusions: The proposed framework may be useful for the evaluation of\nheterogeneity of treatment effect on observational data that are mapped to the\nOMOP Common Data Model. The proof of concept study demonstrates its feasibility\nin large observational data. Further insights may arise by application to\nsafety and effectiveness questions across the global data network.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:48:31 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Rekkas", "Alexandros", ""], ["van Klaveren", "David", ""], ["Ryan", "Patrick B.", ""], ["Steyerberg", "Ewout W.", ""], ["Kent", "David M.", ""], ["Rijnbeek", "Peter R.", ""]]}, {"id": "2010.06439", "submitter": "Johann Brehmer Mr", "authors": "Johann Brehmer and Kyle Cranmer", "title": "Simulation-based inference methods for particle physics", "comments": "To appear in \"Artificial Intelligence for Particle Physics\", World\n  Scientific Publishing Co", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our predictions for particle physics processes are realized in a chain of\ncomplex simulators. They allow us to generate high-fidelity simulated data, but\nthey are not well-suited for inference on the theory parameters with observed\ndata. We explain why the likelihood function of high-dimensional LHC data\ncannot be explicitly evaluated, why this matters for data analysis, and reframe\nwhat the field has traditionally done to circumvent this problem. We then\nreview new simulation-based inference methods that let us directly analyze\nhigh-dimensional data by combining machine learning techniques and information\nfrom the simulator. Initial studies indicate that these techniques have the\npotential to substantially improve the precision of LHC measurements. Finally,\nwe discuss probabilistic programming, an emerging paradigm that lets us extend\ninference to the latent process of the simulator.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:55:28 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 14:31:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Brehmer", "Johann", ""], ["Cranmer", "Kyle", ""]]}, {"id": "2010.06465", "submitter": "Ritabrata Dutta", "authors": "Ritabrata Dutta, Karim Zouaoui-Boudjeltia, Christos Kotsalos,\n  Alexandre Rousseau, Daniel Ribeiro de Sousa, Jean-Marc Desmet, Alain Van\n  Meerhaeghe, Antonietta Mira, Bastien Chopard", "title": "Interpretable pathological test for Cardio-vascular disease: Approximate\n  Bayesian computation with distance learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardio/cerebrovascular diseases (CVD) have become one of the major health\nissue in our societies. But recent studies show that the present clinical tests\nto detect CVD are ineffectual as they do not consider different stages of\nplatelet activation or the molecular dynamics involved in platelet interactions\nand are incapable to consider inter-individual variability. Here we propose a\nstochastic platelet deposition model and an inferential scheme for uncertainty\nquantification of these parameters using Approximate Bayesian Computation and\ndistance learning. Finally we show that our methodology can learn biologically\nmeaningful parameters, which are the specific dysfunctioning parameters in each\ntype of patients, from data collected from healthy volunteers and patients.\nThis work opens up an unprecedented opportunity of personalized pathological\ntest for CVD detection and medical treatment. Also our proposed methodology can\nbe used to other fields of science where we would need machine learning tools\nto be interpretable.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:20:21 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Dutta", "Ritabrata", ""], ["Zouaoui-Boudjeltia", "Karim", ""], ["Kotsalos", "Christos", ""], ["Rousseau", "Alexandre", ""], ["de Sousa", "Daniel Ribeiro", ""], ["Desmet", "Jean-Marc", ""], ["Van Meerhaeghe", "Alain", ""], ["Mira", "Antonietta", ""], ["Chopard", "Bastien", ""]]}, {"id": "2010.06468", "submitter": "Ezequiel Alvarez", "authors": "Ezequiel Alvarez, Daniela Obando, Sebastian Crespo, Enio Garcia,\n  Nicolas Kreplak and Franco Marsico", "title": "Estimating COVID-19 cases and outbreaks on-stream through phone-calls", "comments": "16 pages, 8 figs. Includes details on the Villa Azul outbreak in\n  Argentina", "journal-ref": null, "doi": null, "report-no": "ICAS 054/20", "categories": "q-bio.PE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main problems in controlling COVID-19 epidemic spread is the delay\nin confirming cases. Having information on changes in the epidemic evolution or\noutbreaks rise before lab-confirmation is crucial in decision making for Public\nHealth policies. We present an algorithm to estimate on-stream the number of\nCOVID-19 cases using the data from telephone calls to a COVID-line. By modeling\nthe calls as background (proportional to population) plus signal (proportional\nto infected), we fit the calls in Province of Buenos Aires (Argentina) with\ncoefficient of determination $R^2 > 0.85$. This result allows us to estimate\nthe number of cases given the number of calls from a specific district, days\nbefore the lab results are available. We validate the algorithm with real data.\nWe show how to use the algorithm to track on-stream the epidemic, and present\nthe Early Outbreak Alarm to detect outbreaks in advance to lab results. One key\npoint in the developed algorithm is a detailed track of the uncertainties in\nthe estimations, since the alarm uses the significance of the observables as a\nmain indicator to detect an anomaly. We present the details of the explicit\nexample in Villa Azul (Quilmes) where this tool resulted crucial to control an\noutbreak on time. The presented tools have been designed in urgency with the\navailable data at the time of the development, and therefore have their\nlimitations which we describe and discuss. We consider possible improvements on\nthe tools, many of which are currently under development.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 15:44:05 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Alvarez", "Ezequiel", ""], ["Obando", "Daniela", ""], ["Crespo", "Sebastian", ""], ["Garcia", "Enio", ""], ["Kreplak", "Nicolas", ""], ["Marsico", "Franco", ""]]}, {"id": "2010.06476", "submitter": "J. Emmanuel Johnson", "authors": "J. Emmanuel Johnson, Valero Laparra, Maria Piles, Gustau Camps-Valls", "title": "Gaussianizing the Earth: Multidimensional Information Measures for Earth\n  Data Analysis", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory is an excellent framework for analyzing Earth system data\nbecause it allows us to characterize uncertainty and redundancy, and is\nuniversally interpretable. However, accurately estimating information content\nis challenging because spatio-temporal data is high-dimensional, heterogeneous\nand has non-linear characteristics. In this paper, we apply multivariate\nGaussianization for probability density estimation which is robust to\ndimensionality, comes with statistical guarantees, and is easy to apply. In\naddition, this methodology allows us to estimate information-theoretic measures\nto characterize multivariate densities: information, entropy, total\ncorrelation, and mutual information. We demonstrate how information theory\nmeasures can be applied in various Earth system data analysis problems. First\nwe show how the method can be used to jointly Gaussianize radar backscattering\nintensities, synthesize hyperspectral data, and quantify of information content\nin aerial optical images. We also quantify the information content of several\nvariables describing the soil-vegetation status in agro-ecosystems, and\ninvestigate the temporal scales that maximize their shared information under\nextreme events such as droughts. Finally, we measure the relative information\ncontent of space and time dimensions in remote sensing products and model\nsimulations involving long records of key variables such as precipitation,\nsensible heat and evaporation. Results confirm the validity of the method, for\nwhich we anticipate a wide use and adoption. Code and demos of the implemented\nalgorithms and information-theory measures are provided.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:30:34 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:10:44 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Johnson", "J. Emmanuel", ""], ["Laparra", "Valero", ""], ["Piles", "Maria", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "2010.06529", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Amir-Hossein Karimi, Umang Bhatt, Isabel\n  Valera, Adrian Weller, Bernhard Sch\\\"olkopf", "title": "On the Fairness of Causal Algorithmic Recourse", "comments": "v3 with additional experiments, new case study, new introduction, and\n  revised structure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness is typically studied from the perspective of\npredictions. Instead, here we investigate fairness from the perspective of\nrecourse actions suggested to individuals to remedy an unfavourable\nclassification. We propose two new fairness criteria at the group and\nindividual level, which -- unlike prior work on equalising the average\ngroup-wise distance from the decision boundary -- explicitly account for causal\nrelationships between features, thereby capturing downstream effects of\nrecourse actions performed in the physical world. We explore how our criteria\nrelate to others, such as counterfactual fairness, and show that fairness of\nrecourse is complementary to fairness of prediction. We study theoretically and\nempirically how to enforce fair causal recourse by altering the classifier and\nperform a case study on the Adult dataset. Finally, we discuss whether fairness\nviolations in the data generating process revealed by our criteria may be\nbetter addressed by societal interventions as opposed to constraints on the\nclassifier.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 16:35:06 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 09:48:33 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 16:03:26 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 12:26:07 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Karimi", "Amir-Hossein", ""], ["Bhatt", "Umang", ""], ["Valera", "Isabel", ""], ["Weller", "Adrian", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2010.06538", "submitter": "Carlos M. Ortiz", "authors": "Javier Rubio-Herrero, Carlos Ortiz Marrero, Wai-Tong Louis Fan", "title": "Modeling Atmospheric Data and Identifying Dynamics: Temporal Data-Driven\n  Modeling of Air Pollutants", "comments": null, "journal-ref": null, "doi": null, "report-no": "PNNL-SA-157007", "categories": "stat.AP cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atmospheric modeling has recently experienced a surge with the advent of deep\nlearning. Most of these models, however, predict concentrations of pollutants\nfollowing a data-driven approach in which the physical laws that govern their\nbehaviors and relationships remain hidden. With the aid of real-world air\nquality data collected hourly in different stations throughout Madrid, we\npresent an empirical approach using data-driven techniques with the following\ngoals: (1) Find parsimonious systems of ordinary differential equations via\nsparse identification of nonlinear dynamics (SINDy) that model the\nconcentration of pollutants and their changes over time; (2) assess the\nperformance and limitations of our models using stability analysis; (3)\nreconstruct the time series of chemical pollutants not measured in certain\nstations using delay coordinate embedding results. Our results show that\nAkaike's Information Criterion can work well in conjunction with best subset\nregression as to find an equilibrium between sparsity and goodness of fit. We\nalso find that, due to the complexity of the chemical system under study,\nidentifying the dynamics of this system over longer periods of time require\nhigher levels of data filtering and smoothing. Stability analysis for the\nreconstructed ordinary differential equations (ODEs) reveals that more than\nhalf of the physically relevant critical points are saddle points, suggesting\nthat the system is unstable even under the idealized assumption that all\nenvironmental conditions are constant over time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 16:46:07 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 20:29:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Rubio-Herrero", "Javier", ""], ["Marrero", "Carlos Ortiz", ""], ["Fan", "Wai-Tong Louis", ""]]}, {"id": "2010.06545", "submitter": "Hans Wang", "authors": "Hans Shih-Han Wang, Cory Cornelius, Brandon Edwards, Jason Martin", "title": "Toward Few-step Adversarial Training from a Frequency Perspective", "comments": "9 pages, 9 figures, SPAI'20, ACM ASIACCS 2020", "journal-ref": "Proceedings of the 1st ACM Workshop on Security and Privacy on\n  Artificial Intelligence (2020)", "doi": "10.1145/3385003.3410922", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate adversarial-sample generation methods from a frequency domain\nperspective and extend standard $l_{\\infty}$ Projected Gradient Descent (PGD)\nto the frequency domain. The resulting method, which we call Spectral Projected\nGradient Descent (SPGD), has better success rate compared to PGD during early\nsteps of the method. Adversarially training models using SPGD achieves greater\nadversarial accuracy compared to PGD when holding the number of attack steps\nconstant. The use of SPGD can, therefore, reduce the overhead of adversarial\ntraining when utilizing adversarial generation with a smaller number of steps.\nHowever, we also prove that SPGD is equivalent to a variant of the PGD\nordinarily used for the $l_{\\infty}$ threat model. This PGD variant omits the\nsign function which is ordinarily applied to the gradient. SPGD can, therefore,\nbe performed without explicitly transforming into the frequency domain.\nFinally, we visualize the perturbations SPGD generates and find they use both\nhigh and low-frequency components, which suggests that removing either\nhigh-frequency components or low-frequency components is not an effective\ndefense.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 16:53:47 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Wang", "Hans Shih-Han", ""], ["Cornelius", "Cory", ""], ["Edwards", "Brandon", ""], ["Martin", "Jason", ""]]}, {"id": "2010.06563", "submitter": "Alexander Wein", "authors": "Alexander S. Wein", "title": "Optimal Low-Degree Hardness of Maximum Independent Set", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic task of finding a large independent set in a sparse\nErd\\H{o}s-R\\'{e}nyi random graph with $n$ vertices and average degree $d$. The\nmaximum independent set is known to have size $(2 \\log d / d)n$ in the double\nlimit $n \\to \\infty$ followed by $d \\to \\infty$, but the best known\npolynomial-time algorithms can only find an independent set of half-optimal\nsize $(\\log d / d)n$. We show that the class of low-degree polynomial\nalgorithms can find independent sets of half-optimal size but no larger,\nimproving upon a result of Gamarnik, Jagannath, and the author. This\ngeneralizes earlier work by Rahman and Vir\\'ag, which proved the analogous\nresult for the weaker class of local algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 17:26:09 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 16:44:49 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wein", "Alexander S.", ""]]}, {"id": "2010.06610", "submitter": "Marton Havasi", "authors": "Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah Zhe Liu,\n  Jasper Snoek, Balaji Lakshminarayanan, Andrew M. Dai, Dustin Tran", "title": "Training independent subnetworks for robust prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to efficiently ensemble neural networks have shown that\nstrong robustness and uncertainty performance can be achieved with a negligible\ngain in parameters over the original network. However, these methods still\nrequire multiple forward passes for prediction, leading to a significant\ncomputational cost. In this work, we show a surprising result: the benefits of\nusing multiple predictions can be achieved `for free' under a single model's\nforward pass. In particular, we show that, using a multi-input multi-output\n(MIMO) configuration, one can utilize a single model's capacity to train\nmultiple subnetworks that independently learn the task at hand. By ensembling\nthe predictions made by the subnetworks, we improve model robustness without\nincreasing compute. We observe a significant improvement in negative\nlog-likelihood, accuracy, and calibration error on CIFAR10, CIFAR100, ImageNet,\nand their out-of-distribution variants compared to previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 18:05:13 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Havasi", "Marton", ""], ["Jenatton", "Rodolphe", ""], ["Fort", "Stanislav", ""], ["Liu", "Jeremiah Zhe", ""], ["Snoek", "Jasper", ""], ["Lakshminarayanan", "Balaji", ""], ["Dai", "Andrew M.", ""], ["Tran", "Dustin", ""]]}, {"id": "2010.06651", "submitter": "Jeet Mohapatra", "authors": "Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu,\n  Luca Daniel", "title": "Higher-Order Certification for Randomized Smoothing", "comments": "Accepted to NeurIPS2020(spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing is a recently proposed defense against adversarial\nattacks that has achieved SOTA provable robustness against $\\ell_2$\nperturbations. A number of publications have extended the guarantees to other\nmetrics, such as $\\ell_1$ or $\\ell_\\infty$, by using different smoothing\nmeasures. Although the current framework has been shown to yield near-optimal\n$\\ell_p$ radii, the total safety region certified by the current framework can\nbe arbitrarily small compared to the optimal. In this work, we propose a\nframework to improve the certified safety region for these smoothed classifiers\nwithout changing the underlying smoothing scheme. The theoretical contributions\nare as follows: 1) We generalize the certification for randomized smoothing by\nreformulating certified radius calculation as a nested optimization problem\nover a class of functions. 2) We provide a method to calculate the certified\nsafety region using $0^{th}$-order and $1^{st}$-order information for\nGaussian-smoothed classifiers. We also provide a framework that generalizes the\ncalculation for certification using higher-order information. 3) We design\nefficient, high-confidence estimators for the relevant statistics of the\nfirst-order information. Combining the theoretical contribution 2) and 3)\nallows us to certify safety region that are significantly larger than the ones\nprovided by the current methods. On CIFAR10 and Imagenet datasets, the new\nregions certified by our approach achieve significant improvements on general\n$\\ell_1$ certified radii and on the $\\ell_2$ certified radii for color-space\nattacks ($\\ell_2$ restricted to 1 channel) while also achieving smaller\nimprovements on the general $\\ell_2$ certified radii. Our framework can also\nprovide a way to circumvent the current impossibility results on achieving\nhigher magnitude of certified radii without requiring the use of data-dependent\nsmoothing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:35:48 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Mohapatra", "Jeet", ""], ["Ko", "Ching-Yun", ""], ["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Daniel", "Luca", ""]]}, {"id": "2010.06652", "submitter": "Aaron Berk", "authors": "Aaron Berk", "title": "Deep generative demixing: Recovering Lipschitz signals from noisy\n  subgaussian mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative neural networks (GNNs) have gained renown for efficaciously\ncapturing intrinsic low-dimensional structure in natural images. Here, we\ninvestigate the subgaussian demixing problem for two Lipschitz signals, with\nGNN demixing as a special case. In demixing, one seeks identification of two\nsignals given their sum and prior structural information. Here, we assume each\nsignal lies in the range of a Lipschitz function, which includes many popular\nGNNs as a special case. We prove a sample complexity bound for nearly optimal\nrecovery error that extends a recent result of Bora, et al. (2017) from the\ncompressed sensing setting with gaussian matrices to demixing with subgaussian\nones. Under a linear signal model in which the signals lie in convex sets,\nMcCoy & Tropp (2014) have characterized the sample complexity for\nidentification under subgaussian mixing. In the present setting, the signal\nstructure need not be convex. For example, our result applies to a domain that\nis a non-convex union of convex cones. We support the efficacy of this demixing\nmodel with numerical simulations using trained GNNs, suggesting an algorithm\nthat would be an interesting object of further theoretical study.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:36:54 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Berk", "Aaron", ""]]}, {"id": "2010.06661", "submitter": "Denys Pommeret", "authors": "Robin Fuchs, Denys Pommeret, Cinzia Viroli", "title": "Mixed data Deep Gaussian Mixture Model: A clustering model for mixed\n  datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering mixed data presents numerous challenges inherent to the very\nheterogeneous nature of the variables. A clustering algorithm should be able,\ndespite of this heterogeneity, to extract discriminant pieces of information\nfrom the variables in order to design groups. In this work we introduce a\nmultilayer architecture model-based clustering method called Mixed Deep\nGaussian Mixture Model (MDGMM) that can be viewed as an automatic way to merge\nthe clustering performed separately on continuous and non-continuous data. This\narchitecture is flexible and can be adapted to mixed as well as to continuous\nor non-continuous data. In this sense we generalize Generalized Linear Latent\nVariable Models and Deep Gaussian Mixture Models. We also design a new\ninitialisation strategy and a data driven method that selects the best\nspecification of the model and the optimal number of clusters for a given\ndataset \"on the fly\". Besides, our model provides continuous low-dimensional\nrepresentations of the data which can be a useful tool to visualize mixed\ndatasets. Finally, we validate the performance of our approach comparing its\nresults with state-of-the-art mixed data clustering models over several\ncommonly used datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:52:46 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 18:20:58 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Fuchs", "Robin", ""], ["Pommeret", "Denys", ""], ["Viroli", "Cinzia", ""]]}, {"id": "2010.06667", "submitter": "Vinith Suriyakumar", "authors": "Vinith M. Suriyakumar, Nicolas Papernot, Anna Goldenberg, Marzyeh\n  Ghassemi", "title": "Chasing Your Long Tails: Differentially Private Prediction in Health\n  Care Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models in health care are often deployed in settings where\nit is important to protect patient privacy. In such settings, methods for\ndifferentially private (DP) learning provide a general-purpose approach to\nlearn models with privacy guarantees. Modern methods for DP learning ensure\nprivacy through mechanisms that censor information judged as too unique. The\nresulting privacy-preserving models, therefore, neglect information from the\ntails of a data distribution, resulting in a loss of accuracy that can\ndisproportionately affect small groups. In this paper, we study the effects of\nDP learning in health care. We use state-of-the-art methods for DP learning to\ntrain privacy-preserving models in clinical prediction tasks, including x-ray\nclassification of images and mortality prediction in time series data. We use\nthese models to perform a comprehensive empirical investigation of the\ntradeoffs between privacy, utility, robustness to dataset shift, and fairness.\nOur results highlight lesser-known limitations of methods for DP learning in\nhealth care, models that exhibit steep tradeoffs between privacy and utility,\nand models whose predictions are disproportionately influenced by large\ndemographic groups in the training data. We discuss the costs and benefits of\ndifferentially private learning in health care.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:56:37 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Suriyakumar", "Vinith M.", ""], ["Papernot", "Nicolas", ""], ["Goldenberg", "Anna", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2010.06698", "submitter": "Joshua Hunte", "authors": "Joshua Hunte, Martin Neil, Norman Fenton", "title": "Product risk assessment: a Bayesian network approach", "comments": "32 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Product risk assessment is the overall process of determining whether a\nproduct, which could be anything from a type of washing machine to a type of\nteddy bear, is judged safe for consumers to use. There are several methods used\nfor product risk assessment, including RAPEX, which is the primary method used\nby regulators in the UK and EU. However, despite its widespread use, we\nidentify several limitations of RAPEX including a limited approach to handling\nuncertainty and the inability to incorporate causal explanations for using and\ninterpreting test data. In contrast, Bayesian Networks (BNs) are a rigorous,\nnormative method for modelling uncertainty and causality which are already used\nfor risk assessment in domains such as medicine and finance, as well as\ncritical systems generally. This article proposes a BN model that provides an\nimproved systematic method for product risk assessment that resolves the\nidentified limitations with RAPEX. We use our proposed method to demonstrate\nrisk assessments for a teddy bear and a new uncertified kettle for which there\nis no testing data and the number of product instances is unknown. We show\nthat, while we can replicate the results of the RAPEX method, the BN approach\nis more powerful and flexible.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 16:40:03 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hunte", "Joshua", ""], ["Neil", "Martin", ""], ["Fenton", "Norman", ""]]}, {"id": "2010.06721", "submitter": "Steven Reich", "authors": "Steven Reich, David Mueller, Nicholas Andrews", "title": "Ensemble Distillation for Structured Prediction: Calibrated, Accurate,\n  Fast-Choose Three", "comments": "EMNLP 2020. v2: Changed formatting of title in metadata; no other\n  changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks do not always produce well-calibrated predictions,\neven when trained with a proper scoring function such as cross-entropy. In\nclassification settings, simple methods such as isotonic regression or\ntemperature scaling may be used in conjunction with a held-out dataset to\ncalibrate model outputs. However, extending these methods to structured\nprediction is not always straightforward or effective; furthermore, a held-out\ncalibration set may not always be available. In this paper, we study ensemble\ndistillation as a general framework for producing well-calibrated structured\nprediction models while avoiding the prohibitive inference-time cost of\nensembles. We validate this framework on two tasks: named-entity recognition\nand machine translation. We find that, across both tasks, ensemble distillation\nproduces models which retain much of, and occasionally improve upon, the\nperformance and calibration benefits of ensembles, while only requiring a\nsingle model during test-time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 22:30:06 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 17:32:03 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Reich", "Steven", ""], ["Mueller", "David", ""], ["Andrews", "Nicholas", ""]]}, {"id": "2010.06735", "submitter": "Volodimir Begy", "authors": "Volodimir Begy and Erich Schikuta", "title": "Error-guided likelihood-free MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel posterior inference method for models with\nintractable evidence and likelihood functions. Error-guided likelihood-free\nMCMC, or EG-LF-MCMC in short, has been developed for scientific applications,\nwhere a researcher is interested in obtaining approximate posterior densities\nover model parameters, while avoiding the need for expensive training of\ncomponent estimators on full observational data or the tedious design of\nexpressive summary statistics, as in related approaches. Our technique is based\non two phases. In the first phase, we draw samples from the prior, simulate\nrespective observations and record their errors $\\epsilon$ in relation to the\ntrue observation. We train a classifier to distinguish between corresponding\nand non-corresponding $(\\epsilon, \\boldsymbol{\\theta})$-tuples. In the second\nstage the said classifier is conditioned on the smallest recorded $\\epsilon$\nvalue from the training set and employed for the calculation of transition\nprobabilities in a Markov Chain Monte Carlo sampling procedure. By conditioning\nthe MCMC on specific $\\epsilon$ values, our method may also be used in an\namortized fashion to infer posterior densities for observations, which are\nlocated a given distance away from the observed data. We evaluate the proposed\nmethod on benchmark problems with semantically and structurally different data\nand compare its performance against the state of the art approximate Bayesian\ncomputation (ABC).\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 23:25:31 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 21:45:38 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 19:47:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Begy", "Volodimir", ""], ["Schikuta", "Erich", ""]]}, {"id": "2010.06768", "submitter": "Jeffrey P. Spence", "authors": "Jeffrey P. Spence", "title": "Flexible mean field variational inference using mixtures of\n  non-overlapping exponential families", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse models are desirable for many applications across diverse domains as\nthey can perform automatic variable selection, aid interpretability, and\nprovide regularization. When fitting sparse models in a Bayesian framework,\nhowever, analytically obtaining a posterior distribution over the parameters of\ninterest is intractable for all but the simplest cases. As a result\npractitioners must rely on either sampling algorithms such as Markov chain\nMonte Carlo or variational methods to obtain an approximate posterior. Mean\nfield variational inference is a particularly simple and popular framework that\nis often amenable to analytically deriving closed-form parameter updates. When\nall distributions in the model are members of exponential families and are\nconditionally conjugate, optimization schemes can often be derived by hand.\nYet, I show that using standard mean field variational inference can fail to\nproduce sensible results for models with sparsity-inducing priors, such as the\nspike-and-slab. Fortunately, such pathological behavior can be remedied as I\nshow that mixtures of exponential family distributions with non-overlapping\nsupport form an exponential family. In particular, any mixture of a diffuse\nexponential family and a point mass at zero to model sparsity forms an\nexponential family. Furthermore, specific choices of these distributions\nmaintain conditional conjugacy. I use two applications to motivate these\nresults: one from statistical genetics that has connections to generalized\nleast squares with a spike-and-slab prior on the regression coefficients; and\nsparse probabilistic principal component analysis. The theoretical results\npresented here are broadly applicable beyond these two examples.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 01:46:56 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Spence", "Jeffrey P.", ""]]}, {"id": "2010.06772", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, Brian Jalaian", "title": "Scaling Hamiltonian Monte Carlo Inference for Bayesian Neural Networks\n  with Symmetric Splitting", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) approach\nthat exhibits favourable exploration properties in high-dimensional models such\nas neural networks. Unfortunately, HMC has limited use in large-data regimes\nand little work has explored suitable approaches that aim to preserve the\nentire Hamiltonian. In our work, we introduce a new symmetric integration\nscheme for split HMC that does not rely on stochastic gradients. We show that\nour new formulation is more efficient than previous approaches and is easy to\nimplement with a single GPU. As a result, we are able to perform full HMC over\ncommon deep learning architectures using entire data sets. In addition, when we\ncompare with stochastic gradient MCMC, we show that our method achieves better\nperformance in both accuracy and uncertainty quantification. Our approach\ndemonstrates HMC as a feasible option when considering inference schemes for\nlarge-scale machine learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 01:58:34 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cobb", "Adam D.", ""], ["Jalaian", "Brian", ""]]}, {"id": "2010.06802", "submitter": "Xiaowei Zhang", "authors": "Liang Ding and Xiaowei Zhang", "title": "Sample and Computationally Efficient Simulation Metamodeling in High\n  Dimensions", "comments": "main body: 42 pages; supplemental material: 28 pages; 12 figures in\n  total", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Stochastic kriging has been widely employed for simulation metamodeling to\npredict the response surface of a complex simulation model. However, its use is\nlimited to cases where the design space is low-dimensional, because the number\nof design points required for stochastic kriging to produce accurate\nprediction, in general, grows exponentially in the dimension of the design\nspace. The large sample size results in both a prohibitive sample cost for\nrunning the simulation model and a severe computational challenge due to the\nneed of inverting large covariance matrices. Based on tensor Markov kernels and\nsparse grid experimental designs, we develop a novel methodology that\ndramatically alleviates the curse of dimensionality. We show that the sample\ncomplexity of the proposed methodology grows very mildly in the dimension, even\nunder model misspecification. We also develop fast algorithms that compute\nstochastic kriging in its exact form without any approximation schemes. We\ndemonstrate via extensive numerical experiments that our methodology can handle\nproblems with a design space of more than 10,000 dimensions, improving both\nprediction accuracy and computational efficiency by orders of magnitude\nrelative to typical alternative methods in practice.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 04:10:07 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 14:29:35 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ding", "Liang", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "2010.06845", "submitter": "Span Spanbauer", "authors": "Span Spanbauer, Ian Hunter", "title": "Extended Koopman Models", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two novel generalizations of the Koopman operator method of\nnonlinear dynamic modeling. Each of these generalizations leads to greatly\nimproved predictive performance without sacrificing a unique trait of Koopman\nmethods: the potential for fast, globally optimal control of nonlinear,\nnonconvex systems. The first generalization, Convex Koopman Models, uses convex\nrather than linear dynamics in the lifted space. The second, Extended Koopman\nModels, additionally introduces an invertible transformation of the control\nsignal which contributes to the lifted convex dynamics. We describe a deep\nlearning architecture for parameterizing these classes of models, and show\nexperimentally that each significantly outperforms traditional Koopman models\nin trajectory prediction for two nonlinear, nonconvex dynamic systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 07:10:37 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Spanbauer", "Span", ""], ["Hunter", "Ian", ""]]}, {"id": "2010.06846", "submitter": "Wei Zuo", "authors": "Chunkai Zhang, Wei Zuo, Xuan Wang", "title": "Reconstruct Anomaly to Normal: Adversarial Learned and Latent\n  Vector-constrained Autoencoder for Time-series Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in time series has been widely researched and has important\npractical applications. In recent years, anomaly detection algorithms are\nmostly based on deep-learning generative models and use the reconstruction\nerror to detect anomalies. They try to capture the distribution of normal data\nby reconstructing normal data in the training phase, then calculate the\nreconstruction error of test data to do anomaly detection. However, most of\nthem only use the normal data in the training phase and can not ensure the\nreconstruction process of anomaly data. So, anomaly data can also be well\nreconstructed sometimes and gets low reconstruction error, which leads to the\nomission of anomalies. What's more, the neighbor information of data points in\ntime series data has not been fully utilized in these algorithms. In this\npaper, we propose RAN based on the idea of Reconstruct Anomalies to Normal and\napply it for unsupervised time series anomaly detection. To minimize the\nreconstruction error of normal data and maximize this of anomaly data, we do\nnot just ensure normal data to reconstruct well, but also try to make the\nreconstruction of anomaly data consistent with the distribution of normal data,\nthen anomalies will get higher reconstruction errors. We implement this idea by\nintroducing the \"imitated anomaly data\" and combining a specially designed\nlatent vector-constrained Autoencoder with the discriminator to construct an\nadversary network. Extensive experiments on time-series datasets from different\nscenes such as ECG diagnosis also show that RAN can detect meaningful\nanomalies, and it outperforms other algorithms in terms of AUC-ROC.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 07:10:55 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhang", "Chunkai", ""], ["Zuo", "Wei", ""], ["Wang", "Xuan", ""]]}, {"id": "2010.06866", "submitter": "Basil Mustafa", "authors": "Basil Mustafa and Carlos Riquelme and Joan Puigcerver and Andr\\'e\n  Susano Pinto and Daniel Keysers and Neil Houlsby", "title": "Deep Ensembles for Low-Data Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the low-data regime, it is difficult to train good supervised models from\nscratch. Instead practitioners turn to pre-trained models, leveraging transfer\nlearning. Ensembling is an empirically and theoretically appealing way to\nconstruct powerful predictive models, but the predominant approach of training\nmultiple deep networks with different random initialisations collides with the\nneed for transfer via pre-trained weights. In this work, we study different\nways of creating ensembles from pre-trained models. We show that the nature of\npre-training itself is a performant source of diversity, and propose a\npractical algorithm that efficiently identifies a subset of pre-trained models\nfor any downstream dataset. The approach is simple: Use nearest-neighbour\naccuracy to rank pre-trained models, fine-tune the best ones with a small\nhyperparameter sweep, and greedily construct an ensemble to minimise validation\ncross-entropy. When evaluated together with strong baselines on 19 different\ndownstream tasks (the Visual Task Adaptation Benchmark), this achieves\nstate-of-the-art performance at a much lower inference budget, even when\nselecting from over 2,000 pre-trained models. We also assess our ensembles on\nImageNet variants and show improved robustness to distribution shift.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 07:59:00 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 10:59:20 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Mustafa", "Basil", ""], ["Riquelme", "Carlos", ""], ["Puigcerver", "Joan", ""], ["Pinto", "Andr\u00e9 Susano", ""], ["Keysers", "Daniel", ""], ["Houlsby", "Neil", ""]]}, {"id": "2010.06889", "submitter": "David R\\\"ugamer", "authors": "David R\\\"ugamer, Florian Pfisterer and Bernd Bischl", "title": "Neural Mixture Distributional Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present neural mixture distributional regression (NMDR), a holistic\nframework to estimate complex finite mixtures of distributional regressions\ndefined by flexible additive predictors. Our framework is able to handle a\nlarge number of mixtures of potentially different distributions in\nhigh-dimensional settings, allows for efficient and scalable optimization and\ncan be applied to recent concepts that combine structured regression models\nwith deep neural networks. While many existing approaches for mixture models\naddress challenges in optimization of such and provide results for convergence\nunder specific model assumptions, our approach is assumption-free and instead\nmakes use of optimizers well-established in deep learning. Through extensive\nnumerical experiments and a high-dimensional deep learning application we\nprovide evidence that the proposed approach is competitive to existing\napproaches and works well in more complex scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 09:00:16 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["R\u00fcgamer", "David", ""], ["Pfisterer", "Florian", ""], ["Bischl", "Bernd", ""]]}, {"id": "2010.06890", "submitter": "Rahaf Aljundi", "authors": "Rahaf Aljundi, Nikolay Chumerin and Daniel Olmeda Reino", "title": "Identifying Wrongly Predicted Samples: A Method for Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art machine learning models require access to significant amount\nof annotated data in order to achieve the desired level of performance. While\nunlabelled data can be largely available and even abundant, annotation process\ncan be quite expensive and limiting. Under the assumption that some samples are\nmore important for a given task than others, active learning targets the\nproblem of identifying the most informative samples that one should acquire\nannotations for. Instead of the conventional reliance on model uncertainty as a\nproxy to leverage new unknown labels, in this work we propose a simple sample\nselection criterion that moves beyond uncertainty. By first accepting the model\nprediction and then judging its effect on the generalization error, we can\nbetter identify wrongly predicted samples. We further present an approximation\nto our criterion that is very efficient and provides a similarity based\ninterpretation. In addition to evaluating our method on the standard benchmarks\nof active learning, we consider the challenging yet realistic scenario of\nimbalanced data where categories are not equally represented. We show\nstate-of-the-art results and better rates at identifying wrongly predicted\nsamples. Our method is simple, model agnostic and relies on the current model\nstatus without the need for re-training from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 09:00:42 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Chumerin", "Nikolay", ""], ["Reino", "Daniel Olmeda", ""]]}, {"id": "2010.06948", "submitter": "Karolis Martinkus", "authors": "Karolis Martinkus, Aurelien Lucchi, Nathana\\\"el Perraudin", "title": "Scalable Graph Networks for Particle Simulations", "comments": "19 pages, 20 figures, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning system dynamics directly from observations is a promising direction\nin machine learning due to its potential to significantly enhance our ability\nto understand physical systems. However, the dynamics of many real-world\nsystems are challenging to learn due to the presence of nonlinear potentials\nand a number of interactions that scales quadratically with the number of\nparticles $N$, as in the case of the N-body problem. In this work, we introduce\nan approach that transforms a fully-connected interaction graph into a\nhierarchical one which reduces the number of edges to $O(N)$. This results in\nlinear time and space complexity while the pre-computation of the hierarchical\ngraph requires $O(N\\log (N))$ time and $O(N)$ space. Using our approach, we are\nable to train models on much larger particle counts, even on a single GPU. We\nevaluate how the phase space position accuracy and energy conservation depend\non the number of simulated particles. Our approach retains high accuracy and\nefficiency even on large-scale gravitational N-body simulations which are\nimpossible to run on a single machine if a fully-connected graph is used.\nSimilar results are also observed when simulating Coulomb interactions.\nFurthermore, we make several important observations regarding the performance\nof this new hierarchical model, including: i) its accuracy tends to improve\nwith the number of particles in the simulation and ii) its generalisation to\nunseen particle counts is also much better than for models that use all\n$O(N^2)$ interactions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 10:54:54 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 20:22:18 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 18:52:34 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Martinkus", "Karolis", ""], ["Lucchi", "Aurelien", ""], ["Perraudin", "Nathana\u00ebl", ""]]}, {"id": "2010.06978", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Tushar Nagarajan, Daniel Malinsky, Ilya Shpitser", "title": "Differentiable Causal Discovery Under Unmeasured Confounding", "comments": "Main draft: 9 pages. Appendix: 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data drawn from biological, economic, and social systems are often\nconfounded due to the presence of unmeasured variables. Prior work in causal\ndiscovery has focused on discrete search procedures for selecting acyclic\ndirected mixed graphs (ADMGs), specifically ancestral ADMGs, that encode\nordinary conditional independence constraints among the observed variables of\nthe system. However, confounded systems also exhibit more general equality\nrestrictions that cannot be represented via these graphs, placing a limit on\nthe kinds of structures that can be learned using ancestral ADMGs. In this\nwork, we derive differentiable algebraic constraints that fully characterize\nthe space of ancestral ADMGs, as well as more general classes of ADMGs, arid\nADMGs and bow-free ADMGs, that capture all equality restrictions on the\nobserved variables. We use these constraints to cast causal discovery as a\ncontinuous optimization problem and design differentiable procedures to find\nthe best fitting ADMG when the data comes from a confounded linear system of\nequations with correlated errors. We demonstrate the efficacy of our method\nthrough simulations and application to a protein expression dataset. Code\nimplementing our methods is open-source and publicly available at\nhttps://gitlab.com/rbhatta8/dcd and will be incorporated into the Ananke\npackage.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 11:47:45 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 02:20:26 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Nagarajan", "Tushar", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2010.06986", "submitter": "Sruthi Gorantla", "authors": "Sruthi Gorantla, Amit Deshpande, Anand Louis", "title": "On the Problem of Underranking in Group-Fair Ranking", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search and recommendation systems, such as search engines, recruiting tools,\nonline marketplaces, news, and social media, output ranked lists of content,\nproducts, and sometimes, people. Credit ratings, standardized tests, risk\nassessments output only a score, but are also used implicitly for ranking. Bias\nin such ranking systems, especially among the top ranks, can worsen social and\neconomic inequalities, polarize opinions, and reinforce stereotypes. On the\nother hand, a bias correction for minority groups can cause more harm if\nperceived as favoring group-fair outcomes over meritocracy. In this paper, we\nformulate the problem of underranking in group-fair rankings, which was not\naddressed in previous work. Most group-fair ranking algorithms post-process a\ngiven ranking and output a group-fair ranking. We define underranking based on\nhow close the group-fair rank of each item is to its original rank, and prove a\nlower bound on the trade-off achievable for simultaneous underranking and group\nfairness in ranking. We give a fair ranking algorithm that takes any given\nranking and outputs another ranking with simultaneous underranking and group\nfairness guarantees comparable to the lower bound we prove. Our algorithm works\nwith group fairness constraints for any number of groups. Our experimental\nresults confirm the theoretical trade-off between underranking and group\nfairness, and also show that our algorithm achieves the best of both when\ncompared to the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:56:10 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 17:20:54 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Gorantla", "Sruthi", ""], ["Deshpande", "Amit", ""], ["Louis", "Anand", ""]]}, {"id": "2010.06987", "submitter": "Ehtsham Elahi", "authors": "Ehtsham Elahi and Ashok Chandrashekar", "title": "Learning Representations of Hierarchical Slates in Collaborative\n  Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in building collaborative filtering models for\nrecommendation systems where users interact with slates instead of individual\nitems. These slates can be hierarchical in nature. The central idea of our\napproach is to learn low dimensional embeddings of these slates. We present a\nnovel way to learn these embeddings by making use of the (unknown) statistics\nof the underlying distribution generating the hierarchical data. Our\nrepresentation learning algorithm can be viewed as a simple composition rule\nthat can be applied recursively in a bottom-up fashion to represent arbitrarily\ncomplex hierarchical structures in terms of the representations of its\nconstituent components. We demonstrate our ideas on two real world\nrecommendation systems datasets including the one used for the RecSys 2019\nchallenge. For that dataset, we improve upon the performance achieved by the\nwinning team's model by incorporating embeddings as features generated by our\napproach in their solution.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 18:34:02 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Elahi", "Ehtsham", ""], ["Chandrashekar", "Ashok", ""]]}, {"id": "2010.06988", "submitter": "Stefano Ermon", "authors": "Marshall Burke, Anne Driscoll, David B. Lobell, Stefano Ermon", "title": "Using satellite imagery to understand and promote sustainable\n  development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and comprehensive measurements of a range of sustainable development\noutcomes are fundamental inputs into both research and policy. We synthesize\nthe growing literature that uses satellite imagery to understand these\noutcomes, with a focus on approaches that combine imagery with machine\nlearning. We quantify the paucity of ground data on key human-related outcomes\nand the growing abundance and resolution (spatial, temporal, and spectral) of\nsatellite imagery. We then review recent machine learning approaches to\nmodel-building in the context of scarce and noisy training data, highlighting\nhow this noise often leads to incorrect assessment of models' predictive\nperformance. We quantify recent model performance across multiple sustainable\ndevelopment domains, discuss research and policy applications, explore\nconstraints to future progress, and highlight key research directions for the\nfield.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 05:20:00 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Burke", "Marshall", ""], ["Driscoll", "Anne", ""], ["Lobell", "David B.", ""], ["Ermon", "Stefano", ""]]}, {"id": "2010.06992", "submitter": "Stefan Postavaru", "authors": "\\c{S}tefan Post\\u{a}varu, Anton Tsitsulin, Filipe Miguel Gon\\c{c}alves\n  de Almeida, Yingtao Tian, Silvio Lattanzi, Bryan Perozzi", "title": "InstantEmbedding: Efficient Local Node Representations", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce InstantEmbedding, an efficient method for\ngenerating single-node representations using local PageRank computations. We\ntheoretically prove that our approach produces globally consistent\nrepresentations in sublinear time. We demonstrate this empirically by\nconducting extensive experiments on real-world datasets with over a billion\nedges. Our experiments confirm that InstantEmbedding requires drastically less\ncomputation time (over 9,000 times faster) and less memory (by over 8,000\ntimes) to produce a single node's embedding than traditional methods including\nDeepWalk, node2vec, VERSE, and FastRP. We also show that our method produces\nhigh quality representations, demonstrating results that meet or exceed the\nstate of the art for unsupervised representation learning on tasks like node\nclassification and link prediction.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 12:08:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Post\u0103varu", "\u015etefan", ""], ["Tsitsulin", "Anton", ""], ["de Almeida", "Filipe Miguel Gon\u00e7alves", ""], ["Tian", "Yingtao", ""], ["Lattanzi", "Silvio", ""], ["Perozzi", "Bryan", ""]]}, {"id": "2010.06993", "submitter": "Pavel Kalaidin", "authors": "Artem Chumachenko and Daniil Gavrilov and Nikita Balagansky and Pavel\n  Kalaidin", "title": "Weight Squeezing: Reparameterization for Extreme Compression and Fast\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a novel approach for simultaneous knowledge transfer\nand model compression called Weight Squeezing. With this method, we perform\nknowledge transfer from a pre-trained teacher model by learning the mapping\nfrom its weights to smaller student model weights, without significant loss of\nmodel accuracy.\n  We applied Weight Squeezing to a pre-trained text classification model and\ncompared our method to various other knowledge transfer and model compression\nmethods on several downstream text classification tasks based on the GLUE\ndataset. We observed that our approach produces better results than other\nmethods for training student models without any loss in inference speed. We\nalso compared Weight Squeezing with Low-Rank Factorization approach and\nobserved that our method is significantly faster at inference while being\ncompetitive in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 12:13:28 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 11:32:49 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Chumachenko", "Artem", ""], ["Gavrilov", "Daniil", ""], ["Balagansky", "Nikita", ""], ["Kalaidin", "Pavel", ""]]}, {"id": "2010.07033", "submitter": "Andreas Kr\\\"amer", "authors": "Andreas Kr\\\"amer, Jonas K\\\"ohler and Frank No\\'e", "title": "Training Invertible Linear Layers through Rank-One Perturbations", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC physics.chem-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many types of neural network layers rely on matrix properties such as\ninvertibility or orthogonality. Retaining such properties during optimization\nwith gradient-based stochastic optimizers is a challenging task, which is\nusually addressed by either reparameterization of the affected parameters or by\ndirectly optimizing on the manifold. This work presents a novel approach for\ntraining invertible linear layers. In lieu of directly optimizing the network\nparameters, we train rank-one perturbations and add them to the actual weight\nmatrices infrequently. This P$^{4}$Inv update allows keeping track of inverses\nand determinants without ever explicitly computing them. We show how such\ninvertible blocks improve the mixing and thus the mode separation of the\nresulting normalizing flows. Furthermore, we outline how the P$^4$ concept can\nbe utilized to retain properties other than invertibility.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 12:43:47 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 00:58:50 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kr\u00e4mer", "Andreas", ""], ["K\u00f6hler", "Jonas", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2010.07035", "submitter": "Marlesson Santana", "authors": "Marlesson R. O. Santana, Luckeciano C. Melo, Fernando H. F. Camargo,\n  Bruno Brand\\~ao, Anderson Soares, Renan M. Oliveira and Sandor Caetano", "title": "MARS-Gym: A Gym framework to model, train, and evaluate Recommender\n  Systems for Marketplaces", "comments": "15 pages, 14 figures, see\n  https://github.com/deeplearningbrasil/mars-gym", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are especially challenging for marketplaces since they\nmust maximize user satisfaction while maintaining the healthiness and fairness\nof such ecosystems. In this context, we observed a lack of resources to design,\ntrain, and evaluate agents that learn by interacting within these environments.\nFor this matter, we propose MARS-Gym, an open-source framework to empower\nresearchers and engineers to quickly build and evaluate Reinforcement Learning\nagents for recommendations in marketplaces. MARS-Gym addresses the whole\ndevelopment pipeline: data processing, model design and optimization, and\nmulti-sided evaluation. We also provide the implementation of a diverse set of\nbaseline agents, with a metrics-driven analysis of them in the Trivago\nmarketplace dataset, to illustrate how to conduct a holistic assessment using\nthe available metrics of recommendation, off-policy estimation, and fairness.\nWith MARS-Gym, we expect to bridge the gap between academic research and\nproduction systems, as well as to facilitate the design of new algorithms and\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:39:31 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Santana", "Marlesson R. O.", ""], ["Melo", "Luckeciano C.", ""], ["Camargo", "Fernando H. F.", ""], ["Brand\u00e3o", "Bruno", ""], ["Soares", "Anderson", ""], ["Oliveira", "Renan M.", ""], ["Caetano", "Sandor", ""]]}, {"id": "2010.07038", "submitter": "David Conal Higgins", "authors": "David Higgins", "title": "OnRAMP for Regulating AI in Medical Products", "comments": "46 pages, 3 tables, 1 figure. Published in Advanced Intelligent\n  Systems, July 2021. (See DOI link)", "journal-ref": null, "doi": "10.1002/aisy.202100042", "report-no": null, "categories": "cs.CY cs.AI stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medical Artificial Intelligence (AI) involves the application of machine\nlearning algorithms to biomedical datasets in order to improve medical\npractices. Products incorporating medical AI require certification before\ndeployment in most jurisdictions. To date, clear pathways for regulating\nmedical AI are still under development. Below the level of formal pathways lies\nthe actual practice of developing a medical AI solution. This Perspective\nproposes best practice guidelines for development compatible with the\nproduction of a regulatory package which, regardless of the formal regulatory\npath, will form a core component of a certification process. The approach is\npredicated on a statistical risk perspective, typical of medical device\nregulators, and a deep understanding of machine learning methodologies. These\nguidelines will allow all parties to communicate more clearly in the\ndevelopment of a common Good Machine Learning Practice (GMLP), and thus lead to\nthe enhanced development of both medical AI products and regulations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 14:02:30 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:52:24 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 15:47:15 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 14:41:05 GMT"}, {"version": "v5", "created": "Mon, 1 Feb 2021 14:51:39 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 11:51:05 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Higgins", "David", ""]]}, {"id": "2010.07064", "submitter": "Onur Teymur", "authors": "Onur Teymur, Jackson Gorham, Marina Riabiz and Chris. J. Oates", "title": "Optimal quantisation of probability measures using maximum mean\n  discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several researchers have proposed minimisation of maximum mean discrepancy\n(MMD) as a method to quantise probability measures, i.e., to approximate a\ntarget distribution by a representative point set. We consider sequential\nalgorithms that greedily minimise MMD over a discrete candidate set. We propose\na novel non-myopic algorithm and, in order to both improve statistical\nefficiency and reduce computational cost, we investigate a variant that applies\nthis technique to a mini-batch of the candidate set at each iteration. When the\ncandidate points are sampled from the target, the consistency of these new\nalgorithm - and their mini-batch variants - is established. We demonstrate the\nalgorithms on a range of important computational problems, including\noptimisation of nodes in Bayesian cubature and the thinning of Markov chain\noutput.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:09:48 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:03:37 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 09:43:56 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 11:40:18 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Teymur", "Onur", ""], ["Gorham", "Jackson", ""], ["Riabiz", "Marina", ""], ["Oates", "Chris. J.", ""]]}, {"id": "2010.07067", "submitter": "Oliver T. Unke", "authors": "Oliver T. Unke, Stefan Chmiela, Huziel E. Sauceda, Michael Gastegger,\n  Igor Poltavsky, Kristof T. Sch\\\"utt, Alexandre Tkatchenko, Klaus-Robert\n  M\\\"uller", "title": "Machine Learning Force Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use of Machine Learning (ML) in computational chemistry\nhas enabled numerous advances previously out of reach due to the computational\ncomplexity of traditional electronic-structure methods. One of the most\npromising applications is the construction of ML-based force fields (FFs), with\nthe aim to narrow the gap between the accuracy of ab initio methods and the\nefficiency of classical FFs. The key idea is to learn the statistical relation\nbetween chemical structure and potential energy without relying on a\npreconceived notion of fixed chemical bonds or knowledge about the relevant\ninteractions. Such universal ML approximations are in principle only limited by\nthe quality and quantity of the reference data used to train them. This review\ngives an overview of applications of ML-FFs and the chemical insights that can\nbe obtained from them. The core concepts underlying ML-FFs are described in\ndetail and a step-by-step guide for constructing and testing them from scratch\nis given. The text concludes with a discussion of the challenges that remain to\nbe overcome by the next generation of ML-FFs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:14:14 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 14:57:54 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Unke", "Oliver T.", ""], ["Chmiela", "Stefan", ""], ["Sauceda", "Huziel E.", ""], ["Gastegger", "Michael", ""], ["Poltavsky", "Igor", ""], ["Sch\u00fctt", "Kristof T.", ""], ["Tkatchenko", "Alexandre", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2010.07069", "submitter": "Rajaei Khatib", "authors": "Rajaei Khatib, Dror Simon and Michael Elad", "title": "Learned Greedy Method (LGM): A Novel Neural Architecture for Sparse\n  Coding and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of signal and image processing have been deeply influenced by the\nintroduction of deep neural networks. These are successfully deployed in a wide\nrange of real-world applications, obtaining state of the art results and\nsurpassing well-known and well-established classical methods. Despite their\nimpressive success, the architectures used in many of these neural networks\ncome with no clear justification. As such, these are usually treated as \"black\nbox\" machines that lack any kind of interpretability. A constructive remedy to\nthis drawback is a systematic design of such networks by unfolding\nwell-understood iterative algorithms. A popular representative of this approach\nis the Iterative Shrinkage-Thresholding Algorithm (ISTA) and its learned\nversion -- LISTA, aiming for the sparse representations of the processed\nsignals. In this paper we revisit this sparse coding task and propose an\nunfolded version of a greedy pursuit algorithm for the same goal. More\nspecifically, we concentrate on the well-known Orthogonal-Matching-Pursuit\n(OMP) algorithm, and introduce its unfolded and learned version. Key features\nof our Learned Greedy Method (LGM) are the ability to accommodate a dynamic\nnumber of unfolded layers, and a stopping mechanism based on representation\nerror, both adapted to the input. We develop several variants of the proposed\nLGM architecture and test some of them in various experiments, demonstrating\ntheir flexibility and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:17:02 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 14:44:52 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Khatib", "Rajaei", ""], ["Simon", "Dror", ""], ["Elad", "Michael", ""]]}, {"id": "2010.07093", "submitter": "Muhammad Waleed Gondal", "authors": "Muhammad Waleed Gondal, Shruti Joshi, Nasim Rahaman, Stefan Bauer,\n  Manuel W\\\"uthrich, Bernhard Sch\\\"olkopf", "title": "Function Contrastive Learning of Transferable Meta-Representations", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms adapt quickly to new tasks that are drawn from the\nsame task distribution as the training tasks. The mechanism leading to fast\nadaptation is the conditioning of a downstream predictive model on the inferred\nrepresentation of the task's underlying data generative process, or\n\\emph{function}. This \\emph{meta-representation}, which is computed from a few\nobserved examples of the underlying function, is learned jointly with the\npredictive model. In this work, we study the implications of this joint\ntraining on the transferability of the meta-representations. Our goal is to\nlearn meta-representations that are robust to noise in the data and facilitate\nsolving a wide range of downstream tasks that share the same underlying\nfunctions. To this end, we propose a decoupled encoder-decoder approach to\nsupervised meta-learning, where the encoder is trained with a contrastive\nobjective to find a good representation of the underlying function. In\nparticular, our training scheme is driven by the self-supervision signal\nindicating whether two sets of examples stem from the same function. Our\nexperiments on a number of synthetic and real-world datasets show that the\nrepresentations we obtain outperform strong baselines in terms of downstream\nperformance and noise robustness, even when these baselines are trained in an\nend-to-end manner.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:50:22 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 19:35:16 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 11:45:09 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Gondal", "Muhammad Waleed", ""], ["Joshi", "Shruti", ""], ["Rahaman", "Nasim", ""], ["Bauer", "Stefan", ""], ["W\u00fcthrich", "Manuel", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2010.07110", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz", "title": "Online Anomaly Detection in Surveillance Videos with Asymptotic Bounds\n  on False Alarm Rate", "comments": "Submitted to Pattern Recognition. arXiv admin note: substantial text\n  overlap with arXiv:2004.07941", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in surveillance videos is attracting an increasing amount\nof attention. Despite the competitive performance of recent methods, they lack\ntheoretical performance analysis, particularly due to the complex deep neural\nnetwork architectures used in decision making. Additionally, online decision\nmaking is an important but mostly neglected factor in this domain. Much of the\nexisting methods that claim to be online, depend on batch or offline processing\nin practice. Motivated by these research gaps, we propose an online anomaly\ndetection method in surveillance videos with asymptotic bounds on the false\nalarm rate, which in turn provides a clear procedure for selecting a proper\ndecision threshold that satisfies the desired false alarm rate. Our proposed\nalgorithm consists of a multi-objective deep learning module along with a\nstatistical anomaly detection module, and its effectiveness is demonstrated on\nseveral publicly available data sets where we outperform the state-of-the-art\nalgorithms. All codes are available at\nhttps://github.com/kevaldoshi17/Prediction-based-Video-Anomaly-Detection-.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 04:46:16 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2010.07137", "submitter": "Vitor Cerqueira", "authors": "Vitor Cerqueira, Nuno Moniz, Carlos Soares", "title": "VEST: Automatic Feature Engineering for Forecasting", "comments": "25 pages, R code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is a challenging task with applications in a wide\nrange of domains. Auto-regression is one of the most common approaches to\naddress these problems. Accordingly, observations are modelled by multiple\nregression using their past lags as predictor variables. We investigate the\nextension of auto-regressive processes using statistics which summarise the\nrecent past dynamics of time series. The result of our research is a novel\nframework called VEST, designed to perform feature engineering using univariate\nand numeric time series automatically. The proposed approach works in three\nmain steps. First, recent observations are mapped onto different\nrepresentations. Second, each representation is summarised by statistical\nfunctions. Finally, a filter is applied for feature selection. We discovered\nthat combining the features generated by VEST with auto-regression\nsignificantly improves forecasting performance. We provide evidence using 90\ntime series with high sampling frequency. VEST is publicly available online.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 14:54:56 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Moniz", "Nuno", ""], ["Soares", "Carlos", ""]]}, {"id": "2010.07140", "submitter": "James Lucas", "authors": "James Lucas, Mengye Ren, Irene Kameni, Toniann Pitassi, Richard Zemel", "title": "Theoretical bounds on estimation error for meta-learning", "comments": "12 pages in main paper,22 pages in appendix,4 figures total", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have traditionally been developed under the\nassumption that the training and test distributions match exactly. However,\nrecent success in few-shot learning and related problems are encouraging signs\nthat these models can be adapted to more realistic settings where train and\ntest distributions differ. Unfortunately, there is severely limited theoretical\nsupport for these algorithms and little is known about the difficulty of these\nproblems. In this work, we provide novel information-theoretic lower-bounds on\nminimax rates of convergence for algorithms that are trained on data from\nmultiple sources and tested on novel data. Our bounds depend intuitively on the\ninformation shared between sources of data, and characterize the difficulty of\nlearning in this setting for arbitrary algorithms. We demonstrate these bounds\non a hierarchical Bayesian model of meta-learning, computing both upper and\nlower bounds on parameter estimation via maximum-a-posteriori inference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 14:57:21 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Lucas", "James", ""], ["Ren", "Mengye", ""], ["Kameni", "Irene", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "2010.07154", "submitter": "Liyuan Xu", "authors": "Liyuan Xu, Yutian Chen, Siddarth Srinivasan, Nando de Freitas, Arnaud\n  Doucet, Arthur Gretton", "title": "Learning Deep Features in Instrumental Variable Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrumental variable (IV) regression is a standard strategy for learning\ncausal relationships between confounded treatment and outcome variables from\nobservational data by utilizing an instrumental variable, which affects the\noutcome only through the treatment. In classical IV regression, learning\nproceeds in two stages: stage 1 performs linear regression from the instrument\nto the treatment; and stage 2 performs linear regression from the treatment to\nthe outcome, conditioned on the instrument. We propose a novel method, deep\nfeature instrumental variable regression (DFIV), to address the case where\nrelations between instruments, treatments, and outcomes may be nonlinear. In\nthis case, deep neural nets are trained to define informative nonlinear\nfeatures on the instruments and treatments. We propose an alternating training\nregime for these features to ensure good end-to-end performance when composing\nstages 1 and 2, thus obtaining highly flexible feature maps in a\ncomputationally efficient manner. DFIV outperforms recent state-of-the-art\nmethods on challenging IV benchmarks, including settings involving high\ndimensional image data. DFIV also exhibits competitive performance in\noff-policy policy evaluation for reinforcement learning, which can be\nunderstood as an IV regression task.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 15:14:49 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 10:29:20 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 15:36:04 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xu", "Liyuan", ""], ["Chen", "Yutian", ""], ["Srinivasan", "Siddarth", ""], ["de Freitas", "Nando", ""], ["Doucet", "Arnaud", ""], ["Gretton", "Arthur", ""]]}, {"id": "2010.07167", "submitter": "Jens M\\\"uller", "authors": "Jens M\\\"uller, Robert Schmier, Lynton Ardizzone, Carsten Rother and\n  Ullrich K\\\"othe", "title": "Learning Robust Models Using The Principle of Independent Causal\n  Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard supervised learning breaks down under data distribution shift.\nHowever, the principle of independent causal mechanisms (ICM, Peters et al.\n(2017)) can turn this weakness into an opportunity: one can take advantage of\ndistribution shift between different environments during training in order to\nobtain more robust models. We propose a new gradient-based learning framework\nwhose objective function is derived from the ICM principle. We show\ntheoretically and experimentally that neural networks trained in this framework\nfocus on relations remaining invariant across environments and ignore unstable\nones. Moreover, we prove that the recovered stable relations correspond to the\ntrue causal mechanisms under certain conditions. In both regression and\nclassification, the resulting models generalize well to unseen scenarios where\ntraditionally trained models fail.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 15:38:01 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 15:39:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["M\u00fcller", "Jens", ""], ["Schmier", "Robert", ""], ["Ardizzone", "Lynton", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2010.07212", "submitter": "Debajyoti Datta", "authors": "Debajyoti Datta, Shashwat Kumar, Laura Barnes, Tom Fletcher", "title": "Geometry matters: Exploring language examples at the decision boundary", "comments": "Preprint: Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of recent evidence has highlighted the limitations of natural\nlanguage processing (NLP) datasets and classifiers. These include the presence\nof annotation artifacts in datasets, classifiers relying on shallow features\nlike a single word (e.g., if a movie review has the word \"romantic\", the review\ntends to be positive), or unnecessary words (e.g., learning a proper noun to\nclassify a movie as positive or negative). The presence of such artifacts has\nsubsequently led to the development of challenging datasets to force the model\nto generalize better. While a variety of heuristic strategies, such as\ncounterfactual examples and contrast sets, have been proposed, the theoretical\njustification about what makes these examples difficult for the classifier is\noften lacking or unclear. In this paper, using tools from information geometry,\nwe propose a theoretical way to quantify the difficulty of an example in NLP.\nUsing our approach, we explore difficult examples for several deep learning\narchitectures. We discover that both BERT, CNN and fasttext are susceptible to\nword substitutions in high difficulty examples. These classifiers tend to\nperform poorly on the FIM test set. (generated by sampling and perturbing\ndifficult examples, with accuracy dropping below 50%). We replicate our\nexperiments on 5 NLP datasets (YelpReviewPolarity, AGNEWS, SogouNews,\nYelpReviewFull and Yahoo Answers). On YelpReviewPolarity we observe a\ncorrelation coefficient of -0.4 between resilience to perturbations and the\ndifficulty score. Similarly we observe a correlation of 0.35 between the\ndifficulty score and the empirical success probability of random substitutions.\nOur approach is simple, architecture agnostic and can be used to study the\nfragilities of text classification models. All the code used will be made\npublicly available, including a tool to explore the difficult examples for\nother datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:26:13 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 05:48:40 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Datta", "Debajyoti", ""], ["Kumar", "Shashwat", ""], ["Barnes", "Laura", ""], ["Fletcher", "Tom", ""]]}, {"id": "2010.07242", "submitter": "Nan Wu", "authors": "David B Dunson, Hau-Tieng Wu and Nan Wu", "title": "Diffusion Based Gaussian Processes on Restricted Domains", "comments": "27 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nonparametric regression and spatial process modeling, it is common for\nthe inputs to fall in a restricted subset of Euclidean space. For example, the\nlocations at which spatial data are collected may be restricted to a narrow\nnon-linear subset, such as near the edge of a lake. Typical kernel-based\nmethods that do not take into account the intrinsic geometric of the domain\nacross which observations are collected may produce sub-optimal results. In\nthis article, we focus on solving this problem in the context of Gaussian\nprocess (GP) models, proposing a new class of diffusion-based GPs (DB-GPs),\nwhich learn a covariance that respects the geometry of the input domain. We use\nthe term `diffusion-based' as the idea is to measure intrinsic distances\nbetween inputs in a restricted domain via a diffusion process. As the heat\nkernel is intractable computationally, we approximate the covariance using\nfinitely-many eigenpairs of the Graph Laplacian (GL). Our proposed algorithm\nhas the same order of computational complexity as current GP algorithms using\nsimple covariance kernels. We provide substantial theoretical support for the\nDB-GP methodology, and illustrate performance gains through toy examples,\nsimulation studies, and applications to ecology data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:01:29 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Dunson", "David B", ""], ["Wu", "Hau-Tieng", ""], ["Wu", "Nan", ""]]}, {"id": "2010.07252", "submitter": "Tanut Treetanthiploet", "authors": "Samuel N. Cohen and Tanut Treetanthiploet", "title": "Asymptotic Randomised Control with applications to bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general multi-armed bandit problem with correlated (and simple\ncontextual and restless) elements, as a relaxed control problem. By introducing\nan entropy premium, we obtain a smooth asymptotic approximation to the value\nfunction. This yields a novel semi-index approximation of the optimal decision\nprocess, obtained numerically by solving a fixed point problem, which can be\ninterpreted as explicitly balancing an exploration-exploitation trade-off.\nPerformance of the resulting Asymptotic Randomised Control (ARC) algorithm\ncompares favourably with other approaches to correlated multi-armed bandits.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:17:48 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cohen", "Samuel N.", ""], ["Treetanthiploet", "Tanut", ""]]}, {"id": "2010.07283", "submitter": "Haoyu Chen", "authors": "Haoyu Chen, Wenbin Lu, Rui Song", "title": "Statistical Inference for Online Decision-Making: In a Contextual Bandit\n  Setting", "comments": "Accepted by the Journal of the American Statistical Association", "journal-ref": null, "doi": "10.1080/01621459.2020.1770098", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online decision-making problem requires us to make a sequence of decisions\nbased on incremental information. Common solutions often need to learn a reward\nmodel of different actions given the contextual information and then maximize\nthe long-term reward. It is meaningful to know if the posited model is\nreasonable and how the model performs in the asymptotic sense. We study this\nproblem under the setup of the contextual bandit framework with a linear reward\nmodel. The $\\varepsilon$-greedy policy is adopted to address the classic\nexploration-and-exploitation dilemma. Using the martingale central limit\ntheorem, we show that the online ordinary least squares estimator of model\nparameters is asymptotically normal. When the linear model is misspecified, we\npropose the online weighted least squares estimator using the inverse\npropensity score weighting and also establish its asymptotic normality. Based\non the properties of the parameter estimators, we further show that the\nin-sample inverse propensity weighted value estimator is asymptotically normal.\nWe illustrate our results using simulations and an application to a news\narticle recommendation dataset from Yahoo!.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:57:14 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Chen", "Haoyu", ""], ["Lu", "Wenbin", ""], ["Song", "Rui", ""]]}, {"id": "2010.07289", "submitter": "Kriste Krstovski", "authors": "Paul Glasserman, Kriste Krstovski, Paul Laliberte, Harry Mamaysky", "title": "Choosing News Topics to Explain Stock Market Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze methods for selecting topics in news articles to explain stock\nreturns. We find, through empirical and theoretical results, that supervised\nLatent Dirichlet Allocation (sLDA) implemented through Gibbs sampling in a\nstochastic EM algorithm will often overfit returns to the detriment of the\ntopic model. We obtain better out-of-sample performance through a random search\nof plain LDA models. A branching procedure that reinforces effective topic\nassignments often performs best. We test methods on an archive of over 90,000\nnews articles about S&P 500 firms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 01:38:35 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Glasserman", "Paul", ""], ["Krstovski", "Kriste", ""], ["Laliberte", "Paul", ""], ["Mamaysky", "Harry", ""]]}, {"id": "2010.07290", "submitter": "Zaccharie Ramzi", "authors": "Zaccharie Ramzi, Philippe Ciuciu, Jean-Luc Starck", "title": "XPDNet for MRI Reconstruction: an application to the 2020 fastMRI\n  challenge", "comments": "8 pages, 3 figures, presented as an oral to the 2021 ISMRM conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new neural network, the XPDNet, for MRI reconstruction from\nperiodically under-sampled multi-coil data. We inform the design of this\nnetwork by taking best practices from MRI reconstruction and computer vision.\nWe show that this network can achieve state-of-the-art reconstruction results,\nas shown by its ranking of second in the fastMRI 2020 challenge.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:45:00 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 08:57:52 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Ramzi", "Zaccharie", ""], ["Ciuciu", "Philippe", ""], ["Starck", "Jean-Luc", ""]]}, {"id": "2010.07341", "submitter": "Haoyu Chen", "authors": "Haoyu Chen, Wenbin Lu, Rui Song", "title": "Statistical Inference for Online Decision Making via Stochastic Gradient\n  Descent", "comments": "Accepted by the Journal of the American Statistical Association", "journal-ref": null, "doi": "10.1080/01621459.2020.1826325", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online decision making aims to learn the optimal decision rule by making\npersonalized decisions and updating the decision rule recursively. It has\nbecome easier than before with the help of big data, but new challenges also\ncome along. Since the decision rule should be updated once per step, an offline\nupdate which uses all the historical data is inefficient in computation and\nstorage. To this end, we propose a completely online algorithm that can make\ndecisions and update the decision rule online via stochastic gradient descent.\nIt is not only efficient but also supports all kinds of parametric reward\nmodels. Focusing on the statistical inference of online decision making, we\nestablish the asymptotic normality of the parameter estimator produced by our\nalgorithm and the online inverse probability weighted value estimator we used\nto estimate the optimal value. Online plugin estimators for the variance of the\nparameter and value estimators are also provided and shown to be consistent, so\nthat interval estimation and hypothesis test are possible using our method. The\nproposed algorithm and theoretical results are tested by simulations and a real\ndata application to news article recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:25:18 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Chen", "Haoyu", ""], ["Lu", "Wenbin", ""], ["Song", "Rui", ""]]}, {"id": "2010.07343", "submitter": "Vishwali Mhasawade", "authors": "Vishwali Mhasawade and Rumi Chunara", "title": "Causal Multi-Level Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic systems are known to impact marginalized groups severely, and\nmore so, if all sources of bias are not considered. While work in algorithmic\nfairness to-date has primarily focused on addressing discrimination due to\nindividually linked attributes, social science research elucidates how some\nproperties we link to individuals can be conceptualized as having causes at\nmacro (e.g. structural) levels, and it may be important to be fair to\nattributes at multiple levels. For example, instead of simply considering race\nas a causal, protected attribute of an individual, the cause may be distilled\nas perceived racial discrimination an individual experiences, which in turn can\nbe affected by neighborhood-level factors. This multi-level conceptualization\nis relevant to questions of fairness, as it may not only be important to take\ninto account if the individual belonged to another demographic group, but also\nif the individual received advantaged treatment at the macro-level. In this\npaper, we formalize the problem of multi-level fairness using tools from causal\ninference in a manner that allows one to assess and account for effects of\nsensitive attributes at multiple levels. We show importance of the problem by\nillustrating residual unfairness if macro-level sensitive attributes are not\naccounted for, or included without accounting for their multi-level nature.\nFurther, in the context of a real-world task of predicting income based on\nmacro and individual-level attributes, we demonstrate an approach for\nmitigating unfairness, a result of multi-level sensitive attributes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:26:17 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 18:06:29 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 18:48:01 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Chunara", "Rumi", ""]]}, {"id": "2010.07349", "submitter": "Vincent Le-Guen", "authors": "Vincent Le Guen, Nicolas Thome", "title": "Probabilistic Time Series Forecasting with Structured Shape and Temporal\n  Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic forecasting consists in predicting a distribution of possible\nfuture outcomes. In this paper, we address this problem for non-stationary time\nseries, which is very challenging yet crucially important. We introduce the\nSTRIPE model for representing structured diversity based on shape and time\nfeatures, ensuring both probable predictions while being sharp and accurate.\nSTRIPE is agnostic to the forecasting model, and we equip it with a\ndiversification mechanism relying on determinantal point processes (DPP). We\nintroduce two DPP kernels for modeling diverse trajectories in terms of shape\nand time, which are both differentiable and proved to be positive\nsemi-definite. To have an explicit control on the diversity structure, we also\ndesign an iterative sampling mechanism to disentangle shape and time\nrepresentations in the latent space. Experiments carried out on synthetic\ndatasets show that STRIPE significantly outperforms baseline methods for\nrepresenting diversity, while maintaining accuracy of the forecasting model. We\nalso highlight the relevance of the iterative sampling scheme and the\nimportance to use different criteria for measuring quality and diversity.\nFinally, experiments on real datasets illustrate that STRIPE is able to\noutperform state-of-the-art probabilistic forecasting approaches in the best\nsample prediction.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:31:43 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 11:50:53 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 07:50:13 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Guen", "Vincent Le", ""], ["Thome", "Nicolas", ""]]}, {"id": "2010.07355", "submitter": "Ben Adlam", "authors": "Ben Adlam, Jaehoon Lee, Lechao Xiao, Jeffrey Pennington, and Jasper\n  Snoek", "title": "Exploring the Uncertainty Properties of Neural Networks' Implicit Priors\n  in the Infinite-Width Limit", "comments": "23 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning models have achieved great success in predictive\naccuracy for many data modalities. However, their application to many\nreal-world tasks is restricted by poor uncertainty estimates, such as\noverconfidence on out-of-distribution (OOD) data and ungraceful failing under\ndistributional shift. Previous benchmarks have found that ensembles of neural\nnetworks (NNs) are typically the best calibrated models on OOD data. Inspired\nby this, we leverage recent theoretical advances that characterize the\nfunction-space prior of an ensemble of infinitely-wide NNs as a Gaussian\nprocess, termed the neural network Gaussian process (NNGP). We use the NNGP\nwith a softmax link function to build a probabilistic model for multi-class\nclassification and marginalize over the latent Gaussian outputs to sample from\nthe posterior. This gives us a better understanding of the implicit prior NNs\nplace on function space and allows a direct comparison of the calibration of\nthe NNGP and its finite-width analogue. We also examine the calibration of\nprevious approaches to classification with the NNGP, which treat classification\nproblems as regression to the one-hot labels. In this case the Bayesian\nposterior is exact, and we compare several heuristics to generate a categorical\ndistribution over classes. We find these methods are well calibrated under\ndistributional shift. Finally, we consider an infinite-width final layer in\nconjunction with a pre-trained embedding. This replicates the important\npractical use case of transfer learning and allows scaling to significantly\nlarger datasets. As well as achieving competitive predictive accuracy, this\napproach is better calibrated than its finite width analogue.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:41:54 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Adlam", "Ben", ""], ["Lee", "Jaehoon", ""], ["Xiao", "Lechao", ""], ["Pennington", "Jeffrey", ""], ["Snoek", "Jasper", ""]]}, {"id": "2010.07384", "submitter": "Christopher Frye", "authors": "Damien de Mijolla, Christopher Frye, Markus Kunesch, John Mansir, Ilya\n  Feige", "title": "Human-interpretable model explainability on high-dimensional data", "comments": "8 pages, 6 figures, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of explainability in machine learning continues to grow, as\nboth neural-network architectures and the data they model become increasingly\ncomplex. Unique challenges arise when a model's input features become high\ndimensional: on one hand, principled model-agnostic approaches to\nexplainability become too computationally expensive; on the other, more\nefficient explainability algorithms lack natural interpretations for general\nusers. In this work, we introduce a framework for human-interpretable\nexplainability on high-dimensional data, consisting of two modules. First, we\napply a semantically meaningful latent representation, both to reduce the raw\ndimensionality of the data, and to ensure its human interpretability. These\nlatent features can be learnt, e.g. explicitly as disentangled representations\nor implicitly through image-to-image translation, or they can be based on any\ncomputable quantities the user chooses. Second, we adapt the Shapley paradigm\nfor model-agnostic explainability to operate on these latent features. This\nleads to interpretable model explanations that are both theoretically\ncontrolled and computationally tractable. We benchmark our approach on\nsynthetic data and demonstrate its effectiveness on several\nimage-classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 20:06:28 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["de Mijolla", "Damien", ""], ["Frye", "Christopher", ""], ["Kunesch", "Markus", ""], ["Mansir", "John", ""], ["Feige", "Ilya", ""]]}, {"id": "2010.07388", "submitter": "Lev Utkin", "authors": "Andrei V. Konstantinov and Lev V. Utkin", "title": "Interpretable Machine Learning with an Ensemble of Gradient Boosting\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for the local and global interpretation of a black-box model on the\nbasis of the well-known generalized additive models is proposed. It can be\nviewed as an extension or a modification of the algorithm using the neural\nadditive model. The method is based on using an ensemble of gradient boosting\nmachines (GBMs) such that each GBM is learned on a single feature and produces\na shape function of the feature. The ensemble is composed as a weighted sum of\nseparate GBMs resulting a weighted sum of shape functions which form the\ngeneralized additive model. GBMs are built in parallel using randomized\ndecision trees of depth 1, which provide a very simple architecture. Weights of\nGBMs as well as features are computed in each iteration of boosting by using\nthe Lasso method and then updated by means of a specific smoothing procedure.\nIn contrast to the neural additive model, the method provides weights of\nfeatures in the explicit form, and it is simply trained. A lot of numerical\nexperiments with an algorithm implementing the proposed method on synthetic and\nreal datasets demonstrate its efficiency and properties for local and global\ninterpretation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 20:18:40 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Konstantinov", "Andrei V.", ""], ["Utkin", "Lev V.", ""]]}, {"id": "2010.07389", "submitter": "Christopher Frye", "authors": "Tom Begley, Tobias Schwedes, Christopher Frye, Ilya Feige", "title": "Explainability for fair machine learning", "comments": "8 pages, 3 figures, 2 tables, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the decisions made or influenced by machine learning models increasingly\nimpact our lives, it is crucial to detect, understand, and mitigate unfairness.\nBut even simply determining what \"unfairness\" should mean in a given context is\nnon-trivial: there are many competing definitions, and choosing between them\noften requires a deep understanding of the underlying task. It is thus tempting\nto use model explainability to gain insights into model fairness, however\nexisting explainability tools do not reliably indicate whether a model is\nindeed fair. In this work we present a new approach to explaining fairness in\nmachine learning, based on the Shapley value paradigm. Our fairness\nexplanations attribute a model's overall unfairness to individual input\nfeatures, even in cases where the model does not operate on sensitive\nattributes directly. Moreover, motivated by the linearity of Shapley\nexplainability, we propose a meta algorithm for applying existing training-time\nfairness interventions, wherein one trains a perturbation to the original\nmodel, rather than a new model entirely. By explaining the original model, the\nperturbation, and the fair-corrected model, we gain insight into the\naccuracy-fairness trade-off that is being made by the intervention. We further\nshow that this meta algorithm enjoys both flexibility and stability benefits\nwith no loss in performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 20:21:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Begley", "Tom", ""], ["Schwedes", "Tobias", ""], ["Frye", "Christopher", ""], ["Feige", "Ilya", ""]]}, {"id": "2010.07422", "submitter": "HanQin Cai", "authors": "HanQin Cai, Keaton Hamm, Longxiu Huang, Jiaqi Li, Tao Wang", "title": "Rapid Robust Principal Component Analysis: CUR Accelerated Inexact Low\n  Rank Estimation", "comments": null, "journal-ref": "IEEE Signal Processing Letters, 28 (2021): 116-120", "doi": "10.1109/LSP.2020.3044130", "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.NA math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust principal component analysis (RPCA) is a widely used tool for\ndimension reduction. In this work, we propose a novel non-convex algorithm,\ncoined Iterated Robust CUR (IRCUR), for solving RPCA problems, which\ndramatically improves the computational efficiency in comparison with the\nexisting algorithms. IRCUR achieves this acceleration by employing CUR\ndecomposition when updating the low rank component, which allows us to obtain\nan accurate low rank approximation via only three small submatrices.\nConsequently, IRCUR is able to process only the small submatrices and avoid\nexpensive computing on the full matrix through the entire algorithm. Numerical\nexperiments establish the computational advantage of IRCUR over the\nstate-of-art algorithms on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 22:30:20 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 01:41:41 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 06:43:25 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Cai", "HanQin", ""], ["Hamm", "Keaton", ""], ["Huang", "Longxiu", ""], ["Li", "Jiaqi", ""], ["Wang", "Tao", ""]]}, {"id": "2010.07468", "submitter": "Juntang Zhuang", "authors": "Juntang Zhuang, Tommy Tang, Yifan Ding, Sekhar Tatikonda, Nicha\n  Dvornek, Xenophon Papademetris, James S. Duncan", "title": "AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed\n  Gradients", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most popular optimizers for deep learning can be broadly categorized as\nadaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient\ndescent (SGD) with momentum). For many models such as convolutional neural\nnetworks (CNNs), adaptive methods typically converge faster but generalize\nworse compared to SGD; for complex settings such as generative adversarial\nnetworks (GANs), adaptive methods are typically the default because of their\nstability.We propose AdaBelief to simultaneously achieve three goals: fast\nconvergence as in adaptive methods, good generalization as in SGD, and training\nstability. The intuition for AdaBelief is to adapt the stepsize according to\nthe \"belief\" in the current gradient direction. Viewing the exponential moving\naverage (EMA) of the noisy gradient as the prediction of the gradient at the\nnext time step, if the observed gradient greatly deviates from the prediction,\nwe distrust the current observation and take a small step; if the observed\ngradient is close to the prediction, we trust it and take a large step. We\nvalidate AdaBelief in extensive experiments, showing that it outperforms other\nmethods with fast convergence and high accuracy on image classification and\nlanguage modeling. Specifically, on ImageNet, AdaBelief achieves comparable\naccuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief\ndemonstrates high stability and improves the quality of generated samples\ncompared to a well-tuned Adam optimizer. Code is available at\nhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 01:46:13 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 00:04:24 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 16:29:28 GMT"}, {"version": "v4", "created": "Sat, 28 Nov 2020 03:01:41 GMT"}, {"version": "v5", "created": "Sun, 20 Dec 2020 22:30:36 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Zhuang", "Juntang", ""], ["Tang", "Tommy", ""], ["Ding", "Yifan", ""], ["Tatikonda", "Sekhar", ""], ["Dvornek", "Nicha", ""], ["Papademetris", "Xenophon", ""], ["Duncan", "James S.", ""]]}, {"id": "2010.07532", "submitter": "Brendon G. Anderson", "authors": "Brendon G. Anderson, Somayeh Sojoudi", "title": "Certifying Neural Network Robustness to Random Input Noise from Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods to certify the robustness of neural networks in the presence of input\nuncertainty are vital in safety-critical settings. Most certification methods\nin the literature are designed for adversarial input uncertainty, but\nresearchers have recently shown a need for methods that consider random\nuncertainty. In this paper, we propose a novel robustness certification method\nthat upper bounds the probability of misclassification when the input noise\nfollows an arbitrary probability distribution. This bound is cast as a\nchance-constrained optimization problem, which is then reformulated using\ninput-output samples to replace the optimization constraints. The resulting\noptimization reduces to a linear program with an analytical solution.\nFurthermore, we develop a sufficient condition on the number of samples needed\nto make the misclassification bound hold with overwhelming probability. Our\ncase studies on MNIST classifiers show that this method is able to certify a\nuniform infinity-norm uncertainty region with a radius of nearly 50 times\nlarger than what the current state-of-the-art method can certify.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 05:27:21 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Anderson", "Brendon G.", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2010.07594", "submitter": "Xiaohan Yan", "authors": "William B. Nicholson, Xiaohan Yan", "title": "An Improved Online Penalty Parameter Selection Procedure for\n  $\\ell_1$-Penalized Autoregressive with Exogenous Variables", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent developments in the high-dimensional statistical time series\nliterature have centered around time-dependent applications that can be adapted\nto regularized least squares. Of particular interest is the lasso, which both\nserves to regularize and provide feature selection. The lasso requires the\nspecification of a penalty parameter that determines the degree of sparsity to\nimpose. The most popular penalty parameter selection approaches that respect\ntime dependence are very computationally intensive and are not appropriate for\nmodeling certain classes of time series. We propose enhancing a canonical time\nseries model, the autoregressive model with exogenous variables, with a novel\nonline penalty parameter selection procedure that takes advantage of the\nsequential nature of time series data to improve both computational performance\nand forecast accuracy relative to existing methods in both a simulation and\nempirical application involving macroeconomic indicators.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 08:32:27 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Nicholson", "William B.", ""], ["Yan", "Xiaohan", ""]]}, {"id": "2010.07604", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Kyungwoo Song, YoonYeong Kim, Yongjin Shin, Wanmo Kang,\n  Il-Chul Moon", "title": "Sequential Likelihood-Free Inference with Implicit Surrogate Proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference without the access of likelihood, or likelihood-free\ninference, has been a key research topic in simulations, to yield a more\nrealistic generation result. Recent likelihood-free inference updates an\napproximate posterior sequentially with the dataset of the cumulative\nsimulation input-output pairs over inference rounds. Therefore, the dataset is\ngathered through the iterative simulations with sampled inputs from a proposal\ndistribution by MCMC, which becomes the key of inference quality in this\nsequential framework. This paper introduces a new proposal modeling, named as\nImplicit Surrogate Proposal (ISP), to generate a cumulated dataset with further\nsample efficiency. ISP constructs the cumulative dataset in the most diverse\nway by drawing i.i.d samples via a feed-forward fashion, so the posterior\ninference does not suffer from the disadvantages of MCMC caused by its\nnon-i.i.d nature, such as auto-correlation and slow mixing. We analyze the\nconvergence property of ISP in both theoretical and empirical aspects to\nguarantee that ISP provides an asymptotically exact sampler. We demonstrate\nthat ISP outperforms the baseline inference algorithms on simulations with\nmulti-modal posteriors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 08:59:23 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 16:55:23 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kim", "Dongjun", ""], ["Song", "Kyungwoo", ""], ["Kim", "YoonYeong", ""], ["Shin", "Yongjin", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2010.07615", "submitter": "George De Ath", "authors": "George De Ath, Richard M. Everson, Jonathan E. Fieldsend", "title": "Asynchronous \\epsilon-Greedy Bayesian Optimisation", "comments": "Accepted for the 37th conference on Uncertainty in Artificial\n  Intelligence (UAI 2021). 11 pages (main paper) + 22 pages (supplementary\n  material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Bayesian optimisation (BO) is a successful technique for the\noptimisation of expensive black-box functions. Asynchronous BO can reduce\nwallclock time by starting a new evaluation as soon as another finishes, thus\nmaximising resource utilisation. To maximise resource allocation, we develop a\nnovel asynchronous BO method, AEGiS (Asynchronous $\\epsilon$-Greedy Global\nSearch) that combines greedy search, exploiting the surrogate's mean\nprediction, with Thompson sampling and random selection from the approximate\nPareto set describing the trade-off between exploitation (surrogate mean\nprediction) and exploration (surrogate posterior variance). We demonstrate\nempirically the efficacy of AEGiS on synthetic benchmark problems,\nmeta-surrogate hyperparameter tuning problems and real-world problems, showing\nthat AEGiS generally outperforms existing methods for asynchronous BO. When a\nsingle worker is available performance is no worse than BO using expected\nimprovement.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:21:02 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 11:10:00 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 16:06:56 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 11:15:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard M.", ""], ["Fieldsend", "Jonathan E.", ""]]}, {"id": "2010.07693", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt, Ari Morcos", "title": "Linking average- and worst-case perturbation robustness via class\n  selectivity and dimensionality", "comments": "arXiv admin note: text overlap with arXiv:2007.04440", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational sparsity is known to affect robustness to input\nperturbations in deep neural networks (DNNs), but less is known about how the\nsemantic content of representations affects robustness. Class selectivity-the\nvariability of a unit's responses across data classes or dimensions-is one way\nof quantifying the sparsity of semantic representations. Given recent evidence\nthat class selectivity may not be necessary for, and in some cases can impair\ngeneralization, we investigate whether it also confers robustness (or\nvulnerability) to perturbations of input data. We found that networks\nregularized to have lower levels of class selectivity were more robust to\naverage-case (naturalistic) perturbations, while networks with higher class\nselectivity are more vulnerable. In contrast, class selectivity increases\nrobustness to multiple types of worst-case (i.e. white box adversarial)\nperturbations, suggesting that while decreasing class selectivity is helpful\nfor average-case perturbations, it is harmful for worst-case perturbations. To\nexplain this difference, we studied the dimensionality of the networks'\nrepresentations: we found that the dimensionality of early-layer\nrepresentations is inversely proportional to a network's class selectivity, and\nthat adversarial samples cause a larger increase in early-layer dimensionality\nthan corrupted samples. Furthermore, the input-unit gradient is more variable\nacross samples and units in high-selectivity networks compared to\nlow-selectivity networks. These results lead to the conclusion that units\nparticipate more consistently in low-selectivity regimes compared to\nhigh-selectivity regimes, effectively creating a larger attack surface and\nhence vulnerability to worst-case perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 00:45:29 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 22:49:58 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2010.07744", "submitter": "Martin Keller-Ressel", "authors": "Martin Keller-Ressel", "title": "A Theory of Hyperbolic Prototype Learning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Hyperbolic Prototype Learning, a type of supervised learning,\nwhere class labels are represented by ideal points (points at infinity) in\nhyperbolic space. Learning is achieved by minimizing the 'penalized Busemann\nloss', a new loss function based on the Busemann function of hyperbolic\ngeometry. We discuss several theoretical features of this setup. In particular,\nHyperbolic Prototype Learning becomes equivalent to logistic regression in the\none-dimensional case.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:45:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Keller-Ressel", "Martin", ""]]}, {"id": "2010.07753", "submitter": "James Brofos", "authors": "James A. Brofos and Roy R. Lederman", "title": "Magnetic Manifold Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms offer various strategies for\nsampling; the Hamiltonian Monte Carlo (HMC) family of samplers are MCMC\nalgorithms which often exhibit improved mixing properties. The recently\nintroduced magnetic HMC, a generalization of HMC motivated by the physics of\nparticles influenced by magnetic field forces, has been demonstrated to improve\nthe performance of HMC. In many applications, one wishes to sample from a\ndistribution restricted to a constrained set, often manifested as an embedded\nmanifold (for example, the surface of a sphere). We introduce magnetic manifold\nHMC, an HMC algorithm on embedded manifolds motivated by the physics of\nparticles constrained to a manifold and moving under magnetic field forces. We\ndiscuss the theoretical properties of magnetic Hamiltonian dynamics on\nmanifolds, and introduce a reversible and symplectic integrator for the HMC\nupdates. We demonstrate that magnetic manifold HMC produces favorable sampling\nbehaviors relative to the canonical variant of manifold-constrained HMC.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:53:49 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Brofos", "James A.", ""], ["Lederman", "Roy R.", ""]]}, {"id": "2010.07765", "submitter": "Cedric Renggli", "authors": "Luka Rimanic, Cedric Renggli, Bo Li, Ce Zhang", "title": "On Convergence of Nearest Neighbor Classifiers over Feature\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-Nearest Neighbors (kNN) classifier is a fundamental non-parametric\nmachine learning algorithm. However, it is well known that it suffers from the\ncurse of dimensionality, which is why in practice one often applies a kNN\nclassifier on top of a (pre-trained) feature transformation. From a theoretical\nperspective, most, if not all theoretical results aimed at understanding the\nkNN classifier are derived for the raw feature space. This leads to an emerging\ngap between our theoretical understanding of kNN and its practical\napplications. In this paper, we take a first step towards bridging this gap. We\nprovide a novel analysis on the convergence rates of a kNN classifier over\ntransformed features. This analysis requires in-depth understanding of the\nproperties that connect both the transformed space and the raw feature space.\nMore precisely, we build our convergence bound upon two key properties of the\ntransformed space: (1) safety -- how well can one recover the raw posterior\nfrom the transformed space, and (2) smoothness -- how complex this recovery\nfunction is. Based on our result, we are able to explain why some (pre-trained)\nfeature transformations are better suited for a kNN classifier than other. We\nempirically validate that both properties have an impact on the kNN convergence\non 30 feature transformations with 6 benchmark datasets spanning from the\nvision to the text domain.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:05:53 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Rimanic", "Luka", ""], ["Renggli", "Cedric", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""]]}, {"id": "2010.07853", "submitter": "Aditya Gangrade", "authors": "Aditya Gangrade, Anil Kag, Venkatesh Saligrama", "title": "Selective Classification via One-Sided Prediction", "comments": "v3: minor rewrites, an extra appendix on relationship to conformal\n  prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for selective classification (SC), a problem which\nallows a classifier to abstain from predicting some instances, thus trading off\naccuracy against coverage (the fraction of instances predicted). In contrast to\nprior gating or confidence-set based work, our proposed method optimises a\ncollection of class-wise decoupled one-sided empirical risks, and is in essence\na method for explicitly finding the largest decision sets for each class that\nhave few false positives. This one-sided prediction (OSP) based relaxation\nyields an SC scheme that attains near-optimal coverage in the practically\nrelevant high target accuracy regime, and further admits efficient\nimplementation, leading to a flexible and principled method for SC. We\ntheoretically derive generalization bounds for SC and OSP, and empirically we\nshow that our scheme strongly outperforms state of the art methods in coverage\nat small error levels.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:14:27 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 04:06:44 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 04:58:52 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Gangrade", "Aditya", ""], ["Kag", "Anil", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "2010.07860", "submitter": "David R\\\"ugamer", "authors": "Philipp F.M. Baumann, Torsten Hothorn and David R\\\"ugamer", "title": "Deep Conditional Transformation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the cumulative distribution function (CDF) of an outcome variable\nconditional on a set of features remains challenging, especially in\nhigh-dimensional settings. Conditional transformation models provide a\nsemi-parametric approach that allows to model a large class of conditional CDFs\nwithout an explicit parametric distribution assumption and with only a few\nparameters. Existing estimation approaches within this class are, however,\neither limited in their complexity and applicability to unstructured data\nsources such as images or text, lack interpretability, or are restricted to\ncertain types of outcomes. We close this gap by introducing the class of deep\nconditional transformation models which unifies existing approaches and allows\nto learn both interpretable (non-)linear model terms and more complex neural\nnetwork predictors in one holistic framework. To this end we propose a novel\nnetwork architecture, provide details on different model definitions and derive\nsuitable constraints as well as network regularization terms. We demonstrate\nthe efficacy of our approach through numerical experiments and applications.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:25:45 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 16:54:34 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 20:18:17 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 17:45:07 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Baumann", "Philipp F. M.", ""], ["Hothorn", "Torsten", ""], ["R\u00fcgamer", "David", ""]]}, {"id": "2010.07866", "submitter": "Shuxi Zeng", "authors": "Shuxi Zeng, Serge Assaad, Chenyang Tao, Shounak Datta, Lawrence Carin,\n  Fan Li", "title": "Double Robust Representation Learning for Counterfactual Prediction", "comments": "18 pages, 5 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference, or counterfactual prediction, is central to decision making\nin healthcare, policy and social sciences. To de-bias causal estimators with\nhigh-dimensional data in observational studies, recent advances suggest the\nimportance of combining machine learning models for both the propensity score\nand the outcome function. We propose a novel scalable method to learn\ndouble-robust representations for counterfactual predictions, leading to\nconsistent causal estimation if the model for either the propensity score or\nthe outcome, but not necessarily both, is correctly specified. Specifically, we\nuse the entropy balancing method to learn the weights that minimize the\nJensen-Shannon divergence of the representation between the treated and control\ngroups, based on which we make robust and efficient counterfactual predictions\nfor both individual and average treatment effects. We provide theoretical\njustifications for the proposed method. The algorithm shows competitive\nperformance with the state-of-the-art on real world and synthetic data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 16:39:26 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:32:28 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zeng", "Shuxi", ""], ["Assaad", "Serge", ""], ["Tao", "Chenyang", ""], ["Datta", "Shounak", ""], ["Carin", "Lawrence", ""], ["Li", "Fan", ""]]}, {"id": "2010.07915", "submitter": "Ayan Mukhopadhyay", "authors": "Tina Diao and Samriddhi Singla and Ayan Mukhopadhyay and Ahmed Eldawy\n  and Ross Shachter and Mykel Kochenderfer", "title": "Uncertainty Aware Wildfire Management", "comments": "Accepted at AI for Social Good Workshop, AAAI Fall Symposium Series\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent wildfires in the United States have resulted in loss of life and\nbillions of dollars, destroying countless structures and forests. Fighting\nwildfires is extremely complex. It is difficult to observe the true state of\nfires due to smoke and risk associated with ground surveillance. There are\nlimited resources to be deployed over a massive area and the spread of the fire\nis challenging to predict. This paper proposes a decision-theoretic approach to\ncombat wildfires. We model the resource allocation problem as a\npartially-observable Markov decision process. We also present a data-driven\nmodel that lets us simulate how fires spread as a function of relevant\ncovariates. A major problem in using data-driven models to combat wildfires is\nthe lack of comprehensive data sources that relate fires with relevant\ncovariates. We present an algorithmic approach based on large-scale raster and\nvector analysis that can be used to create such a dataset. Our data with over 2\nmillion data points is the first open-source dataset that combines existing\nfire databases with covariates extracted from satellite imagery. Through\nexperiments using real-world wildfire data, we demonstrate that our forecasting\nmodel can accurately model the spread of wildfires. Finally, we use simulations\nto demonstrate that our response strategy can significantly reduce response\ntimes compared to baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:47:31 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Diao", "Tina", ""], ["Singla", "Samriddhi", ""], ["Mukhopadhyay", "Ayan", ""], ["Eldawy", "Ahmed", ""], ["Shachter", "Ross", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "2010.07922", "submitter": "Jovana Mitrovic", "authors": "Jovana Mitrovic, Brian McWilliams, Jacob Walker, Lars Buesing, Charles\n  Blundell", "title": "Representation Learning via Invariant Causal Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning has emerged as a strategy to reduce the reliance on\ncostly supervised signal by pretraining representations only using unlabeled\ndata. These methods combine heuristic proxy classification tasks with data\naugmentations and have achieved significant success, but our theoretical\nunderstanding of this success remains limited. In this paper we analyze\nself-supervised representation learning using a causal framework. We show how\ndata augmentations can be more effectively utilized through explicit invariance\nconstraints on the proxy classifiers employed during pretraining. Based on\nthis, we propose a novel self-supervised objective, Representation Learning via\nInvariant Causal Mechanisms (ReLIC), that enforces invariant prediction of\nproxy targets across augmentations through an invariance regularizer which\nyields improved generalization guarantees. Further, using causality we\ngeneralize contrastive learning, a particular kind of self-supervised method,\nand provide an alternative theoretical explanation for the success of these\nmethods. Empirically, ReLIC significantly outperforms competing methods in\nterms of robustness and out-of-distribution generalization on ImageNet, while\nalso significantly outperforming these methods on Atari achieving above\nhuman-level performance on $51$ out of $57$ games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:53:37 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mitrovic", "Jovana", ""], ["McWilliams", "Brian", ""], ["Walker", "Jacob", ""], ["Buesing", "Lars", ""], ["Blundell", "Charles", ""]]}, {"id": "2010.07955", "submitter": "Tony Bonnaire", "authors": "T. Bonnaire, A. Decelle, N. Aghanim", "title": "Cascade of Phase Transitions for Multi-Scale Clustering", "comments": "8 pages, 5 figures, submitted to PRE", "journal-ref": "Phys. Rev. E 103, 012105 (2021)", "doi": "10.1103/PhysRevE.103.012105", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework exploiting the cascade of phase transitions\noccurring during a simulated annealing of the Expectation-Maximisation\nalgorithm to cluster datasets with multi-scale structures. Using the weighted\nlocal covariance, we can extract, a posteriori and without any prior knowledge,\ninformation on the number of clusters at different scales together with their\nsize. We also study the linear stability of the iterative scheme to derive the\nthreshold at which the first transition occurs and show how to approximate the\nnext ones. Finally, we combine simulated annealing together with recent\ndevelopments of regularised Gaussian mixture models to learn a principal graph\nfrom spatially structured datasets that can also exhibit many scales.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 18:01:37 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bonnaire", "T.", ""], ["Decelle", "A.", ""], ["Aghanim", "N.", ""]]}, {"id": "2010.07962", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji, Junjie Yang and Yingbin Liang", "title": "Bilevel Optimization: Nonasymptotic Analysis and Faster Algorithms", "comments": "37 pages, 18 figures, 2 tables. New results and codes have been\n  provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization has arisen as a powerful tool for many machine learning\nproblems such as meta-learning, hyperparameter optimization, and reinforcement\nlearning. In this paper, we investigate the nonconvex-strongly-convex bilevel\noptimization problem. For deterministic bilevel optimization, we provide a\ncomprehensive finite-time convergence analysis for two popular algorithms\nrespectively based on approximate implicit differentiation (AID) and iterative\ndifferentiation (ITD). For the AID-based method, we orderwisely improve the\nprevious finite-time convergence analysis due to a more practical parameter\nselection as well as a warm start strategy, and for the ITD-based method we\nestablish the first theoretical convergence rate. Our analysis also provides a\nquantitative comparison between ITD and AID based approaches. For stochastic\nbilevel optimization, we propose a novel algorithm named stocBiO, which\nfeatures a sample-efficient hypergradient estimator using efficient Jacobian-\nand Hessian-vector product computations. We provide the finite-time convergence\nguarantee for stocBiO, and show that stocBiO outperforms the best known\ncomputational complexities orderwisely with respect to the condition number\n$\\kappa$ and the target accuracy $\\epsilon$. We further validate our\ntheoretical results and demonstrate the efficiency of bilevel optimization\nalgorithms by the experiments on meta-learning and hyperparameter optimization.\nOur code for stocBiO and its comparison to other algorithms is available\nonline$^1$.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 18:09:48 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:16:06 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ji", "Kaiyi", ""], ["Yang", "Junjie", ""], ["Liang", "Yingbin", ""]]}, {"id": "2010.07964", "submitter": "Santiago Mazuelas", "authors": "Santiago Mazuelas and Andrea Zanoni and Aritz Perez", "title": "Minimax Classification with 0-1 Loss and Performance Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised classification techniques use training samples to find\nclassification rules with small expected 0-1 loss. Conventional methods achieve\nefficient learning and out-of-sample generalization by minimizing surrogate\nlosses over specific families of rules. This paper presents minimax risk\nclassifiers (MRCs) that do not rely on a choice of surrogate loss and family of\nrules. MRCs achieve efficient learning and out-of-sample generalization by\nminimizing worst-case expected 0-1 loss w.r.t. uncertainty sets that are\ndefined by linear constraints and include the true underlying distribution. In\naddition, MRCs' learning stage provides performance guarantees as lower and\nupper tight bounds for expected 0-1 loss. We also present MRCs' finite-sample\ngeneralization bounds in terms of training size and smallest minimax risk, and\nshow their competitive classification performance w.r.t. state-of-the-art\ntechniques using benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 18:11:28 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mazuelas", "Santiago", ""], ["Zanoni", "Andrea", ""], ["Perez", "Aritz", ""]]}, {"id": "2010.08007", "submitter": "Shashank Singh", "authors": "Shashank Singh", "title": "Continuum-Armed Bandits: A Function Space Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuum-armed bandits (a.k.a., black-box or $0^{th}$-order optimization)\ninvolves optimizing an unknown objective function given an oracle that\nevaluates the function at a query point, with the goal of using as few query\npoints as possible. In the most well-studied case, the objective function is\nassumed to be Lipschitz continuous and minimax rates of simple and cumulative\nregrets are known in both noiseless and noisy settings. This paper studies\ncontinuum-armed bandits under more general smoothness conditions, namely Besov\nsmoothness conditions, on the objective function. In both noiseless and noisy\nconditions, we derive minimax rates under simple and cumulative regrets. Our\nresults show that minimax rates over objective functions in a Besov space are\nidentical to minimax rates over objective functions in the smallest H\\\"older\nspace into which the Besov space embeds.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 20:21:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:50:03 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 20:22:25 GMT"}, {"version": "v4", "created": "Sun, 21 Mar 2021 22:22:25 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Singh", "Shashank", ""]]}, {"id": "2010.08012", "submitter": "Agnieszka Maria S{\\l}owik", "authors": "Alex Lamb, Anirudh Goyal, Agnieszka S{\\l}owik, Michael Mozer, Philippe\n  Beaudoin, Yoshua Bengio", "title": "Neural Function Modules with Sparse Arguments: A Dynamic Approach to\n  Integrating Information across Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward neural networks consist of a sequence of layers, in which each\nlayer performs some processing on the information from the previous layer. A\ndownside to this approach is that each layer (or module, as multiple modules\ncan operate in parallel) is tasked with processing the entire hidden state,\nrather than a particular part of the state which is most relevant for that\nmodule. Methods which only operate on a small number of input variables are an\nessential part of most programming languages, and they allow for improved\nmodularity and code re-usability. Our proposed method, Neural Function Modules\n(NFM), aims to introduce the same structural capability into deep learning.\nMost of the work in the context of feed-forward networks combining top-down and\nbottom-up feedback is limited to classification problems. The key contribution\nof our work is to combine attention, sparsity, top-down and bottom-up feedback,\nin a flexible algorithm which, as we show, improves the results in standard\nclassification, out-of-domain generalization, generative modeling, and learning\nrepresentations in the context of reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 20:43:17 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lamb", "Alex", ""], ["Goyal", "Anirudh", ""], ["S\u0142owik", "Agnieszka", ""], ["Mozer", "Michael", ""], ["Beaudoin", "Philippe", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2010.08029", "submitter": "Matt Shannon", "authors": "Matt Shannon, Ben Poole, Soroosh Mariooryad, Tom Bagby, Eric\n  Battenberg, David Kao, Daisy Stanton, RJ Skerry-Ryan", "title": "Non-saturating GAN training as divergence minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-saturating generative adversarial network (GAN) training is widely used\nand has continued to obtain groundbreaking results. However so far this\napproach has lacked strong theoretical justification, in contrast to\nalternatives such as f-GANs and Wasserstein GANs which are motivated in terms\nof approximate divergence minimization. In this paper we show that\nnon-saturating GAN training does in fact approximately minimize a particular\nf-divergence. We develop general theoretical tools to compare and classify\nf-divergences and use these to show that the new f-divergence is qualitatively\nsimilar to reverse KL. These results help to explain the high sample quality\nbut poor diversity often observed empirically when using this scheme.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 21:34:56 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Shannon", "Matt", ""], ["Poole", "Ben", ""], ["Mariooryad", "Soroosh", ""], ["Bagby", "Tom", ""], ["Battenberg", "Eric", ""], ["Kao", "David", ""], ["Stanton", "Daisy", ""], ["Skerry-Ryan", "RJ", ""]]}, {"id": "2010.08048", "submitter": "Ziping Xu", "authors": "Ziping Xu, Amirhossein Meisami, Ambuj Tewari", "title": "Decision Making Problems with Funnel Structure: A Multi-Task Learning\n  Approach with Application to Email Marketing Campaigns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the decision making problem with Funnel Structure. Funnel\nstructure, a well-known concept in the marketing field, occurs in those systems\nwhere the decision maker interacts with the environment in a layered manner\nreceiving far fewer observations from deep layers than shallow ones. For\nexample, in the email marketing campaign application, the layers correspond to\nOpen, Click and Purchase events. Conversions from Click to Purchase happen very\ninfrequently because a purchase cannot be made unless the link in an email is\nclicked on.\n  We formulate this challenging decision making problem as a contextual bandit\nwith funnel structure and develop a multi-task learning algorithm that\nmitigates the lack of sufficient observations from deeper layers. We analyze\nboth the prediction error and the regret of our algorithms. We verify our\ntheory on prediction errors through a simple simulation. Experiments on both a\nsimulated environment and an environment based on real-world data from a major\nemail marketing company show that our algorithms offer significant improvement\nover previous methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 22:30:03 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 01:32:41 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Xu", "Ziping", ""], ["Meisami", "Amirhossein", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2010.08061", "submitter": "Xuedong Shang", "authors": "Xuedong Shang, Han Shao, Jian Qian", "title": "Stochastic Bandits with Vector Losses: Minimizing $\\ell^\\infty$-Norm of\n  Relative Losses", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-armed bandits are widely applied in scenarios like recommender systems,\nfor which the goal is to maximize the click rate. However, more factors should\nbe considered, e.g., user stickiness, user growth rate, user experience\nassessment, etc. In this paper, we model this situation as a problem of\n$K$-armed bandit with multiple losses. We define relative loss vector of an arm\nwhere the $i$-th entry compares the arm and the optimal arm with respect to the\n$i$-th loss. We study two goals: (a) finding the arm with the minimum\n$\\ell^\\infty$-norm of relative losses with a given confidence level (which\nrefers to fixed-confidence best-arm identification); (b) minimizing the\n$\\ell^\\infty$-norm of cumulative relative losses (which refers to regret\nminimization). For goal (a), we derive a problem-dependent sample complexity\nlower bound and discuss how to achieve matching algorithms. For goal (b), we\nprovide a regret lower bound of $\\Omega(T^{2/3})$ and provide a matching\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 23:03:35 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Shang", "Xuedong", ""], ["Shao", "Han", ""], ["Qian", "Jian", ""]]}, {"id": "2010.08097", "submitter": "Lam Ho", "authors": "Vu Dinh, Lam Si Tung Ho", "title": "Consistent Feature Selection for Analytic Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important steps toward interpretability and explainability of\nneural network models is feature selection, which aims to identify the subset\nof relevant features. Theoretical results in the field have mostly focused on\nthe prediction aspect of the problem with virtually no work on feature\nselection consistency for deep neural networks due to the model's severe\nnonlinearity and unidentifiability. This lack of theoretical foundation casts\ndoubt on the applicability of deep learning to contexts where correct\ninterpretations of the features play a central role.\n  In this work, we investigate the problem of feature selection for analytic\ndeep networks. We prove that for a wide class of networks, including deep\nfeed-forward neural networks, convolutional neural networks, and a major\nsub-class of residual neural networks, the Adaptive Group Lasso selection\nprocedure with Group Lasso as the base estimator is selection-consistent. The\nwork provides further evidence that Group Lasso might be inefficient for\nfeature selection with neural networks and advocates the use of Adaptive Group\nLasso over the popular Group Lasso.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 01:59:53 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Dinh", "Vu", ""], ["Ho", "Lam Si Tung", ""]]}, {"id": "2010.08120", "submitter": "Madeline Navarro", "authors": "Madeline Navarro, Yuhao Wang, Antonio G. Marques, Caroline Uhler,\n  Santiago Segarra", "title": "Joint Inference of Multiple Graphs from Matrix Polynomials", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring graph structure from observations on the nodes is an important and\npopular network science task. Departing from the more common inference of a\nsingle graph and motivated by social and biological networks, we study the\nproblem of jointly inferring multiple graphs from the observation of signals at\ntheir nodes (graph signals), which are assumed to be stationary in the sought\ngraphs. From a mathematical point of view, graph stationarity implies that the\nmapping between the covariance of the signals and the sparse matrix\nrepresenting the underlying graph is given by a matrix polynomial. A prominent\nexample is that of Markov random fields, where the inverse of the covariance\nyields the sparse matrix of interest. From a modeling perspective, stationary\ngraph signals can be used to model linear network processes evolving on a set\nof (not necessarily known) networks. Leveraging that matrix polynomials\ncommute, a convex optimization method along with sufficient conditions that\nguarantee the recovery of the true graphs are provided when perfect covariance\ninformation is available. Particularly important from an empirical viewpoint,\nwe provide high-probability bounds on the recovery error as a function of the\nnumber of signals observed and other key problem parameters. Numerical\nexperiments using synthetic and real-world data demonstrate the effectiveness\nof the proposed method with perfect covariance information as well as its\nrobustness in the noisy regime.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:45:15 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Navarro", "Madeline", ""], ["Wang", "Yuhao", ""], ["Marques", "Antonio G.", ""], ["Uhler", "Caroline", ""], ["Segarra", "Santiago", ""]]}, {"id": "2010.08127", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Behnam Neyshabur, Hanie Sedghi", "title": "The Deep Bootstrap Framework: Good Online Learners are Good Offline\n  Generalizers", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for reasoning about generalization in deep\nlearning. The core idea is to couple the Real World, where optimizers take\nstochastic gradient steps on the empirical loss, to an Ideal World, where\noptimizers take steps on the population loss. This leads to an alternate\ndecomposition of test error into: (1) the Ideal World test error plus (2) the\ngap between the two worlds. If the gap (2) is universally small, this reduces\nthe problem of generalization in offline learning to the problem of\noptimization in online learning. We then give empirical evidence that this gap\nbetween worlds can be small in realistic deep learning settings, in particular\nsupervised image classification. For example, CNNs generalize better than MLPs\non image distributions in the Real World, but this is \"because\" they optimize\nfaster on the population loss in the Ideal World. This suggests our framework\nis a useful tool for understanding generalization in deep learning, and lays a\nfoundation for future research in the area.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 03:07:49 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 03:24:24 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Neyshabur", "Behnam", ""], ["Sedghi", "Hanie", ""]]}, {"id": "2010.08148", "submitter": "Yiming Xu", "authors": "Braxton Osting, Dong Wang, Yiming Xu and Dominique Zosso", "title": "Consistency of archetypal analysis", "comments": "30 pages, 9 figures; add some details to the proof of Lemma 2.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archetypal analysis is an unsupervised learning method that uses a convex\npolytope to summarize multivariate data. For fixed $k$, the method finds a\nconvex polytope with $k$ vertices, called archetype points, such that the\npolytope is contained in the convex hull of the data and the mean squared\ndistance between the data and the polytope is minimal. In this paper, we prove\na consistency result that shows if the data is independently sampled from a\nprobability measure with bounded support, then the archetype points converge to\na solution of the continuum version of the problem, of which we identify and\nestablish several properties. We also obtain the convergence rate of the\noptimal objective values under appropriate assumptions on the distribution. If\nthe data is independently sampled from a distribution with unbounded support,\nwe also prove a consistency result for a modified method that penalizes the\ndispersion of the archetype points. Our analysis is supported by detailed\ncomputational experiments of the archetype points for data sampled from the\nuniform distribution in a disk, the normal distribution, an annular\ndistribution, and a Gaussian mixture model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 04:07:26 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 14:11:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Osting", "Braxton", ""], ["Wang", "Dong", ""], ["Xu", "Yiming", ""], ["Zosso", "Dominique", ""]]}, {"id": "2010.08236", "submitter": "Oscar Hernan Madrid Padilla", "authors": "Oscar Hernan Madrid Padilla, Wesley Tansey, Yanzhen Chen", "title": "Quantile regression with deep ReLU Networks: Estimators and minimax\n  rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile regression is the task of estimating a specified percentile\nresponse, such as the median, from a collection of known covariates. We study\nquantile regression with rectified linear unit (ReLU) neural networks as the\nchosen model class. We derive an upper bound on the expected mean squared error\nof a ReLU network used to estimate any quantile conditional on a set of\ncovariates. This upper bound only depends on the best possible approximation\nerror, the number of layers in the network, and the number of nodes per layer.\nWe further show upper bounds that are tight for two large classes of functions:\ncompositions of H\\\"older functions and members of a Besov space. These tight\nbounds imply ReLU networks with quantile regression achieve minimax rates for\nbroad collections of function types. Unlike existing work, the theoretical\nresults hold under minimal assumptions and apply to general error\ndistributions, including heavy-tailed distributions. Empirical simulations on a\nsuite of synthetic response functions demonstrate the theoretical results\ntranslate to practical implementations of ReLU networks. Overall, the\ntheoretical and empirical results provide insight into the strong performance\nof ReLU neural networks for quantile regression across a broad range of\nfunction classes and error distributions. All code for this paper is publicly\navailable at https://github.com/tansey/quantile-regression.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:34:04 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 10:20:07 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 11:39:50 GMT"}, {"version": "v4", "created": "Tue, 27 Oct 2020 04:53:49 GMT"}, {"version": "v5", "created": "Fri, 18 Dec 2020 02:40:16 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Padilla", "Oscar Hernan Madrid", ""], ["Tansey", "Wesley", ""], ["Chen", "Yanzhen", ""]]}, {"id": "2010.08244", "submitter": "Baifeng Shi", "authors": "Baifeng Shi, Judy Hoffman, Kate Saenko, Trevor Darrell, Huijuan Xu", "title": "Auxiliary Task Reweighting for Minimum-data Learning", "comments": "NeurIPS 2020. Project page:\n  https://sites.google.com/view/auxiliary-task-reweighting/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning requires a large amount of training data, limiting its\napplication where labeled data is scarce. To compensate for data scarcity, one\npossible method is to utilize auxiliary tasks to provide additional supervision\nfor the main task. Assigning and optimizing the importance weights for\ndifferent auxiliary tasks remains an crucial and largely understudied research\nquestion. In this work, we propose a method to automatically reweight auxiliary\ntasks in order to reduce the data requirement on the main task. Specifically,\nwe formulate the weighted likelihood function of auxiliary tasks as a surrogate\nprior for the main task. By adjusting the auxiliary task weights to minimize\nthe divergence between the surrogate prior and the true prior of the main task,\nwe obtain a more accurate prior estimation, achieving the goal of minimizing\nthe required amount of training data for the main task and avoiding a costly\ngrid search. In multiple experimental settings (e.g. semi-supervised learning,\nmulti-label classification), we demonstrate that our algorithm can effectively\nutilize limited labeled data of the main task with the benefit of auxiliary\ntasks compared with previous task reweighting methods. We also show that under\nextreme cases with only a few extra examples (e.g. few-shot domain adaptation),\nour algorithm results in significant improvement over the baseline.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:45:37 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Shi", "Baifeng", ""], ["Hoffman", "Judy", ""], ["Saenko", "Kate", ""], ["Darrell", "Trevor", ""], ["Xu", "Huijuan", ""]]}, {"id": "2010.08258", "submitter": "Fan Bao", "authors": "Fan Bao, Kun Xu, Chongxuan Li, Lanqing Hong, Jun Zhu, Bo Zhang", "title": "Variational (Gradient) Estimate of the Score Function in Energy-based\n  Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning and evaluation of energy-based latent variable models (EBLVMs)\nwithout any structural assumptions are highly challenging, because the true\nposteriors and the partition functions in such models are generally\nintractable. This paper presents variational estimates of the score function\nand its gradient with respect to the model parameters in a general EBLVM,\nreferred to as VaES and VaGES respectively. The variational posterior is\ntrained to minimize a certain divergence to the true model posterior and the\nbias in both estimates can be bounded by the divergence theoretically. With a\nminimal model assumption, VaES and VaGES can be applied to the kernelized Stein\ndiscrepancy (KSD) and score matching (SM)-based methods to learn EBLVMs.\nBesides, VaES can also be used to estimate the exact Fisher divergence between\nthe data and general EBLVMs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 09:20:52 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 03:10:51 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 13:26:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bao", "Fan", ""], ["Xu", "Kun", ""], ["Li", "Chongxuan", ""], ["Hong", "Lanqing", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "2010.08270", "submitter": "Nicolas Keriven", "authors": "Hashem Ghanem and Nicolas Keriven and Nicolas Tremblay", "title": "Fast Graph Kernel with Optical Random Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graphlet kernel is a classical method in graph classification. It however\nsuffers from a high computation cost due to the isomorphism test it includes.\nAs a generic proxy, and in general at the cost of losing some information, this\ntest can be efficiently replaced by a user-defined mapping that computes\nvarious graph characteristics. In this paper, we propose to leverage kernel\nrandom features within the graphlet framework, and establish a theoretical link\nwith a mean kernel metric. If this method can still be prohibitively costly for\nusual random features, we then incorporate optical random features that can be\ncomputed in constant time. Experiments show that the resulting algorithm is\norders of magnitude faster that the graphlet kernel for the same, or better,\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 09:43:47 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ghanem", "Hashem", ""], ["Keriven", "Nicolas", ""], ["Tremblay", "Nicolas", ""]]}, {"id": "2010.08349", "submitter": "Francesco Romor", "authors": "Francesco Romor, Marco Tezzele, Gianluigi Rozza", "title": "Multi-fidelity data fusion for the approximation of scalar functions\n  with low intrinsic dimensionality through active subspaces", "comments": null, "journal-ref": null, "doi": "10.1002/pamm.202000349", "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are employed for non-parametric regression in a Bayesian\nsetting. They generalize linear regression, embedding the inputs in a latent\nmanifold inside an infinite-dimensional reproducing kernel Hilbert space. We\ncan augment the inputs with the observations of low-fidelity models in order to\nlearn a more expressive latent manifold and thus increment the model's\naccuracy. This can be realized recursively with a chain of Gaussian processes\nwith incrementally higher fidelity. We would like to extend these\nmulti-fidelity model realizations to case studies affected by a\nhigh-dimensional input space but with low intrinsic dimensionality. In this\ncases physical supported or purely numerical low-order models are still\naffected by the curse of dimensionality when queried for responses. When the\nmodel's gradient information is provided, the presence of an active subspace\ncan be exploited to design low-fidelity response surfaces and thus enable\nGaussian process multi-fidelity regression, without the need to perform new\nsimulations. This is particularly useful in the case of data scarcity. In this\nwork we present a multi-fidelity approach involving active subspaces and we\ntest it on two different high-dimensional benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 12:35:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Romor", "Francesco", ""], ["Tezzele", "Marco", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "2010.08354", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel and Arthur Mensch and Jean-Philippe Vert", "title": "Differentiable Divergences Between Time Series", "comments": "V3: AISTATS 2021 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the discrepancy between time series of variable sizes is\nnotoriously challenging. While dynamic time warping (DTW) is popularly used for\nthis purpose, it is not differentiable everywhere and is known to lead to bad\nlocal optima when used as a \"loss\". Soft-DTW addresses these issues, but it is\nnot a positive definite divergence: due to the bias introduced by entropic\nregularization, it can be negative and it is not minimized when the time series\nare equal. We propose in this paper a new divergence, dubbed soft-DTW\ndivergence, which aims to correct these issues. We study its properties; in\nparticular, under conditions on the ground cost, we show that it is a valid\ndivergence: it is non-negative and minimized if and only if the two time series\nare equal. We also propose a new \"sharp\" variant by further removing entropic\nbias. We showcase our divergences on time series averaging and demonstrate\nsignificant accuracy improvements compared to both DTW and soft-DTW on 84 time\nseries classification datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 12:45:13 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:28:34 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 23:13:18 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Blondel", "Mathieu", ""], ["Mensch", "Arthur", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2010.08376", "submitter": "Beate Sick", "authors": "Lucas Kook, Lisa Herzog, Torsten Hothorn, Oliver D\\\"urr, Beate Sick", "title": "Deep and interpretable regression models for ordinal outcomes", "comments": "41 pages (incl. appendix, figures and literature), 11 figures in main\n  text, 4 figures in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Outcomes with a natural order commonly occur in prediction tasks and often\nthe available input data are a mixture of complex data like images and tabular\npredictors. Deep Learning (DL) models are state-of-the-art for image\nclassification tasks but frequently treat ordinal outcomes as unordered and\nlack interpretability. In contrast, classical ordinal regression models\nconsider the outcome's order and yield interpretable predictor effects but are\nlimited to tabular data. We present ordinal neural network transformation\nmodels (ONTRAMs), which unite DL with classical ordinal regression approaches.\nONTRAMs are a special case of transformation models and trade off flexibility\nand interpretability by additively decomposing the transformation function into\nterms for image and tabular data using jointly trained neural networks. The\nperformance of the most flexible ONTRAM is by definition equivalent to a\nstandard multi-class DL model trained with cross-entropy while being faster in\ntraining when facing ordinal outcomes. Lastly, we discuss how to interpret\nmodel components for both tabular and image data on two publicly available\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 13:27:34 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 10:32:08 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 13:50:05 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 15:09:52 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Kook", "Lucas", ""], ["Herzog", "Lisa", ""], ["Hothorn", "Torsten", ""], ["D\u00fcrr", "Oliver", ""], ["Sick", "Beate", ""]]}, {"id": "2010.08407", "submitter": "Mike Ludkovski", "authors": "Mike Ludkovski and Yuri Saporito", "title": "KrigHedge: Gaussian Process Surrogates for Delta Hedging", "comments": "29 pages, 6 figures, plus RMarkdown supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a machine learning approach to option Greeks approximation\nbased on Gaussian process (GP) surrogates. The method takes in noisily observed\noption prices, fits a nonparametric input-output map and then analytically\ndifferentiates the latter to obtain the various price sensitivities. Our\nmotivation is to compute Greeks in cases where direct computation is expensive,\nsuch as in local volatility models, or can only ever be done approximately. We\nprovide a detailed analysis of numerous aspects of GP surrogates, including\nchoice of kernel family, simulation design, choice of trend function and impact\nof noise.\n  We further discuss the application to Delta hedging, including a new Lemma\nthat relates quality of the Delta approximation to discrete-time hedging loss.\nResults are illustrated with two extensive case studies that consider\nestimation of Delta, Theta and Gamma and benchmark approximation quality and\nuncertainty quantification using a variety of statistical metrics. Among our\nkey take-aways are the recommendation to use Matern kernels, the benefit of\nincluding virtual training points to capture boundary conditions, and the\nsignificant loss of fidelity when training on stock-path-based datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 14:08:13 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 13:05:53 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 17:20:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ludkovski", "Mike", ""], ["Saporito", "Yuri", ""]]}, {"id": "2010.08418", "submitter": "Goran \\v{Z}u\\v{z}i\\'c", "authors": "Goran Zuzic, Di Wang, Aranyak Mehta, D. Sivakumar", "title": "Learning Robust Algorithms for Online Allocation Problems Using\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of finding algorithms for online allocation (i.e.\nbipartite matching) using a machine learning approach. In this paper, we focus\non the AdWords problem, which is a classical online budgeted matching problem\nof both theoretical and practical significance. In contrast to existing work,\nour goal is to accomplish algorithm design {\\em tabula rasa}, i.e., without any\nhuman-provided insights or expert-tuned training data beyond specifying the\nobjective and constraints of the optimization problem. We construct a framework\nbased on insights and ideas from game theory, adversarial training and GANs Key\nto our approach is to generate adversarial examples that expose the weakness of\nany given algorithm. A unique challenge in our context is to generate complete\nexamples from scratch rather than perturbing given examples and we demonstrate\nthis can be accomplished for the Adwords problem. We use this framework to\nco-train an algorithm network and an adversarial network against each other\nuntil they converge to an equilibrium. This approach finds algorithms and\nadversarial examples that are consistent with known optimal results. Secondly,\nwe address the question of robustness of the algorithm, namely can we design\nalgorithms that are both strong under practical distributions, as well as\nexhibit robust performance against adversarial instances. To accomplish this,\nwe train algorithm networks using a mixture of adversarial and practical\ndistributions like power-laws; the resulting networks exhibit a smooth\ntrade-off between the two input regimes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 14:33:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zuzic", "Goran", ""], ["Wang", "Di", ""], ["Mehta", "Aranyak", ""], ["Sivakumar", "D.", ""]]}, {"id": "2010.08463", "submitter": "Andrii Babii", "authors": "Andrii Babii and Xi Chen and Eric Ghysels and Rohit Kumar", "title": "Binary Choice with Asymmetric Loss in a Data-Rich Environment: Theory\n  and an Application to Racial Justice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of asymmetries in prediction problems arising in economics has\nbeen recognized for a long time. In this paper, we focus on binary choice\nproblems in a data-rich environment with general loss functions. In contrast to\nthe asymmetric regression problems, the binary choice with general loss\nfunctions and high-dimensional datasets is challenging and not well understood.\nEconometricians have studied binary choice problems for a long time, but the\nliterature does not offer computationally attractive solutions in data-rich\nenvironments. In contrast, the machine learning literature has many\ncomputationally attractive algorithms that form the basis for much of the\nautomated procedures that are implemented in practice, but it is focused on\nsymmetric loss functions that are independent of individual characteristics.\nOne of the main contributions of our paper is to show that the theoretically\nvalid predictions of binary outcomes with arbitrary loss functions can be\nachieved via a very simple reweighting of the logistic regression, or other\nstate-of-the-art machine learning techniques, such as boosting or (deep) neural\nnetworks. We apply our analysis to racial justice in pretrial detention.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:01:20 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 23:14:42 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 18:32:22 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Babii", "Andrii", ""], ["Chen", "Xi", ""], ["Ghysels", "Eric", ""], ["Kumar", "Rohit", ""]]}, {"id": "2010.08479", "submitter": "Phil Long", "authors": "Peter L. Bartlett and Philip M. Long", "title": "Failures of model-dependent generalization bounds for least-norm\n  interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider bounds on the generalization performance of the least-norm linear\nregressor, in the over-parameterized regime where it can interpolate the data.\nWe describe a sense in which any generalization bound of a type that is\ncommonly proved in statistical learning theory must sometimes be very loose\nwhen applied to analyze the least-norm interpolant. In particular, for a\nvariety of natural joint distributions on training examples, any valid\ngeneralization bound that depends only on the output of the learning algorithm,\nthe number of training examples, and the confidence parameter, and that\nsatisfies a mild condition (substantially weaker than monotonicity in sample\nsize), must sometimes be very loose -- it can be bounded below by a constant\nwhen the true excess risk goes to zero.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:30:05 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 23:12:30 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 17:05:24 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Long", "Philip M.", ""]]}, {"id": "2010.08488", "submitter": "Takuo Matsubara", "authors": "Takuo Matsubara and Chris J. Oates and Fran\\c{c}ois-Xavier Briol", "title": "The Ridgelet Prior: A Covariance Function Approach to Prior\n  Specification for Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks attempt to combine the strong predictive performance\nof neural networks with formal quantification of uncertainty associated with\nthe predictive output in the Bayesian framework. However, it remains unclear\nhow to endow the parameters of the network with a prior distribution that is\nmeaningful when lifted into the output space of the network. A possible\nsolution is proposed that enables the user to posit an appropriate Gaussian\nprocess covariance function for the task at hand. Our approach constructs a\nprior distribution for the parameters of the network, called a ridgelet prior,\nthat approximates the posited Gaussian process in the output space of the\nnetwork. In contrast to existing work on the connection between neural networks\nand Gaussian processes, our analysis is non-asymptotic, with finite sample-size\nerror bounds provided. This establishes the universality property that a\nBayesian neural network can approximate any Gaussian process whose covariance\nfunction is sufficiently regular. Our experimental assessment is limited to a\nproof-of-concept, where we demonstrate that the ridgelet prior can out-perform\nan unstructured prior on regression problems for which a suitable Gaussian\nprocess prior can be provided.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:39:45 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 09:42:34 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 12:30:45 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Matsubara", "Takuo", ""], ["Oates", "Chris J.", ""], ["Briol", "Fran\u00e7ois-Xavier", ""]]}, {"id": "2010.08508", "submitter": "Yamini Bansal", "authors": "Yamini Bansal, Gal Kaplun, Boaz Barak", "title": "For self-supervised learning, Rationality implies generalization,\n  provably", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new upper bound on the generalization gap of classifiers that are\nobtained by first using self-supervision to learn a representation $r$ of the\ntraining data, and then fitting a simple (e.g., linear) classifier $g$ to the\nlabels. Specifically, we show that (under the assumptions described below) the\ngeneralization gap of such classifiers tends to zero if $\\mathsf{C}(g) \\ll n$,\nwhere $\\mathsf{C}(g)$ is an appropriately-defined measure of the simple\nclassifier $g$'s complexity, and $n$ is the number of training samples. We\nstress that our bound is independent of the complexity of the representation\n$r$. We do not make any structural or conditional-independence assumptions on\nthe representation-learning task, which can use the same training dataset that\nis later used for classification. Rather, we assume that the training procedure\nsatisfies certain natural noise-robustness (adding small amount of label noise\ncauses small degradation in performance) and rationality (getting the wrong\nlabel is not better than getting no label at all) conditions that widely hold\nacross many standard architectures. We show that our bound is non-vacuous for\nmany popular representation-learning based classifiers on CIFAR-10 and\nImageNet, including SimCLR, AMDIM and MoCo.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:07:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Bansal", "Yamini", ""], ["Kaplun", "Gal", ""], ["Barak", "Boaz", ""]]}, {"id": "2010.08515", "submitter": "Zhiyuan Li", "authors": "Zhiyuan Li, Yi Zhang, Sanjeev Arora", "title": "Why Are Convolutional Nets More Sample-Efficient than Fully-Connected\n  Nets?", "comments": "24 pages, 1 figure; Accepted by ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks often dominate fully-connected counterparts in\ngeneralization performance, especially on image classification tasks. This is\noften explained in terms of 'better inductive bias'. However, this has not been\nmade mathematically rigorous, and the hurdle is that the fully connected net\ncan always simulate the convolutional net (for a fixed task). Thus the training\nalgorithm plays a role. The current work describes a natural task on which a\nprovable sample complexity gap can be shown, for standard training algorithms.\nWe construct a single natural distribution on $\\mathbb{R}^d\\times\\{\\pm 1\\}$ on\nwhich any orthogonal-invariant algorithm (i.e. fully-connected networks trained\nwith most gradient-based methods from gaussian initialization) requires\n$\\Omega(d^2)$ samples to generalize while $O(1)$ samples suffice for\nconvolutional architectures. Furthermore, we demonstrate a single target\nfunction, learning which on all possible distributions leads to an $O(1)$ vs\n$\\Omega(d^2/\\varepsilon)$ gap. The proof relies on the fact that SGD on\nfully-connected network is orthogonal equivariant. Similar results are achieved\nfor $\\ell_2$ regression and adaptive training algorithms, e.g. Adam and\nAdaGrad, which are only permutation equivariant.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:15:39 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 17:54:15 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Li", "Zhiyuan", ""], ["Zhang", "Yi", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.08529", "submitter": "Tianyi Yao", "authors": "Tianyi Yao and Genevera I. Allen", "title": "Feature Selection for Huge Data via Minipatch Learning", "comments": "Updated theoretical statements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Feature selection often leads to increased model interpretability, faster\ncomputation, and improved model performance by discarding irrelevant or\nredundant features. While feature selection is a well-studied problem with many\nwidely-used techniques, there are typically two key challenges: i) many\nexisting approaches become computationally intractable in huge-data settings\nwith millions of observations and features; and ii) the statistical accuracy of\nselected features degrades in high-noise, high-correlation settings, thus\nhindering reliable model interpretation. We tackle these problems by proposing\nStable Minipatch Selection (STAMPS) and Adaptive STAMPS (AdaSTAMPS). These are\nmeta-algorithms that build ensembles of selection events of base feature\nselectors trained on many tiny, (adaptively-chosen) random subsets of both the\nobservations and features of the data, which we call minipatches. Our\napproaches are general and can be employed with a variety of existing feature\nselection strategies and machine learning techniques. In addition, we provide\ntheoretical insights on STAMPS and empirically demonstrate that our approaches,\nespecially AdaSTAMPS, dominate competing methods in terms of feature selection\naccuracy and computational time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:41:08 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 23:40:25 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Yao", "Tianyi", ""], ["Allen", "Genevera I.", ""]]}, {"id": "2010.08531", "submitter": "Tianjun Zhang", "authors": "Tianjun Zhang, Huazhe Xu, Xiaolong Wang, Yi Wu, Kurt Keutzer, Joseph\n  E. Gonzalez, Yuandong Tian", "title": "Multi-Agent Collaboration via Reward Attribution Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in multi-agent reinforcement learning (MARL) have achieved\nsuper-human performance in games like Quake 3 and Dota 2. Unfortunately, these\ntechniques require orders-of-magnitude more training rounds than humans and\ndon't generalize to new agent configurations even on the same game. In this\nwork, we propose Collaborative Q-learning (CollaQ) that achieves\nstate-of-the-art performance in the StarCraft multi-agent challenge and\nsupports ad hoc team play. We first formulate multi-agent collaboration as a\njoint optimization on reward assignment and show that each agent has an\napproximately optimal policy that decomposes into two parts: one part that only\nrelies on the agent's own state, and the other part that is related to states\nof nearby agents. Following this novel finding, CollaQ decomposes the\nQ-function of each agent into a self term and an interactive term, with a\nMulti-Agent Reward Attribution (MARA) loss that regularizes the training.\nCollaQ is evaluated on various StarCraft maps and shows that it outperforms\nexisting state-of-the-art techniques (i.e., QMIX, QTRAN, and VDN) by improving\nthe win rate by 40% with the same number of samples. In the more challenging ad\nhoc team play setting (i.e., reweight/add/remove units without re-training or\nfinetuning), CollaQ outperforms previous SoTA by over 30%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:42:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Tianjun", ""], ["Xu", "Huazhe", ""], ["Wang", "Xiaolong", ""], ["Wu", "Yi", ""], ["Keutzer", "Kurt", ""], ["Gonzalez", "Joseph E.", ""], ["Tian", "Yuandong", ""]]}, {"id": "2010.08625", "submitter": "Ehsan Amid", "authors": "Manfred K. Warmuth, Wojciech Kot{\\l}owski, Ehsan Amid", "title": "A case where a spindly two-layer linear network whips any neural network\n  with a fully connected input layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was conjectured that any neural network of any structure and arbitrary\ndifferentiable transfer functions at the nodes cannot learn the following\nproblem sample efficiently when trained with gradient descent: The instances\nare the rows of a $d$-dimensional Hadamard matrix and the target is one of the\nfeatures, i.e. very sparse. We essentially prove this conjecture: We show that\nafter receiving a random training set of size $k < d$, the expected square loss\nis still $1-\\frac{k}{(d-1)}$. The only requirement needed is that the input\nlayer is fully connected and the initial weight vectors of the input nodes are\nchosen from a rotation invariant distribution.\n  Surprisingly the same type of problem can be solved drastically more\nefficient by a simple 2-layer linear neural network in which the $d$ inputs are\nconnected to the output node by chains of length 2 (Now the input layer has\nonly one edge per input). When such a network is trained by gradient descent,\nthen it has been shown that its expected square loss is $\\frac{\\log d}{k}$.\n  Our lower bounds essentially show that a sparse input layer is needed to\nsample efficiently learn sparse targets with gradient descent when the number\nof examples is less than the number of input features.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 20:49:58 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Warmuth", "Manfred K.", ""], ["Kot\u0142owski", "Wojciech", ""], ["Amid", "Ehsan", ""]]}, {"id": "2010.08626", "submitter": "Daniel Chen", "authors": "Daniel Chen, Yekun Xu, Betis Baheri, Chuan Bi, Ying Mao, Qiang Quan,\n  Shuai Xu", "title": "Quantum-Inspired Classical Algorithm for Principal Component Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a sublinear classical algorithm for principal component\nregression. The algorithm uses quantum-inspired linear algebra, an idea\ndeveloped by Tang. Using this technique, her algorithm for recommendation\nsystems achieved runtime only polynomially slower than its quantum counterpart.\nHer work was quickly adapted to solve many other problems in sublinear time\ncomplexity. In this work, we developed an algorithm for principal component\nregression that runs in time polylogarithmic to the number of data points, an\nexponential speed up over the state-of-the-art algorithm, under the mild\nassumption that the input is given in some data structure that supports a\nnorm-based sampling procedure. This exponential speed up allows for potential\napplications in much larger data sets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 20:50:48 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Daniel", ""], ["Xu", "Yekun", ""], ["Baheri", "Betis", ""], ["Bi", "Chuan", ""], ["Mao", "Ying", ""], ["Quan", "Qiang", ""], ["Xu", "Shuai", ""]]}, {"id": "2010.08627", "submitter": "Qiuyun Zhu", "authors": "Qiuyun Zhu, Yves Atchade", "title": "Minimax Quasi-Bayesian estimation in sparse canonical correlation\n  analysis via a Rayleigh quotient function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) is a popular statistical technique for\nexploring the relationship between datasets. The estimation of sparse canonical\ncorrelation vectors has emerged in recent years as an important but challenging\nvariation of the CCA problem, with widespread applications. Currently available\nrate-optimal estimators for sparse canonical correlation vectors are expensive\nto compute. We propose a quasi-Bayesian estimation procedure that achieves the\nminimax estimation rate, and yet is easy to compute by Markov Chain Monte Carlo\n(MCMC). The method builds on ([37]) and uses a re-scaled Rayleigh quotient\nfunction as a quasi-log-likelihood. However unlike these authors, we adopt a\nBayesian framework that combines this quasi-log-likelihood with a\nspike-and-slab prior that serves to regularize the inference and promote\nsparsity. We investigated the empirical behavior of the proposed method on both\ncontinuous and truncated data, and we noted that it outperforms several\nstate-of-the-art methods. As an application, we use the methodology to\nmaximally correlate clinical variables and proteomic data for a better\nunderstanding of covid-19 disease.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 21:00:57 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 16:52:56 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhu", "Qiuyun", ""], ["Atchade", "Yves", ""]]}, {"id": "2010.08633", "submitter": "Neha Gupta", "authors": "Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan", "title": "Universal guarantees for decision tree induction via a higher-order\n  splitting criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple extension of top-down decision tree learning heuristics\nsuch as ID3, C4.5, and CART. Our algorithm achieves provable guarantees for all\ntarget functions $f: \\{-1,1\\}^n \\to \\{-1,1\\}$ with respect to the uniform\ndistribution, circumventing impossibility results showing that existing\nheuristics fare poorly even for simple target functions. The crux of our\nextension is a new splitting criterion that takes into account the correlations\nbetween $f$ and small subsets of its attributes. The splitting criteria of\nexisting heuristics (e.g. Gini impurity and information gain), in contrast, are\nbased solely on the correlations between $f$ and its individual attributes.\n  Our algorithm satisfies the following guarantee: for all target functions $f\n: \\{-1,1\\}^n \\to \\{-1,1\\}$, sizes $s\\in \\mathbb{N}$, and error parameters\n$\\epsilon$, it constructs a decision tree of size $s^{\\tilde{O}((\\log\ns)^2/\\epsilon^2)}$ that achieves error $\\le O(\\mathsf{opt}_s) + \\epsilon$,\nwhere $\\mathsf{opt}_s$ denotes the error of the optimal size $s$ decision tree.\nA key technical notion that drives our analysis is the noise stability of $f$,\na well-studied smoothness measure.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 21:20:45 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Blanc", "Guy", ""], ["Gupta", "Neha", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2010.08689", "submitter": "Cole Hawkins", "authors": "Cole Hawkins, Xing Liu, Zheng Zhang", "title": "Towards Compact Neural Networks via End-to-End Training: A Bayesian\n  Tensor Approach with Automatic Rank Determination", "comments": "Updated version with DLRM experiments and more technical details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While post-training model compression can greatly reduce the inference cost\nof a deep neural network, uncompressed training still consumes a huge amount of\nhardware resources, run-time and energy. It is highly desirable to directly\ntrain a compact neural network from scratch with low memory and low\ncomputational cost. Low-rank tensor decomposition is one of the most effective\napproaches to reduce the memory and computing requirements of large-size neural\nnetworks. However, directly training a low-rank tensorized neural network is a\nvery challenging task because it is hard to determine a proper tensor rank {\\it\na priori}, which controls the model complexity and compression ratio in the\ntraining process. This paper presents a novel end-to-end framework for low-rank\ntensorized training of neural networks. We first develop a flexible Bayesian\nmodel that can handle various low-rank tensor formats (e.g., CP, Tucker, tensor\ntrain and tensor-train matrix) that compress neural network parameters in\ntraining. This model can automatically determine the tensor ranks inside a\nnonlinear forward model, which is beyond the capability of existing Bayesian\ntensor methods. We further develop a scalable stochastic variational inference\nsolver to estimate the posterior density of large-scale problems in training.\nOur work provides the first general-purpose rank-adaptive framework for\nend-to-end tensorized training. Our numerical results on various neural network\narchitectures show orders-of-magnitude parameter reduction and little accuracy\nloss (or even better accuracy) in the training process. Specifically, on a very\nlarge deep learning recommendation system with over $4.2\\times 10^9$ model\nparameters, our method can reduce the variables to only $1.6\\times 10^5$\nautomatically in the training process (i.e., by $2.6\\times 10^4$ times) while\nachieving almost the same accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 01:23:26 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 18:50:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hawkins", "Cole", ""], ["Liu", "Xing", ""], ["Zhang", "Zheng", ""]]}, {"id": "2010.08710", "submitter": "Shuxi Zeng", "authors": "Shuxi Zeng, Murat Ali Bayir, Joesph J.Pfeiffer III, Denis Charles,\n  Emre Kiciman", "title": "Causal Transfer Random Forest: Combining Logged Data and Randomized\n  Experiments for Robust Prediction", "comments": "9 pages, 7 figures, 2 tables, accepted to WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often critical for prediction models to be robust to distributional\nshifts between training and testing data. From a causal perspective, the\nchallenge is to distinguish the stable causal relationships from the unstable\nspurious correlations across shifts. We describe a causal transfer random\nforest (CTRF) that combines existing training data with a small amount of data\nfrom a randomized experiment to train a model which is robust to the feature\nshifts and therefore transfers to a new targeting distribution. Theoretically,\nwe justify the robustness of the approach against feature shifts with the\nknowledge from causal learning. Empirically, we evaluate the CTRF using both\nsynthetic data experiments and real-world experiments in the Bing Ads platform,\nincluding a click prediction task and in the context of an end-to-end\ncounterfactual optimization system. The proposed CTRF produces robust\npredictions and outperforms most baseline methods compared in the presence of\nfeature shifts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 03:54:37 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 16:29:07 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Zeng", "Shuxi", ""], ["Bayir", "Murat Ali", ""], ["Pfeiffer", "Joesph J.", "III"], ["Charles", "Denis", ""], ["Kiciman", "Emre", ""]]}, {"id": "2010.08729", "submitter": "Tsuyoshi Ishizone", "authors": "Tsuyoshi Ishizone, Tomoyuki Higuchi, Kazuyuki Nakamura", "title": "Ensemble Kalman Variational Objectives: Nonlinear Latent Trajectory\n  Inference with A Hybrid of Variational Inference and Ensemble Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Inference (VI) combined with Bayesian nonlinear filtering\nproduces the state-of-the-art results for latent trajectory inference. A body\nof recent works focused on Sequential Monte Carlo (SMC) and its expansion,\ne.g., Forward Filtering Backward Simulation (FFBSi). These studies achieved a\ngreat success, however, remain a serious problem for particle degeneracy. In\nthis paper, we propose Ensemble Kalman Objectives (EnKOs), the hybrid method of\nVI and Ensemble Kalman Filter (EnKF), to infer the State Space Models (SSMs).\nUnlike the SMC based methods, the our proposed method can identify the latent\ndynamics given fewer particles because of its rich particle diversity. We\ndemonstrate that EnKOs outperform the SMC based methods in terms of predictive\nability for three benchmark nonlinear dynamics systems tasks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 07:01:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ishizone", "Tsuyoshi", ""], ["Higuchi", "Tomoyuki", ""], ["Nakamura", "Kazuyuki", ""]]}, {"id": "2010.08766", "submitter": "Min Zhang", "authors": "Min Zhang, Yao Shu, Kun He", "title": "Tight Lower Complexity Bounds for Strongly Convex Finite-Sum\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-sum optimization plays an important role in the area of machine\nlearning, and hence has triggered a surge of interest in recent years. To\naddress this optimization problem, various randomized incremental gradient\nmethods have been proposed with guaranteed upper and lower complexity bounds\nfor their convergence. Nonetheless, these lower bounds rely on certain\nconditions: deterministic optimization algorithm, or fixed probability\ndistribution for the selection of component functions. Meanwhile, some lower\nbounds even do not match the upper bounds of the best known methods in certain\ncases. To break these limitations, we derive tight lower complexity bounds of\nrandomized incremental gradient methods, including SAG, SAGA, SVRG, and SARAH,\nfor two typical cases of finite-sum optimization. Specifically, our results\ntightly match the upper complexity of Katyusha when each component function is\nstrongly convex and smooth, and tightly match the upper complexity of SDCA\nwithout duality and of KatyushaX when the finite-sum function is strongly\nconvex and the component functions are average smooth.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 11:19:07 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhang", "Min", ""], ["Shu", "Yao", ""], ["He", "Kun", ""]]}, {"id": "2010.08820", "submitter": "Bark{\\i}n Tuncer", "authors": "Bark{\\i}n Tuncer, Emre \\\"Ozkan", "title": "Random Matrix Based Extended Target Tracking with Orientation: A New\n  Model and Inference", "comments": "12 pages, 6 figures, submitted to IEEE TSP", "journal-ref": null, "doi": "10.1109/TSP.2021.3065136", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel extended target tracking algorithm which is\ncapable of representing the extent of dynamic objects as an ellipsoid with a\ntime-varying orientation angle. A diagonal positive semi-definite matrix is\ndefined to model objects' extent within the random matrix framework where the\ndiagonal elements have inverse-Gamma priors. The resulting measurement equation\nis non-linear in the state variables, and it is not possible to find a\nclosed-form analytical expression for the true posterior because of the absence\nof conjugacy. We use the variational Bayes technique to perform approximate\ninference, where the Kullback-Leibler divergence between the true and the\napproximate posterior is minimized by performing fixed-point iterations. The\nupdate equations are easy to implement, and the algorithm can be used in\nreal-time tracking applications. We illustrate the performance of the method in\nsimulations and experiments with real data. The proposed method outperforms the\nstate-of-the-art methods when compared with respect to accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 16:33:06 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 09:36:36 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Tuncer", "Bark\u0131n", ""], ["\u00d6zkan", "Emre", ""]]}, {"id": "2010.08847", "submitter": "Fernando Gama", "authors": "Samuel Pfrommer, Fernando Gama, Alejandro Ribeiro", "title": "Discriminability of Single-Layer Graph Neural Networks", "comments": "Submitted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network data can be conveniently modeled as a graph signal, where data values\nare assigned to the nodes of a graph describing the underlying network\ntopology. Successful learning from network data requires methods that\neffectively exploit this graph structure. Graph neural networks (GNNs) provide\none such method and have exhibited promising performance on a wide range of\nproblems. Understanding why GNNs work is of paramount importance, particularly\nin applications involving physical networks. We focus on the property of\ndiscriminability and establish conditions under which the inclusion of\npointwise nonlinearities to a stable graph filter bank leads to an increased\ndiscriminative capacity for high-eigenvalue content. We define a notion of\ndiscriminability tied to the stability of the architecture, show that GNNs are\nat least as discriminative as linear graph filter banks, and characterize the\nsignals that cannot be discriminated by either.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 18:52:34 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 13:01:14 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Pfrommer", "Samuel", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2010.08853", "submitter": "Gilad Yehudai", "authors": "Gilad Yehudai, Ethan Fetaya, Eli Meirom, Gal Chechik, Haggai Maron", "title": "From Local Structures to Size Generalization in Graph Neural Networks", "comments": "Camera ready version for ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) can process graphs of different sizes, but their\nability to generalize across sizes, specifically from small to large graphs, is\nstill not well understood. In this paper, we identify an important type of data\nwhere generalization from small to large graphs is challenging: graph\ndistributions for which the local structure depends on the graph size. This\neffect occurs in multiple important graph learning domains, including social\nand biological networks. We first prove that when there is a difference between\nthe local structures, GNNs are not guaranteed to generalize across sizes: there\nare \"bad\" global minima that do well on small graphs but fail on large graphs.\nWe then study the size-generalization problem empirically and demonstrate that\nwhen there is a discrepancy in local structure, GNNs tend to converge to\nnon-generalizing solutions. Finally, we suggest two approaches for improving\nsize generalization, motivated by our findings. Notably, we propose a novel\nSelf-Supervised Learning (SSL) task aimed at learning meaningful\nrepresentations of local structures that appear in large graphs. Our SSL task\nimproves classification accuracy on several popular datasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 19:36:54 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 14:49:30 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 19:18:06 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Yehudai", "Gilad", ""], ["Fetaya", "Ethan", ""], ["Meirom", "Eli", ""], ["Chechik", "Gal", ""], ["Maron", "Haggai", ""]]}, {"id": "2010.08870", "submitter": "Xiaotian Xie", "authors": "Xiaotian Xie, Dimitrios Katselis, Carolyn L. Beck and R. Srikant", "title": "On the Consistency of Maximum Likelihood Estimators for Causal Network\n  Identification", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying parameters of a particular class of\nMarkov chains, called Bernoulli Autoregressive (BAR) processes. The structure\nof any BAR model is encoded by a directed graph. Incoming edges to a node in\nthe graph indicate that the state of the node at a particular time instant is\ninfluenced by the states of the corresponding parental nodes in the previous\ntime instant. The associated edge weights determine the corresponding level of\ninfluence from each parental node. In the simplest setup, the Bernoulli\nparameter of a particular node's state variable is a convex combination of the\nparental node states in the previous time instant and an additional Bernoulli\nnoise random variable. This paper focuses on the problem of edge weight\nidentification using Maximum Likelihood (ML) estimation and proves that the ML\nestimator is strongly consistent for two variants of the BAR model. We\nadditionally derive closed-form estimators for the aforementioned two variants\nand prove their strong consistency.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:25:44 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Xie", "Xiaotian", ""], ["Katselis", "Dimitrios", ""], ["Beck", "Carolyn L.", ""], ["Srikant", "R.", ""]]}, {"id": "2010.08873", "submitter": "Hamed Jalali", "authors": "Hamed Jalali, Gjergji Kasneci", "title": "Aggregating Dependent Gaussian Experts in Local Approximation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Gaussian processes (DGPs) are prominent local approximation\nmethods to scale Gaussian processes (GPs) to large datasets. Instead of a\nglobal estimation, they train local experts by dividing the training set into\nsubsets, thus reducing the time complexity. This strategy is based on the\nconditional independence assumption, which basically means that there is a\nperfect diversity between the local experts. In practice, however, this\nassumption is often violated, and the aggregation of experts leads to\nsub-optimal and inconsistent solutions. In this paper, we propose a novel\napproach for aggregating the Gaussian experts by detecting strong violations of\nconditional independence. The dependency between experts is determined by using\na Gaussian graphical model, which yields the precision matrix. The precision\nmatrix encodes conditional dependencies between experts and is used to detect\nstrongly dependent experts and construct an improved aggregation. Using both\nsynthetic and real datasets, our experimental evaluations illustrate that our\nnew method outperforms other state-of-the-art (SOTA) DGP approaches while being\nsubstantially more time-efficient than SOTA approaches, which build on\nindependent experts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:49:43 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Jalali", "Hamed", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "2010.08887", "submitter": "Kibok Lee", "authors": "Kibok Lee, Yian Zhu, Kihyuk Sohn, Chun-Liang Li, Jinwoo Shin, Honglak\n  Lee", "title": "i-Mix: A Domain-Agnostic Strategy for Contrastive Representation\n  Learning", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive representation learning has shown to be effective to learn\nrepresentations from unlabeled data. However, much progress has been made in\nvision domains relying on data augmentations carefully designed using domain\nknowledge. In this work, we propose i-Mix, a simple yet effective\ndomain-agnostic regularization strategy for improving contrastive\nrepresentation learning. We cast contrastive learning as training a\nnon-parametric classifier by assigning a unique virtual class to each data in a\nbatch. Then, data instances are mixed in both the input and virtual label\nspaces, providing more augmented data during training. In experiments, we\ndemonstrate that i-Mix consistently improves the quality of learned\nrepresentations across domains, including image, speech, and tabular data.\nFurthermore, we confirm its regularization effect via extensive ablation\nstudies across model and dataset sizes. The code is available at\nhttps://github.com/kibok90/imix.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 23:32:26 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 07:13:31 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Lee", "Kibok", ""], ["Zhu", "Yian", ""], ["Sohn", "Kihyuk", ""], ["Li", "Chun-Liang", ""], ["Shin", "Jinwoo", ""], ["Lee", "Honglak", ""]]}, {"id": "2010.08891", "submitter": "Aayam Shrestha", "authors": "Aayam Shrestha, Stefan Lee, Prasad Tadepalli, Alan Fern", "title": "DeepAveragers: Offline Reinforcement Learning by Solving Derived\n  Non-Parametric MDPs", "comments": "Preprint. Under review at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an approach to offline reinforcement learning (RL) based on\noptimally solving finitely-represented MDPs derived from a static dataset of\nexperience. This approach can be applied on top of any learned representation\nand has the potential to easily support multiple solution objectives as well as\nzero-shot adjustment to changing environments and goals. Our main contribution\nis to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate\nits solutions for offline RL. DAC-MDPs are a non-parametric model that can\nleverage deep representations and account for limited data by introducing costs\nfor exploiting under-represented parts of the model. In theory, we show\nconditions that allow for lower-bounding the performance of DAC-MDP solutions.\nWe also investigate the empirical behavior in a number of environments,\nincluding those with image-based observations. Overall, the experiments\ndemonstrate that the framework can work in practice and scale to large complex\noffline RL problems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 00:11:45 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Shrestha", "Aayam", ""], ["Lee", "Stefan", ""], ["Tadepalli", "Prasad", ""], ["Fern", "Alan", ""]]}, {"id": "2010.08899", "submitter": "Vipul Gupta", "authors": "Vipul Gupta, Dhruv Choudhary, Ping Tak Peter Tang, Xiaohan Wei, Xing\n  Wang, Yuzhen Huang, Arun Kejariwal, Kannan Ramchandran, Michael W. Mahoney", "title": "Training Recommender Systems at Scale: Communication-Efficient Model and\n  Data Parallelism", "comments": "27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider hybrid parallelism -- a paradigm that employs both\nData Parallelism (DP) and Model Parallelism (MP) -- to scale distributed\ntraining of large recommendation models. We propose a compression framework\ncalled Dynamic Communication Thresholding (DCT) for communication-efficient\nhybrid training. DCT filters the entities to be communicated across the network\nthrough a simple hard-thresholding function, allowing only the most relevant\ninformation to pass through. For communication efficient DP, DCT compresses the\nparameter gradients sent to the parameter server during model synchronization.\nThe threshold is updated only once every few thousand iterations to reduce the\ncomputational overhead of compression. For communication efficient MP, DCT\nincorporates a novel technique to compress the activations and gradients sent\nacross the network during the forward and backward propagation, respectively.\nThis is done by identifying and updating only the most relevant neurons of the\nneural network for each training sample in the data. We evaluate DCT on\npublicly available natural language processing and recommender models and\ndatasets, as well as recommendation systems used in production at Facebook. DCT\nreduces communication by at least $100\\times$ and $20\\times$ during DP and MP,\nrespectively. The algorithm has been deployed in production, and it improves\nend-to-end training time for a state-of-the-art industrial recommender model by\n37\\%, without any loss in performance.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 01:44:42 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 08:23:19 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Gupta", "Vipul", ""], ["Choudhary", "Dhruv", ""], ["Tang", "Ping Tak Peter", ""], ["Wei", "Xiaohan", ""], ["Wang", "Xing", ""], ["Huang", "Yuzhen", ""], ["Kejariwal", "Arun", ""], ["Ramchandran", "Kannan", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2010.09022", "submitter": "Xingchun Xiang", "authors": "Xingchun Xiang, Qingtao Tang, Huaixuan Zhang, Tao Dai, Jiawei Li,\n  Shu-Tao Xia", "title": "JSRT: James-Stein Regression Tree", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regression tree (RT) has been widely used in machine learning and data mining\ncommunity. Given a target data for prediction, a regression tree is first\nconstructed based on a training dataset before making prediction for each leaf\nnode. In practice, the performance of RT relies heavily on the local mean of\nsamples from an individual node during the tree construction/prediction stage,\nwhile neglecting the global information from different nodes, which also plays\nan important role. To address this issue, we propose a novel regression tree,\nnamed James-Stein Regression Tree (JSRT) by considering global information from\ndifferent nodes. Specifically, we incorporate the global mean information based\non James-Stein estimator from different nodes during the construction/predicton\nstage. Besides, we analyze the generalization error of our method under the\nmean square error (MSE) metric. Extensive experiments on public benchmark\ndatasets verify the effectiveness and efficiency of our method, and demonstrate\nthe superiority of our method over other RT prediction methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 16:28:49 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 13:26:26 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Xiang", "Xingchun", ""], ["Tang", "Qingtao", ""], ["Zhang", "Huaixuan", ""], ["Dai", "Tao", ""], ["Li", "Jiawei", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2010.09042", "submitter": "Anand Joshi", "authors": "Haleh Akrami, Anand A. Joshi, Sergul Aydore and Richard M. Leahy", "title": "Addressing Variance Shrinkage in Variational Autoencoders using Quantile\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of uncertainty in deep learning models is of vital importance,\nespecially in medical imaging, where reliance on inference without taking into\naccount uncertainty could lead to misdiagnosis. Recently, the probabilistic\nVariational AutoEncoder (VAE) has become a popular model for anomaly detection\nin applications such as lesion detection in medical images. The VAE is a\ngenerative graphical model that is used to learn the data distribution from\nsamples and then generate new samples from this distribution. By training on\nnormal samples, the VAE can be used to detect inputs that deviate from this\nlearned distribution. The VAE models the output as a conditionally independent\nGaussian characterized by means and variances for each output dimension. VAEs\ncan therefore use reconstruction probability instead of reconstruction error\nfor anomaly detection. Unfortunately, joint optimization of both mean and\nvariance in the VAE leads to the well-known problem of shrinkage or\nunderestimation of variance. We describe an alternative approach that avoids\nthis variance shrinkage problem by using quantile regression. Using estimated\nquantiles to compute mean and variance under the Gaussian assumption, we\ncompute reconstruction probability as a principled approach to outlier or\nanomaly detection. Results on simulated and Fashion MNIST data demonstrate the\neffectiveness of our approach. We also show how our approach can be used for\nprincipled heterogeneous thresholding for lesion detection in brain images.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 17:37:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Akrami", "Haleh", ""], ["Joshi", "Anand A.", ""], ["Aydore", "Sergul", ""], ["Leahy", "Richard M.", ""]]}, {"id": "2010.09077", "submitter": "Yunling Zheng", "authors": "Yunling Zheng, Zhijian Li, Jack Xin, Guofa Zhou", "title": "A Spatial-Temporal Graph Based Hybrid Infectious Disease Model with\n  Application to COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 pandemic evolves, reliable prediction plays an important role\nfor policy making. The classical infectious disease model SEIR\n(susceptible-exposed-infectious-recovered) is a compact yet simplistic temporal\nmodel. The data-driven machine learning models such as RNN (recurrent neural\nnetworks) can suffer in case of limited time series data such as COVID-19. In\nthis paper, we combine SEIR and RNN on a graph structure to develop a hybrid\nspatio-temporal model to achieve both accuracy and efficiency in training and\nforecasting. We introduce two features on the graph structure: node feature\n(local temporal infection trend) and edge feature (geographic neighbor effect).\nFor node feature, we derive a discrete recursion (called I-equation) from SEIR\nso that gradient descend method applies readily to its optimization. For edge\nfeature, we design an RNN model to capture the neighboring effect and\nregularize the landscape of loss function so that local minima are effective\nand robust for prediction. The resulting hybrid model (called IeRNN) improves\nthe prediction accuracy on state-level COVID-19 new case data from the US,\nout-performing standard temporal models (RNN, SEIR, and ARIMA) in 1-day and\n7-day ahead forecasting. Our model accommodates various degrees of reopening\nand provides potential outcomes for policymakers.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 19:34:54 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zheng", "Yunling", ""], ["Li", "Zhijian", ""], ["Xin", "Jack", ""], ["Zhou", "Guofa", ""]]}, {"id": "2010.09106", "submitter": "Themistoklis Gouleakis", "authors": "Ioannis Anagnostides, Themis Gouleakis, Ali Marashian", "title": "Robust Learning under Strong Noise via SQs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides several new insights on the robustness of Kearns'\nstatistical query framework against challenging label-noise models. First, we\nbuild on a recent result by \\cite{DBLP:journals/corr/abs-2006-04787} that\nshowed noise tolerance of distribution-independently evolvable concept classes\nunder Massart noise. Specifically, we extend their characterization to more\ngeneral noise models, including the Tsybakov model which considerably\ngeneralizes the Massart condition by allowing the flipping probability to be\narbitrarily close to $\\frac{1}{2}$ for a subset of the domain. As a corollary,\nwe employ an evolutionary algorithm by \\cite{DBLP:conf/colt/KanadeVV10} to\nobtain the first polynomial time algorithm with arbitrarily small excess error\nfor learning linear threshold functions over any spherically symmetric\ndistribution in the presence of spherically symmetric Tsybakov noise. Moreover,\nwe posit access to a stronger oracle, in which for every labeled example we\nadditionally obtain its flipping probability. In this model, we show that every\nSQ learnable class admits an efficient learning algorithm with OPT + $\\epsilon$\nmisclassification error for a broad class of noise models. This setting\nsubstantially generalizes the widely-studied problem of classification under\nRCN with known noise rate, and corresponds to a non-convex optimization problem\neven when the noise function -- i.e. the flipping probabilities of all points\n-- is known in advance.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 21:02:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Anagnostides", "Ioannis", ""], ["Gouleakis", "Themis", ""], ["Marashian", "Ali", ""]]}, {"id": "2010.09107", "submitter": "Chen Xu", "authors": "Chen Xu, Yao Xie", "title": "Conformal prediction interval for dynamic time-series", "comments": "Accepted as a long talk/oral (3% of total submissions) in the\n  Proceedings of the 38th International Conference on Machine Learning, PMLR\n  139, 2021 (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a method to construct distribution-free prediction intervals for\ndynamic time-series, called \\Verb|EnbPI| that wraps around any bootstrap\nensemble estimator to construct sequential prediction intervals. \\Verb|EnbPI|\nis closely related to the conformal prediction (CP) framework but does not\nrequire data exchangeability. Theoretically, these intervals attain\nfinite-sample, \\textit{approximately valid} marginal coverage for broad classes\nof regression functions and time-series with strongly mixing stochastic errors.\nComputationally, \\Verb|EnbPI| avoids overfitting and requires neither\ndata-splitting nor training multiple ensemble estimators; it efficiently\naggregates bootstrap estimators that have been trained. In general,\n\\Verb|EnbPI| is easy to implement, scalable to producing arbitrarily many\nprediction intervals sequentially, and well-suited to a wide range of\nregression functions. We perform extensive real-data analyses to demonstrate\nits effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 21:05:32 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 14:31:22 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 16:43:03 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 17:41:46 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 13:15:53 GMT"}, {"version": "v6", "created": "Sat, 15 May 2021 22:21:53 GMT"}, {"version": "v7", "created": "Sun, 23 May 2021 07:58:06 GMT"}, {"version": "v8", "created": "Wed, 2 Jun 2021 02:14:46 GMT"}, {"version": "v9", "created": "Wed, 16 Jun 2021 14:03:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Xu", "Chen", ""], ["Xie", "Yao", ""]]}, {"id": "2010.09133", "submitter": "Dennis Wei", "authors": "Dennis Wei, Tian Gao, Yue Yu", "title": "DAGs with No Fears: A Closer Look at Continuous Optimization for\n  Learning Bayesian Networks", "comments": "40 pages, 8 figures, to appear at the 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper re-examines a continuous optimization framework dubbed NOTEARS for\nlearning Bayesian networks. We first generalize existing algebraic\ncharacterizations of acyclicity to a class of matrix polynomials. Next,\nfocusing on a one-parameter-per-edge setting, it is shown that the\nKarush-Kuhn-Tucker (KKT) optimality conditions for the NOTEARS formulation\ncannot be satisfied except in a trivial case, which explains a behavior of the\nassociated algorithm. We then derive the KKT conditions for an equivalent\nreformulation, show that they are indeed necessary, and relate them to explicit\nconstraints that certain edges be absent from the graph. If the score function\nis convex, these KKT conditions are also sufficient for local minimality\ndespite the non-convexity of the constraint. Informed by the KKT conditions, a\nlocal search post-processing algorithm is proposed and shown to substantially\nand universally improve the structural Hamming distance of all tested\nalgorithms, typically by a factor of 2 or more. Some combinations with local\nsearch are both more accurate and more efficient than the original NOTEARS.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 22:59:37 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wei", "Dennis", ""], ["Gao", "Tian", ""], ["Yu", "Yue", ""]]}, {"id": "2010.09157", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Poincare: Recommending Publication Venues via Treatment Effect\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing a publication venue for an academic paper is a crucial step in the\nresearch process. However, in many cases, decisions are based on the experience\nof researchers, which often leads to suboptimal results. Although some existing\nmethods recommend publication venues, they just recommend venues where a paper\nis likely to be published. In this study, we aim to recommend publication\nvenues from a different perspective. We estimate the number of citations a\npaper will receive if the paper is published in each venue and recommend the\nvenue where the paper has the most potential impact. However, there are two\nchallenges to this task. First, a paper is published in only one venue, and\nthus, we cannot observe the number of citations the paper would receive if the\npaper were published in another venue. Secondly, the contents of a paper and\nthe publication venue are not statistically independent; that is, there exist\nselection biases in choosing publication venues. In this paper, we propose to\nuse a causal inference method to estimate the treatment effects of choosing a\npublication venue effectively and to recommend venues based on the potential\ninfluence of papers.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 00:50:48 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2010.09225", "submitter": "Kyohei Atarashi", "authors": "Kyohei Atarashi, Satoshi Oyama, Masahito Kurihara", "title": "Factorization Machines with Regularization for Sparse Feature\n  Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization machines (FMs) are machine learning predictive models based on\nsecond-order feature interactions and FMs with sparse regularization are called\nsparse FMs. Such regularizations enable feature selection, which selects the\nmost relevant features for accurate prediction, and therefore they can\ncontribute to the improvement of the model accuracy and interpretability.\nHowever, because FMs use second-order feature interactions, the selection of\nfeatures often causes the loss of many relevant feature interactions in the\nresultant models. In such cases, FMs with regularization specially designed for\nfeature interaction selection trying to achieve interaction-level sparsity may\nbe preferred instead of those just for feature selection trying to achieve\nfeature-level sparsity. In this paper, we present a new regularization scheme\nfor feature interaction selection in FMs. The proposed regularizer is an upper\nbound of the $\\ell_1$ regularizer for the feature interaction matrix, which is\ncomputed from the parameter matrix of FMs. For feature interaction selection,\nour proposed regularizer makes the feature interaction matrix sparse without a\nrestriction on sparsity patterns imposed by the existing methods. We also\ndescribe efficient proximal algorithms for the proposed FMs and present\ntheoretical analyses of both existing and the new regularize. In addition, we\nwill discuss how our ideas can be applied or extended to more accurate feature\nselection and other related models such as higher-order FMs and the all-subsets\nmodel. The analysis and experimental results on synthetic and real-world\ndatasets show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 05:00:40 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 03:51:12 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Atarashi", "Kyohei", ""], ["Oyama", "Satoshi", ""], ["Kurihara", "Masahito", ""]]}, {"id": "2010.09237", "submitter": "Nicolas Schreuder", "authors": "Nicolas Schreuder and Victor-Emmanuel Brunel and Arnak Dalalyan", "title": "Statistical guarantees for generative models without domination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a convenient framework for studying (adversarial)\ngenerative models from a statistical perspective. It consists in modeling the\ngenerative device as a smooth transformation of the unit hypercube of a\ndimension that is much smaller than that of the ambient space and measuring the\nquality of the generative model by means of an integral probability metric. In\nthe particular case of integral probability metric defined through a smoothness\nclass, we establish a risk bound quantifying the role of various parameters. In\nparticular, it clearly shows the impact of dimension reduction on the error of\nthe generative model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 06:09:48 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Schreuder", "Nicolas", ""], ["Brunel", "Victor-Emmanuel", ""], ["Dalalyan", "Arnak", ""]]}, {"id": "2010.09265", "submitter": "Di Wang", "authors": "Di Wang and Xiangyu Guo and Chaowen Guan and Shi Li and Jinhui Xu", "title": "Estimating Stochastic Linear Combination of Non-linear Regressions\n  Efficiently and Scalably", "comments": "This paper is a substantially extended version of our previous work\n  appeared in AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many machine learning and statistical models such as non-linear\nregressions, the Single Index, Multi-index, Varying Coefficient Index Models\nand Two-layer Neural Networks can be reduced to or be seen as a special case of\na new model which is called the \\textit{Stochastic Linear Combination of\nNon-linear Regressions} model. However, due to the high non-convexity of the\nproblem, there is no previous work study how to estimate the model. In this\npaper, we provide the first study on how to estimate the model efficiently and\nscalably. Specifically, we first show that with some mild assumptions, if the\nvariate vector $x$ is multivariate Gaussian, then there is an algorithm whose\noutput vectors have $\\ell_2$-norm estimation errors of $O(\\sqrt{\\frac{p}{n}})$\nwith high probability, where $p$ is the dimension of $x$ and $n$ is the number\nof samples. The key idea of the proof is based on an observation motived by the\nStein's lemma. Then we extend our result to the case where $x$ is bounded and\nsub-Gaussian using the zero-bias transformation, which could be seen as a\ngeneralization of the classic Stein's lemma. We also show that with some\nadditional assumptions there is an algorithm whose output vectors have\n$\\ell_\\infty$-norm estimation errors of\n$O(\\frac{1}{\\sqrt{p}}+\\sqrt{\\frac{p}{n}})$ with high probability. We also\nprovide a concrete example to show that there exists some link function which\nsatisfies the previous assumptions. Finally, for both Gaussian and sub-Gaussian\ncases we propose a faster sub-sampling based algorithm and show that when the\nsub-sample sizes are large enough then the estimation errors will not be\nsacrificed by too much. Experiments for both cases support our theoretical\nresults.\n  To the best of our knowledge, this is the first work that studies and\nprovides theoretical guarantees for the stochastic linear combination of\nnon-linear regressions model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:15:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Di", ""], ["Guo", "Xiangyu", ""], ["Guan", "Chaowen", ""], ["Li", "Shi", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.09267", "submitter": "Touboul Adrien", "authors": "Julien Reygner (CERMICS, GdR MASCOT-NUM), Adrien Touboul (CERMICS, IRT\n  SystemX)", "title": "Reweighting samples under covariate shift using a Wasserstein distance\n  criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering two random variables with different laws to which we only have\naccess through finite size iid samples, we address how to reweight the first\nsample so that its empirical distribution converges towards the true law of the\nsecond sample as the size of both samples goes to infinity. We study an optimal\nreweighting that minimizes the Wasserstein distance between the empirical\nmeasures of the two samples, and leads to an expression of the weights in terms\nof Nearest Neighbors. The consistency and some asymptotic convergence rates in\nterms of expected Wasserstein distance are derived, and do not need the\nassumption of absolute continuity of one random variable with respect to the\nother. These results have some application in Uncertainty Quantification for\ndecoupled estimation and in the bound of the generalization error for the\nNearest Neighbor Regression under covariate shift.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:23:55 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Reygner", "Julien", "", "CERMICS, GdR MASCOT-NUM"], ["Touboul", "Adrien", "", "CERMICS, IRT\n  SystemX"]]}, {"id": "2010.09283", "submitter": "Mohammed Haroon Dupty", "authors": "Mohammed Haroon Dupty, Wee Sun Lee", "title": "Neuralizing Efficient Higher-order Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network models have been extensively used to learn node\nrepresentations for graph structured data in an end-to-end setting. These\nmodels often rely on localized first order approximations of spectral graph\nconvolutions and hence are unable to capture higher-order relational\ninformation between nodes. Probabilistic Graphical Models form another class of\nmodels that provide rich flexibility in incorporating such relational\ninformation but are limited by inefficient approximate inference algorithms at\nhigher order. In this paper, we propose to combine these approaches to learn\nbetter node and graph representations. First, we derive an efficient\napproximate sum-product loopy belief propagation inference algorithm for\nhigher-order PGMs. We then embed the message passing updates into a neural\nnetwork to provide the inductive bias of the inference algorithm in end-to-end\nlearning. This gives us a model that is flexible enough to accommodate domain\nknowledge while maintaining the computational advantage. We further propose\nmethods for constructing higher-order factors that are conditioned on node and\nedge features and share parameters wherever necessary. Our experimental\nevaluation shows that our model indeed captures higher-order information,\nsubstantially outperforming state-of-the-art $k$-order graph neural networks in\nmolecular datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:51:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Dupty", "Mohammed Haroon", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2010.09293", "submitter": "Razane Tajeddine", "authors": "Razane Tajeddine, Joonas J\\\"alk\\\"o, Samuel Kaski, and Antti Honkela", "title": "Privacy-preserving Data Sharing on Vertically Partitioned Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we present a method for differentially private data sharing by\ntraining a mixture model on vertically partitioned data, where each party holds\ndifferent features for the same set of individuals. We use secure multi-party\ncomputation (MPC) to combine the contribution of the data from the parties to\ntrain the model. We apply the differentially private variational inference\n(DPVI) for learning the model. Assuming the mixture components contain no\ndependencies across different parties, the objective function can be factorized\ninto a sum of products of individual components of each party. Therefore, each\nparty can calculate its shares on its own without the use of MPC. Then MPC is\nonly needed to get the product between the different shares and add the noise.\nApplying the method to demographic data from the US Census, we obtain\ncomparable accuracy to the non-partitioned case with approximately 20-fold\nincrease in computing time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:10:34 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tajeddine", "Razane", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2010.09301", "submitter": "Anh Tong", "authors": "Anh Tong, Jaesik Choi", "title": "Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Gaussian Processes (DGPs) show the potential to have\nmore expressive representation than that of traditional Gaussian Processes\n(GPs). However, there exists a pathology of deep Gaussian processes that their\nlearning capacities reduce significantly when the number of layers increases.\nIn this paper, we present a new analysis in DGPs by studying its corresponding\nnonlinear dynamic systems to explain the issue. Existing work reports the\npathology for the squared exponential kernel function. We extend our\ninvestigation to four types of common stationary kernel functions. The\nrecurrence relations between layers are analytically derived, providing a\ntighter bound and the rate of convergence of the dynamic systems. We\ndemonstrate our finding with a number of experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:24:11 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 06:00:31 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 13:43:19 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Tong", "Anh", ""], ["Choi", "Jaesik", ""]]}, {"id": "2010.09327", "submitter": "Anton Mallasto", "authors": "Anton Mallasto, Markus Heinonen, Samuel Kaski", "title": "Bayesian Inference for Optimal Transport with Stochastic Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning and computer vision, optimal transport has had\nsignificant success in learning generative models and defining metric distances\nbetween structured and stochastic data objects, that can be cast as probability\nmeasures. The key element of optimal transport is the so called lifting of an\n\\emph{exact} cost (distance) function, defined on the sample space, to a cost\n(distance) between probability measures over the sample space. However, in many\nreal life applications the cost is \\emph{stochastic}: e.g., the unpredictable\ntraffic flow affects the cost of transportation between a factory and an\noutlet. To take this stochasticity into account, we introduce a Bayesian\nframework for inferring the optimal transport plan distribution induced by the\nstochastic cost, allowing for a principled way to include prior information and\nto model the induced stochasticity on the transport plans. Additionally, we\ntailor an HMC method to sample from the resulting transport plan posterior\ndistribution.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:07:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Mallasto", "Anton", ""], ["Heinonen", "Markus", ""], ["Kaski", "Samuel", ""]]}, {"id": "2010.09336", "submitter": "Pranay Yadav", "authors": "Pranay SY and Nithin Nagaraj", "title": "Causal Discovery using Compression-Complexity Measures", "comments": "Accepted version with major revisions to results and discussion. 17\n  pages, 9 figures", "journal-ref": "Pranay SY, & Nagaraj, N. (2021). Causal discovery using\n  compression-complexity measures. Journal of Biomedical Informatics, 103724", "doi": "10.1016/j.jbi.2021.103724", "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Causal inference is one of the most fundamental problems across all domains\nof science. We address the problem of inferring a causal direction from two\nobserved discrete symbolic sequences $X$ and $Y$. We present a framework which\nrelies on lossless compressors for inferring context-free grammars (CFGs) from\nsequence pairs and quantifies the extent to which the grammar inferred from one\nsequence compresses the other sequence. We infer $X$ causes $Y$ if the grammar\ninferred from $X$ better compresses $Y$ than in the other direction. To put\nthis notion to practice, we propose three models that use the\nCompression-Complexity Measures (CCMs) - Lempel-Ziv (LZ) complexity and\nEffort-To-Compress (ETC) to infer CFGs and discover causal directions without\ndemanding temporal structures. We evaluate these models on synthetic and\nreal-world benchmarks and empirically observe performances competitive with\ncurrent state-of-the-art methods. Lastly, we present two unique applications of\nthe proposed models for causal inference directly from pairs of genome\nsequences belonging to the SARS-CoV-2 virus. Using a large number of sequences,\nwe show that our models capture directed causal information exchange between\nsequence pairs, presenting novel opportunities for addressing key issues such\nas contact-tracing, motif discovery, evolution of virulence and pathogenicity\nin future applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:19:56 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:46:08 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 10:45:26 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["SY", "Pranay", ""], ["Nagaraj", "Nithin", ""]]}, {"id": "2010.09337", "submitter": "Christoph Molnar", "authors": "Christoph Molnar, Giuseppe Casalicchio, and Bernd Bischl", "title": "Interpretable Machine Learning -- A Brief History, State-of-the-Art and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a brief history of the field of interpretable machine learning\n(IML), give an overview of state-of-the-art interpretation methods, and discuss\nchallenges. Research in IML has boomed in recent years. As young as the field\nis, it has over 200 years old roots in regression modeling and rule-based\nmachine learning, starting in the 1960s. Recently, many new IML methods have\nbeen proposed, many of them model-agnostic, but also interpretation techniques\nspecific to deep learning and tree-based ensembles. IML methods either directly\nanalyze model components, study sensitivity to input perturbations, or analyze\nlocal or global surrogate approximations of the ML model. The field approaches\na state of readiness and stability, with many methods not only proposed in\nresearch, but also implemented in open-source software. But many important\nchallenges remain for IML, such as dealing with dependent features, causal\ninterpretation, and uncertainty estimation, which need to be resolved for its\nsuccessful application to scientific problems. A further challenge is a missing\nrigorous definition of interpretability, which is accepted by the community. To\naddress the challenges and advance the field, we urge to recall our roots of\ninterpretable, data-driven modeling in statistics and (rule-based) ML, but also\nto consider other areas such as sensitivity analysis, causal inference, and the\nsocial sciences.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:20:03 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Molnar", "Christoph", ""], ["Casalicchio", "Giuseppe", ""], ["Bischl", "Bernd", ""]]}, {"id": "2010.09345", "submitter": "Jayneel Parekh", "authors": "Jayneel Parekh, Pavlo Mozharovskyi, Florence d'Alch\\'e-Buc", "title": "A Framework to Learn with Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To tackle interpretability in deep learning, we present a novel framework to\njointly learn a predictive model and its associated interpretation model. The\ninterpreter provides both local and global interpretability about the\npredictive model in terms of human-understandable high level attribute\nfunctions, with minimal loss of accuracy. This is achieved by a dedicated\narchitecture and well chosen regularization penalties. We seek for a small-size\ndictionary of high level attribute functions that take as inputs the outputs of\nselected hidden layers and whose outputs feed a linear classifier. We impose\nstrong conciseness on the activation of attributes with an entropy-based\ncriterion while enforcing fidelity to both inputs and outputs of the predictive\nmodel. A detailed pipeline to visualize the learnt features is also developed.\nMoreover, besides generating interpretable models by design, our approach can\nbe specialized to provide post-hoc interpretations for a pre-trained neural\nnetwork. We validate our approach against several state-of-the-art methods on\nmultiple datasets and show its efficacy on both kinds of tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:26:28 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 18:44:17 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 14:21:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Parekh", "Jayneel", ""], ["Mozharovskyi", "Pavlo", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "2010.09360", "submitter": "Graziano Mita", "authors": "Graziano Mita, Maurizio Filippone, Pietro Michiardi", "title": "An Identifiable Double VAE For Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large part of the literature on learning disentangled representations\nfocuses on variational autoencoders (VAE). Recent developments demonstrate that\ndisentanglement cannot be obtained in a fully unsupervised setting without\ninductive biases on models and data. However, Khemakhem et al., AISTATS, 2020\nsuggest that employing a particular form of factorized prior, conditionally\ndependent on auxiliary variables complementing input observations, can be one\nsuch bias, resulting in an identifiable model with guarantees on\ndisentanglement. Working along this line, we propose a novel VAE-based\ngenerative model with theoretical guarantees on identifiability. We obtain our\nconditional prior over the latents by learning an optimal representation, which\nimposes an additional strength on their regularization. We also extend our\nmethod to semi-supervised settings. Experimental results indicate superior\nperformance with respect to state-of-the-art approaches, according to several\nestablished metrics proposed in the literature on disentanglement.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:59:31 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 13:36:14 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mita", "Graziano", ""], ["Filippone", "Maurizio", ""], ["Michiardi", "Pietro", ""]]}, {"id": "2010.09370", "submitter": "Anders Kirk Uhrenholt", "authors": "Anders Kirk Uhrenholt, Valentin Charvet, Bj{\\o}rn Sand Jensen", "title": "Probabilistic selection of inducing points in sparse Gaussian processes", "comments": "37th Conference on Uncertainty in Artificial Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Gaussian processes and various extensions thereof are enabled through\ninducing points, that simultaneously bottleneck the predictive capacity and act\nas the main contributor towards model complexity. However, the number of\ninducing points is generally not associated with uncertainty which prevents us\nfrom applying the apparatus of Bayesian reasoning for identifying an\nappropriate trade-off. In this work we place a point process prior on the\ninducing points and approximate the associated posterior through stochastic\nvariational inference. By letting the prior encourage a moderate number of\ninducing points, we enable the model to learn which and how many points to\nutilise. We experimentally show that fewer inducing points are preferred by the\nmodel as the points become less informative, and further demonstrate how the\nmethod can be employed in deep Gaussian processes and latent variable\nmodelling.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 10:29:30 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 12:02:36 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 17:14:19 GMT"}, {"version": "v4", "created": "Sun, 25 Jul 2021 14:13:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Uhrenholt", "Anders Kirk", ""], ["Charvet", "Valentin", ""], ["Jensen", "Bj\u00f8rn Sand", ""]]}, {"id": "2010.09386", "submitter": "Armeen Taeb", "authors": "Armeen Taeb, Parikshit Shah, Venkat Chandrasekaran", "title": "Learning Exponential Family Graphical Models with Latent Variables using\n  Regularized Conditional Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting a graphical model to a collection of random variables given sample\nobservations is a challenging task if the observed variables are influenced by\nlatent variables, which can induce significant confounding statistical\ndependencies among the observed variables. We present a new convex relaxation\nframework based on regularized conditional likelihood for latent-variable\ngraphical modeling in which the conditional distribution of the observed\nvariables conditioned on the latent variables is given by an exponential family\ngraphical model. In comparison to previously proposed tractable methods that\nproceed by characterizing the marginal distribution of the observed variables,\nour approach is applicable in a broader range of settings as it does not\nrequire knowledge about the specific form of distribution of the latent\nvariables and it can be specialized to yield tractable approaches to problems\nin which the observed data are not well-modeled as Gaussian. We demonstrate the\nutility and flexibility of our framework via a series of numerical experiments\non synthetic as well as real data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 11:16:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Taeb", "Armeen", ""], ["Shah", "Parikshit", ""], ["Chandrasekaran", "Venkat", ""]]}, {"id": "2010.09388", "submitter": "Johannes Haug", "authors": "Johannes Haug and Gjergji Kasneci", "title": "Learning Parameter Distributions to Detect Concept Drift in Data Streams", "comments": "To be published in the proceedings of the 25th International\n  Conference on Pattern Recognition (ICPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data distributions in streaming environments are usually not stationary. In\norder to maintain a high predictive quality at all times, online learning\nmodels need to adapt to distributional changes, which are known as concept\ndrift. The timely and robust identification of concept drift can be difficult,\nas we never have access to the true distribution of streaming data. In this\nwork, we propose a novel framework for the detection of real concept drift,\ncalled ERICS. By treating the parameters of a predictive model as random\nvariables, we show that concept drift corresponds to a change in the\ndistribution of optimal parameters. To this end, we adopt common measures from\ninformation theory. The proposed framework is completely model-agnostic. By\nchoosing an appropriate base model, ERICS is also capable to detect concept\ndrift at the input level, which is a significant advantage over existing\napproaches. An evaluation on several synthetic and real-world data sets\nsuggests that the proposed framework identifies concept drift more effectively\nand precisely than various existing works.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 11:19:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Haug", "Johannes", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "2010.09416", "submitter": "Wu Xinxing", "authors": "Xinxing Wu and Qiang Cheng", "title": "A Uniformly Stable Algorithm For Unsupervised Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data presents challenges for data management. Feature\nselection, as an important dimensionality reduction technique, reduces the\ndimensionality of data by identifying an essential subset of input features,\nand it can provide interpretable, effective, and efficient insights for\nanalysis and decision-making processes. Algorithmic stability is a key\ncharacteristic of an algorithm in its sensitivity to perturbations of input\nsamples. In this paper, first we propose an innovative unsupervised feature\nselection algorithm. The architecture of our algorithm consists of a feature\nscorer and a feature selector. The scorer trains a neural network (NN) to score\nall the features globally, and the selector is in a dependence sub-NN which\nlocally evaluates the representation abilities to select features. Further, we\npresent algorithmic stability analysis and show our algorithm has a performance\nguarantee by providing a generalization error bound. Empirically, extensive\nexperimental results on ten real-world datasets corroborate the superior\ngeneralization performance of our algorithm over contemporary algorithms.\nNotably, the features selected by our algorithm have comparable performance to\nthe original features; therefore, our algorithm significantly facilitates data\nmanagement.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 12:25:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wu", "Xinxing", ""], ["Cheng", "Qiang", ""]]}, {"id": "2010.09443", "submitter": "Jessica Gronsbell", "authors": "Jessica Gronsbell and Molei Liu and Lu Tian and Tianxi Cai", "title": "Efficient Estimation and Evaluation of Prediction Rules in\n  Semi-Supervised Settings under Stratified Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contemporary applications, large amounts of unlabeled data are\nreadily available while labeled examples are limited. There has been\nsubstantial interest in semi-supervised learning (SSL) which aims to leverage\nunlabeled data to improve estimation or prediction. However, current SSL\nliterature focuses primarily on settings where labeled data is selected\nrandomly from the population of interest. Non-random sampling, while posing\nadditional analytical challenges, is highly applicable to many real world\nproblems. Moreover, no SSL methods currently exist for estimating the\nprediction performance of a fitted model under non-random sampling. In this\npaper, we propose a two-step SSL procedure for evaluating a prediction rule\nderived from a working binary regression model based on the Brier score and\noverall misclassification rate under stratified sampling. In step I, we impute\nthe missing labels via weighted regression with nonlinear basis functions to\naccount for nonrandom sampling and to improve efficiency. In step II, we\naugment the initial imputations to ensure the consistency of the resulting\nestimators regardless of the specification of the prediction model or the\nimputation model. The final estimator is then obtained with the augmented\nimputations. We provide asymptotic theory and numerical studies illustrating\nthat our proposals outperform their supervised counterparts in terms of\nefficiency gain. Our methods are motivated by electronic health records (EHR)\nresearch and validated with a real data analysis of an EHR-based study of\ndiabetic neuropathy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 12:54:45 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Gronsbell", "Jessica", ""], ["Liu", "Molei", ""], ["Tian", "Lu", ""], ["Cai", "Tianxi", ""]]}, {"id": "2010.09515", "submitter": "Adam Foster", "authors": "Adam Foster, Rattana Pukdee, Tom Rainforth", "title": "Improving Transformation Invariance in Contrastive Representation\n  Learning", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose methods to strengthen the invariance properties of representations\nobtained by contrastive learning. While existing approaches implicitly induce a\ndegree of invariance as representations are learned, we look to more directly\nenforce invariance in the encoding process. To this end, we first introduce a\ntraining objective for contrastive learning that uses a novel regularizer to\ncontrol how the representation changes under transformation. We show that\nrepresentations trained with this objective perform better on downstream tasks\nand are more robust to the introduction of nuisance transformations at test\ntime. Second, we propose a change to how test time representations are\ngenerated by introducing a feature averaging approach that combines encodings\nfrom multiple transformations of the original input, finding that this leads to\nacross the board performance gains. Finally, we introduce the novel Spirograph\ndataset to explore our ideas in the context of a differentiable generative\nprocess with multiple downstream tasks, showing that our techniques for\nlearning invariance are highly beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:49:29 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 14:20:51 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Foster", "Adam", ""], ["Pukdee", "Rattana", ""], ["Rainforth", "Tom", ""]]}, {"id": "2010.09540", "submitter": "Biraj Guha", "authors": "Biraj Subhra Guha, Anirban Bhattacharya and Debdeep Pati", "title": "Statistical Guarantees and Algorithmic Convergence Issues of Variational\n  Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide statistical guarantees for Bayesian variational boosting by\nproposing a novel small bandwidth Gaussian mixture variational family. We\nemploy a functional version of Frank-Wolfe optimization as our variational\nalgorithm and study frequentist properties of the iterative boosting updates.\nComparisons are drawn to the recent literature on boosting, describing how the\nchoice of the variational family and the discrepancy measure affect both\nconvergence and finite-sample statistical properties of the optimization\nroutine. Specifically, we first demonstrate stochastic boundedness of the\nboosting iterates with respect to the data generating distribution. We next\nintegrate this within our algorithm to provide an explicit convergence rate,\nending with a result on the required number of boosting updates.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:12:36 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 00:15:06 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Guha", "Biraj Subhra", ""], ["Bhattacharya", "Anirban", ""], ["Pati", "Debdeep", ""]]}, {"id": "2010.09541", "submitter": "Tomas Geffner", "authors": "Tomas Geffner and Justin Domke", "title": "On the Difficulty of Unbiased Alpha Divergence Minimization", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several approximate inference algorithms have been proposed to minimize an\nalpha-divergence between an approximating distribution and a target\ndistribution. Many of these algorithms introduce bias, the magnitude of which\nbecomes problematic in high dimensions. Other algorithms are unbiased. These\noften seem to suffer from high variance, but little is rigorously known. In\nthis work we study unbiased methods for alpha-divergence minimization through\nthe Signal-to-Noise Ratio (SNR) of the gradient estimator. We study several\nrepresentative scenarios where strong analytical results are possible, such as\nfully-factorized or Gaussian distributions. We find that when alpha is not\nzero, the SNR worsens exponentially in the dimensionality of the problem. This\ncasts doubt on the practicality of these methods. We empirically confirm these\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:14:31 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:54:50 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 03:49:21 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "2010.09545", "submitter": "Thomas Moreau", "authors": "Hamza Cherkaoui and Jeremias Sulam and Thomas Moreau", "title": "Learning to solve TV regularized problems with unrolled algorithms", "comments": "accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Total Variation (TV) is a popular regularization strategy that promotes\npiece-wise constant signals by constraining the $\\ell_1$-norm of the first\norder derivative of the estimated signal. The resulting optimization problem is\nusually solved using iterative algorithms such as proximal gradient descent,\nprimal-dual algorithms or ADMM. However, such methods can require a very large\nnumber of iterations to converge to a suitable solution. In this paper, we\naccelerate such iterative algorithms by unfolding proximal gradient descent\nsolvers in order to learn their parameters for 1D TV regularized problems.\nWhile this could be done using the synthesis formulation, we demonstrate that\nthis leads to slower performances. The main difficulty in applying such methods\nin the analysis formulation lies in proposing a way to compute the derivatives\nthrough the proximal operator. As our main contribution, we develop and\ncharacterize two approaches to do so, describe their benefits and limitations,\nand discuss the regime where they can actually improve over iterative\nprocedures. We validate those findings with experiments on synthetic and real\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:19:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Cherkaoui", "Hamza", ""], ["Sulam", "Jeremias", ""], ["Moreau", "Thomas", ""]]}, {"id": "2010.09546", "submitter": "Jian Shen", "authors": "Jian Shen, Han Zhao, Weinan Zhang, Yong Yu", "title": "Model-based Policy Optimization with Unsupervised Model Adaptation", "comments": "Thirty-fourth Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning methods learn a dynamics model with real\ndata sampled from the environment and leverage it to generate simulated data to\nderive an agent. However, due to the potential distribution mismatch between\nsimulated data and real data, this could lead to degraded performance. Despite\nmuch effort being devoted to reducing this distribution mismatch, existing\nmethods fail to solve it explicitly. In this paper, we investigate how to\nbridge the gap between real and simulated data due to inaccurate model\nestimation for better policy optimization. To begin with, we first derive a\nlower bound of the expected return, which naturally inspires a bound\nmaximization algorithm by aligning the simulated and real data distributions.\nTo this end, we propose a novel model-based reinforcement learning framework\nAMPO, which introduces unsupervised model adaptation to minimize the integral\nprobability metric (IPM) between feature distributions from real and simulated\ndata. Instantiating our framework with Wasserstein-1 distance gives a practical\nmodel-based approach. Empirically, our approach achieves state-of-the-art\nperformance in terms of sample efficiency on a range of continuous control\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:19:42 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 07:00:55 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Shen", "Jian", ""], ["Zhao", "Han", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "2010.09570", "submitter": "Edward Yu", "authors": "Edward Yu", "title": "Bayesian Neural Networks with Soft Evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayes's rule deals with hard evidence, that is, we can calculate the\nprobability of event $A$ occuring given that event $B$ has occurred. Soft\nevidence, on the other hand, involves a degree of uncertainty about whether\nevent $B$ has actually occurred or not. Jeffrey's rule of conditioning provides\na way to update beliefs in the case of soft evidence. We provide a framework to\nlearn a probability distribution on the weights of a neural network trained\nusing soft evidence by way of two simple algorithms for approximating Jeffrey\nconditionalization. We propose an experimental protocol for benchmarking these\nalgorithms on empirical datasets and find that Jeffrey based methods are\ncompetitive or better in terms of accuracy yet show improvements in calibration\nmetrics upwards of 20% in some cases, even when the data contains mislabeled\npoints.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:56:14 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 04:31:24 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Yu", "Edward", ""]]}, {"id": "2010.09576", "submitter": "Di Wang", "authors": "Di Wang and Xiangyu Guo and Shi Li and Jinhui Xu", "title": "Robust High Dimensional Expectation Maximization Algorithm via Trimmed\n  Hard Thresholding", "comments": "Accepted at Machine Learning", "journal-ref": null, "doi": "10.1007/s10994-020-05926-z", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of estimating latent variable models with\narbitrarily corrupted samples in high dimensional space ({\\em i.e.,} $d\\gg n$)\nwhere the underlying parameter is assumed to be sparse. Specifically, we\npropose a method called Trimmed (Gradient) Expectation Maximization which adds\na trimming gradients step and a hard thresholding step to the Expectation step\n(E-step) and the Maximization step (M-step), respectively. We show that under\nsome mild assumptions and with an appropriate initialization, the algorithm is\ncorruption-proofing and converges to the (near) optimal statistical rate\ngeometrically when the fraction of the corrupted samples $\\epsilon$ is bounded\nby $ \\tilde{O}(\\frac{1}{\\sqrt{n}})$. Moreover, we apply our general framework\nto three canonical models: mixture of Gaussians, mixture of regressions and\nlinear regression with missing covariates. Our theory is supported by thorough\nnumerical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:00:35 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Di", ""], ["Guo", "Xiangyu", ""], ["Li", "Shi", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.09597", "submitter": "Quanquan Gu", "authors": "Difan Zou and Pan Xu and Quanquan Gu", "title": "Faster Convergence of Stochastic Gradient Langevin Dynamics for\n  Non-Log-Concave Sampling", "comments": "44 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new convergence analysis of stochastic gradient Langevin\ndynamics (SGLD) for sampling from a class of distributions that can be\nnon-log-concave. At the core of our approach is a novel conductance analysis of\nSGLD using an auxiliary time-reversible Markov Chain. Under certain conditions\non the target distribution, we prove that $\\tilde O(d^4\\epsilon^{-2})$\nstochastic gradient evaluations suffice to guarantee $\\epsilon$-sampling error\nin terms of the total variation distance, where $d$ is the problem dimension.\nThis improves existing results on the convergence rate of SGLD (Raginsky et\nal., 2017; Xu et al., 2018). We further show that provided an additional\nHessian Lipschitz condition on the log-density function, SGLD is guaranteed to\nachieve $\\epsilon$-sampling error within $\\tilde O(d^{15/4}\\epsilon^{-3/2})$\nstochastic gradient evaluations. Our proof technique provides a new way to\nstudy the convergence of Langevin-based algorithms and sheds some light on the\ndesign of fast stochastic gradient-based sampling algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:23:18 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 07:15:34 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zou", "Difan", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2010.09610", "submitter": "Eshaan Nichani", "authors": "Eshaan Nichani, Adityanarayanan Radhakrishnan, Caroline Uhler", "title": "Increasing Depth Leads to U-Shaped Test Risk in Over-parameterized\n  Convolutional Networks", "comments": "27 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have demonstrated that increasing model capacity through width\nin over-parameterized neural networks leads to a decrease in test risk. For\nneural networks, however, model capacity can also be increased through depth,\nyet understanding the impact of increasing depth on test risk remains an open\nquestion. In this work, we demonstrate that the test risk of over-parameterized\nconvolutional networks is a U-shaped curve (i.e. monotonically decreasing, then\nincreasing) with increasing depth. We first provide empirical evidence for this\nphenomenon via image classification experiments using both ResNets and the\nconvolutional neural tangent kernel (CNTK). We then present a novel linear\nregression framework for characterizing the impact of depth on test risk, and\nshow that increasing depth leads to a U-shaped test risk for the linear CNTK.\nIn particular, we prove that the linear CNTK corresponds to a depth-dependent\nlinear transformation on the original space and characterize properties of this\ntransformation. We then analyze over-parameterized linear regression under\narbitrary linear transformations and, in simplified settings, provably identify\nthe depths which minimize each of the bias and variance terms of the test risk.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:46:48 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 21:57:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nichani", "Eshaan", ""], ["Radhakrishnan", "Adityanarayanan", ""], ["Uhler", "Caroline", ""]]}, {"id": "2010.09629", "submitter": "Warren Morningstar", "authors": "Warren R. Morningstar, Alexander A. Alemi and Joshua V. Dillon", "title": "PAC$^m$-Bayes: Narrowing the Empirical Risk Gap in the Misspecified\n  Bayesian Regime", "comments": "Submitted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the decision-theoretic optimality of the Bayesian formalism under\ncorrect model specification is well-known (Berger 2013), the Bayesian case\nbecomes less clear under model misspecification (Grunwald 2017; Ramamoorthi\n2015; Fushiki 2005). To formally understand the consequences of Bayesian\nmisspecification, this work examines the relationship between posterior\npredictive risk and its sensitivity to correct model assumptions, i.e., choice\nof likelihood and prior. We present the multisample PAC$^m$-Bayes risk. This\nrisk is justified by theoretical analysis based on PAC-Bayes as well as\nempirical study on a number of toy problems. The PAC$^m$-Bayes risk is\nappealing in that it entails direct minimization of the Monte-Carlo\napproximated posterior predictive risk yet recovers both the Bayesian formalism\nas well as the MLE in its limits. Our work is heavily influenced by Masegosa\n(2019); our contributions are to align training and generalization risks while\noffering a tighter bound which empirically performs at least as well and\nsometimes much better.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:08:34 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 21:10:18 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Morningstar", "Warren R.", ""], ["Alemi", "Alexander A.", ""], ["Dillon", "Joshua V.", ""]]}, {"id": "2010.09654", "submitter": "Zal\\'an Borsos", "authors": "Zal\\'an Borsos, Marco Tagliasacchi, Andreas Krause", "title": "Semi-supervised Batch Active Learning via Bilevel Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is an effective technique for reducing the labeling cost by\nimproving data efficiency. In this work, we propose a novel batch acquisition\nstrategy for active learning in the setting where the model training is\nperformed in a semi-supervised manner. We formulate our approach as a data\nsummarization problem via bilevel optimization, where the queried batch\nconsists of the points that best summarize the unlabeled data pool. We show\nthat our method is highly effective in keyword detection tasks in the regime\nwhen only few labeled samples are available.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:53:24 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Borsos", "Zal\u00e1n", ""], ["Tagliasacchi", "Marco", ""], ["Krause", "Andreas", ""]]}, {"id": "2010.09658", "submitter": "Zal\\'an Borsos", "authors": "Zal\\'an Borsos, Yunpeng Li, Beat Gfeller, Marco Tagliasacchi", "title": "MicAugment: One-shot Microphone Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial aspect for the successful deployment of audio-based models\n\"in-the-wild\" is the robustness to the transformations introduced by\nheterogeneous acquisition conditions. In this work, we propose a method to\nperform one-shot microphone style transfer. Given only a few seconds of audio\nrecorded by a target device, MicAugment identifies the transformations\nassociated to the input acquisition pipeline and uses the learned\ntransformations to synthesize audio as if it were recorded under the same\nconditions as the target audio. We show that our method can successfully apply\nthe style transfer to real audio and that it significantly increases model\nrobustness when used as data augmentation in the downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:56:04 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Borsos", "Zal\u00e1n", ""], ["Li", "Yunpeng", ""], ["Gfeller", "Beat", ""], ["Tagliasacchi", "Marco", ""]]}, {"id": "2010.09670", "submitter": "Maksym Andriushchenko", "authors": "Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo\n  Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, Matthias Hein", "title": "RobustBench: a standardized adversarial robustness benchmark", "comments": "Version 2: 90+ evaluations, 60+ models, 5 leaderboards (Linf, L2,\n  common corruptions), significantly expanded analysis part (calibration,\n  fairness, privacy leakage, smoothness, transferability)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a research community, we are still lacking a systematic understanding of\nthe progress on adversarial robustness, which often makes it hard to identify\nthe most promising ideas in training robust models. A key challenge in\nbenchmarking robustness is that its evaluation is often error-prone, leading to\noverestimation of the true robustness of models. While adaptive attacks\ndesigned for a particular defense are a potential solution, they have to be\nhighly customized for particular models, which makes it difficult to compare\ndifferent methods. Our goal is to instead establish a standardized benchmark of\nadversarial robustness, which as accurately as possible reflects the robustness\nof the considered models within a reasonable computational budget. To evaluate\nthe robustness of models for our benchmark, we consider AutoAttack, an ensemble\nof white- and black-box attacks which was recently shown in a large-scale study\nto improve almost all robustness evaluations compared to the original\npublications. We also impose some restrictions on the admitted models to rule\nout defenses that only make gradient-based attacks ineffective without\nimproving actual robustness. Our leaderboard, hosted at\nhttps://robustbench.github.io/, contains evaluations of 90+ models and aims at\nreflecting the current state of the art on a set of well-defined tasks in\n$\\ell_\\infty$- and $\\ell_2$-threat models and on common corruptions, with\npossible extensions in the future. Additionally, we open-source the library\nhttps://github.com/RobustBench/robustbench that provides unified access to 60+\nrobust models to facilitate their downstream applications. Finally, based on\nthe collected models, we analyze the impact of robustness on the performance on\ndistribution shifts, calibration, out-of-distribution detection, fairness,\nprivacy leakage, smoothness, and transferability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 17:06:18 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 13:50:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Croce", "Francesco", ""], ["Andriushchenko", "Maksym", ""], ["Sehwag", "Vikash", ""], ["Debenedetti", "Edoardo", ""], ["Flammarion", "Nicolas", ""], ["Chiang", "Mung", ""], ["Mittal", "Prateek", ""], ["Hein", "Matthias", ""]]}, {"id": "2010.09686", "submitter": "Ian Waudby-Smith", "authors": "Ian Waudby-Smith and Aaditya Ramdas", "title": "Estimating means of bounded random variables by betting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives confidence intervals (CI) and time-uniform confidence\nsequences (CS) for the classical problem of estimating an unknown mean from\nbounded observations. We present a general approach for deriving concentration\nbounds, that can be seen as a generalization (and improvement) of the\ncelebrated Chernoff method. At its heart, it is based on deriving a new class\nof composite nonnegative martingales, with strong connections to betting and\nthe method of mixtures. We show how to extend these ideas to sampling without\nreplacement, another heavily studied problem. In all cases, our bounds are\nadaptive to the unknown variance, and empirically vastly outperform competing\napproaches based on Hoeffding or empirical Bernstein inequalities and their\nrecent supermartingale generalizations. In short, we establish a new\nstate-of-the-art for four fundamental problems: CSs and CIs for bounded means,\nwith and without replacement.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 17:22:03 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 01:29:19 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 00:57:37 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 02:56:49 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Waudby-Smith", "Ian", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2010.09790", "submitter": "Jakub Tomczak", "authors": "Ilze Amanda Auzina and Jakub M. Tomczak", "title": "ABC-Di: Approximate Bayesian Computation for Discrete Data", "comments": "Code: https://github.com/IlzeAmandaA/ABCdiscrete", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-life problems are represented as a black-box, i.e., the internal\nworkings are inaccessible or a closed-form mathematical expression of the\nlikelihood function cannot be defined. For continuous random variables\nlikelihood-free inference problems can be solved by a group of methods under\nthe name of Approximate Bayesian Computation (ABC). However, a similar approach\nfor discrete random variables is yet to be formulated. Here, we aim to fill\nthis research gap. We propose to use a population-based MCMC ABC framework.\nFurther, we present a valid Markov kernel, and propose a new kernel that is\ninspired by Differential Evolution. We assess the proposed approach on a\nproblem with the known likelihood function, namely, discovering the underlying\ndiseases based on a QMR-DT Network, and three likelihood-free inference\nproblems: (i) the QMR-DT Network with the unknown likelihood function, (ii)\nlearning binary neural network, and (iii) Neural Architecture Search. The\nobtained results indicate the high potential of the proposed framework and the\nsuperiority of the new Markov kernel.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:06:00 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Auzina", "Ilze Amanda", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "2010.09800", "submitter": "Wei Deng", "authors": "Wei Deng and Guang Lin and Faming Liang", "title": "A Contour Stochastic Gradient Langevin Dynamics Algorithm for\n  Simulations of Multi-modal Distributions", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adaptively weighted stochastic gradient Langevin dynamics\nalgorithm (SGLD), so-called contour stochastic gradient Langevin dynamics\n(CSGLD), for Bayesian learning in big data statistics. The proposed algorithm\nis essentially a \\emph{scalable dynamic importance sampler}, which\nautomatically \\emph{flattens} the target distribution such that the simulation\nfor a multi-modal distribution can be greatly facilitated. Theoretically, we\nprove a stability condition and establish the asymptotic convergence of the\nself-adapting parameter to a {\\it unique fixed-point}, regardless of the\nnon-convexity of the original energy function; we also present an error\nanalysis for the weighted averaging estimators. Empirically, the CSGLD\nalgorithm is tested on multiple benchmark datasets including CIFAR10 and\nCIFAR100. The numerical results indicate its superiority over the existing\nstate-of-the-art algorithms in training deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:20:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Deng", "Wei", ""], ["Lin", "Guang", ""], ["Liang", "Faming", ""]]}, {"id": "2010.09808", "submitter": "Kuno Kim", "authors": "Kuno Kim, Akshat Jindal, Yang Song, Jiaming Song, Yanan Sui, Stefano\n  Ermon", "title": "Imitation with Neural Density Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for Imitation Learning (IL) via density estimation\nof the expert's occupancy measure followed by Maximum Occupancy Entropy\nReinforcement Learning (RL) using the density as a reward. Our approach\nmaximizes a non-adversarial model-free RL objective that provably lower bounds\nreverse Kullback-Leibler divergence between occupancy measures of the expert\nand imitator. We present a practical IL algorithm, Neural Density Imitation\n(NDI), which obtains state-of-the-art demonstration efficiency on benchmark\ncontrol tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:38:36 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Kim", "Kuno", ""], ["Jindal", "Akshat", ""], ["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Sui", "Yanan", ""], ["Ermon", "Stefano", ""]]}, {"id": "2010.09818", "submitter": "Mohammad Reza Karimi Jaghargh", "authors": "Mohammad Reza Karimi, Nezihe Merve G\\\"urel, Bojan Karla\\v{s}, Johannes\n  Rausch, Ce Zhang and Andreas Krause", "title": "Online Active Model Selection for Pre-trained Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $k$ pre-trained classifiers and a stream of unlabeled data examples,\nhow can we actively decide when to query a label so that we can distinguish the\nbest model from the rest while making a small number of queries? Answering this\nquestion has a profound impact on a range of practical scenarios. In this work,\nwe design an online selective sampling approach that actively selects\ninformative examples to label and outputs the best model with high probability\nat any round. Our algorithm can be used for online prediction tasks for both\nadversarial and stochastic streams. We establish several theoretical guarantees\nfor our algorithm and extensively demonstrate its effectiveness in our\nexperimental studies.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 19:53:15 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:18:22 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 14:36:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Karimi", "Mohammad Reza", ""], ["G\u00fcrel", "Nezihe Merve", ""], ["Karla\u0161", "Bojan", ""], ["Rausch", "Johannes", ""], ["Zhang", "Ce", ""], ["Krause", "Andreas", ""]]}, {"id": "2010.09851", "submitter": "Disi Ji", "authors": "Disi Ji, Padhraic Smyth, Mark Steyvers", "title": "Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data\n  and Bayesian Inference", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of reliably assessing group fairness when labeled\nexamples are few but unlabeled examples are plentiful. We propose a general\nBayesian framework that can augment labeled data with unlabeled data to produce\nmore accurate and lower-variance estimates compared to methods based on labeled\ndata alone. Our approach estimates calibrated scores for unlabeled examples in\neach group using a hierarchical latent variable model conditioned on labeled\nexamples. This in turn allows for inference of posterior distributions with\nassociated notions of uncertainty for a variety of group fairness metrics. We\ndemonstrate that our approach leads to significant and consistent reductions in\nestimation error across multiple well-known fairness datasets, sensitive\nattributes, and predictive models. The results show the benefits of using both\nunlabeled data and Bayesian inference in terms of assessing whether a\nprediction model is fair or not.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:42:18 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Ji", "Disi", ""], ["Smyth", "Padhraic", ""], ["Steyvers", "Mark", ""]]}, {"id": "2010.09875", "submitter": "Ghassen Jerfel", "authors": "Yeming Wen, Ghassen Jerfel, Rafael Muller, Michael W. Dusenberry,\n  Jasper Snoek, Balaji Lakshminarayanan, Dustin Tran", "title": "Combining Ensembles and Data Augmentation can Harm your Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods which average over multiple neural network predictions are a\nsimple approach to improve a model's calibration and robustness. Similarly,\ndata augmentation techniques, which encode prior information in the form of\ninvariant feature transformations, are effective for improving calibration and\nrobustness. In this paper, we show a surprising pathology: combining ensembles\nand data augmentation can harm model calibration. This leads to a trade-off in\npractice, whereby improved accuracy by combining the two techniques comes at\nthe expense of calibration. On the other hand, selecting only one of the\ntechniques ensures good uncertainty estimates at the expense of accuracy. We\ninvestigate this pathology and identify a compounding under-confidence among\nmethods which marginalize over sets of weights and data augmentation techniques\nwhich soften labels. Finally, we propose a simple correction, achieving the\nbest of both worlds with significant accuracy and calibration gains over using\nonly ensembles or data augmentation individually. Applying the correction\nproduces new state-of-the art in uncertainty calibration across CIFAR-10,\nCIFAR-100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 21:25:22 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 19:55:32 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Wen", "Yeming", ""], ["Jerfel", "Ghassen", ""], ["Muller", "Rafael", ""], ["Dusenberry", "Michael W.", ""], ["Snoek", "Jasper", ""], ["Lakshminarayanan", "Balaji", ""], ["Tran", "Dustin", ""]]}, {"id": "2010.09877", "submitter": "Cosme Louart", "authors": "Cosme Louart and Romain Couillet", "title": "Concentration of solutions to random equations with concentration of\n  measure hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose here to study the concentration of random objects that are\nimplicitly formulated as fixed points to equations $Y = f(X)$ where $f$ is a\nrandom mapping. Starting from an hypothesis taken from the concentration of the\nmeasure theory, we are able to express precisely the concentration of such\nsolutions, under some contractivity hypothesis on $f$. This statement has\nimportant implication to random matrix theory, and is at the basis of the study\nof some optimization procedures like the logistic regression for instance. In\nthose last cases, we give precise estimations to the first statistics of the\nsolution $Y$ which allows us predict the performances of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 21:26:30 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Louart", "Cosme", ""], ["Couillet", "Romain", ""]]}, {"id": "2010.09889", "submitter": "Yuanhao Xiong", "authors": "Yuanhao Xiong, Xuanqing Liu, Li-Cheng Lan, Yang You, Si Si, Cho-Jui\n  Hsieh", "title": "How much progress have we made in neural network training? A New\n  Evaluation Protocol for Benchmarking Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimizers have been proposed for training deep neural networks, and\nthey often have multiple hyperparameters, which make it tricky to benchmark\ntheir performance. In this work, we propose a new benchmarking protocol to\nevaluate both end-to-end efficiency (training a model from scratch without\nknowing the best hyperparameter) and data-addition training efficiency (the\npreviously selected hyperparameters are used for periodically re-training the\nmodel with newly collected data). For end-to-end efficiency, unlike previous\nwork that assumes random hyperparameter tuning, which over-emphasizes the\ntuning time, we propose to evaluate with a bandit hyperparameter tuning\nstrategy. A human study is conducted to show that our evaluation protocol\nmatches human tuning behavior better than the random search. For data-addition\ntraining, we propose a new protocol for assessing the hyperparameter\nsensitivity to data shift. We then apply the proposed benchmarking framework to\n7 optimizers and various tasks, including computer vision, natural language\nprocessing, reinforcement learning, and graph mining. Our results show that\nthere is no clear winner across all the tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 21:46:39 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Xiong", "Yuanhao", ""], ["Liu", "Xuanqing", ""], ["Lan", "Li-Cheng", ""], ["You", "Yang", ""], ["Si", "Si", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2010.09891", "submitter": "Kezhi Kong", "authors": "Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard\n  Ghanem, Gavin Taylor, Tom Goldstein", "title": "FLAG: Adversarial Data Augmentation for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation helps neural networks generalize better, but it remains an\nopen question how to effectively augment graph data to enhance the performance\nof GNNs (Graph Neural Networks). While most existing graph regularizers focus\non augmenting graph topological structures by adding/removing edges, we offer a\nnovel direction to augment in the input node feature space for better\nperformance. We propose a simple but effective solution, FLAG (Free Large-scale\nAdversarial Augmentation on Graphs), which iteratively augments node features\nwith gradient-based adversarial perturbations during training, and boosts\nperformance at test time. Empirically, FLAG can be easily implemented with a\ndozen lines of code and is flexible enough to function with any GNN backbone,\non a wide variety of large-scale datasets, and in both transductive and\ninductive settings. Without modifying a model's architecture or training setup,\nFLAG yields a consistent and salient performance boost across both node and\ngraph classification tasks. Using FLAG, we reach state-of-the-art performance\non the large-scale ogbg-molpcba, ogbg-ppa, and ogbg-code datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 21:51:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Kong", "Kezhi", ""], ["Li", "Guohao", ""], ["Ding", "Mucong", ""], ["Wu", "Zuxuan", ""], ["Zhu", "Chen", ""], ["Ghanem", "Bernard", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "2010.09908", "submitter": "Amit Moscovich", "authors": "Sharon Zhang, Amit Moscovich, Amit Singer", "title": "Product Manifold Learning", "comments": "10 pages, 4 figures", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics. 130 (2021) 3241-3249", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems of dimensionality reduction and learning data\nrepresentations for continuous spaces with two or more independent degrees of\nfreedom. Such problems occur, for example, when observing shapes with several\ncomponents that move independently. Mathematically, if the parameter space of\neach continuous independent motion is a manifold, then their combination is\nknown as a product manifold. In this paper, we present a new paradigm for\nnon-linear independent component analysis called manifold factorization. Our\nfactorization algorithm is based on spectral graph methods for manifold\nlearning and the separability of the Laplacian operator on product spaces.\nRecovering the factors of a manifold yields meaningful lower-dimensional\nrepresentations and provides a new way to focus on particular aspects of the\ndata space while ignoring others. We demonstrate the potential use of our\nmethod for an important and challenging problem in structural biology: mapping\nthe motions of proteins and other large molecules using cryo-electron\nmicroscopy datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 22:51:06 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhang", "Sharon", ""], ["Moscovich", "Amit", ""], ["Singer", "Amit", ""]]}, {"id": "2010.09921", "submitter": "Jun Yu", "authors": "Cheng Meng and Jun Yu and Jingyi Zhang and Ping Ma and Wenxuan Zhong", "title": "Sufficient dimension reduction for classification using principal\n  optimal transport direction", "comments": "18 pages, 4 figures, to be published in 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), add the supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sufficient dimension reduction is used pervasively as a supervised dimension\nreduction approach. Most existing sufficient dimension reduction methods are\ndeveloped for data with a continuous response and may have an unsatisfactory\nperformance for the categorical response, especially for the binary-response.\nTo address this issue, we propose a novel estimation method of sufficient\ndimension reduction subspace (SDR subspace) using optimal transport. The\nproposed method, named principal optimal transport direction (POTD), estimates\nthe basis of the SDR subspace using the principal directions of the optimal\ntransport coupling between the data respecting different response categories.\nThe proposed method also reveals the relationship among three seemingly\nirrelevant topics, i.e., sufficient dimension reduction, support vector\nmachine, and optimal transport. We study the asymptotic properties of POTD and\nshow that in the cases when the class labels contain no error, POTD estimates\nthe SDR subspace exclusively. Empirical studies show POTD outperforms most of\nthe state-of-the-art linear dimension reduction methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:38:31 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 01:48:14 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 04:34:24 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 04:10:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Meng", "Cheng", ""], ["Yu", "Jun", ""], ["Zhang", "Jingyi", ""], ["Ma", "Ping", ""], ["Zhong", "Wenxuan", ""]]}, {"id": "2010.09923", "submitter": "Gil Shamir", "authors": "Gil I. Shamir and Lorenzo Coviello", "title": "Anti-Distillation: Improving reproducibility of deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have been revolutionary in improving performance of machine\nlearning and artificial intelligence systems. Their high prediction accuracy,\nhowever, comes at a price of \\emph{model irreproducibility\\/} in very high\nlevels that do not occur with classical linear models. Two models, even if they\nare supposedly identical, with identical architecture and identical trained\nparameter sets, and that are trained on the same set of training examples,\nwhile possibly providing identical average prediction accuracies, may predict\nvery differently on individual, previously unseen, examples. \\emph{Prediction\ndifferences\\/} may be as large as the order of magnitude of the predictions\nthemselves. Ensembles have been shown to somewhat mitigate this behavior, but\nwithout an extra push, may not be utilizing their full potential. In this work,\na novel approach, \\emph{Anti-Distillation\\/}, is proposed to address\nirreproducibility in deep networks, where ensemble models are used to generate\npredictions. Anti-Distillation forces ensemble components away from one another\nby techniques like de-correlating their outputs over mini-batches of examples,\nforcing them to become even more different and more diverse. Doing so enhances\nthe benefit of ensembles, making the final predictions more reproducible.\nEmpirical results demonstrate substantial prediction difference reductions\nachieved by Anti-Distillation on benchmark and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:47:12 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Shamir", "Gil I.", ""], ["Coviello", "Lorenzo", ""]]}, {"id": "2010.09929", "submitter": "Gautam Kamath", "authors": "Ishaq Aden-Ali, Hassan Ashtiani, Gautam Kamath", "title": "On the Sample Complexity of Privately Learning Unbounded\n  High-Dimensional Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide sample complexity upper bounds for agnostically learning\nmultivariate Gaussians under the constraint of approximate differential\nprivacy. These are the first finite sample upper bounds for general Gaussians\nwhich do not impose restrictions on the parameters of the distribution. Our\nbounds are near-optimal in the case when the covariance is known to be the\nidentity, and conjectured to be near-optimal in the general case. From a\ntechnical standpoint, we provide analytic tools for arguing the existence of\nglobal \"locally small\" covers from local covers of the space. These are\nexploited using modifications of recent techniques for differentially private\nhypothesis selection. Our techniques may prove useful for privately learning\nother distribution classes which do not possess a finite cover.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:55:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Aden-Ali", "Ishaq", ""], ["Ashtiani", "Hassan", ""], ["Kamath", "Gautam", ""]]}, {"id": "2010.09931", "submitter": "Gil Shamir", "authors": "Gil I. Shamir, Dong Lin, and Lorenzo Coviello", "title": "Smooth activations and reproducibility in deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are gradually penetrating almost every domain in our lives due\nto their amazing success. However, with substantive performance accuracy\nimprovements comes the price of \\emph{irreproducibility}. Two identical models,\ntrained on the exact same training dataset may exhibit large differences in\npredictions on individual examples even when average accuracy is similar,\nespecially when trained on highly distributed parallel systems. The popular\nRectified Linear Unit (ReLU) activation has been key to recent success of deep\nnetworks. We demonstrate, however, that ReLU is also a catalyzer to\nirreproducibility in deep networks. We show that not only can activations\nsmoother than ReLU provide better accuracy, but they can also provide better\naccuracy-reproducibility tradeoffs. We propose a new family of activations;\nSmooth ReLU (\\emph{SmeLU}), designed to give such better tradeoffs, while also\nkeeping the mathematical expression simple, and thus implementation cheap.\nSmeLU is monotonic, mimics ReLU, while providing continuous gradients, yielding\nbetter reproducibility. We generalize SmeLU to give even more flexibility and\nthen demonstrate that SmeLU and its generalized form are special cases of a\nmore general methodology of REctified Smooth Continuous Unit (RESCU)\nactivations. Empirical results demonstrate the superior\naccuracy-reproducibility tradeoffs with smooth activations, SmeLU in\nparticular.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 00:06:47 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 00:11:42 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Shamir", "Gil I.", ""], ["Lin", "Dong", ""], ["Coviello", "Lorenzo", ""]]}, {"id": "2010.09938", "submitter": "Shailesh Nirgudkar", "authors": "Shailesh Nirgudkar, Tianyu Ding", "title": "Early Detection of Sepsis using Ensemblers", "comments": null, "journal-ref": "2019 Computing in Cardiology", "doi": "10.23919/CinC49843.2019.9005878", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a methodology to detect sepsis ahead of time by\nanalyzing hourly patient records. The Physionet 2019 challenge consists of\nmedical records of over 40,000 patients. Using imputation and weak ensembler\ntechnique to analyze these medical records and 3-fold validation, a model is\ncreated and validated internally. The model achieved an accuracy of 93.45% and\na utility score of 0.271. The utility score as defined by the organizers takes\ninto account true positives, negatives and false alarms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 00:42:49 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nirgudkar", "Shailesh", ""], ["Ding", "Tianyu", ""]]}, {"id": "2010.09941", "submitter": "Tomoki Tokuda", "authors": "Tomoki Tokuda, Okito Yamashita, Junichiro Yoshimoto", "title": "Multiple-view clustering for identifying subject clusters and brain\n  sub-networks using functional connectivity matrices without vectorization", "comments": null, "journal-ref": "Neural Networks, 2021", "doi": "10.1016/j.neunet.2021.05.016", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, the functional magnetic resonance imaging (fMRI) is a vital\ntool to non-invasively access brain activity. Using fMRI, the functional\nconnectivity (FC) between brain regions can be inferred, which has contributed\nto a number of findings of the fundamental properties of the brain. As an\nimportant clinical application of FC, clustering of subjects based on FC\nrecently draws much attention, which can potentially reveal important\nheterogeneity in subjects such as subtypes of psychiatric disorders. In\nparticular, a multiple-view clustering method is a powerful analytical tool,\nwhich identifies clustering patterns of subjects depending on their FC in\nspecific brain areas. However, when one applies an existing multiple-view\nclustering method to fMRI data, there is a need to simplify the data structure,\nindependently dealing with elements in a FC matrix, i.e., vectorizing a\ncorrelation matrix. Such a simplification may distort the clustering results.\nTo overcome this problem, we propose a novel multiple-view clustering method\nbased on Wishart mixture models, which preserves the correlation matrix\nstructure without vectorization. The uniqueness of this method is that the\nmultiple-view clustering of subjects is based on particular networks of nodes\n(or regions of interest, ROIs), optimized in a data-driven manner. Hence, it\ncan identify multiple underlying pairs of associations between a subject\ncluster solution and a ROI sub-network. The key assumption of the method is\nindependence among sub-networks, which is effectively addressed by whitening\ncorrelation matrices. We applied the proposed method to synthetic and fMRI\ndata, demonstrating the usefulness and power of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 00:51:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 11:14:53 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Tokuda", "Tomoki", ""], ["Yamashita", "Okito", ""], ["Yoshimoto", "Junichiro", ""]]}, {"id": "2010.09993", "submitter": "Cesar A. Uribe", "authors": "Eduardo Mojica-Nava and David Yanguas-Rojas and C\\'esar A. Uribe", "title": "Robust Asynchronous and Network-Independent Cooperative Learning", "comments": "Submitted to ACC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of cooperative learning via distributed non-Bayesian\nlearning, where a network of agents tries to jointly agree on a hypothesis that\nbest described a sequence of locally available observations. Building upon\nrecently proposed weak communication network models, we propose a robust\ncooperative learning rule that allows asynchronous communications, message\ndelays, unpredictable message losses, and directed communication among nodes.\nWe show that our proposed learning dynamics guarantee that all agents in the\nnetwork will have an asymptotic exponential decay of their beliefs on the wrong\nhypothesis, indicating that the beliefs of all agents will concentrate on the\noptimal hypotheses. Numerical experiments provide evidence on a number of\nnetwork setups.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 03:54:20 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mojica-Nava", "Eduardo", ""], ["Yanguas-Rojas", "David", ""], ["Uribe", "C\u00e9sar A.", ""]]}, {"id": "2010.10012", "submitter": "Adish Singla", "authors": "Farnam Mansouri, Yuxin Chen, Ara Vartanian, Xiaojin Zhu, Adish Singla", "title": "Preference-Based Batch and Sequential Teaching", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.10944", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic machine teaching studies the interaction between a teacher and a\nlearner where the teacher selects labeled examples aiming at teaching a target\nhypothesis. In a quest to lower teaching complexity, several teaching models\nand complexity measures have been proposed for both the batch settings (e.g.,\nworst-case, recursive, preference-based, and non-clashing models) and the\nsequential settings (e.g., local preference-based model). To better understand\nthe connections between these models, we develop a novel framework that\ncaptures the teaching process via preference functions $\\Sigma$. In our\nframework, each function $\\sigma \\in \\Sigma$ induces a teacher-learner pair\nwith teaching complexity as $TD(\\sigma)$. We show that the above-mentioned\nteaching models are equivalent to specific types/families of preference\nfunctions. We analyze several properties of the teaching complexity parameter\n$TD(\\sigma)$ associated with different families of the preference functions,\ne.g., comparison to the VC dimension of the hypothesis class and\nadditivity/sub-additivity of $TD(\\sigma)$ over disjoint domains. Finally, we\nidentify preference functions inducing a novel family of sequential models with\nteaching complexity linear in the VC dimension: this is in contrast to the\nbest-known complexity result for the batch models, which is quadratic in the VC\ndimension.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 14:39:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mansouri", "Farnam", ""], ["Chen", "Yuxin", ""], ["Vartanian", "Ara", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2010.10030", "submitter": "Mohammad Mohammadi Amiri Dr.", "authors": "Mohammad Mohammadi Amiri, Tolga M. Duman, Deniz Gunduz, Sanjeev R.\n  Kulkarni, H. Vincent Poor", "title": "Blind Federated Edge Learning", "comments": "submitted for publication. arXiv admin note: text overlap with\n  arXiv:1907.03909", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study federated edge learning (FEEL), where wireless edge devices, each\nwith its own dataset, learn a global model collaboratively with the help of a\nwireless access point acting as the parameter server (PS). At each iteration,\nwireless devices perform local updates using their local data and the most\nrecent global model received from the PS, and send their local updates to the\nPS over a wireless fading multiple access channel (MAC). The PS then updates\nthe global model according to the signal received over the wireless MAC, and\nshares it with the devices. Motivated by the additive nature of the wireless\nMAC, we propose an analog `over-the-air' aggregation scheme, in which the\ndevices transmit their local updates in an uncoded fashion. Unlike recent\nliterature on over-the-air edge learning, here we assume that the devices do\nnot have channel state information (CSI), while the PS has imperfect CSI.\nInstead, the PS is equipped multiple antennas to alleviate the destructive\neffect of the channel, exacerbated due to the lack of perfect CSI. We design a\nreceive beamforming scheme at the PS, and show that it can compensate for the\nlack of perfect CSI when the PS has a sufficient number of antennas. We also\nderive the convergence rate of the proposed algorithm highlighting the impact\nof the lack of perfect CSI, as well as the number of PS antennas. Both the\nexperimental results and the convergence analysis illustrate the performance\nimprovement of the proposed algorithm with the number of PS antennas, where the\nwireless fading MAC becomes deterministic despite the lack of perfect CSI when\nthe PS has a sufficiently large number of antennas.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:22:28 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Duman", "Tolga M.", ""], ["Gunduz", "Deniz", ""], ["Kulkarni", "Sanjeev R.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2010.10045", "submitter": "Fuwei Li", "authors": "Fuwei Li, Lifeng Lai, Shuguang Cui", "title": "On the Adversarial Robustness of LASSO Based Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the adversarial robustness of feature selection\nbased on the $\\ell_1$ regularized linear regression model, namely LASSO. In the\nconsidered model, there is a malicious adversary who can observe the whole\ndataset, and then will carefully modify the response values or the feature\nmatrix in order to manipulate the selected features. We formulate the\nmodification strategy of the adversary as a bi-level optimization problem. Due\nto the difficulty of the non-differentiability of the $\\ell_1$ norm at the zero\npoint, we reformulate the $\\ell_1$ norm regularizer as linear inequality\nconstraints. We employ the interior-point method to solve this reformulated\nLASSO problem and obtain the gradient information. Then we use the projected\ngradient descent method to design the modification strategy. In addition, We\ndemonstrate that this method can be extended to other $\\ell_1$ based feature\nselection methods, such as group LASSO and sparse group LASSO. Numerical\nexamples with synthetic and real data illustrate that our method is efficient\nand effective.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 05:51:26 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Li", "Fuwei", ""], ["Lai", "Lifeng", ""], ["Cui", "Shuguang", ""]]}, {"id": "2010.10059", "submitter": "Sebastian Buschj\\\"ager", "authors": "Sebastian Buschj\\\"ager, Philipp-Jan Honysz, Lukas Pfahler, Katharina\n  Morik", "title": "Very Fast Streaming Submodular Function Maximization", "comments": "9 pages, 14 pages appendix, 5 figures, 2 tables, 10 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data summarization has become a valuable tool in understanding even terabytes\nof data. Due to their compelling theoretical properties, submodular functions\nhave been in the focus of summarization algorithms. These algorithms offer\nworst-case approximations guarantees to the expense of higher computation and\nmemory requirements. However, many practical applications do not fall under\nthis worst-case, but are usually much more well-behaved. In this paper, we\npropose a new submodular function maximization algorithm called ThreeSieves,\nwhich ignores the worst-case, but delivers a good solution in high probability.\nIt selects the most informative items from a data-stream on the fly and\nmaintains a provable performance on a fixed memory budget. In an extensive\nevaluation, we compare our method against $6$ other methods on $8$ different\ndatasets with and without concept drift. We show that our algorithm outperforms\ncurrent state-of-the-art algorithms and, at the same time, uses fewer\nresources. Last, we highlight a real-world use-case of our algorithm for data\nsummarization in gamma-ray astronomy. We make our code publicly available at\nhttps://github.com/sbuschjaeger/SubmodularStreamingMaximization.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 06:36:14 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:26:06 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 08:13:58 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 11:14:34 GMT"}, {"version": "v5", "created": "Sat, 8 May 2021 21:11:53 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Buschj\u00e4ger", "Sebastian", ""], ["Honysz", "Philipp-Jan", ""], ["Pfahler", "Lukas", ""], ["Morik", "Katharina", ""]]}, {"id": "2010.10070", "submitter": "Lorenzo Croissant", "authors": "Lorenzo Croissant, Marc Abeille, Cl\\'ement Calauz\\`enes", "title": "Real-Time Optimisation for Online Learning in Auctions", "comments": "International Conference on Machine Learning 2020, Jul 2020, Vienna,\n  Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In display advertising, a small group of sellers and bidders face each other\nin up to 10 12 auctions a day. In this context, revenue maximisation via\nmonopoly price learning is a high-value problem for sellers. By nature, these\nauctions are online and produce a very high frequency stream of data. This\nresults in a computational strain that requires algorithms be real-time.\nUnfortunately, existing methods inherited from the batch setting suffer\nO($\\sqrt t$) time/memory complexity at each update, prohibiting their use. In\nthis paper, we provide the first algorithm for online learning of monopoly\nprices in online auctions whose update is constant in time and memory.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 06:58:46 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Croissant", "Lorenzo", ""], ["Abeille", "Marc", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""]]}, {"id": "2010.10075", "submitter": "Tae-Min Choi", "authors": "Tae-Min Choi, Ji-Su Kang, Jong-Hwan Kim", "title": "RDIS: Random Drop Imputation with Self-Training for Incomplete Time\n  Series Data", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common that time-series data with missing values are encountered in\nmany fields such as in finance, meteorology, and robotics. Imputation is an\nintrinsic method to handle such missing values. In the previous research, most\nof imputation networks were trained implicitly for the incomplete time series\ndata because missing values have no ground truth. This paper proposes Random\nDrop Imputation with Self-training (RDIS), a novel training method for\nimputation networks for the incomplete time-series data. In RDIS, there are\nextra missing values by applying a random drop on the given incomplete data\nsuch that the imputation network can explicitly learn by imputing the random\ndrop values. Also, self-training is introduced to exploit the original missing\nvalues without ground truth. To verify the effectiveness of our RDIS on\nimputation tasks, we graft RDIS to a bidirectional GRU and achieve\nstate-of-the-art results on two real-world datasets, an air quality dataset and\na gas sensor dataset with 7.9% and 5.8% margin, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:04:25 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Choi", "Tae-Min", ""], ["Kang", "Ji-Su", ""], ["Kim", "Jong-Hwan", ""]]}, {"id": "2010.10079", "submitter": "Dinghuai Zhang", "authors": "Yanzhi Chen, Dinghuai Zhang, Michael Gutmann, Aaron Courville,\n  Zhanxing Zhu", "title": "Neural Approximate Sufficient Statistics for Implicit Models", "comments": "ICLR2021 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the fundamental problem of how to automatically construct summary\nstatistics for implicit generative models where the evaluation of the\nlikelihood function is intractable, but sampling data from the model is\npossible. The idea is to frame the task of constructing sufficient statistics\nas learning mutual information maximizing representations of the data with the\nhelp of deep neural networks. The infomax learning procedure does not need to\nestimate any density or density ratio. We apply our approach to both\ntraditional approximate Bayesian computation and recent neural likelihood\nmethods, boosting their performance on a range of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:11:40 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 13:35:14 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Yanzhi", ""], ["Zhang", "Dinghuai", ""], ["Gutmann", "Michael", ""], ["Courville", "Aaron", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "2010.10090", "submitter": "Guangda Ji", "authors": "Guangda Ji, Zhanxing Zhu", "title": "Knowledge Distillation in Wide Neural Networks: Risk Bound, Data\n  Efficiency and Imperfect Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is a strategy of training a student network with guide\nof the soft output from a teacher network. It has been a successful method of\nmodel compression and knowledge transfer. However, currently knowledge\ndistillation lacks a convincing theoretical understanding. On the other hand,\nrecent finding on neural tangent kernel enables us to approximate a wide neural\nnetwork with a linear model of the network's random features. In this paper, we\ntheoretically analyze the knowledge distillation of a wide neural network.\nFirst we provide a transfer risk bound for the linearized model of the network.\nThen we propose a metric of the task's training difficulty, called data\ninefficiency. Based on this metric, we show that for a perfect teacher, a high\nratio of teacher's soft labels can be beneficial. Finally, for the case of\nimperfect teacher, we find that hard labels can correct teacher's wrong\nprediction, which explains the practice of mixing hard and soft labels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:33:21 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Ji", "Guangda", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "2010.10151", "submitter": "Eleonora Giunchiglia", "authors": "Eleonora Giunchiglia, Thomas Lukasiewicz", "title": "Coherent Hierarchical Multi-Label Classification Networks", "comments": "Neural Information Processing Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical multi-label classification (HMC) is a challenging classification\ntask extending standard multi-label classification problems by imposing a\nhierarchy constraint on the classes. In this paper, we propose C-HMCNN(h), a\nnovel approach for HMC problems, which, given a network h for the underlying\nmulti-label classification problem, exploits the hierarchy information in order\nto produce predictions coherent with the constraint and improve performance. We\nconduct an extensive experimental analysis showing the superior performance of\nC-HMCNN(h) when compared to state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 09:37:02 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Giunchiglia", "Eleonora", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2010.10168", "submitter": "Fan Wu", "authors": "Fan Wu and Patrick Rebeschini", "title": "A Continuous-Time Mirror Descent Approach to Sparse Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze continuous-time mirror descent applied to sparse phase retrieval,\nwhich is the problem of recovering sparse signals from a set of magnitude-only\nmeasurements. We apply mirror descent to the unconstrained empirical risk\nminimization problem (batch setting), using the square loss and square\nmeasurements. We provide a convergence analysis of the algorithm in this\nnon-convex setting and prove that, with the hypentropy mirror map, mirror\ndescent recovers any $k$-sparse vector $\\mathbf{x}^\\star\\in\\mathbb{R}^n$ with\nminimum (in modulus) non-zero entry on the order of $\\| \\mathbf{x}^\\star\n\\|_2/\\sqrt{k}$ from $k^2$ Gaussian measurements, modulo logarithmic terms. This\nyields a simple algorithm which, unlike most existing approaches to sparse\nphase retrieval, adapts to the sparsity level, without including thresholding\nsteps or adding regularization terms. Our results also provide a principled\ntheoretical understanding for Hadamard Wirtinger flow [58], as Euclidean\ngradient descent applied to the empirical risk problem with Hadamard\nparametrization can be recovered as a first-order approximation to mirror\ndescent in discrete time.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:03:44 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Wu", "Fan", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "2010.10177", "submitter": "Matthew Ashman", "authors": "Matthew Ashman, Jonathan So, Will Tebbutt, Vincent Fortuin, Michael\n  Pearce, Richard E. Turner", "title": "Sparse Gaussian Process Variational Autoencoders", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, multi-dimensional spatio-temporal datasets are omnipresent in modern\nscience and engineering. An effective framework for handling such data are\nGaussian process deep generative models (GP-DGMs), which employ GP priors over\nthe latent variables of DGMs. Existing approaches for performing inference in\nGP-DGMs do not support sparse GP approximations based on inducing points, which\nare essential for the computational efficiency of GPs, nor do they handle\nmissing data -- a natural occurrence in many spatio-temporal datasets -- in a\nprincipled manner. We address these shortcomings with the development of the\nsparse Gaussian process variational autoencoder (SGP-VAE), characterised by the\nuse of partial inference networks for parameterising sparse GP approximations.\nLeveraging the benefits of amortised variational inference, the SGP-VAE enables\ninference in multi-output sparse GPs on previously unobserved data with no\nadditional training. The SGP-VAE is evaluated in a variety of experiments where\nit outperforms alternative approaches including multi-output GPs and structured\nVAEs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:19:56 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 10:29:06 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Ashman", "Matthew", ""], ["So", "Jonathan", ""], ["Tebbutt", "Will", ""], ["Fortuin", "Vincent", ""], ["Pearce", "Michael", ""], ["Turner", "Richard E.", ""]]}, {"id": "2010.10181", "submitter": "Voot Tangkaratt", "authors": "Voot Tangkaratt, Nontawat Charoenphakdee, and Masashi Sugiyama", "title": "Robust Imitation Learning from Noisy Demonstrations", "comments": "16 pages, 9 figures. Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust learning from noisy demonstrations is a practical but highly\nchallenging problem in imitation learning. In this paper, we first\ntheoretically show that robust imitation learning can be achieved by optimizing\na classification risk with a symmetric loss. Based on this theoretical finding,\nwe then propose a new imitation learning method that optimizes the\nclassification risk by effectively combining pseudo-labeling with co-training.\nUnlike existing methods, our method does not require additional labels or\nstrict assumptions about noise distributions. Experimental results on\ncontinuous-control benchmarks show that our method is more robust compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:41:37 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 05:34:29 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 13:38:24 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Tangkaratt", "Voot", ""], ["Charoenphakdee", "Nontawat", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2010.10182", "submitter": "Claire Vernade", "authors": "Alexandra Carpentier and Claire Vernade and Yasin Abbasi-Yadkori", "title": "The Elliptical Potential Lemma Revisited", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note proposes a new proof and new perspectives on the so-called\nElliptical Potential Lemma. This result is important in online learning,\nespecially for linear stochastic bandits. The original proof of the result,\nhowever short and elegant, does not give much flexibility on the type of\npotentials considered and we believe that this new interpretation can be of\ninterest for future research in this field.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:43:41 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Carpentier", "Alexandra", ""], ["Vernade", "Claire", ""], ["Abbasi-Yadkori", "Yasin", ""]]}, {"id": "2010.10194", "submitter": "Solt Kov\\'acs", "authors": "Solt Kov\\'acs, Housen Li, Lorenz Haubner, Axel Munk, Peter B\\\"uhlmann", "title": "Optimistic search strategy: Change point detection for large-scale data\n  via adaptive logarithmic queries", "comments": "extended Table 1; added Model II and Lemma 5.3; added further minor\n  explanations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a classical and ever reviving topic, change point detection is often\nformulated as a search for the maximum of a gain function describing improved\nfits when segmenting the data. Searching through all candidate split points on\nthe grid for finding the best one requires $O(T)$ evaluations of the gain\nfunction for an interval with $T$ observations. If each evaluation is\ncomputationally demanding (e.g. in high-dimensional models), this can become\ninfeasible. Instead, we propose optimistic search strategies with $O(\\log T)$\nevaluations exploiting specific structure of the gain function.\n  Towards solid understanding of our strategies, we investigate in detail the\nclassical univariate Gaussian change in mean setup. For some of our proposals\nwe prove asymptotic minimax optimality for single and multiple change point\nscenarios. Our search strategies generalize far beyond the theoretically\nanalyzed univariate setup. We illustrate, as an example, massive computational\nspeedup in change point detection for high-dimensional Gaussian graphical\nmodels. More generally, we demonstrate empirically that our optimistic search\nmethods lead to competitive estimation performance while heavily reducing\nrun-time.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 11:09:52 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 23:50:55 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kov\u00e1cs", "Solt", ""], ["Li", "Housen", ""], ["Haubner", "Lorenz", ""], ["Munk", "Axel", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "2010.10218", "submitter": "Anant Raj", "authors": "Anant Raj and Cameron Musco and Lester Mackey and Nicolo Fusi", "title": "Model-specific Data Subsampling with Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection requires repeatedly evaluating models on a given dataset and\nmeasuring their relative performances. In modern applications of machine\nlearning, the models being considered are increasingly more expensive to\nevaluate and the datasets of interest are increasing in size. As a result, the\nprocess of model selection is time-consuming and computationally inefficient.\nIn this work, we develop a model-specific data subsampling strategy that\nimproves over random sampling whenever training points have varying influence.\nSpecifically, we leverage influence functions to guide our selection strategy,\nproving theoretically, and demonstrating empirically that our approach quickly\nselects high-quality models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 12:10:28 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Raj", "Anant", ""], ["Musco", "Cameron", ""], ["Mackey", "Lester", ""], ["Fusi", "Nicolo", ""]]}, {"id": "2010.10241", "submitter": "Michal Valko", "authors": "Pierre H. Richemond, Jean-Bastien Grill, Florent Altch\\'e, Corentin\n  Tallec, Florian Strub, Andrew Brock, Samuel Smith, Soham De, Razvan Pascanu,\n  Bilal Piot, Michal Valko", "title": "BYOL works even without batch statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap Your Own Latent (BYOL) is a self-supervised learning approach for\nimage representation. From an augmented view of an image, BYOL trains an online\nnetwork to predict a target network representation of a different augmented\nview of the same image. Unlike contrastive methods, BYOL does not explicitly\nuse a repulsion term built from negative pairs in its training objective. Yet,\nit avoids collapse to a trivial, constant representation. Thus, it has recently\nbeen hypothesized that batch normalization (BN) is critical to prevent collapse\nin BYOL. Indeed, BN flows gradients across batch elements, and could leak\ninformation about negative views in the batch, which could act as an implicit\nnegative (contrastive) term. However, we experimentally show that replacing BN\nwith a batch-independent normalization scheme (namely, a combination of group\nnormalization and weight standardization) achieves performance comparable to\nvanilla BYOL ($73.9\\%$ vs. $74.3\\%$ top-1 accuracy under the linear evaluation\nprotocol on ImageNet with ResNet-$50$). Our finding disproves the hypothesis\nthat the use of batch statistics is a crucial ingredient for BYOL to learn\nuseful representations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 13:05:05 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Grill", "Jean-Bastien", ""], ["Altch\u00e9", "Florent", ""], ["Tallec", "Corentin", ""], ["Strub", "Florian", ""], ["Brock", "Andrew", ""], ["Smith", "Samuel", ""], ["De", "Soham", ""], ["Pascanu", "Razvan", ""], ["Piot", "Bilal", ""], ["Valko", "Michal", ""]]}, {"id": "2010.10346", "submitter": "Fernando Llorente Fern\\'andez", "authors": "F. Llorente, L. Martino, D. Delgado, G. Camps-Valls", "title": "Deep Importance Sampling based on Regression for Model Inversion and\n  Emulation", "comments": null, "journal-ref": null, "doi": "10.1016/j.dsp.2021.103104", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding systems by forward and inverse modeling is a recurrent topic of\nresearch in many domains of science and engineering. In this context, Monte\nCarlo methods have been widely used as powerful tools for numerical inference\nand optimization. They require the choice of a suitable proposal density that\nis crucial for their performance. For this reason, several adaptive importance\nsampling (AIS) schemes have been proposed in the literature. We here present an\nAIS framework called Regression-based Adaptive Deep Importance Sampling\n(RADIS). In RADIS, the key idea is the adaptive construction via regression of\na non-parametric proposal density (i.e., an emulator), which mimics the\nposterior distribution and hence minimizes the mismatch between proposal and\ntarget densities. RADIS is based on a deep architecture of two (or more) nested\nIS schemes, in order to draw samples from the constructed emulator. The\nalgorithm is highly efficient since employs the posterior approximation as\nproposal density, which can be improved adding more support points. As a\nconsequence, RADIS asymptotically converges to an exact sampler under mild\nconditions. Additionally, the emulator produced by RADIS can be in turn used as\na cheap surrogate model for further studies. We introduce two specific RADIS\nimplementations that use Gaussian Processes (GPs) and Nearest Neighbors (NN)\nfor constructing the emulator. Several numerical experiments and comparisons\nshow the benefits of the proposed schemes. A real-world application in remote\nsensing model inversion and emulation confirms the validity of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:12:30 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 18:46:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Llorente", "F.", ""], ["Martino", "L.", ""], ["Delgado", "D.", ""], ["Camps-Valls", "G.", ""]]}, {"id": "2010.10374", "submitter": "Valerio Lucarini", "authors": "Georgios Margazoglou and Tobias Grafke and Alessandro Laio and Valerio\n  Lucarini", "title": "Dynamical Landscape and Multistability of a Climate Model", "comments": "28 pages, 12 figures plus Supplementary Material. Revised version", "journal-ref": null, "doi": "10.1098/rspa.2021.0019", "report-no": null, "categories": "physics.ao-ph cond-mat.stat-mech physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply two independent data analysis methodologies to locate stable climate\nstates in an intermediate complexity climate model and analyze their interplay.\nFirst, drawing from the theory of quasipotentials, and viewing the state space\nas an energy landscape with valleys and mountain ridges, we infer the relative\nlikelihood of the identified multistable climate states, and investigate the\nmost likely transition trajectories as well as the expected transition times\nbetween them. Second, harnessing techniques from data science, specifically\nmanifold learning, we characterize the data landscape of the simulation output\nto find climate states and basin boundaries within a fully agnostic and\nunsupervised framework. Both approaches show remarkable agreement, and reveal,\napart from the well known warm and snowball earth states, a third intermediate\nstable state in one of the two climate models we consider. The combination of\nour approaches allows to identify how the negative feedback of ocean heat\ntransport and entropy production via the hydrological cycle drastically change\nthe topography of the dynamical landscape of Earth's climate.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:31:38 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 23:24:13 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Margazoglou", "Georgios", ""], ["Grafke", "Tobias", ""], ["Laio", "Alessandro", ""], ["Lucarini", "Valerio", ""]]}, {"id": "2010.10412", "submitter": "Qiong Zhang", "authors": "Qiong Zhang and Jiahua Chen", "title": "Distributed Learning of Finite Gaussian Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in information technology have led to extremely large datasets that\nare often kept in different storage centers. Existing statistical methods must\nbe adapted to overcome the resulting computational obstacles while retaining\nstatistical validity and efficiency. Split-and-conquer approaches have been\napplied in many areas, including quantile processes, regression analysis,\nprincipal eigenspaces, and exponential families. We study split-and-conquer\napproaches for the distributed learning of finite Gaussian mixtures. We\nrecommend a reduction strategy and develop an effective MM algorithm. The new\nestimator is shown to be consistent and retains root-n consistency under some\ngeneral conditions. Experiments based on simulated and real-world data show\nthat the proposed split-and-conquer approach has comparable statistical\nperformance with the global estimator based on the full dataset, if the latter\nis feasible. It can even slightly outperform the global estimator if the model\nassumption does not match the real-world data. It also has better statistical\nand computational performance than some existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:17:47 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 23:24:21 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Qiong", ""], ["Chen", "Jiahua", ""]]}, {"id": "2010.10436", "submitter": "Lorenz Richter", "authors": "Lorenz Richter, Ayman Boustati, Nikolas N\\\"usken, Francisco J. R.\n  Ruiz, \\\"Omer Deniz Akyildiz", "title": "VarGrad: A Low-Variance Gradient Estimator for Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the properties of an unbiased gradient estimator of the ELBO for\nvariational inference, based on the score function method with leave-one-out\ncontrol variates. We show that this gradient estimator can be obtained using a\nnew loss, defined as the variance of the log-ratio between the exact posterior\nand the variational approximation, which we call the $\\textit{log-variance\nloss}$. Under certain conditions, the gradient of the log-variance loss equals\nthe gradient of the (negative) ELBO. We show theoretically that this gradient\nestimator, which we call $\\textit{VarGrad}$ due to its connection to the\nlog-variance loss, exhibits lower variance than the score function method in\ncertain settings, and that the leave-one-out control variate coefficients are\nclose to the optimal ones. We empirically demonstrate that VarGrad offers a\nfavourable variance versus computation trade-off compared to other\nstate-of-the-art estimators on a discrete VAE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:46:01 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 10:27:27 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Richter", "Lorenz", ""], ["Boustati", "Ayman", ""], ["N\u00fcsken", "Nikolas", ""], ["Ruiz", "Francisco J. R.", ""], ["Akyildiz", "\u00d6mer Deniz", ""]]}, {"id": "2010.10450", "submitter": "Siddharth Mishra-Sharma", "authors": "Siddharth Mishra-Sharma and Kyle Cranmer", "title": "Semi-parametric $\\gamma$-ray modeling with Gaussian processes and\n  variational inference", "comments": "8 pages, 1 figure, extended abstract submitted to the Machine\n  Learning and the Physical Sciences Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.HE astro-ph.CO astro-ph.IM hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mismodeling the uncertain, diffuse emission of Galactic origin can seriously\nbias the characterization of astrophysical gamma-ray data, particularly in the\nregion of the Inner Milky Way where such emission can make up over 80% of the\nphoton counts observed at ~GeV energies. We introduce a novel class of methods\nthat use Gaussian processes and variational inference to build flexible\nbackground and signal models for gamma-ray analyses with the goal of enabling a\nmore robust interpretation of the make-up of the gamma-ray sky, particularly\nfocusing on characterizing potential signals of dark matter in the Galactic\nCenter with data from the Fermi telescope.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:04:37 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mishra-Sharma", "Siddharth", ""], ["Cranmer", "Kyle", ""]]}, {"id": "2010.10502", "submitter": "Samy Jelassi", "authors": "Samy Jelassi, Aaron Defazio", "title": "Dual Averaging is Surprisingly Effective for Deep Learning Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order stochastic optimization methods are currently the most widely\nused class of methods for training deep neural networks. However, the choice of\nthe optimizer has become an ad-hoc rule that can significantly affect the\nperformance. For instance, SGD with momentum (SGD+M) is typically used in\ncomputer vision (CV) and Adam is used for training transformer models for\nNatural Language Processing (NLP). Using the wrong method can lead to\nsignificant performance degradation. Inspired by the dual averaging algorithm,\nwe propose Modernized Dual Averaging (MDA), an optimizer that is able to\nperform as well as SGD+M in CV and as Adam in NLP. Our method is not adaptive\nand is significantly simpler than Adam. We show that MDA induces a decaying\nuncentered $L_2$-regularization compared to vanilla SGD+M and hypothesize that\nthis may explain why it works on NLP problems where SGD+M fails.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:55:11 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Jelassi", "Samy", ""], ["Defazio", "Aaron", ""]]}, {"id": "2010.10549", "submitter": "Alexander Levine", "authors": "Alexander Levine, Aounon Kumar, Thomas Goldstein, and Soheil Feizi", "title": "Tight Second-Order Certificates for Randomized Smoothing", "comments": "Updated to reference and reflect results of concurrent work,\n  Mohapatra et al., which shows that second-order certificates are possible\n  using sqrt(d) samples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing is a popular way of providing robustness guarantees\nagainst adversarial attacks: randomly-smoothed functions have a universal\nLipschitz-like bound, allowing for robustness certificates to be easily\ncomputed. In this work, we show that there also exists a universal\ncurvature-like bound for Gaussian random smoothing: given the exact value and\ngradient of a smoothed function, we compute a lower bound on the distance of a\npoint to its closest adversarial example, called the Second-order Smoothing\n(SoS) robustness certificate. In addition to proving the correctness of this\nnovel certificate, we show that SoS certificates are realizable and therefore\ntight. Interestingly, we show that the maximum achievable benefits, in terms of\ncertified robustness, from using the additional information of the gradient\nnorm are relatively small: because our bounds are tight, this is a fundamental\nnegative result. The gain of SoS certificates further diminishes if we consider\nthe estimation error of the gradient norms, for which we have developed an\nestimator. We therefore additionally develop a variant of Gaussian smoothing,\ncalled Gaussian dipole smoothing, which provides similar bounds to randomized\nsmoothing with gradient information, but with much-improved sample efficiency.\nThis allows us to achieve (marginally) improved robustness certificates on\nhigh-dimensional datasets such as CIFAR-10 and ImageNet. Code is available at\nhttps://github.com/alevine0/smoothing_second_order.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 18:03:45 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 03:17:36 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Levine", "Alexander", ""], ["Kumar", "Aounon", ""], ["Goldstein", "Thomas", ""], ["Feizi", "Soheil", ""]]}, {"id": "2010.10569", "submitter": "Anusha Lalitha", "authors": "Anusha Lalitha and Andrea Goldsmith", "title": "Bayesian Algorithms for Decentralized Stochastic Bandits", "comments": "Submitted to IEEE Journal on Selected Areas in Information Theory\n  (JSAIT) issue on Sequential, Active, and Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a decentralized cooperative multi-agent multi-armed bandit problem\nwith $K$ arms and $N$ agents connected over a network. In our model, each arm's\nreward distribution is same for all agents, and rewards are drawn independently\nacross agents and over time steps. In each round, agents choose an arm to play\nand subsequently send a message to their neighbors. The goal is to minimize\ncumulative regret averaged over the entire network. We propose a decentralized\nBayesian multi-armed bandit framework that extends single-agent Bayesian bandit\nalgorithms to the decentralized setting. Specifically, we study an information\nassimilation algorithm that can be combined with existing Bayesian algorithms,\nand using this, we propose a decentralized Thompson Sampling algorithm and\ndecentralized Bayes-UCB algorithm. We analyze the decentralized Thompson\nSampling algorithm under Bernoulli rewards and establish a problem-dependent\nupper bound on the cumulative regret. We show that regret incurred scales\nlogarithmically over the time horizon with constants that match those of an\noptimal centralized agent with access to all observations across the network.\nOur analysis also characterizes the cumulative regret in terms of the network\nstructure. Through extensive numerical studies, we show that our extensions of\nThompson Sampling and Bayes-UCB incur lesser cumulative regret than the\nstate-of-art algorithms inspired by the Upper Confidence Bound algorithm. We\nimplement our proposed decentralized Thompson Sampling under gossip protocol,\nand over time-varying networks, where each communication link has a fixed\nprobability of failure.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 19:14:20 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 00:06:05 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Lalitha", "Anusha", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "2010.10596", "submitter": "Sahil Verma", "authors": "Sahil Verma and John Dickerson and Keegan Hines", "title": "Counterfactual Explanations for Machine Learning: A Review", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays a role in many deployed decision systems, often in\nways that are difficult or impossible to understand by human stakeholders.\nExplaining, in a human-understandable way, the relationship between the input\nand output of machine learning models is essential to the development of\ntrustworthy machine-learning-based systems. A burgeoning body of research seeks\nto define the goals and methods of explainability in machine learning. In this\npaper, we seek to review and categorize research on counterfactual\nexplanations, a specific class of explanation that provides a link between what\ncould have happened had input to a model been changed in a particular way.\nModern approaches to counterfactual explainability in machine learning draw\nconnections to the established legal doctrine in many countries, making them\nappealing to fielded systems in high-impact areas such as finance and\nhealthcare. Thus, we design a rubric with desirable properties of\ncounterfactual explanation algorithms and comprehensively evaluate all\ncurrently-proposed algorithms against that rubric. Our rubric provides easy\ncomparison and comprehension of the advantages and disadvantages of different\napproaches and serves as an introduction to major research themes in this\nfield. We also identify gaps and discuss promising research directions in the\nspace of counterfactual explainability.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:08:42 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Verma", "Sahil", ""], ["Dickerson", "John", ""], ["Hines", "Keegan", ""]]}, {"id": "2010.10604", "submitter": "Xinjie Fan", "authors": "Xinjie Fan and Shujian Zhang and Bo Chen and Mingyuan Zhou", "title": "Bayesian Attention Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention modules, as simple and effective tools, have not only enabled deep\nneural networks to achieve state-of-the-art results in many domains, but also\nenhanced their interpretability. Most current models use deterministic\nattention modules due to their simplicity and ease of optimization. Stochastic\ncounterparts, on the other hand, are less popular despite their potential\nbenefits. The main reason is that stochastic attention often introduces\noptimization issues or requires significant model changes. In this paper, we\npropose a scalable stochastic version of attention that is easy to implement\nand optimize. We construct simplex-constrained attention distributions by\nnormalizing reparameterizable distributions, making the training process\ndifferentiable. We learn their parameters in a Bayesian framework where a\ndata-dependent prior is introduced for regularization. We apply the proposed\nstochastic attention modules to various attention-based models, with\napplications to graph node classification, visual question answering, image\ncaptioning, machine translation, and language understanding. Our experiments\nshow the proposed method brings consistent improvements over the corresponding\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 20:30:55 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Fan", "Xinjie", ""], ["Zhang", "Shujian", ""], ["Chen", "Bo", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2010.10631", "submitter": "Hemant Kumar Aggarwal", "authors": "Hemant Kumar Aggarwal, Aniket Pramanik, Mathews Jacob", "title": "ENSURE: A General Approach for Unsupervised Training of Deep Image\n  Reconstruction Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image reconstruction using deep learning algorithms offers improved\nreconstruction quality and lower reconstruction time than classical compressed\nsensing and model-based algorithms. Unfortunately, clean and fully sampled\nground-truth data to train the deep networks is often not available in several\napplications, restricting the applicability of the above methods. This work\nintroduces the ENsemble Stein's Unbiased Risk Estimate (ENSURE) framework as a\ngeneral approach to train deep image reconstruction algorithms without fully\nsampled and noise-free images. The proposed framework is the generalization of\nthe classical SURE and GSURE formulation to the setting where the images are\nsampled by different measurement operators, chosen randomly from a set. We show\nthat the ENSURE loss function, which only uses the measurement data, is an\nunbiased estimate for the true mean-square error. Our experiments show that the\nnetworks trained with this loss function can offer reconstructions comparable\nto the supervised setting. While we demonstrate this framework in the context\nof MR image recovery, the ENSURE framework is generally applicable to arbitrary\ninverse problems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 21:18:33 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 16:31:08 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 18:06:00 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Aggarwal", "Hemant Kumar", ""], ["Pramanik", "Aniket", ""], ["Jacob", "Mathews", ""]]}, {"id": "2010.10644", "submitter": "Daniel J. Mankowitz", "authors": "Daniel J. Mankowitz and Dan A. Calian and Rae Jeong and Cosmin\n  Paduraru and Nicolas Heess and Sumanth Dathathri and Martin Riedmiller and\n  Timothy Mann", "title": "Robust Constrained Reinforcement Learning for Continuous Control with\n  Model Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world physical control systems are required to satisfy constraints\nupon deployment. Furthermore, real-world systems are often subject to effects\nsuch as non-stationarity, wear-and-tear, uncalibrated sensors and so on. Such\neffects effectively perturb the system dynamics and can cause a policy trained\nsuccessfully in one domain to perform poorly when deployed to a perturbed\nversion of the same domain. This can affect a policy's ability to maximize\nfuture rewards as well as the extent to which it satisfies constraints. We\nrefer to this as constrained model misspecification. We present an algorithm\nthat mitigates this form of misspecification, and showcase its performance in\nmultiple simulated Mujoco tasks from the Real World Reinforcement Learning\n(RWRL) suite.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 22:05:37 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 20:51:18 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 10:32:32 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 09:54:49 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Calian", "Dan A.", ""], ["Jeong", "Rae", ""], ["Paduraru", "Cosmin", ""], ["Heess", "Nicolas", ""], ["Dathathri", "Sumanth", ""], ["Riedmiller", "Martin", ""], ["Mann", "Timothy", ""]]}, {"id": "2010.10650", "submitter": "Zhun Deng", "authors": "Zhun Deng, Hangfeng He, Jiaoyang Huang, Weijie J. Su", "title": "Towards Understanding the Dynamics of the First-Order Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An acknowledged weakness of neural networks is their vulnerability to\nadversarial perturbations to the inputs. To improve the robustness of these\nmodels, one of the most popular defense mechanisms is to alternatively maximize\nthe loss over the constrained perturbations (or called adversaries) on the\ninputs using projected gradient ascent and minimize over weights. In this\npaper, we analyze the dynamics of the maximization step towards understanding\nthe experimentally observed effectiveness of this defense mechanism.\nSpecifically, we investigate the non-concave landscape of the adversaries for a\ntwo-layer neural network with a quadratic loss. Our main result proves that\nprojected gradient ascent finds a local maximum of this non-concave problem in\na polynomial number of iterations with high probability. To our knowledge, this\nis the first work that provides a convergence analysis of the first-order\nadversaries. Moreover, our analysis demonstrates that, in the initial phase of\nadversarial training, the scale of the inputs matters in the sense that a\nsmaller input scale leads to faster convergence of adversarial training and a\n\"more regular\" landscape. Finally, we show that these theoretical findings are\nin excellent agreement with a series of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 22:20:53 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Deng", "Zhun", ""], ["He", "Hangfeng", ""], ["Huang", "Jiaoyang", ""], ["Su", "Weijie J.", ""]]}, {"id": "2010.10711", "submitter": "Chengyuan Deng", "authors": "Chen Wang and Chengyuan Deng", "title": "On the Global Self-attention Mechanism for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Global Self-attention (GSA) mechanism over features has achieved\nremarkable success on Convolutional Neural Networks (CNNs). However, it is not\nclear if Graph Convolutional Networks (GCNs) can similarly benefit from such a\ntechnique. In this paper, inspired by the similarity between CNNs and GCNs, we\nstudy the impact of the Global Self-attention mechanism on GCNs. We find that\nconsistent with the intuition, the GSA mechanism allows GCNs to capture\nfeature-based vertex relations regardless of edge connections; As a result, the\nGSA mechanism can introduce extra expressive power to the GCNs. Furthermore, we\nanalyze the impacts of the GSA mechanism on the issues of overfitting and\nover-smoothing. We prove that the GSA mechanism can alleviate both the\noverfitting and the over-smoothing issues based on some recent technical\ndevelopments. Experiments on multiple benchmark datasets illustrate both\nsuperior expressive power and less significant overfitting and over-smoothing\nproblems for the GSA-augmented GCNs, which corroborate the intuitions and the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 02:09:33 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""]]}, {"id": "2010.10737", "submitter": "Ramanujam Madhavan", "authors": "Ramanujam Madhavan, Mohit Wadhwa", "title": "Directed Graph Representation through Vector Cross Product", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding methods embed the nodes in a graph in low dimensional vector\nspace while preserving graph topology to carry out the downstream tasks such as\nlink prediction, node recommendation and clustering. These tasks depend on a\nsimilarity measure such as cosine similarity and Euclidean distance between a\npair of embeddings that are symmetric in nature and hence do not hold good for\ndirected graphs. Recent work on directed graphs, HOPE, APP, and NERD, proposed\nto preserve the direction of edges among nodes by learning two embeddings,\nsource and target, for every node. However, these methods do not take into\naccount the properties of directed edges explicitly. To understand the\ndirectional relation among nodes, we propose a novel approach that takes\nadvantage of the non commutative property of vector cross product to learn\nembeddings that inherently preserve the direction of edges among nodes. We\nlearn the node embeddings through a Siamese neural network where the\ncross-product operation is incorporated into the network architecture. Although\ncross product between a pair of vectors is defined in three dimensional, the\napproach is extended to learn N dimensional embeddings while maintaining the\nnon-commutative property. In our empirical experiments on three real-world\ndatasets, we observed that even very low dimensional embeddings could\neffectively preserve the directional property while outperforming some of the\nstate-of-the-art methods on link prediction and node recommendation tasks\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 03:17:44 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Madhavan", "Ramanujam", ""], ["Wadhwa", "Mohit", ""]]}, {"id": "2010.10742", "submitter": "Mahdi Abolghasemi", "authors": "Mahdi Abolghasemi, Rob J Hyndman, Evangelos Spiliotis, Christoph\n  Bergmeir", "title": "Model selection in reconciling hierarchical time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection has been proven an effective strategy for improving accuracy\nin time series forecasting applications. However, when dealing with\nhierarchical time series, apart from selecting the most appropriate forecasting\nmodel, forecasters have also to select a suitable method for reconciling the\nbase forecasts produced for each series to make sure they are coherent.\nAlthough some hierarchical forecasting methods like minimum trace are strongly\nsupported both theoretically and empirically for reconciling the base\nforecasts, there are still circumstances under which they might not produce the\nmost accurate results, being outperformed by other methods. In this paper we\npropose an approach for dynamically selecting the most appropriate hierarchical\nforecasting method and succeeding better forecasting accuracy along with\ncoherence. The approach, to be called conditional hierarchical forecasting, is\nbased on Machine Learning classification methods and uses time series features\nas leading indicators for performing the selection for each hierarchy examined\nconsidering a variety of alternatives. Our results suggest that conditional\nhierarchical forecasting leads to significantly more accurate forecasts than\nstandard approaches, especially at lower hierarchical levels.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 03:40:35 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 09:58:14 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Abolghasemi", "Mahdi", ""], ["Hyndman", "Rob J", ""], ["Spiliotis", "Evangelos", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "2010.10786", "submitter": "Yiping Guo", "authors": "Yiping Guo and Howard D. Bondell", "title": "On Robust Probabilistic Principal Component Analysis using Multivariate\n  $t$-Distributions", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is a common multivariate statistical\nanalysis method, and Probabilistic Principal Component Analysis (PPCA) is its\nprobabilistic reformulation under the framework of Gaussian latent variable\nmodel. To improve the robustness of PPCA, it has been proposed to change the\nunderlying Gaussian distributions to multivariate $t$-distributions. Based on\nthe representation of $t$-distribution as a scale mixture of Gaussians, a\nhierarchical model is used for implementation. However, although the robust\nPPCA methods work reasonably well for some simulation studies and real data,\nthe hierarchical model implemented does not yield the equivalent\ninterpretation. In this paper, we present a set of equivalent relationships\nbetween those models, and discuss the performance of robust PPCA methods using\ndifferent multivariate $t$-distributed structures through several simulation\nstudies. In doing so, we clarify a current misrepresentation in the literature,\nand make connections between a set of hierarchical models for robust PPCA.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 06:49:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Guo", "Yiping", ""], ["Bondell", "Howard D.", ""]]}, {"id": "2010.10794", "submitter": "Andrew Lim", "authors": "Jun-ya Gotoh, Michael Jong Kim, Andrew E.B.Lim", "title": "Worst-case sensitivity", "comments": "27 Pages + 11 page Appendix, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.SY eess.SY q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of Worst-Case Sensitivity, defined as the worst-case\nrate of increase in the expected cost of a Distributionally Robust Optimization\n(DRO) model when the size of the uncertainty set vanishes. We show that\nworst-case sensitivity is a Generalized Measure of Deviation and that a large\nclass of DRO models are essentially mean-(worst-case) sensitivity problems when\nuncertainty sets are small, unifying recent results on the relationship between\nDRO and regularized empirical optimization with worst-case sensitivity playing\nthe role of the regularizer. More generally, DRO solutions can be sensitive to\nthe family and size of the uncertainty set, and reflect the properties of its\nworst-case sensitivity. We derive closed-form expressions of worst-case\nsensitivity for well known uncertainty sets including smooth $\\phi$-divergence,\ntotal variation, \"budgeted\" uncertainty sets, uncertainty sets corresponding to\na convex combination of expected value and CVaR, and the Wasserstein metric.\nThese can be used to select the uncertainty set and its size for a given\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 07:19:53 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gotoh", "Jun-ya", ""], ["Kim", "Michael Jong", ""], ["Lim", "Andrew E. B.", ""]]}, {"id": "2010.10797", "submitter": "Kejun Tang", "authors": "Yani Feng, Kejun Tang, Lianxing He, Pingqiang Zhou, Qifeng Liao", "title": "Tensor Train Random Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel tensor train random projection (TTRP) method for\ndimension reduction, where the pairwise distances can be approximately\npreserved. Based on the tensor train format, this new random projection method\ncan speed up the computation for high dimensional problems and requires less\nstorage with little loss in accuracy, compared with existing methods (e.g.,\nvery sparse random projection). Our TTRP is systematically constructed through\na rank-one TT-format with Rademacher random variables, which results in\nefficient projection with small variances. The isometry property of TTRP is\nproven in this work, and detailed numerical experiments with data sets\n(synthetic, MNIST and CIFAR-10) are conducted to demonstrate the efficiency of\nTTRP.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 07:31:45 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 05:42:43 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 02:34:56 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Feng", "Yani", ""], ["Tang", "Kejun", ""], ["He", "Lianxing", ""], ["Zhou", "Pingqiang", ""], ["Liao", "Qifeng", ""]]}, {"id": "2010.10814", "submitter": "Kaixin Wang", "authors": "Kaixin Wang, Bingyi Kang, Jie Shao, Jiashi Feng", "title": "Improving Generalization in Reinforcement Learning with Mixture\n  Regularization", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) agents trained in a limited set of\nenvironments tend to suffer overfitting and fail to generalize to unseen\ntesting environments. To improve their generalizability, data augmentation\napproaches (e.g. cutout and random convolution) are previously explored to\nincrease the data diversity. However, we find these approaches only locally\nperturb the observations regardless of the training environments, showing\nlimited effectiveness on enhancing the data diversity and the generalization\nperformance. In this work, we introduce a simple approach, named mixreg, which\ntrains agents on a mixture of observations from different training environments\nand imposes linearity constraints on the observation interpolations and the\nsupervision (e.g. associated reward) interpolations. Mixreg increases the data\ndiversity more effectively and helps learn smoother policies. We verify its\neffectiveness on improving generalization by conducting extensive experiments\non the large-scale Procgen benchmark. Results show mixreg outperforms the\nwell-established baselines on unseen testing environments by a large margin.\nMixreg is simple, effective and general. It can be applied to both policy-based\nand value-based RL algorithms. Code is available at\nhttps://github.com/kaixin96/mixreg .\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 08:12:03 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Kaixin", ""], ["Kang", "Bingyi", ""], ["Shao", "Jie", ""], ["Feng", "Jiashi", ""]]}, {"id": "2010.10886", "submitter": "Arezou Rezazadeh", "authors": "Arezou Rezazadeh, Sharu Theresa Jose, Giuseppe Durisi, Osvaldo Simeone", "title": "Conditional Mutual Information-Based Generalization Bound for Meta\n  Learning", "comments": "Submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning optimizes an inductive bias---typically in the form of the\nhyperparameters of a base-learning algorithm---by observing data from a finite\nnumber of related tasks. This paper presents an information-theoretic bound on\nthe generalization performance of any given meta-learner, which builds on the\nconditional mutual information (CMI) framework of Steinke and Zakynthinou\n(2020). In the proposed extension to meta-learning, the CMI bound involves a\ntraining \\textit{meta-supersample} obtained by first sampling $2N$ independent\ntasks from the task environment, and then drawing $2M$ independent training\nsamples for each sampled task. The meta-training data fed to the meta-learner\nis modelled as being obtained by randomly selecting $N$ tasks from the\navailable $2N$ tasks and $M$ training samples per task from the available $2M$\ntraining samples per task. The resulting bound is explicit in two CMI terms,\nwhich measure the information that the meta-learner output and the base-learner\noutput provide about which training data are selected, given the entire\nmeta-supersample. Finally, we present a numerical example that illustrates the\nmerits of the proposed bound in comparison to prior information-theoretic\nbounds for meta-learning.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 10:44:33 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 17:27:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Rezazadeh", "Arezou", ""], ["Jose", "Sharu Theresa", ""], ["Durisi", "Giuseppe", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2010.10896", "submitter": "Yiping Guo", "authors": "Yiping Guo and Howard D. Bondell", "title": "Conditional Density Estimation via Weighted Logistic Regressions", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to the conditional mean as a simple point estimator, the conditional\ndensity function is more informative to describe the distributions with\nmulti-modality, asymmetry or heteroskedasticity. In this paper, we propose a\nnovel parametric conditional density estimation method by showing the\nconnection between the general density and the likelihood function of\ninhomogeneous Poisson process models. The maximum likelihood estimates can be\nobtained via weighted logistic regressions, and the computation can be\nsignificantly relaxed by combining a block-wise alternating maximization scheme\nand local case-control sampling. We also provide simulation studies for\nillustration.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 11:08:25 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Guo", "Yiping", ""], ["Bondell", "Howard D.", ""]]}, {"id": "2010.10935", "submitter": "Chaitanya Manapragada", "authors": "Chaitanya Manapragada and Heitor M Gomes and Mahsa Salehi and Albert\n  Bifet and Geoffrey I Webb", "title": "An Eager Splitting Strategy for Online Decision Trees", "comments": "arXiv admin note: text overlap with arXiv:2010.08199", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of replacing the split strategy for the\nstate-of-the-art online tree learner, Hoeffding Tree, with a rigorous but more\neager splitting strategy. Our method, Hoeffding AnyTime Tree (HATT), uses the\nHoeffding Test to determine whether the current best candidate split is\nsuperior to the current split, with the possibility of revision, while\nHoeffding Tree aims to determine whether the top candidate is better than the\nsecond best and fixes it for all posterity. Our method converges to the ideal\nbatch tree while Hoeffding Tree does not. Decision tree ensembles are widely\nused in practice, and in this work, we study the efficacy of HATT as a base\nlearner for online bagging and online boosting ensembles. On UCI and synthetic\nstreams, the success of Hoeffding AnyTime Tree in terms of prequential accuracy\nover Hoeffding Tree is established. HATT as a base learner component\noutperforms HT within a 0.05 significance level for the majority of tested\nensembles on what we believe is the largest and most comprehensive set of\ntestbenches in the online learning literature. Our results indicate that HATT\nis a superior alternative to Hoeffding Tree in a large number of ensemble\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 04:37:50 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Manapragada", "Chaitanya", ""], ["Gomes", "Heitor M", ""], ["Salehi", "Mahsa", ""], ["Bifet", "Albert", ""], ["Webb", "Geoffrey I", ""]]}, {"id": "2010.10969", "submitter": "Wanqian Yang", "authors": "Wanqian Yang, Lars Lorch, Moritz A. Graule, Himabindu Lakkaraju,\n  Finale Doshi-Velez", "title": "Incorporating Interpretable Output Constraints in Bayesian Neural\n  Networks", "comments": "11 pages, with six supplementary pages. 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada. Code\n  available at: https://github.com/dtak/ocbnn-public. Updated version (final,\n  official submission to NeurIPS in January 2021) includes post-conference\n  revisions: improved results in Section 6.2, and corrected minor errata in\n  Appendix C", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domains where supervised models are deployed often come with task-specific\nconstraints, such as prior expert knowledge on the ground-truth function, or\ndesiderata like safety and fairness. We introduce a novel probabilistic\nframework for reasoning with such constraints and formulate a prior that\nenables us to effectively incorporate them into Bayesian neural networks\n(BNNs), including a variant that can be amortized over tasks. The resulting\nOutput-Constrained BNN (OC-BNN) is fully consistent with the Bayesian framework\nfor uncertainty quantification and is amenable to black-box inference. Unlike\ntypical BNN inference in uninterpretable parameter space, OC-BNNs widen the\nrange of functional knowledge that can be incorporated, especially for model\nusers without expertise in machine learning. We demonstrate the efficacy of\nOC-BNNs on real-world datasets, spanning multiple domains such as healthcare,\ncriminal justice, and credit scoring.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:00:05 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 10:07:56 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Yang", "Wanqian", ""], ["Lorch", "Lars", ""], ["Graule", "Moritz A.", ""], ["Lakkaraju", "Himabindu", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2010.10973", "submitter": "Junhyung Park", "authors": "Junhyunng Park and Krikamol Muandet", "title": "Regularised Least-Squares Regression with Infinite-Dimensional Output\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some learning theory results on vector-valued reproducing kernel\nHilbert space (RKHS) regression, where the input space is allowed to be\nnon-compact and the output space is a (possibly infinite-dimensional) Hilbert\nspace.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:03:02 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:39:56 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 16:15:29 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 16:40:25 GMT"}, {"version": "v5", "created": "Tue, 30 Mar 2021 14:00:18 GMT"}, {"version": "v6", "created": "Wed, 28 Apr 2021 09:37:41 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Park", "Junhyunng", ""], ["Muandet", "Krikamol", ""]]}, {"id": "2010.10987", "submitter": "Jungang Yang", "authors": "Jungang Yang, Liyao Xiang, Ruidong Chen, Yukun Wang, Wei Wang, Xinbing\n  Wang", "title": "Certified Distributional Robustness on Smoothed Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of deep neural networks (DNNs) against adversarial example\nattacks has raised wide attention. For smoothed classifiers, we propose the\nworst-case adversarial loss over input distributions as a robustness\ncertificate. Compared with previous certificates, our certificate better\ndescribes the empirical performance of the smoothed classifiers. By exploiting\nduality and the smoothness property, we provide an easy-to-compute upper bound\nas a surrogate for the certificate. We adopt a noisy adversarial learning\nprocedure to minimize the surrogate loss to improve model robustness. We show\nthat our training method provides a theoretically tighter bound over the\ndistributional robust base classifiers. Experiments on a variety of datasets\nfurther demonstrate superior robustness performance of our method over the\nstate-of-the-art certified or heuristic methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:22:25 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 07:24:47 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Yang", "Jungang", ""], ["Xiang", "Liyao", ""], ["Chen", "Ruidong", ""], ["Wang", "Yukun", ""], ["Wang", "Wei", ""], ["Wang", "Xinbing", ""]]}, {"id": "2010.10994", "submitter": "Borja Rodr\\'iguez G\\'alvez", "authors": "Borja Rodr\\'iguez-G\\'alvez, Germ\\'an Bassi, Ragnar Thobaben, and\n  Mikael Skoglund", "title": "On Random Subset Generalization Error Bounds and the Stochastic Gradient\n  Langevin Dynamics Algorithm", "comments": "To appear in the Information Theory Workshop (ITW 2020) conference.\n  10 pages, 5 of the main text, and 5 of appendices", "journal-ref": null, "doi": "10.1109/ITW46852.2021.9457578", "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we unify several expected generalization error bounds based on\nrandom subsets using the framework developed by Hellstr\\\"om and Durisi [1].\nFirst, we recover the bounds based on the individual sample mutual information\nfrom Bu et al. [2] and on a random subset of the dataset from Negrea et al.\n[3]. Then, we introduce their new, analogous bounds in the randomized subsample\nsetting from Steinke and Zakynthinou [4], and we identify some limitations of\nthe framework. Finally, we extend the bounds from Haghifam et al. [5] for\nLangevin dynamics to stochastic gradient Langevin dynamics and we refine them\nfor loss functions with potentially large gradient norms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:36:01 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 10:58:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Rodr\u00edguez-G\u00e1lvez", "Borja", ""], ["Bassi", "Germ\u00e1n", ""], ["Thobaben", "Ragnar", ""], ["Skoglund", "Mikael", ""]]}, {"id": "2010.11002", "submitter": "Masatoshi Uehara", "authors": "Nathan Kallus, Yuta Saito, Masatoshi Uehara", "title": "Optimal Off-Policy Evaluation from Multiple Logging Policies", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study off-policy evaluation (OPE) from multiple logging policies, each\ngenerating a dataset of fixed size, i.e., stratified sampling. Previous work\nnoted that in this setting the ordering of the variances of different\nimportance sampling estimators is instance-dependent, which brings up a dilemma\nas to which importance sampling weights to use. In this paper, we resolve this\ndilemma by finding the OPE estimator for multiple loggers with minimum variance\nfor any instance, i.e., the efficient one. In particular, we establish the\nefficiency bound under stratified sampling and propose an estimator achieving\nthis bound when given consistent $q$-estimates. To guard against\nmisspecification of $q$-functions, we also provide a way to choose the control\nvariate in a hypothesis class to minimize variance. Extensive experiments\ndemonstrate the benefits of our methods' efficiently leveraging of the\nstratified sampling of off-policy data from multiple loggers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:43:48 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Kallus", "Nathan", ""], ["Saito", "Yuta", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "2010.11024", "submitter": "Ievgen Redko", "authors": "Nina Vesseron, Ievgen Redko, Charlotte Laclau", "title": "Deep Neural Networks Are Congestion Games: From Loss Landscape to\n  Wardrop Equilibrium and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theoretical analysis of deep neural networks (DNN) is arguably among the\nmost challenging research directions in machine learning (ML) right now, as it\nrequires from scientists to lay novel statistical learning foundations to\nexplain their behaviour in practice. While some success has been achieved\nrecently in this endeavour, the question on whether DNNs can be analyzed using\nthe tools from other scientific fields outside the ML community has not\nreceived the attention it may well have deserved. In this paper, we explore the\ninterplay between DNNs and game theory (GT), and show how one can benefit from\nthe classic readily available results from the latter when analyzing the\nformer. In particular, we consider the widely studied class of congestion\ngames, and illustrate their intrinsic relatedness to both linear and non-linear\nDNNs and to the properties of their loss surface. Beyond retrieving the\nstate-of-the-art results from the literature, we argue that our work provides a\nvery promising novel tool for analyzing the DNNs and support this claim by\nproposing concrete open problems that can advance significantly our\nunderstanding of DNNs when solved.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:11:40 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Vesseron", "Nina", ""], ["Redko", "Ievgen", ""], ["Laclau", "Charlotte", ""]]}, {"id": "2010.11029", "submitter": "Derek Hoiem", "authors": "Derek Hoiem, Tanmay Gupta, Zhizhong Li, Michal M. Shlapentokh-Rothman", "title": "Learning Curves for Analysis of Deep Networks", "comments": "Improved text and figure organization, additional experiments on\n  optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning curves model a classifier's test error as a function of the number\nof training samples. Prior works show that learning curves can be used to\nselect model parameters and extrapolate performance. We investigate how to use\nlearning curves to evaluate design choices, such as pretraining, architecture,\nand data augmentation. We propose a method to robustly estimate learning\ncurves, abstract their parameters into error and data-reliance, and evaluate\nthe effectiveness of different parameterizations. Our experiments exemplify use\nof learning curves for analysis and yield several interesting observations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:20:05 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 17:01:02 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Hoiem", "Derek", ""], ["Gupta", "Tanmay", ""], ["Li", "Zhizhong", ""], ["Shlapentokh-Rothman", "Michal M.", ""]]}, {"id": "2010.11037", "submitter": "Sai Li", "authors": "Sai Li and T. Tony Cai and Hongzhe Li", "title": "Transfer Learning in Large-scale Gaussian Graphical Models with False\n  Discovery Rate Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning for high-dimensional Gaussian graphical models (GGMs) is\nstudied with the goal of estimating the target GGM by utilizing the data from\nsimilar and related auxiliary studies. The similarity between the target graph\nand each auxiliary graph is characterized by the sparsity of a divergence\nmatrix. An estimation algorithm, Trans-CLIME, is proposed and shown to attain a\nfaster convergence rate than the minimax rate in the single study setting.\nFurthermore, a debiased Trans-CLIME estimator is introduced and shown to be\nelement-wise asymptotically normal. It is used to construct a multiple testing\nprocedure for edge detection with false discovery rate control. The proposed\nestimation and multiple testing procedures demonstrate superior numerical\nperformance in simulations and are applied to infer the gene networks in a\ntarget brain tissue by leveraging the gene expressions from multiple other\nbrain tissues. A significant decrease in prediction errors and a significant\nincrease in power for link detection are observed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:39:14 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Li", "Sai", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "2010.11039", "submitter": "Milo\\v{s} Simi\\'c", "authors": "Milo\\v{s} Simi\\'c", "title": "How to Control the Error Rates of Binary Classifiers", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional binary classification framework constructs classifiers which\nmay have good accuracy, but whose false positive and false negative error rates\nare not under users' control. In many cases, one of the errors is more severe\nand only the classifiers with the corresponding rate lower than the predefined\nthreshold are acceptable. In this study, we combine binary classification with\nstatistical hypothesis testing to control the target error rate of already\ntrained classifiers. In particular, we show how to turn binary classifiers into\nstatistical tests, calculate the classification p-values, and use them to limit\nthe target error rate.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:43:14 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Simi\u0107", "Milo\u0161", ""]]}, {"id": "2010.11082", "submitter": "Di Wang", "authors": "Di Wang and Hanshen Xiao and Srini Devadas and Jinhui Xu", "title": "On Differentially Private Stochastic Convex Optimization with\n  Heavy-tailed Data", "comments": "Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of designing Differentially Private\n(DP) algorithms for Stochastic Convex Optimization (SCO) on heavy-tailed data.\nThe irregularity of such data violates some key assumptions used in almost all\nexisting DP-SCO and DP-ERM methods, resulting in failure to provide the DP\nguarantees. To better understand this type of challenges, we provide in this\npaper a comprehensive study of DP-SCO under various settings. First, we\nconsider the case where the loss function is strongly convex and smooth. For\nthis case, we propose a method based on the sample-and-aggregate framework,\nwhich has an excess population risk of $\\tilde{O}(\\frac{d^3}{n\\epsilon^4})$\n(after omitting other factors), where $n$ is the sample size and $d$ is the\ndimensionality of the data. Then, we show that with some additional assumptions\non the loss functions, it is possible to reduce the \\textit{expected} excess\npopulation risk to $\\tilde{O}(\\frac{ d^2}{ n\\epsilon^2 })$. To lift these\nadditional conditions, we also provide a gradient smoothing and trimming based\nscheme to achieve excess population risks of $\\tilde{O}(\\frac{\nd^2}{n\\epsilon^2})$ and\n$\\tilde{O}(\\frac{d^\\frac{2}{3}}{(n\\epsilon^2)^\\frac{1}{3}})$ for strongly\nconvex and general convex loss functions, respectively, \\textit{with high\nprobability}. Experiments suggest that our algorithms can effectively deal with\nthe challenges caused by data irregularity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:45:27 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Di", ""], ["Xiao", "Hanshen", ""], ["Devadas", "Srini", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.11151", "submitter": "Gergely Neu", "authors": "Joan Bas-Serrano, Sebastian Curi, Andreas Krause, Gergely Neu", "title": "Logistic Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new reinforcement learning algorithm derived from a regularized\nlinear-programming formulation of optimal control in MDPs. The method is\nclosely related to the classic Relative Entropy Policy Search (REPS) algorithm\nof Peters et al. (2010), with the key difference that our method introduces a\nQ-function that enables efficient exact model-free implementation. The main\nfeature of our algorithm (called QREPS) is a convex loss function for policy\nevaluation that serves as a theoretically sound alternative to the widely used\nsquared Bellman error. We provide a practical saddle-point optimization method\nfor minimizing this loss function and provide an error-propagation analysis\nthat relates the quality of the individual updates to the performance of the\noutput policy. Finally, we demonstrate the effectiveness of our method on a\nrange of benchmark problems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:14:31 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 21:34:03 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Bas-Serrano", "Joan", ""], ["Curi", "Sebastian", ""], ["Krause", "Andreas", ""], ["Neu", "Gergely", ""]]}, {"id": "2010.11166", "submitter": "Aditya Balu", "authors": "Aditya Balu, Zhanhong Jiang, Sin Yong Tan, Chinmay Hedge, Young M Lee,\n  Soumik Sarkar", "title": "Decentralized Deep Learning using Momentum-Accelerated Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of decentralized deep learning where multiple agents\ncollaborate to learn from a distributed dataset. While there exist several\ndecentralized deep learning approaches, the majority consider a central\nparameter-server topology for aggregating the model parameters from the agents.\nHowever, such a topology may be inapplicable in networked systems such as\nad-hoc mobile networks, field robotics, and power network systems where direct\ncommunication with the central parameter server may be inefficient. In this\ncontext, we propose and analyze a novel decentralized deep learning algorithm\nwhere the agents interact over a fixed communication topology (without a\ncentral server). Our algorithm is based on the heavy-ball acceleration method\nused in gradient-based optimization. We propose a novel consensus protocol\nwhere each agent shares with its neighbors its model parameters as well as\ngradient-momentum values during the optimization process. We consider both\nstrongly convex and non-convex objective functions and theoretically analyze\nour algorithm's performance. We present several empirical comparisons with\ncompeting decentralized learning methods to demonstrate the efficacy of our\napproach under different communication topologies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:39:52 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 17:06:17 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Balu", "Aditya", ""], ["Jiang", "Zhanhong", ""], ["Tan", "Sin Yong", ""], ["Hedge", "Chinmay", ""], ["Lee", "Young M", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2010.11171", "submitter": "Yi Sun", "authors": "Boris Hanin and Yi Sun", "title": "Data augmentation as stochastic optimization", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical framework recasting data augmentation as stochastic\noptimization for a sequence of time-varying proxy losses. This provides a\nunified approach to understanding techniques commonly thought of as data\naugmentation, including synthetic noise and label-preserving transformations,\nas well as more traditional ideas in stochastic optimization such as learning\nrate and batch size scheduling. We prove a time-varying Monro-Robbins theorem\nwith rates of convergence which gives conditions on the learning rate and\naugmentation schedule under which augmented gradient descent converges. Special\ncases give provably good joint schedules for augmentation with additive noise,\nminibatch SGD, and minibatch SGD with noise.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:46:32 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Hanin", "Boris", ""], ["Sun", "Yi", ""]]}, {"id": "2010.11176", "submitter": "Mufan (Bill) Li", "authors": "Mufan Bill Li, Murat A. Erdogdu", "title": "Riemannian Langevin Algorithm for Solving Semidefinite Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Langevin diffusion-based algorithm for non-convex optimization\nand sampling on a product manifold of spheres. Under a logarithmic Sobolev\ninequality, we establish a guarantee for finite iteration convergence to the\nGibbs distribution in terms of Kullback--Leibler divergence. We show that with\nan appropriate temperature choice, the suboptimality gap to the global minimum\nis guaranteed to be arbitrarily small with high probability.\n  As an application, we consider the Burer--Monteiro approach for solving a\nsemidefinite program (SDP) with diagonal constraints, and analyze the proposed\nLangevin algorithm for optimizing the non-convex objective. In particular, we\nestablish a logarithmic Sobolev inequality for the Burer--Monteiro problem when\nthere are no spurious local minima, but under the presence saddle points.\nCombining the results, we then provide a global optimality guarantee for the\nSDP and the Max-Cut problem. More precisely, we show that the Langevin\nalgorithm achieves $\\epsilon$ accuracy with high probability in\n$\\widetilde{\\Omega}( \\epsilon^{-5} )$ iterations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:51:08 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 18:16:24 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 19:27:30 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Li", "Mufan Bill", ""], ["Erdogdu", "Murat A.", ""]]}, {"id": "2010.11213", "submitter": "Mahdi Soltanolkotabi", "authors": "Adel Javanmard and Mahdi Soltanolkotabi", "title": "Precise Statistical Analysis of Classification Accuracies for\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wide empirical success of modern machine learning algorithms and\nmodels in a multitude of applications, they are known to be highly susceptible\nto seemingly small indiscernible perturbations to the input data known as\nadversarial attacks. A variety of recent adversarial training procedures have\nbeen proposed to remedy this issue. Despite the success of such procedures at\nincreasing accuracy on adversarially perturbed inputs or robust accuracy, these\ntechniques often reduce accuracy on natural unperturbed inputs or standard\naccuracy. Complicating matters further the effect and trend of adversarial\ntraining procedures on standard and robust accuracy is rather counter intuitive\nand radically dependent on a variety of factors including the perceived form of\nthe perturbation during training, size/quality of data, model\noverparameterization, etc. In this paper we focus on binary classification\nproblems where the data is generated according to the mixture of two Gaussians\nwith general anisotropic covariance matrices and derive a precise\ncharacterization of the standard and robust accuracy for a class of minimax\nadversarially trained models. We consider a general norm-based adversarial\nmodel, where the adversary can add perturbations of bounded $\\ell_p$ norm to\neach input data, for an arbitrary $p\\ge 1$. Our comprehensive analysis allows\nus to theoretically explain several intriguing empirical phenomena and provide\na precise understanding of the role of different problem parameters on standard\nand robust accuracies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 18:00:53 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Javanmard", "Adel", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2010.11266", "submitter": "Mohammadreza Armandpour", "authors": "Mohammadreza Armandpour, Mingyuan Zhou", "title": "Convex Polytope Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decision tree is commonly restricted to use a single hyperplane to split\nthe covariate space at each of its internal nodes. It often requires a large\nnumber of nodes to achieve high accuracy, hurting its interpretability. In this\npaper, we propose convex polytope trees (CPT) to expand the family of decision\ntrees by an interpretable generalization of their decision boundary. The\nsplitting function at each node of CPT is based on the logical disjunction of a\ncommunity of differently weighted probabilistic linear decision-makers, which\nalso geometrically corresponds to a convex polytope in the covariate space. We\nuse a nonparametric Bayesian prior at each node to infer the community's size,\nencouraging simpler decision boundaries by shrinking the number of polytope\nfacets. We develop a greedy method to efficiently construct CPT and scalable\nend-to-end training algorithms for the tree parameters when the tree structure\nis given. We empirically demonstrate the efficiency of CPT over existing\nstate-of-the-art decision trees in several real-world classification and\nregression tasks from diverse domains.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 19:38:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Armandpour", "Mohammadreza", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2010.11332", "submitter": "Drew Dimmery", "authors": "David Arbour, Drew Dimmery, Anup Rao", "title": "Efficient Balanced Treatment Assignments for Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we reframe the problem of balanced treatment assignment as\noptimization of a two-sample test between test and control units. Using this\nlens we provide an assignment algorithm that is optimal with respect to the\nminimum spanning tree test of Friedman and Rafsky (1979). This assignment to\ntreatment groups may be performed exactly in polynomial time. We provide a\nprobabilistic interpretation of this process in terms of the most probable\nelement of designs drawn from a determinantal point process which admits a\nprobabilistic interpretation of the design. We provide a novel formulation of\nestimation as transductive inference and show how the tree structures used in\ndesign can also be used in an adjustment estimator. We conclude with a\nsimulation study demonstrating the improved efficacy of our method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 22:06:37 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Arbour", "David", ""], ["Dimmery", "Drew", ""], ["Rao", "Anup", ""]]}, {"id": "2010.11345", "submitter": "T. Mitchell Roddenberry", "authors": "Chiraag Kaushik, T. Mitchell Roddenberry, Santiago Segarra", "title": "Network topology change-point detection from graph signals with prior\n  spectral signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sequential graph topology change-point detection\nfrom graph signals. We assume that signals on the nodes of the graph are\nregularized by the underlying graph structure via a graph filtering model,\nwhich we then leverage to distill the graph topology change-point detection\nproblem to a subspace detection problem. We demonstrate how prior information\non the spectral signature of the post-change graph can be incorporated to\nimplicitly denoise the observed sequential data, thus leading to a natural\nCUSUM-based algorithm for change-point detection. Numerical experiments\nillustrate the performance of our proposed approach, particularly underscoring\nthe benefits of (potentially noisy) prior information.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 23:21:37 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kaushik", "Chiraag", ""], ["Roddenberry", "T. Mitchell", ""], ["Segarra", "Santiago", ""]]}, {"id": "2010.11356", "submitter": "Xiang Wang", "authors": "Xiang Wang, Chenwei Wu, Jason D. Lee, Tengyu Ma, Rong Ge", "title": "Beyond Lazy Training for Over-parameterized Tensor Decomposition", "comments": "NeurIPS 2020; the first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parametrization is an important technique in training neural networks.\nIn both theory and practice, training a larger network allows the optimization\nalgorithm to avoid bad local optimal solutions. In this paper we study a\nclosely related tensor decomposition problem: given an $l$-th order tensor in\n$(R^d)^{\\otimes l}$ of rank $r$ (where $r\\ll d$), can variants of gradient\ndescent find a rank $m$ decomposition where $m > r$? We show that in a lazy\ntraining regime (similar to the NTK regime for neural networks) one needs at\nleast $m = \\Omega(d^{l-1})$, while a variant of gradient descent can find an\napproximate tensor when $m = O^*(r^{2.5l}\\log d)$. Our results show that\ngradient descent on over-parametrized objective could go beyond the lazy\ntraining regime and utilize certain low-rank structure in the data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 00:32:12 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Xiang", ""], ["Wu", "Chenwei", ""], ["Lee", "Jason D.", ""], ["Ma", "Tengyu", ""], ["Ge", "Rong", ""]]}, {"id": "2010.11366", "submitter": "Zhiyan Ding", "authors": "Zhiyan Ding and Qin Li and Jianfeng Lu and Stephen J. Wright", "title": "Random Coordinate Underdamped Langevin Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Underdamped Langevin Monte Carlo (ULMC) is a popular Markov chain Monte\nCarlo sampling method. It requires the computation of the full gradient of the\nlog-density at each iteration, an expensive operation if the dimension of the\nproblem is high. We propose a sampling method called Random Coordinate ULMC\n(RC-ULMC), which selects a single coordinate at each iteration to be updated\nand leaves the other coordinates untouched. We investigate the computational\ncomplexity of RC-ULMC and compare it with the classical ULMC for strongly\nlog-concave probability distributions. We show that RC-ULMC is always cheaper\nthan the classical ULMC, with a significant cost reduction when the problem is\nhighly skewed and high dimensional. Our complexity bound for RC-ULMC is also\ntight in terms of dimension dependence.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 01:12:13 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ding", "Zhiyan", ""], ["Li", "Qin", ""], ["Lu", "Jianfeng", ""], ["Wright", "Stephen J.", ""]]}, {"id": "2010.11415", "submitter": "Ruize Gao", "authors": "Ruize Gao, Feng Liu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu,\n  Masashi Sugiyama", "title": "Maximum Mean Discrepancy Test is Aware of Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum mean discrepancy (MMD) test could in principle detect any\ndistributional discrepancy between two datasets. However, it has been shown\nthat the MMD test is unaware of adversarial attacks -- the MMD test failed to\ndetect the discrepancy between natural and adversarial data. Given this\nphenomenon, we raise a question: are natural and adversarial data really from\ndifferent distributions? The answer is affirmative -- the previous use of the\nMMD test on the purpose missed three key factors, and accordingly, we propose\nthree components. Firstly, the Gaussian kernel has limited representation\npower, and we replace it with an effective deep kernel. Secondly, the test\npower of the MMD test was neglected, and we maximize it following asymptotic\nstatistics. Finally, adversarial data may be non-independent, and we overcome\nthis issue with the wild bootstrap. By taking care of the three factors, we\nverify that the MMD test is aware of adversarial attacks, which lights up a\nnovel road for adversarial data detection based on two-sample tests.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:42:12 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 00:00:22 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 17:54:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Gao", "Ruize", ""], ["Liu", "Feng", ""], ["Zhang", "Jingfeng", ""], ["Han", "Bo", ""], ["Liu", "Tongliang", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2010.11425", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Differentially-Private Federated Linear Bandits", "comments": "22 pages. Camera-ready for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid proliferation of decentralized learning systems mandates the need\nfor differentially-private cooperative learning. In this paper, we study this\nin context of the contextual linear bandit: we consider a collection of agents\ncooperating to solve a common contextual bandit, while ensuring that their\ncommunication remains private. For this problem, we devise \\textsc{FedUCB}, a\nmultiagent private algorithm for both centralized and decentralized\n(peer-to-peer) federated learning. We provide a rigorous technical analysis of\nits utility in terms of regret, improving several results in cooperative bandit\nlearning, and provide rigorous privacy guarantees as well. Our algorithms\nprovide competitive performance both in terms of pseudoregret bounds and\nempirical benchmark performance in various multi-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:58:39 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2010.11502", "submitter": "Stephan Eckstein", "authors": "Luca De Gennaro Aquino, Stephan Eckstein", "title": "MinMax Methods for Optimal Transport and Beyond: Regularization,\n  Approximation and Numerics", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study MinMax solution methods for a general class of optimization problems\nrelated to (and including) optimal transport. Theoretically, the focus is on\nfitting a large class of problems into a single MinMax framework and\ngeneralizing regularization techniques known from classical optimal transport.\nWe show that regularization techniques justify the utilization of neural\nnetworks to solve such problems by proving approximation theorems and\nillustrating fundamental issues if no regularization is used. We further study\nthe relation to the literature on generative adversarial nets, and analyze\nwhich algorithmic techniques used therein are particularly suitable to the\nclass of problems studied in this paper. Several numerical experiments showcase\nthe generality of the setting and highlight which theoretical insights are most\nbeneficial in practice.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 07:43:51 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Aquino", "Luca De Gennaro", ""], ["Eckstein", "Stephan", ""]]}, {"id": "2010.11518", "submitter": "Cl\\'ement Chadebec", "authors": "Cl\\'ement Chadebec (CRC, Universit\\'e de Paris), Cl\\'ement Mantoux\n  (ARAMIS) and St\\'ephanie Allassonni\\`ere (CRC, Universit\\'e de Paris)", "title": "Geometry-Aware Hamiltonian Variational Auto-Encoder", "comments": "44 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational auto-encoders (VAEs) have proven to be a well suited tool for\nperforming dimensionality reduction by extracting latent variables lying in a\npotentially much smaller dimensional space than the data. Their ability to\ncapture meaningful information from the data can be easily apprehended when\nconsidering their capability to generate new realistic samples or perform\npotentially meaningful interpolations in a much smaller space. However, such\ngenerative models may perform poorly when trained on small data sets which are\nabundant in many real-life fields such as medicine. This may, among others,\ncome from the lack of structure of the latent space, the geometry of which is\noften under-considered. We thus propose in this paper to see the latent space\nas a Riemannian manifold endowed with a parametrized metric learned at the same\ntime as the encoder and decoder networks. This metric is then used in what we\ncalled the Riemannian Hamiltonian VAE which extends the Hamiltonian VAE\nintroduced by arXiv:1805.11328 to better exploit the underlying geometry of the\nlatent space. We argue that such latent space modelling provides useful\ninformation about its underlying structure leading to far more meaningful\ninterpolations, more realistic data-generation and more reliable clustering.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 08:26:46 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chadebec", "Cl\u00e9ment", "", "CRC, Universit\u00e9 de Paris"], ["Mantoux", "Cl\u00e9ment", "", "ARAMIS"], ["Allassonni\u00e8re", "St\u00e9phanie", "", "CRC, Universit\u00e9 de Paris"]]}, {"id": "2010.11530", "submitter": "James Liley", "authors": "James Liley and Samuel R Emerson and Bilal A Mateen and Catalina A\n  Vallejos and Louis J M Aslett and Sebastian J Vollmer", "title": "Model updating after interventions paradoxically introduces bias", "comments": "Sections of this preprint on 'Successive adjuvancy' (section 4,\n  theorem 2, figures 4,5, and associated discussions) were not included in the\n  originally submitted version of this paper due to length. This material does\n  not appear in the published version of this manuscript, and the reader should\n  be aware that these sections did not undergo peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly being used to generate prediction models for\nuse in a number of real-world settings, from credit risk assessment to clinical\ndecision support. Recent discussions have highlighted potential problems in the\nupdating of a predictive score for a binary outcome when an existing predictive\nscore forms part of the standard workflow, driving interventions. In this\nsetting, the existing score induces an additional causative pathway which leads\nto miscalibration when the original score is replaced. We propose a general\ncausal framework to describe and address this problem, and demonstrate an\nequivalent formulation as a partially observed Markov decision process. We use\nthis model to demonstrate the impact of such `naive updating' when performed\nrepeatedly. Namely, we show that successive predictive scores may converge to a\npoint where they predict their own effect, or may eventually tend toward a\nstable oscillation between two values, and we argue that neither outcome is\ndesirable. Furthermore, we demonstrate that even if model-fitting procedures\nimprove, actual performance may worsen. We complement these findings with a\ndiscussion of several potential routes to overcome these issues.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 08:43:29 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 08:55:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Liley", "James", ""], ["Emerson", "Samuel R", ""], ["Mateen", "Bilal A", ""], ["Vallejos", "Catalina A", ""], ["Aslett", "Louis J M", ""], ["Vollmer", "Sebastian J", ""]]}, {"id": "2010.11552", "submitter": "Fredrik Hellstr\\\"om", "authors": "Fredrik Hellstr\\\"om and Giuseppe Durisi", "title": "Fast-Rate Loss Bounds via Conditional Information Measures with\n  Applications to Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to derive bounds on the test loss of randomized\nlearning algorithms for the case of bounded loss functions. Drawing from\nSteinke & Zakynthinou (2020), this framework leads to bounds that depend on the\nconditional information density between the the output hypothesis and the\nchoice of the training set, given a larger set of data samples from which the\ntraining set is formed. Furthermore, the bounds pertain to the average test\nloss as well as to its tail probability, both for the PAC-Bayesian and the\nsingle-draw settings. If the conditional information density is bounded\nuniformly in the size $n$ of the training set, our bounds decay as $1/n$. This\nis in contrast with the tail bounds involving conditional information measures\navailable in the literature, which have a less benign $1/\\sqrt{n}$ dependence.\nWe demonstrate the usefulness of our tail bounds by showing that they lead to\nnonvacuous estimates of the test loss achievable with some neural network\narchitectures trained on MNIST and Fashion-MNIST.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 09:23:25 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 17:09:11 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 10:23:34 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Hellstr\u00f6m", "Fredrik", ""], ["Durisi", "Giuseppe", ""]]}, {"id": "2010.11595", "submitter": "Vitor Cerqueira", "authors": "Vitor Cerqueira, Luis Torgo, Carlos Soares", "title": "Early Anomaly Detection in Time Series: A Hierarchical Approach for\n  Predicting Critical Health Episodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early detection of anomalous events in time series data is essential in\nmany domains of application. In this paper we deal with critical health events,\nwhich represent a significant cause of mortality in intensive care units of\nhospitals. The timely prediction of these events is crucial for mitigating\ntheir consequences and improving healthcare. One of the most common approaches\nto tackle early anomaly detection problems is standard classification methods.\nIn this paper we propose a novel method that uses a layered learning\narchitecture to address these tasks. One key contribution of our work is the\nidea of pre-conditional events, which denote arbitrary but computable relaxed\nversions of the event of interest. We leverage this idea to break the original\nproblem into two hierarchical layers, which we hypothesize are easier to solve.\nThe results suggest that the proposed approach leads to a better performance\nrelative to state of the art approaches for critical health episode prediction.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 10:56:47 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Torgo", "Luis", ""], ["Soares", "Carlos", ""]]}, {"id": "2010.11617", "submitter": "Gaetano Perone", "authors": "Gaetano Perone", "title": "Comparison of ARIMA, ETS, NNAR and hybrid models to forecast the second\n  wave of COVID-19 hospitalizations in Italy", "comments": "19 pages, 8 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Coronavirus disease (COVID-19) is a severe ongoing novel pandemic that has\nemerged in Wuhan, China, in December 2019. As of October 13, the outbreak has\nspread rapidly across the world, affecting over 38 million people, and causing\nover 1 million deaths. In this article, I analysed several time series\nforecasting methods to predict the spread of COVID-19 second wave in Italy,\nover the period after October 13, 2020. I used an autoregressive model (ARIMA),\nan exponential smoothing state space model (ETS), a neural network\nautoregression model (NNAR), and the following hybrid combinations of them:\nARIMA-ETS, ARIMA-NNAR, ETS-NNAR, and ARIMA-ETS-NNAR. About the data, I\nforecasted the number of patients hospitalized with mild symptoms, and in\nintensive care units (ICU). The data refer to the period February 21,\n2020-October 13, 2020 and are extracted from the website of the Italian\nMinistry of Health (www.salute.gov.it). The results show that i) the hybrid\nmodels, except for ARIMA-ETS, are better at capturing the linear and non-linear\nepidemic patterns, by outperforming the respective single models; and ii) the\nnumber of COVID-19-related hospitalized with mild symptoms and in ICU will\nrapidly increase in the next weeks, by reaching the peak in about 50-60 days,\ni.e. in mid-December 2020, at least. To tackle the upcoming COVID-19 second\nwave, on one hand, it is necessary to hire healthcare workers and implement\nsufficient hospital facilities, protective equipment, and ordinary and\nintensive care beds; and on the other hand, it may be useful to enhance social\ndistancing by improving public transport and adopting the double-shifts\nschooling system, for example.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 11:29:24 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Perone", "Gaetano", ""]]}, {"id": "2010.11634", "submitter": "Alberto Natali", "authors": "Alberto Natali, Mario Coutino, Elvin Isufi and Geert Leus", "title": "Online Time-Varying Topology Identification via Prediction-Correction\n  Algorithms", "comments": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal processing and machine learning algorithms for data supported over\ngraphs, require the knowledge of the graph topology. Unless this information is\ngiven by the physics of the problem (e.g., water supply networks, power grids),\nthe topology has to be learned from data. Topology identification is a\nchallenging task, as the problem is often ill-posed, and becomes even harder\nwhen the graph structure is time-varying. In this paper, we address the problem\nof dynamic topology identification by building on recent results from\ntime-varying optimization, devising a general-purpose online algorithm\noperating in non-stationary environments. Because of its iteration-constrained\nnature, the proposed approach exhibits an intrinsic temporal-regularization of\nthe graph topology without explicitly enforcing it. As a case-study, we\nspecialize our method to the Gaussian graphical model (GGM) problem and\ncorroborate its performance.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:02:27 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 15:45:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Natali", "Alberto", ""], ["Coutino", "Mario", ""], ["Isufi", "Elvin", ""], ["Leus", "Geert", ""]]}, {"id": "2010.11642", "submitter": "Matias Vera", "authors": "Matias Vera, Leonardo Rey Vega and Pablo Piantanida", "title": "The Role of Mutual Information in Variational Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting data is a well-known phenomenon related with the generation of a\nmodel that mimics too closely (or exactly) a particular instance of data, and\nmay therefore fail to predict future observations reliably. In practice, this\nbehaviour is controlled by various--sometimes heuristics--regularization\ntechniques, which are motivated by developing upper bounds to the\ngeneralization error. In this work, we study the generalization error of\nclassifiers relying on stochastic encodings trained on the cross-entropy loss,\nwhich is often used in deep learning for classification problems. We derive\nbounds to the generalization error showing that there exists a regime where the\ngeneralization error is bounded by the mutual information between input\nfeatures and the corresponding representations in the latent space, which are\nrandomly generated according to the encoding distribution. Our bounds provide\nan information-theoretic understanding of generalization in the so-called class\nof variational classifiers, which are regularized by a Kullback-Leibler (KL)\ndivergence term. These results give theoretical grounds for the highly popular\nKL term in variational inference methods that was already recognized to act\neffectively as a regularization penalty. We further observe connections with\nwell studied notions such as Variational Autoencoders, Information Dropout,\nInformation Bottleneck and Boltzmann Machines. Finally, we perform numerical\nexperiments on MNIST and CIFAR datasets and show that mutual information is\nindeed highly representative of the behaviour of the generalization error.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:27:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Vera", "Matias", ""], ["Vega", "Leonardo Rey", ""], ["Piantanida", "Pablo", ""]]}, {"id": "2010.11652", "submitter": "Bo Dai", "authors": "Bo Dai, Ofir Nachum, Yinlam Chow, Lihong Li, Csaba Szepesv\\'ari and\n  Dale Schuurmans", "title": "CoinDICE: Off-Policy Confidence Interval Estimation", "comments": "To appear at NeurIPS 2020 as spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study high-confidence behavior-agnostic off-policy evaluation in\nreinforcement learning, where the goal is to estimate a confidence interval on\na target policy's value, given only access to a static experience dataset\ncollected by unknown behavior policies. Starting from a function space\nembedding of the linear program formulation of the $Q$-function, we obtain an\noptimization problem with generalized estimating equation constraints. By\napplying the generalized empirical likelihood method to the resulting\nLagrangian, we propose CoinDICE, a novel and efficient algorithm for computing\nconfidence intervals. Theoretically, we prove the obtained confidence intervals\nare valid, in both asymptotic and finite-sample regimes. Empirically, we show\nin a variety of benchmarks that the confidence interval estimates are tighter\nand more accurate than existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:39:11 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dai", "Bo", ""], ["Nachum", "Ofir", ""], ["Chow", "Yinlam", ""], ["Li", "Lihong", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2010.11653", "submitter": "Wenzhong Yan", "authors": "Wenzhong Yan, Di Jin, Zhidi Lin, Feng Yin", "title": "Graph Neural Network for Large-Scale Network Localization", "comments": "Accepted by ICASSP 2021, Code available at\n  https://github.com/Yanzongzi/GNN-For-localization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are popular to use for classifying structured\ndata in the context of machine learning. But surprisingly, they are rarely\napplied to regression problems. In this work, we adopt GNN for a classic but\nchallenging nonlinear regression problem, namely the network localization. Our\nmain findings are in order. First, GNN is potentially the best solution to\nlarge-scale network localization in terms of accuracy, robustness and\ncomputational time. Second, proper thresholding of the communication range is\nessential to its superior performance. Simulation results corroborate that the\nproposed GNN based method outperforms all state-of-the-art benchmarks by far.\nSuch inspiring results are theoretically justified in terms of data\naggregation, non-line-of-sight (NLOS) noise removal and low-pass filtering\neffect, all affected by the threshold for neighbor selection. Code is available\nat https://github.com/Yanzongzi/GNN-For-localization.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:39:26 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 07:24:39 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Yan", "Wenzhong", ""], ["Jin", "Di", ""], ["Lin", "Zhidi", ""], ["Yin", "Feng", ""]]}, {"id": "2010.11665", "submitter": "Kolyan Ray", "authors": "Kolyan Ray, Botond Szabo, Gabriel Clara", "title": "Spike and slab variational Bayes for high dimensional logistic\n  regression", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) is a popular scalable alternative to Markov chain\nMonte Carlo for Bayesian inference. We study a mean-field spike and slab VB\napproximation of widely used Bayesian model selection priors in sparse\nhigh-dimensional logistic regression. We provide non-asymptotic theoretical\nguarantees for the VB posterior in both $\\ell_2$ and prediction loss for a\nsparse truth, giving optimal (minimax) convergence rates. Since the VB\nalgorithm does not depend on the unknown truth to achieve optimality, our\nresults shed light on effective prior choices. We confirm the improved\nperformance of our VB algorithm over common sparse VB approaches in a numerical\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:49:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ray", "Kolyan", ""], ["Szabo", "Botond", ""], ["Clara", "Gabriel", ""]]}, {"id": "2010.11672", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Nobukatsu Hojo", "title": "CycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-spectrogram\n  Conversion", "comments": "Accepted to Interspeech 2020. Project page:\n  http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc3/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel voice conversion (VC) is a technique for learning mappings\nbetween source and target speeches without using a parallel corpus. Recently,\ncycle-consistent adversarial network (CycleGAN)-VC and CycleGAN-VC2 have shown\npromising results regarding this problem and have been widely used as benchmark\nmethods. However, owing to the ambiguity of the effectiveness of\nCycleGAN-VC/VC2 for mel-spectrogram conversion, they are typically used for\nmel-cepstrum conversion even when comparative methods employ mel-spectrogram as\na conversion target. To address this, we examined the applicability of\nCycleGAN-VC/VC2 to mel-spectrogram conversion. Through initial experiments, we\ndiscovered that their direct applications compromised the time-frequency\nstructure that should be preserved during conversion. To remedy this, we\npropose CycleGAN-VC3, an improvement of CycleGAN-VC2 that incorporates\ntime-frequency adaptive normalization (TFAN). Using TFAN, we can adjust the\nscale and bias of the converted features while reflecting the time-frequency\nstructure of the source mel-spectrogram. We evaluated CycleGAN-VC3 on\ninter-gender and intra-gender non-parallel VC. A subjective evaluation of\nnaturalness and similarity showed that for every VC pair, CycleGAN-VC3\noutperforms or is competitive with the two types of CycleGAN-VC2, one of which\nwas applied to mel-cepstrum and the other to mel-spectrogram. Audio samples are\navailable at\nhttp://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc3/index.html.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 13:08:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Kameoka", "Hirokazu", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "2010.11684", "submitter": "Jiantao Wu", "authors": "Jiantao Wu and Lin Wang", "title": "Disentangling Action Sequences: Discovering Correlated Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentanglement is a highly desirable property of representation due to its\nsimilarity with human's understanding and reasoning. This improves\ninterpretability, enables the performance of down-stream tasks, and enables\ncontrollable generative models. However, this domain is challenged by the\nabstract notion and incomplete theories to support unsupervised disentanglement\nlearning. We demonstrate the data itself, such as the orientation of images,\nplays a crucial role in disentanglement and instead of the factors, and the\ndisentangled representations align the latent variables with the action\nsequences. We further introduce the concept of disentangling action sequences\nwhich facilitates the description of the behaviours of the existing\ndisentangling approaches. An analogy for this process is to discover the\ncommonality between the things and categorizing them. Furthermore, we analyze\nthe inductive biases on the data and find that the latent information\nthresholds are correlated with the significance of the actions. For the\nsupervised and unsupervised settings, we respectively introduce two methods to\nmeasure the thresholds. We further propose a novel framework, fractional\nvariational autoencoder (FVAE), to disentangle the action sequences with\ndifferent significance step-by-step. Experimental results on dSprites and 3D\nChairs show that FVAE improves the stability of disentanglement.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 07:37:50 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Wu", "Jiantao", ""], ["Wang", "Lin", ""]]}, {"id": "2010.11708", "submitter": "Terrence Alsup", "authors": "Terrence Alsup and Benjamin Peherstorfer", "title": "Context-aware surrogate modeling for balancing approximation and\n  sampling costs in multi-fidelity importance sampling and Bayesian inverse\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-fidelity methods leverage low-cost surrogate models to speed up\ncomputations and make occasional recourse to expensive high-fidelity models to\nestablish accuracy guarantees. Because surrogate and high-fidelity models are\nused together, poor predictions by the surrogate models can be compensated with\nfrequent recourse to high-fidelity models. Thus, there is a trade-off between\ninvesting computational resources to improve surrogate models and the frequency\nof making recourse to expensive high-fidelity models; however, this trade-off\nis ignored by traditional modeling methods that construct surrogate models that\nare meant to replace high-fidelity models rather than being used together with\nhigh-fidelity models. This work considers multi-fidelity importance sampling\nand theoretically and computationally derives the optimal trade-off between\nimproving the fidelity of surrogate models for constructing more accurate\nbiasing densities and the number of samples that is required from the\nhigh-fidelity model to compensate poor biasing densities. Numerical examples\ndemonstrate that such optimal---context-aware---surrogate models for\nmulti-fidelity importance sampling have lower fidelity than what typically is\nset as tolerance in traditional model reduction, leading to runtime speedups of\nup to one order of magnitude in the presented examples.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 13:31:51 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Alsup", "Terrence", ""], ["Peherstorfer", "Benjamin", ""]]}, {"id": "2010.11740", "submitter": "Yicong He", "authors": "Yicong He, George K. Atia", "title": "Robust Low-tubal-rank Tensor Completion based on Tensor Factorization\n  and Maximum Correntopy Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of tensor completion is to recover a tensor from a subset of its\nentries, often by exploiting its low-rank property. Among several useful\ndefinitions of tensor rank, the low-tubal-rank was shown to give a valuable\ncharacterization of the inherent low-rank structure of a tensor. While some\nlow-tubal-rank tensor completion algorithms with favorable performance have\nbeen recently proposed, these algorithms utilize second-order statistics to\nmeasure the error residual, which may not work well when the observed entries\ncontain large outliers. In this paper, we propose a new objective function for\nlow-tubal-rank tensor completion, which uses correntropy as the error measure\nto mitigate the effect of the outliers. To efficiently optimize the proposed\nobjective, we leverage a half-quadratic minimization technique whereby the\noptimization is transformed to a weighted low-tubal-rank tensor factorization\nproblem. Subsequently, we propose two simple and efficient algorithms to obtain\nthe solution and provide their convergence and complexity analysis. Numerical\nresults using both synthetic and real data demonstrate the robust and superior\nperformance of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 13:56:55 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["He", "Yicong", ""], ["Atia", "George K.", ""]]}, {"id": "2010.11748", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee, Zhenghang Cui, Yivan Zhang, Masashi Sugiyama", "title": "Classification with Rejection Based on Cost-sensitive Classification", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of classification with rejection is to avoid risky misclassification\nin error-critical applications such as medical diagnosis and product\ninspection. In this paper, based on the relationship between classification\nwith rejection and cost-sensitive classification, we propose a novel method of\nclassification with rejection by learning an ensemble of cost-sensitive\nclassifiers, which satisfies all the following properties: (i) it can avoid\nestimating class-posterior probabilities, resulting in improved classification\naccuracy, (ii) it allows a flexible choice of losses including non-convex ones,\n(iii) it does not require complicated modifications when using different\nlosses, (iv) it is applicable to both binary and multiclass cases, and (v) it\nis theoretically justifiable for any classification-calibrated loss.\nExperimental results demonstrate the usefulness of our proposed approach in\nclean-labeled, noisy-labeled, and positive-unlabeled classification.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:05:05 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 05:18:38 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 15:10:16 GMT"}, {"version": "v4", "created": "Tue, 6 Jul 2021 12:19:27 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Cui", "Zhenghang", ""], ["Zhang", "Yivan", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2010.11750", "submitter": "Hongyang Zhang", "authors": "Hongyang R. Zhang, Fan Yang, Sen Wu, Weijie J. Su, Christopher R\\'e", "title": "Sharp Bias-variance Tradeoffs of Hard Parameter Sharing in\n  High-dimensional Linear Regression", "comments": "44 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard parameter sharing for multi-task learning is widely used in empirical\nresearch despite the fact that its generalization properties have not been well\nestablished in many cases. This paper studies its generalization properties in\na fundamental setting: How does hard parameter sharing work given multiple\nlinear regression tasks? We develop new techniques and establish a number of\nnew results in the high-dimensional setting, where the sample size and feature\ndimension increase at a fixed ratio. First, we show a sharp bias-variance\ndecomposition of hard parameter sharing, given multiple tasks with the same\nfeatures. Second, we characterize the asymptotic bias-variance limit for two\ntasks, even when they have arbitrarily different sample size ratios and\ncovariate shifts. We also demonstrate that these limiting estimates for the\nempirical loss are incredibly accurate in moderate dimensions. Finally, we\nexplain an intriguing phenomenon where increasing one task's sample size helps\nanother task initially by reducing variance but hurts eventually due to\nincreasing bias. This suggests progressively adding data for optimizing hard\nparameter sharing, and we validate its efficiency in text classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:14:20 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhang", "Hongyang R.", ""], ["Yang", "Fan", ""], ["Wu", "Sen", ""], ["Su", "Weijie J.", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2010.11765", "submitter": "Aran Nayebi", "authors": "Aran Nayebi, Sanjana Srivastava, Surya Ganguli, Daniel L.K. Yamins", "title": "Identifying Learning Rules From Neural Network Observables", "comments": "NeurIPS 2020 Camera Ready Version, 21 pages including supplementary\n  information, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain modifies its synaptic strengths during learning in order to better\nadapt to its environment. However, the underlying plasticity rules that govern\nlearning are unknown. Many proposals have been suggested, including Hebbian\nmechanisms, explicit error backpropagation, and a variety of alternatives. It\nis an open question as to what specific experimental measurements would need to\nbe made to determine whether any given learning rule is operative in a real\nbiological system. In this work, we take a \"virtual experimental\" approach to\nthis problem. Simulating idealized neuroscience experiments with artificial\nneural networks, we generate a large-scale dataset of learning trajectories of\naggregate statistics measured in a variety of neural network architectures,\nloss functions, learning rule hyperparameters, and parameter initializations.\nWe then take a discriminative approach, training linear and simple non-linear\nclassifiers to identify learning rules from features based on these\nobservables. We show that different classes of learning rules can be separated\nsolely on the basis of aggregate statistics of the weights, activations, or\ninstantaneous layer-wise activity changes, and that these results generalize to\nlimited access to the trajectory and held-out architectures and learning\ncurricula. We identify the statistics of each observable that are most relevant\nfor rule identification, finding that statistics from network activities across\ntraining are more robust to unit undersampling and measurement noise than those\nobtained from the synaptic strengths. Our results suggest that activation\npatterns, available from electrophysiological recordings of post-synaptic\nactivities on the order of several hundred units, frequently measured at wider\nintervals over the course of learning, may provide a good basis on which to\nidentify learning rules.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:36:54 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 18:48:02 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Nayebi", "Aran", ""], ["Srivastava", "Sanjana", ""], ["Ganguli", "Surya", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2010.11771", "submitter": "Paul Fearnhead", "authors": "Augustin Chevallier, Paul Fearnhead, Matthew Sutton", "title": "Reversible Jump PDMP Samplers for Variable Selection", "comments": "Code available from https://github.com/matt-sutton/rjpdmp", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of Markov chain Monte Carlo (MCMC) algorithms, based on\nsimulating piecewise deterministic Markov processes (PDMPs), have recently\nshown great promise: they are non-reversible, can mix better than standard MCMC\nalgorithms, and can use subsampling ideas to speed up computation in big data\nscenarios. However, current PDMP samplers can only sample from posterior\ndensities that are differentiable almost everywhere, which precludes their use\nfor model choice. Motivated by variable selection problems, we show how to\ndevelop reversible jump PDMP samplers that can jointly explore the discrete\nspace of models and the continuous space of parameters. Our framework is\ngeneral: it takes any existing PDMP sampler, and adds two types of\ntrans-dimensional moves that allow for the addition or removal of a variable\nfrom the model. We show how the rates of these trans-dimensional moves can be\ncalculated so that the sampler has the correct invariant distribution.\nSimulations show that the new samplers can mix better than standard MCMC\nalgorithms. Our empirical results show they are also more efficient than\ngradient-based samplers that avoid model choice through use of continuous\nspike-and-slab priors which replace a point mass at zero for each parameter\nwith a density concentrated around zero.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:46:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chevallier", "Augustin", ""], ["Fearnhead", "Paul", ""], ["Sutton", "Matthew", ""]]}, {"id": "2010.11773", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth, G\\\"unther Schindler, Holger Fr\\\"oning, Franz Pernkopf", "title": "On Resource-Efficient Bayesian Network Classifiers and Deep Neural\n  Networks", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two methods to reduce the complexity of Bayesian network (BN)\nclassifiers. First, we introduce quantization-aware training using the\nstraight-through gradient estimator to quantize the parameters of BNs to few\nbits. Second, we extend a recently proposed differentiable tree-augmented naive\nBayes (TAN) structure learning approach by also considering the model size.\nBoth methods are motivated by recent developments in the deep learning\ncommunity, and they provide effective means to trade off between model size and\nprediction accuracy, which is demonstrated in extensive experiments.\nFurthermore, we contrast quantized BN classifiers with quantized deep neural\nnetworks (DNNs) for small-scale scenarios which have hardly been investigated\nin the literature. We show Pareto optimal models with respect to model size,\nnumber of operations, and test error and find that both model classes are\nviable options.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:47:55 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Roth", "Wolfgang", ""], ["Schindler", "G\u00fcnther", ""], ["Fr\u00f6ning", "Holger", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2010.11775", "submitter": "Shuxiao Chen", "authors": "Shuxiao Chen, Hangfeng He, Weijie J. Su", "title": "Label-Aware Neural Tangent Kernel: Toward Better Generalization and\n  Local Elasticity", "comments": "NeurIPS 2020 camera ready version, 32 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular approach to modeling the dynamics of training overparametrized\nneural networks (NNs), the neural tangent kernels (NTK) are known to fall\nbehind real-world NNs in generalization ability. This performance gap is in\npart due to the \\textit{label agnostic} nature of the NTK, which renders the\nresulting kernel not as \\textit{locally elastic} as NNs~\\citep{he2019local}. In\nthis paper, we introduce a novel approach from the perspective of\n\\emph{label-awareness} to reduce this gap for the NTK. Specifically, we propose\ntwo label-aware kernels that are each a superimposition of a label-agnostic\npart and a hierarchy of label-aware parts with increasing complexity of label\ndependence, using the Hoeffding decomposition. Through both theoretical and\nempirical evidence, we show that the models trained with the proposed kernels\nbetter simulate NNs in terms of generalization ability and local elasticity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:54:32 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:23:44 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chen", "Shuxiao", ""], ["He", "Hangfeng", ""], ["Su", "Weijie J.", ""]]}, {"id": "2010.11779", "submitter": "Matthew Fisher Mr", "authors": "Matthew A. Fisher, Tui Nolan, Matthew M. Graham, Dennis Prangle, Chris\n  J. Oates", "title": "Measure Transport with Kernel Stein Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measure transport underpins several recent algorithms for posterior\napproximation in the Bayesian context, wherein a transport map is sought to\nminimise the Kullback--Leibler divergence (KLD) from the posterior to the\napproximation. The KLD is a strong mode of convergence, requiring absolute\ncontinuity of measures and placing restrictions on which transport maps can be\npermitted. Here we propose to minimise a kernel Stein discrepancy (KSD)\ninstead, requiring only that the set of transport maps is dense in an $L^2$\nsense and demonstrating how this condition can be validated. The consistency of\nthe associated posterior approximation is established and empirical results\nsuggest that KSD is competitive and more flexible alternative to KLD for\nmeasure transport.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:55:47 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 12:08:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Fisher", "Matthew A.", ""], ["Nolan", "Tui", ""], ["Graham", "Matthew M.", ""], ["Prangle", "Dennis", ""], ["Oates", "Chris J.", ""]]}, {"id": "2010.11797", "submitter": "Fuli Feng", "authors": "Fuli Feng, Weiran Huang, Xiangnan He, Xin Xin, Qifan Wang, Tat-Seng\n  Chua", "title": "Should Graph Convolution Trust Neighbors? A Simple Causal Inference\n  Method", "comments": "Accepted by SIGIR'21", "journal-ref": null, "doi": "10.1145/3404835.3462971", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) is an emerging technique for information\nretrieval (IR) applications. While GCN assumes the homophily property of a\ngraph, real-world graphs are never perfect: the local structure of a node may\ncontain discrepancy, e.g., the labels of a node's neighbors could vary. This\npushes us to consider the discrepancy of local structure in GCN modeling.\nExisting work approaches this issue by introducing an additional module such as\ngraph attention, which is expected to learn the contribution of each neighbor.\nHowever, such module may not work reliably as expected, especially when there\nlacks supervision signal, e.g., when the labeled data is small. Moreover,\nexisting methods focus on modeling the nodes in the training data, and never\nconsider the local structure discrepancy of testing nodes.\n  This work focuses on the local structure discrepancy issue for testing nodes,\nwhich has received little scrutiny. From a novel perspective of causality, we\ninvestigate whether a GCN should trust the local structure of a testing node\nwhen predicting its label. To this end, we analyze the working mechanism of GCN\nwith causal graph, estimating the causal effect of a node's local structure for\nthe prediction. The idea is simple yet effective: given a trained GCN model, we\nfirst intervene the prediction by blocking the graph structure; we then compare\nthe original prediction with the intervened prediction to assess the causal\neffect of the local structure on the prediction. Through this way, we can\neliminate the impact of local structure discrepancy and make more accurate\nprediction. Extensive experiments on seven node classification datasets show\nthat our method effectively enhances the inference stage of GCN.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 15:21:47 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 06:29:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Feng", "Fuli", ""], ["Huang", "Weiran", ""], ["He", "Xiangnan", ""], ["Xin", "Xin", ""], ["Wang", "Qifan", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2010.11825", "submitter": "Quentin Klopfenstein", "authors": "Quentin Klopfenstein and Quentin Bertrand and Alexandre Gramfort and\n  Joseph Salmon and Samuel Vaiter", "title": "Model identification and local linear convergence of coordinate descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For composite nonsmooth optimization problems, Forward-Backward algorithm\nachieves model identification (e.g. support identification for the Lasso) after\na finite number of iterations, provided the objective function is regular\nenough. Results concerning coordinate descent are scarcer and model\nidentification has only been shown for specific estimators, the support-vector\nmachine for instance. In this work, we show that cyclic coordinate descent\nachieves model identification in finite time for a wide class of functions. In\naddition, we prove explicit local linear convergence rates for coordinate\ndescent. Extensive experiments on various estimators and on real datasets\ndemonstrate that these rates match well empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:03:19 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Klopfenstein", "Quentin", ""], ["Bertrand", "Quentin", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""], ["Vaiter", "Samuel", ""]]}, {"id": "2010.11858", "submitter": "Andrea Agazzi", "authors": "Andrea Agazzi, Jianfeng Lu", "title": "Global optimality of softmax policy gradient with single hidden layer\n  neural networks in the mean-field regime", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of policy optimization for infinite-horizon discounted\nMarkov Decision Processes with softmax policy and nonlinear function\napproximation trained with policy gradient algorithms. We concentrate on the\ntraining dynamics in the mean-field regime, modeling e.g., the behavior of wide\nsingle hidden layer neural networks, when exploration is encouraged through\nentropy regularization. The dynamics of these models is established as a\nWasserstein gradient flow of distributions in parameter space. We further prove\nglobal optimality of the fixed points of this dynamics under mild conditions on\ntheir initialization.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:47:22 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Agazzi", "Andrea", ""], ["Lu", "Jianfeng", ""]]}, {"id": "2010.11882", "submitter": "Andrew Wilson", "authors": "Gregory Benton, Marc Finzi, Pavel Izmailov, Andrew Gordon Wilson", "title": "Learning Invariances in Neural Networks", "comments": "NeurIPS 2020. Code available at\n  https://github.com/g-benton/learning-invariances", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariances to translations have imbued convolutional neural networks with\npowerful generalization properties. However, we often do not know a priori what\ninvariances are present in the data, or to what extent a model should be\ninvariant to a given symmetry group. We show how to \\emph{learn} invariances\nand equivariances by parameterizing a distribution over augmentations and\noptimizing the training loss simultaneously with respect to the network\nparameters and augmentation parameters. With this simple procedure we can\nrecover the correct set and extent of invariances on image classification,\nregression, segmentation, and molecular property prediction from a large space\nof augmentations, on training data alone.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:18:48 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 17:38:11 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Benton", "Gregory", ""], ["Finzi", "Marc", ""], ["Izmailov", "Pavel", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2010.11887", "submitter": "Maria I. Gorinova", "authors": "Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, Matthijs Vakar", "title": "Conditional independence by typing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A central goal of probabilistic programming languages (PPLs) is to separate\nmodelling from inference. However, this goal is hard to achieve in practice.\nUsers are often forced to re-write their models in order to improve efficiency\nof inference or meet restrictions imposed by the PPL. Conditional independence\n(CI) relationships among parameters are a crucial aspect of probabilistic\nmodels that captures a qualitative summary of the specified model and can\nfacilitate more efficient inference.\n  We present an information flow type system for probabilistic programming that\ncaptures conditional independence (CI) relationships, and show that, for a\nwell-typed program in our system, the distribution it implements is guaranteed\nto have certain CI-relationships. Further, by using type inference, we can\nstatically \\emph{deduce} which CI-properties are present in a specified model.\n  As a practical application, we consider the problem of how to perform\ninference on models with mixed discrete and continuous parameters. Inference on\nsuch models is challenging in many existing PPLs, but can be improved through a\nworkaround, where the discrete parameters are used \\textit{implicitly}, at the\nexpense of manual model re-writing. We present a source-to-source\nsemantics-preserving transformation, which uses our CI-type system to automate\nthis workaround by eliminating the discrete parameters from a probabilistic\nprogram. The resulting program can be seen as a hybrid inference algorithm on\nthe original program, where continuous parameters can be drawn using efficient\ngradient-based inference methods, while the discrete parameters are drawn using\nvariable elimination.\n  We implement our CI-type system and its example application in SlicStan: a\ncompositional variant of Stan.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:27:22 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gorinova", "Maria I.", ""], ["Gordon", "Andrew D.", ""], ["Sutton", "Charles", ""], ["Vakar", "Matthijs", ""]]}, {"id": "2010.11895", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Dean P. Foster, Sham M. Kakade", "title": "What are the Statistical Limits of Offline RL with Linear Function\n  Approximation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning seeks to utilize offline (observational) data\nto guide the learning of (causal) sequential decision making strategies. The\nhope is that offline reinforcement learning coupled with function approximation\nmethods (to deal with the curse of dimensionality) can provide a means to help\nalleviate the excessive sample complexity burden in modern sequential decision\nmaking problems. However, the extent to which this broader approach can be\neffective is not well understood, where the literature largely consists of\nsufficient conditions.\n  This work focuses on the basic question of what are necessary\nrepresentational and distributional conditions that permit provable\nsample-efficient offline reinforcement learning. Perhaps surprisingly, our main\nresult shows that even if: i) we have realizability in that the true value\nfunction of \\emph{every} policy is linear in a given set of features and 2) our\noff-policy data has good coverage over all features (under a strong spectral\ncondition), then any algorithm still (information-theoretically) requires a\nnumber of offline samples that is exponential in the problem horizon in order\nto non-trivially estimate the value of \\emph{any} given policy. Our results\nhighlight that sample-efficient offline policy evaluation is simply not\npossible unless significantly stronger conditions hold; such conditions include\neither having low distribution shift (where the offline data distribution is\nclose to the distribution of the policy to be evaluated) or significantly\nstronger representational conditions (beyond realizability).\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:32:13 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Ruosong", ""], ["Foster", "Dean P.", ""], ["Kakade", "Sham M.", ""]]}, {"id": "2010.11909", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh", "title": "Contrastive Self-Supervised Learning for Wireless Power Control", "comments": "Final version to be presented at IEEE ICASSP 2021. Code available at\n  https://github.com/navid-naderi/ContrastiveSSL_WirelessPowerControl", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for power control in wireless networks using\nself-supervised learning. We partition a multi-layer perceptron that takes as\ninput the channel matrix and outputs the power control decisions into a\nbackbone and a head, and we show how we can use contrastive learning to\npre-train the backbone so that it produces similar embeddings at its output for\nsimilar channel matrices and vice versa, where similarity is defined in an\ninformation-theoretic sense by identifying the interference links that can be\noptimally treated as noise. The backbone and the head are then fine-tuned using\na limited number of labeled samples. Simulation results show the effectiveness\nof the proposed approach, demonstrating significant gains over pure supervised\nlearning methods in both sum-throughput and sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:44:33 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 19:50:48 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Naderializadeh", "Navid", ""]]}, {"id": "2010.11921", "submitter": "Gabor Lugosi", "authors": "Gabor Lugosi and Shahar Mendelson", "title": "Multivariate mean estimation with direction-dependent accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the mean of a random vector based on\n$N$ independent, identically distributed observations. We prove the existence\nof an estimator that has a near-optimal error in all directions in which the\nvariance of the one dimensional marginal of the random vector is not too small:\nwith probability $1-\\delta$, the procedure returns $\\wh{\\mu}_N$ which satisfies\nthat for every direction $u \\in S^{d-1}$, \\[ \\inr{\\wh{\\mu}_N - \\mu, u}\\le\n\\frac{C}{\\sqrt{N}} \\left( \\sigma(u)\\sqrt{\\log(1/\\delta)} + \\left(\\E\\|X-\\EXP\nX\\|_2^2\\right)^{1/2} \\right)~, \\] where $\\sigma^2(u) = \\var(\\inr{X,u})$ and $C$\nis a constant. To achieve this, we require only slightly more than the\nexistence of the covariance matrix, in the form of a certain moment-equivalence\nassumption.\n  The proof relies on novel bounds for the ratio of empirical and true\nprobabilities that hold uniformly over certain classes of random variables.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:52:45 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lugosi", "Gabor", ""], ["Mendelson", "Shahar", ""]]}, {"id": "2010.11924", "submitter": "Alexandre Drouin", "authors": "Gintare Karolina Dziugaite, Alexandre Drouin, Brady Neal, Nitarshan\n  Rajkumar, Ethan Caballero, Linbo Wang, Ioannis Mitliagkas, Daniel M. Roy", "title": "In Search of Robust Measures of Generalization", "comments": "27 pages, 11 figures, 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the principal scientific challenges in deep learning is explaining\ngeneralization, i.e., why the particular way the community now trains networks\nto achieve small training error also leads to small error on held-out data from\nthe same population. It is widely appreciated that some worst-case theories --\nsuch as those based on the VC dimension of the class of predictors induced by\nmodern neural network architectures -- are unable to explain empirical\nperformance. A large volume of work aims to close this gap, primarily by\ndeveloping bounds on generalization error, optimization error, and excess risk.\nWhen evaluated empirically, however, most of these bounds are numerically\nvacuous. Focusing on generalization bounds, this work addresses the question of\nhow to evaluate such bounds empirically. Jiang et al. (2020) recently described\na large-scale empirical study aimed at uncovering potential causal\nrelationships between bounds/measures and generalization. Building on their\nstudy, we highlight where their proposed methods can obscure failures and\nsuccesses of generalization measures in explaining generalization. We argue\nthat generalization measures should instead be evaluated within the framework\nof distributional robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:54:25 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 20:08:21 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Dziugaite", "Gintare Karolina", ""], ["Drouin", "Alexandre", ""], ["Neal", "Brady", ""], ["Rajkumar", "Nitarshan", ""], ["Caballero", "Ethan", ""], ["Wang", "Linbo", ""], ["Mitliagkas", "Ioannis", ""], ["Roy", "Daniel M.", ""]]}, {"id": "2010.11939", "submitter": "Chu-Cheng Lin", "authors": "Chu-Cheng Lin and Aaron Jaech and Xin Li and Matthew R. Gormley and\n  Jason Eisner", "title": "Limitations of Autoregressive Models and Their Alternatives", "comments": "NAACL 2021 (same content, more relaxed layout)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Standard autoregressive language models perform only polynomial-time\ncomputation to compute the probability of the next symbol. While this is\nattractive, it means they cannot model distributions whose next-symbol\nprobability is hard to compute. Indeed, they cannot even model them well enough\nto solve associated easy decision problems for which an engineer might want to\nconsult a language model. These limitations apply no matter how much\ncomputation and data are used to train the model, unless the model is given\naccess to oracle parameters that grow superpolynomially in sequence length.\n  Thus, simply training larger autoregressive language models is not a panacea\nfor NLP. Alternatives include energy-based models (which give up efficient\nsampling) and latent-variable autoregressive models (which give up efficient\nscoring of a given string). Both are powerful enough to escape the above\nlimitations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 17:59:09 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 14:24:32 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 02:09:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lin", "Chu-Cheng", ""], ["Jaech", "Aaron", ""], ["Li", "Xin", ""], ["Gormley", "Matthew R.", ""], ["Eisner", "Jason", ""]]}, {"id": "2010.11947", "submitter": "Zekun Xu", "authors": "Zekun Xu, Abhinav Aggarwal, Oluwaseyi Feyisetan, Nathanael Teissier", "title": "A Differentially Private Text Perturbation Method Using a Regularized\n  Mahalanobis Metric", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing the privacy-utility tradeoff is a crucial requirement of many\npractical machine learning systems that deal with sensitive customer data. A\npopular approach for privacy-preserving text analysis is noise injection, in\nwhich text data is first mapped into a continuous embedding space, perturbed by\nsampling a spherical noise from an appropriate distribution, and then projected\nback to the discrete vocabulary space. While this allows the perturbation to\nadmit the required metric differential privacy, often the utility of downstream\ntasks modeled on this perturbed data is low because the spherical noise does\nnot account for the variability in the density around different words in the\nembedding space. In particular, words in a sparse region are likely unchanged\neven when the noise scale is large. %Using the global sensitivity of the\nmechanism can potentially add too much noise to the words in the dense regions\nof the embedding space, causing a high utility loss, whereas using local\nsensitivity can leak information through the scale of the noise added.\n  In this paper, we propose a text perturbation mechanism based on a carefully\ndesigned regularized variant of the Mahalanobis metric to overcome this\nproblem. For any given noise scale, this metric adds an elliptical noise to\naccount for the covariance structure in the embedding space. This heterogeneity\nin the noise scale along different directions helps ensure that the words in\nthe sparse region have sufficient likelihood of replacement without sacrificing\nthe overall utility. We provide a text-perturbation algorithm based on this\nmetric and formally prove its privacy guarantees. Additionally, we empirically\nshow that our mechanism improves the privacy statistics to achieve the same\nlevel of utility as compared to the state-of-the-art Laplace mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 23:06:44 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Xu", "Zekun", ""], ["Aggarwal", "Abhinav", ""], ["Feyisetan", "Oluwaseyi", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2010.11970", "submitter": "Jie Wang", "authors": "Jie Wang, Rui Gao, Yao Xie", "title": "Two-sample Test using Projected Wasserstein Distance: Breaking the Curse\n  of Dimensionality", "comments": "10 pages, 3 figures. Accepted in ISIT-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a projected Wasserstein distance for the two-sample test, a\nfundamental problem in statistics and machine learning: given two sets of\nsamples, to determine whether they are from the same distribution. In\nparticular, we aim to circumvent the curse of dimensionality in Wasserstein\ndistance: when the dimension is high, it has diminishing testing power, which\nis inherently due to the slow concentration property of Wasserstein metrics in\nthe high dimension space. A key contribution is to couple optimal projection to\nfind the low dimensional linear mapping to maximize the Wasserstein distance\nbetween projected probability distributions. We characterize the theoretical\nproperty of the finite-sample convergence rate on IPMs and present practical\nalgorithms for computing this metric. Numerical examples validate our\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 18:08:58 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 11:31:49 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 21:58:06 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Wang", "Jie", ""], ["Gao", "Rui", ""], ["Xie", "Yao", ""]]}, {"id": "2010.11994", "submitter": "Kaito Ariu", "authors": "Kaito Ariu, Kenshi Abe, Alexandre Prouti\\`ere", "title": "Thresholded Lasso Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the regret minimization problem in sparse\nstochastic contextual linear bandits, where feature vectors may be of large\ndimension $d$, but where the reward function depends on a few, say $s_0\\ll d$,\nof these features only. We present Thresholded Lasso bandit, an algorithm that\n(i) estimates the vector defining the reward function as well as its sparse\nsupport, i.e., significant feature elements, using the Lasso framework with\nthresholding, and (ii) selects an arm greedily according to this estimate\nprojected on its support. The algorithm does not require prior knowledge of the\nsparsity index $s_0$. For this simple algorithm, we establish non-asymptotic\nregret upper bounds scaling as $\\mathcal{O}( \\log d + \\sqrt{T} )$ in general,\nand as $\\mathcal{O}( \\log d + \\log T)$ under the so-called margin condition (a\nsetting where arms are well separated). The regret of previous algorithms\nscales as $\\mathcal{O}( \\log d + \\sqrt{T \\log (d T)})$ and $\\mathcal{O}( \\log T\n\\log d)$ in the two settings, respectively. Through numerical experiments, we\nconfirm that our algorithm outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 19:14:37 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 10:56:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ariu", "Kaito", ""], ["Abe", "Kenshi", ""], ["Prouti\u00e8re", "Alexandre", ""]]}, {"id": "2010.12001", "submitter": "Arthur Delarue", "authors": "Arthur Delarue, Ross Anderson, Christian Tjandraatmadja", "title": "Reinforcement Learning with Combinatorial Actions: An Application to\n  Vehicle Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-function-based methods have long played an important role in\nreinforcement learning. However, finding the best next action given a value\nfunction of arbitrary complexity is nontrivial when the action space is too\nlarge for enumeration. We develop a framework for value-function-based deep\nreinforcement learning with a combinatorial action space, in which the action\nselection problem is explicitly formulated as a mixed-integer optimization\nproblem. As a motivating example, we present an application of this framework\nto the capacitated vehicle routing problem (CVRP), a combinatorial optimization\nproblem in which a set of locations must be covered by a single vehicle with\nlimited capacity. On each instance, we model an action as the construction of a\nsingle route, and consider a deterministic policy which is improved through a\nsimple policy iteration algorithm. Our approach is competitive with other\nreinforcement learning methods and achieves an average gap of 1.7% with\nstate-of-the-art OR methods on standard library instances of medium size.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 19:32:21 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Delarue", "Arthur", ""], ["Anderson", "Ross", ""], ["Tjandraatmadja", "Christian", ""]]}, {"id": "2010.12016", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt, Ari Morcos", "title": "Towards falsifiable interpretability research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for understanding the decisions of and mechanisms underlying deep\nneural networks (DNNs) typically rely on building intuition by emphasizing\nsensory or semantic features of individual examples. For instance, methods aim\nto visualize the components of an input which are \"important\" to a network's\ndecision, or to measure the semantic properties of single neurons. Here, we\nargue that interpretability research suffers from an over-reliance on\nintuition-based approaches that risk-and in some cases have caused-illusory\nprogress and misleading conclusions. We identify a set of limitations that we\nargue impede meaningful progress in interpretability research, and examine two\npopular classes of interpretability methods-saliency and single-neuron-based\napproaches-that serve as case studies for how overreliance on intuition and\nlack of falsifiability can undermine interpretability research. To address\nthese concerns, we propose a strategy to address these impediments in the form\nof a framework for strongly falsifiable interpretability research. We encourage\nresearchers to use their intuitions as a starting point to develop and test\nclear, falsifiable hypotheses, and hope that our framework yields robust,\nevidence-based interpretability methods that generate meaningful advances in\nour understanding of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:03:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2010.12059", "submitter": "Samuel Gomes Fadel", "authors": "Samuel G. Fadel and Sebastian Mair and Ricardo da S. Torres and Ulf\n  Brefeld", "title": "Principled Interpolation in Normalizing Flows", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models based on normalizing flows are very successful in modeling\ncomplex data distributions using simpler ones. However, straightforward linear\ninterpolations show unexpected side effects, as interpolation paths lie outside\nthe area where samples are observed. This is caused by the standard choice of\nGaussian base distributions and can be seen in the norms of the interpolated\nsamples. This observation suggests that correcting the norm should generally\nresult in better interpolations, but it is not clear how to correct the norm in\nan unambiguous way. In this paper, we solve this issue by enforcing a fixed\nnorm and, hence, change the base distribution, to allow for a principled way of\ninterpolation. Specifically, we use the Dirichlet and von Mises-Fisher base\ndistributions. Our experimental results show superior performance in terms of\nbits per dimension, Fr\\'echet Inception Distance (FID), and Kernel Inception\nDistance (KID) scores for interpolation, while maintaining the same generative\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 21:02:10 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Fadel", "Samuel G.", ""], ["Mair", "Sebastian", ""], ["Torres", "Ricardo da S.", ""], ["Brefeld", "Ulf", ""]]}, {"id": "2010.12082", "submitter": "Ramin Okhrati", "authors": "Ramin Okhrati and Aldo Lipani", "title": "A Multilinear Sampling Algorithm to Estimate Shapley Values", "comments": "2020 25th International Conference on Pattern Recognition (ICPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley values are great analytical tools in game theory to measure the\nimportance of a player in a game. Due to their axiomatic and desirable\nproperties such as efficiency, they have become popular for feature importance\nanalysis in data science and machine learning. However, the time complexity to\ncompute Shapley values based on the original formula is exponential, and as the\nnumber of features increases, this becomes infeasible. Castro et al. [1]\ndeveloped a sampling algorithm, to estimate Shapley values. In this work, we\npropose a new sampling method based on a multilinear extension technique as\napplied in game theory. The aim is to provide a more efficient (sampling)\nmethod for estimating Shapley values. Our method is applicable to any machine\nlearning model, in particular for either multi-class classifications or\nregression problems. We apply the method to estimate Shapley values for\nmultilayer perceptrons (MLPs) and through experimentation on two datasets, we\ndemonstrate that our method provides more accurate estimations of the Shapley\nvalues by reducing the variance of the sampling statistics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 21:47:16 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Okhrati", "Ramin", ""], ["Lipani", "Aldo", ""]]}, {"id": "2010.12087", "submitter": "Soumyabrata Pal", "authors": "Venkata Gandikota, Arya Mazumdar, Soumyabrata Pal", "title": "Recovery of sparse linear classifiers from mixture of responses", "comments": "31 pages, 2 figures (To Appear at NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning a mixture of linear classifiers, the aim is to\nlearn a collection of hyperplanes from a sequence of binary responses. Each\nresponse is a result of querying with a vector and indicates the side of a\nrandomly chosen hyperplane from the collection the query vector belongs to.\nThis model provides a rich representation of heterogeneous data with\ncategorical labels and has only been studied in some special settings. We look\nat a hitherto unstudied problem of query complexity upper bound of recovering\nall the hyperplanes, especially for the case when the hyperplanes are sparse.\nThis setting is a natural generalization of the extreme quantization problem\nknown as 1-bit compressed sensing. Suppose we have a set of $\\ell$ unknown\n$k$-sparse vectors. We can query the set with another vector $\\boldsymbol{a}$,\nto obtain the sign of the inner product of $\\boldsymbol{a}$ and a randomly\nchosen vector from the $\\ell$-set. How many queries are sufficient to identify\nall the $\\ell$ unknown vectors? This question is significantly more challenging\nthan both the basic 1-bit compressed sensing problem (i.e., $\\ell=1$ case) and\nthe analogous regression problem (where the value instead of the sign is\nprovided). We provide rigorous query complexity results (with efficient\nalgorithms) for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:03:53 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 02:33:35 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 21:06:09 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Gandikota", "Venkata", ""], ["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2010.12088", "submitter": "Jeremias Sulam", "authors": "Jeremias Sulam, Ramchandran Muthukumar, Raman Arora", "title": "Adversarial Robustness of Supervised Sparse Coding", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent results provide theoretical insights into the phenomena of\nadversarial examples. Existing results, however, are often limited due to a gap\nbetween the simplicity of the models studied and the complexity of those\ndeployed in practice. In this work, we strike a better balance by considering a\nmodel that involves learning a representation while at the same time giving a\nprecise generalization bound and a robustness certificate. We focus on the\nhypothesis class obtained by combining a sparsity-promoting encoder coupled\nwith a linear classifier, and show an interesting interplay between the\nexpressivity and stability of the (supervised) representation map and a notion\nof margin in the feature space. We bound the robust risk (to $\\ell_2$-bounded\nperturbations) of hypotheses parameterized by dictionaries that achieve a mild\nencoder gap on training data. Furthermore, we provide a robustness certificate\nfor end-to-end classification. We demonstrate the applicability of our analysis\nby computing certified accuracy on real data, and compare with other\nalternatives for certified robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:05:21 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 15:10:47 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Sulam", "Jeremias", ""], ["Muthukumar", "Ramchandran", ""], ["Arora", "Raman", ""]]}, {"id": "2010.12103", "submitter": "Leonardo Pellegrina", "authors": "Leonardo Pellegrina", "title": "Sharper convergence bounds of Monte Carlo Rademacher Averages through\n  Self-Bounding functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive sharper probabilistic concentration bounds for the Monte Carlo\nEmpirical Rademacher Averages (MCERA), which are proved through recent results\non the concentration of self-bounding functions. Our novel bounds are\ncharacterized by convergence rates that depend on data-dependent characteristic\nquantities of the set of functions under consideration, such as the empirical\nwimpy variance, an essential improvement w.r.t. standard bounds based on the\nmethods of bounded differences. For this reason, our new results are applicable\nto yield sharper bounds to (Local) Rademacher Averages. We also derive improved\nnovel variance-dependent bounds for the special case where only one vector of\nRademacher random variables is used to compute the MCERA, through the\napplication of Bousquet's inequality and novel data-dependent bounds to the\nwimpy variance. Then, we leverage the framework of self-bounding functions to\nderive novel probabilistic bounds to the supremum deviations, that may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 23:05:16 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 19:53:02 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Pellegrina", "Leonardo", ""]]}, {"id": "2010.12125", "submitter": "Yuuki Takai", "authors": "Yuuki Takai, Akiyoshi Sannai, Matthieu Cordonnier", "title": "On the Number of Linear Functions Composing Deep Neural Network: Towards\n  a Refined Definition of Neural Networks Complexity", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical approach to measure the expressive power of deep neural\nnetworks with piecewise linear activations is based on counting their maximum\nnumber of linear regions. This complexity measure is quite relevant to\nunderstand general properties of the expressivity of neural networks such as\nthe benefit of depth over width. Nevertheless, it appears limited when it comes\nto comparing the expressivity of different network architectures. This lack\nbecomes particularly prominent when considering permutation-invariant networks,\ndue to the symmetrical redundancy among the linear regions. To tackle this, we\npropose a refined definition of piecewise linear function complexity: instead\nof counting the number of linear regions directly, we first introduce an\nequivalence relation among the linear functions composing a piecewise linear\nfunction and then count those linear functions relative to that equivalence\nrelation. Our new complexity measure can clearly distinguish between the two\naforementioned models, is consistent with the classical measure, and increases\nexponentially with depth.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 01:46:12 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 06:22:35 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Takai", "Yuuki", ""], ["Sannai", "Akiyoshi", ""], ["Cordonnier", "Matthieu", ""]]}, {"id": "2010.12128", "submitter": "Feynman Liang", "authors": "Feynman Liang, Nimar Arora, Nazanin Tehrani, Yucen Li, Michael\n  Tingley, Erik Meijer", "title": "Accelerating Metropolis-Hastings with Lightweight Inference Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to construct accurate proposers for Metropolis-Hastings Markov Chain\nMonte Carlo, we integrate ideas from probabilistic graphical models and neural\nnetworks in an open-source framework we call Lightweight Inference Compilation\n(LIC). LIC implements amortized inference within an open-universe declarative\nprobabilistic programming language (PPL). Graph neural networks are used to\nparameterize proposal distributions as functions of Markov blankets, which\nduring \"compilation\" are optimized to approximate single-site Gibbs sampling\ndistributions. Unlike prior work in inference compilation (IC), LIC forgoes\nimportance sampling of linear execution traces in favor of operating directly\non Bayesian networks. Through using a declarative PPL, the Markov blankets of\nnodes (which may be non-static) are queried at inference-time to produce\nproposers Experimental results show LIC can produce proposers which have less\nparameters, greater robustness to nuisance random variables, and improved\nposterior sampling in a Bayesian logistic regression and $n$-schools inference\napplication.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 02:05:37 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Liang", "Feynman", ""], ["Arora", "Nimar", ""], ["Tehrani", "Nazanin", ""], ["Li", "Yucen", ""], ["Tingley", "Michael", ""], ["Meijer", "Erik", ""]]}, {"id": "2010.12163", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal, Jinglin Chen and Nan Jiang", "title": "Improved Worst-Case Regret Bounds for Randomized Least-Squares Value\n  Iteration", "comments": "Updated version, bug fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies regret minimization with randomized value functions in\nreinforcement learning. In tabular finite-horizon Markov Decision Processes, we\nintroduce a clipping variant of one classical Thompson Sampling (TS)-like\nalgorithm, randomized least-squares value iteration (RLSVI). Our\n$\\tilde{\\mathrm{O}}(H^2S\\sqrt{AT})$ high-probability worst-case regret bound\nimproves the previous sharpest worst-case regret bounds for RLSVI and matches\nthe existing state-of-the-art worst-case TS-based regret bounds.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 04:52:53 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 19:33:06 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 21:36:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Agrawal", "Priyank", ""], ["Chen", "Jinglin", ""], ["Jiang", "Nan", ""]]}, {"id": "2010.12167", "submitter": "Sho Takemori Ph.D", "authors": "Sho Takemori, Masahiro Sato", "title": "Approximation Theory Based Methods for RKHS Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RKHS bandit problem (also called kernelized multi-armed bandit problem)\nis an online optimization problem of non-linear functions with noisy feedback.\nAlthough the problem has been extensively studied, there are unsatisfactory\nresults for some problems compared to the well-studied linear bandit case.\nSpecifically, there is no general algorithm for the adversarial RKHS bandit\nproblem. In addition, high computational complexity of existing algorithms\nhinders practical application. We address these issues by considering a novel\namalgamation of approximation theory and the misspecified linear bandit\nproblem. Using an approximation method, we propose efficient algorithms for the\nstochastic RKHS bandit problem and the first general algorithm for the\nadversarial RKHS bandit problem. Furthermore, we empirically show that one of\nour proposed methods has comparable cumulative regret to IGP-UCB and its\nrunning time is much shorter.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 05:14:21 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 07:55:45 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 07:56:57 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 02:16:25 GMT"}, {"version": "v5", "created": "Mon, 26 Jul 2021 02:04:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Takemori", "Sho", ""], ["Sato", "Masahiro", ""]]}, {"id": "2010.12222", "submitter": "Gabriel Frisch", "authors": "Gabriel Frisch (Heudiasyc), Jean-Benoist L\\'eger (Heudiasyc), Yves\n  Grandvalet (Heudiasyc)", "title": "Learning from missing data with the Latent Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data can be informative. Ignoring this information can lead to\nmisleading conclusions when the data model does not allow information to be\nextracted from the missing data. We propose a co-clustering model, based on the\nLatent Block Model, that aims to take advantage of this nonignorable\nnonresponses, also known as Missing Not At Random data (MNAR). A variational\nexpectation-maximization algorithm is derived to perform inference and a model\nselection criterion is presented. We assess the proposed approach on a\nsimulation study, before using our model on the voting records from the lower\nhouse of the French Parliament, where our analysis brings out relevant groups\nof MPs and texts, together with a sensible interpretation of the behavior of\nnon-voters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 08:11:43 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Frisch", "Gabriel", "", "Heudiasyc"], ["L\u00e9ger", "Jean-Benoist", "", "Heudiasyc"], ["Grandvalet", "Yves", "", "Heudiasyc"]]}, {"id": "2010.12236", "submitter": "Solenne Gaucher", "authors": "Solenne Gaucher (LMO)", "title": "Finite Continuum-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a situation where an agent has $T$ ressources to be allocated to\na larger number $N$ of actions. Each action can be completed at most once and\nresults in a stochastic reward with unknown mean. The goal of the agent is to\nmaximize her cumulative reward. Non trivial strategies are possible when side\ninformation on the actions is available, for example in the form of covariates.\nFocusing on a nonparametric setting, where the mean reward is an unknown\nfunction of a one-dimensional covariate, we propose an optimal strategy for\nthis problem. Under natural assumptions on the reward function, we prove that\nthe optimal regret scales as $O(T^{1/3})$ up to poly-logarithmic factors when\nthe budget $T$ is proportional to the number of actions $N$. When $T$ becomes\nsmall compared to $N$, a smooth transition occurs. When the ratio $T/N$\ndecreases from a constant to $N^{-1/3}$, the regret increases progressively up\nto the $O(T^{1/2})$ rate encountered in continuum-armed bandits.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 08:48:45 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 14:37:47 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gaucher", "Solenne", "", "LMO"]]}, {"id": "2010.12245", "submitter": "Edoardo Vittori", "authors": "Edoardo Vittori, Michele Trapletti, Marcello Restelli", "title": "Option Hedging with Risk Averse Reinforcement Learning", "comments": "Published to ICAIF2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show how risk-averse reinforcement learning can be used to\nhedge options. We apply a state-of-the-art risk-averse algorithm: Trust Region\nVolatility Optimization (TRVO) to a vanilla option hedging environment,\nconsidering realistic factors such as discrete time and transaction costs.\nRealism makes the problem twofold: the agent must both minimize volatility and\ncontain transaction costs, these tasks usually being in competition. We use the\nalgorithm to train a sheaf of agents each characterized by a different risk\naversion, so to be able to span an efficient frontier on the volatility-p\\&l\nspace. The results show that the derived hedging strategy not only outperforms\nthe Black \\& Scholes delta hedge, but is also extremely robust and flexible, as\nit can efficiently hedge options with different characteristics and work on\nmarkets with different behaviors than what was used in training.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:08:24 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Vittori", "Edoardo", ""], ["Trapletti", "Michele", ""], ["Restelli", "Marcello", ""]]}, {"id": "2010.12247", "submitter": "Andrea Tirinzoni", "authors": "Andrea Tirinzoni, Matteo Pirotta, Marcello Restelli, Alessandro\n  Lazaric", "title": "An Asymptotically Optimal Primal-Dual Incremental Algorithm for\n  Contextual Linear Bandits", "comments": "To appear at NeurIPS 2020. V2: clarified dependencies in the\n  worst-case regret bound", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contextual linear bandit setting, algorithms built on the optimism\nprinciple fail to exploit the structure of the problem and have been shown to\nbe asymptotically suboptimal. In this paper, we follow recent approaches of\nderiving asymptotically optimal algorithms from problem-dependent regret lower\nbounds and we introduce a novel algorithm improving over the state-of-the-art\nalong multiple dimensions. We build on a reformulation of the lower bound,\nwhere context distribution and exploration policy are decoupled, and we obtain\nan algorithm robust to unbalanced context distributions. Then, using an\nincremental primal-dual approach to solve the Lagrangian relaxation of the\nlower bound, we obtain a scalable and computationally efficient algorithm.\nFinally, we remove forced exploration and build on confidence intervals of the\noptimization problem to encourage a minimum level of exploration that is better\nadapted to the problem structure. We demonstrate the asymptotic optimality of\nour algorithm, while providing both problem-dependent and worst-case\nfinite-time regret guarantees. Our bounds scale with the logarithm of the\nnumber of arms, thus avoiding the linear dependence common in all related prior\nworks. Notably, we establish minimax optimality for any learning horizon in the\nspecial case of non-contextual linear bandits. Finally, we verify that our\nalgorithm obtains better empirical performance than state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:12:47 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 09:19:44 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Tirinzoni", "Andrea", ""], ["Pirotta", "Matteo", ""], ["Restelli", "Marcello", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2010.12260", "submitter": "Alejo Jesus Nevado-Holgado", "authors": "Yurika Sakai, Andrey Kormilitzin, Qiang Liu, Alejo Nevado-Holgado", "title": "Population Gradients improve performance across data-sets and\n  architectures in object classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most successful methods such as ReLU transfer functions, batch\nnormalization, Xavier initialization, dropout, learning rate decay, or dynamic\noptimizers, have become standards in the field due, particularly, to their\nability to increase the performance of Neural Networks (NNs) significantly and\nin almost all situations. Here we present a new method to calculate the\ngradients while training NNs, and show that it significantly improves final\nperformance across architectures, data-sets, hyper-parameter values, training\nlength, and model sizes, including when it is being combined with other common\nperformance-improving methods (such as the ones mentioned above). Besides being\neffective in the wide array situations that we have tested, the increase in\nperformance (e.g. F1) it provides is as high or higher than this one of all the\nother widespread performance-improving methods that we have compared against.\nWe call our method Population Gradients (PG), and it consists on using a\npopulation of NNs to calculate a non-local estimation of the gradient, which is\ncloser to the theoretical exact gradient (i.e. this one obtainable only with an\ninfinitely big data-set) of the error function than the empirical gradient\n(i.e. this one obtained with the real finite data-set).\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:40:23 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sakai", "Yurika", ""], ["Kormilitzin", "Andrey", ""], ["Liu", "Qiang", ""], ["Nevado-Holgado", "Alejo", ""]]}, {"id": "2010.12268", "submitter": "Jianan Wang", "authors": "Jianan Wang, Eren Sezener, David Budden, Marcus Hutter, Joel Veness", "title": "A Combinatorial Perspective on Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human intelligence is characterized not only by the capacity to learn complex\nskills, but the ability to rapidly adapt and acquire new skills within an\never-changing environment. In this work we study how the learning of modular\nsolutions can allow for effective generalization to both unseen and potentially\ndifferently distributed data. Our main postulate is that the combination of\ntask segmentation, modular learning and memory-based ensembling can give rise\nto generalization on an exponentially growing number of unseen tasks. We\nprovide a concrete instantiation of this idea using a combination of: (1) the\nForget-Me-Not Process, for task segmentation and memory based ensembling; and\n(2) Gated Linear Networks, which in contrast to contemporary deep learning\ntechniques use a modular and local learning mechanism. We demonstrate that this\nsystem exhibits a number of desirable continual learning properties: robustness\nto catastrophic forgetting, no negative transfer and increasing levels of\npositive transfer as more tasks are seen. We show competitive performance\nagainst both offline and online methods on standard continual learning\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:53:31 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Wang", "Jianan", ""], ["Sezener", "Eren", ""], ["Budden", "David", ""], ["Hutter", "Marcus", ""], ["Veness", "Joel", ""]]}, {"id": "2010.12313", "submitter": "Christian H\\\"ager", "authors": "Rick M. B\\\"utler, Christian H\\\"ager, Henry D. Pfister, Gabriele Liga,\n  Alex Alvarado", "title": "Model-Based Machine Learning for Joint Digital Backpropagation and PMD\n  Compensation", "comments": "10 pages, 11 figures, to appear in the IEEE/OSA Journal of Lightwave\n  Technology", "journal-ref": null, "doi": "10.1109/JLT.2020.3034047", "report-no": null, "categories": "eess.SP cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model-based machine-learning approach for\ndual-polarization systems by parameterizing the split-step Fourier method for\nthe Manakov-PMD equation. The resulting method combines hardware-friendly\ntime-domain nonlinearity mitigation via the recently proposed learned digital\nbackpropagation (LDBP) with distributed compensation of polarization-mode\ndispersion (PMD). We refer to the resulting approach as LDBP-PMD. We train\nLDBP-PMD on multiple PMD realizations and show that it converges within 1% of\nits peak dB performance after 428 training iterations on average, yielding a\npeak effective signal-to-noise ratio of only 0.30 dB below the PMD-free case.\nSimilar to state-of-the-art lumped PMD compensation algorithms in practical\nsystems, our approach does not assume any knowledge about the particular PMD\nrealization along the link, nor any knowledge about the total accumulated PMD.\nThis is a significant improvement compared to prior work on distributed PMD\ncompensation, where knowledge about the accumulated PMD is typically assumed.\nWe also compare different parameterization choices in terms of performance,\ncomplexity, and convergence behavior. Lastly, we demonstrate that the learned\nmodels can be successfully retrained after an abrupt change of the PMD\nrealization along the fiber.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 11:37:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["B\u00fctler", "Rick M.", ""], ["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""], ["Liga", "Gabriele", ""], ["Alvarado", "Alex", ""]]}, {"id": "2010.12353", "submitter": "Arun Verma", "authors": "Arun Verma, Manjesh K. Hanawal, Csaba Szepesv\\'ari, Venkatesh\n  Saligrama", "title": "Online Algorithm for Unsupervised Sequential Selection with Contextual\n  Information", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study Contextual Unsupervised Sequential Selection (USS), a\nnew variant of the stochastic contextual bandits problem where the loss of an\narm cannot be inferred from the observed feedback. In our setup, arms are\nassociated with fixed costs and are ordered, forming a cascade. In each round,\na context is presented, and the learner selects the arms sequentially till some\ndepth. The total cost incurred by stopping at an arm is the sum of fixed costs\nof arms selected and the stochastic loss associated with the arm. The learner's\ngoal is to learn a decision rule that maps contexts to arms with the goal of\nminimizing the total expected loss. The problem is challenging as we are faced\nwith an unsupervised setting as the total loss cannot be estimated. Clearly,\nlearning is feasible only if the optimal arm can be inferred (explicitly or\nimplicitly) from the problem structure. We observe that learning is still\npossible when the problem instance satisfies the so-called 'Contextual Weak\nDominance' (CWD) property. Under CWD, we propose an algorithm for the\ncontextual USS problem and demonstrate that it has sub-linear regret.\nExperiments on synthetic and real datasets validate our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:32:21 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "2010.12362", "submitter": "Diego Arribas", "authors": "Diego M. Arribas, Yuan Zhao and Il Memming Park", "title": "Rescuing neural spike train models from bad MLE", "comments": "To appear in Advances in Neural Information Processing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach to fitting an autoregressive spike train model is to\nmaximize the likelihood for one-step prediction. This maximum likelihood\nestimation (MLE) often leads to models that perform poorly when generating\nsamples recursively for more than one time step. Moreover, the generated spike\ntrains can fail to capture important features of the data and even show\ndiverging firing rates. To alleviate this, we propose to directly minimize the\ndivergence between neural recorded and model generated spike trains using spike\ntrain kernels. We develop a method that stochastically optimizes the maximum\nmean discrepancy induced by the kernel. Experiments performed on both real and\nsynthetic neural data validate the proposed approach, showing that it leads to\nwell-behaving models. Using different combinations of spike train kernels, we\nshow that we can control the trade-off between different features which is\ncritical for dealing with model-mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:46:12 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Arribas", "Diego M.", ""], ["Zhao", "Yuan", ""], ["Park", "Il Memming", ""]]}, {"id": "2010.12363", "submitter": "Kaito Ariu", "authors": "Kaito Ariu, Narae Ryu, Se-Young Yun, Alexandre Prouti\\`ere", "title": "Regret in Online Recommendation Systems", "comments": "Advances in Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a theoretical analysis of recommendation systems in an\nonline setting, where items are sequentially recommended to users over time. In\neach round, a user, randomly picked from a population of $m$ users, requests a\nrecommendation. The decision-maker observes the user and selects an item from a\ncatalogue of $n$ items. Importantly, an item cannot be recommended twice to the\nsame user. The probabilities that a user likes each item are unknown. The\nperformance of the recommendation algorithm is captured through its regret,\nconsidering as a reference an Oracle algorithm aware of these probabilities. We\ninvestigate various structural assumptions on these probabilities: we derive\nfor each structure regret lower bounds, and devise algorithms achieving these\nlimits. Interestingly, our analysis reveals the relative weights of the\ndifferent components of regret: the component due to the constraint of not\npresenting the same item twice to the same user, that due to learning the\nchances users like items, and finally that arising when learning the underlying\nstructure.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:48:35 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Ariu", "Kaito", ""], ["Ryu", "Narae", ""], ["Yun", "Se-Young", ""], ["Prouti\u00e8re", "Alexandre", ""]]}, {"id": "2010.12367", "submitter": "Cong Zhang", "authors": "Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, Chi Xu", "title": "Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Priority dispatching rule (PDR) is widely used for solving real-world\nJob-shop scheduling problem (JSSP). However, the design of effective PDRs is a\ntedious task, requiring a myriad of specialized knowledge and often delivering\nlimited performance. In this paper, we propose to automatically learn PDRs via\nan end-to-end deep reinforcement learning agent. We exploit the disjunctive\ngraph representation of JSSP, and propose a Graph Neural Network based scheme\nto embed the states encountered during solving. The resulting policy network is\nsize-agnostic, effectively enabling generalization on large-scale instances.\nExperiments show that the agent can learn high-quality PDRs from scratch with\nelementary raw features, and demonstrates strong performance against the best\nexisting PDRs. The learned policies also perform well on much larger instances\nthat are unseen in training.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:53:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Zhang", "Cong", ""], ["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""], ["Tan", "Puay Siew", ""], ["Xu", "Chi", ""]]}, {"id": "2010.12408", "submitter": "Hande Dong", "authors": "Hande Dong, Jiawei Chen, Fuli Feng, Xiangnan He, Shuxian Bi, Zhaolin\n  Ding, Peng Cui", "title": "On the Equivalence of Decoupled Graph Convolution Network and Label\n  Propagation", "comments": "Accepted by WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original design of Graph Convolution Network (GCN) couples feature\ntransformation and neighborhood aggregation for node representation learning.\nRecently, some work shows that coupling is inferior to decoupling, which\nsupports deep graph propagation better and has become the latest paradigm of\nGCN (e.g., APPNP and SGCN). Despite effectiveness, the working mechanisms of\nthe decoupled GCN are not well understood. In this paper, we explore the\ndecoupled GCN for semi-supervised node classification from a novel and\nfundamental perspective -- label propagation. We conduct thorough theoretical\nanalyses, proving that the decoupled GCN is essentially the same as the\ntwo-step label propagation: first, propagating the known labels along the graph\nto generate pseudo-labels for the unlabeled nodes, and second, training normal\nneural network classifiers on the augmented pseudo-labeled data. More\ninterestingly, we reveal the effectiveness of decoupled GCN: going beyond the\nconventional label propagation, it could automatically assign structure- and\nmodel- aware weights to the pseudo-label data. This explains why the decoupled\nGCN is relatively robust to the structure noise and over-smoothing, but\nsensitive to the label noise and model initialization. Based on this insight,\nwe propose a new label propagation method named Propagation then Training\nAdaptively (PTA), which overcomes the flaws of the decoupled GCN with a dynamic\nand adaptive weighting strategy. Our PTA is simple yet more effective and\nrobust than decoupled GCN. We empirically validate our findings on four\nbenchmark datasets, demonstrating the advantages of our method. The code is\navailable at https://github.com/DongHande/PT_propagation_then_training.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 13:57:39 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 12:23:39 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dong", "Hande", ""], ["Chen", "Jiawei", ""], ["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Bi", "Shuxian", ""], ["Ding", "Zhaolin", ""], ["Cui", "Peng", ""]]}, {"id": "2010.12460", "submitter": "Fartash Faghri", "authors": "Fartash Faghri, Iman Tabrizian, Ilia Markov, Dan Alistarh, Daniel Roy,\n  Ali Ramezani-Kebrya", "title": "Adaptive Gradient Quantization for Data-Parallel SGD", "comments": "Accepted at the conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many communication-efficient variants of SGD use gradient quantization\nschemes. These schemes are often heuristic and fixed over the course of\ntraining. We empirically observe that the statistics of gradients of deep\nmodels change during the training. Motivated by this observation, we introduce\ntwo adaptive quantization schemes, ALQ and AMQ. In both schemes, processors\nupdate their compression schemes in parallel by efficiently computing\nsufficient statistics of a parametric distribution. We improve the validation\naccuracy by almost 2% on CIFAR-10 and 1% on ImageNet in challenging low-cost\ncommunication setups. Our adaptive methods are also significantly more robust\nto the choice of hyperparameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 14:58:02 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Faghri", "Fartash", ""], ["Tabrizian", "Iman", ""], ["Markov", "Ilia", ""], ["Alistarh", "Dan", ""], ["Roy", "Daniel", ""], ["Ramezani-Kebrya", "Ali", ""]]}, {"id": "2010.12464", "submitter": "Alex Mansbridge", "authors": "Alex Mansbridge, Gregory Barbour, Davide Piras, Christopher Frye, Ilya\n  Feige, David Barber", "title": "Learning to Noise: Application-Agnostic Data Sharing with Local\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collection and sharing of individuals' data has become commonplace in\nmany industries. Local differential privacy (LDP) is a rigorous approach to\npreserving data privacy even from a database administrator, unlike the more\nstandard central differential privacy. To achieve LDP, one traditionally adds\nnoise directly to each data dimension, but for high-dimensional data the level\nof noise required for sufficient anonymization all but entirely destroys the\ndata's utility. In this paper, we introduce a novel LDP mechanism that\nleverages representation learning to overcome the prohibitive noise\nrequirements of direct methods. We demonstrate that, rather than simply\nestimating aggregate statistics of the privatized data as is the norm in LDP\napplications, our method enables the training of performant machine learning\nmodels. Unique applications of our approach include private novel-class\nclassification and the augmentation of clean datasets with additional\nprivatized features. Methods that rely on central differential privacy are not\napplicable to such tasks. Our approach achieves significant performance gains\non these tasks relative to state-of-the-art LDP benchmarks that noise data\ndirectly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 15:01:19 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 17:00:15 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Mansbridge", "Alex", ""], ["Barbour", "Gregory", ""], ["Piras", "Davide", ""], ["Frye", "Christopher", ""], ["Feige", "Ilya", ""], ["Barber", "David", ""]]}, {"id": "2010.12470", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Kenshi Abe, Kaito Ariu, Shota Yasui", "title": "A Practical Guide of Off-Policy Evaluation for Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) is the problem of estimating the value of a\ntarget policy from samples obtained via different policies. Recently, applying\nOPE methods for bandit problems has garnered attention. For the theoretical\nguarantees of an estimator of the policy value, the OPE methods require various\nconditions on the target policy and policy used for generating the samples.\nHowever, existing studies did not carefully discuss the practical situation\nwhere such conditions hold, and the gap between them remains. This paper aims\nto show new results for bridging the gap. Based on the properties of the\nevaluation policy, we categorize OPE situations. Then, among practical\napplications, we mainly discuss the best policy selection. For the situation,\nwe propose a meta-algorithm based on existing OPE estimators. We investigate\nthe proposed concepts using synthetic and open real-world datasets in\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 15:11:19 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kato", "Masahiro", ""], ["Abe", "Kenshi", ""], ["Ariu", "Kaito", ""], ["Yasui", "Shota", ""]]}, {"id": "2010.12487", "submitter": "Damien Garreau", "authors": "Dina Mardaoui and Damien Garreau", "title": "An Analysis of LIME for Text Data", "comments": "29 pages, 17 figures, accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text data are increasingly handled in an automated fashion by machine\nlearning algorithms. But the models handling these data are not always\nwell-understood due to their complexity and are more and more often referred to\nas \"black-boxes.\" Interpretability methods aim to explain how these models\noperate. Among them, LIME has become one of the most popular in recent years.\nHowever, it comes without theoretical guarantees: even for simple models, we\nare not sure that LIME behaves accurately. In this paper, we provide a first\ntheoretical analysis of LIME for text data. As a consequence of our theoretical\nfindings, we show that LIME indeed provides meaningful explanations for simple\nmodels, namely decision trees and linear models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 15:40:13 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 08:43:16 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mardaoui", "Dina", ""], ["Garreau", "Damien", ""]]}, {"id": "2010.12493", "submitter": "Chenxi Sun", "authors": "Chenxi Sun, Shenda Hong, Moxian Song and Hongyan Li", "title": "A Review of Deep Learning Methods for Irregularly Sampled Medical Time\n  Series Data", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregularly sampled time series (ISTS) data has irregular temporal intervals\nbetween observations and different sampling rates between sequences. ISTS\ncommonly appears in healthcare, economics, and geoscience. Especially in the\nmedical environment, the widely used Electronic Health Records (EHRs) have\nabundant typical irregularly sampled medical time series (ISMTS) data.\nDeveloping deep learning methods on EHRs data is critical for personalized\ntreatment, precise diagnosis and medical management. However, it is challenging\nto directly use deep learning models for ISMTS data. On the one hand, ISMTS\ndata has the intra-series and inter-series relations. Both the local and global\nstructures should be considered. On the other hand, methods should consider the\ntrade-off between task accuracy and model complexity and remain generality and\ninterpretability. So far, many existing works have tried to solve the above\nproblems and have achieved good results. In this paper, we review these deep\nlearning methods from the perspectives of technology and task. Under the\ntechnology-driven perspective, we summarize them into two categories - missing\ndata-based methods and raw data-based methods. Under the task-driven\nperspective, we also summarize them into two categories - data\nimputation-oriented and downstream task-oriented. For each of them, we point\nout their advantages and disadvantages. Moreover, we implement some\nrepresentative methods and compare them on four medical datasets with two\ntasks. Finally, we discuss the challenges and opportunities in this area.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 15:51:23 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 04:51:39 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sun", "Chenxi", ""], ["Hong", "Shenda", ""], ["Song", "Moxian", ""], ["Li", "Hongyan", ""]]}, {"id": "2010.12546", "submitter": "Erdem Koyuncu", "authors": "Erdem Koyuncu", "title": "Quantizing Multiple Sources to a Common Cluster Center: An Asymptotic\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider quantizing an $Ld$-dimensional sample, which is obtained by\nconcatenating $L$ vectors from datasets of $d$-dimensional vectors, to a\n$d$-dimensional cluster center. The distortion measure is the weighted sum of\n$r$th powers of the distances between the cluster center and the samples. For\n$L=1$, one recovers the ordinary center based clustering formulation. The\ngeneral case $L>1$ appears when one wishes to cluster a dataset through $L$\nnoisy observations of each of its members. We find a formula for the average\ndistortion performance in the asymptotic regime where the number of cluster\ncenters are large. We also provide an algorithm to numerically optimize the\ncluster centers and verify our analytical results on real and artificial\ndatasets. In terms of faithfulness to the original (noiseless) dataset, our\nclustering approach outperforms the naive approach that relies on quantizing\nthe $Ld$-dimensional noisy observation vectors to $Ld$-dimensional centers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:14:28 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Koyuncu", "Erdem", ""]]}, {"id": "2010.12561", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, Asuman Ozdaglar", "title": "Train simultaneously, generalize better: Stability of gradient-based\n  minimax learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of minimax learning problems of generative adversarial networks\n(GANs) has been observed to depend on the minimax optimization algorithm used\nfor their training. This dependence is commonly attributed to the convergence\nspeed and robustness properties of the underlying optimization algorithm. In\nthis paper, we show that the optimization algorithm also plays a key role in\nthe generalization performance of the trained minimax model. To this end, we\nanalyze the generalization properties of standard gradient descent ascent (GDA)\nand proximal point method (PPM) algorithms through the lens of algorithmic\nstability under both convex concave and non-convex non-concave minimax\nsettings. While the GDA algorithm is not guaranteed to have a vanishing excess\nrisk in convex concave problems, we show the PPM algorithm enjoys a bounded\nexcess risk in the same setup. For non-convex non-concave problems, we compare\nthe generalization performance of stochastic GDA and GDmax algorithms where the\nlatter fully solves the maximization subproblem at every iteration. Our\ngeneralization analysis suggests the superiority of GDA provided that the\nminimization and maximization subproblems are solved simultaneously with\nsimilar learning rates. We discuss several numerical results indicating the\nrole of optimization algorithms in the generalization of the learned minimax\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:44:43 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Farnia", "Farzan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2010.12574", "submitter": "Djallel Bouneffouf", "authors": "Sohini Upadhyay, Mikhail Yurochkin, Mayank Agarwal, Yasaman Khazaeni\n  and DjallelBouneffouf", "title": "Online Semi-Supervised Learning with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a new problem at the intersectionof semi-supervised learning and\ncontextual bandits,motivated by several applications including clini-cal trials\nand ad recommendations. We demonstratehow Graph Convolutional Network (GCN), a\nsemi-supervised learning approach, can be adjusted tothe new problem\nformulation. We also propose avariant of the linear contextual bandit with\nsemi-supervised missing rewards imputation. We thentake the best of both\napproaches to develop multi-GCN embedded contextual bandit. Our algorithmsare\nverified on several real world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:56:38 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Upadhyay", "Sohini", ""], ["Yurochkin", "Mikhail", ""], ["Agarwal", "Mayank", ""], ["Khazaeni", "Yasaman", ""], ["DjallelBouneffouf", "", ""]]}, {"id": "2010.12605", "submitter": "Alban Farchi", "authors": "Alban Farchi and Patrick Laloyaux and Massimo Bonavita and Marc\n  Bocquet", "title": "Using machine learning to correct model error in data assimilation and\n  forecast applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of using machine learning (ML) methods to reconstruct the dynamics\nof a system is the topic of recent studies in the geosciences, in which the key\noutput is a surrogate model meant to emulate the dynamical model. In order to\ntreat sparse and noisy observations in a rigorous way, ML can be combined to\ndata assimilation (DA). This yields a class of iterative methods in which, at\neach iteration a DA step assimilates the observations, and alternates with a ML\nstep to learn the underlying dynamics of the DA analysis. In this article, we\npropose to use this method to correct the error of an existent, knowledge-based\nmodel. In practice, the resulting surrogate model is an hybrid model between\nthe original (knowledge-based) model and the ML model. We demonstrate\nnumerically the feasibility of the method using a two-layer, two-dimensional\nquasi-geostrophic channel model. Model error is introduced by the means of\nperturbed parameters. The DA step is performed using the strong-constraint\n4D-Var algorithm, while the ML step is performed using deep learning tools. The\nML models are able to learn a substantial part of the model error and the\nresulting hybrid surrogate models produce better short- to mid-range forecasts.\nFurthermore, using the hybrid surrogate models for DA yields a significantly\nbetter analysis than using the original model.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 18:30:45 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 06:46:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Farchi", "Alban", ""], ["Laloyaux", "Patrick", ""], ["Bonavita", "Massimo", ""], ["Bocquet", "Marc", ""]]}, {"id": "2010.12618", "submitter": "Serge Assaad", "authors": "Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta,\n  Ricardo Henao, Fan Li, Lawrence Carin", "title": "Counterfactual Representation Learning with Balancing Weights", "comments": "Accepted to International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key to causal inference with observational data is achieving balance in\npredictive features associated with each treatment type. Recent literature has\nexplored representation learning to achieve this goal. In this work, we discuss\nthe pitfalls of these strategies - such as a steep trade-off between achieving\nbalance and predictive power - and present a remedy via the integration of\nbalancing weights in causal learning. Specifically, we theoretically link\nbalance to the quality of propensity estimation, emphasize the importance of\nidentifying a proper target population, and elaborate on the complementary\nroles of feature balancing and weight adjustments. Using these concepts, we\nthen develop an algorithm for flexible, scalable and accurate estimation of\ncausal effects. Finally, we show how the learned weighted representations may\nserve to facilitate alternative causal learning procedures with appealing\nstatistical features. We conduct an extensive set of experiments on both\nsynthetic examples and standard benchmarks, and report encouraging results\nrelative to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:06:03 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 03:01:10 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Assaad", "Serge", ""], ["Zeng", "Shuxi", ""], ["Tao", "Chenyang", ""], ["Datta", "Shounak", ""], ["Mehta", "Nikhil", ""], ["Henao", "Ricardo", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""]]}, {"id": "2010.12622", "submitter": "Rahul Ragesh", "authors": "Arunava Chakraborty, Rahul Ragesh, Mahir Shah, Nipun Kwatra", "title": "S2cGAN: Semi-Supervised Training of Conditional GANs with Fewer Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have been remarkably successful in\nlearning complex high dimensional real word distributions and generating\nrealistic samples. However, they provide limited control over the generation\nprocess. Conditional GANs (cGANs) provide a mechanism to control the generation\nprocess by conditioning the output on a user defined input. Although training\nGANs requires only unsupervised data, training cGANs requires labelled data\nwhich can be very expensive to obtain. We propose a framework for\nsemi-supervised training of cGANs which utilizes sparse labels to learn the\nconditional mapping, and at the same time leverages a large amount of\nunsupervised data to learn the unconditional distribution. We demonstrate\neffectiveness of our method on multiple datasets and different conditional\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:13:44 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chakraborty", "Arunava", ""], ["Ragesh", "Rahul", ""], ["Shah", "Mahir", ""], ["Kwatra", "Nipun", ""]]}, {"id": "2010.12636", "submitter": "Yunjin Tong", "authors": "Shiying Xiong, Yunjin Tong, Xingzhe He, Shuqi Yang, Cheng Yang, Bo Zhu", "title": "Nonseparable Symplectic Neural Networks", "comments": "ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the behaviors of Hamiltonian systems has been drawing increasing\nattention in scientific machine learning. However, the vast majority of the\nliterature was focused on predicting separable Hamiltonian systems with their\nkinematic and potential energy terms being explicitly decoupled while building\ndata-driven paradigms to predict nonseparable Hamiltonian systems that are\nubiquitous in fluid dynamics and quantum mechanics were rarely explored. The\nmain computational challenge lies in the effective embedding of symplectic\npriors to describe the inherently coupled evolution of position and momentum,\nwhich typically exhibits intricate dynamics. To solve the problem, we propose a\nnovel neural network architecture, Nonseparable Symplectic Neural Networks\n(NSSNNs), to uncover and embed the symplectic structure of a nonseparable\nHamiltonian system from limited observation data. The enabling mechanics of our\napproach is an augmented symplectic time integrator to decouple the position\nand momentum energy terms and facilitate their evolution. We demonstrated the\nefficacy and versatility of our method by predicting a wide range of\nHamiltonian systems, both separable and nonseparable, including chaotic\nvortical flows. We showed the unique computational merits of our approach to\nyield long-term, accurate, and robust predictions for large-scale Hamiltonian\nsystems by rigorously enforcing symplectomorphism.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:50:13 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 05:33:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Xiong", "Shiying", ""], ["Tong", "Yunjin", ""], ["He", "Xingzhe", ""], ["Yang", "Shuqi", ""], ["Yang", "Cheng", ""], ["Zhu", "Bo", ""]]}, {"id": "2010.12638", "submitter": "Hao Cheng", "authors": "Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, Jianfeng Gao", "title": "Posterior Differential Regularization with f-divergence for Improving\n  Model Robustness", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of enhancing model robustness through regularization.\nSpecifically, we focus on methods that regularize the model posterior\ndifference between clean and noisy inputs. Theoretically, we provide a\nconnection of two recent methods, Jacobian Regularization and Virtual\nAdversarial Training, under this framework. Additionally, we generalize the\nposterior differential regularization to the family of $f$-divergences and\ncharacterize the overall regularization framework in terms of Jacobian matrix.\nEmpirically, we systematically compare those regularizations and standard BERT\ntraining on a diverse set of tasks to provide a comprehensive profile of their\neffect on model in-domain and out-of-domain generalization. For both fully\nsupervised and semi-supervised settings, our experiments show that regularizing\nthe posterior differential with $f$-divergence can result in well-improved\nmodel robustness. In particular, with a proper $f$-divergence, a BERT-base\nmodel can achieve comparable generalization as its BERT-large counterpart for\nin-domain, adversarial and domain shift scenarios, indicating the great\npotential of the proposed framework for boosting model generalization for NLP\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:58:01 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 17:22:04 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Cheng", "Hao", ""], ["Liu", "Xiaodong", ""], ["Pereira", "Lis", ""], ["Yu", "Yaoliang", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2010.12642", "submitter": "Louis Faury", "authors": "Marc Abeille, Louis Faury and Cl\\'ement Calauz\\`enes", "title": "Instance-Wise Minimax-Optimal Algorithms for Logistic Bandits", "comments": "40 pages. AISTATS 2021, oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic Bandits have recently attracted substantial attention, by providing\nan uncluttered yet challenging framework for understanding the impact of\nnon-linearity in parametrized bandits. It was shown by Faury et al. (2020) that\nthe learning-theoretic difficulties of Logistic Bandits can be embodied by a\nlarge (sometimes prohibitively) problem-dependent constant $\\kappa$,\ncharacterizing the magnitude of the reward's non-linearity. In this paper we\nintroduce a novel algorithm for which we provide a refined analysis. This\nallows for a better characterization of the effect of non-linearity and yields\nimproved problem-dependent guarantees. In most favorable cases this leads to a\nregret upper-bound scaling as $\\tilde{\\mathcal{O}}(d\\sqrt{T/\\kappa})$, which\ndramatically improves over the $\\tilde{\\mathcal{O}}(d\\sqrt{T}+\\kappa)$\nstate-of-the-art guarantees. We prove that this rate is minimax-optimal by\nderiving a $\\Omega(d\\sqrt{T/\\kappa})$ problem-dependent lower-bound. Our\nanalysis identifies two regimes (permanent and transitory) of the regret, which\nultimately re-conciliates Faury et al. (2020) with the Bayesian approach of\nDong et al. (2019). In contrast to previous works, we find that in the\npermanent regime non-linearity can dramatically ease the\nexploration-exploitation trade-off. While it also impacts the length of the\ntransitory phase in a problem-dependent fashion, we show that this impact is\nmild in most reasonable configurations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:07:31 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 11:09:05 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Abeille", "Marc", ""], ["Faury", "Louis", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""]]}, {"id": "2010.12644", "submitter": "David Lipshutz", "authors": "David Lipshutz, Charlie Windolf, Siavash Golkar, Dmitri B. Chklovskii", "title": "A biologically plausible neural network for Slow Feature Analysis", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent features from time series data is an important problem in\nboth machine learning and brain function. One approach, called Slow Feature\nAnalysis (SFA), leverages the slowness of many salient features relative to the\nrapidly varying input signals. Furthermore, when trained on naturalistic\nstimuli, SFA reproduces interesting properties of cells in the primary visual\ncortex and hippocampus, suggesting that the brain uses temporal slowness as a\ncomputational principle for learning latent features. However, despite the\npotential relevance of SFA for modeling brain function, there is currently no\nSFA algorithm with a biologically plausible neural network implementation, by\nwhich we mean an algorithm operates in the online setting and can be mapped\nonto a neural network with local synaptic updates. In this work, starting from\nan SFA objective, we derive an SFA algorithm, called Bio-SFA, with a\nbiologically plausible neural network implementation. We validate Bio-SFA on\nnaturalistic stimuli.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:09:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lipshutz", "David", ""], ["Windolf", "Charlie", ""], ["Golkar", "Siavash", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2010.12648", "submitter": "Blair Chen", "authors": "Blair Chen, Liu Ziyin, Zihao Wang, Paul Pu Liang", "title": "An Investigation of how Label Smoothing Affects Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been hypothesized that label smoothing can reduce overfitting and\nimprove generalization, and current empirical evidence seems to corroborate\nthese effects. However, there is a lack of mathematical understanding of when\nand why such empirical improvements occur. In this paper, as a step towards\nunderstanding why label smoothing is effective, we propose a theoretical\nframework to show how label smoothing provides in controlling the\ngeneralization loss. In particular, we show that this benefit can be precisely\nformulated and identified in the label noise setting, where the training is\npartially mislabeled. Our theory also predicts the existence of an optimal\nlabel smoothing point, a single value for the label smoothing hyperparameter\nthat minimizes generalization loss. Extensive experiments are done to confirm\nthe predictions of our theory. We believe that our findings will help both\ntheoreticians and practitioners understand label smoothing, and better apply\nthem to real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:26:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chen", "Blair", ""], ["Ziyin", "Liu", ""], ["Wang", "Zihao", ""], ["Liang", "Paul Pu", ""]]}, {"id": "2010.12664", "submitter": "Gholamali Aminian", "authors": "Gholamali Aminian, Laura Toni, Miguel R. D. Rodrigues", "title": "Jensen-Shannon Information Based Characterization of the Generalization\n  Error of Learning Algorithms", "comments": "Accepted in ITW 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization error bounds are critical to understanding the performance of\nmachine learning models. In this work, we propose a new information-theoretic\nbased generalization error upper bound applicable to supervised learning\nscenarios. We show that our general bound can specialize in various previous\nbounds. We also show that our general bound can be specialized under some\nconditions to a new bound involving the Jensen-Shannon information between a\nrandom variable modelling the set of training samples and another random\nvariable modelling the hypothesis. We also prove that our bound can be tighter\nthan mutual information-based bounds under some conditions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:53:07 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 15:27:01 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Aminian", "Gholamali", ""], ["Toni", "Laura", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "2010.12687", "submitter": "Siddharth Jain", "authors": "Bijan Mazaheri, Siddharth Jain, Jehoshua Bruck", "title": "Robust Correction of Sampling Bias Using Cumulative Distribution\n  Functions", "comments": "Accepted in Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Varying domains and biased datasets can lead to differences between the\ntraining and the target distributions, known as covariate shift. Current\napproaches for alleviating this often rely on estimating the ratio of training\nand target probability density functions. These techniques require parameter\ntuning and can be unstable across different datasets. We present a new method\nfor handling covariate shift using the empirical cumulative distribution\nfunction estimates of the target distribution by a rigorous generalization of a\nrecent idea proposed by Vapnik and Izmailov. Further, we show experimentally\nthat our method is more robust in its predictions, is not reliant on parameter\ntuning and shows similar classification performance compared to the current\nstate-of-the-art techniques on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 22:13:00 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mazaheri", "Bijan", ""], ["Jain", "Siddharth", ""], ["Bruck", "Jehoshua", ""]]}, {"id": "2010.12711", "submitter": "Poorya Mianjy", "authors": "Poorya Mianjy and Raman Arora", "title": "On Convergence and Generalization of Dropout Training", "comments": null, "journal-ref": "In Proceedings of Advances in Neural Information Processing\n  Systems (NeurIPS), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study dropout in two-layer neural networks with rectified linear unit\n(ReLU) activations. Under mild overparametrization and assuming that the\nlimiting kernel can separate the data distribution with a positive margin, we\nshow that dropout training with logistic loss achieves $\\epsilon$-suboptimality\nin test error in $O(1/\\epsilon)$ iterations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 23:41:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mianjy", "Poorya", ""], ["Arora", "Raman", ""]]}, {"id": "2010.12718", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Yuan Zhou, Jian Peng", "title": "Learning Guidance Rewards with Trajectory-space Smoothing", "comments": "NeurIPS 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term temporal credit assignment is an important challenge in deep\nreinforcement learning (RL). It refers to the ability of the agent to attribute\nactions to consequences that may occur after a long time interval. Existing\npolicy-gradient and Q-learning algorithms typically rely on dense environmental\nrewards that provide rich short-term supervision and help with credit\nassignment. However, they struggle to solve tasks with delays between an action\nand the corresponding rewarding feedback. To make credit assignment easier,\nrecent works have proposed algorithms to learn dense \"guidance\" rewards that\ncould be used in place of the sparse or delayed environmental rewards. This\npaper is in the same vein -- starting with a surrogate RL objective that\ninvolves smoothing in the trajectory-space, we arrive at a new algorithm for\nlearning guidance rewards. We show that the guidance rewards have an intuitive\ninterpretation, and can be obtained without training any additional neural\nnetworks. Due to the ease of integration, we use the guidance rewards in a few\npopular algorithms (Q-learning, Actor-Critic, Distributional-RL) and present\nresults in single-agent and multi-agent tasks that elucidate the benefit of our\napproach when the environmental rewards are sparse or delayed.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 23:55:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Zhou", "Yuan", ""], ["Peng", "Jian", ""]]}, {"id": "2010.12721", "submitter": "Alireza Mehrtash", "authors": "Alireza Mehrtash, Purang Abolmaesumi, Polina Golland, Tina Kapur,\n  Demian Wassermann, William M. Wells III", "title": "PEP: Parameter Ensembling by Perturbation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembling is now recognized as an effective approach for increasing the\npredictive performance and calibration of deep networks. We introduce a new\napproach, Parameter Ensembling by Perturbation (PEP), that constructs an\nensemble of parameter values as random perturbations of the optimal parameter\nset from training by a Gaussian with a single variance parameter. The variance\nis chosen to maximize the log-likelihood of the ensemble average ($\\mathbb{L}$)\non the validation data set. Empirically, and perhaps surprisingly, $\\mathbb{L}$\nhas a well-defined maximum as the variance grows from zero (which corresponds\nto the baseline model). Conveniently, calibration level of predictions also\ntends to grow favorably until the peak of $\\mathbb{L}$ is reached. In most\nexperiments, PEP provides a small improvement in performance, and, in some\ncases, a substantial improvement in empirical calibration. We show that this\n\"PEP effect\" (the gain in log-likelihood) is related to the mean curvature of\nthe likelihood function and the empirical Fisher information. Experiments on\nImageNet pre-trained networks including ResNet, DenseNet, and Inception showed\nimproved calibration and likelihood. We further observed a mild improvement in\nclassification accuracy on these networks. Experiments on classification\nbenchmarks such as MNIST and CIFAR-10 showed improved calibration and\nlikelihood, as well as the relationship between the PEP effect and overfitting;\nthis demonstrates that PEP can be used to probe the level of overfitting that\noccurred during training. In general, no special training procedure or network\narchitecture is needed, and in the case of pre-trained networks, no additional\ntraining is needed.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 00:16:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mehrtash", "Alireza", ""], ["Abolmaesumi", "Purang", ""], ["Golland", "Polina", ""], ["Kapur", "Tina", ""], ["Wassermann", "Demian", ""], ["Wells", "William M.", "III"]]}, {"id": "2010.12760", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis and Nicol\\`o Fusi", "title": "Dataset Dynamics via Gradient Flows in Probability Space", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various machine learning tasks, from generative modeling to domain\nadaptation, revolve around the concept of dataset transformation and\nmanipulation. While various methods exist for transforming unlabeled datasets,\nprincipled methods to do so for labeled (e.g., classification) datasets are\nmissing. In this work, we propose a novel framework for dataset transformation,\nwhich we cast as optimization over data-generating joint probability\ndistributions. We approach this class of problems through Wasserstein gradient\nflows in probability space, and derive practical and efficient particle-based\nmethods for a flexible but well-behaved class of objective functions. Through\nvarious experiments, we show that this framework can be used to impose\nconstraints on classification datasets, adapt them for transfer learning, or to\nre-purpose fixed or black-box models to classify -- with high accuracy --\npreviously unseen datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 03:29:22 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 16:33:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Fusi", "Nicol\u00f2", ""]]}, {"id": "2010.12797", "submitter": "Bryan Kian Hsiang Low", "authors": "Rachael Hwee Ling Sim, Yehong Zhang, Mun Choon Chan, Bryan Kian Hsiang\n  Low", "title": "Collaborative Machine Learning with Incentive-Aware Model Rewards", "comments": "37th International Conference on Machine Learning (ICML 2020),\n  Extended version with proofs and additional experimental results, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative machine learning (ML) is an appealing paradigm to build\nhigh-quality ML models by training on the aggregated data from many parties.\nHowever, these parties are only willing to share their data when given enough\nincentives, such as a guaranteed fair reward based on their contributions. This\nmotivates the need for measuring a party's contribution and designing an\nincentive-aware reward scheme accordingly. This paper proposes to value a\nparty's reward based on Shapley value and information gain on model parameters\ngiven its data. Subsequently, we give each party a model as a reward. To\nformally incentivize the collaboration, we define some desirable properties\n(e.g., fairness and stability) which are inspired by cooperative game theory\nbut adapted for our model reward that is uniquely freely replicable. Then, we\npropose a novel model reward scheme to satisfy fairness and trade off between\nthe desirable properties via an adjustable parameter. The value of each party's\nmodel reward determined by our scheme is attained by injecting Gaussian noise\nto the aggregated training data with an optimized noise variance. We\nempirically demonstrate interesting properties of our scheme and evaluate its\nperformance using synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 06:20:55 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sim", "Rachael Hwee Ling", ""], ["Zhang", "Yehong", ""], ["Chan", "Mun Choon", ""], ["Low", "Bryan Kian Hsiang", ""]]}, {"id": "2010.12799", "submitter": "Bryan Kian Hsiang Low", "authors": "Dmitrii Kharkovskii, Zhongxiang Dai, Bryan Kian Hsiang Low", "title": "Private Outsourced Bayesian Optimization", "comments": "37th International Conference on Machine Learning (ICML 2020),\n  Extended version with proofs, 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the private-outsourced-Gaussian process-upper confidence\nbound (PO-GP-UCB) algorithm, which is the first algorithm for\nprivacy-preserving Bayesian optimization (BO) in the outsourced setting with a\nprovable performance guarantee. We consider the outsourced setting where the\nentity holding the dataset and the entity performing BO are represented by\ndifferent parties, and the dataset cannot be released non-privately. For\nexample, a hospital holds a dataset of sensitive medical records and outsources\nthe BO task on this dataset to an industrial AI company. The key idea of our\napproach is to make the BO performance of our algorithm similar to that of\nnon-private GP-UCB run using the original dataset, which is achieved by using a\nrandom projection-based transformation that preserves both privacy and the\npairwise distances between inputs. Our main theoretical contribution is to show\nthat a regret bound similar to that of the standard GP-UCB algorithm can be\nestablished for our PO-GP-UCB algorithm. We empirically evaluate the\nperformance of our PO-GP-UCB algorithm with synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 06:30:45 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kharkovskii", "Dmitrii", ""], ["Dai", "Zhongxiang", ""], ["Low", "Bryan Kian Hsiang", ""]]}, {"id": "2010.12810", "submitter": "Chenlin Meng", "authors": "Chenlin Meng, Lantao Yu, Yang Song, Jiaming Song and Stefano Ermon", "title": "Autoregressive Score Matching", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive models use chain rule to define a joint probability\ndistribution as a product of conditionals. These conditionals need to be\nnormalized, imposing constraints on the functional families that can be used.\nTo increase flexibility, we propose autoregressive conditional score models\n(AR-CSM) where we parameterize the joint distribution in terms of the\nderivatives of univariate log-conditionals (scores), which need not be\nnormalized. To train AR-CSM, we introduce a new divergence between\ndistributions named Composite Score Matching (CSM). For AR-CSM models, this\ndivergence between data and model distributions can be computed and optimized\nefficiently, requiring no expensive sampling or adversarial training. Compared\nto previous score matching algorithms, our method is more scalable to high\ndimensional data and more stable to optimize. We show with extensive\nexperimental results that it can be applied to density estimation on synthetic\ndata, image generation, image denoising, and training latent variable models\nwith implicit encoders.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 07:01:24 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Meng", "Chenlin", ""], ["Yu", "Lantao", ""], ["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "2010.12811", "submitter": "Tailin Wu", "authors": "Tailin Wu, Hongyu Ren, Pan Li, Jure Leskovec", "title": "Graph Information Bottleneck", "comments": "20 pages, 3 figures, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning of graph-structured data is challenging because both\ngraph structure and node features carry important information. Graph Neural\nNetworks (GNNs) provide an expressive way to fuse information from network\nstructure and node features. However, GNNs are prone to adversarial attacks.\nHere we introduce Graph Information Bottleneck (GIB), an information-theoretic\nprinciple that optimally balances expressiveness and robustness of the learned\nrepresentation of graph-structured data. Inheriting from the general\nInformation Bottleneck (IB), GIB aims to learn the minimal sufficient\nrepresentation for a given task by maximizing the mutual information between\nthe representation and the target, and simultaneously constraining the mutual\ninformation between the representation and the input data. Different from the\ngeneral IB, GIB regularizes the structural as well as the feature information.\nWe design two sampling algorithms for structural regularization and instantiate\nthe GIB principle with two new models: GIB-Cat and GIB-Bern, and demonstrate\nthe benefits by evaluating the resilience to adversarial attacks. We show that\nour proposed models are more robust than state-of-the-art graph defense models.\nGIB-based models empirically achieve up to 31% improvement with adversarial\nperturbation of the graph structure as well as node features.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 07:13:00 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wu", "Tailin", ""], ["Ren", "Hongyu", ""], ["Li", "Pan", ""], ["Leskovec", "Jure", ""]]}, {"id": "2010.12842", "submitter": "Nicole M\\\"ucke", "authors": "Nicole M\\\"ucke", "title": "Stochastic Gradient Descent Meets Distribution Regression", "comments": null, "journal-ref": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) provides a simple and efficient way to\nsolve a broad range of machine learning problems. Here, we focus on\ndistribution regression (DR), involving two stages of sampling: Firstly, we\nregress from probability measures to real-valued responses. Secondly, we sample\nbags from these distributions for utilizing them to solve the overall\nregression problem. Recently, DR has been tackled by applying kernel ridge\nregression and the learning properties of this approach are well understood.\nHowever, nothing is known about the learning properties of SGD for two stage\nsampling problems. We fill this gap and provide theoretical guarantees for the\nperformance of SGD for DR. Our bounds are optimal in a mini-max sense under\nstandard assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 09:03:00 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 16:33:42 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["M\u00fccke", "Nicole", ""]]}, {"id": "2010.12859", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Eugenio Clerico, Bobby He, George Deligiannidis,\n  Arnaud Doucet, Judith Rousseau", "title": "Stable ResNet", "comments": "43 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep ResNet architectures have achieved state of the art performance on many\ntasks. While they solve the problem of gradient vanishing, they might suffer\nfrom gradient exploding as the depth becomes large (Yang et al. 2017).\nMoreover, recent results have shown that ResNet might lose expressivity as the\ndepth goes to infinity (Yang et al. 2017, Hayou et al. 2019). To resolve these\nissues, we introduce a new class of ResNet architectures, called Stable ResNet,\nthat have the property of stabilizing the gradient while ensuring expressivity\nin the infinite depth limit.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:27:24 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 17:27:53 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hayou", "Soufiane", ""], ["Clerico", "Eugenio", ""], ["He", "Bobby", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""], ["Rousseau", "Judith", ""]]}, {"id": "2010.12864", "submitter": "Xisen Jin", "authors": "Xisen Jin, Francesco Barbieri, Brendan Kennedy, Aida Mostafazadeh\n  Davani, Leonardo Neves, Xiang Ren", "title": "On Transferability of Bias Mitigation Effects in Language Model\n  Fine-Tuning", "comments": "14 pages; Accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuned language models have been shown to exhibit biases against\nprotected groups in a host of modeling tasks such as text classification and\ncoreference resolution. Previous works focus on detecting these biases,\nreducing bias in data representations, and using auxiliary training objectives\nto mitigate bias during fine-tuning. Although these techniques achieve bias\nreduction for the task and domain at hand, the effects of bias mitigation may\nnot directly transfer to new tasks, requiring additional data collection and\ncustomized annotation of sensitive attributes, and re-evaluation of appropriate\nfairness metrics. We explore the feasibility and benefits of upstream bias\nmitigation (UBM) for reducing bias on downstream tasks, by first applying bias\nmitigation to an upstream model through fine-tuning and subsequently using it\nfor downstream fine-tuning. We find, in extensive experiments across hate\nspeech detection, toxicity detection, occupation prediction, and coreference\nresolution tasks over various bias factors, that the effects of UBM are indeed\ntransferable to new downstream tasks or domains via fine-tuning, creating less\nbiased downstream models than directly fine-tuning on the downstream task or\ntransferring from a vanilla upstream model. Though challenges remain, we show\nthat UBM promises more efficient and accessible bias mitigation in LM\nfine-tuning.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:36:11 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 23:34:33 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Jin", "Xisen", ""], ["Barbieri", "Francesco", ""], ["Kennedy", "Brendan", ""], ["Davani", "Aida Mostafazadeh", ""], ["Neves", "Leonardo", ""], ["Ren", "Xiang", ""]]}, {"id": "2010.12865", "submitter": "Jiajin Li", "authors": "Jiajin Li, Caihua Chen, Anthony Man-Cho So", "title": "Fast Epigraphical Projection-based Incremental Algorithms for\n  Wasserstein Distributionally Robust Support Vector Machine", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein \\textbf{D}istributionally \\textbf{R}obust \\textbf{O}ptimization\n(DRO) is concerned with finding decisions that perform well on data that are\ndrawn from the worst-case probability distribution within a Wasserstein ball\ncentered at a certain nominal distribution. In recent years, it has been shown\nthat various DRO formulations of learning models admit tractable convex\nreformulations. However, most existing works propose to solve these convex\nreformulations by general-purpose solvers, which are not well-suited for\ntackling large-scale problems. In this paper, we focus on a family of\nWasserstein distributionally robust support vector machine (DRSVM) problems and\npropose two novel epigraphical projection-based incremental algorithms to solve\nthem. The updates in each iteration of these algorithms can be computed in a\nhighly efficient manner. Moreover, we show that the DRSVM problems considered\nin this paper satisfy a H\\\"olderian growth condition with explicitly determined\ngrowth exponents. Consequently, we are able to establish the convergence rates\nof the proposed incremental algorithms. Our numerical results indicate that the\nproposed methods are orders of magnitude faster than the state-of-the-art, and\nthe performance gap grows considerably as the problem size increases.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:42:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Jiajin", ""], ["Chen", "Caihua", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "2010.12866", "submitter": "Sungbin Lim", "authors": "Kyungjae Lee and Hongjun Yang and Sungbin Lim and Songhwai Oh", "title": "Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed\n  Rewards", "comments": "38 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider stochastic multi-armed bandits (MABs) with\nheavy-tailed rewards, whose $p$-th moment is bounded by a constant $\\nu_{p}$\nfor $1<p\\leq2$. First, we propose a novel robust estimator which does not\nrequire $\\nu_{p}$ as prior information, while other existing robust estimators\ndemand prior knowledge about $\\nu_{p}$. We show that an error probability of\nthe proposed estimator decays exponentially fast. Using this estimator, we\npropose a perturbation-based exploration strategy and develop a generalized\nregret analysis scheme that provides upper and lower regret bounds by revealing\nthe relationship between the regret and the cumulative density function of the\nperturbation. From the proposed analysis scheme, we obtain gap-dependent and\ngap-independent upper and lower regret bounds of various perturbations. We also\nfind the optimal hyperparameters for each perturbation, which can achieve the\nminimax optimal regret bound with respect to total rounds. In simulation, the\nproposed estimator shows favorable performance compared to existing robust\nestimators for various $p$ values and, for MAB problems, the proposed\nperturbation strategy outperforms existing exploration methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:44:02 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lee", "Kyungjae", ""], ["Yang", "Hongjun", ""], ["Lim", "Sungbin", ""], ["Oh", "Songhwai", ""]]}, {"id": "2010.12870", "submitter": "Ahmed Touati", "authors": "Ahmed Touati and Pascal Vincent", "title": "Efficient Learning in Non-Stationary Linear Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study episodic reinforcement learning in non-stationary linear (a.k.a.\nlow-rank) Markov Decision Processes (MDPs), i.e, both the reward and transition\nkernel are linear with respect to a given feature map and are allowed to evolve\neither slowly or abruptly over time. For this problem setting, we propose\nOPT-WLSVI an optimistic model-free algorithm based on weighted least squares\nvalue iteration which uses exponential weights to smoothly forget data that are\nfar in the past. We show that our algorithm, when competing against the best\npolicy at each time, achieves a regret that is upper bounded by\n$\\widetilde{\\mathcal{O}}(d^{5/4}H^2 \\Delta^{1/4} K^{3/4})$ where $d$ is the\ndimension of the feature space, $H$ is the planning horizon, $K$ is the number\nof episodes and $\\Delta$ is a suitable measure of non-stationarity of the MDP.\nMoreover, we point out technical gaps in the study of forgetting strategies in\nnon-stationary linear bandits setting made by previous works and we propose a\nfix to their regret analysis.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 11:02:45 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 14:05:08 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Touati", "Ahmed", ""], ["Vincent", "Pascal", ""]]}, {"id": "2010.12883", "submitter": "Bryan Kian Hsiang Low", "authors": "Quoc Phong Nguyen, Bryan Kian Hsiang Low, Patrick Jaillet", "title": "Variational Bayesian Unlearning", "comments": "34th Annual Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Extended version with proofs, 22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of approximately unlearning a Bayesian model\nfrom a small subset of the training data to be erased. We frame this problem as\none of minimizing the Kullback-Leibler divergence between the approximate\nposterior belief of model parameters after directly unlearning from erased data\nvs. the exact posterior belief from retraining with remaining data. Using the\nvariational inference (VI) framework, we show that it is equivalent to\nminimizing an evidence upper bound which trades off between fully unlearning\nfrom erased data vs. not entirely forgetting the posterior belief given the\nfull data (i.e., including the remaining data); the latter prevents\ncatastrophic unlearning that can render the model useless. In model training\nwith VI, only an approximate (instead of exact) posterior belief given the full\ndata can be obtained, which makes unlearning even more challenging. We propose\ntwo novel tricks to tackle this challenge. We empirically demonstrate our\nunlearning methods on Bayesian models such as sparse Gaussian process and\nlogistic regression using synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 11:53:00 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Nguyen", "Quoc Phong", ""], ["Low", "Bryan Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2010.12887", "submitter": "Jincheng Bai", "authors": "Jincheng Bai, Qifan Song, Guang Cheng", "title": "Nearly Optimal Variational Inference for High Dimensional Regression\n  with Shrinkage Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a variational Bayesian (VB) procedure for high-dimensional linear\nmodel inferences with heavy tail shrinkage priors, such as student-t prior.\nTheoretically, we establish the consistency of the proposed VB method and prove\nthat under the proper choice of prior specifications, the contraction rate of\nthe VB posterior is nearly optimal. It justifies the validity of VB inference\nas an alternative of Markov Chain Monte Carlo (MCMC) sampling. Meanwhile,\ncomparing to conventional MCMC methods, the VB procedure achieves much higher\ncomputational efficiency, which greatly alleviates the computing burden for\nmodern machine learning applications such as massive data analysis. Through\nnumerical studies, we demonstrate that the proposed VB method leads to shorter\ncomputing time, higher estimation accuracy, and lower variable selection error\nthan competitive sparse Bayesian methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 12:10:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bai", "Jincheng", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2010.12905", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Zhenghang Cui, Yoshihiro Fukuhara", "title": "ATRO: Adversarial Training with a Rejection Option", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a classification framework with a rejection option to\nmitigate the performance deterioration caused by adversarial examples. While\nrecent machine learning algorithms achieve high prediction performance, they\nare empirically vulnerable to adversarial examples, which are slightly\nperturbed data samples that are wrongly classified. In real-world applications,\nadversarial attacks using such adversarial examples could cause serious\nproblems. To this end, various methods are proposed to obtain a classifier that\nis robust against adversarial examples. Adversarial training is one of them,\nwhich trains a classifier to minimize the worst-case loss under adversarial\nattacks. In this paper, in order to acquire a more reliable classifier against\nadversarial attacks, we propose the method of Adversarial Training with a\nRejection Option (ATRO). Applying the adversarial training objective to both a\nclassifier and a rejection function simultaneously, classifiers trained by ATRO\ncan choose to abstain from classification when it has insufficient confidence\nto classify a test data point. We examine the feasibility of the framework\nusing the surrogate maximum hinge loss and establish a generalization bound for\nlinear models. Furthermore, we empirically confirmed the effectiveness of ATRO\nusing various models and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 14:05:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kato", "Masahiro", ""], ["Cui", "Zhenghang", ""], ["Fukuhara", "Yoshihiro", ""]]}, {"id": "2010.12909", "submitter": "Depen Morwani", "authors": "Depen Morwani, Harish G. Ramaswamy", "title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized\n  Smooth Homogeneous Neural Nets", "comments": "We have modified proposition 3, removing the extra assumptions,\n  resulting in a slightly less sharp instability result. We have also added a\n  figure showing the norm of the weights for SWN, EWN and NWN for the MNIST\n  training procedure (Appendix N, Figure 11). A few more references that use\n  SWN have been added to page 3. We have also fixed a few typos and grammatical\n  errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the inductive bias of gradient descent for weight normalized\nsmooth homogeneous neural nets, when trained on exponential or cross-entropy\nloss. Our analysis focuses on exponential weight normalization (EWN), which\nencourages weight updates along the radial direction. This paper shows that the\ngradient flow path with EWN is equivalent to gradient flow on standard networks\nwith an adaptive learning rate, and hence causes the weights to be updated in a\nway that prefers asymptotic relative sparsity. These results can be extended to\nhold for gradient descent via an appropriate adaptive learning rate. The\nasymptotic convergence rate of the loss in this setting is given by\n$\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the\nnetwork. We contrast these results with the inductive bias of standard weight\nnormalization (SWN) and unnormalized architectures, and demonstrate their\nimplications on synthetic data sets.Experimental results on simple data sets\nand architectures support our claim on sparse EWN solutions, even with SGD.\nThis demonstrates its potential applications in learning prunable neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 14:34:56 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 05:30:53 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Morwani", "Depen", ""], ["Ramaswamy", "Harish G.", ""]]}, {"id": "2010.12916", "submitter": "Katelyn Gao", "authors": "Katelyn Gao and Ozan Sener", "title": "Modeling and Optimization Trade-off in Meta-learning", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By searching for shared inductive biases across tasks, meta-learning promises\nto accelerate learning on novel tasks, but with the cost of solving a complex\nbilevel optimization problem. We introduce and rigorously define the trade-off\nbetween accurate modeling and optimization ease in meta-learning. At one end,\nclassic meta-learning algorithms account for the structure of meta-learning but\nsolve a complex optimization problem, while at the other end domain randomized\nsearch (otherwise known as joint training) ignores the structure of\nmeta-learning and solves a single level optimization problem. Taking MAML as\nthe representative meta-learning algorithm, we theoretically characterize the\ntrade-off for general non-convex risk functions as well as linear regression,\nfor which we are able to provide explicit bounds on the errors associated with\nmodeling and optimization. We also empirically study this trade-off for\nmeta-reinforcement learning benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:32:08 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 20:03:56 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Gao", "Katelyn", ""], ["Sener", "Ozan", ""]]}, {"id": "2010.12986", "submitter": "Rui Liu", "authors": "Rui Liu, Tianyi Wu, Barzan Mozafari", "title": "Adam with Bandit Sampling for Deep Learning", "comments": "Accepted to NeurIPS 2020 as spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is a widely used optimization method for training deep learning models.\nIt computes individual adaptive learning rates for different parameters. In\nthis paper, we propose a generalization of Adam, called Adambs, that allows us\nto also adapt to different training examples based on their importance in the\nmodel's convergence. To achieve this, we maintain a distribution over all\nexamples, selecting a mini-batch in each iteration by sampling according to\nthis distribution, which we update using a multi-armed bandit algorithm. This\nensures that examples that are more beneficial to the model training are\nsampled with higher probabilities. We theoretically show that Adambs improves\nthe convergence rate of Adam---$O(\\sqrt{\\frac{\\log n}{T} })$ instead of\n$O(\\sqrt{\\frac{n}{T}})$ in some cases. Experiments on various models and\ndatasets demonstrate Adambs's fast convergence in practice.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 21:01:26 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Liu", "Rui", ""], ["Wu", "Tianyi", ""], ["Mozafari", "Barzan", ""]]}, {"id": "2010.12993", "submitter": "Juan Cervino", "authors": "Juan Cervino, Juan Andres Bazerque, Miguel Calvo-Fullana and Alejandro\n  Ribeiro", "title": "Multi-task Supervised Learning via Cross-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider a problem known as multi-task learning, consisting\nof fitting a set of classifier or regression functions intended for solving\ndifferent tasks. In our novel formulation, we couple the parameters of these\nfunctions, so that they learn in their task specific domains while staying\nclose to each other. This facilitates cross-fertilization in which data\ncollected across different domains help improving the learning performance at\neach other task. First, we present a simplified case in which the goal is to\nestimate the means of two Gaussian variables, for the purpose of gaining some\ninsights on the advantage of the proposed cross-learning strategy. Then we\nprovide a stochastic projected gradient algorithm to perform cross-learning\nover a generic loss function. If the number of parameters is large, then the\nprojection step becomes computationally expensive. To avoid this situation, we\nderive a primal-dual algorithm that exploits the structure of the dual problem,\nachieving a formulation whose complexity only depends on the number of tasks.\nPreliminary numerical experiments for image classification by neural networks\ntrained on a dataset divided in different domains corroborate that the\ncross-learned function outperforms both the task-specific and the consensus\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 21:35:57 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 16:06:47 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 01:55:44 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Cervino", "Juan", ""], ["Bazerque", "Juan Andres", ""], ["Calvo-Fullana", "Miguel", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2010.12995", "submitter": "Mathieu Alain", "authors": "Yann Pequignot, Mathieu Alain, Patrick Dallaire, Alireza\n  Yeganehparast, Pascal Germain, Jos\\'ee Desharnais and Fran\\c{c}ois Laviolette", "title": "Implicit Variational Inference: the Parameter and the Predictor Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having access to accurate confidence levels along with the predictions allows\nto determine whether making a decision is worth the risk. Under the Bayesian\nparadigm, the posterior distribution over parameters is used to capture model\nuncertainty, a valuable information that can be translated into predictive\nuncertainty. However, computing the posterior distribution for high capacity\npredictors, such as neural networks, is generally intractable, making\napproximate methods such as variational inference a promising alternative.\nWhile most methods perform inference in the space of parameters, we explore the\nbenefits of carrying inference directly in the space of predictors. Relying on\na family of distributions given by a deep generative neural network, we present\ntwo ways of carrying variational inference: one in \\emph{parameter space}, one\nin \\emph{predictor space}. Importantly, the latter requires us to choose a\ndistribution of inputs, therefore allowing us at the same time to explicitly\naddress the question of \\emph{out-of-distribution} uncertainty. We explore from\nvarious perspectives the implications of working in the predictor space induced\nby neural networks as opposed to the parameter space, focusing mainly on the\nquality of uncertainty estimation for data lying outside of the training\ndistribution. We compare posterior approximations obtained with these two\nmethods to several standard methods and present results showing that\nvariational approximations learned in the predictor space distinguish\nthemselves positively from those trained in the parameter space.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 21:41:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pequignot", "Yann", ""], ["Alain", "Mathieu", ""], ["Dallaire", "Patrick", ""], ["Yeganehparast", "Alireza", ""], ["Germain", "Pascal", ""], ["Desharnais", "Jos\u00e9e", ""], ["Laviolette", "Fran\u00e7ois", ""]]}, {"id": "2010.13006", "submitter": "Xiaoyong Jin", "authors": "Xiaoyong Jin, Yu-Xiang Wang, Xifeng Yan", "title": "Inter-Series Attention Model for COVID-19 Forecasting", "comments": "Accepted by SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic has an unprecedented impact all over the world since early\n2020. During this public health crisis, reliable forecasting of the disease\nbecomes critical for resource allocation and administrative planning. The\nresults from compartmental models such as SIR and SEIR are popularly referred\nby CDC and news media. With more and more COVID-19 data becoming available, we\nexamine the following question: Can a direct data-driven approach without\nmodeling the disease spreading dynamics outperform the well referred\ncompartmental models and their variants? In this paper, we show the\npossibility. It is observed that as COVID-19 spreads at different speed and\nscale in different geographic regions, it is highly likely that similar\nprogression patterns are shared among these regions within different time\nperiods. This intuition lead us to develop a new neural forecasting model,\ncalled Attention Crossing Time Series (\\textbf{ACTS}), that makes forecasts via\ncomparing patterns across time series obtained from multiple regions. The\nattention mechanism originally developed for natural language processing can be\nleveraged and generalized to materialize this idea. Among 13 out of 18 testings\nincluding forecasting newly confirmed cases, hospitalizations and deaths,\n\\textbf{ACTS} outperforms all the leading COVID-19 forecasters highlighted by\nCDC.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 00:11:49 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 20:53:55 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Jin", "Xiaoyong", ""], ["Wang", "Yu-Xiang", ""], ["Yan", "Xifeng", ""]]}, {"id": "2010.13013", "submitter": "Sanath Kumar Krishnamurthy", "authors": "Sanath Kumar Krishnamurthy, Vitor Hadad, and Susan Athey", "title": "Tractable contextual bandits beyond realizability", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractable contextual bandit algorithms often rely on the realizability\nassumption - i.e., that the true expected reward model belongs to a known\nclass, such as linear functions. In this work, we present a tractable bandit\nalgorithm that is not sensitive to the realizability assumption and\ncomputationally reduces to solving a constrained regression problem in every\nepoch. When realizability does not hold, our algorithm ensures the same\nguarantees on regret achieved by realizability-based algorithms under\nrealizability, up to an additive term that accounts for the misspecification\nerror. This extra term is proportional to T times a function of the mean\nsquared error between the best model in the class and the true model, where T\nis the total number of time-steps. Our work sheds light on the bias-variance\ntrade-off for tractable contextual bandits. This trade-off is not captured by\nalgorithms that assume realizability, since under this assumption there exists\nan estimator in the class that attains zero bias.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 01:36:04 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 00:08:36 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Krishnamurthy", "Sanath Kumar", ""], ["Hadad", "Vitor", ""], ["Athey", "Susan", ""]]}, {"id": "2010.13015", "submitter": "Zirui Liu", "authors": "Zirui Liu, Qingquan Song, Kaixiong Zhou, Ting Hsiang Wang, Ying Shan,\n  Xia Hu", "title": "Towards Interaction Detection Using Topological Analysis on Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Detecting statistical interactions between input features is a crucial and\nchallenging task. Recent advances demonstrate that it is possible to extract\nlearned interactions from trained neural networks. It has also been observed\nthat, in neural networks, any interacting features must follow a strongly\nweighted connection to common hidden units. Motivated by the observation, in\nthis paper, we propose to investigate the interaction detection problem from a\nnovel topological perspective by analyzing the connectivity in neural networks.\nSpecially, we propose a new measure for quantifying interaction strength, based\nupon the well-received theory of persistent homology. Based on this measure, a\nPersistence Interaction detection~(PID) algorithm is developed to efficiently\ndetect interactions. Our proposed algorithm is evaluated across a number of\ninteraction detection tasks on several synthetic and real world datasets with\ndifferent hyperparameters. Experimental results validate that the PID algorithm\noutperforms the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 02:15:24 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 03:05:09 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Liu", "Zirui", ""], ["Song", "Qingquan", ""], ["Zhou", "Kaixiong", ""], ["Wang", "Ting Hsiang", ""], ["Shan", "Ying", ""], ["Hu", "Xia", ""]]}, {"id": "2010.13018", "submitter": "Takeyuki Sasai", "authors": "Takeyuki Sasai and Hironori Fujisawa", "title": "Adversarial Robust Low Rank Matrix Estimation: Compressed Sensing and\n  Matrix Completion", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust low rank matrix estimation when outputs are contaminated\nby adversary. Our method covers matrix compressed sensing (including lasso as a\npartial problem) and matrix completion. We attain fast convergence rates by\nusing convex estimators.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 02:32:07 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 08:45:37 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Sasai", "Takeyuki", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "2010.13032", "submitter": "Jiani Li", "authors": "Jiani Li, Waseem Abbas, Xenofon Koutsoukos", "title": "Byzantine Resilient Distributed Multi-Task Learning", "comments": null, "journal-ref": "Thirty-fourth Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed multi-task learning provides significant advantages in\nmulti-agent networks with heterogeneous data sources where agents aim to learn\ndistinct but correlated models simultaneously.However, distributed algorithms\nfor learning relatedness among tasks are not resilient in the presence of\nByzantine agents. In this paper, we present an approach for Byzantine resilient\ndistributed multi-task learning. We propose an efficient online weight\nassignment rule by measuring the accumulated loss using an agent's data and its\nneighbors' models. A small accumulated loss indicates a large similarity\nbetween the two tasks. In order to ensure the Byzantine resilience of the\naggregation at a normal agent, we introduce a step for filtering out larger\nlosses. We analyze the approach for convex models and show that normal agents\nconverge resiliently towards the global minimum.Further, aggregation with the\nproposed weight assignment rule always results in an improved expected regret\nthan the non-cooperative case. Finally, we demonstrate the approach using three\ncase studies, including regression and classification problems, and show that\nour method exhibits good empirical performance for non-convex models, such as\nconvolutional neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 04:32:52 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 19:10:47 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Li", "Jiani", ""], ["Abbas", "Waseem", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2010.13039", "submitter": "Debdeep Pati", "authors": "Indrajit Ghosh, Anirban Bhattacharya and Debdeep Pati", "title": "Statistical optimality and stability of tangent transform algorithms in\n  logit models", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A systematic approach to finding variational approximation in an otherwise\nintractable non-conjugate model is to exploit the general principle of convex\nduality by minorizing the marginal likelihood that renders the problem\ntractable. While such approaches are popular in the context of variational\ninference in non-conjugate Bayesian models, theoretical guarantees on\nstatistical optimality and algorithmic convergence are lacking. Focusing on\nlogistic regression models, we provide mild conditions on the data generating\nprocess to derive non-asymptotic upper bounds to the risk incurred by the\nvariational optima. We demonstrate that these assumptions can be completely\nrelaxed if one considers a slight variation of the algorithm by raising the\nlikelihood to a fractional power. Next, we utilize the theory of dynamical\nsystems to provide convergence guarantees for such algorithms in logistic and\nmultinomial logit regression. In particular, we establish local asymptotic\nstability of the algorithm without any assumptions on the data-generating\nprocess. We explore a special case involving a semi-orthogonal design under\nwhich a global convergence is obtained. The theory is further illustrated using\nseveral numerical studies.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 05:15:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ghosh", "Indrajit", ""], ["Bhattacharya", "Anirban", ""], ["Pati", "Debdeep", ""]]}, {"id": "2010.13048", "submitter": "Edith Cohen", "authors": "Edith Cohen, Ofir Geri, Tamas Sarlos, Uri Stemmer", "title": "Differentially Private Weighted Sampling", "comments": "38 pages, 9 figures", "journal-ref": "AISTATS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common datasets have the form of elements with keys (e.g., transactions and\nproducts) and the goal is to perform analytics on the aggregated form of key\nand frequency pairs. A weighted sample of keys by (a function of) frequency is\na highly versatile summary that provides a sparse set of representative keys\nand supports approximate evaluations of query statistics. We propose private\nweighted sampling (PWS): A method that ensures element-level differential\nprivacy while retaining, to the extent possible, the utility of a respective\nnon-private weighted sample. PWS maximizes the reporting probabilities of keys\nand estimation quality of a broad family of statistics. PWS improves over the\nstate of the art also for the well-studied special case of private histograms,\nwhen no sampling is performed. We empirically demonstrate significant\nperformance gains compared with prior baselines: 20%-300% increase in key\nreporting for common Zipfian frequency distributions and accuracy for $\\times\n2$-$ 8$ lower frequencies in estimation tasks. Moreover, PWS is applied as a\nsimple post-processing of a non-private sample, without requiring the original\ndata. This allows for seamless integration with existing implementations of\nnon-private schemes and retaining the efficiency of schemes designed for\nresource-constrained settings such as massive distributed or streamed data. We\nbelieve that due to practicality and performance, PWS may become a method of\nchoice in applications where privacy is desired.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 06:54:09 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 06:24:54 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 16:55:09 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Cohen", "Edith", ""], ["Geri", "Ofir", ""], ["Sarlos", "Tamas", ""], ["Stemmer", "Uri", ""]]}, {"id": "2010.13055", "submitter": "Edo Cohen-Karlik", "authors": "Edo Cohen-Karlik, Avichai Ben David and Amir Globerson", "title": "Regularizing Towards Permutation Invariance in Recurrent Models", "comments": "9 pages, 5 figures, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning problems the output should not depend on the order\nof the input. Such \"permutation invariant\" functions have been studied\nextensively recently. Here we argue that temporal architectures such as RNNs\nare highly relevant for such problems, despite the inherent dependence of RNNs\non order. We show that RNNs can be regularized towards permutation invariance,\nand that this can result in compact models, as compared to non-recurrent\narchitectures. We implement this idea via a novel form of stochastic\nregularization.\n  Existing solutions mostly suggest restricting the learning problem to\nhypothesis classes which are permutation invariant by design. Our approach of\nenforcing permutation invariance via regularization gives rise to models which\nare \\textit{semi permutation invariant} (e.g. invariant to some permutations\nand not to others). We show that our method outperforms other permutation\ninvariant approaches on synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 07:46:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Cohen-Karlik", "Edo", ""], ["David", "Avichai Ben", ""], ["Globerson", "Amir", ""]]}, {"id": "2010.13061", "submitter": "Trong-Nghia Nguyen", "authors": "T.-N. Nguyen, M.-N. Tran, and R. Kohn", "title": "Recurrent Conditional Heteroskedasticity", "comments": "47 pages, 17 figures, 22 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of financial volatility models, which we call the\nREcurrent Conditional Heteroskedastic (RECH) models, to improve both the\nin-sample analysis and out-of-sample forecast performance of the traditional\nconditional heteroskedastic models. In particular, we incorporate auxiliary\ndeterministic processes, governed by recurrent neural networks, into the\nconditional variance of the traditional conditional heteroskedastic models,\ne.g. the GARCH-type models, to flexibly capture the dynamics of the underlying\nvolatility. The RECH models can detect interesting effects in financial\nvolatility overlooked by the existing conditional heteroskedastic models such\nas the GARCH (Bollerslev, 1986), GJR (Glosten et al., 1993) and EGARCH (Nelson,\n1991). The new models often have good out-of-sample forecasts while still\nexplain well the stylized facts of financial volatility by retaining the\nwell-established structures of the econometric GARCH-type models. These\nproperties are illustrated through simulation studies and applications to four\nreal stock index datasets. An user-friendly software package together with the\nexamples reported in the paper are available at https://github.com/vbayeslab.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 08:09:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Nguyen", "T. -N.", ""], ["Tran", "M. -N.", ""], ["Kohn", "R.", ""]]}, {"id": "2010.13064", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Bin Dai, David Wipf and Jun Zhu", "title": "Further Analysis of Outlier Detection with Deep Generative Models", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent, counter-intuitive discovery that deep generative models (DGMs)\ncan frequently assign a higher likelihood to outliers has implications for both\noutlier detection applications as well as our overall understanding of\ngenerative modeling. In this work, we present a possible explanation for this\nphenomenon, starting from the observation that a model's typical set and\nhigh-density region may not conincide. From this vantage point we propose a\nnovel outlier test, the empirical success of which suggests that the failure of\nexisting likelihood-based outlier tests does not necessarily imply that the\ncorresponding generative model is uncalibrated. We also conduct additional\nexperiments to help disentangle the impact of low-level texture versus\nhigh-level semantics in differentiating outliers. In aggregate, these results\nsuggest that modifications to the standard evaluation practices and benchmarks\ncommonly applied in the literature are needed.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 08:20:38 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Ziyu", ""], ["Dai", "Bin", ""], ["Wipf", "David", ""], ["Zhu", "Jun", ""]]}, {"id": "2010.13146", "submitter": "Andreea-Ioana Deac", "authors": "Andreea Deac, Petar Veli\\v{c}kovi\\'c, Ognjen Milinkovi\\'c, Pierre-Luc\n  Bacon, Jian Tang, Mladen Nikoli\\'c", "title": "XLVIN: eXecuted Latent Value Iteration Nets", "comments": "NeurIPS 2020 Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value Iteration Networks (VINs) have emerged as a popular method to\nincorporate planning algorithms within deep reinforcement learning, enabling\nperformance improvements on tasks requiring long-range reasoning and\nunderstanding of environment dynamics. This came with several limitations,\nhowever: the model is not incentivised in any way to perform meaningful\nplanning computations, the underlying state space is assumed to be discrete,\nand the Markov decision process (MDP) is assumed fixed and known. We propose\neXecuted Latent Value Iteration Networks (XLVINs), which combine recent\ndevelopments across contrastive self-supervised learning, graph representation\nlearning and neural algorithmic reasoning to alleviate all of the above\nlimitations, successfully deploying VIN-style models on generic environments.\nXLVINs match the performance of VIN-like models when the underlying MDP is\ndiscrete, fixed and known, and provides significant improvements to model-free\nbaselines across three general MDP setups.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:04:30 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 16:59:01 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Deac", "Andreea", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Milinkovi\u0107", "Ognjen", ""], ["Bacon", "Pierre-Luc", ""], ["Tang", "Jian", ""], ["Nikoli\u0107", "Mladen", ""]]}, {"id": "2010.13152", "submitter": "Cencheng Shen", "authors": "Carey E. Priebe, Cencheng Shen, Ningyuan Huang, Tianyi Chen", "title": "A Simple Spectral Failure Mode for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple generative model in which spectral graph embedding for\nsubsequent inference succeeds whereas unsupervised graph convolutional networks\n(GCN) fail. The geometrical insight is that the GCN is unable to look beyond\nthe first non-informative spectral dimension.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:22:48 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 16:31:23 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Priebe", "Carey E.", ""], ["Shen", "Cencheng", ""], ["Huang", "Ningyuan", ""], ["Chen", "Tianyi", ""]]}, {"id": "2010.13165", "submitter": "Zhiqi Bu", "authors": "Zhiqi Bu, Shiyun Xu, Kan Chen", "title": "A Dynamical View on Optimization Algorithms of Overparameterized Neural\n  Networks", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When equipped with efficient optimization algorithms, the over-parameterized\nneural networks have demonstrated high level of performance even though the\nloss function is non-convex and non-smooth. While many works have been focusing\non understanding the loss dynamics by training neural networks with the\ngradient descent (GD), in this work, we consider a broad class of optimization\nalgorithms that are commonly used in practice. For example, we show from a\ndynamical system perspective that the Heavy Ball (HB) method can converge to\nglobal minimum on mean squared error (MSE) at a linear rate (similar to GD);\nhowever, the Nesterov accelerated gradient descent (NAG) may only converges to\nglobal minimum sublinearly.\n  Our results rely on the connection between neural tangent kernel (NTK) and\nfinite over-parameterized neural networks with ReLU activation, which leads to\nanalyzing the limiting ordinary differential equations (ODE) for optimization\nalgorithms. We show that, optimizing the non-convex loss over the weights\ncorresponds to optimizing some strongly convex loss over the prediction error.\nAs a consequence, we can leverage the classical convex optimization theory to\nunderstand the convergence behavior of neural networks. We believe our approach\ncan also be extended to other optimization algorithms and network\narchitectures.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 17:10:22 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 17:28:13 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Bu", "Zhiqi", ""], ["Xu", "Shiyun", ""], ["Chen", "Kan", ""]]}, {"id": "2010.13178", "submitter": "Orestis Plevrakis", "authors": "Orestis Plevrakis and Elad Hazan", "title": "Geometric Exploration for Online Control", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the control of an \\emph{unknown} linear dynamical system under\ngeneral convex costs. The objective is minimizing regret vs. the class of\ndisturbance-feedback-controllers, which encompasses all stabilizing\nlinear-dynamical-controllers. In this work, we first consider the case of known\ncost functions, for which we design the first polynomial-time algorithm with\n$n^3\\sqrt{T}$-regret, where $n$ is the dimension of the state plus the\ndimension of control input. The $\\sqrt{T}$-horizon dependence is optimal, and\nimproves upon the previous best known bound of $T^{2/3}$. The main component of\nour algorithm is a novel geometric exploration strategy: we adaptively\nconstruct a sequence of barycentric spanners in the policy space. Second, we\nconsider the case of bandit feedback, for which we give the first\npolynomial-time algorithm with $poly(n)\\sqrt{T}$-regret, building on Stochastic\nBandit Convex Optimization.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 18:11:28 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 12:19:11 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Plevrakis", "Orestis", ""], ["Hazan", "Elad", ""]]}, {"id": "2010.13187", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Yamini Bansal, Yukun Ding, Cole Hurwitz, Kai Xu,\n  Bernhard Egger, Prasanna Sattigeri, Josh Tenenbaum, David D. Cox, Dan\n  Gutfreund", "title": "Improving the Reconstruction of Disentangled Representation Learners via\n  Multi-Stage Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current autoencoder-based disentangled representation learning methods\nachieve disentanglement by penalizing the (aggregate) posterior to encourage\nstatistical independence of the latent factors. This approach introduces a\ntrade-off between disentangled representation learning and reconstruction\nquality since the model does not have enough capacity to learn correlated\nlatent variables that capture detail information present in most image data. To\novercome this trade-off, we present a novel multi-stage modelling approach\nwhere the disentangled factors are first learned using a preexisting\ndisentangled representation learning method (such as $\\beta$-TCVAE); then, the\nlow-quality reconstruction is improved with another deep generative model that\nis trained to model the missing correlated latent variables, adding detail\ninformation while maintaining conditioning on the previously learned\ndisentangled factors. Taken together, our multi-stage modelling approach\nresults in a single, coherent probabilistic model that is theoretically\njustified by the principal of D-separation and can be realized with a variety\nof model classes including likelihood-based models such as variational\nautoencoders, implicit models such as generative adversarial networks, and\ntractable models like normalizing flows or mixtures of Gaussians. We\ndemonstrate that our multi-stage model has much higher reconstruction quality\nthan current state-of-the-art methods with equivalent disentanglement\nperformance across multiple standard benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 18:51:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Srivastava", "Akash", ""], ["Bansal", "Yamini", ""], ["Ding", "Yukun", ""], ["Hurwitz", "Cole", ""], ["Xu", "Kai", ""], ["Egger", "Bernhard", ""], ["Sattigeri", "Prasanna", ""], ["Tenenbaum", "Josh", ""], ["Cox", "David D.", ""], ["Gutfreund", "Dan", ""]]}, {"id": "2010.13229", "submitter": "Marina Vannucci", "authors": "Nathan Osborne, Christine B. Peterson, and Marina Vannucci", "title": "Latent Network Estimation and Variable Selection for Compositional Data\n  via Variational EM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network estimation and variable selection have been extensively studied in\nthe statistical literature, but only recently have those two challenges been\naddressed simultaneously. In this paper, we seek to develop a novel method to\nsimultaneously estimate network interactions and associations to relevant\ncovariates for count data, and specifically for compositional data, which have\na fixed sum constraint. We use a hierarchical Bayesian model with latent layers\nand employ spike-and-slab priors for both edge and covariate selection. For\nposterior inference, we develop a novel variational inference scheme with an\nexpectation maximization step, to enable efficient estimation. Through\nsimulation studies, we demonstrate that the proposed model outperforms existing\nmethods in its accuracy of network recovery. We show the practical utility of\nour model via an application to microbiome data. The human microbiome has been\nshown to contribute to many of the functions of the human body, and also to be\nlinked with a number of diseases. In our application, we seek to better\nunderstand the interaction between microbes and relevant covariates, as well as\nthe interaction of microbes with each other. We provide a Python implementation\nof our algorithm, called SINC (Simultaneous Inference for Networks and\nCovariates), available online.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 21:52:39 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 02:44:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Osborne", "Nathan", ""], ["Peterson", "Christine B.", ""], ["Vannucci", "Marina", ""]]}, {"id": "2010.13269", "submitter": "Shih-Gu Huang", "authors": "Shih-Gu Huang, Moo K. Chung, Anqi Qiu, Alzheimer's Disease\n  Neuroimaging Initiative", "title": "Revisiting convolutional neural network on graphs with polynomial\n  approximations of Laplace-Beltrami spectral filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits spectral graph convolutional neural networks (graph-CNNs)\ngiven in Defferrard (2016) and develops the Laplace-Beltrami CNN (LB-CNN) by\nreplacing the graph Laplacian with the LB operator. We then define spectral\nfilters via the LB operator on a graph. We explore the feasibility of\nChebyshev, Laguerre, and Hermite polynomials to approximate LB-based spectral\nfilters and define an update of the LB operator for pooling in the LBCNN. We\nemploy the brain image data from Alzheimer's Disease Neuroimaging Initiative\n(ADNI) and demonstrate the use of the proposed LB-CNN. Based on the cortical\nthickness of the ADNI dataset, we showed that the LB-CNN didn't improve\nclassification accuracy compared to the spectral graph-CNN. The three\npolynomials had a similar computational cost and showed comparable\nclassification accuracy in the LB-CNN or spectral graph-CNN. Our findings\nsuggest that even though the shapes of the three polynomials are different,\ndeep learning architecture allows us to learn spectral filters such that the\nclassification performance is not dependent on the type of the polynomials or\nthe operators (graph Laplacian and LB operator).\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 01:18:05 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Huang", "Shih-Gu", ""], ["Chung", "Moo K.", ""], ["Qiu", "Anqi", ""], ["Initiative", "Alzheimer's Disease Neuroimaging", ""]]}, {"id": "2010.13275", "submitter": "Hossein Taheri", "authors": "Hossein Taheri, Ramtin Pedarsani, and Christos Thrampoulidis", "title": "Asymptotic Behavior of Adversarial Training in Binary Classification", "comments": "V3: additional theoretical results, extensions to correlated features", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been consistently reported that many machine learning models are\nsusceptible to adversarial attacks i.e., small additive adversarial\nperturbations applied to data points can cause misclassification. Adversarial\ntraining using empirical risk minimization is considered to be the\nstate-of-the-art method for defense against adversarial attacks. Despite being\nsuccessful in practice, several problems in understanding generalization\nperformance of adversarial training remain open. In this paper, we derive\nprecise theoretical predictions for the performance of adversarial training in\nbinary classification. We consider the high-dimensional regime where the\ndimension of data grows with the size of the training data-set at a constant\nratio. Our results provide exact asymptotics for standard and adversarial test\nerrors of the estimators obtained by adversarial training with $\\ell_q$-norm\nbounded perturbations ($q \\ge 1$) for both discriminative binary models and\ngenerative Gaussian-mixture models with correlated features. Furthermore, we\nuse these sharp predictions to uncover several intriguing observations on the\nrole of various parameters including the over-parameterization ratio, the data\nmodel, and the attack budget on the adversarial and standard errors.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 01:44:20 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 02:06:01 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 01:20:45 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Taheri", "Hossein", ""], ["Pedarsani", "Ramtin", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2010.13301", "submitter": "Ang Yang", "authors": "Ang Yang", "title": "Scalable Bayesian Optimization with Sparse Gaussian Process Models", "comments": "Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This thesis focuses on Bayesian optimization with the improvements coming\nfrom two aspects:(i) the use of derivative information to accelerate the\noptimization convergence; and (ii) the consideration of scalable GPs for\nhandling massive data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 03:16:54 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yang", "Ang", ""]]}, {"id": "2010.13335", "submitter": "Satoshi Takabe", "authors": "Satoshi Takabe and Tadashi Wadayama", "title": "Convergence Acceleration via Chebyshev Step: Plausible Interpretation of\n  Deep-Unfolded Gradient Descent", "comments": "17 pages, 22 figures, This manuscript is the revised and updated\n  version of arXiv:2001.03280 and arXiv:2001.05142", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding is a promising deep-learning technique, whose network\narchitecture is based on expanding the recursive structure of existing\niterative algorithms. Although convergence acceleration is a remarkable\nadvantage of deep unfolding, its theoretical aspects have not been revealed\nyet. The first half of this study details the theoretical analysis of the\nconvergence acceleration in deep-unfolded gradient descent (DUGD) whose\ntrainable parameters are step sizes. We propose a plausible interpretation of\nthe learned step-size parameters in DUGD by introducing the principle of\nChebyshev steps derived from Chebyshev polynomials. The use of Chebyshev steps\nin gradient descent (GD) enables us to bound the spectral radius of a matrix\ngoverning the convergence speed of GD, leading to a tight upper bound on the\nconvergence rate. The convergence rate of GD using Chebyshev steps is shown to\nbe asymptotically optimal, although it has no momentum terms. We also show that\nChebyshev steps numerically explain the learned step-size parameters in DUGD\nwell. In the second half of the study, %we apply the theory of Chebyshev steps\nand Chebyshev-periodical successive over-relaxation (Chebyshev-PSOR) is\nproposed for accelerating linear/nonlinear fixed-point iterations. Theoretical\nanalysis and numerical experiments indicate that Chebyshev-PSOR exhibits\nsignificantly faster convergence for various examples such as Jacobi method and\nproximal gradient methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 04:28:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Takabe", "Satoshi", ""], ["Wadayama", "Tadashi", ""]]}, {"id": "2010.13356", "submitter": "Xudong Pan", "authors": "Xudong Pan, Mi Zhang, Yifan Yan, Jiaming Zhu, Min Yang", "title": "Theory-Oriented Deep Leakage from Gradients via Linear Equation Solver", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we take a theory-oriented approach to systematically study the\nprivacy properties of gradients from a broad class of neural networks with\nrectified linear units (ReLU), probably the most popular activation function\nused in current deep learning practices. By utilizing some intrinsic properties\nof neural networks with ReLU, we prove the existence of exclusively activated\nneurons is critical to the separability of the activation patterns of different\nsamples. Intuitively, an activation pattern is like the fingerprint of the\ncorresponding sample during the training process. With the separated activation\npatterns, we for the first time show the equivalence of data reconstruction\nattacks with a sparse linear equation system.\n  In practice, we propose a novel data reconstruction attack on fully-connected\nneural networks and extend the attack to more commercial convolutional neural\nnetwork architectures. Our systematic evaluations cover more than $10$\nrepresentative neural network architectures (e.g., GoogLeNet, VGGNet and $6$\nmore), on various real-world scenarios related with healthcare, medical\nimaging, location, face recognition and shopping behaviors. In the majority of\ntest cases, our proposed attack is able to infer ground-truth labels in the\ntraining batch with near $100\\%$ accuracy, reconstruct the input data to\nfully-connected neural networks with lower than $10^{-6}$ MSE error, and\nprovide better reconstruction results on both shallow and deep convolutional\nneural networks than previous attacks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 05:54:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pan", "Xudong", ""], ["Zhang", "Mi", ""], ["Yan", "Yifan", ""], ["Zhu", "Jiaming", ""], ["Yang", "Min", ""]]}, {"id": "2010.13364", "submitter": "Tian Tong", "authors": "Tian Tong, Cong Ma, Yuejie Chi", "title": "Low-Rank Matrix Recovery with Scaled Subgradient Methods: Fast and\n  Robust Convergence Without the Condition Number", "comments": "Accepted to IEEE Transaction on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2021.3071560", "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in data science can be treated as estimating a low-rank matrix\nfrom highly incomplete, sometimes even corrupted, observations. One popular\napproach is to resort to matrix factorization, where the low-rank matrix\nfactors are optimized via first-order methods over a smooth loss function, such\nas the residual sum of squares. While tremendous progresses have been made in\nrecent years, the natural smooth formulation suffers from two sources of\nill-conditioning, where the iteration complexity of gradient descent scales\npoorly both with the dimension as well as the condition number of the low-rank\nmatrix. Moreover, the smooth formulation is not robust to corruptions. In this\npaper, we propose scaled subgradient methods to minimize a family of nonsmooth\nand nonconvex formulations -- in particular, the residual sum of absolute\nerrors -- which is guaranteed to converge at a fast rate that is almost\ndimension-free and independent of the condition number, even in the presence of\ncorruptions. We illustrate the effectiveness of our approach when the\nobservation operator satisfies certain mixed-norm restricted isometry\nproperties, and derive state-of-the-art performance guarantees for a variety of\nproblems such as robust low-rank matrix sensing and quadratic sampling.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 06:21:14 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 15:09:42 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tong", "Tian", ""], ["Ma", "Cong", ""], ["Chi", "Yuejie", ""]]}, {"id": "2010.13366", "submitter": "Keisuke Kinoshita", "authors": "Keisuke Kinoshita, Marc Delcroix, Naohiro Tawara", "title": "Integrating end-to-end neural and clustering-based diarization: Getting\n  the best of both worlds", "comments": "To appear in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent diarization technologies can be categorized into two approaches, i.e.,\nclustering and end-to-end neural approaches, which have different pros and\ncons. The clustering-based approaches assign speaker labels to speech regions\nby clustering speaker embeddings such as x-vectors. While it can be seen as a\ncurrent state-of-the-art approach that works for various challenging data with\nreasonable robustness and accuracy, it has a critical disadvantage that it\ncannot handle overlapped speech that is inevitable in natural conversational\ndata. In contrast, the end-to-end neural diarization (EEND), which directly\npredicts diarization labels using a neural network, was devised to handle the\noverlapped speech. While the EEND, which can easily incorporate emerging\ndeep-learning technologies, has started outperforming the x-vector clustering\napproach in some realistic database, it is difficult to make it work for `long'\nrecordings (e.g., recordings longer than 10 minutes) because of, e.g., its huge\nmemory consumption. Block-wise independent processing is also difficult because\nit poses an inter-block label permutation problem, i.e., an ambiguity of the\nspeaker label assignments between blocks. In this paper, we propose a simple\nbut effective hybrid diarization framework that works with overlapped speech\nand for long recordings containing an arbitrary number of speakers. It modifies\nthe conventional EEND framework to simultaneously output global speaker\nembeddings so that speaker clustering can be performed across blocks to solve\nthe permutation problem. With experiments based on simulated noisy reverberant\n2-speaker meeting-like data, we show that the proposed framework works\nsignificantly better than the original EEND especially when the input data is\nlong.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 06:33:02 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 02:34:07 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Kinoshita", "Keisuke", ""], ["Delcroix", "Marc", ""], ["Tawara", "Naohiro", ""]]}, {"id": "2010.13388", "submitter": "Hamidreza Arian", "authors": "Hamidreza Arian, Seyed Mohammad Sina Seyfi, Azin Sharifi", "title": "A Novel Classification Approach for Credit Scoring based on Gaussian\n  Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit scoring is a rapidly expanding analytical technique used by banks and\nother financial institutions. Academic studies on credit scoring provide a\nrange of classification techniques used to differentiate between good and bad\nborrowers. The main contribution of this paper is to introduce a new method for\ncredit scoring based on Gaussian Mixture Models. Our algorithm classifies\nconsumers into groups which are labeled as positive or negative. Labels are\nestimated according to the probability associated with each class. We apply our\nmodel with real world databases from Australia, Japan, and Germany. Numerical\nresults show that not only our model's performance is comparable to others, but\nalso its flexibility avoids over-fitting even in the absence of standard cross\nvalidation techniques. The framework developed by this paper can provide a\ncomputationally efficient and powerful tool for assessment of consumer default\nrisk in related financial institutions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 07:34:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Arian", "Hamidreza", ""], ["Seyfi", "Seyed Mohammad Sina", ""], ["Sharifi", "Azin", ""]]}, {"id": "2010.13405", "submitter": "Francois Bachoc", "authors": "Fran\\c{c}ois Bachoc (IMT), Tommaso Cesari (TSE), S\\'ebastien\n  Gerchinovitz (IMT)", "title": "The sample complexity of level set approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating the level set of an unknown function by\nsequentially querying its values. We introduce a family of algorithms called\nBisect and Approximate through which we reduce the level set approximation\nproblem to a local function approximation problem. We then show how this\napproach leads to rate-optimal sample complexity guarantees for H{\\\"o}lder\nfunctions, and we investigate how such rates improve when additional smoothness\nor other structural assumptions hold true.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 08:02:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 09:09:29 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Bachoc", "Fran\u00e7ois", "", "IMT"], ["Cesari", "Tommaso", "", "TSE"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"]]}, {"id": "2010.13407", "submitter": "Dominique Vaufreydaz", "authors": "Niranjan Deshpande (CHROMA), Dominique Vaufreydaz (LIG), Anne\n  Spalanzani (CHROMA)", "title": "Behavioral decision-making for urban autonomous driving in the presence\n  of pedestrians using Deep Recurrent Q-Network", "comments": null, "journal-ref": "16th International Conference on Control, Automation, Robotics and\n  Vision (ICARCV), Dec 2020, Shenzhen, China", "doi": null, "report-no": null, "categories": "cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making for autonomous driving in urban environments is challenging\ndue to the complexity of the road structure and the uncertainty in the behavior\nof diverse road users. Traditional methods consist of manually designed rules\nas the driving policy, which require expert domain knowledge, are difficult to\ngeneralize and might give sub-optimal results as the environment gets complex.\nWhereas, using reinforcement learning, optimal driving policy could be learned\nand improved automatically through several interactions with the environment.\nHowever, current research in the field of reinforcement learning for autonomous\ndriving is mainly focused on highway setup with little to no emphasis on urban\nenvironments. In this work, a deep reinforcement learning based decision-making\napproach for high-level driving behavior is proposed for urban environments in\nthe presence of pedestrians. For this, the use of Deep Recurrent Q-Network\n(DRQN) is explored, a method combining state-of-the art Deep Q-Network (DQN)\nwith a long term short term memory (LSTM) layer helping the agent gain a memory\nof the environment. A 3-D state representation is designed as the input\ncombined with a well defined reward function to train the agent for learning an\nappropriate behavior policy in a real-world like urban simulator. The proposed\nmethod is evaluated for dense urban scenarios and compared with a rule-based\napproach and results show that the proposed DRQN based driving behavior\ndecision maker outperforms the rule-based approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 08:08:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Deshpande", "Niranjan", "", "CHROMA"], ["Vaufreydaz", "Dominique", "", "LIG"], ["Spalanzani", "Anne", "", "CHROMA"]]}, {"id": "2010.13452", "submitter": "Hawre Jalal", "authors": "Hawre Jalal and Fernando Alarid-Escudero", "title": "BayCANN: Streamlining Bayesian Calibration with Artificial Neural\n  Network Metamodeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Bayesian calibration is theoretically superior to standard\ndirect-search algorithm because it can reveal the full joint posterior\ndistribution of the calibrated parameters. However, to date, Bayesian\ncalibration has not been used often in health decision sciences due to\npractical and computational burdens. In this paper we propose to use artificial\nneural networks (ANN) as one solution to these limitations.\n  Methods: Bayesian Calibration using Artificial Neural Networks (BayCANN)\ninvolves (1) training an ANN metamodel on a sample of model inputs and outputs,\nand (2) then calibrating the trained ANN metamodel instead of the full model in\na probabilistic programming language to obtain the posterior joint distribution\nof the calibrated parameters. We demonstrate BayCANN by calibrating a natural\nhistory model of colorectal cancer to adenoma prevalence and cancer incidence\ndata. In addition, we compare the efficiency and accuracy of BayCANN against\nperforming a Bayesian calibration directly on the simulation model using an\nincremental mixture importance sampling (IMIS) algorithm.\n  Results: BayCANN was generally more accurate than IMIS in recovering the\n\"true\" parameter values. The ratio of the absolute ANN deviation from the truth\ncompared to IMIS for eight out of the nine calibrated parameters were less than\none indicating that BayCANN was more accurate than IMIS. In addition, BayCANN\ntook about 15 minutes total compared to the IMIS method which took 80 minutes.\n  Conclusions: In our case study, BayCANN was more accurate than IMIS and was\nfive-folds faster. Because BayCANN does not depend on the structure of the\nsimulation model, it can be adapted to models of various levels of complexity\nwith minor changes to its structure. We provide BayCANN's open-source\nimplementation in R.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:47:39 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jalal", "Hawre", ""], ["Alarid-Escudero", "Fernando", ""]]}, {"id": "2010.13456", "submitter": "Jeremias Knoblauch", "authors": "Jeremias Knoblauch, Lara Vomfell", "title": "Robust Bayesian Inference for Discrete Outcomes with the Total Variation\n  Distance", "comments": "16p., 7 figs.; authors contributed equally & author order determined\n  by coin flip", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of discrete-valued outcomes are easily misspecified if the data\nexhibit zero-inflation, overdispersion or contamination. Without additional\nknowledge about the existence and nature of this misspecification, model\ninference and prediction are adversely affected. Here, we introduce a robust\ndiscrepancy-based Bayesian approach using the Total Variation Distance (TVD).\nIn the process, we address and resolve two challenges: First, we study\nconvergence and robustness properties of a computationally efficient estimator\nfor the TVD between a parametric model and the data-generating mechanism.\nSecond, we provide an efficient inference method adapted from Lyddon et al.\n(2019) which corresponds to formulating an uninformative nonparametric prior\ndirectly over the data-generating mechanism. Lastly, we empirically demonstrate\nthat our approach is robust and significantly improves predictive performance\non a range of simulated and real world data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:53:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Knoblauch", "Jeremias", ""], ["Vomfell", "Lara", ""]]}, {"id": "2010.13472", "submitter": "Vincent Fortuin", "authors": "Metod Jazbec, Matthew Ashman, Vincent Fortuin, Michael Pearce, Stephan\n  Mandt, Gunnar R\\\"atsch", "title": "Scalable Gaussian Process Variational Autoencoders", "comments": "Published at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional variational autoencoders fail in modeling correlations between\ndata points due to their use of factorized priors. Amortized Gaussian process\ninference through GP-VAEs has led to significant improvements in this regard,\nbut is still inhibited by the intrinsic complexity of exact GP inference. We\nimprove the scalability of these methods through principled sparse inference\napproaches. We propose a new scalable GP-VAE model that outperforms existing\napproaches in terms of runtime and memory footprint, is easy to implement, and\nallows for joint end-to-end optimization of all components.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 10:26:02 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 17:53:41 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 17:56:18 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Jazbec", "Metod", ""], ["Ashman", "Matthew", ""], ["Fortuin", "Vincent", ""], ["Pearce", "Michael", ""], ["Mandt", "Stephan", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "2010.13483", "submitter": "Michael Lutter", "authors": "Kai Ploeger, Michael Lutter, Jan Peters", "title": "High Acceleration Reinforcement Learning for Real-World Juggling with\n  Binary Rewards", "comments": "Published at Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots that can learn in the physical world will be important to en-able\nrobots to escape their stiff and pre-programmed movements. For dynamic\nhigh-acceleration tasks, such as juggling, learning in the real-world is\nparticularly challenging as one must push the limits of the robot and its\nactuation without harming the system, amplifying the necessity of sample\nefficiency and safety for robot learning algorithms. In contrast to prior work\nwhich mainly focuses on the learning algorithm, we propose a learning system,\nthat directly incorporates these requirements in the design of the policy\nrepresentation, initialization, and optimization. We demonstrate that this\nsystem enables the high-speed Barrett WAM manipulator to learn juggling two\nballs from 56 minutes of experience with a binary reward signal. The final\npolicy juggles continuously for up to 33 minutes or about 4500 repeated\ncatches. The videos documenting the learning process and the evaluation can be\nfound at https://sites.google.com/view/jugglingbot\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:13:47 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:41:39 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 18:15:45 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ploeger", "Kai", ""], ["Lutter", "Michael", ""], ["Peters", "Jan", ""]]}, {"id": "2010.13491", "submitter": "Anirudh Singhal", "authors": "Anirudh Singhal, Subham Pirojiwala and Nikhil Karamchandani", "title": "Query Complexity of k-NN based Mode Estimation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the mode estimation problem of an unknown multivariate\nprobability density function, we study the problem of identifying the point\nwith the minimum k-th nearest neighbor distance for a given dataset of n\npoints. We study the case where the pairwise distances are apriori unknown, but\nwe have access to an oracle which we can query to get noisy information about\nthe distance between any pair of points. For two natural oracle models, we\ndesign a sequential learning algorithm, based on the idea of confidence\nintervals, which adaptively decides which queries to send to the oracle and is\nable to correctly solve the problem with high probability. We derive\ninstance-dependent upper bounds on the query complexity of our proposed scheme\nand also demonstrate significant improvement over the performance of other\nbaselines via extensive numerical evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:32:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Singhal", "Anirudh", ""], ["Pirojiwala", "Subham", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "2010.13498", "submitter": "Markus Heinonen", "authors": "Trung Trinh, Samuel Kaski, Markus Heinonen", "title": "Scalable Bayesian neural networks by layer-wise input augmentation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce implicit Bayesian neural networks, a simple and scalable\napproach for uncertainty representation in deep learning. Standard Bayesian\napproach to deep learning requires the impractical inference of the posterior\ndistribution over millions of parameters. Instead, we propose to induce a\ndistribution that captures the uncertainty over neural networks by augmenting\neach layer's inputs with latent variables. We present appropriate input\ndistributions and demonstrate state-of-the-art performance in terms of\ncalibration, robustness and uncertainty characterisation over large-scale,\nmulti-million parameter image classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:45:19 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Trinh", "Trung", ""], ["Kaski", "Samuel", ""], ["Heinonen", "Markus", ""]]}, {"id": "2010.13511", "submitter": "Yu-Sheng Li", "authors": "Bowen Yuan, Yu-Sheng Li, Pengrui Quan, Chih-Jen Lin", "title": "Efficient Optimization Methods for Extreme Similarity Learning with\n  Nonlinear Embeddings", "comments": "Published as a conference paper at KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467363", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning similarity by using nonlinear embedding\nmodels (e.g., neural networks) from all possible pairs. This problem is\nwell-known for its difficulty of training with the extreme number of pairs. For\nthe special case of using linear embeddings, many studies have addressed this\nissue of handling all pairs by considering certain loss functions and\ndeveloping efficient optimization algorithms. This paper aims to extend results\nfor general nonlinear embeddings. First, we finish detailed derivations and\nprovide clean formulations for efficiently calculating some building blocks of\noptimization algorithms such as function, gradient evaluation, and\nHessian-vector product. The result enables the use of many optimization methods\nfor extreme similarity learning with nonlinear embeddings. Second, we study\nsome optimization methods in detail. Due to the use of nonlinear embeddings,\nimplementation issues different from linear cases are addressed. In the end,\nsome methods are shown to be highly efficient for extreme similarity learning\nwith nonlinear embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 12:09:09 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 11:53:13 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yuan", "Bowen", ""], ["Li", "Yu-Sheng", ""], ["Quan", "Pengrui", ""], ["Lin", "Chih-Jen", ""]]}, {"id": "2010.13514", "submitter": "Juhan Bae", "authors": "Juhan Bae, Roger Grosse", "title": "Delta-STN: Efficient Bilevel Optimization for Neural Networks using\n  Structured Response Jacobians", "comments": "Published as a conference paper at Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization of neural networks can be elegantly formulated as\na bilevel optimization problem. While research on bilevel optimization of\nneural networks has been dominated by implicit differentiation and unrolling,\nhypernetworks such as Self-Tuning Networks (STNs) have recently gained traction\ndue to their ability to amortize the optimization of the inner objective. In\nthis paper, we diagnose several subtle pathologies in the training of STNs.\nBased on these observations, we propose the $\\Delta$-STN, an improved\nhypernetwork architecture which stabilizes training and optimizes\nhyperparameters much more efficiently than STNs. The key idea is to focus on\naccurately approximating the best-response Jacobian rather than the full\nbest-response function; we achieve this by reparameterizing the hypernetwork\nand linearizing the network around the current parameters. We demonstrate\nempirically that our $\\Delta$-STN can tune regularization hyperparameters (e.g.\nweight decay, dropout, number of cutout holes) with higher accuracy, faster\nconvergence, and improved stability compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 12:12:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bae", "Juhan", ""], ["Grosse", "Roger", ""]]}, {"id": "2010.13520", "submitter": "Di Wang", "authors": "Di Wang and Jiahao Ding and Lijie Hu and Zejun Xie and Miao Pan and\n  Jinhui Xu", "title": "Differentially Private (Gradient) Expectation Maximization Algorithm\n  with Statistical Guarantees", "comments": "Submiited. arXiv admin note: text overlap with arXiv:2010.09576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  (Gradient) Expectation Maximization (EM) is a widely used algorithm for\nestimating the maximum likelihood of mixture models or incomplete data\nproblems. A major challenge facing this popular technique is how to effectively\npreserve the privacy of sensitive data. Previous research on this problem has\nalready lead to the discovery of some Differentially Private (DP) algorithms\nfor (Gradient) EM. However, unlike in the non-private case, existing techniques\nare not yet able to provide finite sample statistical guarantees. To address\nthis issue, we propose in this paper the first DP version of (Gradient) EM\nalgorithm with statistical guarantees. Moreover, we apply our general framework\nto three canonical models: Gaussian Mixture Model (GMM), Mixture of Regressions\nModel (MRM) and Linear Regression with Missing Covariates (RMC). Specifically,\nfor GMM in the DP model, our estimation error is near optimal in some cases.\nFor the other two models, we provide the first finite sample statistical\nguarantees. Our theory is supported by thorough numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:41:19 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 17:33:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wang", "Di", ""], ["Ding", "Jiahao", ""], ["Hu", "Lijie", ""], ["Xie", "Zejun", ""], ["Pan", "Miao", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.13523", "submitter": "Yikun Zhang", "authors": "Yikun Zhang, Yen-Chi Chen", "title": "Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional\n  Data", "comments": "92 pages, 11 figures. Accepted to the Journal of Machine Learning\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Directional data consist of observations distributed on a (hyper)sphere, and\nappear in many applied fields, such as astronomy, ecology, and environmental\nscience. This paper studies both statistical and computational problems of\nkernel smoothing for directional data. We generalize the classical mean shift\nalgorithm to directional data, which allows us to identify local modes of the\ndirectional kernel density estimator (KDE). The statistical convergence rates\nof the directional KDE and its derivatives are derived, and the problem of mode\nestimation is examined. We also prove the ascending property of the directional\nmean shift algorithm and investigate a general problem of gradient ascent on\nthe unit hypersphere. To demonstrate the applicability of the algorithm, we\nevaluate it as a mode clustering method on both simulated and real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 01:53:47 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 08:38:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Yikun", ""], ["Chen", "Yen-Chi", ""]]}, {"id": "2010.13527", "submitter": "Markus Marks", "authors": "Benjamin Estermann, Markus Marks, Mehmet Fatih Yanik", "title": "Robust Disentanglement of a Few Factors at a Time", "comments": "The first two authors contributed equally. Code is available at this\n  url https://github.com/besterma/robust_disentanglement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentanglement is at the forefront of unsupervised learning, as disentangled\nrepresentations of data improve generalization, interpretability, and\nperformance in downstream tasks. Current unsupervised approaches remain\ninapplicable for real-world datasets since they are highly variable in their\nperformance and fail to reach levels of disentanglement of (semi-)supervised\napproaches. We introduce population-based training (PBT) for improving\nconsistency in training variational autoencoders (VAEs) and demonstrate the\nvalidity of this approach in a supervised setting (PBT-VAE). We then use\nUnsupervised Disentanglement Ranking (UDR) as an unsupervised heuristic to\nscore models in our PBT-VAE training and show how models trained this way tend\nto consistently disentangle only a subset of the generative factors. Building\non top of this observation we introduce the recursive rPU-VAE approach. We\ntrain the model until convergence, remove the learned factors from the dataset\nand reiterate. In doing so, we can label subsets of the dataset with the\nlearned factors and consecutively use these labels to train one model that\nfully disentangles the whole dataset. With this approach, we show striking\nimprovement in state-of-the-art unsupervised disentanglement performance and\nrobustness across multiple datasets and metrics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 12:34:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Estermann", "Benjamin", ""], ["Marks", "Markus", ""], ["Yanik", "Mehmet Fatih", ""]]}, {"id": "2010.13551", "submitter": "Graham Pulford", "authors": "Graham W. Pulford", "title": "From the Expectation Maximisation Algorithm to Autoencoded Variational\n  Bayes", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the expectation maximisation (EM) algorithm was introduced in 1970,\nit remains somewhat inaccessible to machine learning practitioners due to its\nobscure notation, terse proofs and lack of concrete links to modern machine\nlearning techniques like autoencoded variational Bayes. This has resulted in\ngaps in the AI literature concerning the meaning of such concepts like \"latent\nvariables\" and \"variational lower bound,\" which are frequently used but often\nnot clearly explained. The roots of these ideas lie in the EM algorithm. We\nfirst give a tutorial presentation of the EM algorithm for estimating the\nparameters of a $K$-component mixture density. The Gaussian mixture case is\npresented in detail using $K$-ary scalar hidden (or latent) variables rather\nthan the more traditional binary valued $K$-dimenional vectors. This\npresentation is motivated by mixture modelling from the target tracking\nliterature. In a similar style to Bishop's 2009 book, we present variational\nBayesian inference as a generalised EM algorithm stemming from the variational\n(or evidential) lower bound, as well as the technique of mean field\napproximation (or product density transform). We continue the evolution from EM\nto variational autoencoders, developed by Kingma & Welling in 2014. In so\ndoing, we establish clear links between the EM algorithm and its variational\ncounterparts, hence clarifying the meaning of \"latent variables.\" We provide a\ndetailed coverage of the \"reparametrisation trick\" and focus on how the AEVB\ndiffers from conventional variational Bayesian inference. Throughout the\ntutorial, consistent notational conventions are used. This unifies the\nnarrative and clarifies the concepts. Some numerical examples are given to\nfurther illustrate the algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:23:26 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 07:33:28 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Pulford", "Graham W.", ""]]}, {"id": "2010.13554", "submitter": "Masahiro Kato", "authors": "Masahiro Kato and Yusuke Kaneko", "title": "Off-Policy Evaluation of Bandit Algorithm from Dependent Samples under\n  Batch Update Policy", "comments": "arXiv admin note: text overlap with arXiv:2010.03792", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of off-policy evaluation (OPE) is to evaluate a new policy using\nhistorical data obtained via a behavior policy. However, because the contextual\nbandit algorithm updates the policy based on past observations, the samples are\nnot independent and identically distributed (i.i.d.). This paper tackles this\nproblem by constructing an estimator from a martingale difference sequence\n(MDS) for the dependent samples. In the data-generating process, we do not\nassume the convergence of the policy, but the policy uses the same conditional\nprobability of choosing an action during a certain period. Then, we derive an\nasymptotically normal estimator of the value of an evaluation policy. As\nanother advantage of our method, the batch-based approach simultaneously solves\nthe deficient support problem. Using benchmark and real-world datasets, we\nexperimentally confirm the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 15:22:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kato", "Masahiro", ""], ["Kaneko", "Yusuke", ""]]}, {"id": "2010.13568", "submitter": "Kejun He", "authors": "Ya Zhou, Raymond K. W. Wong and Kejun He", "title": "CP Degeneracy in Tensor Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor linear regression is an important and useful tool for analyzing tensor\ndata. To deal with high dimensionality, CANDECOMP/PARAFAC (CP) low-rank\nconstraints are often imposed on the coefficient tensor parameter in the\n(penalized) $M$-estimation. However, we show that the corresponding\noptimization may not be attainable, and when this happens, the estimator is not\nwell-defined. This is closely related to a phenomenon, called CP degeneracy, in\nlow-rank tensor approximation problems. In this article, we provide useful\nresults of CP degeneracy in tensor regression problems. In addition, we provide\na general penalized strategy as a solution to overcome CP degeneracy. The\nasymptotic properties of the resulting estimation are also studied. Numerical\nexperiments are conducted to illustrate our findings.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:08:44 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhou", "Ya", ""], ["Wong", "Raymond K. W.", ""], ["He", "Kejun", ""]]}, {"id": "2010.13581", "submitter": "Andrew Wilson", "authors": "Marc Finzi, Ke Alexander Wang, Andrew Gordon Wilson", "title": "Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit\n  Constraints", "comments": "NeurIPS 2020. Code available at\n  https://github.com/mfinzi/constrained-hamiltonian-neural-networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about the physical world requires models that are endowed with the\nright inductive biases to learn the underlying dynamics. Recent works improve\ngeneralization for predicting trajectories by learning the Hamiltonian or\nLagrangian of a system rather than the differential equations directly. While\nthese methods encode the constraints of the systems using generalized\ncoordinates, we show that embedding the system into Cartesian coordinates and\nenforcing the constraints explicitly with Lagrange multipliers dramatically\nsimplifies the learning problem. We introduce a series of challenging chaotic\nand extended-body systems, including systems with N-pendulums, spring coupling,\nmagnetic fields, rigid rotors, and gyroscopes, to push the limits of current\napproaches. Our experiments show that Cartesian coordinates with explicit\nconstraints lead to a 100x improvement in accuracy and data efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 13:35:16 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Finzi", "Marc", ""], ["Wang", "Ke Alexander", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2010.13632", "submitter": "Erik Bodin", "authors": "Erik Bodin, Zhenwen Dai, Neill D. F. Campbell, Carl Henrik Ek", "title": "Black-box density function estimation using recursive partitioning", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to Bayesian inference and general Bayesian\ncomputation that is defined through a sequential decision loop. Our method\ndefines a recursive partitioning of the sample space. It neither relies on\ngradients nor requires any problem-specific tuning, and is asymptotically exact\nfor any density function with a bounded domain. The output is an approximation\nto the whole density function including the normalisation constant, via\npartitions organised in efficient data structures. Such approximations may be\nused for evidence estimation or fast posterior sampling, but also as building\nblocks to treat a larger class of estimation problems. The algorithm shows\ncompetitive performance to recent state-of-the-art methods on synthetic and\nreal-world problems including parameter inference for gravitational-wave\nphysics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 14:47:32 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 21:34:37 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Bodin", "Erik", ""], ["Dai", "Zhenwen", ""], ["Campbell", "Neill D. F.", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "2010.13639", "submitter": "Cyril Zhang", "authors": "Naman Agarwal, Rohan Anil, Tomer Koren, Kunal Talwar, Cyril Zhang", "title": "Stochastic Optimization with Laggard Data Pipelines", "comments": "Published as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art optimization is steadily shifting towards massively parallel\npipelines with extremely large batch sizes. As a consequence, CPU-bound\npreprocessing and disk/memory/network operations have emerged as new\nperformance bottlenecks, as opposed to hardware-accelerated gradient\ncomputations. In this regime, a recently proposed approach is data echoing\n(Choi et al., 2019), which takes repeated gradient steps on the same batch\nwhile waiting for fresh data to arrive from upstream. We provide the first\nconvergence analyses of \"data-echoed\" extensions of common optimization\nmethods, showing that they exhibit provable improvements over their synchronous\ncounterparts. Specifically, we show that in convex optimization with stochastic\nminibatches, data echoing affords speedups on the curvature-dominated part of\nthe convergence rate, while maintaining the optimal statistical rate.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 14:55:31 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Agarwal", "Naman", ""], ["Anil", "Rohan", ""], ["Koren", "Tomer", ""], ["Talwar", "Kunal", ""], ["Zhang", "Cyril", ""]]}, {"id": "2010.13685", "submitter": "Veronica Chelu", "authors": "Veronica Chelu, Doina Precup, Hado van Hasselt", "title": "Forethought and Hindsight in Credit Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of credit assignment in reinforcement learning and\nexplore fundamental questions regarding the way in which an agent can best use\nadditional computation to propagate new information, by planning with internal\nmodels of the world to improve its predictions. Particularly, we work to\nunderstand the gains and peculiarities of planning employed as forethought via\nforward models or as hindsight operating with backward models. We establish the\nrelative merits, limitations and complementary properties of both planning\nmechanisms in carefully constructed scenarios. Further, we investigate the best\nuse of models in planning, primarily focusing on the selection of states in\nwhich predictions should be (re)-evaluated. Lastly, we discuss the issue of\nmodel estimation and highlight a spectrum of methods that stretch from explicit\nenvironment-dynamics predictors to more abstract planner-aware models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:00:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chelu", "Veronica", ""], ["Precup", "Doina", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2010.13734", "submitter": "Ernesto Araya Valdivia", "authors": "Ernesto Araya Valdivia", "title": "Random Geometric Graphs on Euclidean Balls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a latent space model for random graphs where a node $i$ is\nassociated to a random latent point $X_i$ on the Euclidean unit ball. The\nprobability that an edge exists between two nodes is determined by a ``link''\nfunction, which corresponds to a dot product kernel. For a given class $\\F$ of\nspherically symmetric distributions for $X_i$, we consider two estimation\nproblems: latent norm recovery and latent Gram matrix estimation. We construct\nan estimator for the latent norms based on the degree of the nodes of an\nobserved graph in the case of the model where the edge probability is given by\n$f(\\langle X_i,X_j\\rangle)=\\mathbbm{1}_{\\langle X_i,X_j\\rangle\\geq \\tau}$,\nwhere $0<\\tau<1$. We introduce an estimator for the Gram matrix based on the\neigenvectors of observed graph and we establish Frobenius type guarantee for\nthe error, provided that the link function is sufficiently regular in the\nSobolev sense and that a spectral-gap-type condition holds. We prove that for\ncertain link functions, the model considered here generates graphs with degree\ndistribution that have tails with a power-law-type distribution, which can be\nseen as an advantage of the model presented here with respect to the classic\nRandom Geometric Graph model on the Euclidean sphere. We illustrate our results\nwith numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:21:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Valdivia", "Ernesto Araya", ""]]}, {"id": "2010.13749", "submitter": "Gemma Anderson", "authors": "Gemma J. Anderson, Jim A. Gaffney, Brian K. Spears, Peer-Timo Bremer,\n  Rushil Anirudh and Jayaraman J. Thiagarajan", "title": "Meaningful uncertainties from deep neural network surrogates of\n  large-scale numerical simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale numerical simulations are used across many scientific disciplines\nto facilitate experimental development and provide insights into underlying\nphysical processes, but they come with a significant computational cost. Deep\nneural networks (DNNs) can serve as highly-accurate surrogate models, with the\ncapacity to handle diverse datatypes, offering tremendous speed-ups for\nprediction and many other downstream tasks. An important use-case for these\nsurrogates is the comparison between simulations and experiments; prediction\nuncertainty estimates are crucial for making such comparisons meaningful, yet\nstandard DNNs do not provide them. In this work we define the fundamental\nrequirements for a DNN to be useful for scientific applications, and\ndemonstrate a general variational inference approach to equip predictions of\nscalar and image data from a DNN surrogate model trained on inertial\nconfinement fusion simulations with calibrated Bayesian uncertainties.\nCritically, these uncertainties are interpretable, meaningful and preserve\nphysics-correlations in the predicted quantities.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:39:05 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Anderson", "Gemma J.", ""], ["Gaffney", "Jim A.", ""], ["Spears", "Brian K.", ""], ["Bremer", "Peer-Timo", ""], ["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""]]}, {"id": "2010.13764", "submitter": "Gintare Karolina Dziugaite", "authors": "Gintare Karolina Dziugaite, Shai Ben-David, Daniel M. Roy", "title": "Enforcing Interpretability and its Statistical Impacts: Trade-offs\n  between Accuracy and Interpretability", "comments": "12 pages; minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, there has been no formal study of the statistical cost of\ninterpretability in machine learning. As such, the discourse around potential\ntrade-offs is often informal and misconceptions abound. In this work, we aim to\ninitiate a formal study of these trade-offs. A seemingly insurmountable\nroadblock is the lack of any agreed upon definition of interpretability.\nInstead, we propose a shift in perspective. Rather than attempt to define\ninterpretability, we propose to model the \\emph{act} of \\emph{enforcing}\ninterpretability. As a starting point, we focus on the setting of empirical\nrisk minimization for binary classification, and view interpretability as a\nconstraint placed on learning. That is, we assume we are given a subset of\nhypothesis that are deemed to be interpretable, possibly depending on the data\ndistribution and other aspects of the context. We then model the act of\nenforcing interpretability as that of performing empirical risk minimization\nover the set of interpretable hypotheses. This model allows us to reason about\nthe statistical implications of enforcing interpretability, using known results\nin statistical learning theory. Focusing on accuracy, we perform a case\nanalysis, explaining why one may or may not observe a trade-off between\naccuracy and interpretability when the restriction to interpretable classifiers\ndoes or does not come at the cost of some excess statistical risk. We close\nwith some worked examples and some open problems, which we hope will spur\nfurther theoretical development around the tradeoffs involved in\ninterpretability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:52:34 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:34:32 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Dziugaite", "Gintare Karolina", ""], ["Ben-David", "Shai", ""], ["Roy", "Daniel M.", ""]]}, {"id": "2010.13833", "submitter": "Sebastiano Stramaglia", "authors": "Sebastiano Stramaglia, Tomas Scagliarini, Yuri Antonacci, Luca Faes", "title": "Local Granger Causality", "comments": "4 figures", "journal-ref": "Phys. Rev. E 103, 020102 (2021)", "doi": "10.1103/PhysRevE.103.L020102", "report-no": null, "categories": "q-bio.QM cond-mat.dis-nn physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality is a statistical notion of causal influence based on\nprediction via vector autoregression. For Gaussian variables it is equivalent\nto transfer entropy, an information-theoretic measure of time-directed\ninformation transfer between jointly dependent processes. We exploit such\nequivalence and calculate exactly the 'local Granger causality', i.e. the\nprofile of the information transfer at each discrete time point in Gaussian\nprocesses; in this frame Granger causality is the average of its local version.\nOur approach offers a robust and computationally fast method to follow the\ninformation transfer along the time history of linear stochastic processes, as\nwell as of nonlinear complex systems studied in the Gaussian approximation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 18:38:57 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Stramaglia", "Sebastiano", ""], ["Scagliarini", "Tomas", ""], ["Antonacci", "Yuri", ""], ["Faes", "Luca", ""]]}, {"id": "2010.13872", "submitter": "Kamil Adamczewski", "authors": "Kamil Adamczewski, Frederik Harder, Mijung Park", "title": "Q-FIT: The Quantifiable Feature Importance Technique for Explainable\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework to quantify the importance of each input\nfeature for model explainability. A user of our framework can choose between\ntwo modes: (a) global explanation: providing feature importance globally across\nall the data points; and (b) local explanation: providing feature importance\nlocally for each individual data point. The core idea of our method comes from\nutilizing the Dirichlet distribution to define a distribution over the\nimportance of input features. This particular distribution is useful in ranking\nthe importance of the input features as a sample from this distribution is a\nprobability vector (i.e., the vector components sum to 1), Thus, the ranking\nuncovered by our framework which provides a \\textit{quantifiable explanation}\nof how significant each input feature is to a model's output. This quantifiable\nexplainability differentiates our method from existing feature-selection\nmethods, which simply determine whether a feature is relevant or not.\nFurthermore, a distribution over the explanation allows to define a closed-form\ndivergence to measure the similarity between learned feature importance under\ndifferent models. We use this divergence to study how the feature importance\ntrade-offs with essential notions in modern machine learning, such as privacy\nand fairness. We show the effectiveness of our method on a variety of synthetic\nand real datasets, taking into account both tabular and image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:55:58 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Adamczewski", "Kamil", ""], ["Harder", "Frederik", ""], ["Park", "Mijung", ""]]}, {"id": "2010.13898", "submitter": "Jinghang Lin", "authors": "Jinghang Lin, Xiaoran Tong, Chenxi Li, Qing Lu", "title": "Expectile Neural Networks for Genetic Data Analysis of Complex Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The genetic etiologies of common diseases are highly complex and\nheterogeneous. Classic statistical methods, such as linear regression, have\nsuccessfully identified numerous genetic variants associated with complex\ndiseases. Nonetheless, for most complex diseases, the identified variants only\naccount for a small proportion of heritability. Challenges remain to discover\nadditional variants contributing to complex diseases. Expectile regression is a\ngeneralization of linear regression and provides completed information on the\nconditional distribution of a phenotype of interest. While expectile regression\nhas many nice properties and holds great promise for genetic data analyses\n(e.g., investigating genetic variants predisposing to a high-risk population),\nit has been rarely used in genetic research. In this paper, we develop an\nexpectile neural network (ENN) method for genetic data analyses of complex\ndiseases. Similar to expectile regression, ENN provides a comprehensive view of\nrelationships between genetic variants and disease phenotypes and can be used\nto discover genetic variants predisposing to sub-populations (e.g., high-risk\ngroups). We further integrate the idea of neural networks into ENN, making it\ncapable of capturing non-linear and non-additive genetic effects (e.g.,\ngene-gene interactions). Through simulations, we showed that the proposed\nmethod outperformed an existing expectile regression when there exist complex\nrelationships between genetic variants and disease phenotypes. We also applied\nthe proposed method to the genetic data from the Study of Addiction: Genetics\nand Environment(SAGE), investigating the relationships of candidate genes with\nsmoking quantity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 21:07:40 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lin", "Jinghang", ""], ["Tong", "Xiaoran", ""], ["Li", "Chenxi", ""], ["Lu", "Qing", ""]]}, {"id": "2010.13924", "submitter": "Aya Abdelsalam Ismail", "authors": "Aya Abdelsalam Ismail, Mohamed Gunady, H\\'ector Corrada Bravo, and\n  Soheil Feizi", "title": "Benchmarking Deep Learning Interpretability in Time Series Predictions", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods are used extensively to highlight the importance of input\nfeatures in model predictions. These methods are mostly used in vision and\nlanguage tasks, and their applications to time series data is relatively\nunexplored. In this paper, we set out to extensively compare the performance of\nvarious saliency-based interpretability methods across diverse neural\narchitectures, including Recurrent Neural Network, Temporal Convolutional\nNetworks, and Transformers in a new benchmark of synthetic time series data. We\npropose and report multiple metrics to empirically evaluate the performance of\nsaliency methods for detecting feature importance over time using both\nprecision (i.e., whether identified features contain meaningful signals) and\nrecall (i.e., the number of features with signal identified as important).\nThrough several experiments, we show that (i) in general, network architectures\nand saliency methods fail to reliably and accurately identify feature\nimportance over time in time series data, (ii) this failure is mainly due to\nthe conflation of time and feature domains, and (iii) the quality of saliency\nmaps can be improved substantially by using our proposed two-step temporal\nsaliency rescaling (TSR) approach that first calculates the importance of each\ntime step before calculating the importance of each feature at a time step.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 22:07:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ismail", "Aya Abdelsalam", ""], ["Gunady", "Mohamed", ""], ["Bravo", "H\u00e9ctor Corrada", ""], ["Feizi", "Soheil", ""]]}, {"id": "2010.13933", "submitter": "Jason W. Rocks", "authors": "Jason W. Rocks and Pankaj Mehta", "title": "Memorizing without overfitting: Bias, variance, and interpolation in\n  over-parameterized models", "comments": "24 pages (double column), 7 figures, 56 pages of supplemental\n  material (single column)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The bias-variance trade-off is a central concept in supervised learning. In\nclassical statistics, increasing the complexity of a model (e.g., number of\nparameters) reduces bias but also increases variance. Until recently, it was\ncommonly believed that optimal performance is achieved at intermediate model\ncomplexities which strike a balance between bias and variance. Modern Deep\nLearning methods flout this dogma, achieving state-of-the-art performance using\n\"over-parameterized models\" where the number of fit parameters is large enough\nto perfectly fit the training data. As a result, understanding bias and\nvariance in over-parameterized models has emerged as a fundamental problem in\nmachine learning. Here, we use methods from statistical physics to derive\nanalytic expressions for bias and variance in three minimal models for\nover-parameterization (linear regression and two-layer neural networks with\nlinear and nonlinear activation functions), allowing us to disentangle\nproperties stemming from the model architecture and random sampling of data.\nAll three models exhibit a phase transition to an interpolation regime where\nthe training error is zero. At the interpolation transition for each model, the\ntest error diverges due to diverging variance (while bias remains finite). In\ncontrast with classical intuition, we also show that over-parameterized models\ncan overfit even in the absence of noise and exhibit bias even if the student\nand teacher models match. We synthesize these results to construct a holistic\nunderstanding of generalization error and the bias-variance trade-off in\nover-parameterized models and relate our results to random matrix theory.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 22:31:04 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 16:38:03 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Rocks", "Jason W.", ""], ["Mehta", "Pankaj", ""]]}, {"id": "2010.13934", "submitter": "Yujie Zhao", "authors": "Yujie Zhao, Xiaoming Huo", "title": "A Homotopic Method to Solve the Lasso Problems with an Improved Upper\n  Bound of Convergence Rate", "comments": "40 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In optimization, it is known that when the objective functions are strictly\nconvex and well-conditioned, gradient based approaches can be extremely\neffective, e.g., achieving the exponential rate in convergence. On the other\nhand, the existing Lasso-type of estimator in general cannot achieve the\noptimal rate due to the undesirable behavior of the absolute function at the\norigin. A homotopic method is to use a sequence of surrogate functions to\napproximate the $\\ell_1$ penalty that is used in the Lasso-type of estimators.\nThe surrogate functions will converge to the $\\ell_1$ penalty in the Lasso\nestimator. At the same time, each surrogate function is strictly convex, which\nenables provable faster numerical rate of convergence. In this paper, we\ndemonstrate that by meticulously defining the surrogate functions, one can\nprove faster numerical convergence rate than any existing methods in computing\nfor the Lasso-type of estimators. Namely, the state-of-the-art algorithms can\nonly guarantee $O(1/\\epsilon)$ or $O(1/\\sqrt{\\epsilon})$ convergence rates,\nwhile we can prove an $O([\\log(1/\\epsilon)]^2)$ for the newly proposed\nalgorithm. Our numerical simulations show that the new algorithm also performs\nbetter empirically.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 22:37:49 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhao", "Yujie", ""], ["Huo", "Xiaoming", ""]]}, {"id": "2010.13953", "submitter": "Ziyu Xu", "authors": "Ziyu Xu, Aaditya Ramdas", "title": "Dynamic Algorithms for Online Multiple Testing", "comments": "32 pages, 15 figures. Will be published in Mathematical and\n  Scientific Machine Learning 2021 (PMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive new algorithms for online multiple testing that provably control\nfalse discovery exceedance (FDX) while achieving orders of magnitude more power\nthan previous methods. This statistical advance is enabled by the development\nof new algorithmic ideas: earlier algorithms are more \"static\" while our new\nones allow for the dynamical adjustment of testing levels based on the amount\nof wealth the algorithm has accumulated. We demonstrate that our algorithms\nachieve higher power in a variety of synthetic experiments. We also prove that\nSupLORD can provide error control for both FDR and FDX, and controls FDR at\nstopping times. Stopping times are particularly important as they permit the\nexperimenter to end the experiment arbitrarily early while maintaining desired\ncontrol of the FDR. SupLORD is the first non-trivial algorithm, to our\nknowledge, that can control FDR at stopping times in the online setting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 23:41:54 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 22:25:47 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 15:43:59 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xu", "Ziyu", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2010.13997", "submitter": "Sudeep Salgia", "authors": "Sudeep Salgia, Sattar Vakili, Qing Zhao", "title": "A Computationally Efficient Approach to Black-box Optimization using\n  Gaussian Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sequential optimization of an unknown function under Gaussian\nprocess models. We develop a computationally efficient algorithm that reduces\nthe complexity of the prevailing GP-UCB family of algorithms by a factor of\n$O(T^{2d-1})$ (where $T$ is the time horizon and $d$ the dimension of the\nfunction domain). The algorithm is also shown to have order-optimal regret\nperformance (up to a poly-logarithmic factor). The basic structure of the\nproposed algorithm is a tree-based \\emph{localized} search strategy guided by a\nlocalized optimization procedure for finding function values exceeding an\niteratively updated threshold. More specifically, the global optimum is\napproached through a sequence of localized searches in the domain of the\nfunction guided by an iterative search in the range of the function.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 02:15:15 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 22:37:31 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Salgia", "Sudeep", ""], ["Vakili", "Sattar", ""], ["Zhao", "Qing", ""]]}, {"id": "2010.14019", "submitter": "Matias Valdenegro-Toro", "authors": "Akshatha Kamath and Dwaraknath Gnaneshwar and Matias Valdenegro-Toro", "title": "Know Where To Drop Your Weights: Towards Faster Uncertainty Estimation", "comments": "8 pages, 6 figures, 1 table, with appendix, submitted to a NeurIPS\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating epistemic uncertainty of models used in low-latency applications\nand Out-Of-Distribution samples detection is a challenge due to the\ncomputationally demanding nature of uncertainty estimation techniques.\nEstimating model uncertainty using approximation techniques like Monte Carlo\nDropout (MCD), DropConnect (MCDC) requires a large number of forward passes\nthrough the network, rendering them inapt for low-latency applications. We\npropose Select-DC which uses a subset of layers in a neural network to model\nepistemic uncertainty with MCDC. Through our experiments, we show a significant\nreduction in the GFLOPS required to model uncertainty, compared to Monte Carlo\nDropConnect, with marginal trade-off in performance. We perform a suite of\nexperiments on CIFAR 10, CIFAR 100, and SVHN datasets with ResNet and VGG\nmodels. We further show how applying DropConnect to various layers in the\nnetwork with different drop probabilities affects the networks performance and\nthe entropy of the predictive distribution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 02:56:27 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kamath", "Akshatha", ""], ["Gnaneshwar", "Dwaraknath", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "2010.14023", "submitter": "Seng Pei Liew", "authors": "Seng Pei Liew and Tsubasa Takahashi", "title": "FaceLeaks: Inference Attacks against Transfer Learning Models via\n  Black-box Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a useful machine learning framework that allows one to\nbuild task-specific models (student models) without significantly incurring\ntraining costs using a single powerful model (teacher model) pre-trained with a\nlarge amount of data. The teacher model may contain private data, or interact\nwith private inputs. We investigate if one can leak or infer such private\ninformation without interacting with the teacher model directly. We describe\nsuch inference attacks in the context of face recognition, an application of\ntransfer learning that is highly sensitive to personal privacy.\n  Under black-box and realistic settings, we show that existing inference\ntechniques are ineffective, as interacting with individual training instances\nthrough the student models does not reveal information about the teacher. We\nthen propose novel strategies to infer from aggregate-level information.\nConsequently, membership inference attacks on the teacher model are shown to be\npossible, even when the adversary has access only to the student models.\n  We further demonstrate that sensitive attributes can be inferred, even in the\ncase where the adversary has limited auxiliary information. Finally, defensive\nstrategies are discussed and evaluated. Our extensive study indicates that\ninformation leakage is a real privacy threat to the transfer learning framework\nwidely used in real-life situations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 03:02:40 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liew", "Seng Pei", ""], ["Takahashi", "Tsubasa", ""]]}, {"id": "2010.14056", "submitter": "Sean Plummer", "authors": "Sean Plummer, Shuang Zhou, Anirban Bhattacharya, David Dunson, Debdeep\n  Pati", "title": "Statistical Guarantees for Transformation Based Models with Applications\n  to Implicit Variational Inference", "comments": "First two authors contributed equally to this work. arXiv admin note:\n  text overlap with arXiv:1701.07572", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformation-based methods have been an attractive approach in\nnon-parametric inference for problems such as unconditional and conditional\ndensity estimation due to their unique hierarchical structure that models the\ndata as flexible transformation of a set of common latent variables. More\nrecently, transformation-based models have been used in variational inference\n(VI) to construct flexible implicit families of variational distributions.\nHowever, their use in both non-parametric inference and variational inference\nlacks theoretical justification. We provide theoretical justification for the\nuse of non-linear latent variable models (NL-LVMs) in non-parametric inference\nby showing that the support of the transformation induced prior in the space of\ndensities is sufficiently large in the $L_1$ sense. We also show that, when a\nGaussian process (GP) prior is placed on the transformation function, the\nposterior concentrates at the optimal rate up to a logarithmic factor. Adopting\nthe flexibility demonstrated in the non-parametric setting, we use the NL-LVM\nto construct an implicit family of variational distributions, deemed GP-IVI. We\ndelineate sufficient conditions under which GP-IVI achieves optimal risk bounds\nand approximates the true posterior in the sense of the Kullback-Leibler\ndivergence. To the best of our knowledge, this is the first work on providing\ntheoretical guarantees for implicit variational inference.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 21:06:29 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 20:02:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Plummer", "Sean", ""], ["Zhou", "Shuang", ""], ["Bhattacharya", "Anirban", ""], ["Dunson", "David", ""], ["Pati", "Debdeep", ""]]}, {"id": "2010.14075", "submitter": "Shijun Zhang", "authors": "Zuowei Shen and Haizhao Yang and Shijun Zhang", "title": "Neural Network Approximation: Three Hidden Layers Are Enough", "comments": null, "journal-ref": "Neural Networks, Volume 141, September 2021, Pages 160-173", "doi": "10.1016/j.neunet.2021.04.011", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A three-hidden-layer neural network with super approximation power is\nintroduced. This network is built with the floor function ($\\lfloor x\\rfloor$),\nthe exponential function ($2^x$), the step function ($1_{x\\geq 0}$), or their\ncompositions as the activation function in each neuron and hence we call such\nnetworks as Floor-Exponential-Step (FLES) networks. For any width\nhyper-parameter $N\\in\\mathbb{N}^+$, it is shown that FLES networks with width\n$\\max\\{d,N\\}$ and three hidden layers can uniformly approximate a H\\\"older\ncontinuous function $f$ on $[0,1]^d$ with an exponential approximation rate\n$3\\lambda (2\\sqrt{d})^{\\alpha} 2^{-\\alpha N}$, where $\\alpha \\in(0,1]$ and\n$\\lambda>0$ are the H\\\"older order and constant, respectively. More generally\nfor an arbitrary continuous function $f$ on $[0,1]^d$ with a modulus of\ncontinuity $\\omega_f(\\cdot)$, the constructive approximation rate is\n$2\\omega_f(2\\sqrt{d}){2^{-N}}+\\omega_f(2\\sqrt{d}\\,2^{-N})$. Moreover, we extend\nsuch a result to general bounded continuous functions on a bounded set\n$E\\subseteq\\mathbb{R}^d$. As a consequence, this new class of networks\novercomes the curse of dimensionality in approximation power when the variation\nof $\\omega_f(r)$ as $r\\rightarrow 0$ is moderate (e.g., $\\omega_f(r)\\lesssim\nr^\\alpha$ for H\\\"older continuous functions), since the major term to be\nconcerned in our approximation rate is essentially $\\sqrt{d}$ times a function\nof $N$ independent of $d$ within the modulus of continuity. Finally, we extend\nour analysis to derive similar approximation results in the $L^p$-norm for\n$p\\in[1,\\infty)$ via replacing Floor-Exponential-Step activation functions by\ncontinuous activation functions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 18:30:57 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 10:55:29 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 18:18:38 GMT"}, {"version": "v4", "created": "Mon, 19 Apr 2021 16:53:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Shen", "Zuowei", ""], ["Yang", "Haizhao", ""], ["Zhang", "Shijun", ""]]}, {"id": "2010.14134", "submitter": "Erik Jones", "authors": "Erik Jones, Shiori Sagawa, Pang Wei Koh, Ananya Kumar, Percy Liang", "title": "Selective Classification Can Magnify Disparities Across Groups", "comments": "Published at the International Conference on Learning Representations\n  (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective classification, in which models can abstain on uncertain\npredictions, is a natural approach to improving accuracy in settings where\nerrors are costly but abstentions are manageable. In this paper, we find that\nwhile selective classification can improve average accuracies, it can\nsimultaneously magnify existing accuracy disparities between various groups\nwithin a population, especially in the presence of spurious correlations. We\nobserve this behavior consistently across five vision and NLP datasets.\nSurprisingly, increasing abstentions can even decrease accuracies on some\ngroups. To better understand this phenomenon, we study the margin distribution,\nwhich captures the model's confidences over all predictions. For symmetric\nmargin distributions, we prove that whether selective classification\nmonotonically improves or worsens accuracy is fully determined by the accuracy\nat full coverage (i.e., without any abstentions) and whether the distribution\nsatisfies a property we call left-log-concavity. Our analysis also shows that\nselective classification tends to magnify full-coverage accuracy disparities.\nMotivated by our analysis, we train distributionally-robust models that achieve\nsimilar full-coverage accuracies across groups and show that selective\nclassification uniformly improves each group on these models. Altogether, our\nresults suggest that selective classification should be used with care and\nunderscore the importance of training models to perform equally well across\ngroups at full coverage.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 08:51:30 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 08:11:52 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 15:56:59 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Jones", "Erik", ""], ["Sagawa", "Shiori", ""], ["Koh", "Pang Wei", ""], ["Kumar", "Ananya", ""], ["Liang", "Percy", ""]]}, {"id": "2010.14167", "submitter": "Frederic Loge", "authors": "Fr\\'ed\\'eric Log\\'e (CMAP), R\\'emi Besson (CRC), St\\'ephanie\n  Allassonni\\`ere (CRC)", "title": "Optimisation des parcours patients pour lutter contre l'errance de\n  diagnostic des patients atteints de maladies rares", "comments": "in French. Journ{\\'e}es de Statistiques de la SFDS, May 2020, Nice,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A patient suffering from a rare disease in France has to wait an average of\ntwo years before being diagnosed. This medical wandering is highly detrimental\nboth for the health system and for patients whose pathology may worsen. There\nexists an efficient network of Centres of Reference for Rare Diseases (CRMR),\nbut patients are often referred to these structures too late. We are\nconsidering a probabilistic modelling of the patient pathway in order to create\na simulator that will allow us to create an alert system that detects wandering\npatients and refers them to a CRMR while considering the potential additional\ncosts associated with these decisions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 09:55:46 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Log\u00e9", "Fr\u00e9d\u00e9ric", "", "CMAP"], ["Besson", "R\u00e9mi", "", "CRC"], ["Allassonni\u00e8re", "St\u00e9phanie", "", "CRC"]]}, {"id": "2010.14171", "submitter": "Xavier Favory", "authors": "Xavier Favory, Konstantinos Drossos, Tuomas Virtanen, Xavier Serra", "title": "Learning Contextual Tag Embeddings for Cross-Modal Alignment of Audio\n  and Tags", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Self-supervised audio representation learning offers an attractive\nalternative for obtaining generic audio embeddings, capable to be employed into\nvarious downstream tasks. Published approaches that consider both audio and\nwords/tags associated with audio do not employ text processing models that are\ncapable to generalize to tags unknown during training. In this work we propose\na method for learning audio representations using an audio autoencoder (AAE), a\ngeneral word embeddings model (WEM), and a multi-head self-attention (MHA)\nmechanism. MHA attends on the output of the WEM, providing a contextualized\nrepresentation of the tags associated with the audio, and we align the output\nof MHA with the output of the encoder of AAE using a contrastive loss. We\njointly optimize AAE and MHA and we evaluate the audio representations (i.e.\nthe output of the encoder of AAE) by utilizing them in three different\ndownstream tasks, namely sound, music genre, and music instrument\nclassification. Our results show that employing multi-head self-attention with\nmultiple heads in the tag-based network can induce better learned audio\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 10:13:17 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Favory", "Xavier", ""], ["Drossos", "Konstantinos", ""], ["Virtanen", "Tuomas", ""], ["Serra", "Xavier", ""]]}, {"id": "2010.14258", "submitter": "Christian H\\\"ager", "authors": "Christian H\\\"ager and Henry D. Pfister", "title": "Physics-Based Deep Learning for Fiber-Optic Communication Systems", "comments": "15 pages, 11 figures, submitted to IEEE J. Sel. Areas Commun., code\n  available at https://github.com/chaeger/LDBP, extension of\n  arXiv:1710.06234(1), arXiv:1804.02799(1), arXiv:1901.07592(2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new machine-learning approach for fiber-optic communication\nsystems whose signal propagation is governed by the nonlinear Schr\\\"odinger\nequation (NLSE). Our main observation is that the popular split-step method\n(SSM) for numerically solving the NLSE has essentially the same functional form\nas a deep multi-layer neural network; in both cases, one alternates linear\nsteps and pointwise nonlinearities. We exploit this connection by\nparameterizing the SSM and viewing the linear steps as general linear\nfunctions, similar to the weight matrices in a neural network. The resulting\nphysics-based machine-learning model has several advantages over \"black-box\"\nfunction approximators. For example, it allows us to examine and interpret the\nlearned solutions in order to understand why they perform well. As an\napplication, low-complexity nonlinear equalization is considered, where the\ntask is to efficiently invert the NLSE. This is commonly referred to as digital\nbackpropagation (DBP). Rather than employing neural networks, the proposed\nalgorithm, dubbed learned DBP (LDBP), uses the physics-based model with\ntrainable filters in each step and its complexity is reduced by progressively\npruning filter taps during gradient descent. Our main finding is that the\nfilters can be pruned to remarkably short lengths-as few as 3 taps/step-without\nsacrificing performance. As a result, the complexity can be reduced by orders\nof magnitude in comparison to prior work. By inspecting the filter responses,\nan additional theoretical justification for the learned parameter\nconfigurations is provided. Our work illustrates that combining data-driven\noptimization with existing domain knowledge can generate new insights into old\ncommunications problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 12:55:23 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "2010.14260", "submitter": "Ekhine Irurozki", "authors": "Collas Fabien and Irurozki Ekhine", "title": "Concentric mixtures of Mallows models for top-$k$ rankings: sampling and\n  identifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider mixtures of two Mallows models for top-$k$\nrankings, both with the same location parameter but with different scale\nparameters, i.e., a mixture of concentric Mallows models. This situation arises\nwhen we have a heterogeneous population of voters formed by two homogeneous\npopulations, one of which is a subpopulation of expert voters while the other\nincludes the non-expert voters. We propose efficient sampling algorithms for\nMallows top-$k$ rankings. We show the identifiability of both components, and\nthe learnability of their respective parameters in this setting by, first,\nbounding the sample complexity for the Borda algorithm with top-$k$ rankings\nand second, proposing polynomial time algorithm for the separation of the\nrankings in each component. Finally, since the rank aggregation will suffer\nfrom a large amount of noise introduced by the non-expert voters, we adapt the\nBorda algorithm to be able to recover the ground truth consensus ranking which\nis especially consistent with the expert rankings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:00:37 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 10:59:28 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Fabien", "Collas", ""], ["Ekhine", "Irurozki", ""]]}, {"id": "2010.14265", "submitter": "Alexander Marx", "authors": "Alexander Marx, Arthur Gretton, Joris M. Mooij", "title": "A Weaker Faithfulness Assumption based on Triple Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core assumptions in causal discovery is the faithfulness\nassumption---i.e. assuming that independencies found in the data are due to\nseparations in the true causal graph. This assumption can, however, be violated\nin many ways, including xor connections, deterministic functions or cancelling\npaths. In this work, we propose a weaker assumption that we call 2-adjacency\nfaithfulness. In contrast to adjacency faithfulness, which assumes that there\nis no conditional independence between each pair of variables that are\nconnected in the causal graph, we only require no conditional independence\nbetween a node and a subset of its Markov blanket that can contain up to two\nnodes. Equivalently, we adapt orientation faithfulness to this setting. We\nfurther propose a sound orientation rule for causal discovery that applies\nunder weaker assumptions. As a proof of concept, we derive a modified Grow and\nShrink algorithm that recovers the Markov blanket of a target node and prove\nits correctness under strictly weaker assumptions than the standard\nfaithfulness assumption.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:04:08 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Marx", "Alexander", ""], ["Gretton", "Arthur", ""], ["Mooij", "Joris M.", ""]]}, {"id": "2010.14298", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Yu Gai, Zhewei Yao, Michael W. Mahoney, Joseph E.\n  Gonzalez", "title": "A Statistical Framework for Low-bitwidth Training of Deep Neural\n  Networks", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully quantized training (FQT), which uses low-bitwidth hardware by\nquantizing the activations, weights, and gradients of a neural network model,\nis a promising approach to accelerate the training of deep neural networks. One\nmajor challenge with FQT is the lack of theoretical understanding, in\nparticular of how gradient quantization impacts convergence properties. In this\npaper, we address this problem by presenting a statistical framework for\nanalyzing FQT algorithms. We view the quantized gradient of FQT as a stochastic\nestimator of its full precision counterpart, a procedure known as\nquantization-aware training (QAT). We show that the FQT gradient is an unbiased\nestimator of the QAT gradient, and we discuss the impact of gradient\nquantization on its variance. Inspired by these theoretical results, we develop\ntwo novel gradient quantizers, and we show that these have smaller variance\nthan the existing per-tensor quantizer. For training ResNet-50 on ImageNet, our\n5-bit block Householder quantizer achieves only 0.5% validation accuracy loss\nrelative to QAT, comparable to the existing INT8 baseline.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 13:57:33 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Chen", "Jianfei", ""], ["Gai", "Yu", ""], ["Yao", "Zhewei", ""], ["Mahoney", "Michael W.", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2010.14323", "submitter": "Emilie Kaufmann", "authors": "Dorian Baudry (CNRS, CRIStAL, SEQUEL), Emilie Kaufmann (CNRS, CRIStAL,\n  SEQUEL), Odalric-Ambrym Maillard (SEQUEL)", "title": "Sub-sampling for Efficient Non-Parametric Bandit Exploration", "comments": "NeurIPS 2020, Dec 2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the first multi-armed bandit algorithm based on\nre-sampling that achieves asymptotically optimal regret simultaneously for\ndifferent families of arms (namely Bernoulli, Gaussian and Poisson\ndistributions). Unlike Thompson Sampling which requires to specify a different\nprior to be optimal in each case, our proposal RB-SDA does not need any\ndistribution-dependent tuning. RB-SDA belongs to the family of Sub-sampling\nDuelling Algorithms (SDA) which combines the sub-sampling idea first used by\nthe BESA [1] and SSMC [2] algorithms with different sub-sampling schemes. In\nparticular, RB-SDA uses Random Block sampling. We perform an experimental study\nassessing the flexibility and robustness of this promising novel approach for\nexploration in bandit models.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:31:55 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Baudry", "Dorian", "", "CNRS, CRIStAL, SEQUEL"], ["Kaufmann", "Emilie", "", "CNRS, CRIStAL,\n  SEQUEL"], ["Maillard", "Odalric-Ambrym", "", "SEQUEL"]]}, {"id": "2010.14324", "submitter": "Christian Soize", "authors": "Christian Soize and Roger Ghanem", "title": "Probabilistic learning on manifolds constrained by nonlinear partial\n  differential equations for small datasets", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2021.113777", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel extension of the Probabilistic Learning on Manifolds (PLoM) is\npresented. It makes it possible to synthesize solutions to a wide range of\nnonlinear stochastic boundary value problems described by partial differential\nequations (PDEs) for which a stochastic computational model (SCM) is available\nand depends on a vector-valued random control parameter. The cost of a single\nnumerical evaluation of this SCM is assumed to be such that only a limited\nnumber of points can be computed for constructing the training dataset (small\ndata). Each point of the training dataset is made up realizations from a\nvector-valued stochastic process (the stochastic solution) and the associated\nrandom control parameter on which it depends. The presented PLoM constrained by\nPDE allows for generating a large number of learned realizations of the\nstochastic process and its corresponding random control parameter. These\nlearned realizations are generated so as to minimize the vector-valued random\nresidual of the PDE in the mean-square sense. Appropriate novel methods are\ndeveloped to solve this challenging problem. Three applications are presented.\nThe first one is a simple uncertain nonlinear dynamical system with a\nnonstationary stochastic excitation. The second one concerns the 2D nonlinear\nunsteady Navier-Stokes equations for incompressible flows in which the Reynolds\nnumber is the random control parameter. The last one deals with the nonlinear\ndynamics of a 3D elastic structure with uncertainties. The results obtained\nmake it possible to validate the PLoM constrained by stochastic PDE but also\nprovide further validation of the PLoM without constraint.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:34:54 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Soize", "Christian", ""], ["Ghanem", "Roger", ""]]}, {"id": "2010.14407", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Frederik Tr\\\"auble, Francesco Locatello, Manuel\n  W\\\"uthrich, Vaibhav Agrawal, Ole Winther, Stefan Bauer, Bernhard Sch\\\"olkopf", "title": "On the Transfer of Disentangled Representations in Realistic Settings", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful representations that disentangle the underlying structure\nof the data generating process is considered to be of key importance in machine\nlearning. While disentangled representations were found to be useful for\ndiverse tasks such as abstract reasoning and fair classification, their\nscalability and real-world impact remain questionable. We introduce a new\nhigh-resolution dataset with 1M simulated images and over 1,800 annotated\nreal-world images of the same setup. In contrast to previous work, this new\ndataset exhibits correlations, a complex underlying structure, and allows to\nevaluate transfer to unseen simulated and real-world settings where the encoder\ni) remains in distribution or ii) is out of distribution. We propose new\narchitectures in order to scale disentangled representation learning to\nrealistic high-resolution settings and conduct a large-scale empirical study of\ndisentangled representations on this dataset. We observe that disentanglement\nis a good predictor for out-of-distribution (OOD) task performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 16:15:24 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 11:43:10 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Dittadi", "Andrea", ""], ["Tr\u00e4uble", "Frederik", ""], ["Locatello", "Francesco", ""], ["W\u00fcthrich", "Manuel", ""], ["Agrawal", "Vaibhav", ""], ["Winther", "Ole", ""], ["Bauer", "Stefan", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2010.14449", "submitter": "Dennis Shen", "authors": "Anish Agarwal, Devavrat Shah, Dennis Shen", "title": "On Principal Component Regression in a High-Dimensional\n  Error-in-Variables Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the classical method of principal component regression (PCR) in a\nhigh-dimensional error-in-variables setting. Here, the observed covariates are\nnot only noisy and contain missing values, but the number of covariates can\nalso exceed the sample size. Under suitable conditions, we establish that PCR\nidentifies the unique linear model parameter with minimum $\\ell_2$-norm, and\nderive non-asymptotic $\\ell_2$-rates of convergence that show its consistency.\nFurthermore, we develop an algorithm for out-of-sample predictions in the\npresence of corrupted data that uses PCR as a key subroutine, and provide its\nnon-asymptotic prediction performance guarantees. Notably, our results do not\nrequire the out-of-samples covariates to follow the same distribution as that\nof the in-sample covariates, but rather that they obey a simple linear\nalgebraic constraint. We provide simulations that illustrate our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:07:36 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 17:50:20 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 23:12:13 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Agarwal", "Anish", ""], ["Shah", "Devavrat", ""], ["Shen", "Dennis", ""]]}, {"id": "2010.14495", "submitter": "Guy Gur-Ari", "authors": "Anna Golubeva, Behnam Neyshabur, Guy Gur-Ari", "title": "Are wider nets better given the same number of parameters?", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical studies demonstrate that the performance of neural networks\nimproves with increasing number of parameters. In most of these studies, the\nnumber of parameters is increased by increasing the network width. This begs\nthe question: Is the observed improvement due to the larger number of\nparameters, or is it due to the larger width itself? We compare different ways\nof increasing model width while keeping the number of parameters constant. We\nshow that for models initialized with a random, static sparsity pattern in the\nweight tensors, network width is the determining factor for good performance,\nwhile the number of weights is secondary, as long as trainability is ensured.\nAs a step towards understanding this effect, we analyze these models in the\nframework of Gaussian Process kernels. We find that the distance between the\nsparse finite-width model kernel and the infinite-width kernel at\ninitialization is indicative of model performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:53:49 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 23:51:44 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Golubeva", "Anna", ""], ["Neyshabur", "Behnam", ""], ["Gur-Ari", "Guy", ""]]}, {"id": "2010.14497", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Aviral Kumar, Nicholas Rhinehart, Sergey Levine,\n  Florian Shkurti, Animesh Garg", "title": "Conservative Safety Critics for Exploration", "comments": "Published as a conference paper in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe exploration presents a major challenge in reinforcement learning (RL):\nwhen active data collection requires deploying partially trained policies, we\nmust ensure that these policies avoid catastrophically unsafe regions, while\nstill enabling trial and error learning. In this paper, we target the problem\nof safe exploration in RL by learning a conservative safety estimate of\nenvironment states through a critic, and provably upper bound the likelihood of\ncatastrophic failures at every training iteration. We theoretically\ncharacterize the tradeoff between safety and policy improvement, show that the\nsafety constraints are likely to be satisfied with high probability during\ntraining, derive provable convergence guarantees for our approach, which is no\nworse asymptotically than standard RL, and demonstrate the efficacy of the\nproposed approach on a suite of challenging navigation, manipulation, and\nlocomotion tasks. Empirically, we show that the proposed approach can achieve\ncompetitive task performance while incurring significantly lower catastrophic\nfailure rates during training than prior methods. Videos are at this url\nhttps://sites.google.com/view/conservative-safety-critics/home\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:54:25 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:38:23 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Kumar", "Aviral", ""], ["Rhinehart", "Nicholas", ""], ["Levine", "Sergey", ""], ["Shkurti", "Florian", ""], ["Garg", "Animesh", ""]]}, {"id": "2010.14498", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Rishabh Agarwal, Dibya Ghosh, Sergey Levine", "title": "Implicit Under-Parameterization Inhibits Data-Efficient Deep\n  Reinforcement Learning", "comments": "Pre-print. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify an implicit under-parameterization phenomenon in value-based deep\nRL methods that use bootstrapping: when value functions, approximated using\ndeep neural networks, are trained with gradient descent using iterated\nregression onto target values generated by previous instances of the value\nnetwork, more gradient updates decrease the expressivity of the current value\nnetwork. We characterize this loss of expressivity in terms of a drop in the\nrank of the learned value network features, and show that this corresponds to a\ndrop in performance. We demonstrate this phenomenon on widely studies domains,\nincluding Atari and Gym benchmarks, in both offline and online RL settings. We\nformally analyze this phenomenon and show that it results from a pathological\ninteraction between bootstrapping and gradient-based optimization. We further\nshow that mitigating implicit under-parameterization by controlling rank\ncollapse improves performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:55:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kumar", "Aviral", ""], ["Agarwal", "Rishabh", ""], ["Ghosh", "Dibya", ""], ["Levine", "Sergey", ""]]}, {"id": "2010.14563", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha, Tomer Koren, Yishay Mansour", "title": "Adversarial Dueling Bandits", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of regret minimization in Adversarial Dueling\nBandits. As in classic Dueling Bandits, the learner has to repeatedly choose a\npair of items and observe only a relative binary `win-loss' feedback for this\npair, but here this feedback is generated from an arbitrary preference matrix,\npossibly chosen adversarially. Our main result is an algorithm whose $T$-round\nregret compared to the \\emph{Borda-winner} from a set of $K$ items is\n$\\tilde{O}(K^{1/3}T^{2/3})$, as well as a matching $\\Omega(K^{1/3}T^{2/3})$\nlower bound. We also prove a similar high probability regret bound. We further\nconsider a simpler \\emph{fixed-gap} adversarial setup, which bridges between\ntwo extreme preference feedback models for dueling bandits: stationary\npreferences and an arbitrary sequence of preferences. For the fixed-gap\nadversarial setup we give an $\\smash{ \\tilde{O}((K/\\Delta^2)\\log{T}) }$ regret\nalgorithm, where $\\Delta$ is the gap in Borda scores between the best item and\nall other items, and show a lower bound of $\\Omega(K/\\Delta^2)$ indicating that\nour dependence on the main problem parameters $K$ and $\\Delta$ is tight (up to\nlogarithmic factors).\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 19:09:08 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Saha", "Aadirupa", ""], ["Koren", "Tomer", ""], ["Mansour", "Yishay", ""]]}, {"id": "2010.14592", "submitter": "Jiaxuan Wang", "authors": "Jiaxuan Wang, Jenna Wiens, Scott Lundberg", "title": "Shapley Flow: A Graph-based Approach to Interpreting Model Predictions", "comments": "camera ready version for AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing approaches for estimating feature importance are problematic\nbecause they ignore or hide dependencies among features. A causal graph, which\nencodes the relationships among input variables, can aid in assigning feature\nimportance. However, current approaches that assign credit to nodes in the\ncausal graph fail to explain the entire graph. In light of these limitations,\nwe propose Shapley Flow, a novel approach to interpreting machine learning\nmodels. It considers the entire causal graph, and assigns credit to\n\\textit{edges} instead of treating nodes as the fundamental unit of credit\nassignment. Shapley Flow is the unique solution to a generalization of the\nShapley value axioms to directed acyclic graphs. We demonstrate the benefit of\nusing Shapley Flow to reason about the impact of a model's input on its output.\nIn addition to maintaining insights from existing approaches, Shapley Flow\nextends the flat, set-based, view prevalent in game theory based explanation\nmethods to a deeper, \\textit{graph-based}, view. This graph-based view enables\nusers to understand the flow of importance through a system, and reason about\npotential interventions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 20:21:00 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 16:29:36 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 15:49:29 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wang", "Jiaxuan", ""], ["Wiens", "Jenna", ""], ["Lundberg", "Scott", ""]]}, {"id": "2010.14610", "submitter": "Baoxiang Pan", "authors": "Baoxiang Pan, Gemma J. Anderson, AndrE Goncalves, Donald D. Lucas,\n  CEline J.W. Bonfils, Jiwoo Lee", "title": "Improving seasonal forecast using probabilistic deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The path toward realizing the potential of seasonal forecasting and its\nsocioeconomic benefits depends heavily on improving general circulation model\nbased dynamical forecasting systems. To improve dynamical seasonal forecast, it\nis crucial to set up forecast benchmarks, and clarify forecast limitations\nposed by model initialization errors, formulation deficiencies, and internal\nclimate variability. With huge cost in generating large forecast ensembles, and\nlimited observations for forecast verification, the seasonal forecast\nbenchmarking and diagnosing task proves challenging. In this study, we develop\na probabilistic deep neural network model, drawing on a wealth of existing\nclimate simulations to enhance seasonal forecast capability and forecast\ndiagnosis. By leveraging complex physical relationships encoded in climate\nsimulations, our probabilistic forecast model demonstrates favorable\ndeterministic and probabilistic skill compared to state-of-the-art dynamical\nforecast systems in quasi-global seasonal forecast of precipitation and\nnear-surface temperature. We apply this probabilistic forecast methodology to\nquantify the impacts of initialization errors and model formulation\ndeficiencies in a dynamical seasonal forecasting system. We introduce the\nsaliency analysis approach to efficiently identify the key predictors that\ninfluence seasonal variability. Furthermore, by explicitly modeling uncertainty\nusing variational Bayes, we give a more definitive answer to how the El\nNino/Southern Oscillation, the dominant mode of seasonal variability, modulates\nglobal seasonal predictability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 21:02:26 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Pan", "Baoxiang", ""], ["Anderson", "Gemma J.", ""], ["Goncalves", "AndrE", ""], ["Lucas", "Donald D.", ""], ["Bonfils", "CEline J. W.", ""], ["Lee", "Jiwoo", ""]]}, {"id": "2010.14615", "submitter": "Juan-Pablo Ortega", "authors": "Christa Cuchiero, Lukas Gonon, Lyudmila Grigoryeva, Juan-Pablo Ortega,\n  and Josef Teichmann", "title": "Discrete-time signatures and randomness in reservoir computing", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new explanation of geometric nature of the reservoir computing phenomenon\nis presented. Reservoir computing is understood in the literature as the\npossibility of approximating input/output systems with randomly chosen\nrecurrent neural systems and a trained linear readout layer. Light is shed on\nthis phenomenon by constructing what is called strongly universal reservoir\nsystems as random projections of a family of state-space systems that generate\nVolterra series expansions. This procedure yields a state-affine reservoir\nsystem with randomly generated coefficients in a dimension that is\nlogarithmically reduced with respect to the original system. This reservoir\nsystem is able to approximate any element in the fading memory filters class\njust by training a different linear readout for each different filter. Explicit\nexpressions for the probability distributions needed in the generation of the\nprojected reservoir system are stated and bounds for the committed\napproximation error are provided.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 10:55:59 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Cuchiero", "Christa", ""], ["Gonon", "Lukas", ""], ["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""], ["Teichmann", "Josef", ""]]}, {"id": "2010.14618", "submitter": "David Powers", "authors": "David M W Powers", "title": "A computationally and cognitively plausible model of supervised and\n  unsupervised learning", "comments": "12 pages, 2 figures, 24 references. Amended version of paper\n  presented at BICS 2013", "journal-ref": "International Conference on Brain Inspired Cognitive Systems 2013,\n  pp. 145-156", "doi": null, "report-no": null, "categories": "cs.NE cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both empirical and mathematical demonstrations of the importance of\nchance-corrected measures are discussed, and a new model of learning is\nproposed based on empirical psychological results on association learning. Two\nforms of this model are developed, the Informatron as a chance-corrected\nPerceptron, and AdaBook as a chance-corrected AdaBoost procedure. Computational\nresults presented show chance correction facilitates learning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 00:31:27 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Powers", "David M W", ""]]}, {"id": "2010.14657", "submitter": "Rui Liu", "authors": "Rui Liu and Alex Olshevsky", "title": "Temporal Difference Learning as Gradient Splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference learning with linear function approximation is a popular\nmethod to obtain a low-dimensional approximation of the value function of a\npolicy in a Markov Decision Process. We give a new interpretation of this\nmethod in terms of a splitting of the gradient of an appropriately chosen\nfunction. As a consequence of this interpretation, convergence proofs for\ngradient descent can be applied almost verbatim to temporal difference\nlearning. Beyond giving a new, fuller explanation of why temporal difference\nworks, our interpretation also yields improved convergence times. We consider\nthe setting with $1/\\sqrt{T}$ step-size, where previous comparable finite-time\nconvergence time bounds for temporal difference learning had the multiplicative\nfactor $1/(1-\\gamma)$ in front of the bound, with $\\gamma$ being the discount\nfactor. We show that a minor variation on TD learning which estimates the mean\nof the value function separately has a convergence time where $1/(1-\\gamma)$\nonly multiplies an asymptotically negligible term.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:50:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Liu", "Rui", ""], ["Olshevsky", "Alex", ""]]}, {"id": "2010.14670", "submitter": "Han Shao", "authors": "Avrim Blum, Han Shao", "title": "Online Learning with Primary and Secondary Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online learning with primary and secondary losses.\nFor example, a recruiter making decisions of which job applicants to hire might\nweigh false positives and false negatives equally (the primary loss) but the\napplicants might weigh false negatives much higher (the secondary loss). We\nconsider the following question: Can we combine \"expert advice\" to achieve low\nregret with respect to the primary loss, while at the same time performing {\\em\nnot much worse than the worst expert} with respect to the secondary loss?\nUnfortunately, we show that this goal is unachievable without any bounded\nvariance assumption on the secondary loss. More generally, we consider the goal\nof minimizing the regret with respect to the primary loss and bounding the\nsecondary loss by a linear threshold. On the positive side, we show that\nrunning any switching-limited algorithm can achieve this goal if all experts\nsatisfy the assumption that the secondary loss does not exceed the linear\nthreshold by $o(T)$ for any time interval. If not all experts satisfy this\nassumption, our algorithms can achieve this goal given access to some external\noracles which determine when to deactivate and reactivate experts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 23:50:27 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Blum", "Avrim", ""], ["Shao", "Han", ""]]}, {"id": "2010.14672", "submitter": "Liam Collins", "authors": "Liam Collins, Aryan Mokhtari, Sanjay Shakkottai", "title": "How Does the Task Landscape Affect MAML Performance?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-Agnostic Meta-Learning (MAML) has become increasingly popular for\ntraining models that can quickly adapt to new tasks via one or few stochastic\ngradient descent steps. However, the MAML objective is significantly more\ndifficult to optimize compared to standard Empirical Risk Minimization (ERM),\nand little is understood about how much MAML improves over ERM in terms of the\nfast adaptability of their solutions in various scenarios. We analytically\naddress this issue in a linear regression setting consisting of a mixture of\neasy and hard tasks, where hardness is related to the condition number of the\ntask's loss function. Specifically, we prove that in order for MAML to achieve\nsubstantial gain over ERM, (i) there must be some discrepancy in hardness among\nthe tasks, and (ii) the optimal solutions of the hard tasks must be closely\npacked with the center far from the center of the easy tasks optimal solutions.\nWe also give numerical and analytical results suggesting that these insights\nalso apply to two-layer neural networks. Finally, we provide few-shot image\nclassification experiments that support our insights for when MAML should be\nused and emphasize the importance of training MAML on hard tasks in practice.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 23:54:44 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 23:25:22 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 20:49:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Collins", "Liam", ""], ["Mokhtari", "Aryan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2010.14680", "submitter": "Arash Tavakoli", "authors": "Arash Tavakoli, Mehdi Fatemi, Petar Kormushev", "title": "Learning to Represent Action Values as a Hypergraph on the Action\n  Vertices", "comments": "ICLR 2021, code:\n  https://github.com/atavakol/action-hypergraph-networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action-value estimation is a critical component of many reinforcement\nlearning (RL) methods whereby sample complexity relies heavily on how fast a\ngood estimator for action value can be learned. By viewing this problem through\nthe lens of representation learning, good representations of both state and\naction can facilitate action-value estimation. While advances in deep learning\nhave seamlessly driven progress in learning state representations, given the\nspecificity of the notion of agency to RL, little attention has been paid to\nlearning action representations. We conjecture that leveraging the\ncombinatorial structure of multi-dimensional action spaces is a key ingredient\nfor learning good representations of action. To test this, we set forth the\naction hypergraph networks framework -- a class of functions for learning\naction representations in multi-dimensional discrete action spaces with a\nstructural inductive bias. Using this framework we realise an agent class based\non a combination with deep Q-networks, which we dub hypergraph Q-networks. We\nshow the effectiveness of our approach on a myriad of domains: illustrative\nprediction problems under minimal confounding effects, Atari 2600 games, and\ndiscretised physical control benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 00:19:13 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 15:14:12 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Tavakoli", "Arash", ""], ["Fatemi", "Mehdi", ""], ["Kormushev", "Petar", ""]]}, {"id": "2010.14689", "submitter": "Erik Daxberger", "authors": "Erik Daxberger, Eric Nalisnick, James Urquhart Allingham, Javier\n  Antor\\'an, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Bayesian Deep Learning via Subnetwork Inference", "comments": "21 pages, extended version with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian paradigm has the potential to solve core issues of deep neural\nnetworks such as poor calibration and data inefficiency. Alas, scaling Bayesian\ninference to large weight spaces often requires restrictive approximations. In\nthis work, we show that it suffices to perform inference over a small subset of\nmodel weights in order to obtain accurate predictive posteriors. The other\nweights are kept as point estimates. This subnetwork inference framework\nenables us to use expressive, otherwise intractable, posterior approximations\nover such subsets. In particular, we implement subnetwork linearized Laplace:\nWe first obtain a MAP estimate of all weights and then infer a full-covariance\nGaussian posterior over a subnetwork. We propose a subnetwork selection\nstrategy that aims to maximally preserve the model's predictive uncertainty.\nEmpirically, our approach is effective compared to ensembles and less\nexpressive posterior approximations over full networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 01:10:11 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 09:20:51 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Daxberger", "Erik", ""], ["Nalisnick", "Eric", ""], ["Allingham", "James Urquhart", ""], ["Antor\u00e1n", "Javier", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2010.14694", "submitter": "Max Farrell", "authors": "Max H. Farrell and Tengyuan Liang and Sanjog Misra", "title": "Deep Learning for Individual Heterogeneity: An Automatic Inference\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop methodology for estimation and inference using machine learning to\nenrich economic models. Our framework takes a standard economic model and\nrecasts the parameters as fully flexible nonparametric functions, to capture\nthe rich heterogeneity based on potentially high dimensional or complex\nobservable characteristics. These \"parameter functions\" retain the\ninterpretability, economic meaning, and discipline of classical parameters.\nDeep learning is particularly well-suited to structured modeling of\nheterogeneity in economics. We show how to design the network architecture to\nmatch the structure of the economic model, delivering novel methodology that\nmoves deep learning beyond prediction. We prove convergence rates for the\nestimated parameter functions. These functions are the key inputs into the\nfinite-dimensional parameter of inferential interest. We obtain inference based\non a novel influence function calculation that covers any second-stage\nparameter and any machine-learning-enriched model that uses a smooth\nper-observation loss function. No additional derivations are required. The\nscore can be taken directly to data, using automatic differentiation if needed.\nThe researcher need only define the original model and define the parameter of\ninterest. A key insight is that we need not write down the influence function\nin order to evaluate it on the data. Our framework gives new results for a host\nof contexts, covering such diverse examples as price elasticities,\nwillingness-to-pay, and surplus measures in binary or multinomial choice\nmodels, effects of continuous treatment variables, fractional outcome models,\ncount data, heterogeneous production functions, and more. We apply our\nmethodology to a large scale advertising experiment for short-term loans. We\nshow how economically meaningful estimates and inferences can be made that\nwould be unavailable without our results.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 01:41:47 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 19:34:50 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Farrell", "Max H.", ""], ["Liang", "Tengyuan", ""], ["Misra", "Sanjog", ""]]}, {"id": "2010.14700", "submitter": "Da Xu", "authors": "Da Xu", "title": "Sparse Symmetric Tensor Regression for Functional Connectivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor regression models, such as CP regression and Tucker regression, have\nmany successful applications in neuroimaging analysis where the covariates are\nof ultrahigh dimensionality and possess complex spatial structures. The\nhigh-dimensional covariate arrays, also known as tensors, can be approximated\nby low-rank structures and fit into the generalized linear models. The\nresulting tensor regression achieves a significant reduction in dimensionality\nwhile remaining efficient in estimation and prediction. Brain functional\nconnectivity is an essential measure of brain activity and has shown\nsignificant association with neurological disorders such as Alzheimer's\ndisease. The symmetry nature of functional connectivity is a property that has\nnot been explored in previous tensor regression models. In this work, we\npropose a sparse symmetric tensor regression that further reduces the number of\nfree parameters and achieves superior performance over symmetrized and ordinary\nCP regression, under a variety of simulation settings. We apply the proposed\nmethod to a study of Alzheimer's disease (AD) and normal ageing from the\nBerkeley Aging Cohort Study (BACS) and detect two regions of interest that have\nbeen identified important to AD.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 02:07:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Xu", "Da", ""]]}, {"id": "2010.14706", "submitter": "Mohammad Farazmand", "authors": "Bryan Chu and Mohammad Farazmand", "title": "Data-driven prediction of multistable systems from sparse measurements", "comments": null, "journal-ref": null, "doi": "10.1063/5.0046203", "report-no": null, "categories": "math.DS math.OC nlin.PS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We develop a data-driven method, based on semi-supervised classification, to\npredict the asymptotic state of multistable systems when only sparse spatial\nmeasurements of the system are feasible. Our method predicts the asymptotic\nbehavior of an observed state by quantifying its proximity to the states in a\nprecomputed library of data. To quantify this proximity, we introduce a\nsparsity-promoting metric-learning (SPML) optimization, which learns a metric\ndirectly from the precomputed data. The optimization problem is designed so\nthat the resulting optimal metric satisfies two important properties: (i) It is\ncompatible with the precomputed library, and (ii) It is computable from sparse\nmeasurements. We prove that the proposed SPML optimization is convex, its\nminimizer is non-degenerate, and it is equivariant with respect to scaling of\nthe constraints. We demonstrate the application of this method on two\nmultistable systems: a reaction-diffusion equation, arising in pattern\nformation, which has four asymptotically stable steady states and a\nFitzHugh-Nagumo model with two asymptotically stable steady states.\nClassifications of the multistable reaction-diffusion equation based on SPML\npredict the asymptotic behavior of initial conditions based on two-point\nmeasurements with 95% accuracy when moderate number of labeled data are used.\nFor the FitzHugh-Nagumo, SPML predicts the asymptotic behavior of initial\nconditions from one-point measurements with 90% accuracy. The learned optimal\nmetric also determines where the measurements need to be made to ensure\naccurate predictions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 02:23:05 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 01:15:33 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Chu", "Bryan", ""], ["Farazmand", "Mohammad", ""]]}, {"id": "2010.14763", "submitter": "Nhuong Nguyen", "authors": "Marten van Dijk, Nhuong V. Nguyen, Toan N. Nguyen, Lam M. Nguyen, Quoc\n  Tran-Dinh and Phuong Ha Nguyen", "title": "Hogwild! over Distributed Local Data Sets with Linearly Increasing\n  Mini-Batch Sizes", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.09208\n  AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hogwild! implements asynchronous Stochastic Gradient Descent (SGD) where\nmultiple threads in parallel access a common repository containing training\ndata, perform SGD iterations and update shared state that represents a jointly\nlearned (global) model. We consider big data analysis where training data is\ndistributed among local data sets in a heterogeneous way -- and we wish to move\nSGD computations to local compute nodes where local data resides. The results\nof these local SGD computations are aggregated by a central \"aggregator\" which\nmimics Hogwild!. We show how local compute nodes can start choosing small\nmini-batch sizes which increase to larger ones in order to reduce communication\ncost (round interaction with the aggregator). We improve state-of-the-art\nliterature and show $O(\\sqrt{K}$) communication rounds for heterogeneous data\nfor strongly convex problems, where $K$ is the total number of gradient\ncomputations across all local compute nodes. For our scheme, we prove a\n\\textit{tight} and novel non-trivial convergence analysis for strongly convex\nproblems for {\\em heterogeneous} data which does not use the bounded gradient\nassumption as seen in many existing publications. The tightness is a\nconsequence of our proofs for lower and upper bounds of the convergence rate,\nwhich show a constant factor difference. We show experimental results for plain\nconvex and non-convex problems for biased (i.e., heterogeneous) and unbiased\nlocal data sets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 03:46:09 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 03:53:19 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["van Dijk", "Marten", ""], ["Nguyen", "Nhuong V.", ""], ["Nguyen", "Toan N.", ""], ["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""], ["Nguyen", "Phuong Ha", ""]]}, {"id": "2010.14765", "submitter": "Yaodong Yu", "authors": "Kwan Ho Ryan Chan, Yaodong Yu, Chong You, Haozhi Qi, John Wright, Yi\n  Ma", "title": "Deep Networks from the Principle of Rate Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work attempts to interpret modern deep (convolutional) networks from the\nprinciples of rate reduction and (shift) invariant classification. We show that\nthe basic iterative gradient ascent scheme for optimizing the rate reduction of\nlearned features naturally leads to a multi-layer deep network, one iteration\nper layer. The layered architectures, linear and nonlinear operators, and even\nparameters of the network are all explicitly constructed layer-by-layer in a\nforward propagation fashion by emulating the gradient scheme. All components of\nthis \"white box\" network have precise optimization, statistical, and geometric\ninterpretation. This principled framework also reveals and justifies the role\nof multi-channel lifting and sparse coding in early stage of deep networks.\nMoreover, all linear operators of the so-derived network naturally become\nmulti-channel convolutions when we enforce classification to be rigorously\nshift-invariant. The derivation also indicates that such a convolutional\nnetwork is significantly more efficient to construct and learn in the spectral\ndomain. Our preliminary simulations and experiments indicate that so\nconstructed deep network can already learn a good discriminative representation\neven without any back propagation training.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 06:01:43 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chan", "Kwan Ho Ryan", ""], ["Yu", "Yaodong", ""], ["You", "Chong", ""], ["Qi", "Haozhi", ""], ["Wright", "John", ""], ["Ma", "Yi", ""]]}, {"id": "2010.14766", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "A Sober Look at the Unsupervised Learning of Disentangled\n  Representations and their Evaluation", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.12359", "journal-ref": "Journal of Machine Learning Research 2020, Volume 21, Number 209", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea behind the \\emph{unsupervised} learning of \\emph{disentangled}\nrepresentations is that real-world data is generated by a few explanatory\nfactors of variation which can be recovered by unsupervised learning\nalgorithms. In this paper, we provide a sober look at recent progress in the\nfield and challenge some common assumptions. We first theoretically show that\nthe unsupervised learning of disentangled representations is fundamentally\nimpossible without inductive biases on both the models and the data. Then, we\ntrain over $14000$ models covering most prominent methods and evaluation\nmetrics in a reproducible large-scale experimental study on eight data sets. We\nobserve that while the different methods successfully enforce properties\n\"encouraged\" by the corresponding losses, well-disentangled models seemingly\ncannot be identified without supervision. Furthermore, different evaluation\nmetrics do not always agree on what should be considered \"disentangled\" and\nexhibit systematic differences in the estimation. Finally, increased\ndisentanglement does not seem to necessarily lead to a decreased sample\ncomplexity of learning for downstream tasks. Our results suggest that future\nwork on disentanglement learning should be explicit about the role of inductive\nbiases and (implicit) supervision, investigate concrete benefits of enforcing\ndisentanglement of the learned representations, and consider a reproducible\nexperimental setup covering several data sets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 10:17:15 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Locatello", "Francesco", ""], ["Bauer", "Stefan", ""], ["Lucic", "Mario", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "2010.14831", "submitter": "Stan Z Li", "authors": "Stan Z. Li, Zelin Zang, Lirong Wu", "title": "Deep Manifold Transformation for Nonlinear Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning-based encoders have been playing important roles in\nnonlinear dimensionality reduction (NLDR) for data exploration. However,\nexisting methods can often fail to preserve geometric, topological and/or\ndistributional structures of data. In this paper, we propose a deep manifold\nlearning framework, called deep manifold transformation (DMT) for unsupervised\nNLDR and embedding learning. DMT enhances deep neural networks by using\ncross-layer local geometry-preserving (LGP) constraints. The LGP constraints\nconstitute the loss for deep manifold learning and serve as geometric\nregularizers for NLDR network training. Extensive experiments on synthetic and\nreal-world data demonstrate that DMT networks outperform existing leading\nmanifold-based NLDR methods in terms of preserving the structures of data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 09:09:41 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 09:26:44 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 15:24:11 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Stan Z.", ""], ["Zang", "Zelin", ""], ["Wu", "Lirong", ""]]}, {"id": "2010.14860", "submitter": "Dennis Forster", "authors": "J\\\"org L\\\"ucke, Dennis Forster, Zhenwen Dai", "title": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum\n  of Three Entropies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central objective function of a variational autoencoder (VAE) is its\nvariational lower bound. Here we show that for standard VAEs the variational\nbound converges to a value given by the sum of three entropies: the (negative)\nentropy of the latent distribution, the expected (negative) entropy of the\nobservable distribution, and the average entropy of the variational\ndistributions. Our derived analytical results are exact and apply for small as\nwell as complex neural networks for decoder and encoder. Furthermore, they\napply for finitely and infinitely many data points and at any stationary point\n(including local and global maxima). As a consequence, we show that the\nvariance parameters of encoder and decoder play the key role in determining the\nvalues of variational bounds at stationary points. Furthermore, the obtained\nresults can allow for closed-form analytical expressions at points of\nconvergence, which may be unexpected as neither variational lower bounds of\nVAEs nor log-likelihoods of VAEs are closed-form during learning. As our main\ncontribution, we provide the proofs for convergence of standard VAEs to sums of\nentropies. Furthermore, we numerically verify our analytical results and\ndiscuss some potential applications. The obtained equality to entropy sums\nprovides novel information on those points in parameter space that variational\nlearning converges to. As such, we believe, they can contribute to our\nunderstanding of established as well as novel VAE approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 10:13:28 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 19:33:01 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 17:38:52 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["L\u00fccke", "J\u00f6rg", ""], ["Forster", "Dennis", ""], ["Dai", "Zhenwen", ""]]}, {"id": "2010.14864", "submitter": "Constantinos Daskalakis", "authors": "Constantinos Daskalakis and Qinxuan Pan", "title": "Sample-Optimal and Efficient Learning of Tree Ising models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that $n$-variable tree-structured Ising models can be learned\ncomputationally-efficiently to within total variation distance $\\epsilon$ from\nan optimal $O(n \\ln n/\\epsilon^2)$ samples, where $O(\\cdot)$ hides an absolute\nconstant which, importantly, does not depend on the model being learned -\nneither its tree nor the magnitude of its edge strengths, on which we place no\nassumptions. Our guarantees hold, in fact, for the celebrated Chow-Liu [1968]\nalgorithm, using the plug-in estimator for estimating mutual information. While\nthis (or any other) algorithm may fail to identify the structure of the\nunderlying model correctly from a finite sample, we show that it will still\nlearn a tree-structured model that is $\\epsilon$-close to the true one in total\nvariation distance, a guarantee called \"proper learning.\"\n  Our guarantees do not follow from known results for the Chow-Liu algorithm\nand the ensuing literature on learning graphical models, including a recent\nrenaissance of algorithms on this learning challenge, which only yield\nasymptotic consistency results, or sample-inefficient and/or time-inefficient\nalgorithms, unless further assumptions are placed on the graphical model, such\nas bounds on the \"strengths\" of the model's edges/hyperedges. While we\nestablish guarantees for a widely known and simple algorithm, the analysis that\nthis algorithm succeeds and is sample-optimal is quite complex, requiring a\nhierarchical classification of the edges into layers with different\nreconstruction guarantees, depending on their strength, combined with delicate\nuses of the subadditivity of the squared Hellinger distance over graphical\nmodels to control the error accumulation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 10:17:48 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 22:50:21 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Pan", "Qinxuan", ""]]}, {"id": "2010.14872", "submitter": "Kristian Miok", "authors": "Kristian Miok, Gregor Pirs and Marko Robnik-Sikonja", "title": "Bayesian Methods for Semi-supervised Text Annotation", "comments": "Accepted for COLING 2020, The 14th Linguistic Annotation Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human annotations are an important source of information in the development\nof natural language understanding approaches. As under the pressure of\nproductivity annotators can assign different labels to a given text, the\nquality of produced annotations frequently varies. This is especially the case\nif decisions are difficult, with high cognitive load, requires awareness of\nbroader context, or careful consideration of background knowledge. To alleviate\nthe problem, we propose two semi-supervised methods to guide the annotation\nprocess: a Bayesian deep learning model and a Bayesian ensemble method. Using a\nBayesian deep learning method, we can discover annotations that cannot be\ntrusted and might require reannotation. A recently proposed Bayesian ensemble\nmethod helps us to combine the annotators' labels with predictions of trained\nmodels. According to the results obtained from three hate speech detection\nexperiments, the proposed Bayesian methods can improve the annotations and\nprediction performance of BERT models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 10:42:04 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Miok", "Kristian", ""], ["Pirs", "Gregor", ""], ["Robnik-Sikonja", "Marko", ""]]}, {"id": "2010.14877", "submitter": "Sebastian Gabriel Popescu", "authors": "Sebastian Popescu, David Sharp, James Cole and Ben Glocker", "title": "Hierarchical Gaussian Processes with Wasserstein-2 Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the usefulness of Wasserstein-2 kernels in the context of\nhierarchical Gaussian Processes. Stemming from an observation that stacking\nGaussian Processes severely diminishes the model's ability to detect outliers,\nwhich when combined with non-zero mean functions, further extrapolates low\nvariance to regions with low training data density, we posit that directly\ntaking into account the variance in the computation of Wasserstein-2 kernels is\nof key importance towards maintaining outlier status as we progress through the\nhierarchy. We propose two new models operating in Wasserstein space which can\nbe seen as equivalents to Deep Kernel Learning and Deep GPs. Through extensive\nexperiments, we show improved performance on large scale datasets and improved\nout-of-distribution detection on both toy and real data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 10:55:26 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Popescu", "Sebastian", ""], ["Sharp", "David", ""], ["Cole", "James", ""], ["Glocker", "Ben", ""]]}, {"id": "2010.14927", "submitter": "Amit Daniely", "authors": "Amit Daniely and Hadas Schacham", "title": "Most ReLU Networks Suffer from $\\ell^2$ Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider ReLU networks with random weights, in which the dimension\ndecreases at each layer. We show that for most such networks, most examples $x$\nadmit an adversarial perturbation at an Euclidean distance of\n$O\\left(\\frac{\\|x\\|}{\\sqrt{d}}\\right)$, where $d$ is the input dimension.\nMoreover, this perturbation can be found via gradient flow, as well as gradient\ndescent with sufficiently small steps. This result can be seen as an\nexplanation to the abundance of adversarial examples, and to the fact that they\nare found via gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 12:42:22 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Daniely", "Amit", ""], ["Schacham", "Hadas", ""]]}, {"id": "2010.14928", "submitter": "Antoine Brochard", "authors": "Antoine Brochard, Bart{\\l}omiej B{\\l}aszczyszyn, St\\'ephane Mallat,\n  Sixin Zhang", "title": "Particle gradient descent model for point process generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a generative model for planar point processes in a\nsquare window, built upon a single realization of a stationary, ergodic point\nprocess observed in this window. Inspired by recent advances in gradient\ndescent methods for maximum entropy models, we propose a method to generate\nsimilar point patterns by jointly moving particles of an initial Poisson\nconfiguration towards a target counting measure. The target measure is\ngenerated via a deterministic gradient descent algorithm, so as to match a set\nof statistics of the given, observed realization. Our statistics are estimators\nof the multi-scale wavelet phase harmonic covariance, recently proposed in\nimage modeling. They allow one to capture geometric structures through\nmulti-scale interactions between wavelet coefficients. Both our statistics and\nthe gradient descent algorithm scale better with the number of observed points\nthan the classical k-nearest neighbour distances previously used in generative\nmodels for point processes, based on the rejection sampling or\nsimulated-annealing. The overall quality of our model is evaluated on point\nprocesses with various geometric structures through spectral and topological\ndata analysis.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 10:15:36 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 15:04:09 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Brochard", "Antoine", ""], ["B\u0142aszczyszyn", "Bart\u0142omiej", ""], ["Mallat", "St\u00e9phane", ""], ["Zhang", "Sixin", ""]]}, {"id": "2010.14942", "submitter": "Michael Gastegger", "authors": "Michael Gastegger, Kristof T. Sch\\\"utt, Klaus-Robert M\\\"uller", "title": "Machine learning of solvent effects on molecular spectra and reactions", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and accurate simulation of complex chemical systems in environments such\nas solutions is a long standing challenge in theoretical chemistry. In recent\nyears, machine learning has extended the boundaries of quantum chemistry by\nproviding highly accurate and efficient surrogate models of electronic\nstructure theory, which previously have been out of reach for conventional\napproaches. Those models have long been restricted to closed molecular systems\nwithout accounting for environmental influences, such as external electric and\nmagnetic fields or solvent effects. Here, we introduce the deep neural network\nFieldSchNet for modeling the interaction of molecules with arbitrary external\nfields. FieldSchNet offers access to a wealth of molecular response properties,\nenabling it to simulate a wide range of molecular spectra, such as infrared,\nRaman and nuclear magnetic resonance. Beyond that, it is able to describe\nimplicit and explicit molecular environments, operating as a polarizable\ncontinuum model for solvation or in a quantum mechanics / molecular mechanics\nsetup. We employ FieldSchNet to study the influence of solvent effects on\nmolecular spectra and a Claisen rearrangement reaction. Based on these results,\nwe use FieldSchNet to design an external environment capable of lowering the\nactivation barrier of the rearrangement reaction significantly, demonstrating\npromising venues for inverse chemical design.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 12:50:30 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 14:21:34 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Gastegger", "Michael", ""], ["Sch\u00fctt", "Kristof T.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2010.14986", "submitter": "Anna-Kathrin Kopetzki", "authors": "Anna-Kathrin Kopetzki, Bertrand Charpentier, Daniel Z\\\"ugner, Sandhya\n  Giri, Stephan G\\\"unnemann", "title": "Evaluating Robustness of Predictive Uncertainty Estimation: Are\n  Dirichlet-based Models Reliable?", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dirichlet-based uncertainty (DBU) models are a recent and promising class of\nuncertainty-aware models. DBU models predict the parameters of a Dirichlet\ndistribution to provide fast, high-quality uncertainty estimates alongside with\nclass predictions. In this work, we present the first large-scale, in-depth\nstudy of the robustness of DBU models under adversarial attacks. Our results\nsuggest that uncertainty estimates of DBU models are not robust w.r.t. three\nimportant tasks: (1) indicating correctly and wrongly classified samples; (2)\ndetecting adversarial examples; and (3) distinguishing between in-distribution\n(ID) and out-of-distribution (OOD) data. Additionally, we explore the first\napproaches to make DBU models more robust. While adversarial training has a\nminor effect, our median smoothing based approach significantly increases\nrobustness of DBU models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 13:53:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 09:32:11 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kopetzki", "Anna-Kathrin", ""], ["Charpentier", "Bertrand", ""], ["Z\u00fcgner", "Daniel", ""], ["Giri", "Sandhya", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2010.15010", "submitter": "Frederik Wenkel M.Sc.", "authors": "Yimeng Min, Frederik Wenkel, Guy Wolf", "title": "Geometric Scattering Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric scattering has recently gained recognition in graph representation\nlearning, and recent work has shown that integrating scattering features in\ngraph convolution networks (GCNs) can alleviate the typical oversmoothing of\nfeatures in node representation learning. However, scattering methods often\nrely on handcrafted design, requiring careful selection of frequency bands via\na cascade of wavelet transforms, as well as an effective weight sharing scheme\nto combine together low- and band-pass information. Here, we introduce a new\nattention-based architecture to produce adaptive task-driven node\nrepresentations by implicitly learning node-wise weights for combining multiple\nscattering and GCN channels in the network. We show the resulting geometric\nscattering attention network (GSAN) outperforms previous networks in\nsemi-supervised node classification, while also enabling a spectral study of\nextracted information by examining node-wise attention weights.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 14:36:40 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Min", "Yimeng", ""], ["Wenkel", "Frederik", ""], ["Wolf", "Guy", ""]]}, {"id": "2010.15011", "submitter": "Yuli Slavutsky", "authors": "Yuli Slavutsky, Yuval Benjamini", "title": "Predicting Classification Accuracy When Adding New Unobserved Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiclass classifiers are often designed and evaluated only on a sample from\nthe classes on which they will eventually be applied. Hence, their final\naccuracy remains unknown. In this work we study how a classifier's performance\nover the initial class sample can be used to extrapolate its expected accuracy\non a larger, unobserved set of classes. For this, we define a measure of\nseparation between correct and incorrect classes that is independent of the\nnumber of classes: the \"reversed ROC\" (rROC), which is obtained by replacing\nthe roles of classes and data-points in the common ROC. We show that the\nclassification accuracy is a function of the rROC in multiclass classifiers,\nfor which the learned representation of data from the initial class sample\nremains unchanged when new classes are added. Using these results we formulate\na robust neural-network-based algorithm, \"CleaneX\", which learns to estimate\nthe accuracy of such classifiers on arbitrarily large sets of classes. Unlike\nprevious methods, our method uses both the observed accuracies of the\nclassifier and densities of classification scores, and therefore achieves\nremarkably better predictions than current state-of-the-art methods on both\nsimulations and real datasets of object detection, face recognition, and brain\ndecoding.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 14:37:25 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 10:56:27 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 14:38:37 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Slavutsky", "Yuli", ""], ["Benjamini", "Yuval", ""]]}, {"id": "2010.15020", "submitter": "Yi Tian", "authors": "Yi Tian, Yuanhao Wang, Tiancheng Yu, Suvrit Sra", "title": "Online Learning in Unknown Markov Games", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning in unknown Markov games, a problem that arises in\nepisodic multi-agent reinforcement learning where the actions of the opponents\nare unobservable. We show that in this challenging setting, achieving sublinear\nregret against the best response in hindsight is statistically hard. We then\nconsider a weaker notion of regret by competing with the \\emph{minimax value}\nof the game, and present an algorithm that achieves a sublinear\n$\\tilde{\\mathcal{O}}(K^{2/3})$ regret after $K$ episodes. This is the first\nsublinear regret bound (to our knowledge) for online learning in unknown Markov\ngames. Importantly, our regret bound is independent of the size of the\nopponents' action spaces. As a result, even when the opponents' actions are\nfully observable, our regret bound improves upon existing analysis (e.g., (Xie\net al., 2020)) by an exponential factor in the number of opponents.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 14:52:15 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 05:24:25 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tian", "Yi", ""], ["Wang", "Yuanhao", ""], ["Yu", "Tiancheng", ""], ["Sra", "Suvrit", ""]]}, {"id": "2010.15031", "submitter": "Abhin Shah", "authors": "Abhin Shah, Devavrat Shah, Gregory W. Wornell", "title": "On Learning Continuous Pairwise Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning a sparse pairwise Markov Random Field (MRF) with\ncontinuous-valued variables from i.i.d samples. We adapt the algorithm of\nVuffray et al. (2019) to this setting and provide finite-sample analysis\nrevealing sample complexity scaling logarithmically with the number of\nvariables, as in the discrete and Gaussian settings. Our approach is applicable\nto a large class of pairwise MRFs with continuous variables and also has\ndesirable asymptotic properties, including consistency and normality under mild\nconditions. Further, we establish that the population version of the\noptimization criterion employed in Vuffray et al. (2019) can be interpreted as\nlocal maximum likelihood estimation (MLE). As part of our analysis, we\nintroduce a robust variation of sparse linear regression a` la Lasso, which may\nbe of interest in its own right.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 15:09:43 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Shah", "Abhin", ""], ["Shah", "Devavrat", ""], ["Wornell", "Gregory W.", ""]]}, {"id": "2010.15040", "submitter": "Chongli Qin", "authors": "Chongli Qin, Yan Wu, Jost Tobias Springenberg, Andrew Brock, Jeff\n  Donahue, Timothy P. Lillicrap, Pushmeet Kohli", "title": "Training Generative Adversarial Networks by Solving Ordinary\n  Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instability of Generative Adversarial Network (GAN) training has\nfrequently been attributed to gradient descent. Consequently, recent methods\nhave aimed to tailor the models and training procedures to stabilise the\ndiscrete updates. In contrast, we study the continuous-time dynamics induced by\nGAN training. Both theory and toy experiments suggest that these dynamics are\nin fact surprisingly stable. From this perspective, we hypothesise that\ninstabilities in training GANs arise from the integration error in discretising\nthe continuous dynamics. We experimentally verify that well-known ODE solvers\n(such as Runge-Kutta) can stabilise training - when combined with a regulariser\nthat controls the integration error. Our approach represents a radical\ndeparture from previous methods which typically use adaptive optimisation and\nstabilisation techniques that constrain the functional space (e.g. Spectral\nNormalisation). Evaluation on CIFAR-10 and ImageNet shows that our method\noutperforms several strong baselines, demonstrating its efficacy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 15:23:49 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 16:07:22 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Qin", "Chongli", ""], ["Wu", "Yan", ""], ["Springenberg", "Jost Tobias", ""], ["Brock", "Andrew", ""], ["Donahue", "Jeff", ""], ["Lillicrap", "Timothy P.", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "2010.15047", "submitter": "Samuel Rivera", "authors": "Samuel Rivera, Catherine A. Best, Hyungwook Yim, Dirk B. Walther,\n  Vladimir M. Sloutsky, Aleix M. Martinez", "title": "Automatic selection of eye tracking variables in visual categorization\n  in adults and infants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual categorization and learning of visual categories exhibit early onset,\nhowever the underlying mechanisms of early categorization are not well\nunderstood. The main limiting factor for examining these mechanisms is the\nlimited duration of infant cooperation (10-15 minutes), which leaves little\nroom for multiple test trials. With its tight link to visual attention, eye\ntracking is a promising method for getting access to the mechanisms of category\nlearning. But how should researchers decide which aspects of the rich eye\ntracking data to focus on? To date, eye tracking variables are generally\nhandpicked, which may lead to biases in the eye tracking data. Here, we propose\nan automated method for selecting eye tracking variables based on analyses of\ntheir usefulness to discriminate learners from non-learners of visual\ncategories. We presented infants and adults with a category learning task and\ntracked their eye movements. We then extracted an over-complete set of eye\ntracking variables encompassing durations, probabilities, latencies, and the\norder of fixations and saccadic eye movements. We compared three statistical\ntechniques for identifying those variables among this large set that are useful\nfor discriminating learners form non-learners: ANOVA ranking, Bayes ranking,\nand L1 regularized logistic regression. We found remarkable agreement between\nthese methods in identifying a small set of discriminant variables. Moreover,\nthe same eye tracking variables allow us to classify category learners from\nnon-learners among adults and 6- to 8-month-old infants with accuracies above\n71%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 15:44:57 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 14:56:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Rivera", "Samuel", ""], ["Best", "Catherine A.", ""], ["Yim", "Hyungwook", ""], ["Walther", "Dirk B.", ""], ["Sloutsky", "Vladimir M.", ""], ["Martinez", "Aleix M.", ""]]}, {"id": "2010.15100", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Roy Adams, Suchi Saria", "title": "Evaluating Model Robustness and Stability to Dataset Shift", "comments": "In Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of machine learning in high impact domains becomes widespread, the\nimportance of evaluating safety has increased. An important aspect of this is\nevaluating how robust a model is to changes in setting or population, which\ntypically requires applying the model to multiple, independent datasets. Since\nthe cost of collecting such datasets is often prohibitive, in this paper, we\npropose a framework for analyzing this type of stability using the available\ndata. We use the original evaluation data to determine distributions under\nwhich the algorithm performs poorly, and estimate the algorithm's performance\non the \"worst-case\" distribution. We consider shifts in user defined\nconditional distributions, allowing some distributions to shift while keeping\nother portions of the data distribution fixed. For example, in a healthcare\ncontext, this allows us to consider shifts in clinical practice while keeping\nthe patient population fixed. To address the challenges associated with\nestimation in complex, high-dimensional distributions, we derive a \"debiased\"\nestimator which maintains $\\sqrt{N}$-consistency even when machine learning\nmethods with slower convergence rates are used to estimate the nuisance\nparameters. In experiments on a real medical risk prediction task, we show this\nestimator can be used to analyze stability and accounts for realistic shifts\nthat could not previously be expressed. The proposed framework allows\npractitioners to proactively evaluate the safety of their models without\nrequiring additional data collection.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:35:39 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:34:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Adams", "Roy", ""], ["Saria", "Suchi", ""]]}, {"id": "2010.15110", "submitter": "Gintare Karolina Dziugaite", "authors": "Stanislav Fort, Gintare Karolina Dziugaite, Mansheej Paul, Sepideh\n  Kharaghani, Daniel M. Roy, Surya Ganguli", "title": "Deep learning versus kernel learning: an empirical study of loss\n  landscape geometry and the time evolution of the Neural Tangent Kernel", "comments": "19 pages, 19 figures, In Advances in Neural Information Processing\n  Systems 34 (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In suitably initialized wide networks, small learning rates transform deep\nneural networks (DNNs) into neural tangent kernel (NTK) machines, whose\ntraining dynamics is well-approximated by a linear weight expansion of the\nnetwork at initialization. Standard training, however, diverges from its\nlinearization in ways that are poorly understood. We study the relationship\nbetween the training dynamics of nonlinear deep networks, the geometry of the\nloss landscape, and the time evolution of a data-dependent NTK. We do so\nthrough a large-scale phenomenological analysis of training, synthesizing\ndiverse measures characterizing loss landscape geometry and NTK dynamics. In\nmultiple neural architectures and datasets, we find these diverse measures\nevolve in a highly correlated manner, revealing a universal picture of the deep\nlearning process. In this picture, deep network training exhibits a highly\nchaotic rapid initial transient that within 2 to 3 epochs determines the final\nlinearly connected basin of low loss containing the end point of training.\nDuring this chaotic transient, the NTK changes rapidly, learning useful\nfeatures from the training data that enables it to outperform the standard\ninitial NTK by a factor of 3 in less than 3 to 4 epochs. After this rapid\nchaotic transient, the NTK changes at constant velocity, and its performance\nmatches that of full network training in 15% to 45% of training time. Overall,\nour analysis reveals a striking correlation between a diverse set of metrics\nover training time, governed by a rapid chaotic to stable transition in the\nfirst few epochs, that together poses challenges and opportunities for the\ndevelopment of more accurate theories of deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:53:01 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Fort", "Stanislav", ""], ["Dziugaite", "Gintare Karolina", ""], ["Paul", "Mansheej", ""], ["Kharaghani", "Sepideh", ""], ["Roy", "Daniel M.", ""], ["Ganguli", "Surya", ""]]}, {"id": "2010.15114", "submitter": "Kyle Aitken", "authors": "Kyle Aitken, Vinay V. Ramasesh, Ankush Garg, Yuan Cao, David Sussillo,\n  Niru Maheswaranathan", "title": "The geometry of integration in text classification RNNs", "comments": "9+19 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread application of recurrent neural networks (RNNs) across\na variety of tasks, a unified understanding of how RNNs solve these tasks\nremains elusive. In particular, it is unclear what dynamical patterns arise in\ntrained RNNs, and how those patterns depend on the training dataset or task.\nThis work addresses these questions in the context of a specific natural\nlanguage processing task: text classification. Using tools from dynamical\nsystems analysis, we study recurrent networks trained on a battery of both\nnatural and synthetic text classification tasks. We find the dynamics of these\ntrained RNNs to be both interpretable and low-dimensional. Specifically, across\narchitectures and datasets, RNNs accumulate evidence for each class as they\nprocess the text, using a low-dimensional attractor manifold as the underlying\nmechanism. Moreover, the dimensionality and geometry of the attractor manifold\nare determined by the structure of the training dataset; in particular, we\ndescribe how simple word-count statistics computed on the training dataset can\nbe used to predict these properties. Our observations span multiple\narchitectures and datasets, reflecting a common mechanism RNNs employ to\nperform text classification. To the degree that integration of evidence towards\na decision is a common computational primitive, this work lays the foundation\nfor using dynamical systems techniques to study the inner workings of RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:58:53 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Aitken", "Kyle", ""], ["Ramasesh", "Vinay V.", ""], ["Garg", "Ankush", ""], ["Cao", "Yuan", ""], ["Sussillo", "David", ""], ["Maheswaranathan", "Niru", ""]]}, {"id": "2010.15116", "submitter": "Zhengdao Chen", "authors": "Lei Chen, Zhengdao Chen, Joan Bruna", "title": "On Graph Neural Networks versus Graph-Augmented MLPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the perspective of expressive power, this work compares multi-layer\nGraph Neural Networks (GNNs) with a simplified alternative that we call\nGraph-Augmented Multi-Layer Perceptrons (GA-MLPs), which first augments node\nfeatures with certain multi-hop operators on the graph and then applies an MLP\nin a node-wise fashion. From the perspective of graph isomorphism testing, we\nshow both theoretically and numerically that GA-MLPs with suitable operators\ncan distinguish almost all non-isomorphic graphs, just like the\nWeifeiler-Lehman (WL) test. However, by viewing them as node-level functions\nand examining the equivalence classes they induce on rooted graphs, we prove a\nseparation in expressive power between GA-MLPs and GNNs that grows\nexponentially in depth. In particular, unlike GNNs, GA-MLPs are unable to count\nthe number of attributed walks. We also demonstrate via community detection\nexperiments that GA-MLPs can be limited by their choice of operator family, as\ncompared to GNNs with higher flexibility in learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:59:59 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 16:46:23 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Chen", "Lei", ""], ["Chen", "Zhengdao", ""], ["Bruna", "Joan", ""]]}, {"id": "2010.15208", "submitter": "M. Giselle Fern\\'andez-Godino", "authors": "M. Giselle Fern\\'andez-Godino, Michael J. Grosskopf, Julia B. Nakhleh,\n  Brandon M. Wilson, John Kline, and Gowri Srinivasan", "title": "Identifying Entangled Physics Relationships through Sparse Matrix\n  Decomposition to Inform Plasma Fusion Design", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-28715", "categories": "physics.plasm-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sustainable burn platform through inertial confinement fusion (ICF) has\nbeen an ongoing challenge for over 50 years. Mitigating engineering limitations\nand improving the current design involves an understanding of the complex\ncoupling of physical processes. While sophisticated simulations codes are used\nto model ICF implosions, these tools contain necessary numerical approximation\nbut miss physical processes that limit predictive capability. Identification of\nrelationships between controllable design inputs to ICF experiments and\nmeasurable outcomes (e.g. yield, shape) from performed experiments can help\nguide the future design of experiments and development of simulation codes, to\npotentially improve the accuracy of the computational models used to simulate\nICF experiments. We use sparse matrix decomposition methods to identify\nclusters of a few related design variables. Sparse principal component analysis\n(SPCA) identifies groupings that are related to the physical origin of the\nvariables (laser, hohlraum, and capsule). A variable importance analysis finds\nthat in addition to variables highly correlated with neutron yield such as\npicket power and laser energy, variables that represent a dramatic change of\nthe ICF design such as number of pulse steps are also very important. The\nobtained sparse components are then used to train a random forest (RF)\nsurrogate for predicting total yield. The RF performance on the training and\ntesting data compares with the performance of the RF surrogate trained using\nall design variables considered. This work is intended to inform design changes\nin future ICF experiments by augmenting the expert intuition and simulations\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 20:20:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Fern\u00e1ndez-Godino", "M. Giselle", ""], ["Grosskopf", "Michael J.", ""], ["Nakhleh", "Julia B.", ""], ["Wilson", "Brandon M.", ""], ["Kline", "John", ""], ["Srinivasan", "Gowri", ""]]}, {"id": "2010.15240", "submitter": "Kaiming Fu", "authors": "Kaiming Fu and Yulu Jin and Zhousheng Chen", "title": "Test Set Optimization by Machine Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosis results are highly dependent on the volume of test set. To derive\nthe most efficient test set, we propose several machine learning based methods\nto predict the minimum amount of test data that produces relatively accurate\ndiagnosis. By collecting outputs from failing circuits, the feature matrix and\nlabel vector are generated, which involves the inference information of the\ntest termination point. Thus we develop a prediction model to fit the data and\ndetermine when to terminate testing. The considered methods include LASSO and\nSupport Vector Machine(SVM) where the relationship between goals(label) and\npredictors(feature matrix) are considered to be linear in LASSO and nonlinear\nin SVM. Numerical results show that SVM reaches a diagnosis accuracy of 90.4%\nwhile deducting the volume of test set by 35.24%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 21:24:06 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Fu", "Kaiming", ""], ["Jin", "Yulu", ""], ["Chen", "Zhousheng", ""]]}, {"id": "2010.15285", "submitter": "Raif Rustamov", "authors": "Raif M. Rustamov and Subhabrata Majumdar", "title": "Intrinsic Sliced Wasserstein Distances for Comparing Collections of\n  Probability Distributions on Manifolds and Graphs", "comments": "Improved exposition, add resampling based test, source code", "journal-ref": null, "doi": null, "report-no": "TD:102696/2020-10-08", "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collections of probability distributions arise in a variety of statistical\napplications ranging from user activity pattern analysis to brain connectomics.\nIn practice these distributions are represented by histograms over diverse\ndomain types including finite intervals, circles, cylinders, spheres, other\nmanifolds, and graphs. This paper introduces an approach for detecting\ndifferences between two collections of histograms over such general domains. We\npropose the intrinsic slicing construction that yields a novel class of\nWasserstein distances on manifolds and graphs. These distances are Hilbert\nembeddable, allowing us to reduce the histogram collection comparison problem\nto a more familiar mean testing problem in a Hilbert space. We provide two\ntesting procedures one based on resampling and another on combining p-values\nfrom coordinate-wise tests. Our experiments in a variety of data settings show\nthat the resulting tests are powerful and the p-values are well-calibrated.\nExample applications to user activity patterns, spatial data, and brain\nconnectomics are provided.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 23:41:42 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 17:50:49 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Rustamov", "Raif M.", ""], ["Majumdar", "Subhabrata", ""]]}, {"id": "2010.15379", "submitter": "Fariborz Salehi", "authors": "Fariborz Salehi, Ehsan Abbasi, Babak Hassibi", "title": "The Performance Analysis of Generalized Margin Maximizer (GMM) on\n  Separable Data", "comments": "ICML 2020 (submitted February 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic models are commonly used for binary classification tasks. The\nsuccess of such models has often been attributed to their connection to\nmaximum-likelihood estimators. It has been shown that gradient descent\nalgorithm, when applied on the logistic loss, converges to the max-margin\nclassifier (a.k.a. hard-margin SVM). The performance of the max-margin\nclassifier has been recently analyzed. Inspired by these results, in this\npaper, we present and study a more general setting, where the underlying\nparameters of the logistic model possess certain structures (sparse,\nblock-sparse, low-rank, etc.) and introduce a more general framework (which is\nreferred to as \"Generalized Margin Maximizer\", GMM). While classical max-margin\nclassifiers minimize the $2$-norm of the parameter vector subject to linearly\nseparating the data, GMM minimizes any arbitrary convex function of the\nparameter vector. We provide a precise analysis of the performance of GMM via\nthe solution of a system of nonlinear equations. We also provide a detailed\nstudy for three special cases: ($1$) $\\ell_2$-GMM that is the max-margin\nclassifier, ($2$) $\\ell_1$-GMM which encourages sparsity, and ($3$)\n$\\ell_{\\infty}$-GMM which is often used when the parameter vector has binary\nentries. Our theoretical results are validated by extensive simulation results\nacross a range of parameter values, problem instances, and model structures.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 06:40:05 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Salehi", "Fariborz", ""], ["Abbasi", "Ehsan", ""], ["Hassibi", "Babak", ""]]}, {"id": "2010.15390", "submitter": "Zhi Wang", "authors": "Zhi Wang, Chicheng Zhang, Manish Kumar Singh, Laurel D. Riek, Kamalika\n  Chaudhuri", "title": "Multitask Bandit Learning Through Heterogeneous Feedback Aggregation", "comments": null, "journal-ref": "In International Conference on Artificial Intelligence and\n  Statistics (pp. 1531-1539). PMLR (2021, March)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, multiple agents seek to learn how to perform\nhighly related yet slightly different tasks in an online bandit learning\nprotocol. We formulate this problem as the $\\epsilon$-multi-player multi-armed\nbandit problem, in which a set of players concurrently interact with a set of\narms, and for each arm, the reward distributions for all players are similar\nbut not necessarily identical. We develop an upper confidence bound-based\nalgorithm, RobustAgg$(\\epsilon)$, that adaptively aggregates rewards collected\nby different players. In the setting where an upper bound on the pairwise\nsimilarities of reward distributions between players is known, we achieve\ninstance-dependent regret guarantees that depend on the amenability of\ninformation sharing across players. We complement these upper bounds with\nnearly matching lower bounds. In the setting where pairwise similarities are\nunknown, we provide a lower bound, as well as an algorithm that trades off\nminimax regret guarantees for adaptivity to unknown similarity structure.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 07:13:28 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 00:27:13 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Zhi", ""], ["Zhang", "Chicheng", ""], ["Singh", "Manish Kumar", ""], ["Riek", "Laurel D.", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2010.15392", "submitter": "Ziyang Tang", "authors": "Ziyang Tang, Yihao Feng, Na Zhang, Jian Peng, Qiang Liu", "title": "Off-Policy Interval Estimation with Lipschitz Value Iteration", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation provides an essential tool for evaluating the effects\nof different policies or treatments using only observed data. When applied to\nhigh-stakes scenarios such as medical diagnosis or financial decision-making,\nit is crucial to provide provably correct upper and lower bounds of the\nexpected reward, not just a classical single point estimate, to the end-users,\nas executing a poor policy can be very costly. In this work, we propose a\nprovably correct method for obtaining interval bounds for off-policy evaluation\nin a general continuous setting. The idea is to search for the maximum and\nminimum values of the expected reward among all the Lipschitz Q-functions that\nare consistent with the observations, which amounts to solving a constrained\noptimization problem on a Lipschitz function space. We go on to introduce a\nLipschitz value iteration method to monotonically tighten the interval, which\nis simple yet efficient and provably convergent. We demonstrate the practical\nefficiency of our method on a range of benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 07:25:56 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Tang", "Ziyang", ""], ["Feng", "Yihao", ""], ["Zhang", "Na", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "2010.15527", "submitter": "Patrick Gensler", "authors": "Patrick Gensler and Andreas Christmann", "title": "On the robustness of kernel-based pairwise learning", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that many results on the statistical robustness of kernel-based\npairwise learning can be derived under basically no assumptions on the input\nand output spaces. In particular neither moment conditions on the conditional\ndistribution of Y given X = x nor the boundedness of the output space is\nneeded. We obtain results on the existence and boundedness of the influence\nfunction and show qualitative robustness of the kernel-based estimator. The\npresent paper generalizes results by Christmann and Zhou (2016) by allowing the\nprediction function to take two arguments and can thus be applied in a variety\nof situations such as ranking.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 12:47:54 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Gensler", "Patrick", ""], ["Christmann", "Andreas", ""]]}, {"id": "2010.15538", "submitter": "Alexander Terenin", "authors": "Viacheslav Borovitskiy, Iskander Azangulov, Alexander Terenin, Peter\n  Mostowsky, Marc Peter Deisenroth, Nicolas Durrande", "title": "Mat\\'ern Gaussian Processes on Graphs", "comments": null, "journal-ref": "Artificial Intelligence and Statistics, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes are a versatile framework for learning unknown functions\nin a manner that permits one to utilize prior information about their\nproperties. Although many different Gaussian process models are readily\navailable when the input space is Euclidean, the choice is much more limited\nfor Gaussian processes whose input space is an undirected graph. In this work,\nwe leverage the stochastic partial differential equation characterization of\nMat\\'ern Gaussian processes - a widely-used model class in the Euclidean\nsetting - to study their analog for undirected graphs. We show that the\nresulting Gaussian processes inherit various attractive properties of their\nEuclidean and Riemannian analogs and provide techniques that allow them to be\ntrained using standard methods, such as inducing points. This enables graph\nMat\\'ern Gaussian processes to be employed in mini-batch and non-conjugate\nsettings, thereby making them more accessible to practitioners and easier to\ndeploy within larger learning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 13:08:07 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 16:11:48 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 13:01:33 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Borovitskiy", "Viacheslav", ""], ["Azangulov", "Iskander", ""], ["Terenin", "Alexander", ""], ["Mostowsky", "Peter", ""], ["Deisenroth", "Marc Peter", ""], ["Durrande", "Nicolas", ""]]}, {"id": "2010.15550", "submitter": "David Powers", "authors": "David M. W. Powers", "title": "ADABOOK & MULTIBOOK: Adaptive Boosting with Chance Correction", "comments": "10 pages, 3 figures. This is an updated preprint of a paper presented\n  at ICINCO2013", "journal-ref": "International Conference on Informatics in Control, Automation and\n  Robotics, 2013. pp. 349-359", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable interest in boosting and bagging, including the\ncombination of the adaptive techniques of AdaBoost with the random selection\nwith replacement techniques of Bagging. At the same time there has been a\nrevisiting of the way we evaluate, with chance-corrected measures like Kappa,\nInformedness, Correlation or ROC AUC being advocated. This leads to the\nquestion of whether learning algorithms can do better by optimizing an\nappropriate chance corrected measure. Indeed, it is possible for a weak learner\nto optimize Accuracy to the detriment of the more reaslistic chance-corrected\nmeasures, and when this happens the booster can give up too early. This\nphenomenon is known to occur with conventional Accuracy-based AdaBoost, and the\nMultiBoost algorithm has been developed to overcome such problems using restart\ntechniques based on bagging. This paper thus complements the theoretical work\nshowing the necessity of using chance-corrected measures for evaluation, with\nempirical work showing how use of a chance-corrected measure can improve\nboosting. We show that the early surrender problem occurs in MultiBoost too, in\nmulticlass situations, so that chance-corrected AdaBook and Multibook can beat\nstandard Multiboost or AdaBoost, and we further identify which chance-corrected\nmeasures to use when.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 01:17:32 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Powers", "David M. W.", ""]]}, {"id": "2010.15551", "submitter": "Xinwei Deng", "authors": "Jiayi Lian, Laura Freeman, Yili Hong, and Xinwei Deng", "title": "Investigating the Robustness of Artificial Intelligent Algorithms with\n  Mixture Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligent (AI) algorithms, such as deep learning and XGboost,\nare used in numerous applications including computer vision, autonomous\ndriving, and medical diagnostics. The robustness of these AI algorithms is of\ngreat interest as inaccurate prediction could result in safety concerns and\nlimit the adoption of AI systems. In this paper, we propose a framework based\non design of experiments to systematically investigate the robustness of AI\nclassification algorithms. A robust classification algorithm is expected to\nhave high accuracy and low variability under different application scenarios.\nThe robustness can be affected by a wide range of factors such as the imbalance\nof class labels in the training dataset, the chosen prediction algorithm, the\nchosen dataset of the application, and a change of distribution in the training\nand test datasets. To investigate the robustness of AI classification\nalgorithms, we conduct a comprehensive set of mixture experiments to collect\nprediction performance results. Then statistical analyses are conducted to\nunderstand how various factors affect the robustness of AI classification\nalgorithms. We summarize our findings and provide suggestions to practitioners\nin AI applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 15:38:53 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Lian", "Jiayi", ""], ["Freeman", "Laura", ""], ["Hong", "Yili", ""], ["Deng", "Xinwei", ""]]}, {"id": "2010.15571", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios, Behnoosh Zamanlooy", "title": "Learning Sub-Patterns in Piecewise Continuous Functions", "comments": "12 Pages + 7 Page Appendix, 1 Figure, and 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most stochastic gradient descent algorithms can optimize neural networks that\nare sub-differentiable in their parameters, which requires their activation\nfunction to exhibit a degree of continuity. However, this continuity constraint\non the activation function prevents these neural models from uniformly\napproximating discontinuous functions. This paper focuses on the case where the\ndiscontinuities arise from distinct sub-patterns, each defined on different\nparts of the input space. We propose a new discontinuous deep neural network\nmodel trainable via a decoupled two-step procedure that avoids passing gradient\nupdates through the network's non-differentiable unit. We provide universal\napproximation guarantees for our architecture in the space of bounded\ncontinuous functions and in the space of piecewise continuous functions, which\nwe introduced herein. We present a novel semi-supervised two-step training\nprocedure for our discontinuous deep learning model, and we provide theoretical\nsupport for its effectiveness. The performance of our architecture is evaluated\nexperimentally on two real-world datasets and one synthetic dataset.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 13:44:13 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 19:47:11 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 14:21:05 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kratsios", "Anastasis", ""], ["Zamanlooy", "Behnoosh", ""]]}, {"id": "2010.15583", "submitter": "Javier Movellan", "authors": "Javier R. Movellan, Prasad Gabbur", "title": "Probabilistic Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Transformers are Maximum Posterior Probability estimators for\nMixtures of Gaussian Models. This brings a probabilistic point of view to\nTransformers and suggests extensions to other probabilistic cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 01:44:59 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 03:19:18 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 16:40:17 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Movellan", "Javier R.", ""], ["Gabbur", "Prasad", ""]]}, {"id": "2010.15604", "submitter": "Carlos Puerto-Santana", "authors": "Carlos Puerto-Santana and Pedro Larra\\~naga and Concha Bielza", "title": "Autoregressive Asymmetric Linear Gaussian Hidden Markov Models", "comments": "34 pages, 16 figures, intended to be published in IEEE Transactions\n  on Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a real life process evolving over time, the relationship between its\nrelevant variables may change. Therefore, it is advantageous to have different\ninference models for each state of the process. Asymmetric hidden Markov models\nfulfil this dynamical requirement and provide a framework where the trend of\nthe process can be expressed as a latent variable. In this paper, we modify\nthese recent asymmetric hidden Markov models to have an asymmetric\nautoregressive component, allowing the model to choose the order of\nautoregression that maximizes its penalized likelihood for a given training\nset. Additionally, we show how inference, hidden states decoding and parameter\nlearning must be adapted to fit the proposed model. Finally, we run experiments\nwith synthetic and real data to show the capabilities of this new model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 08:58:46 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Puerto-Santana", "Carlos", ""], ["Larra\u00f1aga", "Pedro", ""], ["Bielza", "Concha", ""]]}, {"id": "2010.15622", "submitter": "Floris den Hengst", "authors": "Michal Nauman and Floris Den Hengst", "title": "Low-Variance Policy Gradient Estimation with World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose World Model Policy Gradient (WMPG), an approach to\nreduce the variance of policy gradient estimates using learned world models\n(WM's). In WMPG, a WM is trained online and used to imagine trajectories. The\nimagined trajectories are used in two ways. Firstly, to calculate a\nwithout-replacement estimator of the policy gradient. Secondly, the return of\nthe imagined trajectories is used as an informed baseline. We compare the\nproposed approach with AC and MAC on a set of environments of increasing\ncomplexity (CartPole, LunarLander and Pong) and find that WMPG has better\nsample efficiency. Based on these results, we conclude that WMPG can yield\nincreased sample efficiency in cases where a robust latent representation of\nthe environment can be learned.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 14:09:23 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Nauman", "Michal", ""], ["Hengst", "Floris Den", ""]]}, {"id": "2010.15639", "submitter": "Siddarth Asokan", "authors": "Siddarth Asokan and Chandra Sekhar Seelamantula", "title": "Teaching a GAN What Not to Learn", "comments": "Neural Information Processing Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) were originally envisioned as\nunsupervised generative models that learn to follow a target distribution.\nVariants such as conditional GANs, auxiliary-classifier GANs (ACGANs) project\nGANs on to supervised and semi-supervised learning frameworks by providing\nlabelled data and using multi-class discriminators. In this paper, we approach\nthe supervised GAN problem from a different perspective, one that is motivated\nby the philosophy of the famous Persian poet Rumi who said, \"The art of knowing\nis knowing what to ignore.\" In the GAN framework, we not only provide the GAN\npositive data that it must learn to model, but also present it with so-called\nnegative samples that it must learn to avoid - we call this \"The Rumi\nFramework.\" This formulation allows the discriminator to represent the\nunderlying target distribution better by learning to penalize generated samples\nthat are undesirable - we show that this capability accelerates the learning\nprocess of the generator. We present a reformulation of the standard GAN (SGAN)\nand least-squares GAN (LSGAN) within the Rumi setting. The advantage of the\nreformulation is demonstrated by means of experiments conducted on MNIST,\nFashion MNIST, CelebA, and CIFAR-10 datasets. Finally, we consider an\napplication of the proposed formulation to address the important problem of\nlearning an under-represented class in an unbalanced dataset. The Rumi approach\nresults in substantially lower FID scores than the standard GAN frameworks\nwhile possessing better generalization capability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 14:44:24 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Asokan", "Siddarth", ""], ["Seelamantula", "Chandra Sekhar", ""]]}, {"id": "2010.15651", "submitter": "Simon Geisler", "authors": "Simon Geisler, Daniel Z\\\"ugner, Stephan G\\\"unnemann", "title": "Reliable Graph Neural Networks via Robust Aggregation", "comments": "23 pages, 9 figures, 6 Tables, Neural Information Processing Systems,\n  NeurIPS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perturbations targeting the graph structure have proven to be extremely\neffective in reducing the performance of Graph Neural Networks (GNNs), and\ntraditional defenses such as adversarial training do not seem to be able to\nimprove robustness. This work is motivated by the observation that\nadversarially injected edges effectively can be viewed as additional samples to\na node's neighborhood aggregation function, which results in distorted\naggregations accumulating over the layers. Conventional GNN aggregation\nfunctions, such as a sum or mean, can be distorted arbitrarily by a single\noutlier. We propose a robust aggregation function motivated by the field of\nrobust statistics. Our approach exhibits the largest possible breakdown point\nof 0.5, which means that the bias of the aggregation is bounded as long as the\nfraction of adversarial edges of a node is less than 50\\%. Our novel\naggregation function, Soft Medoid, is a fully differentiable generalization of\nthe Medoid and therefore lends itself well for end-to-end deep learning.\nEquipping a GNN with our aggregation improves the robustness with respect to\nstructure perturbations on Cora ML by a factor of 3 (and 5.5 on Citeseer) and\nby a factor of 8 for low-degree nodes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 14:55:20 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Geisler", "Simon", ""], ["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2010.15658", "submitter": "Ekkehard Schnoor", "authors": "Arash Behboodi, Holger Rauhut, Ekkehard Schnoor", "title": "Compressive Sensing and Neural Networks from a Statistical Learning\n  Perspective", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various iterative reconstruction algorithms for inverse problems can be\nunfolded as neural networks. Empirically, this approach has often led to\nimproved results, but theoretical guarantees are still scarce. While some\nprogress on generalization properties of neural networks have been made, great\nchallenges remain. In this chapter, we discuss and combine these topics to\npresent a generalization error analysis for a class of neural networks suitable\nfor sparse reconstruction from few linear measurements. The hypothesis class\nconsidered is inspired by the classical iterative soft-thresholding algorithm\n(ISTA). The neural networks in this class are obtained by unfolding iterations\nof ISTA and learning some of the weights. Based on training samples, we aim at\nlearning the optimal network parameters via empirical risk minimization and\nthereby the optimal network that reconstructs signals from their compressive\nlinear measurements. In particular, we may learn a sparsity basis that is\nshared by all of the iterations/layers and thereby obtain a new approach for\ndictionary learning. For this class of networks, we present a generalization\nbound, which is based on bounding the Rademacher complexity of hypothesis\nclasses consisting of such deep networks via Dudley's integral. Remarkably,\nunder realistic conditions, the generalization error scales only\nlogarithmically in the number of layers, and at most linear in number of\nmeasurements.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 15:05:43 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 11:26:50 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 12:38:40 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Behboodi", "Arash", ""], ["Rauhut", "Holger", ""], ["Schnoor", "Ekkehard", ""]]}, {"id": "2010.15659", "submitter": "Tobias Freidling", "authors": "Tobias Freidling, Benjamin Poignard, H\\'ector Climente-Gonz\\'alez,\n  Makoto Yamada", "title": "Post-selection inference with HSIC-Lasso", "comments": "Changes to previous version: * Incorporating comments and remarks\n  from reviewers * Evaluation of power of the proposed method * Summarising\n  behaviour for different hyper-parameters in one paragraph, instead of several\n  figures * Pseudocode of the algorithm * Additional, in-depth experiment on\n  real-world data", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting influential features in non-linear and/or high-dimensional data is\na challenging and increasingly important task in machine learning. Variable\nselection methods have thus been gaining much attention as well as\npost-selection inference. Indeed, the selected features can be significantly\nflawed when the selection procedure is not accounted for. We propose a\nselective inference procedure using the so-called model-free \"HSIC-Lasso\" based\non the framework of truncated Gaussians combined with the polyhedral lemma. We\nthen develop an algorithm, which allows for low computational costs and\nprovides a selection of the regularisation parameter. The performance of our\nmethod is illustrated by both artificial and real-world data based experiments,\nwhich emphasise a tight control of the type-I error, even for small sample\nsizes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 15:10:21 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 11:19:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Freidling", "Tobias", ""], ["Poignard", "Benjamin", ""], ["Climente-Gonz\u00e1lez", "H\u00e9ctor", ""], ["Yamada", "Makoto", ""]]}, {"id": "2010.15662", "submitter": "Andr\\'es Corrada-Emmanuel", "authors": "Andr\\'es Corrada-Emmanuel, Edward Pantridge, Eddie Zahrebelski, Aditya\n  Chaganti, Simeon Simeonov", "title": "Independence Tests Without Ground Truth for Noisy Learners", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact ground truth invariant polynomial systems can be written for\narbitrarily correlated binary classifiers. Their solutions give estimates for\nsample statistics that require knowledge of the ground truth of the correct\nlabels in the sample. Of these polynomial systems, only a few have been solved\nin closed form. Here we discuss the exact solution for independent binary\nclassifiers - resolving an outstanding problem that has been presented at this\nconference and others. Its practical applicability is hampered by its sole\nremaining assumption - the classifiers need to be independent in their sample\nerrors. We discuss how to use the closed form solution to create a\nself-consistent test that can validate the independence assumption itself\nabsent the correct labels ground truth. It can be cast as an algebraic geometry\nconjecture for binary classifiers that remains unsolved. A similar conjecture\nfor the ground truth invariant algebraic system for scalar regressors is\nsolvable, and we present the solution here. We also discuss experiments on the\nPenn ML Benchmark classification tasks that provide further evidence that the\nconjecture may be true for the polynomial system of binary classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 13:03:26 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Corrada-Emmanuel", "Andr\u00e9s", ""], ["Pantridge", "Edward", ""], ["Zahrebelski", "Eddie", ""], ["Chaganti", "Aditya", ""], ["Simeonov", "Simeon", ""]]}, {"id": "2010.15694", "submitter": "Quanjun Lang", "authors": "Quanjun Lang, Fei Lu", "title": "Learning interaction kernels in mean-field equations of 1st-order\n  systems of interacting particles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nonparametric algorithm to learn interaction kernels of\nmean-field equations for 1st-order systems of interacting particles. The data\nconsist of discrete space-time observations of the solution. By least squares\nwith regularization, the algorithm learns the kernel on data-adaptive\nhypothesis spaces efficiently. A key ingredient is a probabilistic error\nfunctional derived from the likelihood of the mean-field equation's diffusion\nprocess. The estimator converges, in a reproducing kernel Hilbert space and an\nL2 space under an identifiability condition, at a rate optimal in the sense\nthat it equals the numerical integrator's order. We demonstrate our algorithm\non three typical examples: the opinion dynamics with a piecewise linear kernel,\nthe granular media model with a quadratic kernel, and the aggregation-diffusion\nwith a repulsive-attractive kernel.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 15:37:17 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Lang", "Quanjun", ""], ["Lu", "Fei", ""]]}, {"id": "2010.15703", "submitter": "Julieta Martinez", "authors": "Julieta Martinez, Jashan Shewakramani, Ting Wei Liu, Ioan Andrei\n  B\\^arsan, Wenyuan Zeng, Raquel Urtasun", "title": "Permute, Quantize, and Fine-tune: Efficient Compression of Neural\n  Networks", "comments": "CVPR 21 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing large neural networks is an important step for their deployment\nin resource-constrained computational platforms. In this context, vector\nquantization is an appealing framework that expresses multiple parameters using\na single code, and has recently achieved state-of-the-art network compression\non a range of core vision and natural language processing tasks. Key to the\nsuccess of vector quantization is deciding which parameter groups should be\ncompressed together. Previous work has relied on heuristics that group the\nspatial dimension of individual convolutional filters, but a general solution\nremains unaddressed. This is desirable for pointwise convolutions (which\ndominate modern architectures), linear layers (which have no notion of spatial\ndimension), and convolutions (when more than one filter is compressed to the\nsame codeword). In this paper we make the observation that the weights of two\nadjacent layers can be permuted while expressing the same function. We then\nestablish a connection to rate-distortion theory and search for permutations\nthat result in networks that are easier to compress. Finally, we rely on an\nannealed quantization algorithm to better compress the network and achieve\nhigher final accuracy. We show results on image classification, object\ndetection, and segmentation, reducing the gap with the uncompressed model by 40\nto 70% with respect to the current state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 15:47:26 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 01:43:59 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 22:27:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Martinez", "Julieta", ""], ["Shewakramani", "Jashan", ""], ["Liu", "Ting Wei", ""], ["B\u00e2rsan", "Ioan Andrei", ""], ["Zeng", "Wenyuan", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2010.15727", "submitter": "Ari Pakman", "authors": "Yueqi Wang, Yoonho Lee, Pallab Basu, Juho Lee, Yee Whye Teh, Liam\n  Paninski, Ari Pakman", "title": "Amortized Probabilistic Detection of Communities in Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning community structures in graphs has broad applications across\nscientific domains. While graph neural networks (GNNs) have been successful in\nencoding graph structures, existing GNN-based methods for community detection\nare limited by requiring knowledge of the number of communities in advance, in\naddition to lacking a proper probabilistic formulation to handle uncertainty.\nWe propose a simple framework for amortized community detection, which\naddresses both of these issues by combining the expressive power of GNNs with\nrecent methods for amortized clustering. Our models consist of a graph\nrepresentation backbone that extracts structural information and an amortized\nclustering network that naturally handles variable numbers of clusters. Both\ncomponents combine into well-defined models of the posterior distribution of\ngraph communities and are jointly optimized given labeled graphs. At inference\ntime, the models yield parallel samples from the posterior of community labels,\nquantifying uncertainty in a principled way. We evaluate several models from\nour framework on synthetic and real datasets and demonstrate superior\nperformance to previous methods. As a separate contribution, we extend recent\namortized probabilistic clustering architectures by adding attention modules,\nwhich yield further improvements on community detection tasks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 16:18:48 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 14:11:17 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 08:07:29 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Yueqi", ""], ["Lee", "Yoonho", ""], ["Basu", "Pallab", ""], ["Lee", "Juho", ""], ["Teh", "Yee Whye", ""], ["Paninski", "Liam", ""], ["Pakman", "Ari", ""]]}, {"id": "2010.15764", "submitter": "Yuansi Chen", "authors": "Yuansi Chen, Peter B\\\"uhlmann", "title": "Domain adaptation under structural causal models", "comments": "75 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation (DA) arises as an important problem in statistical machine\nlearning when the source data used to train a model is different from the\ntarget data used to test the model. Recent advances in DA have mainly been\napplication-driven and have largely relied on the idea of a common subspace for\nsource and target data. To understand the empirical successes and failures of\nDA methods, we propose a theoretical framework via structural causal models\nthat enables analysis and comparison of the prediction performance of DA\nmethods. This framework also allows us to itemize the assumptions needed for\nthe DA methods to have a low target error. Additionally, with insights from our\ntheory, we propose a new DA method called CIRM that outperforms existing DA\nmethods when both the covariates and label distributions are perturbed in the\ntarget data. We complement the theoretical analysis with extensive simulations\nto show the necessity of the devised assumptions. Reproducible synthetic and\nreal data experiments are also provided to illustrate the strengths and\nweaknesses of DA methods when parts of the assumptions of our theory are\nviolated.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:09:34 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chen", "Yuansi", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "2010.15775", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, Anders Andreassen, Behnam Neyshabur", "title": "Understanding the Failure Modes of Out-of-Distribution Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical studies suggest that machine learning models often rely on\nfeatures, such as the background, that may be spuriously correlated with the\nlabel only during training time, resulting in poor accuracy during test-time.\nIn this work, we identify the fundamental factors that give rise to this\nbehavior, by explaining why models fail this way {\\em even} in easy-to-learn\ntasks where one would expect these models to succeed. In particular, through a\ntheoretical study of gradient-descent-trained linear classifiers on some\neasy-to-learn tasks, we uncover two complementary failure modes. These modes\narise from how spurious correlations induce two kinds of skews in the data: one\ngeometric in nature, and another, statistical in nature. Finally, we construct\nnatural modifications of image classification datasets to understand when these\nfailure modes can arise in practice. We also design experiments to isolate the\ntwo failure modes when training modern neural networks on these datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:19:03 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 04:08:02 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Andreassen", "Anders", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "2010.15805", "submitter": "Hong Zhou", "authors": "Lap Chi Lau and Hong Zhou", "title": "A Local Search Framework for Experimental Design", "comments": "Improved probability bound in Theorem 1.4. A preliminary version\n  accepted by SODA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a local search framework to design and analyze both combinatorial\nalgorithms and rounding algorithms for experimental design problems. This\nframework provides a unifying approach to match and improve all known results\nin D/A/E-design and to obtain new results in previously unknown settings.\n  For combinatorial algorithms, we provide a new analysis of the classical\nFedorov's exchange method. We prove that this simple local search algorithm\nworks well as long as there exists an almost optimal solution with good\ncondition number. Moreover, we design a new combinatorial local search\nalgorithm for E-design using the regret minimization framework.\n  For rounding algorithms, we provide a unified randomized exchange algorithm\nto match and improve previous results for D/A/E-design. Furthermore, the\nalgorithm works in the more general setting to approximately satisfy multiple\nknapsack constraints, which can be used for weighted experimental design and\nfor incorporating fairness constraints into experimental design.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:43:06 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 05:00:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Lau", "Lap Chi", ""], ["Zhou", "Hong", ""]]}, {"id": "2010.15819", "submitter": "Ping Li", "authors": "Yunfeng Cai and Ping Li", "title": "Tensor Completion via Tensor Networks with a Tucker Wrapper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, low-rank tensor completion (LRTC) has received considerable\nattention due to its applications in image/video inpainting, hyperspectral data\nrecovery, etc. With different notions of tensor rank (e.g., CP, Tucker, tensor\ntrain/ring, etc.), various optimization based numerical methods are proposed to\nLRTC. However, tensor network based methods have not been proposed yet. In this\npaper, we propose to solve LRTC via tensor networks with a Tucker wrapper. Here\nby \"Tucker wrapper\" we mean that the outermost factor matrices of the tensor\nnetwork are all orthonormal. We formulate LRTC as a problem of solving a system\nof nonlinear equations, rather than a constrained optimization problem. A\ntwo-level alternative least square method is then employed to update the\nunknown factors. The computation of the method is dominated by tensor matrix\nmultiplications and can be efficiently performed. Also, under proper\nassumptions, it is shown that with high probability, the method converges to\nthe exact solution at a linear rate. Numerical simulations show that the\nproposed algorithm is comparable with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:54:01 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Cai", "Yunfeng", ""], ["Li", "Ping", ""]]}, {"id": "2010.15835", "submitter": "Dean Eckles", "authors": "Jeremy Yang, Dean Eckles, Paramveer Dhillon, Sinan Aral", "title": "Targeting for long-term outcomes", "comments": "main text is 24 pages, with 5 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-makers often want to target interventions (e.g., marketing\ncampaigns) so as to maximize an outcome that is observed only in the long-term.\nThis typically requires delaying decisions until the outcome is observed or\nrelying on simple short-term proxies for the long-term outcome. Here we build\non the statistical surrogacy and off-policy learning literature to impute the\nmissing long-term outcomes and then approximate the optimal targeting policy on\nthe imputed outcomes via a doubly-robust approach. We apply our approach in\nlarge-scale proactive churn management experiments at The Boston Globe by\ntargeting optimal discounts to its digital subscribers to maximize their\nlong-term revenue. We first show that conditions for validity of average\ntreatment effect estimation with imputed outcomes are also sufficient for valid\npolicy evaluation and optimization; furthermore, these conditions can be\nsomewhat relaxed for policy optimization. We then validate this approach\nempirically by comparing it with a policy learned on the ground truth long-term\noutcomes and show that they are statistically indistinguishable. Our approach\nalso outperforms a policy learned on short-term proxies for the long-term\noutcome. In a second field experiment, we implement the optimal targeting\npolicy with additional randomized exploration, which allows us to update the\noptimal policy for each new cohort of customers to account for potential\nnon-stationarity. Over three years, our approach had a net-positive revenue\nimpact in the range of $4-5 million compared to The Boston Globe's current\npolicies.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:31:17 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Yang", "Jeremy", ""], ["Eckles", "Dean", ""], ["Dhillon", "Paramveer", ""], ["Aral", "Sinan", ""]]}, {"id": "2010.15949", "submitter": "Imtiaz Ahmed", "authors": "Imtiaz Ahmed, Travis Galoppo, Xia Hu, Yu Ding", "title": "Graph Regularized Autoencoder and its Application in Unsupervised\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is a crucial first step for many unsupervised\nlearning tasks including anomaly detection and clustering. Autoencoder is a\npopular mechanism to accomplish dimensionality reduction. In order to make\ndimensionality reduction effective for high-dimensional data embedding\nnonlinear low-dimensional manifold, it is understood that some sort of geodesic\ndistance metric should be used to discriminate the data samples. Inspired by\nthe success of geodesic distance approximators such as ISOMAP, we propose to\nuse a minimum spanning tree (MST), a graph-based algorithm, to approximate the\nlocal neighborhood structure and generate structure-preserving distances among\ndata points. We use this MST-based distance metric to replace the Euclidean\ndistance metric in the embedding function of autoencoders and develop a new\ngraph regularized autoencoder, which outperforms a wide range of alternative\nmethods over 20 benchmark anomaly detection datasets. We further incorporate\nthe MST regularizer into two generative adversarial networks and find that\nusing the MST regularizer improves the performance of anomaly detection\nsubstantially for both generative adversarial networks. We also test our MST\nregularized autoencoder on two datasets in a clustering application and witness\nits superior performance as well.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 21:17:41 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 06:18:57 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ahmed", "Imtiaz", ""], ["Galoppo", "Travis", ""], ["Hu", "Xia", ""], ["Ding", "Yu", ""]]}, {"id": "2010.15959", "submitter": "Anil Damle", "authors": "Austin R. Benson, Anil Damle, Alex Townsend", "title": "Over-parametrized neural networks as under-determined linear systems", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We draw connections between simple neural networks and under-determined\nlinear systems to comprehensively explore several interesting theoretical\nquestions in the study of neural networks. First, we emphatically show that it\nis unsurprising such networks can achieve zero training loss. More\nspecifically, we provide lower bounds on the width of a single hidden layer\nneural network such that only training the last linear layer suffices to reach\nzero training loss. Our lower bounds grow more slowly with data set size than\nexisting work that trains the hidden layer weights. Second, we show that\nkernels typically associated with the ReLU activation function have fundamental\nflaws -- there are simple data sets where it is impossible for widely studied\nbias-free models to achieve zero training loss irrespective of how the\nparameters are chosen or trained. Lastly, our analysis of gradient descent\nclearly illustrates how spectral properties of certain matrices impact both the\nearly iteration and long-term training behavior. We propose new activation\nfunctions that avoid the pitfalls of ReLU in that they admit zero training loss\nsolutions for any set of distinct data points and experimentally exhibit\nfavorable spectral properties.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 21:43:00 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Benson", "Austin R.", ""], ["Damle", "Anil", ""], ["Townsend", "Alex", ""]]}, {"id": "2010.15963", "submitter": "Hengrui Cai", "authors": "Hengrui Cai, Chengchun Shi, Rui Song, Wenbin Lu", "title": "Deep Jump Q-Evaluation for Offline Policy Evaluation in Continuous\n  Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy evaluation (OPE) in continuous action domains, such as\ndynamic pricing and personalized dose finding. In OPE, one aims to learn the\nvalue under a new policy using historical data generated by a different\nbehavior policy. Most existing works on OPE focus on discrete action domains.\nTo handle continuous action space, we develop a brand-new deep jump\nQ-evaluation method for OPE. The key ingredient of our method lies in\nadaptively discretizing the action space using deep jump Q-learning. This\nallows us to apply existing OPE methods in discrete domains to handle\ncontinuous actions. Our method is further justified by theoretical results,\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 21:59:08 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Cai", "Hengrui", ""], ["Shi", "Chengchun", ""], ["Song", "Rui", ""], ["Lu", "Wenbin", ""]]}, {"id": "2010.15969", "submitter": "Mao Ye", "authors": "Mao Ye, Lemeng Wu, Qiang Liu", "title": "Greedy Optimization Provably Wins the Lottery: Logarithmic Number of\n  Winning Tickets is Enough", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success of deep learning, recent works show that large deep\nneural networks are often highly redundant and can be significantly reduced in\nsize. However, the theoretical question of how much we can prune a neural\nnetwork given a specified tolerance of accuracy drop is still open. This paper\nprovides one answer to this question by proposing a greedy optimization based\npruning method. The proposed method has the guarantee that the discrepancy\nbetween the pruned network and the original network decays with exponentially\nfast rate w.r.t. the size of the pruned network, under weak assumptions that\napply for most practical settings. Empirically, our method improves prior arts\non pruning various network architectures including ResNet, MobilenetV2/V3 on\nImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 22:06:31 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ye", "Mao", ""], ["Wu", "Lemeng", ""], ["Liu", "Qiang", ""]]}, {"id": "2010.15997", "submitter": "Stephanie Clark", "authors": "Stephanie Clark, Rob J Hyndman, Dan Pagendam, Louise M Ryan", "title": "Modern strategies for time series regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses several modern approaches to regression analysis\ninvolving time series data where some of the predictor variables are also\nindexed by time. We discuss classical statistical approaches as well as methods\nthat have been proposed recently in the machine learning literature. The\napproaches are compared and contrasted, and it will be seen that there are\nadvantages and disadvantages to most currently available approaches. There is\nample room for methodological developments in this area. The work is motivated\nby an application involving the prediction of water levels as a function of\nrainfall and other climate variables in an aquifer in eastern Australia.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 23:56:57 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Clark", "Stephanie", ""], ["Hyndman", "Rob J", ""], ["Pagendam", "Dan", ""], ["Ryan", "Louise M", ""]]}, {"id": "2010.16001", "submitter": "Sarah Dean", "authors": "Sarah Dean, Andrew J. Taylor, Ryan K. Cosner, Benjamin Recht, Aaron D.\n  Ames", "title": "Guaranteeing Safety of Learned Perception Modules via Measurement-Robust\n  Control Barrier Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern nonlinear control theory seeks to develop feedback controllers that\nendow systems with properties such as safety and stability. The guarantees\nensured by these controllers often rely on accurate estimates of the system\nstate for determining control actions. In practice, measurement model\nuncertainty can lead to error in state estimates that degrades these\nguarantees. In this paper, we seek to unify techniques from control theory and\nmachine learning to synthesize controllers that achieve safety in the presence\nof measurement model uncertainty. We define the notion of a Measurement-Robust\nControl Barrier Function (MR-CBF) as a tool for determining safe control inputs\nwhen facing measurement model uncertainty. Furthermore, MR-CBFs are used to\ninform sampling methodologies for learning-based perception systems and\nquantify tolerable error in the resulting learned models. We demonstrate the\nefficacy of MR-CBFs in achieving safety with measurement model uncertainty on a\nsimulated Segway system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 00:19:01 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Dean", "Sarah", ""], ["Taylor", "Andrew J.", ""], ["Cosner", "Ryan K.", ""], ["Recht", "Benjamin", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2010.16040", "submitter": "Shufeng Kong", "authors": "Shufeng Kong, Junwen Bai, Jae Hee Lee, Di Chen, Andrew Allyn, Michelle\n  Stuart, Malin Pinsky, Katherine Mills, Carla P. Gomes", "title": "Deep Hurdle Networks for Zero-Inflated Multi-Target Regression:\n  Application to Multiple Species Abundance Estimation", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in computational sustainability is to understand the\ndistribution of species across landscapes over time. This question gives rise\nto challenging large-scale prediction problems since (i) hundreds of species\nhave to be simultaneously modeled and (ii) the survey data are usually inflated\nwith zeros due to the absence of species for a large number of sites. The\nproblem of tackling both issues simultaneously, which we refer to as the\nzero-inflated multi-target regression problem, has not been addressed by\nprevious methods in statistics and machine learning. In this paper, we propose\na novel deep model for the zero-inflated multi-target regression problem. To\nthis end, we first model the joint distribution of multiple response variables\nas a multivariate probit model and then couple the positive outcomes with a\nmultivariate log-normal distribution. By penalizing the difference between the\ntwo distributions' covariance matrices, a link between both distributions is\nestablished. The whole model is cast as an end-to-end learning framework and we\nprovide an efficient learning algorithm for our model that can be fully\nimplemented on GPUs. We show that our model outperforms the existing\nstate-of-the-art baselines on two challenging real-world species distribution\ndatasets concerning bird and fish populations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 03:26:16 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Kong", "Shufeng", ""], ["Bai", "Junwen", ""], ["Lee", "Jae Hee", ""], ["Chen", "Di", ""], ["Allyn", "Andrew", ""], ["Stuart", "Michelle", ""], ["Pinsky", "Malin", ""], ["Mills", "Katherine", ""], ["Gomes", "Carla P.", ""]]}, {"id": "2010.16052", "submitter": "Kamran Kowsari", "authors": "Mehrdad Fazli, Kamran Kowsari, Erfaneh Gharavi, Laura Barnes, Afsaneh\n  Doryab", "title": "HHAR-net: Hierarchical Human Activity Recognition using Neural Networks", "comments": "Accepted in IHCI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition using built-in sensors in smart and wearable devices\nprovides great opportunities to understand and detect human behavior in the\nwild and gives a more holistic view of individuals' health and well being.\nNumerous computational methods have been applied to sensor streams to recognize\ndifferent daily activities. However, most methods are unable to capture\ndifferent layers of activities concealed in human behavior. Also, the\nperformance of the models starts to decrease with increasing the number of\nactivities. This research aims at building a hierarchical classification with\nNeural Networks to recognize human activities based on different levels of\nabstraction. We evaluate our model on the Extrasensory dataset; a dataset\ncollected in the wild and containing data from smartphones and smartwatches. We\nuse a two-level hierarchy with a total of six mutually exclusive labels namely,\n\"lying down\", \"sitting\", \"standing in place\", \"walking\", \"running\", and\n\"bicycling\" divided into \"stationary\" and \"non-stationary\". The results show\nthat our model can recognize low-level activities (stationary/non-stationary)\nwith 95.8% accuracy and overall accuracy of 92.8% over six labels. This is 3%\nabove our best performing baseline.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:06:42 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 22:52:46 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Fazli", "Mehrdad", ""], ["Kowsari", "Kamran", ""], ["Gharavi", "Erfaneh", ""], ["Barnes", "Laura", ""], ["Doryab", "Afsaneh", ""]]}, {"id": "2010.16055", "submitter": "Jinyu Zhao", "authors": "Jinyu Zhao, Yi Hao, Cyrus Rashtchian", "title": "Unsupervised Embedding of Hierarchical Structure in Euclidean Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep embedding methods have influenced many areas of unsupervised learning.\nHowever, the best methods for learning hierarchical structure use non-Euclidean\nrepresentations, whereas Euclidean geometry underlies the theory behind many\nhierarchical clustering algorithms. To bridge the gap between these two areas,\nwe consider learning a non-linear embedding of data into Euclidean space as a\nway to improve the hierarchical clustering produced by agglomerative\nalgorithms. To learn the embedding, we revisit using a variational autoencoder\nwith a Gaussian mixture prior, and we show that rescaling the latent space\nembedding and then applying Ward's linkage-based algorithm leads to improved\nresults for both dendrogram purity and the Moseley-Wang cost function. Finally,\nwe complement our empirical results with a theoretical explanation of the\nsuccess of this approach. We study a synthetic model of the embedded vectors\nand prove that Ward's method exactly recovers the planted hierarchical\nclustering with high probability.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 03:57:09 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Zhao", "Jinyu", ""], ["Hao", "Yi", ""], ["Rashtchian", "Cyrus", ""]]}, {"id": "2010.16061", "submitter": "David Powers", "authors": "David M. W. Powers", "title": "Evaluation: from precision, recall and F-measure to ROC, informedness,\n  markedness and correlation", "comments": "27 pages, 7 figures. Updated and fixed egregious formatting errors\n  (including a table overlapping text) that were introduced by the publisher.\n  This open access journal appears to have been discontinued. arXiv admin note:\n  text overlap with arXiv:1504.00854", "journal-ref": "International Journal of Machine Learning Technology 2:1 (2011),\n  pp.37-63", "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonly used evaluation measures including Recall, Precision, F-Measure and\nRand Accuracy are biased and should not be used without clear understanding of\nthe biases, and corresponding identification of chance or base case levels of\nthe statistic. Using these measures a system that performs worse in the\nobjective sense of Informedness, can appear to perform better under any of\nthese commonly used measures. We discuss several concepts and measures that\nreflect the probability that prediction is informed versus chance. Informedness\nand introduce Markedness as a dual measure for the probability that prediction\nis marked versus chance. Finally we demonstrate elegant connections between the\nconcepts of Informedness, Markedness, Correlation and Significance as well as\ntheir intuitive relationships with Recall and Precision, and outline the\nextension from the dichotomous case to the general multi-class case.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 02:15:11 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Powers", "David M. W.", ""]]}, {"id": "2010.16087", "submitter": "Kazuki Nakamura", "authors": "Kazuki Nakamura, Ryosuke Kojima, Eiichiro Uchino, Koichi Murashita,\n  Ken Itoh, Shigeyuki Nakaji and Yasushi Okuno", "title": "Health improvement framework for planning actionable treatment process\n  using surrogate Bayesian model", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-021-23319-1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision making regarding treatments based on personal\ncharacteristics leads to effective health improvements. Machine learning (ML)\nhas been the primary concern of diagnosis support according to comprehensive\npatient information. However, the remaining prominent issue is the development\nof objective treatment processes in clinical situations. This study proposes a\nnovel framework to plan treatment processes in a data-driven manner. A key\npoint of the framework is the evaluation of the \"actionability\" for personal\nhealth improvements by using a surrogate Bayesian model in addition to a\nhigh-performance nonlinear ML model. We first evaluated the framework from the\nviewpoint of its methodology using a synthetic dataset. Subsequently, the\nframework was applied to an actual health checkup dataset comprising data from\n3,132 participants, to improve systolic blood pressure values at the individual\nlevel. We confirmed that the computed treatment processes are actionable and\nconsistent with clinical knowledge for lowering blood pressure. These results\ndemonstrate that our framework could contribute toward decision making in the\nmedical field, providing clinicians with deeper insights.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 06:02:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:13:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nakamura", "Kazuki", ""], ["Kojima", "Ryosuke", ""], ["Uchino", "Eiichiro", ""], ["Murashita", "Koichi", ""], ["Itoh", "Ken", ""], ["Nakaji", "Shigeyuki", ""], ["Okuno", "Yasushi", ""]]}, {"id": "2010.16091", "submitter": "Yanqiao Zhu", "authors": "Yanqiao Zhu and Weizhi Xu and Qiang Liu and Shu Wu", "title": "When Contrastive Learning Meets Active Learning: A Novel Graph Active\n  Learning Paradigm with Self-Supervision", "comments": "Preliminary work, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies active learning (AL) on graphs, whose purpose is to\ndiscover the most informative nodes to maximize the performance of graph neural\nnetworks (GNNs). Previously, most graph AL methods focus on learning node\nrepresentations from a carefully selected labeled dataset with large amount of\nunlabeled data neglected. Motivated by the success of contrastive learning\n(CL), we propose a novel paradigm that seamlessly integrates graph AL with CL.\nWhile being able to leverage the power of abundant unlabeled data in a\nself-supervised manner, nodes selected by AL further provide semantic\ninformation that can better guide representation learning. Besides, previous\nwork measures the informativeness of nodes without considering the neighborhood\npropagation scheme of GNNs, so that noisy nodes may be selected. We argue that\ndue to the smoothing nature of GNNs, the central nodes from homophilous\nsubgraphs should benefit the model training most. To this end, we present a\nminimax selection scheme that explicitly harnesses neighborhood information and\ndiscover homophilous subgraphs to facilitate active selection. Comprehensive,\nconfounding-free experiments on five public datasets demonstrate the\nsuperiority of our method over state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 06:20:07 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 12:28:32 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhu", "Yanqiao", ""], ["Xu", "Weizhi", ""], ["Liu", "Qiang", ""], ["Wu", "Shu", ""]]}, {"id": "2010.16132", "submitter": "Yacouba Kaloga", "authors": "Yacouba Kaloga and Pierre Borgnat and Sundeep Prabhakar Chepuri and\n  Patrice Abry and Amaury Habrard", "title": "Multiview Variational Graph Autoencoders for Canonical Correlation\n  Analysis", "comments": "4 pages, 3 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel multiview canonical correlation analysis model based on a\nvariational approach. This is the first nonlinear model that takes into account\nthe available graph-based geometric constraints while being scalable for\nprocessing large scale datasets with multiple views. It is based on an\nautoencoder architecture with graph convolutional neural network layers. We\nexperiment with our approach on classification, clustering, and recommendation\ntasks on real datasets. The algorithm is competitive with state-of-the-art\nmultiview representation learning techniques.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 09:08:05 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 23:00:43 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Kaloga", "Yacouba", ""], ["Borgnat", "Pierre", ""], ["Chepuri", "Sundeep Prabhakar", ""], ["Abry", "Patrice", ""], ["Habrard", "Amaury", ""]]}, {"id": "2010.16138", "submitter": "Yunqi Cai", "authors": "Yunqi Cai, Dong Wang", "title": "Deep generative LDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear discriminant analysis (LDA) is a popular tool for classification and\ndimension reduction. Limited by its linear form and the underlying Gaussian\nassumption, however, LDA is not applicable in situations where the data\ndistribution is complex. Recently, we proposed a discriminative normalization\nflow (DNF) model. In this study, we reinterpret DNF as a deep generative LDA\nmodel, and study its properties in representing complex data. We conducted a\nsimulation experiment and a speaker recognition experiment. The results show\nthat DNF and its subspace version are much more powerful than the conventional\nLDA in modeling complex data and retrieving low-dimensional representations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 09:23:25 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Cai", "Yunqi", ""], ["Wang", "Dong", ""]]}, {"id": "2010.16181", "submitter": "Magda Amiridi", "authors": "Magda Amiridi, Nikos Kargas, Nicholas D. Sidiropoulos", "title": "Information-theoretic Feature Selection via Tensor Decomposition and\n  Submodularity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection by maximizing high-order mutual information between the\nselected feature vector and a target variable is the gold standard in terms of\nselecting the best subset of relevant features that maximizes the performance\nof prediction models. However, such an approach typically requires knowledge of\nthe multivariate probability distribution of all features and the target, and\ninvolves a challenging combinatorial optimization problem. Recent work has\nshown that any joint Probability Mass Function (PMF) can be represented as a\nnaive Bayes model, via Canonical Polyadic (tensor rank) Decomposition. In this\npaper, we introduce a low-rank tensor model of the joint PMF of all variables\nand indirect targeting as a way of mitigating complexity and maximizing the\nclassification performance for a given number of features. Through low-rank\nmodeling of the joint PMF, it is possible to circumvent the curse of\ndimensionality by learning principal components of the joint distribution. By\nindirectly aiming to predict the latent variable of the naive Bayes model\ninstead of the original target variable, it is possible to formulate the\nfeature selection problem as maximization of a monotone submodular function\nsubject to a cardinality constraint - which can be tackled using a greedy\nalgorithm that comes with performance guarantees. Numerical experiments with\nseveral standard datasets suggest that the proposed approach compares favorably\nto the state-of-art for this important problem.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 10:36:46 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Amiridi", "Magda", ""], ["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2010.16223", "submitter": "Nicolas Gillis", "authors": "Valentin Leplat, Nicolas Gillis, J\\'er\\^ome Idier", "title": "Multiplicative Updates for NMF with $\\beta$-Divergences under Disjoint\n  Equality Constraints", "comments": "23 pages + 6 pages of supplementary materials", "journal-ref": "SIAM J. on Matrix Analysis and its Applications 42 (2), 730-752,\n  2021", "doi": "10.1137/20M1377278", "report-no": null, "categories": "cs.LG cs.NA eess.SP math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is the problem of approximating an\ninput nonnegative matrix, $V$, as the product of two smaller nonnegative\nmatrices, $W$ and $H$. In this paper, we introduce a general framework to\ndesign multiplicative updates (MU) for NMF based on $\\beta$-divergences\n($\\beta$-NMF) with disjoint equality constraints, and with penalty terms in the\nobjective function. By disjoint, we mean that each variable appears in at most\none equality constraint. Our MU satisfy the set of constraints after each\nupdate of the variables during the optimization process, while guaranteeing\nthat the objective function decreases monotonically. We showcase this framework\non three NMF models, and show that it competes favorably the state of the art:\n(1)~$\\beta$-NMF with sum-to-one constraints on the columns of $H$, (2)\nminimum-volume $\\beta$-NMF with sum-to-one constraints on the columns of $W$,\nand (3) sparse $\\beta$-NMF with $\\ell_2$-norm constraints on the columns of\n$W$.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:31:35 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Leplat", "Valentin", ""], ["Gillis", "Nicolas", ""], ["Idier", "J\u00e9r\u00f4me", ""]]}, {"id": "2010.16228", "submitter": "Gerasimos Spanakis", "authors": "Thalea Schlender and Gerasimos Spanakis", "title": "\"Thy algorithm shalt not bear false witness\": An Evaluation of\n  Multiclass Debiasing Methods on Word Embeddings", "comments": "15 pages, presented at BNAIC/BENELEARN 2020, data/code at\n  https://github.com/thaleaschlender/An-Evaluation-of-Multiclass-Debiasing-Methods-on-Word-Embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the vast development and employment of artificial intelligence\napplications, research into the fairness of these algorithms has been\nincreased. Specifically, in the natural language processing domain, it has been\nshown that social biases persist in word embeddings and are thus in danger of\namplifying these biases when used. As an example of social bias, religious\nbiases are shown to persist in word embeddings and the need for its removal is\nhighlighted. This paper investigates the state-of-the-art multiclass debiasing\ntechniques: Hard debiasing, SoftWEAT debiasing and Conceptor debiasing. It\nevaluates their performance when removing religious bias on a common basis by\nquantifying bias removal via the Word Embedding Association Test (WEAT), Mean\nAverage Cosine Similarity (MAC) and the Relative Negative Sentiment Bias\n(RNSB). By investigating the religious bias removal on three widely used word\nembeddings, namely: Word2Vec, GloVe, and ConceptNet, it is shown that the\npreferred method is ConceptorDebiasing. Specifically, this technique manages to\ndecrease the measured religious bias on average by 82,42%, 96,78% and 54,76%\nfor the three word embedding sets respectively.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:49:39 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 09:24:21 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Schlender", "Thalea", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "2010.16271", "submitter": "Wouter van Loon", "authors": "Wouter van Loon, Marjolein Fokkema, Botond Szabo, Mark de Rooij", "title": "View selection in multi-view stacking: Choosing the meta-learner", "comments": "37 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view stacking is a framework for combining information from different\nviews (i.e. different feature sets) describing the same set of objects. In this\nframework, a base-learner algorithm is trained on each view separately, and\ntheir predictions are then combined by a meta-learner algorithm. In a previous\nstudy, stacked penalized logistic regression, a special case of multi-view\nstacking, has been shown to be useful in identifying which views are most\nimportant for prediction. In this article we expand this research by\nconsidering seven different algorithms to use as the meta-learner, and\nevaluating their view selection and classification performance in simulations\nand two applications on real gene-expression data sets. Our results suggest\nthat if both view selection and classification accuracy are important to the\nresearch at hand, then the nonnegative lasso, nonnegative adaptive lasso and\nnonnegative elastic net are suitable meta-learners. Exactly which among these\nthree is to be preferred depends on the research context. The remaining four\nmeta-learners, namely nonnegative ridge regression, nonnegative forward\nselection, stability selection and the interpolating predictor, show little\nadvantages in order to be preferred over the other three.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 13:45:14 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["van Loon", "Wouter", ""], ["Fokkema", "Marjolein", ""], ["Szabo", "Botond", ""], ["de Rooij", "Mark", ""]]}, {"id": "2010.16295", "submitter": "Luca Ganassali", "authors": "Luca Ganassali", "title": "Sharp threshold for alignment of graph databases with Gaussian weights", "comments": "18 pages, 2 figures. Revised version: Remark 3 updated, typos\n  corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental limits for reconstruction in weighted graph (or\nmatrix) database alignment. We consider a model of two graphs where $\\pi^*$ is\na planted uniform permutation and all pairs of edge weights $(A_{i,j},\nB_{\\pi^*(i),\\pi^*(j)})_{1 \\leq i<j \\leq n}$ are i.i.d. pairs of Gaussian\nvariables with zero mean, unit variance and correlation parameter $\\rho \\in\n[0,1]$. We prove that there is a sharp threshold for exact recovery of $\\pi^*$:\nif $n \\rho^2 \\geq (4+\\epsilon) \\log n + \\omega(1)$ for some $\\epsilon>0$, there\nis an estimator $\\hat{\\pi}$ -- namely the MAP estimator -- based on the\nobservation of databases $A,B$ that achieves exact reconstruction with high\nprobability. Conversely, if $n \\rho^2 \\leq 4 \\log n - \\log \\log n - \\omega(1)$,\nthen any estimator $\\hat{\\pi}$ verifies $\\hat{\\pi}=\\pi$ with probability\n$o(1)$.\n  This result shows that the information-theoretic threshold for exact recovery\nis the same as the one obtained for detection in a recent work by Wu et al.\n(2020): in other words, for Gaussian weighted graph alignment, the problem of\nreconstruction is not more difficult than that of detection. Though the\nreconstruction task was already well understood for vector-shaped database\nalignment (that is taking signal of the form $(u_i, v_{\\pi^*(i)})_{1 \\leq i\\leq\nn}$ where $(u_i, v_{\\pi^*(i)})$ are i.i.d. pairs in $\\mathbb{R}^{d_u} \\times\n\\mathbb{R}^{d_v}$), its formulation for graph (or matrix) databases brings a\ndrastically different problem for which the hard phase is conjectured to be\nwide.\n  The proofs build upon the analysis of the MAP estimator and the second moment\nmethod, together with the study of the correlation structure of energies of\npermutations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:42:17 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 14:46:09 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ganassali", "Luca", ""]]}, {"id": "2010.16326", "submitter": "Ievgen Redko", "authors": "Charlotte Laclau, Ievgen Redko, Manvi Choudhary, Christine Largeron", "title": "All of the Fairness for Edge Prediction with Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining algorithms have been increasingly used\nrecently to support decision-making systems in many areas of high societal\nimportance such as healthcare, education, or security. While being very\nefficient in their predictive abilities, the deployed algorithms sometimes tend\nto learn an inductive model with a discriminative bias due to the presence of\nthis latter in the learning sample. This problem gave rise to a new field of\nalgorithmic fairness where the goal is to correct the discriminative bias\nintroduced by a certain attribute in order to decorrelate it from the model's\noutput. In this paper, we study the problem of fairness for the task of edge\nprediction in graphs, a largely underinvestigated scenario compared to a more\npopular setting of fair classification. To this end, we formulate the problem\nof fair edge prediction, analyze it theoretically, and propose an\nembedding-agnostic repairing procedure for the adjacency matrix of an arbitrary\ngraph with a trade-off between the group and individual fairness. We\nexperimentally show the versatility of our approach and its capacity to provide\nexplicit control over different notions of fairness and prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 15:33:13 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Laclau", "Charlotte", ""], ["Redko", "Ievgen", ""], ["Choudhary", "Manvi", ""], ["Largeron", "Christine", ""]]}, {"id": "2010.16344", "submitter": "Fergus Simpson", "authors": "Fergus Simpson, Vidhi Lalchand, Carl Edward Rasmussen", "title": "Marginalised Gaussian Processes with Nested Sampling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process (GPs) models are a rich distribution over functions with\ninductive biases controlled by a kernel function. Learning occurs through the\noptimisation of kernel hyperparameters using the marginal likelihood as the\nobjective. This classical approach known as Type-II maximum likelihood (ML-II)\nyields point estimates of the hyperparameters, and continues to be the default\nmethod for training GPs. However, this approach risks underestimating\npredictive uncertainty and is prone to overfitting especially when there are\nmany hyperparameters. Furthermore, gradient based optimisation makes ML-II\npoint estimates highly susceptible to the presence of local minima. This work\npresents an alternative learning procedure where the hyperparameters of the\nkernel function are marginalised using Nested Sampling (NS), a technique that\nis well suited to sample from complex, multi-modal distributions. We focus on\nregression tasks with the spectral mixture (SM) class of kernels and find that\na principled approach to quantifying model uncertainty leads to substantial\ngains in predictive performance across a range of synthetic and benchmark data\nsets. In this context, nested sampling is also found to offer a speed advantage\nover Hamiltonian Monte Carlo (HMC), widely considered to be the gold-standard\nin MCMC based inference.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 16:04:35 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Simpson", "Fergus", ""], ["Lalchand", "Vidhi", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "2010.16358", "submitter": "Romain Egele", "authors": "Romain Egele, Prasanna Balaprakash, Venkatram Vishwanath, Isabelle\n  Guyon, Zhengying Liu", "title": "AgEBO-Tabular: Joint Neural Architecture and Hyperparameter Search with\n  Autotuned Data-Parallel Training for Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing high-performing predictive models for large tabular data sets is a\nchallenging task. The state-of-the-art methods are based on expert-developed\nmodel ensembles from different supervised learning methods. Recently, automated\nmachine learning (AutoML) is emerging as a promising approach to automate\npredictive model development. Neural architecture search (NAS) is an AutoML\napproach that generates and evaluates multiple neural network architectures\nconcurrently and improves the accuracy of the generated models iteratively. A\nkey issue in NAS, particularly for large data sets, is the large computation\ntime required to evaluate each generated architecture. While data-parallel\ntraining is a promising approach that can address this issue, its use within\nNAS is difficult. For different data sets, the data-parallel training settings\nsuch as the number of parallel processes, learning rate, and batch size need to\nbe adapted to achieve high accuracy and reduction in training time. To that\nend, we have developed AgEBO-Tabular, an approach to combine aging evolution\n(AgE), a parallel NAS method that searches over neural architecture space, and\nan asynchronous Bayesian optimization method for tuning the hyperparameters of\nthe data-parallel training simultaneously. We demonstrate the efficacy of the\nproposed method to generate high-performing neural network models for large\ntabular benchmark data sets. Furthermore, we demonstrate that the automatically\ndiscovered neural network models using our method outperform the\nstate-of-the-art AutoML ensemble models in inference speed by two orders of\nmagnitude while reaching similar accuracy values.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 16:28:48 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Egele", "Romain", ""], ["Balaprakash", "Prasanna", ""], ["Vishwanath", "Venkatram", ""], ["Guyon", "Isabelle", ""], ["Liu", "Zhengying", ""]]}, {"id": "2010.16412", "submitter": "Kartik Ahuja", "authors": "Kartik Ahuja, Jun Wang, Amit Dhurandhar, Karthikeyan Shanmugam, Kush\n  R. Varshney", "title": "Empirical or Invariant Risk Minimization? A Sample Complexity\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, invariant risk minimization (IRM) was proposed as a promising\nsolution to address out-of-distribution (OOD) generalization. However, it is\nunclear when IRM should be preferred over the widely-employed empirical risk\nminimization (ERM) framework. In this work, we analyze both these frameworks\nfrom the perspective of sample complexity, thus taking a firm step towards\nanswering this important question. We find that depending on the type of data\ngeneration mechanism, the two approaches might have very different finite\nsample and asymptotic behavior. For example, in the covariate shift setting we\nsee that the two approaches not only arrive at the same asymptotic solution,\nbut also have similar finite sample behavior with no clear winner. For other\ndistribution shifts such as those involving confounders or anti-causal\nvariables, however, the two approaches arrive at different asymptotic solutions\nwhere IRM is guaranteed to be close to the desired OOD solutions in the finite\nsample regime, while ERM is biased even asymptotically. We further investigate\nhow different factors -- the number of environments, complexity of the model,\nand IRM penalty weight -- impact the sample complexity of IRM in relation to\nits distance from the OOD solutions\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:55:30 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ahuja", "Kartik", ""], ["Wang", "Jun", ""], ["Dhurandhar", "Amit", ""], ["Shanmugam", "Karthikeyan", ""], ["Varshney", "Kush R.", ""]]}, {"id": "2010.16418", "submitter": "Jiaxuan You", "authors": "Jiaxuan You, Xiaobai Ma, Daisy Yi Ding, Mykel Kochenderfer, Jure\n  Leskovec", "title": "Handling Missing Data with Graph Representation Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning with missing data has been approached in two different ways,\nincluding feature imputation where missing feature values are estimated based\non observed values, and label prediction where downstream labels are learned\ndirectly from incomplete data. However, existing imputation models tend to have\nstrong prior assumptions and cannot learn from downstream tasks, while models\ntargeting label prediction often involve heuristics and can encounter\nscalability issues. Here we propose GRAPE, a graph-based framework for feature\nimputation as well as label prediction. GRAPE tackles the missing data problem\nusing a graph representation, where the observations and features are viewed as\ntwo types of nodes in a bipartite graph, and the observed feature values as\nedges. Under the GRAPE framework, the feature imputation is formulated as an\nedge-level prediction task and the label prediction as a node-level prediction\ntask. These tasks are then solved with Graph Neural Networks. Experimental\nresults on nine benchmark datasets show that GRAPE yields 20% lower mean\nabsolute error for imputation tasks and 10% lower for label prediction tasks,\ncompared with existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:59:13 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["You", "Jiaxuan", ""], ["Ma", "Xiaobai", ""], ["Ding", "Daisy Yi", ""], ["Kochenderfer", "Mykel", ""], ["Leskovec", "Jure", ""]]}]