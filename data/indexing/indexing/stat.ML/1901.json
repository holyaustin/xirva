[{"id": "1901.00001", "submitter": "Yuri G. Gordienko", "authors": "Vlad Taran, Yuri Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii\n  Stirenko", "title": "Impact of Ground Truth Annotation Quality on Performance of Semantic\n  Image Segmentation of Traffic Conditions", "comments": "10 pages, 6 figures, 2 tables, The Second International Conference on\n  Computer Science, Engineering and Education Applications (ICCSEEA2019) 26-27\n  January 2019, Kiev, Ukraine", "journal-ref": "Hu Z., Petoukhov S., Dychka I., He M. (eds) Advances in Computer\n  Science for Engineering and Education II. ICCSEEA 2019. Advances in\n  Intelligent Systems and Computing, vol 938 (pp.183-193). Springer, Cham", "doi": "10.1007/978-3-030-16621-2_17", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preparation of high-quality datasets for the urban scene understanding is a\nlabor-intensive task, especially, for datasets designed for the autonomous\ndriving applications. The application of the coarse ground truth (GT)\nannotations of these datasets without detriment to the accuracy of semantic\nimage segmentation (by the mean intersection over union - mIoU) could simplify\nand speedup the dataset preparation and model fine tuning before its practical\napplication. Here the results of the comparative analysis for semantic\nsegmentation accuracy obtained by PSPNet deep learning architecture are\npresented for fine and coarse annotated images from Cityscapes dataset. Two\nscenarios were investigated: scenario 1 - the fine GT images for training and\nprediction, and scenario 2 - the fine GT images for training and the coarse GT\nimages for prediction. The obtained results demonstrated that for the most\nimportant classes the mean accuracy values of semantic image segmentation for\ncoarse GT annotations are higher than for the fine GT ones, and the standard\ndeviation values are vice versa. It means that for some applications some\nunimportant classes can be excluded and the model can be tuned further for some\nclasses and specific regions on the coarse GT dataset without loss of the\naccuracy even. Moreover, this opens the perspectives to use deep neural\nnetworks for the preparation of such coarse GT datasets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 09:19:55 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Taran", "Vlad", ""], ["Gordienko", "Yuri", ""], ["Rokovyi", "Alexandr", ""], ["Alienin", "Oleg", ""], ["Stirenko", "Sergii", ""]]}, {"id": "1901.00032", "submitter": "Edward Kim", "authors": "Edward Kim, Zach Jensen, Alexander van Grootel, Kevin Huang, Matthew\n  Staib, Sheshera Mysore, Haw-Shiuan Chang, Emma Strubell, Andrew McCallum,\n  Stefanie Jegelka, Elsa Olivetti", "title": "Inorganic Materials Synthesis Planning with Literature-Trained Neural\n  Networks", "comments": "Added new funding support to the acknowledgments section in this\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging new data sources is a key step in accelerating the pace of\nmaterials design and discovery. To complement the strides in synthesis planning\ndriven by historical, experimental, and computed data, we present an automated\nmethod for connecting scientific literature to synthesis insights. Starting\nfrom natural language text, we apply word embeddings from language models,\nwhich are fed into a named entity recognition model, upon which a conditional\nvariational autoencoder is trained to generate syntheses for arbitrary\nmaterials. We show the potential of this technique by predicting precursors for\ntwo perovskite materials, using only training data published over a decade\nprior to their first reported syntheses. We demonstrate that the model learns\nrepresentations of materials corresponding to synthesis-related properties, and\nthat the model's behavior complements existing thermodynamic knowledge.\nFinally, we apply the model to perform synthesizability screening for proposed\nnovel perovskite compounds.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 20:03:01 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 16:35:34 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kim", "Edward", ""], ["Jensen", "Zach", ""], ["van Grootel", "Alexander", ""], ["Huang", "Kevin", ""], ["Staib", "Matthew", ""], ["Mysore", "Sheshera", ""], ["Chang", "Haw-Shiuan", ""], ["Strubell", "Emma", ""], ["McCallum", "Andrew", ""], ["Jegelka", "Stefanie", ""], ["Olivetti", "Elsa", ""]]}, {"id": "1901.00035", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Convex Relaxations of Convolutional Neural Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose convex relaxations for convolutional neural nets with one hidden\nlayer where the output weights are fixed. For convex activation functions such\nas rectified linear units, the relaxations are convex second order cone\nprograms which can be solved very efficiently. We prove that the relaxation\nrecovers the global minimum under a planted model assumption, given\nsufficiently many training samples from a Gaussian distribution. We also\nidentify a phase transition phenomenon in recovering the global minimum for the\nrelaxation.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 20:21:48 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "1901.00039", "submitter": "Shengqin Jiang", "authors": "Shengqin Jiang, Xiaobo Lu, Yinjie Lei, Lingqiao Liu", "title": "Mask-aware networks for crowd counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crowd counting problem aims to count the number of objects within an image or\na frame in the videos and is usually solved by estimating the density map\ngenerated from the object location annotations. The values in the density map,\nby nature, take two possible states: zero indicating no object around, a\nnon-zero value indicating the existence of objects and the value denoting the\nlocal object density. In contrast to traditional methods which do not\ndifferentiate the density prediction of these two states, we propose to use a\ndedicated network branch to predict the object/non-object mask and then combine\nits prediction with the input image to produce the density map. Our rationale\nis that the mask prediction could be better modeled as a binary segmentation\nproblem and the difficulty of estimating the density could be reduced if the\nmask is known. A key to the proposed scheme is the strategy of incorporating\nthe mask prediction into the density map estimator. To this end, we study five\npossible solutions, and via analysis and experimental validation we identify\nthe most effective one. Through extensive experiments on five public datasets,\nwe demonstrate the superior performance of the proposed approach over the\nbaselines and show that our network could achieve the state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 03:32:42 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 02:20:04 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Jiang", "Shengqin", ""], ["Lu", "Xiaobo", ""], ["Lei", "Yinjie", ""], ["Liu", "Lingqiao", ""]]}, {"id": "1901.00054", "submitter": "Long Zhang", "authors": "Long Zhang, Xuechao Sun, Yong Li and Zhenyu Zhang", "title": "A Noise-Sensitivity-Analysis-Based Test Prioritization Technique for\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been widely used in the fields such as\nnatural language processing, computer vision and image recognition. But several\nstudies have been shown that deep neural networks can be easily fooled by\nartificial examples with some perturbations, which are widely known as\nadversarial examples. Adversarial examples can be used to attack deep neural\nnetworks or to improve the robustness of deep neural networks. A common way of\ngenerating adversarial examples is to first generate some noises and then add\nthem into original examples. In practice, different examples have different\nnoise-sensitive. To generate an effective adversarial example, it may be\nnecessary to add a lot of noise to low noise-sensitive example, which may make\nthe adversarial example meaningless. In this paper, we propose a\nnoise-sensitivity-analysis-based test prioritization technique to pick out\nexamples by their noise sensitivity. We construct an experiment to validate our\napproach on four image sets and two DNN models, which shows that examples are\nsensitive to noise and our method can effectively pick out examples by their\nnoise sensitivity.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 06:42:59 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 08:07:57 GMT"}, {"version": "v3", "created": "Sun, 20 Jan 2019 02:12:25 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zhang", "Long", ""], ["Sun", "Xuechao", ""], ["Li", "Yong", ""], ["Zhang", "Zhenyu", ""]]}, {"id": "1901.00055", "submitter": "Hao Xiong", "authors": "Hao Xiong, Chaoyue Wang, Dacheng Tao, Michael Barnett, Chenyu Wang", "title": "Multiple Sclerosis Lesion Inpainting Using Non-Local Partial\n  Convolutions", "comments": "We make significant changes to the paper and do not plan to submit\n  current version to arXiv until it is accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis (MS) is an inflammatory demyelinating disease of the\ncentral nervous system (CNS) that results in focal injury to the grey and white\nmatter. The presence of white matter lesions biases morphometric analyses such\nas registration, individual longitudinal measurements and tissue segmentation\nfor brain volume measurements. Lesion-inpainting with intensities derived from\nsurrounding healthy tissue represents one approach to alleviate such problems.\nHowever, existing methods inpaint lesions based on texture information derived\nfrom local surrounding tissue, often leading to inconsistent inpainting and the\ngeneration of artifacts such as intensity discrepancy and blurriness. Based on\nthese observations, we propose non-local partial convolutions (NLPC) that\nintegrates a Unet-like network with the non-local module. The non-local module\nis exploited to capture long range dependencies between the lesion area and\nremaining normal-appearing brain regions. Then, the lesion area is filled by\nreferring to normal-appearing regions with more similar features. This method\ngenerates inpainted regions that appear more realistic and natural. Our\nquantitative experimental results also demonstrate superiority of this\ntechnique of existing state-of-the-art inpainting methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 12:56:56 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 10:53:38 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 07:24:41 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Xiong", "Hao", ""], ["Wang", "Chaoyue", ""], ["Tao", "Dacheng", ""], ["Barnett", "Michael", ""], ["Wang", "Chenyu", ""]]}, {"id": "1901.00059", "submitter": "Ami Tavory", "authors": "Ami Tavory", "title": "Determining Principal Component Cardinality through the Principle of\n  Minimum Description Length", "comments": "LOD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PCA (Principal Component Analysis) and its variants areubiquitous techniques\nfor matrix dimension reduction and reduced-dimensionlatent-factor extraction.\nOne significant challenge in using PCA, is thechoice of the number of principal\ncomponents. The information-theoreticMDL (Minimum Description Length) principle\ngives objective compression-based criteria for model selection, but it is\ndifficult to analytically applyits modern definition - NML (Normalized Maximum\nLikelihood) - to theproblem of PCA. This work shows a general reduction of NML\nprob-lems to lower-dimension problems. Applying this reduction, it boundsthe\nNML of PCA, by terms of the NML of linear regression, which areknown.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 22:41:32 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 18:16:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Tavory", "Ami", ""]]}, {"id": "1901.00069", "submitter": "G\\'abor Petneh\\'azi", "authors": "G\\'abor Petneh\\'azi", "title": "Recurrent Neural Networks for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is difficult. It is difficult even for recurrent\nneural networks with their inherent ability to learn sequentiality. This\narticle presents a recurrent neural network based time series forecasting\nframework covering feature engineering, feature importances, point and interval\npredictions, and forecast evaluation. The description of the method is followed\nby an empirical study using both LSTM and GRU networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 00:52:01 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Petneh\u00e1zi", "G\u00e1bor", ""]]}, {"id": "1901.00072", "submitter": "Sean Robertson", "authors": "Sean Robertson, Gerald Penn, Yingxue Wang", "title": "Exploring spectro-temporal features in end-to-end convolutional neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangular, overlapping Mel-scaled filters (\"f-banks\") are the current\nstandard input for acoustic models that exploit their input's time-frequency\ngeometry, because they provide a psycho-acoustically motivated time-frequency\ngeometry for a speech signal. F-bank coefficients are provably robust to small\ndeformations in the scale. In this paper, we explore two ways in which filter\nbanks can be adjusted for the purposes of speech recognition. First, triangular\nfilters can be replaced with Gabor filters, a compactly supported filter that\nbetter localizes events in time, or Gammatone filters, a\npsychoacoustically-motivated filter. Second, by rearranging the order of\noperations in computing filter bank features, features can be integrated over\nsmaller time scales while simultaneously providing better frequency resolution.\nWe make all feature implementations available online through open-source\nrepositories. Initial experimentation with a modern end-to-end CNN phone\nrecognizer yielded no significant improvements to phone error rate due to\neither modification. The result, and its ramifications with respect to learned\nfilter banks, is discussed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 01:17:26 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Robertson", "Sean", ""], ["Penn", "Gerald", ""], ["Wang", "Yingxue", ""]]}, {"id": "1901.00106", "submitter": "Zhipeng Li", "authors": "Zhipeng Li and Saiprasad Ravishankar and Yong Long and Jeffrey A.\n  Fessler", "title": "DECT-MULTRA: Dual-Energy CT Image Decomposition With Learned Mixed\n  Material Models and Efficient Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual energy computed tomography (DECT) imaging plays an important role in\nadvanced imaging applications due to its material decomposition capability.\nImage-domain decomposition operates directly on CT images using linear matrix\ninversion, but the decomposed material images can be severely degraded by noise\nand artifacts. This paper proposes a new method dubbed DECT-MULTRA for\nimage-domain DECT material decomposition that combines conventional penalized\nweighted-least squares (PWLS) estimation with regularization based on a mixed\nunion of learned transforms (MULTRA) model. Our proposed approach pre-learns a\nunion of common-material sparsifying transforms from patches extracted from all\nthe basis materials, and a union of cross-material sparsifying transforms from\nmulti-material patches. The common-material transforms capture the common\nproperties among different material images, while the cross-material transforms\ncapture the cross-dependencies. The proposed PWLS formulation is optimized\nefficiently by alternating between an image update step and a sparse coding and\nclustering step, with both of these steps having closed-form solutions. The\neffectiveness of our method is validated with both XCAT phantom and clinical\nhead data. The results demonstrate that our proposed method provides superior\nmaterial image quality and decomposition accuracy compared to other competing\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 06:47:12 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 05:46:39 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Li", "Zhipeng", ""], ["Ravishankar", "Saiprasad", ""], ["Long", "Yong", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1901.00109", "submitter": "Ranjan Mondal", "authors": "Ranjan Mondal, Soumendu Sundar Mukherjee, Sanchayan Santra and\n  Bhabatosh Chanda", "title": "Morphological Network: How Far Can We Go with Morphological Neurons?", "comments": "35 pages, 19 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the idea of using morphological operations as networks has\nreceived much attention. Mathematical morphology provides very efficient and\nuseful image processing and image analysis tools based on basic operators like\ndilation and erosion, defined in terms of kernels. Many other morphological\noperations are built up using the dilation and erosion operations. Although the\nlearning of structuring elements such as dilation or erosion using the\nbackpropagation algorithm is not new, the order and the way these morphological\noperations are used is not standard. In this paper, we have theoretically\nanalyzed the use of morphological operations for processing 1D feature vectors\nand shown that this gets extended to the 2D case in a simple manner. Our\ntheoretical results show that a morphological block represents a sum of hinge\nfunctions. Hinge functions are used in many places for classification and\nregression tasks (Breiman (1993)). We have also proved a universal\napproximation theorem -- a stack of two morphological blocks can approximate\nany continuous function over arbitrary compact sets. To experimentally validate\nthe efficacy of this network in real-life applications, we have evaluated its\nperformance on satellite image classification datasets since morphological\noperations are very sensitive to geometrical shapes and structures. We have\nalso shown results on a few tasks like segmentation of blood vessels from\nfundus images, segmentation of lungs from chest x-ray and image dehazing. The\nresults are encouraging and further establishes the potential of morphological\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 07:52:24 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 19:19:40 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 22:21:21 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mondal", "Ranjan", ""], ["Mukherjee", "Soumendu Sundar", ""], ["Santra", "Sanchayan", ""], ["Chanda", "Bhabatosh", ""]]}, {"id": "1901.00117", "submitter": "Sai Kiran Narayanaswami", "authors": "Sai Kiran Narayanaswami, Nandan Sudarsanam, Balaraman Ravindran", "title": "An Active Learning Framework for Efficient Robust Policy Search", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Policy Search is the problem of learning policies that do not degrade\nin performance when subject to unseen environment model parameters. It is\nparticularly relevant for transferring policies learned in a simulation\nenvironment to the real world. Several existing approaches involve sampling\nlarge batches of trajectories which reflect the differences in various possible\nenvironments, and then selecting some subset of these to learn robust policies,\nsuch as the ones that result in the worst performance. We propose an active\nlearning based framework, EffAcTS, to selectively choose model parameters for\nthis purpose so as to collect only as much data as necessary to select such a\nsubset. We apply this framework to an existing method, namely EPOpt, and\nexperimentally validate the gains in sample efficiency and the performance of\nour approach on standard continuous control tasks. We also present a Multi-Task\nLearning perspective to the problem of Robust Policy Search, and draw\nconnections from our proposed framework to existing work on Multi-Task\nLearning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 08:50:47 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Narayanaswami", "Sai Kiran", ""], ["Sudarsanam", "Nandan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1901.00120", "submitter": "Mundher Al-Shabi", "authors": "Mundher Al-Shabi, Hwee Kuan Lee, Maxine Tan", "title": "Gated-Dilated Networks for Lung Nodule Classification in CT scans", "comments": "Published in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2958663", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different types of Convolutional Neural Networks (CNNs) have been applied to\ndetect cancerous lung nodules from computed tomography (CT) scans. However, the\nsize of a nodule is very diverse and can range anywhere between 3 and 30\nmillimeters. The high variation of nodule sizes makes classifying them a\ndifficult and challenging task. In this study, we propose a novel CNN\narchitecture called Gated-Dilated (GD) networks to classify nodules as\nmalignant or benign. Unlike previous studies, the GD network uses multiple\ndilated convolutions instead of max-poolings to capture the scale variations.\nMoreover, the GD network has a Context-Aware sub-network that analyzes the\ninput features and guides the features to a suitable dilated convolution. We\nevaluated the proposed network on more than 1,000 CT scans from the LIDC-LDRI\ndataset. Our proposed network outperforms state-of-the-art baseline models\nincluding Multi-Crop, Resnet, and Densenet, with an AUC of >0.95. Compared to\nthe baseline models, the GD network improves the classification accuracies of\nmid-range sized nodules. Furthermore, we observe a relationship between the\nsize of the nodule and the attention signal generated by the Context-Aware\nsub-network, which validates our new network architecture.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 09:13:17 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 10:47:42 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Al-Shabi", "Mundher", ""], ["Lee", "Hwee Kuan", ""], ["Tan", "Maxine", ""]]}, {"id": "1901.00130", "submitter": "Shao-Bo Lin", "authors": "Zheng-Chu Guo, Lei Shi, Shao-Bo Lin", "title": "Realizing data features by deep nets", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the power of deep neural networks (deep nets for short)\nin realizing data features. Based on refined covering number estimates, we find\nthat, to realize some complex data features, deep nets can improve the\nperformances of shallow neural networks (shallow nets for short) without\nrequiring additional capacity costs. This verifies the advantage of deep nets\nin realizing complex features. On the other hand, to realize some simple data\nfeature like the smoothness, we prove that, up to a logarithmic factor, the\napproximation rate of deep nets is asymptotically identical to that of shallow\nnets, provided that the depth is fixed. This exhibits a limitation of deep nets\nin realizing simple features.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 11:00:44 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Guo", "Zheng-Chu", ""], ["Shi", "Lei", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "1901.00137", "submitter": "Zhuoran Yang", "authors": "Jianqing Fan, Zhaoran Wang, Yuchen Xie, Zhuoran Yang", "title": "A Theoretical Analysis of Deep Q-Learning", "comments": "65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great empirical success of deep reinforcement learning, its\ntheoretical foundation is less well understood. In this work, we make the first\nattempt to theoretically understand the deep Q-network (DQN) algorithm (Mnih et\nal., 2015) from both algorithmic and statistical perspectives. In specific, we\nfocus on a slight simplification of DQN that fully captures its key features.\nUnder mild assumptions, we establish the algorithmic and statistical rates of\nconvergence for the action-value functions of the iterative policy sequence\nobtained by DQN. In particular, the statistical error characterizes the bias\nand variance that arise from approximating the action-value function using deep\nneural network, while the algorithmic error converges to zero at a geometric\nrate. As a byproduct, our analysis provides justifications for the techniques\nof experience replay and target network, which are crucial to the empirical\nsuccess of DQN. Furthermore, as a simple extension of DQN, we propose the\nMinimax-DQN algorithm for zero-sum Markov game with two players. Borrowing the\nanalysis of DQN, we also quantify the difference between the policies obtained\nby Minimax-DQN and the Nash equilibrium of the Markov game in terms of both the\nalgorithmic and statistical rates of convergence.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 11:41:23 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:15:22 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 02:40:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Fan", "Jianqing", ""], ["Wang", "Zhaoran", ""], ["Xie", "Yuchen", ""], ["Yang", "Zhuoran", ""]]}, {"id": "1901.00140", "submitter": "Shuang Xu", "authors": "Shuang Xu, Chun-Xia Zhang, Jiangshe Zhang", "title": "Adaptive Quantile Low-Rank Matrix Factorization", "comments": null, "journal-ref": "Pattern Recognition, Volume 103, July 2020, 107310", "doi": "10.1016/j.patcog.2020.107310", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix factorization (LRMF) has received much popularity owing to\nits successful applications in both computer vision and data mining. By\nassuming noise to come from a Gaussian, Laplace or mixture of Gaussian\ndistributions, significant efforts have been made on optimizing the (weighted)\n$L_1$ or $L_2$-norm loss between an observed matrix and its bilinear\nfactorization. However, the type of noise distribution is generally unknown in\nreal applications and inappropriate assumptions will inevitably deteriorate the\nbehavior of LRMF. On the other hand, real data are often corrupted by skew\nrather than symmetric noise. To tackle this problem, this paper presents a\nnovel LRMF model called AQ-LRMF by modeling noise with a mixture of asymmetric\nLaplace distributions. An efficient algorithm based on the\nexpectation-maximization (EM) algorithm is also offered to estimate the\nparameters involved in AQ-LRMF. The AQ-LRMF model possesses the advantage that\nit can approximate noise well no matter whether the real noise is symmetric or\nskew. The core idea of AQ-LRMF lies in solving a weighted $L_1$ problem with\nweights being learned from data. The experiments conducted on synthetic and\nreal datasets show that AQ-LRMF outperforms several state-of-the-art\ntechniques. Furthermore, AQ-LRMF also has the superiority over the other\nalgorithms in terms of capturing local structural information contained in real\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 12:04:06 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 13:50:19 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 14:10:31 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Xu", "Shuang", ""], ["Zhang", "Chun-Xia", ""], ["Zhang", "Jiangshe", ""]]}, {"id": "1901.00150", "submitter": "Milan Vojnovic", "authors": "Milan Vojnovic and Seyoung Yun and Kaifang Zhou", "title": "Accelerated MM Algorithms for Ranking Scores Inference from Comparison\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a popular method for inference of the Bradley-Terry\nmodel parameters, namely the MM algorithm, for maximum likelihood estimation\nand maximum a posteriori probability estimation. This class of models includes\nthe Bradley-Terry model of paired comparisons, the Rao-Kupper model of paired\ncomparisons allowing for tie outcomes, the Luce choice model, and the\nPlackett-Luce ranking model. We establish tight characterizations of the\nconvergence rate for the MM algorithm, and show that it is essentially\nequivalent to that of a gradient descent algorithm. For the maximum likelihood\nestimation, the convergence is shown to be linear with the rate crucially\ndetermined by the algebraic connectivity of the matrix of item pair\nco-occurrences in observed comparison data. For the Bayesian inference, the\nconvergence rate is also shown to be linear, with the rate determined by a\nparameter of the prior distribution in a way that can make the convergence\narbitrarily slow for small values of this parameter. We propose a simple\nmodification of the classical MM algorithm that avoids the observed slow\nconvergence issue and accelerates the convergence. The key component of the\naccelerated MM algorithm is a parameter rescaling performed at each iteration\nstep that is carefully chosen based on theoretical analysis and\ncharacterisation of the convergence rate.\n  Our experimental results, performed on both synthetic and real-world data,\ndemonstrate the identified slow convergence issue of the classic MM algorithm,\nand show that significant efficiency gains can be obtained by our new proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 13:08:53 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 17:13:57 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 12:49:42 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Vojnovic", "Milan", ""], ["Yun", "Seyoung", ""], ["Zhou", "Kaifang", ""]]}, {"id": "1901.00158", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Zhiting Hu, Eric Xing", "title": "Text Infilling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen remarkable progress of text generation in different\ncontexts, such as the most common setting of generating text from scratch, and\nthe emerging paradigm of retrieval-and-rewriting. Text infilling, which fills\nmissing text portions of a sentence or paragraph, is also of numerous use in\nreal life, yet is under-explored. Previous work has focused on restricted\nsettings by either assuming single word per missing portion or limiting to a\nsingle missing portion to the end of the text. This paper studies the general\ntask of text infilling, where the input text can have an arbitrary number of\nportions to be filled, each of which may require an arbitrary unknown number of\ntokens. We study various approaches for the task, including a self-attention\nmodel with segment-aware position encoding and bidirectional context modeling.\nWe create extensive supervised data by masking out text with varying\nstrategies. Experiments show the self-attention model greatly outperforms\nothers, creating a strong baseline for future research.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 14:41:17 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 17:55:36 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhu", "Wanrong", ""], ["Hu", "Zhiting", ""], ["Xing", "Eric", ""]]}, {"id": "1901.00172", "submitter": "Shaobo Han", "authors": "Shaobo Han and David B. Dunson", "title": "Supervised Multiscale Dimension Reduction for Spatial Interaction\n  Networks", "comments": "30 pages, 12 figures, revised for clarity and conciseness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a multiscale supervised dimension reduction method for SPatial\nInteraction Network (SPIN) data, which consist of a collection of spatially\ncoordinated interactions. This type of predictor arises when the sampling unit\nof data is composed of a collection of primitive variables, each of them being\nessentially unique, so that it becomes necessary to group the variables in\norder to simplify the representation and enhance interpretability. In this\npaper, we introduce an empirical Bayes approach called spinlets, which first\nconstructs a partitioning tree to guide the reduction over multiple spatial\ngranularities, and then refines the representation of predictors according to\nthe relevance to the response. We consider an inverse Poisson regression model\nand propose a new multiscale generalized double Pareto prior, which is induced\nvia a tree-structured parameter expansion scheme. Our approach is motivated by\nan application in soccer analytics, in which we obtain compact vectorial\nrepresentations and readily interpretable visualizations of the complex network\nobjects, supervised by the response of interest.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 16:01:36 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 14:46:17 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 20:28:55 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Han", "Shaobo", ""], ["Dunson", "David B.", ""]]}, {"id": "1901.00188", "submitter": "Jung Lee", "authors": "Jung Hoon Lee", "title": "Complementary reinforcement learning towards explainable agents", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms allow agents to learn skills and\nstrategies to perform complex tasks without detailed instructions or expensive\nlabelled training examples. That is, RL agents can learn, as we learn. Given\nthe importance of learning in our intelligence, RL has been thought to be one\nof key components to general artificial intelligence, and recent breakthroughs\nin deep reinforcement learning suggest that neural networks (NN) are natural\nplatforms for RL agents. However, despite the efficiency and versatility of\nNN-based RL agents, their decision-making remains incomprehensible, reducing\ntheir utilities. To deploy RL into a wider range of applications, it is\nimperative to develop explainable NN-based RL agents. Here, we propose a method\nto derive a secondary comprehensible agent from a NN-based RL agent, whose\ndecision-makings are based on simple rules. Our empirical evaluation of this\nsecondary agent's performance supports the possibility of building a\ncomprehensible and transparent agent using a NN-based RL agent.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 18:14:35 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 02:29:24 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Lee", "Jung Hoon", ""]]}, {"id": "1901.00210", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Emma Brunskill", "title": "Tighter Problem-Dependent Regret Bounds in Reinforcement Learning\n  without Domain Knowledge using Value Function Bounds", "comments": "Bug fixes", "journal-ref": "International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong worst-case performance bounds for episodic reinforcement learning\nexist but fortunately in practice RL algorithms perform much better than such\nbounds would predict. Algorithms and theory that provide strong\nproblem-dependent bounds could help illuminate the key features of what makes a\nRL problem hard and reduce the barrier to using RL algorithms in practice. As a\nstep towards this we derive an algorithm for finite horizon discrete MDPs and\nassociated analysis that both yields state-of-the art worst-case regret bounds\nin the dominant terms and yields substantially tighter bounds if the RL\nenvironment has small environmental norm, which is a function of the variance\nof the next-state value functions. An important benefit of our algorithmic is\nthat it does not require apriori knowledge of a bound on the environmental\nnorm. As a result of our analysis, we also help address an open learning theory\nquestion~\\cite{jiang2018open} about episodic MDPs with a constant upper-bound\non the sum of rewards, providing a regret bound with no $H$-dependence in the\nleading term that scales a polynomial function of the number of episodes.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 21:17:21 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 06:43:16 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 17:27:39 GMT"}, {"version": "v4", "created": "Fri, 1 Nov 2019 20:35:28 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zanette", "Andrea", ""], ["Brunskill", "Emma", ""]]}, {"id": "1901.00213", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Andrei V. Konstantinov, Viacheslav S. Chukanov, Mikhail\n  V. Kots, Mikhail A. Ryabinin, Anna A. Meldo", "title": "A weighted random survival forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weighted random survival forest is presented in the paper. It can be\nregarded as a modification of the random forest improving its performance. The\nmain idea underlying the proposed model is to replace the standard procedure of\naveraging used for estimation of the random survival forest hazard function by\nweighted avaraging where the weights are assigned to every tree and can be\nveiwed as training paremeters which are computed in an optimal way by solving a\nstandard quadratic optimization problem maximizing Harrell's C-index. Numerical\nexamples with real data illustrate the outperformance of the proposed model in\ncomparison with the original random survival forest.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 21:54:51 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Utkin", "Lev V.", ""], ["Konstantinov", "Andrei V.", ""], ["Chukanov", "Viacheslav S.", ""], ["Kots", "Mikhail V.", ""], ["Ryabinin", "Mikhail A.", ""], ["Meldo", "Anna A.", ""]]}, {"id": "1901.00214", "submitter": "Brian Swenson", "authors": "Soummya Kar and Brian Swenson", "title": "Clustering with Distributed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider $K$-means clustering in networked environments (e.g., internet of\nthings (IoT) and sensor networks) where data is inherently distributed across\nnodes and processing power at each node may be limited. We consider a\nclustering algorithm referred to as networked $K$-means, or $NK$-means, which\nrelies only on local neighborhood information exchange. Information exchange is\nlimited to low-dimensional statistics and not raw data at the agents. The\nproposed approach develops a parametric family of multi-agent clustering\nobjectives (parameterized by $\\rho$) and associated distributed $NK$-means\nalgorithms (also parameterized by $\\rho$). The $NK$-means algorithm with\nparameter $\\rho$ converges to a set of fixed points relative to the associated\nmulti-agent objective (designated as `generalized minima'). By appropriate\nchoice of $\\rho$, the set of generalized minima may be brought arbitrarily\nclose to the set of Lloyd's minima. Thus, the $NK$-means algorithm may be used\nto compute Lloyd's minima of the collective dataset up to arbitrary accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 22:01:10 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Kar", "Soummya", ""], ["Swenson", "Brian", ""]]}, {"id": "1901.00243", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Orpaz Goldstein, Kimmo Karkkainen, Sajad Darabi,\n  Majid Sarrafzadeh", "title": "Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data\n  Streams", "comments": "https://openreview.net/forum?id=S1eOHo09KX", "journal-ref": "International Conference on Learning Representations (ICLR), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world learning scenarios, features are only acquirable at a cost\nconstrained under a budget. In this paper, we propose a novel approach for\ncost-sensitive feature acquisition at the prediction-time. The suggested method\nacquires features incrementally based on a context-aware feature-value\nfunction. We formulate the problem in the reinforcement learning paradigm, and\nintroduce a reward function based on the utility of each feature. Specifically,\nMC dropout sampling is used to measure expected variations of the model\nuncertainty which is used as a feature-value function. Furthermore, we suggest\nsharing representations between the class predictor and value function\nestimator networks. The suggested approach is completely online and is readily\napplicable to stream learning setups. The solution is evaluated on three\ndifferent datasets including the well-known MNIST dataset as a benchmark as\nwell as two cost-sensitive datasets: Yahoo Learning to Rank and a dataset in\nthe medical domain for diabetes classification. According to the results, the\nproposed method is able to efficiently acquire features and make accurate\npredictions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 02:33:54 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 02:42:39 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Goldstein", "Orpaz", ""], ["Karkkainen", "Kimmo", ""], ["Darabi", "Sajad", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1901.00246", "submitter": "Christopher Hazard", "authors": "Christopher J. Hazard, Christopher Fusting, Michael Resnick, Michael\n  Auerbach, Michael Meehan, Valeri Korobov", "title": "Natively Interpretable Machine Learning and Artificial Intelligence:\n  Preliminary Results and Future Directions", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have become more and more complex in order to better\napproximate complex functions. Although fruitful in many domains, the added\ncomplexity has come at the cost of model interpretability. The once popular\nk-nearest neighbors (kNN) approach, which finds and uses the most similar data\nfor reasoning, has received much less attention in recent decades due to\nnumerous problems when compared to other techniques. We show that many of these\nhistorical problems with kNN can be overcome, and our contribution has\napplications not only in machine learning but also in online learning, data\nsynthesis, anomaly detection, model compression, and reinforcement learning,\nwithout sacrificing interpretability. We introduce a synthesis between kNN and\ninformation theory that we hope will provide a clear path towards models that\nare innately interpretable and auditable. Through this work we hope to gather\ninterest in combining kNN with information theory as a promising path to fully\nauditable machine learning and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 03:00:21 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 16:35:42 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hazard", "Christopher J.", ""], ["Fusting", "Christopher", ""], ["Resnick", "Michael", ""], ["Auerbach", "Michael", ""], ["Meehan", "Michael", ""], ["Korobov", "Valeri", ""]]}, {"id": "1901.00248", "submitter": "Donna Xu", "authors": "Donna Xu, Yaxin Shi, Ivor W. Tsang, Yew-Soon Ong, Chen Gong and Xiaobo\n  Shen", "title": "A Survey on Multi-output Learning", "comments": "Paper accepted by IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output learning aims to simultaneously predict multiple outputs given\nan input. It is an important learning problem due to the pressing need for\nsophisticated decision making in real-world applications. Inspired by big data,\nthe 4Vs characteristics of multi-output imposes a set of challenges to\nmulti-output learning, in terms of the volume, velocity, variety and veracity\nof the outputs. Increasing number of works in the literature have been devoted\nto the study of multi-output learning and the development of novel approaches\nfor addressing the challenges encountered. However, it lacks a comprehensive\noverview on different types of challenges of multi-output learning brought by\nthe characteristics of the multiple outputs and the techniques proposed to\novercome the challenges. This paper thus attempts to fill in this gap to\nprovide a comprehensive review on this area. We first introduce different\nstages of the life cycle of the output labels. Then we present the paradigm on\nmulti-output learning, including its myriads of output structures, definitions\nof its different sub-problems, model evaluation metrics and popular data\nrepositories used in the study. Subsequently, we review a number of\nstate-of-the-art multi-output learning methods, which are categorized based on\nthe challenges.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 03:10:24 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 10:59:28 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Donna", ""], ["Shi", "Yaxin", ""], ["Tsang", "Ivor W.", ""], ["Ong", "Yew-Soon", ""], ["Gong", "Chen", ""], ["Shen", "Xiaobo", ""]]}, {"id": "1901.00251", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni, Brian Stone", "title": "An Automatic Interaction Detection Hybrid Model for Bankcard Response\n  Classification", "comments": null, "journal-ref": "The 2018 5th International Conference on Systems and Informatics\n  (ICSAI2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a hybrid bankcard response model, which integrates\ndecision tree based chi-square automatic interaction detection (CHAID) into\nlogistic regression. In the first stage of the hybrid model, CHAID analysis is\nused to detect the possibly potential variable interactions. Then in the second\nstage, these potential interactions are served as the additional input\nvariables in logistic regression. The motivation of the proposed hybrid model\nis that adding variable interactions may improve the performance of logistic\nregression. To demonstrate the effectiveness of the proposed hybrid model, it\nis evaluated on a real credit customer response data set. As the results\nreveal, by identifying potential interactions among independent variables, the\nproposed hybrid approach outperforms the logistic regression without searching\nfor interactions in terms of classification accuracy, the area under the\nreceiver operating characteristic curve (ROC), and Kolmogorov-Smirnov (KS)\nstatistics. Furthermore, CHAID analysis for interaction detection is much more\ncomputationally efficient than the stepwise search mentioned above and some\nidentified interactions are shown to have statistically significant predictive\npower on the target variable. Last but not least, the customer profile created\nbased on the CHAID tree provides a reasonable interpretation of the\ninteractions, which is the required by regulations of the credit industry.\nHence, this study provides an alternative for handling bankcard classification\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 03:23:18 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""], ["Stone", "Brian", ""]]}, {"id": "1901.00279", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Leslie Pack Kaelbling", "title": "Elimination of All Bad Local Minima in Deep Learning", "comments": "Accepted to appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we theoretically prove that adding one special neuron per\noutput unit eliminates all suboptimal local minima of any deep neural network,\nfor multi-class classification, binary classification, and regression with an\narbitrary loss function, under practical assumptions. At every local minimum of\nany deep neural network with these added neurons, the set of parameters of the\noriginal neural network (without added neurons) is guaranteed to be a global\nminimum of the original neural network. The effects of the added neurons are\nproven to automatically vanish at every local minimum. Moreover, we provide a\nnovel theoretical characterization of a failure mode of eliminating suboptimal\nlocal minima via an additional theorem and several examples. This paper also\nintroduces a novel proof technique based on the perturbable gradient basis\n(PGB) necessary condition of local minima, which provides new insight into the\nelimination of local minima and is applicable to analyze various models and\ntransformations of objective functions beyond the elimination of local minima.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 06:40:36 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 22:20:50 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1901.00301", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang, Alekh Agarwal, Hal Daum\\'e III, John Langford, Sahand\n  N Negahban", "title": "Warm-starting Contextual Bandits: Robustly Combining Supervised and\n  Bandit Feedback", "comments": "42 pages, 21 figures, ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the feasibility of learning from a mix of both fully-labeled\nsupervised data and contextual bandit data. We specifically consider settings\nin which the underlying learning signal may be different between these two data\nsources. Theoretically, we state and prove no-regret algorithms for learning\nthat is robust to misaligned cost distributions between the two sources.\nEmpirically, we evaluate some of these algorithms on a large selection of\ndatasets, showing that our approach is both feasible and helpful in practice.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 09:15:02 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 19:25:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhang", "Chicheng", ""], ["Agarwal", "Alekh", ""], ["Daum\u00e9", "Hal", "III"], ["Langford", "John", ""], ["Negahban", "Sahand N", ""]]}, {"id": "1901.00304", "submitter": "Dong Xia", "authors": "Dong Xia", "title": "Normal Approximation and Confidence Region of Singular Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is on the normal approximation of singular subspaces when the\nnoise matrix has i.i.d. entries. Our contributions are three-fold. First, we\nderive an explicit representation formula of the empirical spectral projectors.\nThe formula is neat and holds for deterministic matrix perturbations. Second,\nwe calculate the expected projection distance between the empirical singular\nsubspaces and true singular subspaces. Our method allows obtaining arbitrary\n$k$-th order approximation of the expected projection distance. Third, we prove\nthe non-asymptotical normal approximation of the projection distance with\ndifferent levels of bias corrections. By the $\\lceil \\log(d_1+d_2)\\rceil$-th\norder bias corrections, the asymptotical normality holds under optimal\nsignal-to-noise ration (SNR) condition where $d_1$ and $d_2$ denote the matrix\nsizes. In addition, it shows that higher order approximations are unnecessary\nwhen $|d_1-d_2|=O((d_1+d_2)^{1/2})$. Finally, we provide comprehensive\nsimulation results to merit our theoretic discoveries.\n  Unlike the existing results, our approach is non-asymptotical and the\nconvergence rates are established. Our method allows the rank $r$ to diverge as\nfast as $o((d_1+d_2)^{1/3})$. Moreover, our method requires no eigen-gap\ncondition (except the SNR) and no constraints between $d_1$ and $d_2$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 09:23:50 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:54:16 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 13:27:26 GMT"}, {"version": "v4", "created": "Fri, 26 Jul 2019 03:05:24 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Xia", "Dong", ""]]}, {"id": "1901.00331", "submitter": "Maciej  Skorski", "authors": "Maciej Skorski", "title": "Kernel Density Estimation Bias under Minimal Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel Density Estimation is a very popular technique of approximating a\ndensity function from samples. The accuracy is generally well-understood and\ndepends, roughly speaking, on the kernel decay and local smoothness of the true\ndensity. However concrete statements in the literature are often invoked in\nvery specific settings (simplified or overly conservative assumptions) or miss\nimportant but subtle points (e.g. it is common to heuristically apply Taylor's\nexpansion globally without referring to compactness). The contribution of this\npaper is twofold (a) we demonstrate that, when the bandwidth is an arbitrary\ninvertible matrix going to zero, it is necessary to keep a certain balance\nbetween the \\emph{kernel decay} and \\emph{magnitudes of bandwidth eigenvalues};\nin fact, without the sufficient decay the estimates may not be even bounded (b)\nwe give a rigorous derivation of bounds with explicit constants for the bias,\nunder possibly minimal assumptions. This connects the kernel decay, bandwidth\nnorm, bandwidth determinant and density smoothness. It has been folklore that\nthe issue with Taylor's formula can be fixed with more complicated assumptions\non the density (for example p. 95 of \"Kernel Smoothing\" by Wand and Jones); we\nshow that this is actually not necessary and can be handled by the kernel decay\nalone.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 12:09:21 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "1901.00397", "submitter": "Bel\\'en Sald\\'ias", "authors": "Belen Saldias, Pavlos Protopapas, Karim Pichara", "title": "A Full Probabilistic Model for Yes/No Type Crowdsourcing in Multi-Class\n  Classification", "comments": "SIAM International Conference on Data Mining (SDM19), 9 official\n  pages, 5 supplementary pages", "journal-ref": "Proceedings of the 2019 SIAM International Conference on Data\n  Mining", "doi": "10.1137/1.9781611975673.85", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has become widely used in supervised scenarios where training\nsets are scarce and difficult to obtain. Most crowdsourcing models in the\nliterature assume labelers can provide answers to full questions. In\nclassification contexts, full questions require a labeler to discern among all\npossible classes. Unfortunately, discernment is not always easy in realistic\nscenarios. Labelers may not be experts in differentiating all classes. In this\nwork, we provide a full probabilistic model for a shorter type of queries. Our\nshorter queries only require \"yes\" or \"no\" responses. Our model estimates a\njoint posterior distribution of matrices related to labelers' confusions and\nthe posterior probability of the class of every object. We developed an\napproximate inference approach, using Monte Carlo Sampling and Black Box\nVariational Inference, which provides the derivation of the necessary\ngradients. We built two realistic crowdsourcing scenarios to test our model.\nThe first scenario queries for irregular astronomical time-series. The second\nscenario relies on the image classification of animals. We achieved results\nthat are comparable with those of full query crowdsourcing. Furthermore, we\nshow that modeling labelers' failures plays an important role in estimating\ntrue classes. Finally, we provide the community with two real datasets obtained\nfrom our crowdsourcing experiments. All our code is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 14:40:10 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 17:57:34 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 02:57:47 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Saldias", "Belen", ""], ["Protopapas", "Pavlos", ""], ["Pichara", "Karim", ""]]}, {"id": "1901.00398", "submitter": "Cristina Garbacea", "authors": "Cristina Garbacea, Samuel Carton, Shiyan Yan, Qiaozhu Mei", "title": "Judge the Judges: A Large-Scale Evaluation Study of Neural Language\n  Models for Online Review Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a large-scale, systematic study to evaluate the existing\nevaluation methods for natural language generation in the context of generating\nonline product reviews. We compare human-based evaluators with a variety of\nautomated evaluation procedures, including discriminative evaluators that\nmeasure how well machine-generated text can be distinguished from human-written\ntext, as well as word overlap metrics that assess how similar the generated\ntext compares to human-written references. We determine to what extent these\ndifferent evaluators agree on the ranking of a dozen of state-of-the-art\ngenerators for online product reviews. We find that human evaluators do not\ncorrelate well with discriminative evaluators, leaving a bigger question of\nwhether adversarial accuracy is the correct objective for natural language\ngeneration. In general, distinguishing machine-generated text is challenging\neven for human evaluators, and human decisions correlate better with lexical\noverlaps. We find lexical diversity an intriguing metric that is indicative of\nthe assessments of different evaluators. A post-experiment survey of\nparticipants provides insights into how to evaluate and improve the quality of\nnatural language generation systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 14:45:02 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 18:25:57 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Garbacea", "Cristina", ""], ["Carton", "Samuel", ""], ["Yan", "Shiyan", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1901.00399", "submitter": "Oren Halvani", "authors": "Oren Halvani, Christian Winter, Lukas Graner", "title": "Unary and Binary Classification Approaches and their Implications for\n  Authorship Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving indexed documents, not by their topical content but their writing\nstyle opens the door for a number of applications in information retrieval\n(IR). One application is to retrieve textual content of a certain author X,\nwhere the queried IR system is provided beforehand with a set of reference\ntexts of X. Authorship verification (AV), which is a research subject in the\nfield of digital text forensics, is suitable for this purpose. The task of AV\nis to determine if two documents (i.e. an indexed and a reference document)\nhave been written by the same author X. Even though AV represents a unary\nclassification problem, a number of existing approaches consider it as a binary\nclassification task. However, the underlying classification model of an AV\nmethod has a number of serious implications regarding its prerequisites,\nevaluability, and applicability. In our comprehensive literature review, we\nobserved several misunderstandings regarding the differentiation of unary and\nbinary AV approaches that require consideration. The objective of this paper\nis, therefore, to clarify these by proposing clear criteria and new properties\nthat aim to improve the characterization of existing and future AV approaches.\nGiven both, we investigate the applicability of eleven existing unary and\nbinary AV methods as well as four generic unary classification algorithms on\ntwo self-compiled corpora. Furthermore, we highlight an important issue\nconcerning the evaluation of AV methods based on fixed decision criterions,\nwhich has not been paid attention in previous AV studies.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:04:16 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Halvani", "Oren", ""], ["Winter", "Christian", ""], ["Graner", "Lukas", ""]]}, {"id": "1901.00400", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Bernhard Lutz, Nicolas Pr\\\"ollochs, Dirk Neumann", "title": "Sentence-Level Sentiment Analysis of Financial News Using Distributed\n  Text Representations and Multi-Instance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers and financial professionals require robust computerized tools\nthat allow users to rapidly operationalize and assess the semantic textual\ncontent in financial news. However, existing methods commonly work at the\ndocument-level while deeper insights into the actual structure and the\nsentiment of individual sentences remain blurred. As a result, investors are\nrequired to apply the utmost attention and detailed, domain-specific knowledge\nin order to assess the information on a fine-grained basis. To facilitate this\nmanual process, this paper proposes the use of distributed text representations\nand multi-instance learning to transfer information from the document-level to\nthe sentence-level. Compared to alternative approaches, this method features\nsuperior predictive performance while preserving context and interpretability.\nOur analysis of a manually-labeled dataset yields a predictive accuracy of up\nto 69.90%, exceeding the performance of alternative approaches by at least 3.80\npercentage points. Accordingly, this study not only benefits investors with\nregard to their financial decision-making, but also helps companies to\ncommunicate their messages as intended.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:30:21 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Lutz", "Bernhard", ""], ["Pr\u00f6llochs", "Nicolas", ""], ["Neumann", "Dirk", ""]]}, {"id": "1901.00403", "submitter": "Peter Schulam", "authors": "Peter Schulam and Suchi Saria", "title": "Can You Trust This Prediction? Auditing Pointwise Reliability After\n  Learning", "comments": "To appear in the proceedings of Artificial Intelligence and\n  Statistics (AISTATS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To use machine learning in high stakes applications (e.g. medicine), we need\ntools for building confidence in the system and evaluating whether it is\nreliable. Methods to improve model reliability often require new learning\nalgorithms (e.g. using Bayesian inference to obtain uncertainty estimates). An\nalternative is to audit a model after it is trained. In this paper, we describe\nresampling uncertainty estimation (RUE), an algorithm to audit the pointwise\nreliability of predictions. Intuitively, RUE estimates the amount that a\nprediction would change if the model had been fit on different training data.\nThe algorithm uses the gradient and Hessian of the model's loss function to\ncreate an ensemble of predictions. Experimentally, we show that RUE more\neffectively detects inaccurate predictions than existing tools for auditing\nreliability subsequent to training. We also show that RUE can create predictive\ndistributions that are competitive with state-of-the-art methods like Monte\nCarlo dropout, probabilistic backpropagation, and deep ensembles, but does not\ndepend on specific algorithms at train-time like these methods do.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 14:53:33 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 21:33:19 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1901.00409", "submitter": "Ari Pakman", "authors": "Ari Pakman, Yueqi Wang, Catalin Mitelut, JinHyung Lee, Liam Paninski", "title": "Neural Clustering Processes", "comments": null, "journal-ref": "Published in Proceedings of the 37th International Conference on\n  Machine Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic clustering models (or equivalently, mixture models) are basic\nbuilding blocks in countless statistical models and involve latent random\nvariables over discrete spaces. For these models, posterior inference methods\ncan be inaccurate and/or very slow. In this work we introduce deep network\narchitectures trained with labeled samples from any generative model of\nclustered datasets. At test time, the networks generate approximate posterior\nsamples of cluster labels for any new dataset of arbitrary size. We develop two\ncomplementary approaches to this task, requiring either O(N) or O(K) network\nforward passes per dataset, where N is the dataset size and K the number of\nclusters. Unlike previous approaches, our methods sample the labels of all the\ndata points from a well-defined posterior, and can learn nonparametric Bayesian\nposteriors since they do not limit the number of mixture components. As a\nscientific application, we present a novel approach to neural spike sorting for\nhigh-density multielectrode arrays.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 23:16:47 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 01:45:18 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 03:24:00 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 04:56:51 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Pakman", "Ari", ""], ["Wang", "Yueqi", ""], ["Mitelut", "Catalin", ""], ["Lee", "JinHyung", ""], ["Paninski", "Liam", ""]]}, {"id": "1901.00415", "submitter": "Dai Tran", "authors": "Dai Hoang Tran, Zawar Hussain, Wei Emma Zhang, Nguyen Lu Dang Khoa,\n  Nguyen H. Tran, Quan Z. Sheng", "title": "Deep Autoencoder for Recommender Systems: Parameter Influence Analysis", "comments": "11 pages, ACIS 2018,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have recently attracted many researchers in the deep\nlearning community. The state-of-the-art deep neural network models used in\nrecommender systems are typically multilayer perceptron and deep Autoencoder\n(DAE), among which DAE usually shows better performance due to its superior\ncapability to reconstruct the inputs. However, we found existing DAE\nrecommendation systems that have similar implementations on similar datasets\nresult in vastly different parameter settings. In this work, we have built a\nflexible DAE model, named FlexEncoder that uses configurable parameters and\nunique features to analyse the parameter influences on the prediction accuracy\nof recommender systems. This will help us identify the best-performance\nparameters given a dataset. Extensive evaluation on the MovieLens datasets are\nconducted, which drives our conclusions on the influences of DAE parameters.\nSpecifically, we find that DAE parameters strongly affect the prediction\naccuracy of the recommender systems, and the effect is transferable to similar\ndatasets in a larger size. We open our code to public which could benefit both\nnew users for DAE -- they can quickly understand how DAE works for\nrecommendation systems, and experienced DAE users -- it easier for them to tune\nthe parameters on different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 03:56:19 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Tran", "Dai Hoang", ""], ["Hussain", "Zawar", ""], ["Zhang", "Wei Emma", ""], ["Khoa", "Nguyen Lu Dang", ""], ["Tran", "Nguyen H.", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "1901.00418", "submitter": "Gustav M{\\aa}rtensson", "authors": "Gustav M{\\aa}rtensson, Daniel Ferreira, Lena Cavallin, J-Sebastian\n  Muehlboeck, Lars-Olof Wahlund, Chunliang Wang, Eric Westman", "title": "AVRA: Automatic Visual Ratings of Atrophy from MRI images using\n  Recurrent Convolutional Neural Networks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": "10.1016/j.nicl.2019.101872", "report-no": null, "categories": "physics.med-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the degree of atrophy is done clinically by neuroradiologists\nfollowing established visual rating scales. For these assessments to be\nreliable the rater requires substantial training and experience, and even then\nthe rating agreement between two radiologists is not perfect. We have developed\na model we call AVRA (Automatic Visual Ratings of Atrophy) based on machine\nlearning methods and trained on 2350 visual ratings made by an experienced\nneuroradiologist. It provides fast and automatic ratings for Scheltens' scale\nof medial temporal atrophy (MTA), the frontal subscale of Pasquier's Global\nCortical Atrophy (GCA-F) scale, and Koedam's scale of Posterior Atrophy (PA).\nWe demonstrate substantial inter-rater agreement between AVRA's and a\nneuroradiologist ratings with Cohen's weighted kappa values of $\\kappa_w$ =\n0.74/0.72 (MTA left/right), $\\kappa_w$ = 0.62 (GCA-F) and $\\kappa_w$ = 0.74\n(PA), with an inherent intra-rater agreement of $\\kappa_w$ = 1. We conclude\nthat automatic visual ratings of atrophy can potentially have great clinical\nand scientific value, and aim to present AVRA as a freely available toolbox.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 10:23:50 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["M\u00e5rtensson", "Gustav", ""], ["Ferreira", "Daniel", ""], ["Cavallin", "Lena", ""], ["Muehlboeck", "J-Sebastian", ""], ["Wahlund", "Lars-Olof", ""], ["Wang", "Chunliang", ""], ["Westman", "Eric", ""]]}, {"id": "1901.00433", "submitter": "Patrick Forr\\'e", "authors": "Patrick Forr\\'e, Joris M. Mooij", "title": "Causal Calculus in the Presence of Cycles, Latent Confounders and\n  Selection Bias", "comments": "Accepted for publication in Conference on Uncertainty in Artificial\n  Intelligence 2019 (UAI-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the main rules of causal calculus (also called do-calculus) for i/o\nstructural causal models (ioSCMs), a generalization of a recently proposed\ngeneral class of non-/linear structural causal models that allow for cycles,\nlatent confounders and arbitrary probability distributions. We also generalize\nadjustment criteria and formulas from the acyclic setting to the general one\n(i.e. ioSCMs). Such criteria then allow to estimate (conditional) causal\neffects from observational data that was (partially) gathered under selection\nbias and cycles. This generalizes the backdoor criterion, the\nselection-backdoor criterion and extensions of these to arbitrary ioSCMs.\nTogether, our results thus enable causal reasoning in the presence of cycles,\nlatent confounders and selection bias. Finally, we extend the ID algorithm for\nthe identification of causal effects to ioSCMs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 15:58:49 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:38:18 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Forr\u00e9", "Patrick", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1901.00434", "submitter": "Roman Vershynin", "authors": "Pierre Baldi, Roman Vershynin", "title": "The capacity of feedforward neural networks", "comments": "49 pages. Introduction is expanded and conclusion is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long standing open problem in the theory of neural networks is the\ndevelopment of quantitative methods to estimate and compare the capabilities of\ndifferent architectures. Here we define the capacity of an architecture by the\nbinary logarithm of the number of functions it can compute, as the synaptic\nweights are varied. The capacity provides an upper bound on the number of bits\nthat can be extracted from the training data and stored in the architecture\nduring learning. We study the capacity of layered, fully-connected,\narchitectures of linear threshold neurons with $L$ layers of size $n_1,n_2,\n\\ldots, n_L$ and show that in essence the capacity is given by a cubic\npolynomial in the layer sizes: $C(n_1,\\ldots, n_L)=\\sum_{k=1}^{L-1}\n\\min(n_1,\\ldots,n_k)n_kn_{k+1}$, where layers that are smaller than all\nprevious layers act as bottlenecks. In proving the main result, we also develop\nnew techniques (multiplexing, enrichment, and stacking) as well as new bounds\non the capacity of finite sets. We use the main result to identify\narchitectures with maximal or minimal capacity under a number of natural\nconstraints. This leads to the notion of structural regularization for deep\narchitectures. While in general, everything else being equal, shallow networks\ncompute more functions than deep networks, the functions computed by deep\nnetworks are more regular and \"interesting\".\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 16:05:28 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 21:06:06 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Baldi", "Pierre", ""], ["Vershynin", "Roman", ""]]}, {"id": "1901.00439", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu", "title": "Deep Representation Learning for Clustering of Health Tweets", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter has been a prominent social media platform for mining\npopulation-level health data and accurate clustering of health-related tweets\ninto topics is important for extracting relevant health insights. In this work,\nwe propose deep convolutional autoencoders for learning compact representations\nof health-related tweets, further to be employed in clustering. We compare our\nmethod to several conventional tweet representation methods including\nbag-of-words, term frequency-inverse document frequency, Latent Dirichlet\nAllocation and Non-negative Matrix Factorization with 3 different clustering\nalgorithms. Our results show that the clustering performance using proposed\nrepresentation learning scheme significantly outperforms that of conventional\nmethods for all experiments of different number of clusters. In addition, we\npropose a constraint on the learned representations during the neural network\ntraining in order to further enhance the clustering performance. All in all,\nthis study introduces utilization of deep neural network-based architectures,\ni.e., deep convolutional autoencoders, for learning informative representations\nof health-related tweets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 00:31:22 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Gencoglu", "Oguzhan", ""]]}, {"id": "1901.00444", "submitter": "Prasad Bhavana Mr", "authors": "Prasad G Bhavana, Vineet C Nair", "title": "BMF: Block matrix approach to factorization of large scale data", "comments": "Disagreement on success criteria of the method with my guide", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Factorization (MF) on large scale matrices is computationally as well\nas memory intensive task. Alternative convergence techniques are needed when\nthe size of the input matrix is higher than the available memory on a Central\nProcessing Unit (CPU) and Graphical Processing Unit (GPU). While alternating\nleast squares (ALS) convergence on CPU could take forever, loading all the\nrequired matrices on to GPU memory may not be possible when the dimensions are\nsignificantly higher. Hence we introduce a novel technique that is based on\nconsidering the entire data into a block matrix and relies on factorization at\na block level.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 16:25:54 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 16:46:17 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Bhavana", "Prasad G", ""], ["Nair", "Vineet C", ""]]}, {"id": "1901.00451", "submitter": "Yi Zhou", "authors": "Yi Zhou, Junjie Yang, Huishuai Zhang, Yingbin Liang, Vahid Tarokh", "title": "SGD Converges to Global Minimum in Deep Learning via Star-convex Path", "comments": "ICLR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been found to be surprisingly effective\nin training a variety of deep neural networks. However, there is still a lack\nof understanding on how and why SGD can train these complex networks towards a\nglobal minimum. In this study, we establish the convergence of SGD to a global\nminimum for nonconvex optimization problems that are commonly encountered in\nneural network training. Our argument exploits the following two important\nproperties: 1) the training loss can achieve zero value (approximately), which\nhas been widely observed in deep learning; 2) SGD follows a star-convex path,\nwhich is verified by various experiments in this paper. In such a context, our\nanalysis shows that SGD, although has long been considered as a randomized\nalgorithm, converges in an intrinsically deterministic manner to a global\nminimum.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 17:09:45 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhou", "Yi", ""], ["Yang", "Junjie", ""], ["Zhang", "Huishuai", ""], ["Liang", "Yingbin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1901.00456", "submitter": "Donghui Yan", "authors": "Donghui Yan, Zhiwei Qin, Songxiang Gu, Haiping Xu, Ming Shao", "title": "Cost-sensitive Selection of Variables by Ensemble of Model Sequences", "comments": "26 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many applications require the collection of data on different variables or\nmeasurements over many system performance metrics. We term those broadly as\nmeasures or variables. Often data collection along each measure incurs a cost,\nthus it is desirable to consider the cost of measures in modeling. This is a\nfairly new class of problems in the area of cost-sensitive learning. A few\nattempts have been made to incorporate costs in combining and selecting\nmeasures. However, existing studies either do not strictly enforce a budget\nconstraint, or are not the `most' cost effective. With a focus on\nclassification problem, we propose a computationally efficient approach that\ncould find a near optimal model under a given budget by exploring the most\n`promising' part of the solution space. Instead of outputting a single model,\nwe produce a model schedule -- a list of models, sorted by model costs and\nexpected predictive accuracy. This could be used to choose the model with the\nbest predictive accuracy under a given budget, or to trade off between the\nbudget and the predictive accuracy. Experiments on some benchmark datasets show\nthat our approach compares favorably to competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 17:35:30 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 14:13:19 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 00:21:30 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Yan", "Donghui", ""], ["Qin", "Zhiwei", ""], ["Gu", "Songxiang", ""], ["Xu", "Haiping", ""], ["Shao", "Ming", ""]]}, {"id": "1901.00461", "submitter": "Marc Chaumont", "authors": "Anthony Brunel, Johanna Pasquet, J\\'er\\^ome Pasquet, Nancy Rodriguez,\n  Fr\\'ed\\'eric Comby, Dominique Fouchez, Marc Chaumont", "title": "A CNN adapted to time series for the classification of Supernovae", "comments": "IS&T International Symposium on Electronic Imaging, EI'2019, Color\n  Imaging XXIV: Displaying, Processing, Hardcopy, and Applications, Burlingame\n  (suburb of San Francisco), California USA, 13 - 17 January, 2019, 8 pages.\n  The CNN is downloadable there:\n  https://github.com/Anzzy30/SupernovaeClassification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cosmologists are facing the problem of the analysis of a huge quantity of\ndata when observing the sky. The methods used in cosmology are, for the most of\nthem, relying on astrophysical models, and thus, for the classification, they\nusually use a machine learning approach in two-steps, which consists in, first,\nextracting features, and second, using a classifier. In this paper, we are\nspecifically studying the supernovae phenomenon and especially the binary\nclassification \"I.a supernovae versus not-I.a supernovae\". We present two\nConvolutional Neural Networks (CNNs) defeating the current state-of-the-art.\nThe first one is adapted to time series and thus to the treatment of supernovae\nlight-curves. The second one is based on a Siamese CNN and is suited to the\nnature of data, i.e. their sparsity and their weak quantity (small learning\ndatabase).\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 17:49:06 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Brunel", "Anthony", ""], ["Pasquet", "Johanna", ""], ["Pasquet", "J\u00e9r\u00f4me", ""], ["Rodriguez", "Nancy", ""], ["Comby", "Fr\u00e9d\u00e9ric", ""], ["Fouchez", "Dominique", ""], ["Chaumont", "Marc", ""]]}, {"id": "1901.00532", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran", "title": "Adversarial Robustness May Be at Odds With Simplicity", "comments": "welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current techniques in machine learning are so far are unable to learn\nclassifiers that are robust to adversarial perturbations. However, they are\nable to learn non-robust classifiers with very high accuracy, even in the\npresence of random perturbations. Towards explaining this gap, we highlight the\nhypothesis that $\\textit{robust classification may require more complex\nclassifiers (i.e. more capacity) than standard classification.}$\n  In this note, we show that this hypothesis is indeed possible, by giving\nseveral theoretical examples of classification tasks and sets of \"simple\"\nclassifiers for which: (1) There exists a simple classifier with high standard\naccuracy, and also high accuracy under random $\\ell_\\infty$ noise. (2) Any\nsimple classifier is not robust: it must have high adversarial loss with\n$\\ell_\\infty$ perturbations. (3) Robust classification is possible, but only\nwith more complex classifiers (exponentially more complex, in some examples).\n  Moreover, $\\textit{there is a quantitative trade-off between robustness and\nstandard accuracy among simple classifiers.}$ This suggests an alternate\nexplanation of this phenomenon, which appears in practice: the tradeoff may\noccur not because the classification task inherently requires such a tradeoff\n(as in [Tsipras-Santurkar-Engstrom-Turner-Madry `18]), but because the\nstructure of our current classifiers imposes such a tradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 20:54:07 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Nakkiran", "Preetum", ""]]}, {"id": "1901.00533", "submitter": "Maksym Byshkin", "authors": "Alexander Borisenko, Maksym Byshkin, Alessandro Lomi", "title": "A Simple Algorithm for Scalable Monte Carlo Inference", "comments": "15 pages + supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math-ph math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The methods of statistical physics are widely used for modelling complex\nnetworks. Building on the recently proposed Equilibrium Expectation approach,\nwe derive a simple and efficient algorithm for maximum likelihood estimation\n(MLE) of parameters of exponential family distributions - a family of\nstatistical models, that includes Ising model, Markov Random Field and\nExponential Random Graph models. Computational experiments and analysis of\nempirical data demonstrate that the algorithm increases by orders of magnitude\nthe size of network data amenable to Monte Carlo based inference. We report\nresults suggesting that the applicability of the algorithm may readily be\nextended to the analysis of large samples of dependent observations commonly\nfound in biology, sociology, astrophysics, and ecology.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 20:59:47 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 07:55:02 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 10:55:25 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 14:02:02 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Borisenko", "Alexander", ""], ["Byshkin", "Maksym", ""], ["Lomi", "Alessandro", ""]]}, {"id": "1901.00544", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Zhaoyang Lv, Joel Schlosser, Phillip Odom, Zsolt Kira", "title": "Multi-class Classification without Multi-class Labels", "comments": "International Conference on Learning Representations (ICLR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new strategy for multi-class classification that\nrequires no class-specific labels, but instead leverages pairwise similarity\nbetween examples, which is a weaker form of annotation. The proposed method,\nmeta classification learning, optimizes a binary classifier for pairwise\nsimilarity prediction and through this process learns a multi-class classifier\nas a submodule. We formulate this approach, present a probabilistic graphical\nmodel for it, and derive a surprisingly simple loss function that can be used\nto learn neural network-based models. We then demonstrate that this same\nframework generalizes to the supervised, unsupervised cross-task, and\nsemi-supervised settings. Our method is evaluated against state of the art in\nall three learning paradigms and shows a superior or comparable accuracy,\nproviding evidence that learning multi-class classification without multi-class\nlabels is a viable learning option.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 22:09:12 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Lv", "Zhaoyang", ""], ["Schlosser", "Joel", ""], ["Odom", "Phillip", ""], ["Kira", "Zsolt", ""]]}, {"id": "1901.00546", "submitter": "Qingquan Song", "authors": "Qingquan Song, Haifeng Jin, Xiao Huang, Xia Hu", "title": "Multi-Label Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are delicately perturbed inputs, which aim to mislead\nmachine learning models towards incorrect outputs. While most of the existing\nwork focuses on generating adversarial perturbations in multi-class\nclassification problems, many real-world applications fall into the multi-label\nsetting in which one instance could be associated with more than one label. For\nexample, a spammer may generate adversarial spams with malicious advertising\nwhile maintaining the other labels such as topic labels unchanged. To analyze\nthe vulnerability and robustness of multi-label learning models, we investigate\nthe generation of multi-label adversarial perturbations. This is a challenging\ntask due to the uncertain number of positive labels associated with one\ninstance, as well as the fact that multiple labels are usually not mutually\nexclusive with each other. To bridge this gap, in this paper, we propose a\ngeneral attacking framework targeting on multi-label classification problem and\nconduct a premier analysis on the perturbations for deep neural networks.\nLeveraging the ranking relationships among labels, we further design a\nranking-based framework to attack multi-label ranking algorithms. We specify\nthe connection between the two proposed frameworks and separately design two\nspecific methods grounded on each of them to generate targeted multi-label\nperturbations. Experiments on real-world multi-label image classification and\nranking problems demonstrate the effectiveness of our proposed frameworks and\nprovide insights of the vulnerability of multi-label deep learning models under\ndiverse targeted attacking strategies. Several interesting findings including\nan unpolished defensive strategy, which could potentially enhance the\ninterpretability and robustness of multi-label deep learning models, are\nfurther presented and discussed at the end.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 22:13:02 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Song", "Qingquan", ""], ["Jin", "Haifeng", ""], ["Huang", "Xiao", ""], ["Hu", "Xia", ""]]}, {"id": "1901.00555", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett and Volkan Cevher", "title": "An Introductory Guide to Fano's Inequality with Applications in\n  Statistical Estimation", "comments": "Chapter in upcoming book \"Information-Theoretic Methods in Data\n  Science\" (Cambridge University Press) edited by Yonina Eldar and Miguel\n  Rodrigues. (v2 & v3) Minor corrections and edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory plays an indispensable role in the development of\nalgorithm-independent impossibility results, both for communication problems\nand for seemingly distinct areas such as statistics and machine learning. While\nnumerous information-theoretic tools have been proposed for this purpose, the\noldest one remains arguably the most versatile and widespread: Fano's\ninequality. In this chapter, we provide a survey of Fano's inequality and its\nvariants in the context of statistical estimation, adopting a versatile\nframework that covers a wide range of specific problems. We present a variety\nof key tools and techniques used for establishing impossibility results via\nthis approach, and provide representative examples covering group testing,\ngraphical model selection, sparse linear regression, density estimation, and\nconvex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 23:56:10 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 03:54:52 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 05:34:42 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Scarlett", "Jonathan", ""], ["Cevher", "Volkan", ""]]}, {"id": "1901.00560", "submitter": "Chaohua Sheng", "authors": "Zengyou He, Chaohua Sheng, Yan Liu, Quan Zou", "title": "Instance-Based Classification through Hypothesis Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is a fundamental problem in machine learning and data mining.\nDuring the past decades, numerous classification methods have been presented\nbased on different principles. However, most existing classifiers cast the\nclassification problem as an optimization problem and do not address the issue\nof statistical significance. In this paper, we formulate the binary\nclassification problem as a two-sample testing problem. More precisely, our\nclassification model is a generic framework that is composed of two steps. In\nthe first step, the distance between the test instance and each training\ninstance is calculated to derive two distance sets. In the second step, the\ntwo-sample test is performed under the null hypothesis that the two sets of\ndistances are drawn from the same cumulative distribution. After these two\nsteps, we have two p-values for each test instance and the test instance is\nassigned to the class associated with the smaller p-value. Essentially, the\npresented classification method can be regarded as an instance-based classifier\nbased on hypothesis testing. The experimental results on 40 real data sets show\nthat our method is able to achieve the same level performance as the\nstate-of-the-art classifiers and has significantly better performance than\nexisting testing-based classifiers. Furthermore, we can handle outlying\ninstances and control the false discovery rate of test instances assigned to\neach class under the same framework.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 00:18:02 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 05:54:19 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["He", "Zengyou", ""], ["Sheng", "Chaohua", ""], ["Liu", "Yan", ""], ["Zou", "Quan", ""]]}, {"id": "1901.00569", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Xuesong Wang, Yinhai Wang", "title": "Human-Like Autonomous Car-Following Model with Deep Reinforcement\n  Learning", "comments": null, "journal-ref": "Transportation Research Part C: Emerging Technologies 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a framework for human-like autonomous car-following\nplanning based on deep reinforcement learning (deep RL). Historical driving\ndata are fed into a simulation environment where an RL agent learns from trial\nand error interactions based on a reward function that signals how much the\nagent deviates from the empirical data. Through these interactions, an optimal\npolicy, or car-following model that maps in a human-like way from speed,\nrelative speed between a lead and following vehicle, and inter-vehicle spacing\nto acceleration of a following vehicle is finally obtained. The model can be\ncontinuously updated when more data are fed in. Two thousand car-following\nperiods extracted from the 2015 Shanghai Naturalistic Driving Study were used\nto train the model and compare its performance with that of traditional and\nrecent data-driven car-following models. As shown by this study results, a deep\ndeterministic policy gradient car-following model that uses disparity between\nsimulated and observed speed as the reward function and considers a reaction\ndelay of 1s, denoted as DDPGvRT, can reproduce human-like car-following\nbehavior with higher accuracy than traditional and recent data-driven\ncar-following models. Specifically, the DDPGvRT model has a spacing validation\nerror of 18% and speed validation error of 5%, which are less than those of\nother models, including the intelligent driver model, models based on locally\nweighted regression, and conventional neural network-based models. Moreover,\nthe DDPGvRT demonstrates good capability of generalization to various driving\nsituations and can adapt to different drivers by continuously learning. This\nstudy demonstrates that reinforcement learning methodology can offer insight\ninto driver behavior and can contribute to the development of human-like\nautonomous driving algorithms and traffic-flow models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 01:05:29 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Zhu", "Meixin", ""], ["Wang", "Xuesong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1901.00578", "submitter": "Zheng Zhang", "authors": "Jiali Luan and Zheng Zhang", "title": "Prediction of multi-dimensional spatial variation data via Bayesian\n  tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-dimensional computational method to predict the\nspatial variation data inside and across multiple dies of a wafer. This\ntechnique is based on tensor computation. A tensor is a high-dimensional\ngeneralization of a matrix or a vector. By exploiting the hidden low-rank\nproperty of a high-dimensional data array, the large amount of unknown\nvariation testing data may be predicted from a few random measurement samples.\nThe tensor rank, which decides the complexity of a tensor representation, is\ndecided by an available variational Bayesian approach. Our approach is\nvalidated by a practical chip testing data set, and it can be easily\ngeneralized to characterize the process variations of multiple wafers. Our\napproach is more efficient than the previous virtual probe techniques in terms\nof memory and computational cost when handling high-dimensional chip testing\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:25:30 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Luan", "Jiali", ""], ["Zhang", "Zheng", ""]]}, {"id": "1901.00596", "submitter": "Shirui Pan", "authors": "Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang,\n  Philip S. Yu", "title": "A Comprehensive Survey on Graph Neural Networks", "comments": "Minor revision (updated tables and references)", "journal-ref": null, "doi": "10.1109/TNNLS.2020.2978386", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has revolutionized many machine learning tasks in recent years,\nranging from image classification and video processing to speech recognition\nand natural language understanding. The data in these tasks are typically\nrepresented in the Euclidean space. However, there is an increasing number of\napplications where data are generated from non-Euclidean domains and are\nrepresented as graphs with complex relationships and interdependency between\nobjects. The complexity of graph data has imposed significant challenges on\nexisting machine learning algorithms. Recently, many studies on extending deep\nlearning approaches for graph data have emerged. In this survey, we provide a\ncomprehensive overview of graph neural networks (GNNs) in data mining and\nmachine learning fields. We propose a new taxonomy to divide the\nstate-of-the-art graph neural networks into four categories, namely recurrent\ngraph neural networks, convolutional graph neural networks, graph autoencoders,\nand spatial-temporal graph neural networks. We further discuss the applications\nof graph neural networks across various domains and summarize the open source\ncodes, benchmark data sets, and model evaluation of graph neural networks.\nFinally, we propose potential research directions in this rapidly growing\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 03:20:55 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 03:15:39 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 05:13:16 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 01:43:00 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Wu", "Zonghan", ""], ["Pan", "Shirui", ""], ["Chen", "Fengwen", ""], ["Long", "Guodong", ""], ["Zhang", "Chengqi", ""], ["Yu", "Philip S.", ""]]}, {"id": "1901.00612", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Ke Bai, Jianqiao Li, Guoyin Wang, Changyou Chen, Lawrence\n  Carin", "title": "Adversarial Learning of a Sampler Based on an Unnormalized Distribution", "comments": "Published in AISTATS 2019; Code: https://github.com/ChunyuanLI/RAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate adversarial learning in the case when only an unnormalized\nform of the density can be accessed, rather than samples. With insights so\ngarnered, adversarial learning is extended to the case for which one has access\nto an unnormalized form u(x) of the target density function, but no samples.\nFurther, new concepts in GAN regularization are developed, based on learning\nfrom samples or from u(x). The proposed method is compared to alternative\napproaches, with encouraging results demonstrated across a range of\napplications, including deep soft Q-learning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 05:23:28 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Li", "Chunyuan", ""], ["Bai", "Ke", ""], ["Li", "Jianqiao", ""], ["Wang", "Guoyin", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "1901.00615", "submitter": "Xin He", "authors": "Xin He, Yeheng Ge, Xingdong Feng", "title": "Structure learning via unstructured kernel-based M-regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning, identifying underlying structures of true target\nfunctions based on observed data plays a crucial role to facilitate subsequent\nmodeling and analysis. Unlike most of those existing methods that focus on some\nspecific settings under certain model assumptions, this paper proposes a\ngeneral and novel framework for recovering true structures of target functions\nby using unstructured M-regression in a reproducing kernel Hilbert space\n(RKHS). The proposed framework is inspired by the fact that gradient functions\ncan be employed as a valid tool to learn underlying structures, including\nsparse learning, interaction selection and model identification, and it is easy\nto implement by taking advantage of the nice properties of the RKHS. More\nimportantly, it admits a wide range of loss functions, and thus includes many\ncommonly used methods, such as mean regression, quantile regression,\nlikelihood-based classification, and margin-based classification, which is also\ncomputationally efficient by solving convex optimization tasks. The asymptotic\nresults of the proposed framework are established within a rich family of loss\nfunctions without any explicit model specifications. The superior performance\nof the proposed framework is also demonstrated by a variety of simulated\nexamples and a real case study.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 05:52:33 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 11:07:38 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["He", "Xin", ""], ["Ge", "Yeheng", ""], ["Feng", "Xingdong", ""]]}, {"id": "1901.00616", "submitter": "Sameera Ramasinghe Mr.", "authors": "Sameera Ramasinghe, Salman Khan, Nick Barnes", "title": "Volumetric Convolution: Automatic Representation Learning in Unit Ball", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution is an efficient technique to obtain abstract feature\nrepresentations using hierarchical layers in deep networks. Although performing\nconvolution in Euclidean geometries is fairly straightforward, its extension to\nother topological spaces---such as a sphere ($\\mathbb{S}^2$) or a unit ball\n($\\mathbb{B}^3$)---entails unique challenges. In this work, we propose a novel\n`\\emph{volumetric convolution}' operation that can effectively convolve\narbitrary functions in $\\mathbb{B}^3$. We develop a theoretical framework for\n\\emph{volumetric convolution} based on Zernike polynomials and efficiently\nimplement it as a differentiable and an easily pluggable layer for deep\nnetworks. Furthermore, our formulation leads to derivation of a novel formula\nto measure the symmetry of a function in $\\mathbb{B}^3$ around an arbitrary\naxis, that is useful in 3D shape analysis tasks. We demonstrate the efficacy of\nproposed volumetric convolution operation on a possible use-case i.e., 3D\nobject recognition task.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 05:53:25 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Ramasinghe", "Sameera", ""], ["Khan", "Salman", ""], ["Barnes", "Nick", ""]]}, {"id": "1901.00630", "submitter": "Michael Wojnowicz", "authors": "Michael Wojnowicz, Di Zhang, Glenn Chisholm, Xuan Zhao, Matt Wolff", "title": "Projecting \"better than randomly\": How to reduce the dimensionality of\n  very large datasets in a way that outperforms random projections", "comments": "Originally published in IEEE DSAA in 2016; this post-print fixes a\n  rendering error of the += operator in Algorithm 3", "journal-ref": "2016 IEEE 3rd International Conference on Data Science and\n  Advanced Analytics (DSAA) (pp. 184-193). IEEE", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For very large datasets, random projections (RP) have become the tool of\nchoice for dimensionality reduction. This is due to the computational\ncomplexity of principal component analysis. However, the recent development of\nrandomized principal component analysis (RPCA) has opened up the possibility of\nobtaining approximate principal components on very large datasets. In this\npaper, we compare the performance of RPCA and RP in dimensionality reduction\nfor supervised learning. In Experiment 1, study a malware classification task\non a dataset with over 10 million samples, almost 100,000 features, and over 25\nbillion non-zero values, with the goal of reducing the dimensionality to a\ncompressed representation of 5,000 features. In order to apply RPCA to this\ndataset, we develop a new algorithm called large sample RPCA (LS-RPCA), which\nextends the RPCA algorithm to work on datasets with arbitrarily many samples.\nWe find that classification performance is much higher when using LS-RPCA for\ndimensionality reduction than when using random projections. In particular,\nacross a range of target dimensionalities, we find that using LS-RPCA reduces\nclassification error by between 37% and 54%. Experiment 2 generalizes the\nphenomenon to multiple datasets, feature representations, and classifiers.\nThese findings have implications for a large number of research projects in\nwhich random projections were used as a preprocessing step for dimensionality\nreduction. As long as accuracy is at a premium and the target dimensionality is\nsufficiently less than the numeric rank of the dataset, randomized PCA may be a\nsuperior choice. Moreover, if the dataset has a large number of samples, then\nLS-RPCA will provide a method for obtaining the approximate principal\ncomponents.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 06:47:37 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Wojnowicz", "Michael", ""], ["Zhang", "Di", ""], ["Chisholm", "Glenn", ""], ["Zhao", "Xuan", ""], ["Wolff", "Matt", ""]]}, {"id": "1901.00660", "submitter": "Dayana Ribas Dr.", "authors": "Dayana Ribas, Jorge Llombart, Antonio Miguel, Luis Vicente", "title": "Deep Speech Enhancement for Reverberated and Noisy Signals using Wide\n  Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a deep speech enhancement method which exploits the high\npotential of residual connections in a wide neural network architecture, a\ntopology known as Wide Residual Network. This is supported on single\ndimensional convolutions computed alongside the time domain, which is a\npowerful approach to process contextually correlated representations through\nthe temporal domain, such as speech feature sequences. We find the residual\nmechanism extremely useful for the enhancement task since the signal always has\na linear shortcut and the non-linear path enhances it in several steps by\nadding or subtracting corrections. The enhancement capacity of the proposal is\nassessed by objective quality metrics and the performance of a speech\nrecognition system. This was evaluated in the framework of the REVERB Challenge\ndataset, including simulated and real samples of reverberated and noisy speech\nsignals. Results showed that enhanced speech from the proposed method succeeded\nfor both, the enhancement task with intelligibility purposes and the speech\nrecognition system. The DNN model, trained with artificial synthesized\nreverberation data, was able to deal with far-field reverberated speech from\nreal scenarios. Furthermore, the method was able to take advantage of the\nresidual connection achieving to enhance signals with low noise level, which is\nusually a strong handicap of traditional enhancement methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 09:41:25 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Ribas", "Dayana", ""], ["Llombart", "Jorge", ""], ["Miguel", "Antonio", ""], ["Vicente", "Luis", ""]]}, {"id": "1901.00696", "submitter": "Yann Ollivier", "authors": "Yann Ollivier", "title": "The Extended Kalman Filter is a Natural Gradient Descent in Trajectory\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extended Kalman filter is perhaps the most standard tool to estimate in\nreal time the state of a dynamical system from noisy measurements of some\nfunction of the system, with extensive practical applications (such as position\ntracking via GPS). While the plain Kalman filter for linear systems is\nwell-understood, the extended Kalman filter relies on linearizations which have\nbeen debated.\n  We recover the exact extended Kalman filter equations from first principles\nin statistical learning: the extended Kalman filter is equal to Amari's online\nnatural gradient, applied in the space of trajectories of the system. Namely,\neach possible trajectory of the dynamical system defines a probability law over\npossible observations. In principle this makes it possible to treat the\nunderlying trajectory as the parameter of a statistical model of the\nobservations. Then the parameter can be learned by gradient ascent on the\nlog-likelihood of observations, as they become available. Using Amari's natural\ngradient from information geometry (a gradient descent preconditioned with the\nFisher matrix, which provides parameterization-invariance) exactly recovers the\nextended Kalman filter.\n  This applies only to a particular choice of process noise in the Kalman\nfilter, namely, taking noise proportional to the posterior covariance - a\ncanonical choice in the absence of specific model information.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 12:26:07 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Ollivier", "Yann", ""]]}, {"id": "1901.00738", "submitter": "Mohammad Motamedi", "authors": "Mohammad Motamedi, Felix Portillo, Mahya Saffarpour, Daniel Fong, and\n  Soheil Ghiasi", "title": "Resource-Scalable CNN Synthesis for IoT Applications", "comments": "7 Pages, 3 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art image recognition systems use sophisticated Convolutional\nNeural Networks (CNNs) that are designed and trained to identify numerous\nobject classes. Such networks are fairly resource intensive to compute,\nprohibiting their deployment on resource-constrained embedded platforms. On one\nhand, the ability to classify an exhaustive list of categories is excessive for\nthe demands of most IoT applications. On the other hand, designing a new\ncustom-designed CNN for each new IoT application is impractical, due to the\ninherent difficulty in developing competitive models and time-to-market\npressure. To address this problem, we investigate the question of: \"Can one\nutilize an existing optimized CNN model to automatically build a competitive\nCNN for an IoT application whose objects of interest are a fraction of\ncategories that the original CNN was designed to classify, such that the\nresource requirement is proportionally scaled down?\" We use the term resource\nscalability to refer to this concept, and develop a methodology for automated\nsynthesis of resource scalable CNNs from an existing optimized baseline CNN.\nThe synthesized CNN has sufficient learning capacity for handling the given IoT\napplication requirements, and yields competitive accuracy. The proposed\napproach is fast, and unlike the presently common practice of CNN design, does\nnot require iterative rounds of training trial and error.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 01:21:57 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Motamedi", "Mohammad", ""], ["Portillo", "Felix", ""], ["Saffarpour", "Mahya", ""], ["Fong", "Daniel", ""], ["Ghiasi", "Soheil", ""]]}, {"id": "1901.00746", "submitter": "Mohammad Hessam Olya", "authors": "Mohammad Hessam Olya, Dongxiao Zhu, Kai Yang", "title": "Multi-task Prediction of Patient Workload", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing reliable workload predictive models can affect many aspects of\nclinical decision making procedure. The primary challenge in healthcare systems\nis handling the demand uncertainty over the time. This issue becomes more\ncritical for the healthcare facilities that provide service for chronic disease\ntreatment because of the need for continuous treatments over the time. Although\nsome researchers focused on exploring the methods for workload prediction\nrecently, few types of research mainly focused on forecasting a quantitative\nmeasure for the workload of healthcare providers. Also, among the mentioned\nstudies most of them just focused on workload prediction within one facility.\nThe drawback of the previous studies is the problem is not investigated for\nmultiple facilities where the quality of provided service, the equipment, and\nresources used for provided service as well as the diagnosis and treatment\nprocedures may differ even for patients with similar conditions. To tackle the\nmentioned issue, this paper suggests a framework for patient workload\nprediction by using patients data from VA facilities across the US. To capture\nthe information of patients with similar attributes and make the prediction\nmore accurate, a heuristic cluster based algorithm for single task learning as\nwell as a multi task learning approach are developed in this research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:51:22 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Olya", "Mohammad Hessam", ""], ["Zhu", "Dongxiao", ""], ["Yang", "Kai", ""]]}, {"id": "1901.00751", "submitter": "Neil Deshmukh", "authors": "Neil Deshmukh", "title": "Low-Cost Device Prototype for Automatic Medical Diagnosis Using Deep\n  Learning Methods", "comments": "Best Machine Learning Paper at the 9th IEEE Columbia Ubiquitous\n  Computing, Electronics & Mobile Communication Conference (UEMCON) and\n  presented at the IEEE MIT Undergraduate Research Technology Conference (URTC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel low-cost device prototype for the automatic\ndiagnosis of diseases, utilizing inputted symptoms and personal background. The\nengineering goal is to solve the problem of limited healthcare access with a\nsingle device. Diagnosing diseases automatically is an immense challenge, owing\nto their variable properties and symptoms. On the other hand, Neural Networks\nhave developed into a powerful tool in the field of machine learning, one that\nis showing to be extremely promising at computing diagnosis even with\ninconsistent variables.\n  In this research, a cheap device was created to allow for straightforward\ndiagnosis and treatment of human diseases. By utilizing Deep Neural Networks\n(DNNs) and Convolutional Neural Networks (CNNs), outfitted on a Raspberry Pi\nZero processor ($5), the device is able to detect up to 1537 different diseases\nand conditions and utilize a CNN for on-device visual diagnostics. The user can\ninput the symptoms using the buttons on the device and can take pictures using\nthe same mechanism. The algorithm processes inputted symptoms, providing\ndiagnosis and possible treatment options for common conditions. The purpose of\nthis work was to be able to diagnose diseases through an affordable processor\nwith high accuracy, as it is currently achieving an accuracy of 90% for Top-5\nsymptom-based diagnoses, and 91% for visual skin diseases. The NNs achieve\nperformance far above any other tested system, and its efficiency and ease of\nuse will prove it to be a helpful tool for people around the world. This device\ncould potentially provide low-cost universal access to vital diagnostics and\ntreatment options.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 03:27:56 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 01:59:35 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Deshmukh", "Neil", ""]]}, {"id": "1901.00756", "submitter": "Avishek Choudhury", "authors": "Avishek Choudhury, Christopher Greene", "title": "Classification of Functioning, Disability, and Health for Children and\n  Youth: ICF-CY Self Care (SCADI Dataset) Using Predictive Analytics", "comments": "In: Proceedings of the 2019 IISE Annual Conference. Edited by\n  Romeijn. HE, Schaefer. A, Thomas. R. Orlando: IISE; 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The International Classification of Functioning, Disability, and Health for\nChildren and Youth (ICF-CY) is a scaffold for designating and systematizing\ndata on functioning and disability. It offers a standard semantic and a\ntheoretical foundation for the demarcation and extent of wellbeing and\ninfirmity. The multidimensional layout of ICF-CY comprehends a plethora of\ninformation with about 1400 categories making it difficult to analyze. Our\nresearch proposes a predictive model that classify self-care problems on\nSelf-Care Activities Dataset based on the ICF- CY. The data used in this study\nresides 206 attributes of 70 children with motor and physical disability. Our\nstudy implements, compare and analyze Random Forest, Support vector machine,\nNaive Bayes, Hoeffding tree, and Lazy locally weighted learning using\ntwo-tailed T-test at 95% confidence interval. Boruta algorithm involved in the\nstudy minimizes the data dimensionality to advocate the minimal-optimal set of\npredictors. Random forest gave the best classification accuracy of 84.75%; root\nmean squared error of 0.18 and receiver operating characteristic of 0.99.\nPredictive analytics can simplify the usage of ICF-CY by automating the\nclassification process of disability, functioning, and health.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 04:31:51 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 09:59:34 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 04:03:32 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Choudhury", "Avishek", ""], ["Greene", "Christopher", ""]]}, {"id": "1901.00770", "submitter": "Johannes Schneider", "authors": "Johanes Schneider, Joshua Handali", "title": "Personalized explanation in machine learning: A conceptualization", "comments": "Accepted at 27th European Conference on Information Systems (ECIS\n  2019), Stockholm-Uppsala, Sweden, June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanation in machine learning and related fields such as artificial\nintelligence aims at making machine learning models and their decisions\nunderstandable to humans. Existing work suggests that personalizing\nexplanations might help to improve understandability. In this work, we derive a\nconceptualization of personalized explanation by defining and structuring the\nproblem based on prior work on machine learning explanation, personalization\n(in machine learning) and concepts and techniques from other domains such as\nprivacy and knowledge elicitation. We perform a categorization of explainee\ndata used in the process of personalization as well as describing means to\ncollect this data. We also identify three key explanation properties that are\namendable to personalization: complexity, decision information and\npresentation. We also enhance existing work on explanation by introducing\nadditional desiderata and measures to quantify the quality of personalized\nexplanations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 14:37:04 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 06:39:54 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Schneider", "Johanes", ""], ["Handali", "Joshua", ""]]}, {"id": "1901.00781", "submitter": "Yury Maximov", "authors": "Nikolay Stulov, Dejan J Sobajic, Yury Maximov, Deepjyoti Deka, Michael\n  Chertkov", "title": "Learning a Generator Model from Terminal Bus Data", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate approaches to reconstruct generator models from\nmeasurements available at the generator terminal bus using machine learning\n(ML) techniques. The goal is to develop an emulator which is trained online and\nis capable of fast predictive computations. The training is illustrated on\nsynthetic data generated based on available open-source dynamical generator\nmodel. Two ML techniques were developed and tested: (a) standard vector\nauto-regressive (VAR) model; and (b) novel customized long short-term memory\n(LSTM) deep learning model. Trade-offs in reconstruction ability between\ncomputationally light but linear AR model and powerful but computationally\ndemanding LSTM model are established and analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 15:03:42 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Stulov", "Nikolay", ""], ["Sobajic", "Dejan J", ""], ["Maximov", "Yury", ""], ["Deka", "Deepjyoti", ""], ["Chertkov", "Michael", ""]]}, {"id": "1901.00785", "submitter": "Kui Xu", "authors": "Kui Xu, Zhe Wang, Jiangping Shi, Hongsheng Li, Qiangfeng Cliff Zhang", "title": "A^2-Net: Molecular Structure Estimation from Cryo-EM Density Volumes", "comments": "8 pages, 5 figures, 4 tables", "journal-ref": "published on AAAI2019", "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Constructing of molecular structural models from Cryo-Electron Microscopy\n(Cryo-EM) density volumes is the critical last step of structure determination\nby Cryo-EM technologies. Methods have evolved from manual construction by\nstructural biologists to perform 6D translation-rotation searching, which is\nextremely compute-intensive. In this paper, we propose a learning-based method\nand formulate this problem as a vision-inspired 3D detection and pose\nestimation task. We develop a deep learning framework for amino acid\ndetermination in a 3D Cryo-EM density volume. We also design a sequence-guided\nMonte Carlo Tree Search (MCTS) to thread over the candidate amino acids to form\nthe molecular structure. This framework achieves 91% coverage on our newly\nproposed dataset and takes only a few minutes for a typical structure with a\nthousand amino acids. Our method is hundreds of times faster and several times\nmore accurate than existing automated solutions without any human intervention.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 15:15:26 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 19:51:56 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 09:25:30 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Xu", "Kui", ""], ["Wang", "Zhe", ""], ["Shi", "Jiangping", ""], ["Li", "Hongsheng", ""], ["Zhang", "Qiangfeng Cliff", ""]]}, {"id": "1901.00786", "submitter": "Yotam Gigi", "authors": "Yotam Gigi (1), Gal Elidan (1), Avinatan Hassidim (2), Yossi Matias\n  (3), Zach Moshe (3), Sella Nevo (3), Guy Shalev (3), Ami Wiesel (1) ((1)\n  Google Research and The Hebrew University of Jerusalem Israel, (2) Google\n  Research and Bar-Ilan University, (3) Google Research)", "title": "Towards Global Remote Discharge Estimation: Using the Few to Estimate\n  The Many", "comments": "The 4-page paper sent to NeurIPS 2018 AI for social good workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning hydrologic models for accurate riverine flood prediction at scale is\na challenge of great importance. One of the key difficulties is the need to\nrely on in-situ river discharge measurements, which can be quite scarce and\nunreliable, particularly in regions where floods cause the most damage every\nyear. Accordingly, in this work we tackle the problem of river discharge\nestimation at different river locations. A core characteristic of the data at\nhand (e.g. satellite measurements) is that we have few measurements for many\nlocations, all sharing the same physics that underlie the water discharge. We\ncapture this scenario in a simple but powerful common mechanism regression\n(CMR) model with a local component as well as a shared one which captures the\nglobal discharge mechanism. The resulting learning objective is non-convex, but\nwe show that we can find its global optimum by leveraging the power of joining\nlocal measurements across sites. In particular, using a spectral initialization\nwith provable near-optimal accuracy, we can find the optimum using standard\ndescent methods. We demonstrate the efficacy of our approach for the problem of\ndischarge estimation using simulations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 15:17:38 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Gigi", "Yotam", ""], ["Elidan", "Gal", ""], ["Hassidim", "Avinatan", ""], ["Matias", "Yossi", ""], ["Moshe", "Zach", ""], ["Nevo", "Sella", ""], ["Shalev", "Guy", ""], ["Wiesel", "Ami", ""]]}, {"id": "1901.00794", "submitter": "Leonardo Enzo Brito Da Silva", "authors": "Leonardo Enzo Brito da Silva, Islam Elnabarawy, Donald C. Wunsch II", "title": "Distributed dual vigilance fuzzy adaptive resonance theory learns\n  online, retrieves arbitrarily-shaped clusters, and mitigates order dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel adaptive resonance theory (ART)-based modular\narchitecture for unsupervised learning, namely the distributed dual vigilance\nfuzzy ART (DDVFA). DDVFA consists of a global ART system whose nodes are local\nfuzzy ART modules. It is equipped with the distinctive features of distributed\nhigher-order activation and match functions, using dual vigilance parameters\nresponsible for cluster similarity and data quantization. Together, these allow\nDDVFA to perform unsupervised modularization, create multi-prototype clustering\nrepresentations, retrieve arbitrarily-shaped clusters, and control its\ncompactness. Another important contribution is the reduction of\norder-dependence, an issue that affects any agglomerative clustering method.\nThis paper demonstrates two approaches for mitigating order-dependence:\npreprocessing using visual assessment of cluster tendency (VAT) or\npostprocessing using a novel Merge ART module. The former is suitable for batch\nprocessing, whereas the latter can be used in online learning. Experimental\nresults in the online learning mode carried out on 30 benchmark data sets show\nthat DDVFA cascaded with Merge ART statistically outperformed the best other\nART-based systems when samples were randomly presented. Conversely, they were\nfound to be statistically equivalent in the offline mode when samples were\npre-processed using VAT. Remarkably, performance comparisons to non-ART-based\nclustering algorithms show that DDVFA (which learns incrementally) was also\nstatistically equivalent to the non-incremental (offline) methods of DBSCAN,\nsingle linkage hierarchical agglomerative clustering (HAC), and k-means, while\nretaining the appealing properties of ART. Links to the source code and data\nare provided. Considering the algorithm's simplicity, online learning\ncapability, and performance, it is an ideal choice for many agglomerative\nclustering applications.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 19:02:35 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["da Silva", "Leonardo Enzo Brito", ""], ["Elnabarawy", "Islam", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "1901.00838", "submitter": "Eric Mazumdar", "authors": "Eric V. Mazumdar, Michael I. Jordan, S. Shankar Sastry", "title": "On Finding Local Nash Equilibria (and Only Local Nash Equilibria) in\n  Zero-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose local symplectic surgery, a two-timescale procedure for finding\nlocal Nash equilibria in two-player zero-sum games. We first show that previous\ngradient-based algorithms cannot guarantee convergence to local Nash equilibria\ndue to the existence of non-Nash stationary points. By taking advantage of the\ndifferential structure of the game, we construct an algorithm for which the\nlocal Nash equilibria are the only attracting fixed points. We also show that\nthe algorithm exhibits no oscillatory behaviors in neighborhoods of equilibria\nand show that it has the same per-iteration complexity as other recently\nproposed algorithms. We conclude by validating the algorithm on two numerical\nexamples: a toy example with multiple Nash equilibria and a non-Nash\nequilibrium, and the training of a small generative adversarial network (GAN).\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 18:33:53 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:00:08 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Mazumdar", "Eric V.", ""], ["Jordan", "Michael I.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1901.00861", "submitter": "Bradley Gram-Hansen", "authors": "Bradley Gram-Hansen, Patrick Helber, Indhu Varatharajan, Faiza Azam,\n  Alejandro Coca-Castro, Veronika Kopackova, Piotr Bilinski", "title": "Mapping Informal Settlements in Developing Countries using Machine\n  Learning and Low Resolution Multi-spectral Data", "comments": "Published at the AAAI/ACM Conference on AI, ethics and society.\n  Extended results from our previous workshop: arXiv:1812.00812", "journal-ref": "AAAI/ACM Conference on AI, Ethics, and Society (AIES 2019)", "doi": "10.1145/3306618.3314253", "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informal settlements are home to the most socially and economically\nvulnerable people on the planet. In order to deliver effective economic and\nsocial aid, non-government organizations (NGOs), such as the United Nations\nChildren's Fund (UNICEF), require detailed maps of the locations of informal\nsettlements. However, data regarding informal and formal settlements is\nprimarily unavailable and if available is often incomplete. This is due, in\npart, to the cost and complexity of gathering data on a large scale. To address\nthese challenges, we, in this work, provide three contributions. 1) A brand new\nmachine learning data-set, purposely developed for informal settlement\ndetection. 2) We show that it is possible to detect informal settlements using\nfreely available low-resolution (LR) data, in contrast to previous studies that\nuse very-high resolution (VHR) satellite and aerial imagery, something that is\ncost-prohibitive for NGOs. 3) We demonstrate two effective classification\nschemes on our curated data set, one that is cost-efficient for NGOs and\nanother that is cost-prohibitive for NGOs, but has additional utility. We\nintegrate these schemes into a semi-automated pipeline that converts either a\nLR or VHR satellite image into a binary map that encodes the locations of\ninformal settlements.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 16:51:40 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 23:18:26 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 11:11:39 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gram-Hansen", "Bradley", ""], ["Helber", "Patrick", ""], ["Varatharajan", "Indhu", ""], ["Azam", "Faiza", ""], ["Coca-Castro", "Alejandro", ""], ["Kopackova", "Veronika", ""], ["Bilinski", "Piotr", ""]]}, {"id": "1901.00862", "submitter": "Duo Xu", "authors": "Duo Xu", "title": "Learning Nonlinear State Space Models with Hamiltonian Sequential Monte\n  Carlo Sampler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State space models (SSM) have been widely applied for the analysis and\nvisualization of large sequential datasets. Sequential Monte Carlo (SMC) is a\nvery popular particle-based method to sample latent states from intractable\nposteriors. However, SSM is significantly influenced by the choice of the\nproposal. Recently Hamiltonian Monte Carlo (HMC) sampling has shown success in\nmany practical problems. In this paper, we propose an SMC augmented by HMC\n(HSMC) for inference and model learning of nonlinear SSM, which can exempt us\nfrom learning proposals and reduce the model complexity significantly. Based on\nthe measure preserving property of HMC, the particles directly generated by\ntransition function can approximate the posterior of latent states arbitrarily\nwell. In order to better adapt to the local geometry of latent space, the HMC\nis conducted on Riemannian manifold defined by a positive definite metric. In\naddition, we show that the proposed HSMC method can improve SSMs realized by\nboth Gaussian Processes (GP) and Neural Network (NN).\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 18:23:25 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Xu", "Duo", ""]]}, {"id": "1901.00877", "submitter": "Chun-An Chou", "authors": "Miaolin Fan, Chun-An Chou, Sheng-Che Yen, Yingzi Lin", "title": "A Network-based Multimodal Data Fusion Approach for Characterizing\n  Dynamic Multimodal Physiological Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the dynamic interactive patterns of complex systems helps gain\nin-depth understanding of how components interrelate with each other while\nperforming certain functions as a whole. In this study, we present a novel\nmultimodal data fusion approach to construct a complex network, which models\nthe interactions of biological subsystems in the human body under emotional\nstates through physiological responses. Joint recurrence plot and temporal\nnetwork metrics are employed to integrate the multimodal information at the\nsignal level. A benchmark public dataset of is used for evaluating our model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 19:04:12 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Fan", "Miaolin", ""], ["Chou", "Chun-An", ""], ["Yen", "Sheng-Che", ""], ["Lin", "Yingzi", ""]]}, {"id": "1901.00884", "submitter": "Jeremiah Johnson", "authors": "Jeremiah Johnson", "title": "Subspace Match Probably Does Not Accurately Assess the Similarity of\n  Learned Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.AC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning informative representations of data is one of the primary goals of\ndeep learning, but there is still little understanding as to what\nrepresentations a neural network actually learns. To better understand this,\nsubspace match was recently proposed as a method for assessing the similarity\nof the representations learned by neural networks. It has been shown that two\nnetworks with the same architecture trained from different initializations\nlearn representations that at hidden layers show low similarity when assessed\nwith subspace match, even when the output layers show high similarity and the\nnetworks largely exhibit similar performance on classification tasks. In this\nnote, we present a simple example motivated by standard results in commutative\nalgebra to illustrate how this can happen, and show that although the subspace\nmatch at a hidden layer may be 0, the representations learned may be isomorphic\nas vector spaces. This leads us to conclude that a subspace match comparison of\nlearned representations may well be uninformative, and it points to the need\nfor better methods of understanding learned representations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 19:17:45 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Johnson", "Jeremiah", ""]]}, {"id": "1901.00898", "submitter": "Horia Porav", "authors": "Horia Porav and Paul Newman", "title": "Imminent Collision Mitigation with Reinforcement Learning and Vision", "comments": "Presented at ITSC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the role of reinforcement learning in reducing the\nseverity of on-road collisions by controlling velocity and steering in\nsituations in which contact is imminent. We construct a model, given camera\nimages as input, that is capable of learning and predicting the dynamics of\nobstacles, cars and pedestrians, and train our policy using this model. Two\npolicies that control both braking and steering are compared against a baseline\nwhere the only action taken is (conventional) braking in a straight line. The\ntwo policies are trained using two distinct reward structures, one where any\nand all collisions incur a fixed penalty, and a second one where the penalty is\ncalculated based on already established delta-v models of injury severity. The\nresults show that both policies exceed the performance of the baseline, with\nthe policy trained using injury models having the highest performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 20:09:40 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Porav", "Horia", ""], ["Newman", "Paul", ""]]}, {"id": "1901.00902", "submitter": "Michael Mitzenmacher", "authors": "Michael Mitzenmacher", "title": "A Model for Learned Bloom Filters, and Optimizing by Sandwiching", "comments": "12 pages; the complete version of the paper that appears in NIPS\n  2018, including addendum on learned Bloomier filters. arXiv admin note:\n  substantial text overlap with arXiv:1802.00884, arXiv:1803.01474", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has suggested enhancing Bloom filters by using a pre-filter,\nbased on applying machine learning to determine a function that models the data\nset the Bloom filter is meant to represent. Here we model such learned Bloom\nfilters,, with the following outcomes: (1) we clarify what guarantees can and\ncannot be associated with such a structure; (2) we show how to estimate what\nsize the learning function must obtain in order to obtain improved performance;\n(3) we provide a simple method, sandwiching, for optimizing learned Bloom\nfilters; and (4) we propose a design and analysis approach for a learned\nBloomier filter, based on our modeling approach.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 20:14:12 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Mitzenmacher", "Michael", ""]]}, {"id": "1901.00952", "submitter": "Shayan Tabatabaei Nikkhah", "authors": "Shayan Tabatabaei Nikkhah, Mehdi Kamal, Ali Afzali-Kusha, Massoud\n  Pedram", "title": "Space Expansion of Feature Selection for Designing more Accurate Error\n  Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate computing is being considered as a promising design paradigm to\novercome the energy and performance challenges in computationally demanding\napplications. If the case where the accuracy can be configured, the quality\nlevel versus energy efficiency or delay also may be traded-off. For this\ntechnique to be used, one needs to make sure a satisfactory user experience.\nThis requires employing error predictors to detect unacceptable approximation\nerrors. In this work, we propose a scheduling-aware feature selection method\nwhich leverages the intermediate results of the hardware accelerator to improve\nthe prediction accuracy. Additionally, it configures the error predictors\naccording to the energy consumption and latency of the system. The approach\nenjoys the flexibility of the prediction time for a higher accuracy. The\nresults on various benchmarks demonstrate significant improvements in the\nprediction accuracy compared to the prior works which used only the accelerator\ninputs for the prediction.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 12:20:00 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Nikkhah", "Shayan Tabatabaei", ""], ["Kamal", "Mehdi", ""], ["Afzali-Kusha", "Ali", ""], ["Pedram", "Massoud", ""]]}, {"id": "1901.00959", "submitter": "Rajarshi Bhattacharyya", "authors": "Rajarshi Bhattacharyya, Archana Bura, Desik Rengarajan, Mason Rumuly,\n  Bainan Xia, Srinivas Shakkottai, Dileep Kalathil, Ricky K. P. Mok, Amogh\n  Dhamdhere", "title": "QFlow: A Learning Approach to High QoE Video Streaming at the Wireless\n  Edge", "comments": "Submitted to ToN in May, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant use of wireless access networks is for media streaming\napplications, which are only gaining popularity as ever more devices become\navailable for this purpose. However, current access networks treat all packets\nidentically, and lack the agility to determine which clients are most in need\nof service at a given time. Software reconfigurability of networking devices\nhas seen wide adoption, and this in turn implies that agile control policies\ncan be now instantiated on access networks. The goal of this work is to design,\ndevelop and demonstrate QFlow, a learning approach to create a value chain from\nthe application on one side, to algorithms operating over reconfigurable\ninfrastructure on the other, so that applications are able to obtain necessary\nresources for optimal performance. Using YouTube video streaming as an example,\nwe illustrate how QFlow is able to adaptively provide such resources and attain\na high QoE for all clients at a wireless access point.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 01:02:30 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 02:43:32 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 22:26:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Bhattacharyya", "Rajarshi", ""], ["Bura", "Archana", ""], ["Rengarajan", "Desik", ""], ["Rumuly", "Mason", ""], ["Xia", "Bainan", ""], ["Shakkottai", "Srinivas", ""], ["Kalathil", "Dileep", ""], ["Mok", "Ricky K. P.", ""], ["Dhamdhere", "Amogh", ""]]}, {"id": "1901.00997", "submitter": "L.A. Prashanth", "authors": "Prashanth L. A., Krishna Jagannathan, and Ravi Kumar Kolla", "title": "Concentration bounds for CVaR estimation: The cases of light-tailed and\n  heavy-tailed distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Value-at-Risk (CVaR) is a widely used risk metric in applications\nsuch as finance. We derive concentration bounds for CVaR estimates, considering\nseparately the cases of light-tailed and heavy-tailed distributions. In the\nlight-tailed case, we use a classical CVaR estimator based on the empirical\ndistribution constructed from the samples. For heavy-tailed random variables,\nwe assume a mild `bounded moment' condition, and derive a concentration bound\nfor a truncation-based estimator. Notably, our concentration bounds enjoy an\nexponential decay in the sample size, for heavy-tailed as well as light-tailed\ndistributions. To demonstrate the applicability of our concentration results,\nwe consider a CVaR optimization problem in a multi-armed bandit setting.\nSpecifically, we address the best CVaR-arm identification problem under a fixed\nbudget. We modify the well-known successive rejects algorithm to incorporate a\nCVaR-based criterion. Using the CVaR concentration result, we derive an\nupper-bound on the probability of incorrect identification by the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 07:10:04 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 18:21:12 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["A.", "Prashanth L.", ""], ["Jagannathan", "Krishna", ""], ["Kolla", "Ravi Kumar", ""]]}, {"id": "1901.01000", "submitter": "Wan Ping Chen", "authors": "Wan-Ping Nicole Chen and Yuan-chin Ivan Chang", "title": "Fast Multi-Class Probabilistic Classifier by Sparse Non-parametric\n  Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model interpretation is essential in many application scenarios and to\nbuild a classification model with a ease of model interpretation may provide\nuseful information for further studies and improvement. It is common to\nencounter with a lengthy set of variables in modern data analysis, especially\nwhen data are collected in some automatic ways. This kinds of datasets may not\ncollected with a specific analysis target and usually contains redundant\nfeatures, which have no contribution to a the current analysis task of\ninterest. Variable selection is a common way to increase the ability of model\ninterpretation and is popularly used with some parametric classification\nmodels. There is a lack of studies about variable selection in nonparametric\nclassification models such as the density estimation-based methods and this is\nespecially the case for multiple-class classification situations. In this study\nwe study multiple-class classification problems using the thought of sparse\nnon-parametric density estimation and propose a method for identifying high\nimpacts variables for each class. We present the asymptotic properties and the\ncomputation procedure for the proposed method together with some suggested\nsample size. We also repost the numerical results using both synthesized and\nsome real data sets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 07:16:12 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Chen", "Wan-Ping Nicole", ""], ["Chang", "Yuan-chin Ivan", ""]]}, {"id": "1901.01002", "submitter": "Haizhang Zhang", "authors": "Rongrong Lin, Haizhang Zhang, and Jun Zhang", "title": "On Reproducing Kernel Banach Spaces: Generic Definitions and Unified\n  Framework of Constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been emerging interest in constructing reproducing kernel\nBanach spaces (RKBS) for applied and theoretical purposes such as machine\nlearning, sampling reconstruction, sparse approximation and functional\nanalysis. Existing constructions include the reflexive RKBS via a bilinear\nform, the semi-inner-product RKBS, the RKBS with $\\ell^1$ norm, the $p$-norm\nRKBS via generalized Mercer kernels, etc. The definitions of RKBS and the\nassociated reproducing kernel in those references are dependent on the\nconstruction. Moreover, relations among those constructions are unclear. We\nexplore a generic definition of RKBS and the reproducing kernel for RKBS that\nis independent of construction. Furthermore, we propose a framework of\nconstructing RKBSs that unifies existing constructions mentioned above via a\ncontinuous bilinear form and a pair of feature maps. A new class of Orlicz\nRKBSs is proposed. Finally, we develop representer theorems for machine\nlearning in RKBSs constructed in our framework, which also unifies representer\ntheorems in existing RKBSs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 07:37:02 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Lin", "Rongrong", ""], ["Zhang", "Haizhang", ""], ["Zhang", "Jun", ""]]}, {"id": "1901.01007", "submitter": "Tong Geng", "authors": "Tong Geng, Tianqi Wang, Ang Li, Xi Jin, Martin Herbordt", "title": "FPDeep: Scalable Acceleration of CNN Training on Deeply-Pipelined FPGA\n  Clusters", "comments": "Accepted by IEEE TRANSACTIONS ON COMPUTERS (TC)", "journal-ref": null, "doi": "10.1109/TC.2020.3000118", "report-no": null, "categories": "cs.LG cs.AR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have revolutionized numerous applications, but\nthe demand for ever more performance remains unabated. Scaling DNN computations\nto larger clusters is generally done by distributing tasks in batch mode using\nmethods such as distributed synchronous SGD. Among the issues with this\napproach is that to make the distributed cluster work with high utilization,\nthe workload distributed to each node must be large, which implies nontrivial\ngrowth in the SGD mini-batch size.\n  In this paper, we propose a framework called FPDeep, which uses a hybrid of\nmodel and layer parallelism to configure distributed reconfigurable clusters to\ntrain DNNs. This approach has numerous benefits. First, the design does not\nsuffer from batch size growth. Second, novel workload and weight partitioning\nleads to balanced loads of both among nodes. And third, the entire system is a\nfine-grained pipeline. This leads to high parallelism and utilization and also\nminimizes the time features need to be cached while waiting for\nback-propagation. As a result, storage demand is reduced to the point where\nonly on-chip memory is used for the convolution layers. We evaluate FPDeep with\nthe Alexnet, VGG-16, and VGG-19 benchmarks. Experimental results show that\nFPDeep has good scalability to a large number of FPGAs, with the limiting\nfactor being the FPGA-to-FPGA bandwidth. With 6 transceivers per FPGA, FPDeep\nshows linearity up to 83 FPGAs. Energy efficiency is evaluated with respect to\nGOPs/J. FPDeep provides, on average, 6.36x higher energy efficiency than\ncomparable GPU servers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 07:54:46 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 19:03:13 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 22:33:11 GMT"}, {"version": "v4", "created": "Sun, 21 Jun 2020 04:17:46 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Geng", "Tong", ""], ["Wang", "Tianqi", ""], ["Li", "Ang", ""], ["Jin", "Xi", ""], ["Herbordt", "Martin", ""]]}, {"id": "1901.01030", "submitter": "Adel Javanmard", "authors": "Adel Javanmard, Hamid Nazerzadeh and Simeng Shao", "title": "Multi-Product Dynamic Pricing in High-Dimensions with Heterogeneous\n  Price Sensitivity", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of multi-product dynamic pricing, in a contextual\nsetting, for a seller of differentiated products. In this environment, the\ncustomers arrive over time and products are described by high-dimensional\nfeature vectors. Each customer chooses a product according to the widely used\nMultinomial Logit (MNL) choice model and her utility depends on the product\nfeatures as well as the prices offered. The seller a-priori does not know the\nparameters of the choice model but can learn them through interactions with\ncustomers. The seller's goal is to design a pricing policy that maximizes her\ncumulative revenue. This model is motivated by online marketplaces such as\nAirbnb platform and online advertising. We measure the performance of a pricing\npolicy in terms of regret, which is the expected revenue loss with respect to a\nclairvoyant policy that knows the parameters of the choice model in advance and\nalways sets the revenue-maximizing prices. We propose a pricing policy, named\nM3P, that achieves a $T$-period regret of $O(\\log(Td) ( \\sqrt{T}+ d\\log(T)))$\nunder heterogeneous price sensitivity for products with features of dimension\n$d$. We also use tools from information theory to prove that no policy can\nachieve worst-case $T$-regret better than $\\Omega(\\sqrt{T})$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 09:33:41 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 20:05:54 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 20:25:26 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Javanmard", "Adel", ""], ["Nazerzadeh", "Hamid", ""], ["Shao", "Simeng", ""]]}, {"id": "1901.01119", "submitter": "Mingjie Feng", "authors": "Mingjie Feng and Shiwen Mao", "title": "Dealing with Limited Backhaul Capacity in Millimeter Wave Systems: A\n  Deep Reinforcement Learning Approach", "comments": "Appear to IEEE Communications Magazine. Version with math contents\n  and equations", "journal-ref": null, "doi": "10.1109/MCOM.2019.1800565", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter Wave (MmWave) communication is one of the key technology of the\nfifth generation (5G) wireless systems to achieve the expected 1000x data rate.\nWith large bandwidth at mmWave band, the link capacity between users and base\nstations (BS) can be much higher compared to sub-6GHz wireless systems.\nMeanwhile, due to the high cost of infrastructure upgrade, it would be\ndifficult for operators to drastically enhance the capacity of backhaul links\nbetween mmWave BSs and the core network. As a result, the data rate provided by\nbackhaul may not be sufficient to support all mmWave links, the backhaul\nconnection becomes the new bottleneck that limits the system performance. On\nthe other hand, as mmWave channels are subject to random blockage, the data\nrates of mmWave users significantly vary over time. With limited backhaul\ncapacity and highly dynamic data rates of users, how to allocate backhaul\nresource to each user remains a challenge for mmWave systems. In this article,\nwe present a deep reinforcement learning (DRL) approach to address this\nchallenge. By learning the blockage pattern, the system dynamics can be\ncaptured and predicted, resulting in efficient utilization of backhaul\nresource. We begin with a discussion on DRL and its application in wireless\nsystems. We then investigate the problem backhaul resource allocation and\npresent the DRL based solution. Finally, we discuss open problems for future\nresearch and conclude this article.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 18:48:37 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Feng", "Mingjie", ""], ["Mao", "Shiwen", ""]]}, {"id": "1901.01144", "submitter": "Yun Feng", "authors": "Yun Feng, Bing-Chuan Wang", "title": "A unified framework of epidemic spreading prediction by empirical mode\n  decomposition based ensemble learning techniques", "comments": "Some issues need to be addressed in this manuscript", "journal-ref": null, "doi": "10.1109/TCSS.2019.2915615", "report-no": null, "categories": "cs.CE cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a unified susceptible-exposed-infected-susceptible-aware\n(SEIS-A) framework is proposed to combine epidemic spreading with individuals'\non-line self-consultation behaviors. An epidemic spreading prediction model is\nestablished based on the SEIS-A framework. The prediction process contains two\nphases. In phase I, the time series data of disease density are decomposed\nthrough the empirical mode decomposition (EMD) method to obtain the intrinsic\nmode functions (IMFs). In phase II, the ensemble learning techniques which use\nthe on-line query data as an additional input are applied to these IMFs.\nFinally, experiments for prediction of weekly consultation rates of\nHand-foot-and-mouth disease (HFMD) in Hong Kong are conducted to validate the\neffectiveness of the proposed method. The main advantage of this method is that\nit outperforms other methods on fluctuating complex data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:49:57 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 12:08:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Feng", "Yun", ""], ["Wang", "Bing-Chuan", ""]]}, {"id": "1901.01189", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Manoj Plakal, Daniel P. W. Ellis, Frederic Font,\n  Xavier Favory, Xavier Serra", "title": "Learning Sound Event Classifiers from Web Audio with Noisy Labels", "comments": "International Conference on Acoustics, Speech, and Signal Processing\n  (ICASSP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As sound event classification moves towards larger datasets, issues of label\nnoise become inevitable. Web sites can supply large volumes of user-contributed\naudio and metadata, but inferring labels from this metadata introduces errors\ndue to unreliable inputs, and limitations in the mapping. There is, however,\nlittle research into the impact of these errors. To foster the investigation of\nlabel noise in sound event classification we present FSDnoisy18k, a dataset\ncontaining 42.5 hours of audio across 20 sound classes, including a small\namount of manually-labeled data and a larger quantity of real-world noisy data.\nWe characterize the label noise empirically, and provide a CNN baseline system.\nExperiments suggest that training with large amounts of noisy data can\noutperform training with smaller amounts of carefully-labeled data. We also\nshow that noise-robust loss functions can be effective in improving performance\nin presence of corrupted labels.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 16:06:21 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 22:37:46 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Plakal", "Manoj", ""], ["Ellis", "Daniel P. W.", ""], ["Font", "Frederic", ""], ["Favory", "Xavier", ""], ["Serra", "Xavier", ""]]}, {"id": "1901.01250", "submitter": "Shirui Pan", "authors": "Shirui Pan, Ruiqi Hu, Sai-fu Fung, Guodong Long, Jing Jiang, Chengqi\n  Zhang", "title": "Learning Graph Embedding with Adversarial Training Methods", "comments": "To appear in IEEE Transactions on Cybernetics. arXiv admin note:\n  substantial text overlap with arXiv:1802.04407", "journal-ref": null, "doi": "10.1109/TCYB.2019.2932096", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding aims to transfer a graph into vectors to facilitate\nsubsequent graph analytics tasks like link prediction and graph clustering.\nMost approaches on graph embedding focus on preserving the graph structure or\nminimizing the reconstruction errors for graph data. They have mostly\noverlooked the embedding distribution of the latent codes, which unfortunately\nmay lead to inferior representation in many cases. In this paper, we present a\nnovel adversarially regularized framework for graph embedding. By employing the\ngraph convolutional network as an encoder, our framework embeds the topological\ninformation and node content into a vector representation, from which a graph\ndecoder is further built to reconstruct the input graph. The adversarial\ntraining principle is applied to enforce our latent codes to match a prior\nGaussian or Uniform distribution. Based on this framework, we derive two\nvariants of adversarial models, the adversarially regularized graph autoencoder\n(ARGA) and its variational version, adversarially regularized variational graph\nautoencoder (ARVGA), to learn the graph embedding effectively. We also exploit\nother potential variations of ARGA and ARVGA to get a deeper understanding on\nour designs. Experimental results compared among twelve algorithms for link\nprediction and twenty algorithms for graph clustering validate our solutions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 01:52:12 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 11:22:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Pan", "Shirui", ""], ["Hu", "Ruiqi", ""], ["Fung", "Sai-fu", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1901.01291", "submitter": "Gokul Swamy", "authors": "Gokul Swamy, Jens Schulz, Rohan Choudhury, Dylan Hadfield-Menell, Anca\n  Dragan", "title": "On the Utility of Model Learning in HRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental to robotics is the debate between model-based and model-free\nlearning: should the robot build an explicit model of the world, or learn a\npolicy directly? In the context of HRI, part of the world to be modeled is the\nhuman. One option is for the robot to treat the human as a black box and learn\na policy for how they act directly. But it can also model the human as an\nagent, and rely on a \"theory of mind\" to guide or bias the learning (grey box).\nWe contribute a characterization of the performance of these methods for an\nautonomous driving task under the optimistic case of having an ideal theory of\nmind, as well as under different scenarios in which the assumptions behind the\nrobot's theory of mind for the human are wrong, as they inevitably will be in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 19:55:49 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 02:34:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Swamy", "Gokul", ""], ["Schulz", "Jens", ""], ["Choudhury", "Rohan", ""], ["Hadfield-Menell", "Dylan", ""], ["Dragan", "Anca", ""]]}, {"id": "1901.01334", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Andrei V. Konstantinov, Viacheslav S. Chukanov, Mikhail\n  V. Kots, Anna A. Meldo", "title": "An Adaptive Weighted Deep Forest Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modification of the confidence screening mechanism based on adaptive\nweighing of every training instance at each cascade level of the Deep Forest is\nproposed. The idea underlying the modification is very simple and stems from\nthe confidence screening mechanism idea proposed by Pang et al. to simplify the\nDeep Forest classifier by means of updating the training set at each level in\naccordance with the classification accuracy of every training instance.\nHowever, if the confidence screening mechanism just removes instances from\ntraining and testing processes, then the proposed modification is more flexible\nand assigns weights by taking into account the classification accuracy. The\nmodification is similar to the AdaBoost to some extent. Numerical experiments\nillustrate good performance of the proposed modification in comparison with the\noriginal Deep Forest proposed by Zhou and Feng.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 22:45:22 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Utkin", "Lev V.", ""], ["Konstantinov", "Andrei V.", ""], ["Chukanov", "Viacheslav S.", ""], ["Kots", "Mikhail V.", ""], ["Meldo", "Anna A.", ""]]}, {"id": "1901.01343", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Daniele Grattarola, Lorenzo Livi, Cesare Alippi", "title": "Graph Neural Networks with convolutional ARMA filters", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2021.3054830", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular graph neural networks implement convolution operations on graphs\nbased on polynomial spectral filters. In this paper, we propose a novel graph\nconvolutional layer inspired by the auto-regressive moving average (ARMA)\nfilter that, compared to polynomial ones, provides a more flexible frequency\nresponse, is more robust to noise, and better captures the global graph\nstructure. We propose a graph neural network implementation of the ARMA filter\nwith a recursive and distributed formulation, obtaining a convolutional layer\nthat is efficient to train, localized in the node space, and can be transferred\nto new graphs at test time. We perform a spectral analysis to study the\nfiltering effect of the proposed ARMA layer and report experiments on four\ndownstream tasks: semi-supervised node classification, graph signal\nclassification, graph classification, and graph regression. Results show that\nthe proposed ARMA layer brings significant improvements over graph neural\nnetworks based on polynomial filters.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 00:16:00 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:48:11 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 11:25:57 GMT"}, {"version": "v4", "created": "Tue, 23 Apr 2019 09:24:34 GMT"}, {"version": "v5", "created": "Thu, 24 Oct 2019 20:18:30 GMT"}, {"version": "v6", "created": "Fri, 9 Oct 2020 16:29:39 GMT"}, {"version": "v7", "created": "Sun, 24 Jan 2021 19:04:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Grattarola", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1901.01346", "submitter": "Hooman Peiro Sajjad", "authors": "Hooman Peiro Sajjad, Andrew Docherty, Yuriy Tyshetskiy", "title": "Efficient Representation Learning Using Random Walks for Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important part of many machine learning workflows on graphs is vertex\nrepresentation learning, i.e., learning a low-dimensional vector representation\nfor each vertex in the graph. Recently, several powerful techniques for\nunsupervised representation learning have been demonstrated to give the\nstate-of-the-art performance in downstream tasks such as vertex classification\nand edge prediction. These techniques rely on random walks performed on the\ngraph in order to capture its structural properties. These structural\nproperties are then encoded in the vector representation space.\n  However, most contemporary representation learning methods only apply to\nstatic graphs while real-world graphs are often dynamic and change over time.\nStatic representation learning methods are not able to update the vector\nrepresentations when the graph changes; therefore, they must re-generate the\nvector representations on an updated static snapshot of the graph regardless of\nthe extent of the change in the graph. In this work, we propose computationally\nefficient algorithms for vertex representation learning that extend random walk\nbased methods to dynamic graphs. The computation complexity of our algorithms\ndepends upon the extent and rate of changes (the number of edges changed per\nupdate) and on the density of the graph. We empirically evaluate our algorithms\non real world datasets for downstream machine learning tasks of multi-class and\nmulti-label vertex classification. The results show that our algorithms can\nachieve competitive results to the state-of-the-art methods while being\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 00:35:43 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 12:37:28 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sajjad", "Hooman Peiro", ""], ["Docherty", "Andrew", ""], ["Tyshetskiy", "Yuriy", ""]]}, {"id": "1901.01347", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran, Svetha Venkatesh", "title": "Learning to Remember More with Less Memorization", "comments": "Accepted to ICLR'19, oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-augmented neural networks consisting of a neural controller and an\nexternal memory have shown potentials in long-term sequential learning. Current\nRAM-like memory models maintain memory accessing every timesteps, thus they do\nnot effectively leverage the short-term memory held in the controller. We\nhypothesize that this scheme of writing is suboptimal in memory utilization and\nintroduces redundant computation. To validate our hypothesis, we derive a\ntheoretical bound on the amount of information stored in a RAM-like system and\nformulate an optimization problem that maximizes the bound. The proposed\nsolution dubbed Uniform Writing is proved to be optimal under the assumption of\nequal timestep contributions. To relax this assumption, we introduce\nmodifications to the original solution, resulting in a solution termed Cached\nUniform Writing. This method aims to balance between maximizing memorization\nand forgetting via overwriting mechanisms. Through an extensive set of\nexperiments, we empirically demonstrate the advantages of our solutions over\nother recurrent architectures, claiming the state-of-the-arts in various\nsequential modeling tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 00:56:09 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 03:13:22 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1901.01365", "submitter": "Takayuki Osa", "authors": "Takayuki Osa and Voot Tangkaratt and Masashi Sugiyama", "title": "Hierarchical Reinforcement Learning via Advantage-Weighted Information\n  Maximization", "comments": "16 pages, ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world tasks are often highly structured. Hierarchical reinforcement\nlearning (HRL) has attracted research interest as an approach for leveraging\nthe hierarchical structure of a given task in reinforcement learning (RL).\nHowever, identifying the hierarchical policy structure that enhances the\nperformance of RL is not a trivial task. In this paper, we propose an HRL\nmethod that learns a latent variable of a hierarchical policy using mutual\ninformation maximization. Our approach can be interpreted as a way to learn a\ndiscrete and latent representation of the state-action space. To learn option\npolicies that correspond to modes of the advantage function, we introduce\nadvantage-weighted importance sampling. In our HRL method, the gating policy\nlearns to select option policies based on an option-value function, and these\noption policies are optimized based on the deterministic policy gradient\nmethod. This framework is derived by leveraging the analogy between a\nmonolithic policy in standard RL and a hierarchical policy in HRL by using a\ndeterministic option policy. Experimental results indicate that our HRL\napproach can learn a diversity of options and that it can enhance the\nperformance of RL in continuous control tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 04:43:05 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 06:34:21 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Osa", "Takayuki", ""], ["Tangkaratt", "Voot", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.01377", "submitter": "Qingbo Yin", "authors": "Qingbo Yin, Ehsan Adeli, Liran Shen, Dinggang Shen", "title": "Population-Guided Large Margin Classifier for High-Dimension Low\n  -Sample-Size Problems", "comments": null, "journal-ref": "Pattern Recognition, vol. 97, pp. 107030, 2020/01/01/, 2020", "doi": "10.1016/j.patcog.2019.107030", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various applications in different fields, such as gene expression analysis or\ncomputer vision, suffer from data sets with high-dimensional low-sample-size\n(HDLSS), which has posed significant challenges for standard statistical and\nmodern machine learning methods. In this paper, we propose a novel linear\nbinary classifier, denoted by population-guided large margin classifier\n(PGLMC), which is applicable to any sorts of data, including HDLSS. PGLMC is\nconceived with a projecting direction w given by the comprehensive\nconsideration of local structural information of the hyperplane and the\nstatistics of the training samples. Our proposed model has several advantages\ncompared to those widely used approaches. First, it is not sensitive to the\nintercept term b. Second, it operates well with imbalanced data. Third, it is\nrelatively simple to be implemented based on Quadratic Programming. Fourth, it\nis robust to the model specification for various real applications. The\ntheoretical properties of PGLMC are proven. We conduct a series of evaluations\non two simulated and six real-world benchmark data sets, including DNA\nclassification, digit recognition, medical image analysis, and face\nrecognition. PGLMC outperforms the state-of-the-art classification methods in\nmost cases, or at least obtains comparable results.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 07:46:38 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 22:10:53 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Yin", "Qingbo", ""], ["Adeli", "Ehsan", ""], ["Shen", "Liran", ""], ["Shen", "Dinggang", ""]]}, {"id": "1901.01379", "submitter": "Enlu Lin", "authors": "Enlu Lin and Qiong Chen and Xiaoming Qi", "title": "Deep Reinforcement Learning for Imbalanced Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data in real-world application often exhibit skewed class distribution which\nposes an intense challenge for machine learning. Conventional classification\nalgorithms are not effective in the case of imbalanced data distribution, and\nmay fail when the data distribution is highly imbalanced. To address this\nissue, we propose a general imbalanced classification model based on deep\nreinforcement learning. We formulate the classification problem as a sequential\ndecision-making process and solve it by deep Q-learning network. The agent\nperforms a classification action on one sample at each time step, and the\nenvironment evaluates the classification action and returns a reward to the\nagent. The reward from minority class sample is larger so the agent is more\nsensitive to the minority class. The agent finally finds an optimal\nclassification policy in imbalanced data under the guidance of specific reward\nfunction and beneficial learning environment. Experiments show that our\nproposed model outperforms the other imbalanced classification algorithms, and\nit can identify more minority samples and has great classification performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 07:59:47 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Lin", "Enlu", ""], ["Chen", "Qiong", ""], ["Qi", "Xiaoming", ""]]}, {"id": "1901.01388", "submitter": "Philipp Petersen", "authors": "H\\'ector Andrade-Loarca, Gitta Kutyniok, Ozan \\\"Oktem, Philipp\n  Petersen", "title": "Extraction of digital wavefront sets using applied harmonic analysis and\n  deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microlocal analysis provides deep insight into singularity structures and is\noften crucial for solving inverse problems, predominately, in imaging sciences.\nOf particular importance is the analysis of wavefront sets and the correct\nextraction of those. In this paper, we introduce the first algorithmic approach\nto extract the wavefront set of images, which combines data-based and\nmodel-based methods. Based on a celebrated property of the shearlet transform\nto unravel information on the wavefront set, we extract the wavefront set of an\nimage by first applying a discrete shearlet transform and then feeding local\npatches of this transform to a deep convolutional neural network trained on\nlabeled data. The resulting algorithm outperforms all competing algorithms in\nedge-orientation and ramp-orientation detection.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 09:27:46 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 12:09:55 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Andrade-Loarca", "H\u00e9ctor", ""], ["Kutyniok", "Gitta", ""], ["\u00d6ktem", "Ozan", ""], ["Petersen", "Philipp", ""]]}, {"id": "1901.01427", "submitter": "Ivan Ovinnikov", "authors": "Ivan Ovinnikov", "title": "Poincar\\'e Wasserstein Autoencoder", "comments": null, "journal-ref": "Bayesian Deep Learning Workshop (NeurIPS 2018)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a reformulation of the recently proposed Wasserstein\nautoencoder framework on a non-Euclidean manifold, the Poincar\\'e ball model of\nthe hyperbolic space. By assuming the latent space to be hyperbolic, we can use\nits intrinsic hierarchy to impose structure on the learned latent space\nrepresentations. We demonstrate the model in the visual domain to analyze some\nof its properties and show competitive results on a graph link prediction task.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 15:07:35 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 21:42:17 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ovinnikov", "Ivan", ""]]}, {"id": "1901.01477", "submitter": "Michael Weylandt", "authors": "Michael Weylandt and John Nagorski and Genevera I. Allen", "title": "Dynamic Visualization and Fast Computation for Convex Clustering via\n  Algorithmic Regularization", "comments": "To appear in the Journal of Computational and Graphical Statistics", "journal-ref": null, "doi": "10.1080/10618600.2019.1629943", "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convex clustering is a promising new approach to the classical problem of\nclustering, combining strong performance in empirical studies with rigorous\ntheoretical foundations. Despite these advantages, convex clustering has not\nbeen widely adopted, due to its computationally intensive nature and its lack\nof compelling visualizations. To address these impediments, we introduce\nAlgorithmic Regularization, an innovative technique for obtaining high-quality\nestimates of regularization paths using an iterative one-step approximation\nscheme. We justify our approach with a novel theoretical result, guaranteeing\nglobal convergence of the approximate path to the exact solution under\neasily-checked non-data-dependent assumptions. The application of algorithmic\nregularization to convex clustering yields the Convex Clustering via\nAlgorithmic Regularization Paths (CARP) algorithm for computing the clustering\nsolution path. On example data sets from genomics and text analysis, CARP\ndelivers over a 100-fold speed-up over existing methods, while attaining a\nfiner approximation grid than standard methods. Furthermore, CARP enables\nimproved visualization of clustering solutions: the fine solution grid returned\nby CARP can be used to construct a convex clustering-based dendrogram, as well\nas forming the basis of a dynamic path-wise visualization based on modern web\ntechnologies. Our methods are implemented in the open-source R package\nclustRviz, available at https://github.com/DataSlingers/clustRviz.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 00:22:35 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 22:40:47 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 21:36:39 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 18:32:32 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Weylandt", "Michael", ""], ["Nagorski", "John", ""], ["Allen", "Genevera I.", ""]]}, {"id": "1901.01484", "submitter": "Renjie Liao", "authors": "Renjie Liao, Zhizhen Zhao, Raquel Urtasun, Richard S. Zemel", "title": "LanczosNet: Multi-Scale Deep Graph Convolutional Networks", "comments": "The International Conference on Learning Representations (ICLR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Lanczos network (LanczosNet), which uses the Lanczos algorithm\nto construct low rank approximations of the graph Laplacian for graph\nconvolution. Relying on the tridiagonal decomposition of the Lanczos algorithm,\nwe not only efficiently exploit multi-scale information via fast approximated\ncomputation of matrix power but also design learnable spectral filters. Being\nfully differentiable, LanczosNet facilitates both graph kernel learning as well\nas learning node embeddings. We show the connection between our LanczosNet and\ngraph based manifold learning methods, especially the diffusion maps. We\nbenchmark our model against several recent deep graph networks on citation\nnetworks and QM8 quantum chemistry dataset. Experimental results show that our\nmodel achieves the state-of-the-art performance in most tasks. Code is released\nat: \\url{https://github.com/lrjconan/LanczosNetwork}.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 01:40:24 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 14:35:41 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Liao", "Renjie", ""], ["Zhao", "Zhizhen", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1901.01493", "submitter": "Huayu Li", "authors": "Huayu Li", "title": "Channel Locality Block: A Variant of Squeeze-and-Excitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism is a hot spot in deep learning field. Using channel\nattention model is an effective method for improving the performance of the\nconvolutional neural network. Squeeze-and-Excitation block takes advantage of\nthe channel dependence, selectively emphasizing the important channels and\ncompressing the relatively useless channel. In this paper, we proposed a\nvariant of SE block based on channel locality. Instead of using full connection\nlayers to explore the global channel dependence, we adopt convolutional layers\nto learn the correlation between the nearby channels. We term this new\nalgorithm Channel Locality(C-Local) block. We evaluate SE block and C-Local\nblock by applying them to different CNNs architectures on cifar-10 dataset. We\nobserved that our C-Local block got higher accuracy than SE block did.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 03:22:26 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Li", "Huayu", ""]]}, {"id": "1901.01498", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma and Chunting Zhou and Eduard Hovy", "title": "MAE: Mutual Posterior-Divergence Regularization for Variational\n  AutoEncoders", "comments": "Published at ICLR-2019. 12 pages contents + 4 pages appendix, 5\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoder (VAE), a simple and effective deep generative model,\nhas led to a number of impressive empirical successes and spawned many advanced\nvariants and theoretical investigations. However, recent studies demonstrate\nthat, when equipped with expressive generative distributions (aka. decoders),\nVAE suffers from learning uninformative latent representations with the\nobservation called KL Varnishing, in which case VAE collapses into an\nunconditional generative model. In this work, we introduce mutual\nposterior-divergence regularization, a novel regularization that is able to\ncontrol the geometry of the latent space to accomplish meaningful\nrepresentation learning, while achieving comparable or superior capability of\ndensity estimation. Experiments on three image benchmark datasets demonstrate\nthat, when equipped with powerful decoders, our model performs well both on\ndensity estimation and representation learning.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 04:01:47 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ma", "Xuezhe", ""], ["Zhou", "Chunting", ""], ["Hovy", "Eduard", ""]]}, {"id": "1901.01499", "submitter": "Ryen Krusinga", "authors": "Ryen Krusinga, Sohil Shah, Matthias Zwicker, Tom Goldstein, David\n  Jacobs", "title": "Understanding the (un)interpretability of natural image distributions\n  using generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability density estimation is a classical and well studied problem, but\nstandard density estimation methods have historically lacked the power to model\ncomplex and high-dimensional image distributions. More recent generative models\nleverage the power of neural networks to implicitly learn and represent\nprobability models over complex images. We describe methods to extract explicit\nprobability density estimates from GANs, and explore the properties of these\nimage density functions. We perform sanity check experiments to provide\nevidence that these probabilities are reasonable. However, we also show that\ndensity functions of natural images are difficult to interpret and thus limited\nin use. We study reasons for this lack of interpretability, and show that we\ncan get interpretability back by doing density estimation on latent\nrepresentations of images.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 04:11:29 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 22:11:57 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Krusinga", "Ryen", ""], ["Shah", "Sohil", ""], ["Zwicker", "Matthias", ""], ["Goldstein", "Tom", ""], ["Jacobs", "David", ""]]}, {"id": "1901.01502", "submitter": "Yuzhong Wu", "authors": "Yuzhong Wu and Tan Lee", "title": "Enhancing Sound Texture in CNN-Based Acoustic Scene Classification", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic scene classification is the task of identifying the scene from which\nthe audio signal is recorded. Convolutional neural network (CNN) models are\nwidely adopted with proven successes in acoustic scene classification. However,\nthere is little insight on how an audio scene is perceived in CNN, as what have\nbeen demonstrated in image recognition research. In the present study, the\nClass Activation Mapping (CAM) is utilized to analyze how the log-magnitude\nMel-scale filter-bank (log-Mel) features of different acoustic scenes are\nlearned in a CNN classifier. It is noted that distinct high-energy\ntime-frequency components of audio signals generally do not correspond to\nstrong activation on CAM, while the background sound texture are well learned\nin CNN. In order to make the sound texture more salient, we propose to apply\nthe Difference of Gaussian (DoG) and Sobel operator to process the log-Mel\nfeatures and enhance edge information of the time-frequency image. Experimental\nresults on the DCASE 2017 ASC challenge show that using edge enhanced log-Mel\nimages as input feature of CNN significantly improves the performance of audio\nscene classification.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 05:21:41 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Wu", "Yuzhong", ""], ["Lee", "Tan", ""]]}, {"id": "1901.01536", "submitter": "Bangalore Ravi Kiran", "authors": "Victor Talpaert, Ibrahim Sobh, B Ravi Kiran, Patrick Mannion, Senthil\n  Yogamani, Ahmad El-Sallab and Patrick Perez", "title": "Exploring applications of deep reinforcement learning for real-world\n  autonomous driving systems", "comments": "Accepted for Oral Presentation at VISAPP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has become increasingly powerful in recent\nyears, with notable achievements such as Deepmind's AlphaGo. It has been\nsuccessfully deployed in commercial vehicles like Mobileye's path planning\nsystem. However, a vast majority of work on DRL is focused on toy examples in\ncontrolled synthetic car simulator environments such as TORCS and CARLA. In\ngeneral, DRL is still at its infancy in terms of usability in real-world\napplications. Our goal in this paper is to encourage real-world deployment of\nDRL in various autonomous driving (AD) applications. We first provide an\noverview of the tasks in autonomous driving systems, reinforcement learning\nalgorithms and applications of DRL to AD systems. We then discuss the\nchallenges which must be addressed to enable further progress towards\nreal-world deployment.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 13:02:46 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 20:36:00 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 17:57:54 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Talpaert", "Victor", ""], ["Sobh", "Ibrahim", ""], ["Kiran", "B Ravi", ""], ["Mannion", "Patrick", ""], ["Yogamani", "Senthil", ""], ["El-Sallab", "Ahmad", ""], ["Perez", "Patrick", ""]]}, {"id": "1901.01544", "submitter": "Zehua Cheng", "authors": "Zehua Cheng and Zhenghua Xu", "title": "Bandwidth Reduction using Importance Weighted Pruning on Ring AllReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is inevitable to train large deep learning models on a large-scale cluster\nequipped with accelerators system. Deep gradient compression would highly\nincrease the bandwidth utilization and speed up the training process but hard\nto implement on ring structure. In this paper, we find that redundant gradient\nand gradient staleness has negative effect on training. We have observed that\nin different epoch and different steps, the neural networks focus on updating\ndifferent layers and different parameters. In order to save more communication\nbandwidth and preserve the accuracy on ring structure, which break the restrict\nas the node increase, we propose a new algorithm to measure the importance of\ngradients on large-scale cluster implementing ring all-reduce based on the size\nof the ratio of parameter calculation gradient to parameter value. Our\nimportance weighted pruning approach achieved 64X and 58.8X of gradient\ncompression ratio on AlexNet and ResNet50 on ImageNet. Meanwhile, in order to\nmaintain the sparseness of the gradient propagation, we randomly broadcast the\nindex of important gradients on each node. While the remaining nodes are ready\nfor the index gradient and perform all-reduce update. This would speed up the\nconvergence of the model and preserve the training accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 13:52:07 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Cheng", "Zehua", ""], ["Xu", "Zhenghua", ""]]}, {"id": "1901.01558", "submitter": "Shaodi Qian", "authors": "Shaodi Qian, Sheng-Che Yen, Eric Folmar, Chun-An Chou", "title": "Self-Expressive Subspace Clustering to Recognize Motion Dynamics of a\n  Multi-Joint Coordination for Chronic Ankle Instability", "comments": null, "journal-ref": null, "doi": "10.1080/24725579.2019.1673521", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ankle sprains and instability are major public health concerns. Up to 70% of\nindividuals do not fully recover from a single ankle sprain and eventually\ndevelop chronic ankle instability (CAI). The diagnosis of CAI has been mainly\nbased on self-report rather than objective biomechanical measures. The goal of\nthis study is to quantitatively recognize the motion pattern of a multi-joint\ncoordination using biosensor data from bilateral hip, knee, and ankle joints,\nand further distinguish between CAI and healthy cohorts. We propose an analytic\nframework, where a nonlinear subspace clustering method is developed to learn\nthe motion dynamic patterns from an inter-connected network of multiply joints.\nA support vector machine model is trained with a leave-one-subject-out cross\nvalidation to validate the learned measures compared to traditional statistical\nmeasures. The computational results showed >70% classification accuracy on\naverage based on the dataset of 48 subjects (25 with CAI and 23 normal\ncontrols) examined in our designed experiment. It is found that CAI can be\nobserved from other joints (e.g., hips) significantly, which reflects the fact\nthat there are interactions in the multi-joint coordination system. The\ndeveloped method presents a potential to support the decisions with motion\npatterns during diagnosis, treatment, rehabilitation of gait abnormality caused\nby physical injury (e.g., ankle sprains in this study) or even central nervous\nsystem disorders.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 15:51:20 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 03:46:57 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 14:13:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Qian", "Shaodi", ""], ["Yen", "Sheng-Che", ""], ["Folmar", "Eric", ""], ["Chou", "Chun-An", ""]]}, {"id": "1901.01568", "submitter": "Bo Yang", "authors": "Bo Yang, Xiao Fu, Nicholas D. Sidiropoulos, Kejun Huang", "title": "Learning Nonlinear Mixtures: Identifiability and Algorithm", "comments": "15 pages", "journal-ref": null, "doi": "10.1109/TSP.2020.2989551", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixture models have proven very useful in a plethora of applications,\ne.g., topic modeling, clustering, and source separation. As a critical aspect\nof the linear mixture models, identifiability of the model parameters is\nwell-studied, under frameworks such as independent component analysis and\nconstrained matrix factorization. Nevertheless, when the linear mixtures are\ndistorted by an unknown nonlinear functions -- which is well-motivated and more\nrealistic in many cases -- the identifiability issues are much less studied.\nThis work proposes an identification criterion for a nonlinear mixture model\nthat is well grounded in many real-world applications, and offers\nidentifiability guarantees. A practical implementation based on a judiciously\ndesigned neural network is proposed to realize the criterion, and an effective\nlearning algorithm is proposed. Numerical results on synthetic and real-data\ncorroborate effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 16:24:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Yang", "Bo", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Huang", "Kejun", ""]]}, {"id": "1901.01585", "submitter": "Antoine Dedieu", "authors": "Antoine Dedieu, Rahul Mazumder", "title": "Solving large-scale L1-regularized SVMs and cousins: the surprising\n  effectiveness of column and constraint generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear Support Vector Machine (SVM) is one of the most popular binary\nclassification techniques in machine learning. Motivated by applications in\nmodern high dimensional statistics, we consider penalized SVM problems\ninvolving the minimization of a hinge-loss function with a convex\nsparsity-inducing regularizer such as: the L1-norm on the coefficients, its\ngrouped generalization and the sorted L1-penalty (aka Slope). Each problem can\nbe expressed as a Linear Program (LP) and is computationally challenging when\nthe number of features and/or samples is large -- the current state of\nalgorithms for these problems is rather nascent when compared to the usual\nL2-regularized linear SVM. To this end, we propose new computational algorithms\nfor these LPs by bringing together techniques from (a) classical column (and\nconstraint) generation methods and (b) first order methods for non-smooth\nconvex optimization - techniques that are rarely used together for solving\nlarge scale LPs. These components have their respective strengths; and while\nthey are found to be useful as separate entities, they have not been used\ntogether in the context of solving large scale LPs such as the ones studied\nherein. Our approach complements the strengths of (a) and (b) --- leading to a\nscheme that seems to outperform commercial solvers as well as specialized\nimplementations for these problems by orders of magnitude. We present numerical\nresults on a series of real and synthetic datasets demonstrating the surprising\neffectiveness of classic column/constraint generation methods in the context of\nchallenging LP-based machine learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 18:14:09 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dedieu", "Antoine", ""], ["Mazumder", "Rahul", ""]]}, {"id": "1901.01588", "submitter": "Yue Zhao", "authors": "Yue Zhao, Zain Nasrullah, Zheng Li", "title": "PyOD: A Python Toolbox for Scalable Outlier Detection", "comments": "7 pages, 1 figure, version 2 (published in JMLR Volume 20, MLOSS\n  track)", "journal-ref": "Journal of Machine Learning Research (JMLR), 20(96):1-7, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PyOD is an open-source Python toolbox for performing scalable outlier\ndetection on multivariate data. Uniquely, it provides access to a wide range of\noutlier detection algorithms, including established outlier ensembles and more\nrecent neural network-based approaches, under a single, well-documented API\ndesigned for use by both practitioners and researchers. With robustness and\nscalability in mind, best practices such as unit testing, continuous\nintegration, code coverage, maintainability checks, interactive examples and\nparallelization are emphasized as core components in the toolbox's development.\nPyOD is compatible with both Python 2 and 3 and can be installed through Python\nPackage Index (PyPI) or https://github.com/yzhao062/pyod.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 18:29:35 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 19:07:19 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Zhao", "Yue", ""], ["Nasrullah", "Zain", ""], ["Li", "Zheng", ""]]}, {"id": "1901.01592", "submitter": "Andrey Kormilitzin", "authors": "Luka Gligic, Andrey Kormilitzin, Paul Goldberg, Alejo Nevado-Holgado", "title": "Named Entity Recognition in Electronic Health Records Using Transfer\n  Learning Bootstrapped Neural Networks", "comments": "11 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) have become the state of the art in many machine\nlearning applications, especially in image and sound processing [1]. The same,\nalthough to a lesser extent [2,3], could be said in natural language processing\n(NLP) tasks, such as named entity recognition. However, the success of NNs\nremains dependent on the availability of large labelled datasets, which is a\nsignificant hurdle in many important applications. One such case are electronic\nhealth records (EHRs), which are arguably the largest source of medical data,\nmost of which lies hidden in natural text [4,5]. Data access is difficult due\nto data privacy concerns, and therefore annotated datasets are scarce. With\nscarce data, NNs will likely not be able to extract this hidden information\nwith practical accuracy. In our study, we develop an approach that solves these\nproblems for named entity recognition, obtaining 94.6 F1 score in I2B2 2009\nMedical Extraction Challenge [6], 4.3 above the architecture that won the\ncompetition. Beyond the official I2B2 challenge, we further achieve 82.4 F1 on\nextracting relationships between medical terms. To reach this state-of-the-art\naccuracy, our approach applies transfer learning to leverage on datasets\nannotated for other I2B2 tasks, and designs and trains embeddings that\nspecially benefit from such transfer.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 18:53:12 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 15:26:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gligic", "Luka", ""], ["Kormilitzin", "Andrey", ""], ["Goldberg", "Paul", ""], ["Nevado-Holgado", "Alejo", ""]]}, {"id": "1901.01604", "submitter": "Eric Hall", "authors": "Kimoon Um and Eric Joseph Hall and Markos A. Katsoulakis and Daniel M.\n  Tartakovsky", "title": "Causality and Bayesian network PDEs for multiscale representations of\n  porous media", "comments": "23 pages, 11 figures and 5 tables", "journal-ref": "Journal of Computational Physics 394 (2019) 658--678", "doi": "10.1016/j.jcp.2019.06.007", "report-no": null, "categories": "math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microscopic (pore-scale) properties of porous media affect and often\ndetermine their macroscopic (continuum- or Darcy-scale) counterparts.\nUnderstanding the relationship between processes on these two scales is\nessential to both the derivation of macroscopic models of, e.g., transport\nphenomena in natural porous media, and the design of novel materials, e.g., for\nenergy storage. Most microscopic properties exhibit complex statistical\ncorrelations and geometric constraints, which presents challenges for the\nestimation of macroscopic quantities of interest (QoIs), e.g., in the context\nof global sensitivity analysis (GSA) of macroscopic QoIs with respect to\nmicroscopic material properties. We present a systematic way of building\ncorrelations into stochastic multiscale models through Bayesian networks. This\nallows us to construct the joint probability density function (PDF) of model\nparameters through causal relationships that emulate engineering processes,\ne.g., the design of hierarchical nanoporous materials. Such PDFs also serve as\ninput for the forward propagation of parametric uncertainty; our findings\nindicate that the inclusion of causal relationships impacts predictions of\nmacroscopic QoIs. To assess the impact of correlations and causal relationships\nbetween microscopic parameters on macroscopic material properties, we use a\nmoment-independent GSA based on the differential mutual information. Our GSA\naccounts for the correlated inputs and complex non-Gaussian QoIs. The global\nsensitivity indices are used to rank the effect of uncertainty in microscopic\nparameters on macroscopic QoIs, to quantify the impact of causality on the\nmultiscale model's predictions, and to provide physical interpretations of\nthese results for hierarchical nanoporous materials.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 20:49:22 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Um", "Kimoon", ""], ["Hall", "Eric Joseph", ""], ["Katsoulakis", "Markos A.", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "1901.01631", "submitter": "Richard Zhang", "authors": "Richard Y. Zhang, Somayeh Sojoudi, Javad Lavaei", "title": "Sharp Restricted Isometry Bounds for the Inexistence of Spurious Local\n  Minima in Nonconvex Matrix Recovery", "comments": "v2: fixed several typos; v3: accepted at JMLR", "journal-ref": "Journal of Machine Learning Research 20 (114): 1-34, 2019", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex matrix recovery is known to contain no spurious local minima under\na restricted isometry property (RIP) with a sufficiently small RIP constant\n$\\delta$. If $\\delta$ is too large, however, then counterexamples containing\nspurious local minima are known to exist. In this paper, we introduce a proof\ntechnique that is capable of establishing sharp thresholds on $\\delta$ to\nguarantee the inexistence of spurious local minima. Using the technique, we\nprove that in the case of a rank-1 ground truth, an RIP constant of\n$\\delta<1/2$ is both necessary and sufficient for exact recovery from any\narbitrary initial point (such as a random point). We also prove a local\nrecovery result: given an initial point $x_{0}$ satisfying\n$f(x_{0})\\le(1-\\delta)^{2}f(0)$, any descent algorithm that converges to\nsecond-order optimality guarantees exact recovery.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 00:11:27 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 00:37:07 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 17:39:29 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Richard Y.", ""], ["Sojoudi", "Somayeh", ""], ["Lavaei", "Javad", ""]]}, {"id": "1901.01672", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, J. Zico Kolter", "title": "Generalization in Deep Networks: The Role of Distance from\n  Initialization", "comments": "Spotlight paper at NeurIPS 2017 workshop on Deep Learning: Bridging\n  Theory and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why does training deep neural networks using stochastic gradient descent\n(SGD) result in a generalization error that does not worsen with the number of\nparameters in the network? To answer this question, we advocate a notion of\neffective model capacity that is dependent on {\\em a given random\ninitialization of the network} and not just the training algorithm and the data\ndistribution. We provide empirical evidences that demonstrate that the model\ncapacity of SGD-trained deep networks is in fact restricted through implicit\nregularization of {\\em the $\\ell_2$ distance from the initialization}. We also\nprovide theoretical arguments that further highlight the need for\ninitialization-dependent notions of model capacity. We leave as open questions\nhow and why distance from initialization is regularized, and whether it is\nsufficient to explain generalization.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 05:59:11 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 08:08:13 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1901.01686", "submitter": "Fayyaz Minhas", "authors": "Fayyaz Minhas, Amina Asif, and Asa Ben-Hur", "title": "Ten ways to fool the masses with machine learning", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If you want to tell people the truth, make them laugh, otherwise they'll kill\nyou. (source unclear)\n  Machine learning and deep learning are the technologies of the day for\ndeveloping intelligent automatic systems. However, a key hurdle for progress in\nthe field is the literature itself: we often encounter papers that report\nresults that are difficult to reconstruct or reproduce, results that\nmis-represent the performance of the system, or contain other biases that limit\ntheir validity. In this semi-humorous article, we discuss issues that arise in\nrunning and reporting results of machine learning experiments. The purpose of\nthe article is to provide a list of watch out points for researchers to be\naware of when developing machine learning models or writing and reviewing\nmachine learning papers.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 07:27:11 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Minhas", "Fayyaz", ""], ["Asif", "Amina", ""], ["Ben-Hur", "Asa", ""]]}, {"id": "1901.01696", "submitter": "Ting Li", "authors": "Ting Li, Ningchen Ying, Xianshi Yu, Bin-Yi Jing", "title": "Semi-supervised learning in unbalanced and heterogeneous networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection was a hot topic on network analysis, where the main aim\nis to perform unsupervised learning or clustering in networks. Recently,\nsemi-supervised learning has received increasing attention among researchers.\nIn this paper, we propose a new algorithm, called weighted inverse Laplacian\n(WIL), for predicting labels in partially labeled networks. The idea comes from\nthe first hitting time in random walk, and it also has nice explanations both\nin information propagation and the regularization framework. We propose a\npartially labeled degree-corrected block model (pDCBM) to describe the\ngeneration of partially labeled networks. We show that WIL ensures the\nmisclassification rate is of order $O(\\frac{1}{d})$ for the pDCBM with average\ndegree $d=\\Omega(\\log n),$ and that it can handle situations with greater\nunbalanced than traditional Laplacian methods. WIL outperforms other\nstate-of-the-art methods in most of our simulations and real datasets,\nespecially in unbalanced networks and heterogeneous networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 08:06:36 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Li", "Ting", ""], ["Ying", "Ningchen", ""], ["Yu", "Xianshi", ""], ["Jing", "Bin-Yi", ""]]}, {"id": "1901.01706", "submitter": "Jong Chul Ye", "authors": "Shujaat Khan, Jaeyoung Huh, Jong Chul Ye", "title": "Universal Deep Beamformer for Variable Rate Ultrasound Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) imaging is based on the time-reversal principle, in which\nindividual channel RF measurements are back-propagated and accumulated to form\nan image after applying specific delays. While this time reversal is usually\nimplemented as a delay-and-sum (DAS) beamformer, the image quality quickly\ndegrades as the number of measurement channels decreases. To address this\nproblem, various types of adaptive beamforming techniques have been proposed\nusing predefined models of the signals. However, the performance of these\nadaptive beamforming approaches degrade when the underlying model is not\nsufficiently accurate. Here, we demonstrate for the first time that a single\nuniversal deep beamformer trained using a purely data-driven way can generate\nsignificantly improved images over widely varying aperture and channel\nsubsampling patterns. In particular, we design an end-to-end deep learning\nframework that can directly process sub-sampled RF data acquired at different\nsubsampling rate and detector configuration to generate high quality ultrasound\nimages using a single beamformer. Experimental results using B-mode focused\nultrasound confirm the efficacy of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 08:52:02 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1901.01727", "submitter": "Wil Ward", "authors": "Wil O C Ward and Mauricio A \\'Alvarez", "title": "Variational bridge constructs for approximate Gaussian process\n  regression", "comments": "4 pages, presented at BNP@NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method to approximate Gaussian process regression by\nrepresenting the problem as a stochastic differential equation and using\nvariational inference to approximate solutions. The approximations are compared\nwith full GP regression and generated paths are demonstrated to be\nindistinguishable from GP samples. We show that the approach extends easily to\nnon-linear dynamics and discuss extensions to which the approach can be easily\napplied.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 09:49:07 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ward", "Wil O C", ""], ["\u00c1lvarez", "Mauricio A", ""]]}, {"id": "1901.01751", "submitter": "Adriano Koshiyama", "authors": "Adriano Koshiyama and Nick Firoozye and Philip Treleaven", "title": "Generative Adversarial Networks for Financial Trading Strategies\n  Fine-Tuning and Combination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic trading strategies are algorithmic procedures that allocate assets\naiming to optimize a certain performance criterion. To obtain an edge in a\nhighly competitive environment, the analyst needs to proper fine-tune its\nstrategy, or discover how to combine weak signals in novel alpha creating\nmanners. Both aspects, namely fine-tuning and combination, have been\nextensively researched using several methods, but emerging techniques such as\nGenerative Adversarial Networks can have an impact into such aspects.\nTherefore, our work proposes the use of Conditional Generative Adversarial\nNetworks (cGANs) for trading strategies calibration and aggregation. To this\npurpose, we provide a full methodology on: (i) the training and selection of a\ncGAN for time series data; (ii) how each sample is used for strategies\ncalibration; and (iii) how all generated samples can be used for ensemble\nmodelling. To provide evidence that our approach is well grounded, we have\ndesigned an experiment with multiple trading strategies, encompassing 579\nassets. We compared cGAN with an ensemble scheme and model validation methods,\nboth suited for time series. Our results suggest that cGANs are a suitable\nalternative for strategies calibration and combination, providing\noutperformance when the traditional techniques fail to generate any alpha.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 11:19:31 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 22:57:18 GMT"}, {"version": "v3", "created": "Sat, 30 Mar 2019 14:19:01 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Koshiyama", "Adriano", ""], ["Firoozye", "Nick", ""], ["Treleaven", "Philip", ""]]}, {"id": "1901.01754", "submitter": "Haroldo Ribeiro", "authors": "H. Y. D. Sigaki, R. F. de Souza, R. T. de Souza, R. S. Zola, H. V.\n  Ribeiro", "title": "Estimating physical properties from liquid crystal textures via machine\n  learning and complexity-entropy methods", "comments": "11 two-column pages, 7 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 99, 013311 (2019)", "doi": "10.1103/PhysRevE.99.013311", "report-no": null, "categories": "physics.data-an cond-mat.stat-mech physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging techniques are essential tools for inquiring a number of properties\nfrom different materials. Liquid crystals are often investigated via optical\nand image processing methods. In spite of that, considerably less attention has\nbeen paid to the problem of extracting physical properties of liquid crystals\ndirectly from textures images of these materials. Here we present an approach\nthat combines two physics-inspired image quantifiers (permutation entropy and\nstatistical complexity) with machine learning techniques for extracting\nphysical properties of nematic and cholesteric liquid crystals directly from\ntheir textures images. We demonstrate the usefulness and accuracy of our\napproach in a series of applications involving simulated and experimental\ntextures, in which physical properties of these materials (namely: average\norder parameter, sample temperature, and cholesteric pitch length) are\npredicted with significant precision. Finally, we believe our approach can be\nuseful in more complex liquid crystal experiments as well as for probing\nphysical properties of other materials that are investigated via imaging\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 11:32:36 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Sigaki", "H. Y. D.", ""], ["de Souza", "R. F.", ""], ["de Souza", "R. T.", ""], ["Zola", "R. S.", ""], ["Ribeiro", "H. V.", ""]]}, {"id": "1901.01761", "submitter": "Th\\'eophane  Weber", "authors": "Th\\'eophane Weber, Nicolas Heess, Lars Buesing, David Silver", "title": "Credit Assignment Techniques in Stochastic Computation Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic computation graphs (SCGs) provide a formalism to represent\nstructured optimization problems arising in artificial intelligence, including\nsupervised, unsupervised, and reinforcement learning. Previous work has shown\nthat an unbiased estimator of the gradient of the expected loss of SCGs can be\nderived from a single principle. However, this estimator often has high\nvariance and requires a full model evaluation per data point, making this\nalgorithm costly in large graphs. In this work, we address these problems by\ngeneralizing concepts from the reinforcement learning literature. We introduce\nthe concepts of value functions, baselines and critics for arbitrary SCGs, and\nshow how to use them to derive lower-variance gradient estimates from partial\nmodel evaluations, paving the way towards general and efficient credit\nassignment for gradient-based optimization. In doing so, we demonstrate how our\nresults unify recent advances in the probabilistic inference and reinforcement\nlearning literature.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 11:58:41 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Weber", "Th\u00e9ophane", ""], ["Heess", "Nicolas", ""], ["Buesing", "Lars", ""], ["Silver", "David", ""]]}, {"id": "1901.01774", "submitter": "Guangliang Gao", "authors": "Guangliang Gao, Zhifeng Bao, Jie Cao, A. K. Qin, Timos Sellis, Fellow,\n  IEEE, Zhiang Wu", "title": "Location-Centered House Price Prediction: A Multi-Task Learning Approach", "comments": "Submitted to IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate house prediction is of great significance to various real estate\nstakeholders such as house owners, buyers, investors, and agents. We propose a\nlocation-centered prediction framework that differs from existing work in terms\nof data profiling and prediction model. Regarding data profiling, we define and\ncapture a fine-grained location profile powered by a diverse range of location\ndata sources, such as transportation profile (e.g., distance to nearest train\nstation), education profile (e.g., school zones and ranking), suburb profile\nbased on census data, facility profile (e.g., nearby hospitals, supermarkets).\nRegarding the choice of prediction model, we observe that a variety of\napproaches either consider the entire house data for modeling, or split the\nentire data and model each partition independently. However, such modeling\nignores the relatedness between partitions, and for all prediction scenarios,\nthere may not be sufficient training samples per partition for the latter\napproach. We address this problem by conducting a careful study of exploiting\nthe Multi-Task Learning (MTL) model. Specifically, we map the strategies for\nsplitting the entire house data to the ways the tasks are defined in MTL, and\neach partition obtained is aligned with a task. Furthermore, we select specific\nMTL-based methods with different regularization terms to capture and exploit\nthe relatedness between tasks. Based on real-world house transaction data\ncollected in Melbourne, Australia. We design extensive experimental\nevaluations, and the results indicate a significant superiority of MTL-based\nmethods over state-of-the-art approaches. Meanwhile, we conduct an in-depth\nanalysis on the impact of task definitions and method selections in MTL on the\nprediction performance, and demonstrate that the impact of task definitions on\nprediction performance far exceeds that of method selections.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 12:36:57 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Gao", "Guangliang", ""], ["Bao", "Zhifeng", ""], ["Cao", "Jie", ""], ["Qin", "A. K.", ""], ["Sellis", "Timos", ""], ["Fellow", "", ""], ["IEEE", "", ""], ["Wu", "Zhiang", ""]]}, {"id": "1901.01777", "submitter": "Matthijs Warrens", "authors": "Matthijs J. Warrens and Hanneke van der Hoef", "title": "Understanding partition comparison indices based on counting object\n  pairs", "comments": "29 pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised machine learning, agreement between partitions is commonly\nassessed with so-called external validity indices. Researchers tend to use and\nreport indices that quantify agreement between two partitions for all clusters\nsimultaneously. Commonly used examples are the Rand index and the adjusted Rand\nindex. Since these overall measures give a general notion of what is going on,\ntheir values are usually hard to interpret.\n  Three families of indices based on counting object pairs are analyzed. It is\nshown that the overall indices can be decomposed into indices that reflect the\ndegree of agreement on the level of individual clusters. The overall indices\nbased on the pair-counting approach are sensitive to cluster size imbalance:\nthey tend to reflect the degree of agreement on the large clusters and provide\nlittle to no information on smaller clusters. Furthermore, the value of\nRand-like indices is determined to a large extent by the number of pairs of\nobjects that are not joined in either of the partitions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 12:40:51 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Warrens", "Matthijs J.", ""], ["van der Hoef", "Hanneke", ""]]}, {"id": "1901.01798", "submitter": "Jian Vora", "authors": "Jian Vora", "title": "Stochastic Approximation Algorithms for Principal Component Analysis", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis is a novel way of of dimensionality reduction.\nThis problem essentially boils down to finding the top k eigen vectors of the\ndata covariance matrix. A considerable amount of literature is found on\nalgorithms meant to do so such as an online method be Warmuth and Kuzmin,\nMatrix Stochastic Gradient by Arora, Oja's method and many others. In this\npaper we see some of these stochastic approaches to the PCA optimization\nproblem and comment on their convergence and runtime to obtain an epsilon\nsub-optimal solution. We revisit convex relaxation based methods for stochastic\noptimization of principal component analysis. While methods that directly solve\nthe non convex problem have been shown to be optimal in terms of statistical\nand computational efficiency, the methods based on convex relaxation have been\nshown to enjoy comparable, or even superior, empirical performance. This\nmotivates the need for a deeper formal understanding of the latter.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 13:40:55 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Vora", "Jian", ""]]}, {"id": "1901.01808", "submitter": "Steven Kommrusch", "authors": "Zimin Chen and Steve Kommrusch and Michele Tufano and Louis-No\\\"el\n  Pouchet and Denys Poshyvanyk and Martin Monperrus", "title": "SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair", "comments": "21 pages, 15 figures", "journal-ref": "IEEE Transactions on Software Engineering, 2019", "doi": "10.1109/TSE.2019.2940179", "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel end-to-end approach to program repair based on\nsequence-to-sequence learning. We devise, implement, and evaluate a system,\ncalled SequenceR, for fixing bugs based on sequence-to-sequence learning on\nsource code. This approach uses the copy mechanism to overcome the unlimited\nvocabulary problem that occurs with big code. Our system is data-driven; we\ntrain it on 35,578 samples, carefully curated from commits to open-source\nrepositories. We evaluate it on 4,711 independent real bug fixes, as well on\nthe Defects4J benchmark used in program repair research. SequenceR is able to\nperfectly predict the fixed line for 950/4711 testing samples, and find correct\npatches for 14 bugs in Defects4J. It captures a wide range of repair operators\nwithout any domain-specific top-down design.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 18:04:14 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 05:19:29 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 06:21:27 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Chen", "Zimin", ""], ["Kommrusch", "Steve", ""], ["Tufano", "Michele", ""], ["Pouchet", "Louis-No\u00ebl", ""], ["Poshyvanyk", "Denys", ""], ["Monperrus", "Martin", ""]]}, {"id": "1901.01837", "submitter": "Karl-Heinz Zimmermann", "authors": "Robert Leppert, Karl-Heinz Zimmermann", "title": "Inference in Graded Bayesian Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning provides algorithms that can learn from data and make\ninferences or predictions on data. Bayesian networks are a class of graphical\nmodels that allow to represent a collection of random variables and their\ncondititional dependencies by directed acyclic graphs. In this paper, an\ninference algorithm for the hidden random variables of a Bayesian network is\ngiven by using the tropicalization of the marginal distribution of the observed\nvariables. By restricting the topological structure to graded networks, an\ninference algorithm for graded Bayesian networks will be established that\nevaluates the hidden random variables rank by rank and in this way yields the\nmost probable states of the hidden variables. This algorithm can be viewed as a\ngeneralized version of the Viterbi algorithm for graded Bayesian networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 10:58:04 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Leppert", "Robert", ""], ["Zimmermann", "Karl-Heinz", ""]]}, {"id": "1901.01860", "submitter": "Sean Yang", "authors": "Sean T. Yang, Kuan-Hao Huang, and Bill Howe", "title": "JECL: Joint Embedding and Cluster Learning for Image-Text Pairs", "comments": "ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose JECL, a method for clustering image-caption pairs by training\nparallel encoders with regularized clustering and alignment objectives,\nsimultaneously learning both representations and cluster assignments. These\nimage-caption pairs arise frequently in high-value applications where\nstructured training data is expensive to produce, but free-text descriptions\nare common. JECL trains by minimizing the Kullback-Leibler divergence between\nthe distribution of the images and text to that of a combined joint target\ndistribution and optimizing the Jensen-Shannon divergence between the soft\ncluster assignments of the images and text. Regularizers are also applied to\nJECL to prevent trivial solutions. Experiments show that JECL outperforms both\nsingle-view and multi-view methods on large benchmark image-caption datasets,\nand is remarkably robust to missing captions and varying data sizes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 18:14:37 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 03:52:01 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 22:19:04 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yang", "Sean T.", ""], ["Huang", "Kuan-Hao", ""], ["Howe", "Bill", ""]]}, {"id": "1901.01960", "submitter": "Cagla Deniz Bahadir", "authors": "Cagla Deniz Bahadir, Adrian V. Dalca and Mert R. Sabuncu", "title": "Learning-based Optimization of the Under-sampling Pattern in MRI", "comments": "13 pages, 5 figures, Accepted as a conference paper in IPMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquisition of Magnetic Resonance Imaging (MRI) scans can be accelerated by\nunder-sampling in k-space (i.e., the Fourier domain). In this paper, we\nconsider the problem of optimizing the sub-sampling pattern in a data-driven\nfashion. Since the reconstruction model's performance depends on the\nsub-sampling pattern, we combine the two problems. For a given sparsity\nconstraint, our method optimizes the sub-sampling pattern and reconstruction\nmodel, using an end-to-end learning strategy. Our algorithm learns from\nfull-resolution data that are under-sampled retrospectively, yielding a\nsub-sampling pattern and reconstruction model that are customized to the type\nof images represented in the training data. The proposed method, which we call\nLOUPE (Learning-based Optimization of the Under-sampling PattErn), was\nimplemented by modifying a U-Net, a widely-used convolutional neural network\narchitecture, that we append with the forward model that encodes the\nunder-sampling process. Our experiments with T1-weighted structural brain MRI\nscans show that the optimized sub-sampling pattern can yield significantly more\naccurate reconstructions compared to standard random uniform, variable density\nor equispaced under-sampling schemes. The code is made available at:\nhttps://github.com/cagladbahadir/LOUPE .\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 18:30:51 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 20:54:30 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Bahadir", "Cagla Deniz", ""], ["Dalca", "Adrian V.", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1901.01977", "submitter": "Lantao Liu", "authors": "Shoubhik Debnath, Gaurav Sukhatme, Lantao Liu", "title": "Accelerating Goal-Directed Reinforcement Learning by Model\n  Characterization", "comments": "The paper was published in 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid approach aimed at improving the sample efficiency in\ngoal-directed reinforcement learning. We do this via a two-step mechanism where\nfirstly, we approximate a model from Model-Free reinforcement learning. Then,\nwe leverage this approximate model along with a notion of reachability using\nMean First Passage Times to perform Model-Based reinforcement learning. Built\non such a novel observation, we design two new algorithms - Mean First Passage\nTime based Q-Learning (MFPT-Q) and Mean First Passage Time based DYNA\n(MFPT-DYNA), that have been fundamentally modified from the state-of-the-art\nreinforcement learning techniques. Preliminary results have shown that our\nhybrid approaches converge with much fewer iterations than their corresponding\nstate-of-the-art counterparts and therefore requiring much fewer samples and\nmuch fewer training trials to converge.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 19:04:37 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Debnath", "Shoubhik", ""], ["Sukhatme", "Gaurav", ""], ["Liu", "Lantao", ""]]}, {"id": "1901.01985", "submitter": "Ming Dong", "authors": "Ming Dong", "title": "Combining Unsupervised and Supervised Learning for Asset Class Failure\n  Prediction in Power Systems", "comments": "8 pages, 3 figures", "journal-ref": "IEEE Trans. on Power Systems, 2019", "doi": "10.1109/TPWRS.2019.2920915", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In power systems, an asset class is a group of power equipment that has the\nsame function and shares similar electrical or mechanical characteristics.\nPredicting failures for different asset classes is critical for electric\nutilities towards developing cost-effective asset management strategies.\nPreviously, physical age based Weibull distribution has been widely used to\nfailure prediction. However, this mathematical model cannot incorporate asset\ncondition data such as inspection or testing results. As a result, the\nprediction cannot be very specific and accurate for individual assets. To solve\nthis important problem, this paper proposes a novel and comprehensive\ndata-driven approach based on asset condition data: K-means clustering as an\nunsupervised learning method is used to analyze the inner structure of\nhistorical asset condition data and produce the asset conditional ages;\nlogistic regression as a supervised learning method takes in both asset\nphysical ages and conditional ages to classify and predict asset statuses.\nFurthermore, an index called average aging rate is defined to quantify, track\nand estimate the relationship between asset physical age and conditional age.\nThis approach was applied to an urban distribution system in West Canada to\npredict medium-voltage cable failures. Case studies and comparison with\nstandard Weibull distribution are provided. The proposed approach demonstrates\nsuperior performance and practicality for predicting asset class failures in\npower systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 03:44:20 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 04:27:19 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dong", "Ming", ""]]}, {"id": "1901.01986", "submitter": "Donghyeon Han", "authors": "Donghyeon Han, Hoi-jun Yoo", "title": "Efficient Convolutional Neural Network Training with Direct Feedback\n  Alignment", "comments": "The paper was submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There were many algorithms to substitute the back-propagation (BP) in the\ndeep neural network (DNN) training. However, they could not become popular\nbecause their training accuracy and the computational efficiency were worse\nthan BP. One of them was direct feedback alignment (DFA), but it showed low\ntraining performance especially for the convolutional neural network (CNN). In\nthis paper, we overcome the limitation of the DFA algorithm by combining with\nthe conventional BP during the CNN training. To improve the training stability,\nwe also suggest the feedback weight initialization method by analyzing the\npatterns of the fixed random matrices in the DFA. Finally, we propose the new\ntraining algorithm, binary direct feedback alignment (BDFA) to minimize the\ncomputational cost while maintaining the training accuracy compared with the\nDFA. In our experiments, we use the CIFAR-10 and CIFAR-100 dataset to simulate\nthe CNN learning from the scratch and apply the BDFA to the online learning\nbased object tracking application to examine the training in the small dataset\nenvironment. Our proposed algorithms show better performance than conventional\nBP in both two different training tasks especially when the dataset is small.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 04:36:38 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Han", "Donghyeon", ""], ["Yoo", "Hoi-jun", ""]]}, {"id": "1901.01994", "submitter": "Vincent Liu", "authors": "Vincent Liu, Ademi Adeniji, Nathaniel Lee, Jason Zhao, Mario Srouji", "title": "Recurrent Control Nets for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central Pattern Generators (CPGs) are biological neural circuits capable of\nproducing coordinated rhythmic outputs in the absence of rhythmic input. As a\nresult, they are responsible for most rhythmic motion in living organisms. This\nrhythmic control is broadly applicable to fields such as locomotive robotics\nand medical devices. In this paper, we explore the possibility of creating a\nself-sustaining CPG network for reinforcement learning that learns rhythmic\nmotion more efficiently and across more general environments than the current\nmultilayer perceptron (MLP) baseline models. Recent work introduces the\nStructured Control Net (SCN), which maintains linear and nonlinear modules for\nlocal and global control, respectively. Here, we show that time-sequence\narchitectures such as Recurrent Neural Networks (RNNs) model CPGs effectively.\nCombining previous work with RNNs and SCNs, we introduce the Recurrent Control\nNet (RCN), which adds a linear component to the, RCNs match and exceed the\nperformance of baseline MLPs and SCNs across all environment tasks. Our\nfindings confirm existing intuitions for RNNs on reinforcement learning tasks,\nand demonstrate promise of SCN-like structures in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 23:35:07 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 03:24:29 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Liu", "Vincent", ""], ["Adeniji", "Ademi", ""], ["Lee", "Nathaniel", ""], ["Zhao", "Jason", ""], ["Srouji", "Mario", ""]]}, {"id": "1901.01995", "submitter": "Zhiyi Tang", "authors": "Yuequan Bao, Zhiyi Tang, Hui Li", "title": "Compressive-Sensing Data Reconstruction for Structural Health\n  Monitoring: A Machine-Learning Approach", "comments": "14 pages, 9 figures, submitted to Structural Health Monitoring\n  (https://journals.sagepub.com/home/shm)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) has been studied and applied in structural health\nmonitoring for wireless data acquisition and transmission, structural modal\nidentification, and spare damage identification. The key issue in CS is finding\nthe optimal solution for sparse optimization. In the past years, many\nalgorithms have been proposed in the field of applied mathematics. In this\npaper, we propose a machine-learning-based approach to solve the CS\ndata-reconstruction problem. By treating a computation process as a data flow,\nthe process of CS-based data reconstruction is formalized into a standard\nsupervised-learning task. The prior knowledge, i.e., the basis matrix and the\nCS-sampled signals, are used as the input and the target of the network; the\nbasis coefficient matrix is embedded as the parameters of a certain layer; the\nobjective function of conventional compressive sensing is set as the loss\nfunction of the network. Regularized by l1-norm, these basis coefficients are\noptimized to reduce the error between the original CS-sampled signals and the\nmasked reconstructed signals with a common optimization algorithm. Also, the\nproposed network can handle complex bases, such as a Fourier basis. Benefiting\nfrom the nature of a multi-neuron layer, multiple signal channels can be\nreconstructed simultaneously. Meanwhile, the disassembled use of a large-scale\nbasis makes the method memory-efficient. A numerical example of multiple\nsinusoidal waves and an example of field-test wireless data from a suspension\nbridge are carried out to illustrate the data-reconstruction ability of the\nproposed approach. The results show that high reconstruction accuracy can be\nobtained by the machine learning-based approach. Also, the parameters of the\nnetwork have clear meanings; the inference of the mapping between input and\noutput is fully transparent, making the CS data reconstruction neural network\ninterpretable.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 01:26:27 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 07:02:53 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Bao", "Yuequan", ""], ["Tang", "Zhiyi", ""], ["Li", "Hui", ""]]}, {"id": "1901.02001", "submitter": "Mohsen Ahmadi Fahandar", "authors": "Mohsen Ahmadi Fahandar, Eyke H\\\"ullermeier", "title": "Analogy-Based Preference Learning with Kernels", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.10207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on a specific formalization of analogical relationships of the form\n\"A relates to B as C relates to D\", we establish a connection between two\nimportant subfields of artificial intelligence, namely analogical reasoning and\nkernel-based machine learning. More specifically, we show that so-called\nanalogical proportions are closely connected to kernel functions on pairs of\nobjects. Based on this result, we introduce the analogy kernel, which can be\nseen as a measure of how strongly four objects are in analogical relationship.\nAs an application, we consider the problem of object ranking in the realm of\npreference learning, for which we develop a new method based on support vector\nmachines trained with the analogy kernel. Our first experimental results for\ndata sets from different domains (sports, education, tourism, etc.) are\npromising and suggest that our approach is competitive to state-of-the-art\nalgorithms in terms of predictive accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 11:23:12 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Fahandar", "Mohsen Ahmadi", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1901.02045", "submitter": "Virag Shah", "authors": "Virag Shah, Jose Blanchet, Ramesh Johari", "title": "Semi-parametric dynamic contextual pricing", "comments": "28 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the application of real-time pricing in e-commerce platforms, we\nconsider the problem of revenue-maximization in a setting where the seller can\nleverage contextual information describing the customer's history and the\nproduct's type to predict her valuation of the product. However, her true\nvaluation is unobservable to the seller, only binary outcome in the form of\nsuccess-failure of a transaction is observed. Unlike in usual contextual bandit\nsettings, the optimal price/arm given a covariate in our setting is sensitive\nto the detailed characteristics of the residual uncertainty distribution. We\ndevelop a semi-parametric model in which the residual distribution is\nnon-parametric and provide the first algorithm which learns both regression\nparameters and residual distribution with $\\tilde O(\\sqrt{n})$ regret. We\nempirically test a scalable implementation of our algorithm and observe good\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 20:07:16 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 17:44:43 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 19:19:32 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 01:59:09 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Shah", "Virag", ""], ["Blanchet", "Jose", ""], ["Johari", "Ramesh", ""]]}, {"id": "1901.02046", "submitter": "Hui Jiang", "authors": "Hui Jiang", "title": "A New Perspective on Machine Learning: How to do Perfect Supervised\n  Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce the concept of bandlimiting into the theory of\nmachine learning because all physical processes are bandlimited by nature,\nincluding real-world machine learning tasks. After the bandlimiting constraint\nis taken into account, our theoretical analysis has shown that all practical\nmachine learning tasks are asymptotically solvable in a perfect sense.\nFurthermore, the key towards this solvability almost solely relies on two\nfactors: i) a sufficiently large amount of training samples beyond a threshold\ndetermined by a difficulty measurement of the underlying task; ii) a\nsufficiently complex and bandlimited model. Moreover, for some special cases,\nwe have derived new error bounds for perfect learning, which can quantify the\ndifficulty of learning. These generalization bounds are not only asymptotically\nconvergent but also irrelevant to model complexity. Our new results on\ngeneralization have provided a new perspective to explain the recent successes\nof large-scale supervised learning using complex models like neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 20:10:55 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 21:15:29 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 16:40:02 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Jiang", "Hui", ""]]}, {"id": "1901.02051", "submitter": "Jasper Snoek", "authors": "Zelda Mariet, Yaniv Ovadia, Jasper Snoek", "title": "DPPNet: Approximating Determinantal Point Processes with Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal Point Processes (DPPs) provide an elegant and versatile way to\nsample sets of items that balance the point-wise quality with the set-wise\ndiversity of selected items. For this reason, they have gained prominence in\nmany machine learning applications that rely on subset selection. However,\nsampling from a DPP over a ground set of size $N$ is a costly operation,\nrequiring in general an $O(N^3)$ preprocessing cost and an $O(Nk^3)$ sampling\ncost for subsets of size $k$. We approach this problem by introducing DPPNets:\ngenerative deep models that produce DPP-like samples for arbitrary ground sets.\nWe develop an inhibitive attention mechanism based on transformer networks that\ncaptures a notion of dissimilarity between feature vectors. We show\ntheoretically that such an approximation is sensible as it maintains the\nguarantees of inhibition or dissimilarity that makes DPPs so powerful and\nunique. Empirically, we demonstrate that samples from our model receive high\nlikelihood under the more expensive DPP alternative.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 20:42:13 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Mariet", "Zelda", ""], ["Ovadia", "Yaniv", ""], ["Snoek", "Jasper", ""]]}, {"id": "1901.02052", "submitter": "Honghui Du", "authors": "Honghui Du, Leandro L. Minku, Huiyu Zhou", "title": "Multi-Source Transfer Learning for Non-Stationary Environments", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852024", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data stream mining, predictive models typically suffer drops in predictive\nperformance due to concept drift. As enough data representing the new concept\nmust be collected for the new concept to be well learnt, the predictive\nperformance of existing models usually takes some time to recover from concept\ndrift. To speed up recovery from concept drift and improve predictive\nperformance in data stream mining, this work proposes a novel approach called\nMulti-sourcE onLine TrAnsfer learning for Non-statIonary Environments\n(Melanie). Melanie is the first approach able to transfer knowledge between\nmultiple data streaming sources in non-stationary environments. It creates\nseveral sub-classifiers to learn different aspects from different source and\ntarget concepts over time. The sub-classifiers that match the current target\nconcept well are identified, and used to compose an ensemble for predicting\nexamples from the target concept. We evaluate Melanie on several synthetic data\nstreams containing different types of concept drift and on real world data\nstreams. The results indicate that Melanie can deal with a variety drifts and\nimprove predictive performance over existing data stream learning algorithms by\nmaking use of multiple sources.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 20:55:02 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:49:57 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Du", "Honghui", ""], ["Minku", "Leandro L.", ""], ["Zhou", "Huiyu", ""]]}, {"id": "1901.02056", "submitter": "Hideo Hirose", "authors": "Hideo Hirose", "title": "Prediction of Success or Failure for Final Examination using Nearest\n  Neighbor Method to the Trend of Weekly Online Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the trends of estimated abilities in terms of item response theory for\nonline testing, we can predict the success/failure status for the final\nexamination to each student at early stages in courses. In prediction, we\napplied the newly developed nearest neighbor method for determining the\nsimilarity of learning skill in the trends of estimated abilities, resulting a\nbetter prediction accuracy for success or failure. This paper shows that the\nuse of the learning analytics incorporating the trends for abilities is\neffective. ROC curve and recall precision curve are informative to assist the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 01:00:41 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Hirose", "Hideo", ""]]}, {"id": "1901.02057", "submitter": "Ma Guijun", "authors": "Ye Yuan, Guijun Ma, Cheng Cheng, Beitong Zhou, Huan Zhao, Hai-Tao\n  Zhang, Han Ding", "title": "Artificial Intelligent Diagnosis and Monitoring in Manufacturing", "comments": null, "journal-ref": null, "doi": "10.1093/nsr/nwz190", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manufacturing sector is heavily influenced by artificial\nintelligence-based technologies with the extraordinary increases in\ncomputational power and data volumes. It has been reported that 35% of US\nmanufacturers are currently collecting data from sensors for manufacturing\nprocesses enhancement. Nevertheless, many are still struggling to achieve the\n'Industry 4.0', which aims to achieve nearly 50% reduction in maintenance cost\nand total machine downtime by proper health management. For increasing\nproductivity and reducing operating costs, a central challenge lies in the\ndetection of faults or wearing parts in machining operations. Here we propose a\ndata-driven, end-to-end framework for monitoring of manufacturing systems. This\nframework, derived from deep learning techniques, evaluates fused sensory\nmeasurements to detect and even predict faults and wearing conditions. This\nwork exploits the predictive power of deep learning to extract hidden\ndegradation features from noisy data. We demonstrate the proposed framework on\nseveral representative experimental manufacturing datasets drawn from a wide\nvariety of applications, ranging from mechanical to electrical systems. Results\nreveal that the framework performs well in all benchmark applications examined\nand can be applied in diverse contexts, indicating its potential for use as a\ncritical corner stone in smart manufacturing.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 02:07:23 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yuan", "Ye", ""], ["Ma", "Guijun", ""], ["Cheng", "Cheng", ""], ["Zhou", "Beitong", ""], ["Zhao", "Huan", ""], ["Zhang", "Hai-Tao", ""], ["Ding", "Han", ""]]}, {"id": "1901.02063", "submitter": "Morteza Haghir Chehreghani", "authors": "Morteza Haghir Chehreghani", "title": "Reliable Agglomerative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the general behavior of agglomerative clustering methods, and\nargue that their strategy yields establishment of a new reliable linkage at\neach step. However, in order to provide adaptive, density-consistent and\nflexible solutions, we propose to extract all the reliable linkages at each\nstep, instead of the smallest one. This leads to a new agglomerative clustering\nstrategy, called reliable agglomerative clustering, which similar to the\nstandard agglomerative variant can be applied with all common criteria.\nMoreover, we prove that this strategy with the single linkage criterion yields\na minimum spanning tree algorithm. We perform experiments on several real-world\ndatasets to demonstrate the superior performance of this strategy, compared to\nthe standard alternative.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:01:05 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 14:34:46 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 13:10:29 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 21:49:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1901.02064", "submitter": "Xue Geng", "authors": "Xue Geng, Jie Fu, Bin Zhao, Jie Lin, Mohamed M. Sabry Aly, Christopher\n  Pal and Vijay Chandrasekhar", "title": "Dataflow-based Joint Quantization of Weights and Activations for Deep\n  Neural Networks", "comments": null, "journal-ref": "Data Compression Conference 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a challenging problem - how to reduce energy consumption\nwithout incurring performance drop when deploying deep neural networks (DNNs)\nat the inference stage. In order to alleviate the computation and storage\nburdens, we propose a novel dataflow-based joint quantization approach with the\nhypothesis that a fewer number of quantization operations would incur less\ninformation loss and thus improve the final performance. It first introduces a\nquantization scheme with efficient bit-shifting and rounding operations to\nrepresent network parameters and activations in low precision. Then it\nrestructures the network architectures to form unified modules for optimization\non the quantized model. Extensive experiments on ImageNet and KITTI validate\nthe effectiveness of our model, demonstrating that state-of-the-art results for\nvarious tasks can be achieved by this quantized model. Besides, we designed and\nsynthesized an RTL model to measure the hardware costs among various\nquantization methods. For each quantization operation, it reduces area cost by\nabout 15 times and energy consumption by about 9 times, compared to a strong\nbaseline.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 08:12:55 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Geng", "Xue", ""], ["Fu", "Jie", ""], ["Zhao", "Bin", ""], ["Lin", "Jie", ""], ["Aly", "Mohamed M. Sabry", ""], ["Pal", "Christopher", ""], ["Chandrasekhar", "Vijay", ""]]}, {"id": "1901.02094", "submitter": "Jiahao Ding", "authors": "Jiahao Ding, Xiaoqi Qin, Wenjun Xu, Yanmin Gong, Chi Zhang and Miao\n  Pan", "title": "Differentially Private ADMM for Distributed Medical Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to massive amounts of data distributed across multiple locations,\ndistributed machine learning has attracted a lot of research interests.\nAlternating Direction Method of Multipliers (ADMM) is a powerful method of\ndesigning distributed machine learning algorithm, whereby each agent computes\nover local datasets and exchanges computation results with its neighbor agents\nin an iterative procedure. There exists significant privacy leakage during this\niterative process if the local data is sensitive. In this paper, we propose a\ndifferentially private ADMM algorithm (P-ADMM) to provide dynamic\nzero-concentrated differential privacy (dynamic zCDP), by inserting Gaussian\nnoise with linearly decaying variance. We prove that P-ADMM has the same\nconvergence rate compared to the non-private counterpart, i.e.,\n$\\mathcal{O}(1/K)$ with $K$ being the number of iterations and linear\nconvergence for general convex and strongly convex problems while providing\ndifferentially private guarantee. Moreover, through our experiments performed\non real-world datasets, we empirically show that P-ADMM has the best-known\nperformance among the existing differentially private ADMM based algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 23:00:01 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 19:05:12 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 16:46:18 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Ding", "Jiahao", ""], ["Qin", "Xiaoqi", ""], ["Xu", "Wenjun", ""], ["Gong", "Yanmin", ""], ["Zhang", "Chi", ""], ["Pan", "Miao", ""]]}, {"id": "1901.02103", "submitter": "Maxim Naumov", "authors": "Maxim Naumov", "title": "On the Dimensionality of Embeddings for Sparse Features and Data", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we discuss a common misconception, namely that embeddings are\nalways used to reduce the dimensionality of the item space. We show that when\nwe measure dimensionality in terms of information entropy then the embedding of\nsparse probability distributions, that can be used to represent sparse features\nor data, may or not reduce the dimensionality of the item space. However, the\nembeddings do provide a different and often more meaningful representation of\nthe items for a particular task at hand. Also, we give upper bounds and more\nprecise guidelines for choosing the embedding dimension.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 23:30:14 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Naumov", "Maxim", ""]]}, {"id": "1901.02104", "submitter": "Hanie Sedghi", "authors": "Philip M. Long and Hanie Sedghi", "title": "On the effect of the activation function on the distribution of hidden\n  nodes in a deep network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the joint probability distribution on the lengths of the vectors\nof hidden variables in different layers of a fully connected deep network, when\nthe weights and biases are chosen randomly according to Gaussian distributions,\nand the input is in $\\{ -1, 1\\}^N$. We show that, if the activation function\n$\\phi$ satisfies a minimal set of assumptions, satisfied by all activation\nfunctions that we know that are used in practice, then, as the width of the\nnetwork gets large, the `length process' converges in probability to a length\nmap that is determined as a simple function of the variances of the random\nweights and biases, and the activation function $\\phi$. We also show that this\nconvergence may fail for $\\phi$ that violate our assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 23:33:14 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Long", "Philip M.", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1901.02144", "submitter": "Abhishek Sehgal", "authors": "Abhishek Sehgal and Nasser Kehtarnavaz", "title": "Guidelines and Benchmarks for Deployment of Deep Learning Models on\n  Smartphones as Real-Time Apps", "comments": "10 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning solutions are being increasingly used in mobile applications.\nAlthough there are many open-source software tools for the development of deep\nlearning solutions, there are no guidelines in one place in a unified manner\nfor using these tools towards real-time deployment of these solutions on\nsmartphones. From the variety of available deep learning tools, the most suited\nones are used in this paper to enable real-time deployment of deep learning\ninference networks on smartphones. A uniform flow of implementation is devised\nfor both Android and iOS smartphones. The advantage of using multi-threading to\nachieve or improve real-time throughputs is also showcased. A benchmarking\nframework consisting of accuracy, CPU/GPU consumption and real-time throughput\nis considered for validation purposes. The developed deployment approach allows\ndeep learning models to be turned into real-time smartphone apps with ease\nbased on publicly available deep learning and smartphone software tools. This\napproach is applied to six popular or representative convolutional neural\nnetwork models and the validation results based on the benchmarking metrics are\nreported.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 03:32:31 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Sehgal", "Abhishek", ""], ["Kehtarnavaz", "Nasser", ""]]}, {"id": "1901.02153", "submitter": "Ahmet Cakmak Dr.", "authors": "Ahmet Faruk Cakmak and Muhammet Balcilar", "title": "Audio Captcha Recognition Using RastaPLP Features by SVM", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, CAPTCHAs are computer generated tests that human can pass but\ncurrent computer systems can not. They have common usage in various web\nservices in order to be able to detect a human from computer programs\nautonomously. In this way, owners can protect their web services from bots. In\naddition to visual CAPTCHAs which consist of distorted images, mostly test\nimages, that a user must write some description about that image, there are a\nsignificant amount of audio CAPTCHAs as well. Briefly, audio CAPTCHAs are sound\nfiles which consist of human sound under heavy noise where the speaker\npronounces a bunch of digits consecutively. Generally, in those sound files,\nthere are some periodic and non-periodic noises to get difficult to recognize\nthem with a program but not for a human listener. We gathered numerous randomly\ncollected audio file to train and then test them using our SVM algorithm to be\nable to extract digits out of each conversation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 04:44:37 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Cakmak", "Ahmet Faruk", ""], ["Balcilar", "Muhammet", ""]]}, {"id": "1901.02161", "submitter": "Daniel Brown", "authors": "Daniel S. Brown, Yuchen Cui, Scott Niekum", "title": "Risk-Aware Active Inverse Reinforcement Learning", "comments": "In proceedings of the 2nd Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning from demonstration allows a robot to query a human for\nspecific types of input to achieve efficient learning. Existing work has\nexplored a variety of active query strategies; however, to our knowledge, none\nof these strategies directly minimize the performance risk of the policy the\nrobot is learning. Utilizing recent advances in performance bounds for inverse\nreinforcement learning, we propose a risk-aware active inverse reinforcement\nlearning algorithm that focuses active queries on areas of the state space with\nthe potential for large generalization error. We show that risk-aware active\nlearning outperforms standard active IRL approaches on gridworld, simulated\ndriving, and table setting tasks, while also providing a performance-based\nstopping criterion that allows a robot to know when it has received enough\ndemonstrations to safely perform a task.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 05:23:03 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 20:46:56 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Brown", "Daniel S.", ""], ["Cui", "Yuchen", ""], ["Niekum", "Scott", ""]]}, {"id": "1901.02182", "submitter": "Talha Cihad Gulcu", "authors": "Talha Cihad Gulcu and Alper Gungor", "title": "Comments on \"Deep Neural Networks with Random Gaussian Weights: A\n  Universal Classification Strategy?\"", "comments": "We got many questions about how the angle between m_i^p and y could\n  be \\theta+\\angle(x,y) and that proof steps are not clear enough. We hope this\n  version clarifies the confusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recently published paper [1], it is shown that deep neural networks\n(DNNs) with random Gaussian weights preserve the metric structure of the data,\nwith the property that the distance shrinks more when the angle between the two\ndata points is smaller. We agree that the random projection setup considered in\n[1] preserves distances with a high probability. But as far as we are\nconcerned, the relation between the angle of the data points and the output\ndistances is quite the opposite, i.e., smaller angles result in a weaker\ndistance shrinkage. This leads us to conclude that Theorem 3 and Figure 5 in\n[1] are not accurate. Hence the usage of random Gaussian weights in DNNs cannot\nprovide an ability of universal classification or treating in-class and\nout-of-class data separately. Consequently, the behavior of networks consisting\nof random Gaussian weights only is not useful to explain how DNNs achieve\nstate-of-art results in a large variety of problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 07:20:34 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 17:18:21 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Gulcu", "Talha Cihad", ""], ["Gungor", "Alper", ""]]}, {"id": "1901.02185", "submitter": "Anh Pham The", "authors": "Anh T. Pham, Shalini Ghosh, Vinod Yegneswaran", "title": "Data Masking with Privacy Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICS/2019/04", "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of data release with privacy, where data is made\navailable with privacy guarantees while keeping the usability of the data as\nhigh as possible --- this is important in health-care and other domains with\nsensitive data. In particular, we propose a method of masking the private data\nwith privacy guarantee while ensuring that a classifier trained on the masked\ndata is similar to the classifier trained on the original data, to maintain\nusability. We analyze the theoretical risks of the proposed method and the\ntraditional input perturbation method. Results show that the proposed method\nachieves lower risk compared to the input perturbation, especially when the\nnumber of training samples gets large. We illustrate the effectiveness of the\nproposed method of data masking for privacy-sensitive learning on $12$\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 07:29:08 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Pham", "Anh T.", ""], ["Ghosh", "Shalini", ""], ["Yegneswaran", "Vinod", ""]]}, {"id": "1901.02199", "submitter": "Louis Clouatre", "authors": "Louis Clou\\^atre, Marc Demers", "title": "FIGR: Few-shot Image Generation with Reptile", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) boast impressive capacity to generate\nrealistic images. However, like much of the field of deep learning, they\nrequire an inordinate amount of data to produce results, thereby limiting their\nusefulness in generating novelty. In the same vein, recent advances in\nmeta-learning have opened the door to many few-shot learning applications. In\nthe present work, we propose Few-shot Image Generation using Reptile (FIGR), a\nGAN meta-trained with Reptile. Our model successfully generates novel images on\nboth MNIST and Omniglot with as little as 4 images from an unseen class. We\nfurther contribute FIGR-8, a new dataset for few-shot image generation, which\ncontains 1,548,944 icons categorized in over 18,409 classes. Trained on FIGR-8,\ninitial results show that our model can generalize to more advanced concepts\n(such as \"bird\" and \"knife\") from as few as 8 samples from a previously unseen\nclass of images and as little as 10 training steps through those 8 images. This\nwork demonstrates the potential of training a GAN for few-shot image generation\nand aims to set a new benchmark for future work in the domain.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 08:15:08 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Clou\u00e2tre", "Louis", ""], ["Demers", "Marc", ""]]}, {"id": "1901.02217", "submitter": "Song Cheng", "authors": "Song Cheng, Lei Wang, Tao Xiang, Pan Zhang", "title": "Tree Tensor Networks for Generative Modeling", "comments": null, "journal-ref": "Phys. Rev. B 99, 155131 (2019)", "doi": "10.1103/PhysRevB.99.155131", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix product states (MPS), a tensor network designed for one-dimensional\nquantum systems, has been recently proposed for generative modeling of natural\ndata (such as images) in terms of `Born machine'. However, the exponential\ndecay of correlation in MPS restricts its representation power heavily for\nmodeling complex data such as natural images. In this work, we push forward the\neffort of applying tensor networks to machine learning by employing the Tree\nTensor Network (TTN) which exhibits balanced performance in expressibility and\nefficient training and sampling. We design the tree tensor network to utilize\nthe 2-dimensional prior of the natural images and develop sweeping learning and\nsampling algorithms which can be efficiently implemented utilizing Graphical\nProcessing Units (GPU). We apply our model to random binary patterns and the\nbinary MNIST datasets of handwritten digits. We show that TTN is superior to\nMPS for generative modeling in keeping correlation of pixels in natural images,\nas well as giving better log-likelihood scores in standard datasets of\nhandwritten digits. We also compare its performance with state-of-the-art\ngenerative models such as the Variational AutoEncoders, Restricted Boltzmann\nmachines, and PixelCNN. Finally, we discuss the future development of Tensor\nNetwork States in machine learning problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 09:34:01 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Cheng", "Song", ""], ["Wang", "Lei", ""], ["Xiang", "Tao", ""], ["Zhang", "Pan", ""]]}, {"id": "1901.02219", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier, Thomas Gabor, Thomy Phan, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Uncertainty-Based Out-of-Distribution Detection in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting out-of-distribution (OOD) samples in\ndeep reinforcement learning. In a value based reinforcement learning setting,\nwe propose to use uncertainty estimation techniques directly on the agent's\nvalue estimating neural network to detect OOD samples. The focus of our work\nlies in analyzing the suitability of approximate Bayesian inference methods and\nrelated ensembling techniques that generate uncertainty estimates. Although\nprior work has shown that dropout-based variational inference techniques and\nbootstrap-based approaches can be used to model epistemic uncertainty, the\nsuitability for detecting OOD samples in deep reinforcement learning remains an\nopen question. Our results show that uncertainty estimation can be used to\ndifferentiate in- from out-of-distribution samples. Over the complete training\nprocess of the reinforcement learning agents, bootstrap-based approaches tend\nto produce more reliable epistemic uncertainty estimates, when compared to\ndropout-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 09:41:11 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["Gabor", "Thomas", ""], ["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1901.02220", "submitter": "Dmytro Perekrestenko", "authors": "Dennis Elbr\\\"achter, Dmytro Perekrestenko, Philipp Grohs, and Helmut\n  B\\\"olcskei", "title": "Deep Neural Network Approximation Theory", "comments": "minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops fundamental limits of deep neural network learning by\ncharacterizing what is possible if no constraints are imposed on the learning\nalgorithm and on the amount of training data. Concretely, we consider\nKolmogorov-optimal approximation through deep neural networks with the guiding\ntheme being a relation between the complexity of the function (class) to be\napproximated and the complexity of the approximating network in terms of\nconnectivity and memory requirements for storing the network topology and the\nassociated quantized weights. The theory we develop establishes that deep\nnetworks are Kolmogorov-optimal approximants for markedly different function\nclasses, such as unit balls in Besov spaces and modulation spaces. In addition,\ndeep networks provide exponential approximation accuracy - i.e., the\napproximation error decays exponentially in the number of nonzero weights in\nthe network - of the multiplication operation, polynomials, sinusoidal\nfunctions, and certain smooth functions. Moreover, this holds true even for\none-dimensional oscillatory textures and the Weierstrass function - a fractal\nfunction, neither of which has previously known methods achieving exponential\napproximation accuracy. We also show that in the approximation of sufficiently\nsmooth functions finite-width deep networks require strictly smaller\nconnectivity than finite-depth wide networks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 09:41:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:25:03 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 14:16:56 GMT"}, {"version": "v4", "created": "Fri, 12 Mar 2021 13:59:26 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Elbr\u00e4chter", "Dennis", ""], ["Perekrestenko", "Dmytro", ""], ["Grohs", "Philipp", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1901.02230", "submitter": "Laurent Orseau", "authors": "Laurent Orseau, Tor Lattimore, Shane Legg", "title": "Soft-Bayes: Prod for Mixtures of Experts with Log-Loss", "comments": null, "journal-ref": "Algorithmic Learning Theory 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider prediction with expert advice under the log-loss with the goal of\nderiving efficient and robust algorithms. We argue that existing algorithms\nsuch as exponentiated gradient, online gradient descent and online Newton step\ndo not adequately satisfy both requirements. Our main contribution is an\nanalysis of the Prod algorithm that is robust to any data sequence and runs in\nlinear time relative to the number of experts in each round. Despite the\nunbounded nature of the log-loss, we derive a bound that is independent of the\nlargest loss and of the largest gradient, and depends only on the number of\nexperts and the time horizon. Furthermore we give a Bayesian interpretation of\nProd and adapt the algorithm to derive a tracking regret.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 10:06:53 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Orseau", "Laurent", ""], ["Lattimore", "Tor", ""], ["Legg", "Shane", ""]]}, {"id": "1901.02256", "submitter": "Tawfik Masrour", "authors": "Ibtissam El Hassani, Choumicha El Mazgualdi and Tawfik Masrour", "title": "Artificial Intelligence and Machine Learning to Predict and Improve\n  Efficiency in Manufacturing Industry", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall equipment effectiveness (OEE) is a performance measurement metric\nwidely used. Its calculation provides to the managers the possibility to\nidentify the main losses that reduce the machine effectiveness and then take\nthe necessary decisions in order to improve the situation. However, this\ncalculation is done a-posterior which is often too late. In the present\nresearch, we implemented different Machine Learning algorithms namely; Support\nvector machine, Optimized Support vector Machine (using Genetic Algorithm),\nRandom Forest, XGBoost and Deep Learning to predict the estimate OEE value. The\ndata used to train our models was provided by an automotive cable production\nindustry. The results show that the Deep Learning and Random Forest are more\naccurate and present better performance for the prediction of the overall\nequipment effectiveness in our case study.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 11:12:37 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 17:26:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Hassani", "Ibtissam El", ""], ["Mazgualdi", "Choumicha El", ""], ["Masrour", "Tawfik", ""]]}, {"id": "1901.02271", "submitter": "Sandhya Tripathi", "authors": "Sandhya Tripathi and N. Hemachandra", "title": "Cost Sensitive Learning in the Presence of Symmetric Label Noise", "comments": "Version 4 updates: Added comparison to noise rate $\\rho=0$ in Table\n  1,2, 9 and 10. Also, corrected the alpha values in the Table 1,2, 9 and 10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In binary classification framework, we are interested in making cost\nsensitive label predictions in the presence of uniform/symmetric label noise.\nWe first observe that $0$-$1$ Bayes classifiers are not (uniform) noise robust\nin cost sensitive setting. To circumvent this impossibility result, we present\ntwo schemes; unlike the existing methods, our schemes do not require noise\nrate. The first one uses $\\alpha$-weighted $\\gamma$-uneven margin squared loss\nfunction, $l_{\\alpha, usq}$, which can handle cost sensitivity arising due to\ndomain requirement (using user given $\\alpha$) or class imbalance (by tuning\n$\\gamma$) or both. However, we observe that $l_{\\alpha, usq}$ Bayes classifiers\nare also not cost sensitive and noise robust. We show that regularized ERM of\nthis loss function over the class of linear classifiers yields a cost sensitive\nuniform noise robust classifier as a solution of a system of linear equations.\nWe also provide a performance bound for this classifier. The second scheme that\nwe propose is a re-sampling based scheme that exploits the special structure of\nthe uniform noise models and uses in-class probability $\\eta$ estimates. Our\ncomputational experiments on some UCI datasets with class imbalance show that\nclassifiers of our two schemes are on par with the existing methods and in fact\nbetter in some cases w.r.t. Accuracy and Arithmetic Mean, without using/tuning\nnoise rate. We also consider other cost sensitive performance measures viz., F\nmeasure and Weighted Cost for evaluation. As our re-sampling scheme requires\nestimates of $\\eta$, we provide a detailed comparative study of various $\\eta$\nestimation methods on synthetic datasets, w.r.t. half a dozen evaluation\ncriterion. Also, we provide understanding on the interpretation of cost\nparameters $\\alpha$ and $\\gamma$ using different synthetic data experiments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 12:04:56 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 16:09:42 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 16:11:40 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 11:58:14 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Tripathi", "Sandhya", ""], ["Hemachandra", "N.", ""]]}, {"id": "1901.02291", "submitter": "S\\'everine Affeldt", "authors": "Severine Affeldt, Lazhar Labiod, Mohamed Nadif", "title": "Spectral Clustering via Ensemble Deep Autoencoder Learning (SC-EDAE)", "comments": "Revised manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a number of works have studied clustering strategies that combine\nclassical clustering algorithms and deep learning methods. These approaches\nfollow either a sequential way, where a deep representation is learned using a\ndeep autoencoder before obtaining clusters with k-means, or a simultaneous way,\nwhere deep representation and clusters are learned jointly by optimizing a\nsingle objective function. Both strategies improve clustering performance,\nhowever the robustness of these approaches is impeded by several deep\nautoencoder setting issues, among which the weights initialization, the width\nand number of layers or the number of epochs. To alleviate the impact of such\nhyperparameters setting on the clustering performance, we propose a new model\nwhich combines the spectral clustering and deep autoencoder strengths in an\nensemble learning framework. Extensive experiments on various benchmark\ndatasets demonstrate the potential and robustness of our approach compared to\nstate-of-the-art deep clustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 12:57:09 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 12:21:34 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Affeldt", "Severine", ""], ["Labiod", "Lazhar", ""], ["Nadif", "Mohamed", ""]]}, {"id": "1901.02302", "submitter": "Anna Bosman", "authors": "Anna Sergeevna Bosman, Andries Engelbrecht, Mard\\'e Helbig", "title": "Visualising Basins of Attraction for the Cross-Entropy and the Squared\n  Error Neural Network Loss Functions", "comments": "Preprint submitted to the Neural Networks journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification of the stationary points and the associated basins of\nattraction of neural network loss surfaces is an important step towards a\nbetter understanding of neural network loss surfaces at large. This work\nproposes a novel method to visualise basins of attraction together with the\nassociated stationary points via gradient-based random sampling. The proposed\ntechnique is used to perform an empirical study of the loss surfaces generated\nby two different error metrics: quadratic loss and entropic loss. The empirical\nobservations confirm the theoretical hypothesis regarding the nature of neural\nnetwork attraction basins. Entropic loss is shown to exhibit stronger gradients\nand fewer stationary points than quadratic loss, indicating that entropic loss\nhas a more searchable landscape. Quadratic loss is shown to be more resilient\nto overfitting than entropic loss. Both losses are shown to exhibit local\nminima, but the number of local minima is shown to decrease with an increase in\ndimensionality. Thus, the proposed visualisation technique successfully\ncaptures the local minima properties exhibited by the neural network loss\nsurfaces, and can be used for the purpose of fitness landscape analysis of\nneural networks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 13:34:36 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 09:42:12 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Bosman", "Anna Sergeevna", ""], ["Engelbrecht", "Andries", ""], ["Helbig", "Mard\u00e9", ""]]}, {"id": "1901.02321", "submitter": "Zhengkun Yi", "authors": "Zhengkun Yi and Cheng Li", "title": "Anti-drift in electronic nose via dimensionality reduction: a\n  discriminative subspace projection approach", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2019.2955712", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor drift is a well-known issue in the field of sensors and measurement\nand has plagued the sensor community for many years. In this paper, we propose\na sensor drift correction method to deal with the sensor drift problem.\nSpecifically, we propose a discriminative subspace projection approach for\nsensor drift reduction in electronic noses. The proposed method inherits the\nmerits of the subspace projection method called domain regularized component\nanalysis. Moreover, the proposed method takes the source data label information\ninto consideration, which minimizes the within-class variance of the projected\nsource samples and at the same time maximizes the between-class variance. The\nlabel information is exploited to avoid overlapping of samples with different\nlabels in the subspace. Experiments on two sensor drift datasets have shown the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 07:58:05 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yi", "Zhengkun", ""], ["Li", "Cheng", ""]]}, {"id": "1901.02322", "submitter": "Philipp Blandfort", "authors": "Philipp Blandfort, Tushar Karayil, Federico Raue, J\\\"orn Hees, Andreas\n  Dengel", "title": "Fusion Strategies for Learning User Embeddings with Neural Networks", "comments": "submitted to IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing amounts of online user data motivate the need for automated\nprocessing techniques. In case of user ratings, one interesting option is to\nuse neural networks for learning to predict ratings given an item and a user.\nWhile training for prediction, such an approach at the same time learns to map\neach user to a vector, a so-called user embedding. Such embeddings can for\nexample be valuable for estimating user similarity. However, there are various\nways how item and user information can be combined in neural networks, and it\nis unclear how the way of combining affects the resulting embeddings. In this\npaper, we run an experiment on movie ratings data, where we analyze the effect\non embedding quality caused by several fusion strategies in neural networks.\nFor evaluating embedding quality, we propose a novel measure, Pair-Distance\nCorrelation, which quantifies the condition that similar users should have\nsimilar embedding vectors. We find that the fusion strategy affects results in\nterms of both prediction performance and embedding quality. Surprisingly, we\nfind that prediction performance not necessarily reflects embedding quality.\nThis suggests that if embeddings are of interest, the common tendency to select\nmodels based on their prediction ability should be reconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 14:24:43 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Blandfort", "Philipp", ""], ["Karayil", "Tushar", ""], ["Raue", "Federico", ""], ["Hees", "J\u00f6rn", ""], ["Dengel", "Andreas", ""]]}, {"id": "1901.02324", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Andr\\'e F. T. Martins, Vlad Niculae", "title": "Learning with Fenchel-Young Losses", "comments": "In Journal of Machine Learning Research, volume 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, numerous loss functions have been been proposed for a\nvariety of supervised learning tasks, including regression, classification,\nranking, and more generally structured prediction. Understanding the core\nprinciples and theoretical properties underpinning these losses is key to\nchoose the right loss for the right problem, as well as to create new losses\nwhich combine their strengths. In this paper, we introduce Fenchel-Young\nlosses, a generic way to construct a convex loss function for a regularized\nprediction function. We provide an in-depth study of their properties in a very\nbroad setting, covering all the aforementioned supervised learning tasks, and\nrevealing new connections between sparsity, generalized entropies, and\nseparation margins. We show that Fenchel-Young losses unify many well-known\nloss functions and allow to create useful new ones easily. Finally, we derive\nefficient predictive and training algorithms, making Fenchel-Young losses\nappealing both in theory and practice.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 14:37:56 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 14:41:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Blondel", "Mathieu", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Niculae", "Vlad", ""]]}, {"id": "1901.02347", "submitter": "Jaedeok Kim", "authors": "Seung-Geon Lee, Jaedeok Kim, Hyun-Joo Jung, Yoonsuck Choe", "title": "Comparing Sample-wise Learnability Across Deep Neural Network Models", "comments": "Accepted to AAAI 2019 Student Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the relative importance of each sample in a training set has\nimportant practical and theoretical value, such as in importance sampling or\ncurriculum learning. This kind of focus on individual samples invokes the\nconcept of sample-wise learnability: How easy is it to correctly learn each\nsample (cf. PAC learnability)? In this paper, we approach the sample-wise\nlearnability problem within a deep learning context. We propose a measure of\nthe learnability of a sample with a given deep neural network (DNN) model. The\nbasic idea is to train the given model on the training set, and for each\nsample, aggregate the hits and misses over the entire training epochs. Our\nexperiments show that the sample-wise learnability measure collected this way\nis highly linearly correlated across different DNN models (ResNet-20, VGG-16,\nand MobileNet), suggesting that such a measure can provide deep general\ninsights on the data's properties. We expect our method to help develop better\ncurricula for training, and help us better understand the data itself.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 15:08:38 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Lee", "Seung-Geon", ""], ["Kim", "Jaedeok", ""], ["Jung", "Hyun-Joo", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "1901.02348", "submitter": "Minhua Wu", "authors": "Ladislav Mo\\v{s}ner, Minhua Wu, Anirudh Raju, Sree Hari Krishnan\n  Parthasarathi, Kenichi Kumatani, Shiva Sundaram, Roland Maas, Bj\\\"orn\n  Hoffmeister", "title": "Improving noise robustness of automatic speech recognition via parallel\n  data and teacher-student learning", "comments": "To Appear in ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For real-world speech recognition applications, noise robustness is still a\nchallenge. In this work, we adopt the teacher-student (T/S) learning technique\nusing a parallel clean and noisy corpus for improving automatic speech\nrecognition (ASR) performance under multimedia noise. On top of that, we apply\na logits selection method which only preserves the k highest values to prevent\nwrong emphasis of knowledge from the teacher and to reduce bandwidth needed for\ntransferring data. We incorporate up to 8000 hours of untranscribed data for\ntraining and present our results on sequence trained models apart from cross\nentropy trained ones. The best sequence trained student model yields relative\nword error rate (WER) reductions of approximately 10.1%, 28.7% and 19.6% on our\nclean, simulated noisy and real test sets respectively comparing to a sequence\ntrained teacher.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 06:22:40 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 06:15:47 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 20:16:57 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Mo\u0161ner", "Ladislav", ""], ["Wu", "Minhua", ""], ["Raju", "Anirudh", ""], ["Parthasarathi", "Sree Hari Krishnan", ""], ["Kumatani", "Kenichi", ""], ["Sundaram", "Shiva", ""], ["Maas", "Roland", ""], ["Hoffmeister", "Bj\u00f6rn", ""]]}, {"id": "1901.02352", "submitter": "Huibing Wang", "authors": "Huibing Wang, Haohao Li, Xianping Fu", "title": "Auto-weighted Mutli-view Sparse Reconstructive Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of multimedia era, multi-view data is generated in\nvarious fields. Contrast with those single-view data, multi-view data brings\nmore useful information and should be carefully excavated. Therefore, it is\nessential to fully exploit the complementary information embedded in multiple\nviews to enhance the performances of many tasks. Especially for those\nhigh-dimensional data, how to develop a multi-view dimension reduction\nalgorithm to obtain the low-dimensional representations is of vital importance\nbut chanllenging. In this paper, we propose a novel multi-view dimensional\nreduction algorithm named Auto-weighted Mutli-view Sparse Reconstructive\nEmbedding (AMSRE) to deal with this problem. AMSRE fully exploits the sparse\nreconstructive correlations between features from multiple views. Furthermore,\nit is equipped with an auto-weighted technique to treat multiple views\ndiscriminatively according to their contributions. Various experiments have\nverified the excellent performances of the proposed AMSRE.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 02:35:47 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Wang", "Huibing", ""], ["Li", "Haohao", ""], ["Fu", "Xianping", ""]]}, {"id": "1901.02354", "submitter": "Xiao Dong", "authors": "Xiao Dong, Ling Zhou", "title": "Geometrization of deep networks for the interpretability of deep\n  learning systems", "comments": "9 pages, draft version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to understand deep learning systems remains an open problem. In this\npaper we propose that the answer may lie in the geometrization of deep\nnetworks. Geometrization is a bridge to connect physics, geometry, deep network\nand quantum computation and this may result in a new scheme to reveal the rule\nof the physical world. By comparing the geometry of image matching and deep\nnetworks, we show that geometrization of deep networks can be used to\nunderstand existing deep learning systems and it may also help to solve the\ninterpretability problem of deep learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 14:32:45 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 17:20:05 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Dong", "Xiao", ""], ["Zhou", "Ling", ""]]}, {"id": "1901.02355", "submitter": "Yang Deng", "authors": "Yang Deng, Yao Sun, Yongpei Zhu, Yue Xu, Qianxi Yang, Shuo Zhang,\n  Mingwang Zhu, Jirang Sun, Weiling Zhao, Xiaobo Zhou and Kehong Yuan", "title": "Efforts estimation of doctors annotating medical image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate annotation of medical image is the crucial step for image AI\nclinical application. However, annotating medical image will incur a great deal\nof annotation effort and expense due to its high complexity and needing\nexperienced doctors. To alleviate annotation cost, some active learning methods\nare proposed. But such methods just cut the number of annotation candidates and\ndo not study how many efforts the doctor will exactly take, which is not enough\nsince even annotating a small amount of medical data will take a lot of time\nfor the doctor.\n  In this paper, we propose a new criterion to evaluate efforts of doctors\nannotating medical image. First, by coming active learning and U-shape network,\nwe employ a suggestive annotation strategy to choose the most effective\nannotation candidates. Then we exploit a fine annotation platform to alleviate\nannotating efforts on each candidate and first utilize a new criterion to\nquantitatively calculate the efforts taken by doctors. In our work, we take MR\nbrain tissue segmentation as an example to evaluate the proposed method.\n  Extensive experiments on the well-known IBSR18 dataset and MRBrainS18\nChallenge dataset show that, using proposed strategy, state-of-the-art\nsegmentation performance can be achieved by using only 60% annotation\ncandidates and annotation efforts can be alleviated by at least 44%, 44%, 47%\non CSF, GM, WM separately.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 02:37:54 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Deng", "Yang", ""], ["Sun", "Yao", ""], ["Zhu", "Yongpei", ""], ["Xu", "Yue", ""], ["Yang", "Qianxi", ""], ["Zhang", "Shuo", ""], ["Zhu", "Mingwang", ""], ["Sun", "Jirang", ""], ["Zhao", "Weiling", ""], ["Zhou", "Xiaobo", ""], ["Yuan", "Kehong", ""]]}, {"id": "1901.02358", "submitter": "Aditya Kusupati", "authors": "Aditya Kusupati, Manish Singh, Kush Bhatia, Ashish Kumar, Prateek Jain\n  and Manik Varma", "title": "FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated\n  Recurrent Neural Network", "comments": "23 pages, 10 figures, Published at Advances in Neural Information\n  Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops the FastRNN and FastGRNN algorithms to address the twin\nRNN limitations of inaccurate training and inefficient prediction. Previous\napproaches have improved accuracy at the expense of prediction costs making\nthem infeasible for resource-constrained and real-time applications. Unitary\nRNNs have increased accuracy somewhat by restricting the range of the state\ntransition matrix's singular values but have also increased the model size as\nthey require a larger number of hidden units to make up for the loss in\nexpressive power. Gated RNNs have obtained state-of-the-art accuracies by\nadding extra parameters thereby resulting in even larger models. FastRNN\naddresses these limitations by adding a residual connection that does not\nconstrain the range of the singular values explicitly and has only two extra\nscalar parameters. FastGRNN then extends the residual connection to a gate by\nreusing the RNN matrices to match state-of-the-art gated RNN accuracies but\nwith a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse\nand quantized resulted in accurate models that could be up to 35x smaller than\nleading gated and unitary RNNs. This allowed FastGRNN to accurately recognize\nthe \"Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely\nresource-constrained IoT microcontrollers too tiny to store other RNN models.\nFastGRNN's code is available at https://github.com/Microsoft/EdgeML/.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 15:19:13 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Kusupati", "Aditya", ""], ["Singh", "Manish", ""], ["Bhatia", "Kush", ""], ["Kumar", "Ashish", ""], ["Jain", "Prateek", ""], ["Varma", "Manik", ""]]}, {"id": "1901.02369", "submitter": "Dario  Izzo", "authors": "Dharmesh Tailor, Dario Izzo", "title": "Learning the optimal state-feedback via supervised imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is a control design paradigm that seeks to learn a control\npolicy reproducing demonstrations from expert agents. By substituting expert\ndemonstrations for optimal behaviours, the same paradigm leads to the design of\ncontrol policies closely approximating the optimal state-feedback. This\napproach requires training a machine learning algorithm (in our case deep\nneural networks) directly on state-control pairs originating from optimal\ntrajectories. We have shown in previous work that, when restricted to\nlow-dimensional state and control spaces, this approach is very successful in\nseveral deterministic, non-linear problems in continuous-time. In this work, we\nrefine our previous studies using as a test case a simple quadcopter model with\nquadratic and time-optimal objective functions. We describe in detail the best\nlearning pipeline we have developed, that is able to approximate via deep\nneural networks the state-feedback map to a very high accuracy. We introduce\nthe use of the softplus activation function in the hidden units of neural\nnetworks showing that it results in a smoother control profile whilst retaining\nthe benefits of rectifiers. We show how to evaluate the optimality of the\ntrained state-feedback, and find that already with two layers the objective\nfunction reached and its optimal value differ by less than one percent. We\nlater consider also an additional metric linked to the system asymptotic\nbehaviour - time taken to converge to the policy's fixed point. With respect to\nthese metrics, we show that improvements in the mean absolute error do not\nnecessarily correspond to better policies.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 14:11:06 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 09:56:14 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Tailor", "Dharmesh", ""], ["Izzo", "Dario", ""]]}, {"id": "1901.02374", "submitter": "Fredrik Lindsten", "authors": "Fredrik Lindsten, Jouni Helske, Matti Vihola", "title": "Graphical model inference: Sequential Monte Carlo meets deterministic\n  approximations", "comments": null, "journal-ref": "32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018), Montr\\'eal, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate inference in probabilistic graphical models (PGMs) can be grouped\ninto deterministic methods and Monte-Carlo-based methods. The former can often\nprovide accurate and rapid inferences, but are typically associated with biases\nthat are hard to quantify. The latter enjoy asymptotic consistency, but can\nsuffer from high computational costs. In this paper we present a way of\nbridging the gap between deterministic and stochastic inference. Specifically,\nwe suggest an efficient sequential Monte Carlo (SMC) algorithm for PGMs which\ncan leverage the output from deterministic inference methods. While generally\napplicable, we show explicitly how this can be done with loopy belief\npropagation, expectation propagation, and Laplace approximations. The resulting\nalgorithm can be viewed as a post-correction of the biases associated with\nthese methods and, indeed, numerical results show clear improvements over the\nbaseline deterministic methods as well as over \"plain\" SMC.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 15:43:39 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Lindsten", "Fredrik", ""], ["Helske", "Jouni", ""], ["Vihola", "Matti", ""]]}, {"id": "1901.02413", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Xin Wang, Ying Nian Wu, Huilin Zhou, Song-Chun Zhu", "title": "Interpretable CNNs for Object Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generic method to learn interpretable convolutional\nfilters in a deep convolutional neural network (CNN) for object classification,\nwhere each interpretable filter encodes features of a specific object part. Our\nmethod does not require additional annotations of object parts or textures for\nsupervision. Instead, we use the same training data as traditional CNNs. Our\nmethod automatically assigns each interpretable filter in a high conv-layer\nwith an object part of a certain category during the learning process. Such\nexplicit knowledge representations in conv-layers of CNN help people clarify\nthe logic encoded in the CNN, i.e., answering what patterns the CNN extracts\nfrom an input image and uses for prediction. We have tested our method using\ndifferent benchmark CNNs with various structures to demonstrate the broad\napplicability of our method. Experiments have shown that our interpretable\nfilters are much more semantically meaningful than traditional filters.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 17:15:19 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 07:04:28 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zhang", "Quanshi", ""], ["Wang", "Xin", ""], ["Wu", "Ying Nian", ""], ["Zhou", "Huilin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1901.02415", "submitter": "Ramtin Zand", "authors": "Ramtin Zand and Ronald F. DeMara", "title": "SNRA: A Spintronic Neuromorphic Reconfigurable Array for In-Circuit\n  Training and Evaluation of Deep Belief Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a spintronic neuromorphic reconfigurable Array (SNRA) is\ndeveloped to fuse together power-efficient probabilistic and in-field\nprogrammable deterministic computing during both training and evaluation phases\nof restricted Boltzmann machines (RBMs). First, probabilistic spin logic\ndevices are used to develop an RBM realization which is adapted to construct\ndeep belief networks (DBNs) having one to three hidden layers of size 10 to 800\nneurons each. Second, we design a hardware implementation for the contrastive\ndivergence (CD) algorithm using a four-state finite state machine capable of\nunsupervised training in N+3 clocks where N denotes the number of neurons in\neach RBM. The functionality of our proposed CD hardware implementation is\nvalidated using ModelSim simulations. We synthesize the developed Verilog HDL\nimplementation of our proposed test/train control circuitry for various DBN\ntopologies where the maximal RBM dimensions yield resource utilization ranging\nfrom 51 to 2,421 lookup tables (LUTs). Next, we leverage spin Hall effect\n(SHE)-magnetic tunnel junction (MTJ) based non-volatile LUTs circuits as an\nalternative for static random access memory (SRAM)-based LUTs storing the\ndeterministic logic configuration to form a reconfigurable fabric. Finally, we\ncompare the performance of our proposed SNRA with SRAM-based configurable\nfabrics focusing on the area and power consumption induced by the LUTs used to\nimplement both CD and evaluation modes. The results obtained indicate more than\n80% reduction in combined dynamic and static power dissipation, while achieving\nat least 50% reduction in device count.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 17:23:42 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Zand", "Ramtin", ""], ["DeMara", "Ronald F.", ""]]}, {"id": "1901.02427", "submitter": "Randy Ardywibowo", "authors": "Randy Ardywibowo, Guang Zhao, Zhangyang Wang, Bobak Mortazavi, Shuai\n  Huang, Xiaoning Qian", "title": "Adaptive Activity Monitoring with Uncertainty Quantification in\n  Switching Gaussian Process Models", "comments": "to appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging wearable sensors have enabled the unprecedented ability to\ncontinuously monitor human activities for healthcare purposes. However, with so\nmany ambient sensors collecting different measurements, it becomes important\nnot only to maintain good monitoring accuracy, but also low power consumption\nto ensure sustainable monitoring. This power-efficient sensing scheme can be\nachieved by deciding which group of sensors to use at a given time, requiring\nan accurate characterization of the trade-off between sensor energy usage and\nthe uncertainty in ignoring certain sensor signals while monitoring. To address\nthis challenge in the context of activity monitoring, we have designed an\nadaptive activity monitoring framework. We first propose a switching Gaussian\nprocess to model the observed sensor signals emitting from the underlying\nactivity states. To efficiently compute the Gaussian process model likelihood\nand quantify the context prediction uncertainty, we propose a block circulant\nembedding technique and use Fast Fourier Transforms (FFT) for inference. By\ncomputing the Bayesian loss function tailored to switching Gaussian processes,\nan adaptive monitoring procedure is developed to select features from available\nsensors that optimize the trade-off between sensor power consumption and the\nprediction performance quantified by state prediction entropy. We demonstrate\nthe effectiveness of our framework on the popular benchmark of UCI Human\nActivity Recognition using Smartphones.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 18:10:57 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Ardywibowo", "Randy", ""], ["Zhao", "Guang", ""], ["Wang", "Zhangyang", ""], ["Mortazavi", "Bobak", ""], ["Huang", "Shuai", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1901.02470", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Rebecca Willett, Stephen Wright, Robert Nowak", "title": "Bilinear Bandits with Low-rank Structure", "comments": "Accepted to ICML'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the bilinear bandit problem with low-rank structure in which an\naction takes the form of a pair of arms from two different entity types, and\nthe reward is a bilinear function of the known feature vectors of the arms. The\nunknown in the problem is a $d_1$ by $d_2$ matrix $\\mathbf{\\Theta}^*$ that\ndefines the reward, and has low rank $r \\ll \\min\\{d_1,d_2\\}$. Determination of\n$\\mathbf{\\Theta}^*$ with this low-rank structure poses a significant challenge\nin finding the right exploration-exploitation tradeoff. In this work, we\npropose a new two-stage algorithm called \"Explore-Subspace-Then-Refine\" (ESTR).\nThe first stage is an explicit subspace exploration, while the second stage is\na linear bandit algorithm called \"almost-low-dimensional OFUL\" (LowOFUL) that\nexploits and further refines the estimated subspace via a regularization\ntechnique. We show that the regret of ESTR is\n$\\widetilde{\\mathcal{O}}((d_1+d_2)^{3/2} \\sqrt{r T})$ where\n$\\widetilde{\\mathcal{O}}$ hides logarithmic factors and $T$ is the time\nhorizon, which improves upon the regret of\n$\\widetilde{\\mathcal{O}}(d_1d_2\\sqrt{T})$ attained for a na\\\"ive linear bandit\nreduction. We conjecture that the regret bound of ESTR is unimprovable up to\npolylogarithmic factors, and our preliminary experiment shows that ESTR\noutperforms a na\\\"ive linear bandit reduction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 19:03:48 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 18:42:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Willett", "Rebecca", ""], ["Wright", "Stephen", ""], ["Nowak", "Robert", ""]]}, {"id": "1901.02495", "submitter": "Efr\\'en Andr\\'es Estrella Terneux", "authors": "Andr\\'es Estrella Terneux, Dami\\'an Nicolalde, Daniel Nicolalde,\n  Andr\\'es Merino-Viteri", "title": "Presence-absence estimation in audio recordings of tropical frog\n  communities", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One non-invasive way to study frog communities is by analyzing long-term\nsamples of acoustic material containing calls. This immense task has been\noptimized by the development of Machine Learning tools to extract ecological\ninformation. We explored a likelihood-ratio audio detector based on Gaussian\nmixture model classification of 10 frog species, and applied it to estimate\npresence-absence in audio recordings from an actual amphibian monitoring\nperformed at Yasun\\'i National Park in the Ecuadorian Amazonia. A modified\nfilter-bank was used to extract 20 cepstral features that model the spectral\ncontent of frog calls. Experiments were carried out to investigate the\nhyperparameters and the minimum frog-call time needed to train an accurate GMM\nclassifier. With 64 Gaussians and 12 seconds of training time, the classifier\nachieved an average weighted error rate of 0.9% on the 10-fold cross-validation\nfor nine species classification, as compared to 3% with MFCC and 1.8% with PLP\nfeatures. For testing, 10 GMMs were trained using all the available\ntraining-validation dataset to study 23.5 hours in 141, 10-minute long samples\nof unidentified real-world audio recorded at two frog communities in 2001 with\nanalog equipment. To evaluate automatic presence-absence estimation, we\ncharacterized the audio samples with 10 binary variables each corresponding to\na frog species, and manually labeled a sub-set of 18 samples using headphones.\nA recall of 87.5% and precision of 100% with average accuracy of 96.66%\nsuggests good generalization ability of the algorithm, and provides evidence of\nthe validity of this approach to study real-world audio recorded in a tropical\nacoustic environment. Finally, we applied the algorithm to the available\ncorpus, and show its potentiality to gain insights into the temporal\nreproductive behavior of frogs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 20:08:42 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Terneux", "Andr\u00e9s Estrella", ""], ["Nicolalde", "Dami\u00e1n", ""], ["Nicolalde", "Daniel", ""], ["Merino-Viteri", "Andr\u00e9s", ""]]}, {"id": "1901.02511", "submitter": "Sumanth Chennupati", "authors": "Ganesh Sistu, Sumanth Chennupati and Senthil Yogamani", "title": "Multi-stream CNN based Video Semantic Segmentation for Automated Driving", "comments": "Accepted for Oral Presentation at VISAPP 2019", "journal-ref": null, "doi": "10.5220/0007248401730180", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of semantic segmentation algorithms operate on a single frame even\nin the case of videos. In this work, the goal is to exploit temporal\ninformation within the algorithm model for leveraging motion cues and temporal\nconsistency. We propose two simple high-level architectures based on Recurrent\nFCN (RFCN) and Multi-Stream FCN (MSFCN) networks. In case of RFCN, a recurrent\nnetwork namely LSTM is inserted between the encoder and decoder. MSFCN combines\nthe encoders of different frames into a fused encoder via 1x1 channel-wise\nconvolution. We use a ResNet50 network as the baseline encoder and construct\nthree networks namely MSFCN of order 2 & 3 and RFCN of order 2. MSFCN-3\nproduces the best results with an accuracy improvement of 9% and 15% for\nHighway and New York-like city scenarios in the SYNTHIA-CVPR'16 dataset using\nmean IoU metric. MSFCN-3 also produced 11% and 6% for SegTrack V2 and DAVIS\ndatasets over the baseline FCN network. We also designed an efficient version\nof MSFCN-2 and RFCN-2 using weight sharing among the two encoders. The\nefficient MSFCN-2 provided an improvement of 11% and 5% for KITTI and SYNTHIA\nwith negligible increase in computational complexity compared to the baseline\nversion.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 20:45:49 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Sistu", "Ganesh", ""], ["Chennupati", "Sumanth", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1901.02513", "submitter": "Ertunc Erdil", "authors": "Ertunc Erdil, Ali Ozgur Argunsah, Tolga Tasdizen, Devrim Unay, Mujdat\n  Cetin", "title": "Combining nonparametric spatial context priors with nonparametric shape\n  priors for dendritic spine segmentation in 2-photon microscopy images", "comments": "IEEE International Symposium on Biomedical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven segmentation is an important initial step of shape prior-based\nsegmentation methods since it is assumed that the data term brings a curve to a\nplausible level so that shape and data terms can then work together to produce\nbetter segmentations. When purely data driven segmentation produces poor\nresults, the final segmentation is generally affected adversely. One challenge\nfaced by many existing data terms is due to the fact that they consider only\npixel intensities to decide whether to assign a pixel to the foreground or to\nthe background region. When the distributions of the foreground and background\npixel intensities have significant overlap, such data terms become ineffective,\nas they produce uncertain results for many pixels in a test image. In such\ncases, using prior information about the spatial context of the object to be\nsegmented together with the data term can bring a curve to a plausible stage,\nwhich would then serve as a good initial point to launch shape-based\nsegmentation. In this paper, we propose a new segmentation approach that\ncombines nonparametric context priors with a learned-intensity-based data term\nand nonparametric shape priors. We perform experiments for dendritic spine\nsegmentation in both 2D and 3D 2-photon microscopy images. The experimental\nresults demonstrate that using spatial context priors leads to significant\nimprovements.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 20:47:46 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 12:21:03 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Erdil", "Ertunc", ""], ["Argunsah", "Ali Ozgur", ""], ["Tasdizen", "Tolga", ""], ["Unay", "Devrim", ""], ["Cetin", "Mujdat", ""]]}, {"id": "1901.02514", "submitter": "Stephanie Ger", "authors": "Stephanie Ger, Diego Klabjan", "title": "Autoencoders and Generative Adversarial Networks for Imbalanced Sequence\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been used in many different\napplications to generate realistic synthetic data. We introduce a novel GAN\nwith Autoencoder (GAN-AE) architecture to generate synthetic samples for\nvariable length, multi-feature sequence datasets. In this model, we develop a\nGAN architecture with an additional autoencoder component, where recurrent\nneural networks (RNNs) are used for each component of the model in order to\ngenerate synthetic data to improve classification accuracy for a highly\nimbalanced medical device dataset. In addition to the medical device dataset,\nwe also evaluate the GAN-AE performance on two additional datasets and\ndemonstrate the application of GAN-AE to a sequence-to-sequence task where both\nsynthetic sequence inputs and sequence outputs must be generated. To evaluate\nthe quality of the synthetic data, we train encoder-decoder models both with\nand without the synthetic data and compare the classification model\nperformance. We show that a model trained with GAN-AE generated synthetic data\noutperforms models trained with synthetic data generated both with standard\noversampling techniques such as SMOTE and Autoencoders as well as with state of\nthe art GAN-based models.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 20:52:35 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 04:06:01 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 13:42:14 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 00:28:15 GMT"}, {"version": "v5", "created": "Wed, 19 Aug 2020 18:59:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Ger", "Stephanie", ""], ["Klabjan", "Diego", ""]]}, {"id": "1901.02549", "submitter": "Pavel Temirchev", "authors": "Pavel Temirchev, Maxim Simonov, Ruslan Kostoev, Evgeny Burnaev, Ivan\n  Oseledets, Alexey Akhmetov, Andrey Margarit, Alexander Sitnikov and Dmitry\n  Koroteev", "title": "Deep Neural Networks Predicting Oil Movement in a Development Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique for assessing the dynamics of multiphase fluid\nflow in the oil reservoir. We demonstrate an efficient workflow for handling\nthe 3D reservoir simulation data in a way which is orders of magnitude faster\nthan the conventional routine. The workflow (we call it \"Metamodel\") is based\non a projection of the system dynamics into a latent variable space, using\nVariational Autoencoder model, where Recurrent Neural Network predicts the\ndynamics. We show that being trained on multiple results of the conventional\nreservoir modelling, the Metamodel does not compromise the accuracy of the\nreservoir dynamics reconstruction in a significant way. It allows forecasting\nnot only the flow rates from the wells, but also the dynamics of pressure and\nfluid saturations within the reservoir. The results open a new perspective in\nthe optimization of oilfield development as the scenario screening could be\naccelerated sufficiently.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 23:08:27 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 11:56:08 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Temirchev", "Pavel", ""], ["Simonov", "Maxim", ""], ["Kostoev", "Ruslan", ""], ["Burnaev", "Evgeny", ""], ["Oseledets", "Ivan", ""], ["Akhmetov", "Alexey", ""], ["Margarit", "Andrey", ""], ["Sitnikov", "Alexander", ""], ["Koroteev", "Dmitry", ""]]}, {"id": "1901.02602", "submitter": "Asanka G. Perera", "authors": "Asanka G Perera, Yee Wei Law, and Javaan Chahl", "title": "UAV-GESTURE: A Dataset for UAV Control and Gesture Recognition", "comments": "12 pages, 4 figures, UAVision workshop, ECCV, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current UAV-recorded datasets are mostly limited to action recognition and\nobject tracking, whereas the gesture signals datasets were mostly recorded in\nindoor spaces. Currently, there is no outdoor recorded public video dataset for\nUAV commanding signals. Gesture signals can be effectively used with UAVs by\nleveraging the UAVs visual sensors and operational simplicity. To fill this gap\nand enable research in wider application areas, we present a UAV gesture\nsignals dataset recorded in an outdoor setting. We selected 13 gestures\nsuitable for basic UAV navigation and command from general aircraft handling\nand helicopter handling signals. We provide 119 high-definition video clips\nconsisting of 37151 frames. The overall baseline gesture recognition\nperformance computed using Pose-based Convolutional Neural Network (P-CNN) is\n91.9 %. All the frames are annotated with body joints and gesture classes in\norder to extend the dataset's applicability to a wider research area including\ngesture recognition, action recognition, human pose recognition and situation\nawareness.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 04:35:18 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Perera", "Asanka G", ""], ["Law", "Yee Wei", ""], ["Chahl", "Javaan", ""]]}, {"id": "1901.02705", "submitter": "Mikael Henaff", "authors": "Mikael Henaff, Alfredo Canziani and Yann LeCun", "title": "Model-Predictive Policy Learning with Uncertainty Regularization for\n  Driving in Dense Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a policy using only observational data is challenging because the\ndistribution of states it induces at execution time may differ from the\ndistribution observed during training. We propose to train a policy by\nunrolling a learned model of the environment dynamics over multiple time steps\nwhile explicitly penalizing two costs: the original cost the policy seeks to\noptimize, and an uncertainty cost which represents its divergence from the\nstates it is trained on. We measure this second cost by using the uncertainty\nof the dynamics model about its own predictions, using recent ideas from\nuncertainty estimation for deep networks. We evaluate our approach using a\nlarge-scale observational dataset of driving behavior recorded from traffic\ncameras, and show that we are able to learn effective driving policies from\npurely observational data, with no environment interaction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 00:39:21 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Henaff", "Mikael", ""], ["Canziani", "Alfredo", ""], ["LeCun", "Yann", ""]]}, {"id": "1901.02717", "submitter": "Bhavya Kailkhura", "authors": "Bhavya Kailkhura, Brian Gallagher, Sookyung Kim, Anna Hiszpanski, T.\n  Yong-Jin Han", "title": "Reliable and Explainable Machine Learning Methods for Accelerated\n  Material Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Material scientists are increasingly adopting the use of machine learning\n(ML) for making potentially important decisions, such as, discovery,\ndevelopment, optimization, synthesis and characterization of materials.\nHowever, despite ML's impressive performance in commercial applications,\nseveral unique challenges exist when applying ML in materials science\napplications. In such a context, the contributions of this work are twofold.\nFirst, we identify common pitfalls of existing ML techniques when learning from\nunderrepresented/imbalanced material data. Specifically, we show that with\nimbalanced data, standard methods for assessing quality of ML models break down\nand lead to misleading conclusions. Furthermore, we found that the model's own\nconfidence score cannot be trusted and model introspection methods (using\nsimpler models) do not help as they result in loss of predictive performance\n(reliability-explainability trade-off). Second, to overcome these challenges,\nwe propose a general-purpose explainable and reliable machine-learning\nframework. Specifically, we propose a novel pipeline that employs an ensemble\nof simpler models to reliably predict material properties. We also propose a\ntransfer learning technique and show that the performance loss due to models'\nsimplicity can be overcome by exploiting correlations among different material\nproperties. A new evaluation metric and a trust score to better quantify the\nconfidence in the predictions are also proposed. To improve the\ninterpretability, we add a rationale generator component to our framework which\nprovides both model-level and decision-level explanations. Finally, we\ndemonstrate the versatility of our technique on two applications: 1) predicting\nproperties of crystalline compounds, and 2) identifying novel potentially\nstable solar cell materials.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 02:17:57 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 22:30:38 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Gallagher", "Brian", ""], ["Kim", "Sookyung", ""], ["Hiszpanski", "Anna", ""], ["Han", "T. Yong-Jin", ""]]}, {"id": "1901.02719", "submitter": "Emanuele Fabbiani", "authors": "Andrea Marziali, Emanuele Fabbiani and Giuseppe De Nicolao", "title": "Forecasting residential gas demand: machine learning approaches and\n  seasonal role of temperature forecasts", "comments": null, "journal-ref": "Int. J. Oil, Gas and Coal Technology, Vol. 26, No. 2, pp.202-224\n  (2021)", "doi": "10.1504/IJOGCT.2021.10035081", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gas demand forecasting is a critical task for energy providers as it impacts\non pipe reservation and stock planning. In this paper, the one-day-ahead\nforecasting of residential gas demand at country level is investigated by\nimplementing and comparing five models: Ridge Regression, Gaussian Process\n(GP), k-Nearest Neighbour, Artificial Neural Network (ANN), and Torus Model.\nItalian demand data from 2007 to 2017 are used for training and testing the\nproposed algorithms. The choice of the relevant covariates and the most\nsignificant aspects of the pre-processing and feature extraction steps are\ndiscussed in-depth, lending particular attention to the role of one-day-ahead\ntemperature forecasts. Our best model, in terms of Root Mean Squared Error\n(RMSE), is the ANN, closely followed by the GP. If the Mean Absolute Error\n(MAE) is taken as an error measure, the GP becomes the best model, although by\na narrow margin. A main novel contribution is the development of a model\ndescribing the propagation of temperature errors to gas forecasting errors that\nis successfully validated on experimental data. Being able to predict the\nquantitative impact of temperature forecasts on gas forecasts could be useful\nin order to assess potential improvement margins associated with more\nsophisticated weather forecasts. On the Italian data, it is shown that\ntemperature forecast errors account for some 18% of the mean squared error of\ngas demand forecasts provided by ANN.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 12:28:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 16:21:18 GMT"}, {"version": "v3", "created": "Sun, 17 Feb 2019 11:48:49 GMT"}, {"version": "v4", "created": "Fri, 3 May 2019 08:01:29 GMT"}, {"version": "v5", "created": "Tue, 10 Mar 2020 16:04:32 GMT"}, {"version": "v6", "created": "Wed, 12 Aug 2020 15:40:15 GMT"}, {"version": "v7", "created": "Thu, 13 Aug 2020 08:16:26 GMT"}, {"version": "v8", "created": "Sat, 23 Jan 2021 17:35:31 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marziali", "Andrea", ""], ["Fabbiani", "Emanuele", ""], ["De Nicolao", "Giuseppe", ""]]}, {"id": "1901.02731", "submitter": "Kumar Shridhar", "authors": "Kumar Shridhar, Felix Laumann, Marcus Liwicki", "title": "A Comprehensive guide to Bayesian Convolutional Neural Network with\n  Variational Inference", "comments": "arXiv admin note: text overlap with arXiv:1506.02158,\n  arXiv:1703.04977 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks are connectionist systems that perform a given\ntask by learning on examples without having prior knowledge about the task.\nThis is done by finding an optimal point estimate for the weights in every\nnode. Generally, the network using point estimates as weights perform well with\nlarge datasets, but they fail to express uncertainty in regions with little or\nno data, leading to overconfident decisions.\n  In this paper, Bayesian Convolutional Neural Network (BayesCNN) using\nVariational Inference is proposed, that introduces probability distribution\nover the weights. Furthermore, the proposed BayesCNN architecture is applied to\ntasks like Image Classification, Image Super-Resolution and Generative\nAdversarial Networks. The results are compared to point-estimates based\narchitectures on MNIST, CIFAR-10 and CIFAR-100 datasets for Image\nCLassification task, on BSD300 dataset for Image Super Resolution task and on\nCIFAR10 dataset again for Generative Adversarial Network task.\n  BayesCNN is based on Bayes by Backprop which derives a variational\napproximation to the true posterior. We, therefore, introduce the idea of\napplying two convolutional operations, one for the mean and one for the\nvariance. Our proposed method not only achieves performances equivalent to\nfrequentist inference in identical architectures but also incorporate a\nmeasurement for uncertainties and regularisation. It further eliminates the use\nof dropout in the model. Moreover, we predict how certain the model prediction\nis based on the epistemic and aleatoric uncertainties and empirically show how\nthe uncertainty can decrease, allowing the decisions made by the network to\nbecome more deterministic as the training accuracy increases. Finally, we\npropose ways to prune the Bayesian architecture and to make it more\ncomputational and time effective.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 13:03:14 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Shridhar", "Kumar", ""], ["Laumann", "Felix", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1901.02733", "submitter": "Mehdi Molkaraie", "authors": "Mehdi Molkaraie", "title": "Marginal Densities, Factor Graph Duality, and High-Temperature Series\n  Expansions", "comments": "Proc. of the 23rd International Conference on Artificial Intelligence\n  and Statistics (AISTATS) 2020, Palermo, Italy. Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the marginal densities of a global probability mass function in\na primal normal factor graph and the corresponding marginal densities in the\ndual normal factor graph are related via local mappings. The mapping depends on\nthe Fourier transform of the local factors of the models. Details of the\nmapping, including its fixed points, are derived for the Ising model, and then\nextended to the Potts model. By employing the mapping, we can transform\nsimultaneously all the estimated marginal densities from one domain to the\nother, which is advantageous if estimating the marginals can be carried out\nmore efficiently in the dual domain. An example of particular significance is\nthe ferromagnetic Ising model in a positive external field, for which there is\na rapidly mixing Markov chain (called the subgraphs-world process) to generate\nconfigurations in the dual normal factor graph of the model. Our numerical\nexperiments illustrate that the proposed procedure can provide more accurate\nestimates of marginal densities in various settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 03:48:18 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 16:38:36 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 19:45:24 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Molkaraie", "Mehdi", ""]]}, {"id": "1901.02739", "submitter": "Weonyoung Joo", "authors": "Weonyoung Joo, Wonsung Lee, Sungrae Park, Il-Chul Moon", "title": "Dirichlet Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Dirichlet Variational Autoencoder (DirVAE) using a\nDirichlet prior for a continuous latent variable that exhibits the\ncharacteristic of the categorical probabilities. To infer the parameters of\nDirVAE, we utilize the stochastic gradient method by approximating the Gamma\ndistribution, which is a component of the Dirichlet distribution, with the\ninverse Gamma CDF approximation. Additionally, we reshape the component\ncollapsing issue by investigating two problem sources, which are decoder weight\ncollapsing and latent value collapsing, and we show that DirVAE has no\ncomponent collapsing; while Gaussian VAE exhibits the decoder weight collapsing\nand Stick-Breaking VAE shows the latent value collapsing. The experimental\nresults show that 1) DirVAE models the latent representation result with the\nbest log-likelihood compared to the baselines; and 2) DirVAE produces more\ninterpretable latent values with no collapsing issues which the baseline models\nsuffer from. Also, we show that the learned latent representation from the\nDirVAE achieves the best classification accuracy in the semi-supervised and the\nsupervised classification tasks on MNIST, OMNIGLOT, and SVHN compared to the\nbaseline VAEs. Finally, we demonstrated that the DirVAE augmented topic models\nshow better performances in most cases.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 13:38:16 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Joo", "Weonyoung", ""], ["Lee", "Wonsung", ""], ["Park", "Sungrae", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1901.02757", "submitter": "HyunJoo Jung", "authors": "Hyun-Joo Jung, Jaedeok Kim, Yoonsuck Choe", "title": "How Compact?: Assessing Compactness of Representations through\n  Layer-Wise Pruning", "comments": "Accepted to AAAI 2019 Workshop on Network Interpretability for Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various forms of representations may arise in the many layers embedded in\ndeep neural networks (DNNs). Of these, where can we find the most compact\nrepresentation? We propose to use a pruning framework to answer this question:\nHow compact can each layer be compressed, without losing performance? Most of\nthe existing DNN compression methods do not consider the relative\ncompressibility of the individual layers. They uniformly apply a single target\nsparsity to all layers or adapt layer sparsity using heuristics and additional\ntraining. We propose a principled method that automatically determines the\nsparsity of individual layers derived from the importance of each layer. To do\nthis, we consider a metric to measure the importance of each layer based on the\nlayer-wise capacity. Given the trained model and the total target sparsity, we\nfirst evaluate the importance of each layer from the model. From the evaluated\nimportance, we compute the layer-wise sparsity of each layer. The proposed\nmethod can be applied to any DNN architecture and can be combined with any\npruning method that takes the total target sparsity as a parameter. To validate\nthe proposed method, we carried out an image classification task with two types\nof DNN architectures on two benchmark datasets and used three pruning methods\nfor compression. In case of VGG-16 model with weight pruning on the ImageNet\ndataset, we achieved up to 75% (17.5% on average) better top-5 accuracy than\nthe baseline under the same total target sparsity. Furthermore, we analyzed\nwhere the maximum compression can occur in the network. This kind of analysis\ncan help us identify the most compact representation within a deep neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 14:18:47 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Jung", "Hyun-Joo", ""], ["Kim", "Jaedeok", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "1901.02860", "submitter": "Zihang Dai", "authors": "Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le,\n  Ruslan Salakhutdinov", "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context", "comments": "ACL 2019 long paper. Code and pretrained models are available at\n  https://github.com/kimiyoung/transformer-xl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformers have a potential of learning longer-term dependency, but are\nlimited by a fixed-length context in the setting of language modeling. We\npropose a novel neural architecture Transformer-XL that enables learning\ndependency beyond a fixed length without disrupting temporal coherence. It\nconsists of a segment-level recurrence mechanism and a novel positional\nencoding scheme. Our method not only enables capturing longer-term dependency,\nbut also resolves the context fragmentation problem. As a result,\nTransformer-XL learns dependency that is 80% longer than RNNs and 450% longer\nthan vanilla Transformers, achieves better performance on both short and long\nsequences, and is up to 1,800+ times faster than vanilla Transformers during\nevaluation. Notably, we improve the state-of-the-art results of bpc/perplexity\nto 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion\nWord, and 54.5 on Penn Treebank (without finetuning). When trained only on\nWikiText-103, Transformer-XL manages to generate reasonably coherent, novel\ntext articles with thousands of tokens. Our code, pretrained models, and\nhyperparameters are available in both Tensorflow and PyTorch.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:28:19 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 18:38:00 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 21:21:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Dai", "Zihang", ""], ["Yang", "Zhilin", ""], ["Yang", "Yiming", ""], ["Carbonell", "Jaime", ""], ["Le", "Quoc V.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1901.02871", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, David Simchi-Levi, Xinshang Wang", "title": "The Lingering of Gradients: Theory and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classically, the time complexity of a first-order method is estimated by its\nnumber of gradient computations. In this paper, we study a more refined\ncomplexity by taking into account the `lingering' of gradients: once a gradient\nis computed at $x_k$, the additional time to compute gradients at\n$x_{k+1},x_{k+2},\\dots$ may be reduced.\n  We show how this improves the running time of several first-order methods.\nFor instance, if the `additional time' scales linearly with respect to the\ntraveled distance, then the `convergence rate' of gradient descent can be\nimproved from $1/T$ to $\\exp(-T^{1/3})$. On the application side, we solve a\nhypothetical revenue management problem on the Yahoo! Front Page Today Module\nwith 4.6m users to $10^{-6}$ error using only 6 passes of the dataset; and\nsolve a real-life support vector machine problem to an accuracy that is two\norders of magnitude better comparing to the state-of-the-art algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:45:10 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 11:44:06 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Simchi-Levi", "David", ""], ["Wang", "Xinshang", ""]]}, {"id": "1901.02878", "submitter": "Enoch Yeung Ph.D.", "authors": "W. Brent Daniel, Enoch Yeung", "title": "A Constructive Approach for One-Shot Training of Neural Networks Using\n  Hypercube-Based Topological Coverings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we presented a novel constructive approach for training deep\nneural networks using geometric approaches. We show that a topological covering\ncan be used to define a class of distributed linear matrix inequalities, which\nin turn directly specify the shape and depth of a neural network architecture.\nThe key insight is a fundamental relationship between linear matrix\ninequalities and their ability to bound the shape of data, and the rectified\nlinear unit (ReLU) activation function employed in modern neural networks. We\nshow that unit cover geometry and cover porosity are two design variables in\ncover-constructive learning that play a critical role in defining the\ncomplexity of the model and generalizability of the resulting neural network\nclassifier. In the context of cover-constructive learning, these findings\nunderscore the age old trade-off between model complexity and overfitting (as\nquantified by the number of elements in the data cover) and generalizability on\ntest data. Finally, we benchmark on algorithm on the Iris, MNIST, and Wine\ndataset and show that the constructive algorithm is able to train a deep neural\nnetwork classifier in one shot, achieving equal or superior levels of training\nand test classification accuracy with reduced training time.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:59:10 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Daniel", "W. Brent", ""], ["Yeung", "Enoch", ""]]}, {"id": "1901.02884", "submitter": "Philipp V. Rouast", "authors": "Philipp V. Rouast, Marc T. P. Adam, and Raymond Chiong", "title": "Deep Learning for Human Affect Recognition: Insights and New\n  Developments", "comments": "To be published in IEEE Transactions on Affective Computing. 20\n  pages, 7 figures, 6 tables", "journal-ref": null, "doi": "10.1109/TAFFC.2018.2890471", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic human affect recognition is a key step towards more natural\nhuman-computer interaction. Recent trends include recognition in the wild using\na fusion of audiovisual and physiological sensors, a challenging setting for\nconventional machine learning algorithms. Since 2010, novel deep learning\nalgorithms have been applied increasingly in this field. In this paper, we\nreview the literature on human affect recognition between 2010 and 2017, with a\nspecial focus on approaches using deep neural networks. By classifying a total\nof 950 studies according to their usage of shallow or deep architectures, we\nare able to show a trend towards deep learning. Reviewing a subset of 233\nstudies that employ deep neural networks, we comprehensively quantify their\napplications in this field. We find that deep learning is used for learning of\n(i) spatial feature representations, (ii) temporal feature representations, and\n(iii) joint feature representations for multimodal sensor data. Exemplary\nstate-of-the-art architectures illustrate the progress. Our findings show the\nrole deep architectures will play in human affect recognition, and can serve as\na reference point for researchers working on related applications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 23:33:47 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Rouast", "Philipp V.", ""], ["Adam", "Marc T. P.", ""], ["Chiong", "Raymond", ""]]}, {"id": "1901.02915", "submitter": "Charles Zheng", "authors": "Charles Y. Zheng, Francisco Pereira, Chris I. Baker, Martin N. Hebart", "title": "Revealing interpretable object representations from human behavior", "comments": "Accepted in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study how mental object representations are related to behavior, we\nestimated sparse, non-negative representations of objects using human\nbehavioral judgments on images representative of 1,854 object categories. These\nrepresentations predicted a latent similarity structure between objects, which\ncaptured most of the explainable variance in human behavioral judgments.\nIndividual dimensions in the low-dimensional embedding were found to be highly\nreproducible and interpretable as conveying degrees of taxonomic membership,\nfunctionality, and perceptual attributes. We further demonstrated the\npredictive power of the embeddings for explaining other forms of human\nbehavior, including categorization, typicality judgments, and feature ratings,\nsuggesting that the dimensions reflect human conceptual representations of\nobjects beyond the specific task.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 20:04:42 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Zheng", "Charles Y.", ""], ["Pereira", "Francisco", ""], ["Baker", "Chris I.", ""], ["Hebart", "Martin N.", ""]]}, {"id": "1901.02920", "submitter": "Tao Sun", "authors": "Tao Sun, Zhewei Wang, C. D. Smith, Jundong Liu", "title": "TraceCaps: A Capsule-based Neural Network for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a capsule-based neural network model to solve the\nsemantic segmentation problem. By taking advantage of the extractable\npart-whole dependencies available in capsule layers, we derive the\nprobabilities of the class labels for individual capsules through a recursive,\nlayer-by-layer procedure. We model this procedure as a traceback pipeline and\ntake it as a central piece to build an end-to-end segmentation network. Under\nthe proposed framework, image-level class labels and object boundaries are\njointly sought in an explicit manner, which poses a significant advantage over\nthe state-of-the-art fully convolutional network (FCN) solutions. With the\ncapability to extracted part-whole information, our traceback pipeline can\npotentially be utilized as the building blocks to design interpretable neural\nnetworks. Experiments conducted on modified MNIST and neuroimages demonstrate\nthat our model considerably enhance the segmentation performance compared to\nthe leading FCN variants.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 20:23:13 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 19:22:44 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Sun", "Tao", ""], ["Wang", "Zhewei", ""], ["Smith", "C. D.", ""], ["Liu", "Jundong", ""]]}, {"id": "1901.02928", "submitter": "Hao Chen Dr.", "authors": "Hao Chen, Lanshan Han, Alvin Lim", "title": "Beyond the EM Algorithm: Constrained Optimization Methods for Latent\n  Class Model", "comments": null, "journal-ref": null, "doi": "10.1080/03610918.2020.1764034", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent class model (LCM), which is a finite mixture of different categorical\ndistributions, is one of the most widely used models in statistics and machine\nlearning fields. Because of its non-continuous nature and the flexibility in\nshape, researchers in practice areas such as marketing and social sciences also\nfrequently use LCM to gain insights from their data. One likelihood-based\nmethod, the Expectation-Maximization (EM) algorithm, is often used to obtain\nthe model estimators. However, the EM algorithm is well-known for its\nnotoriously slow convergence. In this research, we explore alternative\nlikelihood-based methods that can potential remedy the slow convergence of the\nEM algorithm. More specifically, we regard likelihood-based approach as a\nconstrained nonlinear optimization problem, and apply quasi-Newton type methods\nto solve them. We examine two different constrained optimization methods to\nmaximize the log likelihood function. We present simulation study results to\nshow that the proposed methods not only converge in less iterations than the EM\nalgorithm but also produce more accurate model estimators.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 21:00:36 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 01:09:24 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2019 17:57:20 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 05:39:33 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Chen", "Hao", ""], ["Han", "Lanshan", ""], ["Lim", "Alvin", ""]]}, {"id": "1901.02975", "submitter": "Hrushikesh Mhaskar", "authors": "H. N. Mhaskar, A. Cloninger, X. Cheng", "title": "A witness function based construction of discriminative models using\n  Hermite polynomials", "comments": "20 pages, 3.1 MB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, we are given a dataset of the form\n$\\{(\\mathbf{x}_j,y_j)\\}_{j=1}^M$, drawn as i.i.d. samples from an unknown\nprobability distribution $\\mu$; the marginal distribution for the\n$\\mathbf{x}_j$'s being $\\mu^*$. We propose that rather than using a positive\nkernel such as the Gaussian for estimation of these measures, using a\nnon-positive kernel that preserves a large number of moments of these measures\nyields an optimal approximation. We use multi-variate Hermite polynomials for\nthis purpose, and prove optimal and local approximation results in a supremum\nnorm in a probabilistic sense. Together with a permutation test developed with\nthe same kernel, we prove that the kernel estimator serves as a `witness\nfunction' in classification problems. Thus, if the value of this estimator at a\npoint $\\mathbf{x}$ exceeds a certain threshold, then the point is reliably in a\ncertain class. This approach can be used to modify pretrained algorithms, such\nas neural networks or nonlinear dimension reduction techniques, to identify\nin-class vs out-of-class regions for the purposes of generative models,\nclassification uncertainty, or finding robust centroids. This fact is\ndemonstrated in a number of real world data sets including MNIST, CIFAR10,\nScience News documents, and LaLonde data sets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 00:14:26 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Mhaskar", "H. N.", ""], ["Cloninger", "A.", ""], ["Cheng", "X.", ""]]}, {"id": "1901.03006", "submitter": "Daniel Liu", "authors": "Daniel Liu, Ronald Yu, Hao Su", "title": "Extending Adversarial Attacks and Defenses to Deep 3D Point Cloud\n  Classifiers", "comments": "Abridged version accepted at the 2019 IEEE International Conference\n  on Image Processing (ICIP). Source code:\n  https://github.com/Daniel-Liu-c0deb0t/3D-Neural-Network-Adversarial-Attacks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object classification and segmentation using deep neural networks has been\nextremely successful. As the problem of identifying 3D objects has many\nsafety-critical applications, the neural networks have to be robust against\nadversarial changes to the input data set. There is a growing body of research\non generating human-imperceptible adversarial attacks and defenses against them\nin the 2D image classification domain. However, 3D objects have various\ndifferences with 2D images, and this specific domain has not been rigorously\nstudied so far.\n  We present a preliminary evaluation of adversarial attacks on deep 3D point\ncloud classifiers, namely PointNet and PointNet++, by evaluating both white-box\nand black-box adversarial attacks that were proposed for 2D images and\nextending those attacks to reduce the perceptibility of the perturbations in 3D\nspace. We also show the high effectiveness of simple defenses against those\nattacks by proposing new defenses that exploit the unique structure of 3D point\nclouds. Finally, we attempt to explain the effectiveness of the defenses\nthrough the intrinsic structures of both the point clouds and the neural\nnetwork architectures. Overall, we find that networks that process 3D point\ncloud data are weak to adversarial attacks, but they are also more easily\ndefensible compared to 2D image classifiers. Our investigation will provide the\ngroundwork for future studies on improving the robustness of deep neural\nnetworks that handle 3D data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 03:12:07 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 04:50:59 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 03:29:12 GMT"}, {"version": "v4", "created": "Fri, 28 Jun 2019 17:55:46 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Liu", "Daniel", ""], ["Yu", "Ronald", ""], ["Su", "Hao", ""]]}, {"id": "1901.03040", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Hao Gao, Wu-Jun Li", "title": "Quantized Epoch-SGD for Communication-Efficient Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its efficiency and ease to implement, stochastic gradient descent\n(SGD) has been widely used in machine learning. In particular, SGD is one of\nthe most popular optimization methods for distributed learning. Recently,\nquantized SGD (QSGD), which adopts quantization to reduce the communication\ncost in SGD-based distributed learning, has attracted much attention. Although\nseveral QSGD methods have been proposed, some of them are heuristic without\ntheoretical guarantee, and others have high quantization variance which makes\nthe convergence become slow. In this paper, we propose a new method, called\nQuantized Epoch-SGD (QESGD), for communication-efficient distributed learning.\nQESGD compresses (quantizes) the parameter with variance reduction, so that it\ncan get almost the same performance as that of SGD with less communication\ncost. QESGD is implemented on the Parameter Server framework, and empirical\nresults on distributed deep learning show that QESGD can outperform other\nstate-of-the-art quantization methods to achieve the best performance.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 07:16:06 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Gao", "Hao", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1901.03073", "submitter": "Gengyu Lyu", "authors": "Gengyu Lyu, Songhe Feng, Tao Wang, Congyan Lang, Yidong Li", "title": "GM-PLL: Graph Matching based Partial Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Label Learning (PLL) aims to learn from the data where each training\nexample is associated with a set of candidate labels, among which only one is\ncorrect. The key to deal with such problem is to disambiguate the candidate\nlabel sets and obtain the correct assignments between instances and their\ncandidate labels. In this paper, we interpret such assignments as\ninstance-to-label matchings, and reformulate the task of PLL as a matching\nselection problem. To model such problem, we propose a novel Graph Matching\nbased Partial Label Learning (GM-PLL) framework, where Graph Matching (GM)\nscheme is incorporated owing to its excellent capability of exploiting the\ninstance and label relationship. Meanwhile, since conventional one-to-one GM\nalgorithm does not satisfy the constraint of PLL problem that multiple\ninstances may correspond to the same label, we extend a traditional one-to-one\nprobabilistic matching algorithm to the many-to-one constraint, and make the\nproposed framework accommodate to the PLL problem. Moreover, we also propose a\nrelaxed matching prediction model, which can improve the prediction accuracy\nvia GM strategy. Extensive experiments on both artificial and real-world data\nsets demonstrate that the proposed method can achieve superior or comparable\nperformance against the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 09:38:56 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Lyu", "Gengyu", ""], ["Feng", "Songhe", ""], ["Wang", "Tao", ""], ["Lang", "Congyan", ""], ["Li", "Yidong", ""]]}, {"id": "1901.03091", "submitter": "Andrea Pizzoferrato", "authors": "Mihai Cucuringu, Andrea Pizzoferrato and Yves van Gennip", "title": "An MBO scheme for clustering and semi-supervised clustering of signed\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a principled method for the signed clustering problem, where the\ngoal is to partition a graph whose edge weights take both positive and negative\nvalues, such that edges within the same cluster are mostly positive, while\nedges spanning across clusters are mostly negative. Our method relies on a\ngraph-based diffuse interface model formulation utilizing the Ginzburg-Landau\nfunctional, based on an adaptation of the classic numerical\nMerriman-Bence-Osher (MBO) scheme for minimizing such graph-based functionals.\nThe proposed objective function aims to minimize the total weight of\ninter-cluster positively-weighted edges, while maximizing the total weight of\nthe inter-cluster negatively-weighted edges. Our method scales to large sparse\nnetworks, and can be easily adjusted to incorporate labelled data information,\nas is often the case in the context of semi-supervised learning. We tested our\nmethod on a number of both synthetic stochastic block models and real-world\ndata sets (including financial correlation matrices), and obtained promising\nresults that compare favourably against a number of state-of-the-art approaches\nfrom the recent literature.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 10:46:40 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 16:00:38 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 17:32:19 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 09:10:09 GMT"}, {"version": "v5", "created": "Wed, 9 Oct 2019 15:40:59 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Pizzoferrato", "Andrea", ""], ["van Gennip", "Yves", ""]]}, {"id": "1901.03124", "submitter": "Patrick Schlachter", "authors": "Patrick Schlachter and Bin Yang", "title": "Active Learning for One-Class Classification Using Two One-Class\n  Classifiers", "comments": "EUSIPCO 2018", "journal-ref": null, "doi": "10.23919/EUSIPCO.2018.8552958", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel, generic active learning method for one-class\nclassification. Active learning methods play an important role to reduce the\nefforts of manual labeling in the field of machine learning. Although many\nactive learning approaches have been proposed during the last years, most of\nthem are restricted on binary or multi-class problems. One-class classifiers\nuse samples from only one class, the so-called target class, during training\nand hence require special active learning strategies. The few strategies\nproposed for one-class classification either suffer from their limitation on\nspecific one-class classifiers or their performance depends on particular\nassumptions about datasets like imbalance. Our proposed method bases on using\ntwo one-class classifiers, one for the desired target class and one for the\nso-called outlier class. It allows to invent new query strategies, to use\nbinary query strategies and to define simple stopping criteria. Based on the\nnew method, two query strategies are proposed. The provided experiments compare\nthe proposed approach with known strategies on various datasets and show\nimproved results in almost all situations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 12:36:25 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Schlachter", "Patrick", ""], ["Yang", "Bin", ""]]}, {"id": "1901.03134", "submitter": "Christian Agrell", "authors": "Christian Agrell", "title": "Gaussian processes with linear operator inequality constraints", "comments": "Published in JMLR: http://jmlr.org/papers/volume20/19-065/19-065.pdf", "journal-ref": "Journal of Machine Learning Research (JMLR), 20(135):1--36, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for constrained Gaussian Process (GP)\nregression where we assume that a set of linear transformations of the process\nare bounded. It is motivated by machine learning applications for\nhigh-consequence engineering systems, where this kind of information is often\nmade available from phenomenological knowledge. We consider a GP $f$ over\nfunctions on $\\mathcal{X} \\subset \\mathbb{R}^{n}$ taking values in\n$\\mathbb{R}$, where the process $\\mathcal{L}f$ is still Gaussian when\n$\\mathcal{L}$ is a linear operator. Our goal is to model $f$ under the\nconstraint that realizations of $\\mathcal{L}f$ are confined to a convex set of\nfunctions. In particular, we require that $a \\leq \\mathcal{L}f \\leq b$, given\ntwo functions $a$ and $b$ where $a < b$ pointwise. This formulation provides a\nconsistent way of encoding multiple linear constraints, such as\nshape-constraints based on e.g. boundedness, monotonicity or convexity. We\nadopt the approach of using a sufficiently dense set of virtual observation\nlocations where the constraint is required to hold, and derive the exact\nposterior for a conjugate likelihood. The results needed for stable numerical\nimplementation are derived, together with an efficient sampling scheme for\nestimating the posterior process.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 12:58:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 18:38:25 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Agrell", "Christian", ""]]}, {"id": "1901.03161", "submitter": "Arda Aytekin", "authors": "Arda Aytekin and Mikael Johansson", "title": "Harnessing the Power of Serverless Runtimes for Large-Scale Optimization", "comments": "9 pages, double column, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The event-driven and elastic nature of serverless runtimes makes them a very\nefficient and cost-effective alternative for scaling up computations. So far,\nthey have mostly been used for stateless, data parallel and ephemeral\ncomputations. In this work, we propose using serverless runtimes to solve\ngeneric, large-scale optimization problems. Specifically, we build a\nmaster-worker setup using AWS Lambda as the source of our workers, implement a\nparallel optimization algorithm to solve a regularized logistic regression\nproblem, and show that relative speedups up to 256 workers and efficiencies\nabove 70% up to 64 workers can be expected. We also identify possible\nalgorithmic and system-level bottlenecks, propose improvements, and discuss the\nlimitations and challenges in realizing these improvements.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:57:06 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Aytekin", "Arda", ""], ["Johansson", "Mikael", ""]]}, {"id": "1901.03162", "submitter": "Artemij Amiranashvili", "authors": "Artemij Amiranashvili, Alexey Dosovitskiy, Vladlen Koltun, Thomas Brox", "title": "Motion Perception in Reinforcement Learning with Dynamic Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dynamic environments, learned controllers are supposed to take motion into\naccount when selecting the action to be taken. However, in existing\nreinforcement learning works motion is rarely treated explicitly; it is rather\nassumed that the controller learns the necessary motion representation from\ntemporal stacks of frames implicitly. In this paper, we show that for\ncontinuous control tasks learning an explicit representation of motion improves\nthe quality of the learned controller in dynamic scenarios. We demonstrate this\non common benchmark tasks (Walker, Swimmer, Hopper), on target reaching and\nball catching tasks with simulated robotic arms, and on a dynamic single ball\njuggling task. Moreover, we find that when equipped with an appropriate network\narchitecture, the agent can, on some tasks, learn motion features also with\npure reinforcement learning, without additional supervision. Further we find\nthat using an image difference between the current and the previous frame as an\nadditional input leads to better results than a temporal stack of frames.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:59:19 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 15:30:32 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Amiranashvili", "Artemij", ""], ["Dosovitskiy", "Alexey", ""], ["Koltun", "Vladlen", ""], ["Brox", "Thomas", ""]]}, {"id": "1901.03209", "submitter": "Jiayun Dong", "authors": "Jiayun Dong and Cynthia Rudin", "title": "Variable Importance Clouds: A Way to Explore Variable Importance for the\n  Set of Good Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable importance is central to scientific studies, including the social\nsciences and causal inference, healthcare, and other domains. However, current\nnotions of variable importance are often tied to a specific predictive model.\nThis is problematic: what if there were multiple well-performing predictive\nmodels, and a specific variable is important to some of them and not to others?\nIn that case, we may not be able to tell from a single well-performing model\nwhether a variable is always important in predicting the outcome. Rather than\ndepending on variable importance for a single predictive model, we would like\nto explore variable importance for all approximately-equally-accurate\npredictive models. This work introduces the concept of a variable importance\ncloud, which maps every variable to its importance for every good predictive\nmodel. We show properties of the variable importance cloud and draw connections\nto other areas of statistics. We introduce variable importance diagrams as a\nprojection of the variable importance cloud into two dimensions for\nvisualization purposes. Experiments with criminal justice, marketing data, and\nimage classification tasks illustrate how variables can change dramatically in\nimportance for approximately-equally-accurate predictive models\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 15:06:11 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 00:58:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dong", "Jiayun", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1901.03214", "submitter": "Llu\\'is Antoni Jim\\'enez Rugama", "authors": "Giuseppe Nuti, Llu\\'is Antoni Jim\\'enez Rugama and Andreea-Ingrid\n  Cross", "title": "A Bayesian Decision Tree Algorithm", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Decision Trees are known for their probabilistic interpretability.\nHowever, their construction can sometimes be costly. In this article we present\na general Bayesian Decision Tree algorithm applicable to both regression and\nclassification problems. The algorithm does not apply Markov Chain Monte Carlo\nand does not require a pruning step. While it is possible to construct a\nweighted probability tree space we find that one particular tree, the\ngreedy-modal tree (GMT), explains most of the information contained in the\nnumerical examples. This approach seems to perform similarly to Random Forests.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 15:20:54 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 18:37:55 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 12:19:26 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Nuti", "Giuseppe", ""], ["Rugama", "Llu\u00eds Antoni Jim\u00e9nez", ""], ["Cross", "Andreea-Ingrid", ""]]}, {"id": "1901.03227", "submitter": "Raif Rustamov", "authors": "Raif M. Rustamov", "title": "Closed-form Expressions for Maximum Mean Discrepancy with Applications\n  to Wasserstein Auto-Encoders", "comments": "Main paper is considerably shortened by moving some of the material\n  into Appendix", "journal-ref": null, "doi": null, "report-no": "TD:102449/2018-11-27", "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximum Mean Discrepancy (MMD) has found numerous applications in\nstatistics and machine learning, most recently as a penalty in the Wasserstein\nAuto-Encoder (WAE). In this paper we compute closed-form expressions for\nestimating the Gaussian kernel based MMD between a given distribution and the\nstandard multivariate normal distribution. This formula reveals a connection to\nthe Baringhaus-Henze-Epps-Pulley (BHEP) statistic of the Henze-Zirkler test and\nprovides further insights about the MMD. We introduce the standardized version\nof MMD as a penalty for the WAE training objective, allowing for a better\ninterpretability of MMD values and more compatibility across different\nhyperparameter settings. Next, we propose using a version of batch\nnormalization at the code layer; this has the benefits of making the kernel\nwidth selection easier, reducing the training effort, and preventing outliers\nin the aggregate code distribution. Our experiments on synthetic and real data\nshow that the analytic formulation improves over the commonly used stochastic\napproximation of the MMD, and demonstrate that code normalization provides\nsignificant benefits when training WAEs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 15:43:58 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:53:22 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Rustamov", "Raif M.", ""]]}, {"id": "1901.03295", "submitter": "Deepta Rajan", "authors": "Deepta Rajan, David Beymer, Girish Narayan", "title": "Generalization Studies of Neural Network Models for Cardiac Disease\n  Detection Using Limited Channel ECG", "comments": "IEEE Computing in Cardiology (CinC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acceleration of machine learning research in healthcare is challenged by lack\nof large annotated and balanced datasets. Furthermore, dealing with measurement\ninaccuracies and exploiting unsupervised data are considered to be central to\nimproving existing solutions. In particular, a primary objective in predictive\nmodeling is to generalize well to both unseen variations within the observed\nclasses, and unseen classes. In this work, we consider such a challenging\nproblem in machine learning driven diagnosis: detecting a gamut of\ncardiovascular conditions (e.g. infarction, dysrhythmia etc.) from limited\nchannel ECG measurements. Though deep neural networks have achieved\nunprecedented success in predictive modeling, they rely solely on\ndiscriminative models that can generalize poorly to unseen classes. We argue\nthat unsupervised learning can be utilized to construct effective latent spaces\nthat facilitate better generalization. This work extensively compares the\ngeneralization of our proposed approach against a state-of-the-art deep\nlearning solution. Our results show significant improvements in F1-scores.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 02:17:01 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Rajan", "Deepta", ""], ["Beymer", "David", ""], ["Narayan", "Girish", ""]]}, {"id": "1901.03299", "submitter": "Nitzan Shalom Artzi", "authors": "Nitzan S. Artzi, Oren Shriki", "title": "An Analysis of the Accuracy of the P300 BCI", "comments": null, "journal-ref": null, "doi": "10.1080/2326263X.2018.1552357", "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P300 Brain-Computer Interface (BCI) is a well-established communication\nchannel for severely disabled people. The P300 event-related potential is\nmostly characterized by its amplitude or its area, which correlate with the\nspelling accuracy of the P300 speller. Here, we introduce a novel approach for\nestimating the efficiency of this BCI by considering the P300 signal-to-noise\nratio (SNR), a parameter that estimates the spatial and temporal noise levels\nand has a significantly stronger correlation with spelling accuracy.\nFurthermore, we suggest a Gaussian noise model, which utilizes the P300\nevent-related potential SNR to predict spelling accuracy under various\nconditions for LDA-based classification. We demonstrate the utility of this\nanalysis using real data and discuss its potential applications, such as\nspeeding up the process of electrode selection.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 11:34:11 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Artzi", "Nitzan S.", ""], ["Shriki", "Oren", ""]]}, {"id": "1901.03317", "submitter": "Amirhossein Taghvaei", "authors": "Amirhossein Taghvaei, Prashant G. Mehta", "title": "Accelerated Flow for Probability Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology and numerical algorithms for constructing\naccelerated gradient flows on the space of probability distributions. In\nparticular, we extend the recent variational formulation of accelerated\ngradient methods in (wibisono, et. al. 2016) from vector valued variables to\nprobability distributions. The variational problem is modeled as a mean-field\noptimal control problem. The maximum principle of optimal control theory is\nused to derive Hamilton's equations for the optimal gradient flow. The\nHamilton's equation are shown to achieve the accelerated form of density\ntransport from any initial probability distribution to a target probability\ndistribution. A quantitative estimate on the asymptotic convergence rate is\nprovided based on a Lyapunov function construction, when the objective\nfunctional is displacement convex. Two numerical approximations are presented\nto implement the Hamilton's equations as a system of $N$ interacting particles.\nThe continuous limit of the Nesterov's algorithm is shown to be a special case\nwith $N=1$. The algorithm is illustrated with numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 18:42:38 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 02:03:30 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Taghvaei", "Amirhossein", ""], ["Mehta", "Prashant G.", ""]]}, {"id": "1901.03326", "submitter": "Rahman Attar", "authors": "Rahman Attar, Marco Pereanez, Ali Gooya, Xenia Alba, Le Zhang, Stefan\n  K. Piechnik, Stefan Neubauer, Steffen E. Petersen, Alejandro F. Frangi", "title": "High Throughput Computation of Reference Ranges of Biventricular Cardiac\n  Function on the UK Biobank Population Cohort", "comments": "Accepted in STACOM workshop of MICCAI2018", "journal-ref": null, "doi": null, "report-no": "LNCS volume number: 11395", "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploitation of large-scale population data has the potential to improve\nhealthcare by discovering and understanding patterns and trends within this\ndata. To enable high throughput analysis of cardiac imaging data automatically,\na pipeline should comprise quality monitoring of the input images, segmentation\nof the cardiac structures, assessment of the segmentation quality, and parsing\nof cardiac functional indexes. We present a fully automatic, high throughput\nimage parsing workflow for the analysis of cardiac MR images, and test its\nperformance on the UK Biobank (UKB) cardiac dataset. The proposed pipeline is\ncapable of performing end-to-end image processing including: data organisation,\nimage quality assessment, shape model initialisation, segmentation,\nsegmentation quality assessment, and functional parameter computation; all\nwithout any user interaction. To the best of our knowledge,this is the first\npaper tackling the fully automatic 3D analysis of the UKB population study,\nproviding reference ranges for all key cardiovascular functional indexes, from\nboth left and right ventricles of the heart. We tested our workflow on a\nreference cohort of 800 healthy subjects for which manual delineations, and\nreference functional indexes exist. Our results show statistically significant\nagreement between the manually obtained reference indexes, and those\nautomatically computed using our framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 12:35:50 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Attar", "Rahman", ""], ["Pereanez", "Marco", ""], ["Gooya", "Ali", ""], ["Alba", "Xenia", ""], ["Zhang", "Le", ""], ["Piechnik", "Stefan K.", ""], ["Neubauer", "Stefan", ""], ["Petersen", "Steffen E.", ""], ["Frangi", "Alejandro F.", ""]]}, {"id": "1901.03327", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Fernando Bello, Saeid Nahavandi", "title": "A New Tensioning Method using Deep Reinforcement Learning for Surgical\n  Pattern Cutting", "comments": "2019 IEEE International Conference on Industrial Technology (ICIT),\n  Melbourne, Australia (to appear)", "journal-ref": "2019 IEEE International Conference on Industrial Technology (ICIT)", "doi": "10.1109/ICIT.2019.8755235", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgeons normally need surgical scissors and tissue grippers to cut through a\ndeformable surgical tissue. The cutting accuracy depends on the skills to\nmanipulate these two tools. Such skills are part of basic surgical skills\ntraining as in the Fundamentals of Laparoscopic Surgery. The gripper is used to\npinch a point on the surgical sheet and pull the tissue to a certain direction\nto maintain the tension while the scissors cut through a trajectory. As the\nsurgical materials are deformable, it requires a comprehensive tensioning\npolicy to yield appropriate tensioning direction at each step of the cutting\nprocess. Automating a tensioning policy for a given cutting trajectory will\nsupport not only the human surgeons but also the surgical robots to improve the\ncutting accuracy and reliability. This paper presents a multiple pinch point\napproach to modelling an autonomous tensioning planner based on a deep\nreinforcement learning algorithm. Experiments on a simulator show that the\nproposed method is superior to existing methods in terms of both performance\nand robustness.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:30:46 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Bello", "Fernando", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "1901.03357", "submitter": "Felix Berkenkamp", "authors": "Felix Berkenkamp, Angela P. Schoellig, Andreas Krause", "title": "No-Regret Bayesian Optimization with Unknown Hyperparameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) based on Gaussian process models is a powerful\nparadigm to optimize black-box functions that are expensive to evaluate. While\nseveral BO algorithms provably converge to the global optimum of the unknown\nfunction, they assume that the hyperparameters of the kernel are known in\nadvance. This is not the case in practice and misspecification often causes\nthese algorithms to converge to poor local optima. In this paper, we present\nthe first BO algorithm that is provably no-regret and converges to the optimum\nwithout knowledge of the hyperparameters. During optimization we slowly adapt\nthe hyperparameters of stationary kernels and thereby expand the associated\nfunction class over time, so that the BO algorithm considers more complex\nfunction candidates. Based on the theoretical insights, we propose several\npractical algorithms that achieve the empirical sample efficiency of BO with\nonline hyperparameter estimation, but retain theoretical convergence\nguarantees. We evaluate our method on several benchmark problems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 19:50:12 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 20:33:48 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Berkenkamp", "Felix", ""], ["Schoellig", "Angela P.", ""], ["Krause", "Andreas", ""]]}, {"id": "1901.03396", "submitter": "Ryan Webster", "authors": "Ryan Webster, Julien Rabin, Loic Simon, Frederic Jurie", "title": "Detecting Overfitting of Deep Generative Networks via Latent Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State of the art deep generative networks are capable of producing images\nwith such incredible realism that they can be suspected of memorizing training\nimages. It is why it is not uncommon to include visualizations of training set\nnearest neighbors, to suggest generated images are not simply memorized. We\ndemonstrate this is not sufficient and motivates the need to study\nmemorization/overfitting of deep generators with more scrutiny. This paper\naddresses this question by i) showing how simple losses are highly effective at\nreconstructing images for deep generators ii) analyzing the statistics of\nreconstruction errors when reconstructing training and validation images, which\nis the standard way to analyze overfitting in machine learning. Using this\nmethodology, this paper shows that overfitting is not detectable in the pure\nGAN models proposed in the literature, in contrast with those using hybrid\nadversarial losses, which are amongst the most widely applied generative\nmethods. The paper also shows that standard GAN evaluation metrics fail to\ncapture memorization for some deep generators. Finally, the paper also shows\nhow off-the-shelf GAN generators can be successfully applied to face inpainting\nand face super-resolution using the proposed reconstruction method, without\nhybrid adversarial losses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 16:29:05 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Webster", "Ryan", ""], ["Rabin", "Julien", ""], ["Simon", "Loic", ""], ["Jurie", "Frederic", ""]]}, {"id": "1901.03403", "submitter": "Alon Kipnis", "authors": "Alon Kipnis, John C. Duchi", "title": "Mean Estimation from One-Bit Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the mean of a symmetric log-concave\ndistribution under the constraint that only a single bit per sample from this\ndistribution is available to the estimator. We study the mean squared error as\na function of the sample size (and hence the number of bits). We consider three\nsettings: first, a centralized setting, where an encoder may release $n$ bits\ngiven a sample of size $n$, and for which there is no asymptotic penalty for\nquantization; second, an adaptive setting in which each bit is a function of\nthe current observation and previously recorded bits, where we show that the\noptimal relative efficiency compared to the sample mean is precisely the\nefficiency of the median; lastly, we show that in a distributed setting where\neach bit is only a function of a local sample, no estimator can achieve optimal\nefficiency uniformly over the parameter space. We additionally complement our\nresults in the adaptive setting by showing that \\emph{one} round of adaptivity\nis sufficient to achieve optimal mean-square error.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 21:31:57 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 16:05:46 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 19:25:30 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Kipnis", "Alon", ""], ["Duchi", "John C.", ""]]}, {"id": "1901.03407", "submitter": "Raghav Chalapathy", "authors": "Raghavendra Chalapathy (University of Sydney and Capital Markets\n  Cooperative Research Centre (CMCRC)), Sanjay Chawla (Qatar Computing Research\n  Institute (QCRI), HBKU)", "title": "Deep Learning for Anomaly Detection: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is an important problem that has been well-studied within\ndiverse research areas and application domains. The aim of this survey is\ntwo-fold, firstly we present a structured and comprehensive overview of\nresearch methods in deep learning-based anomaly detection. Furthermore, we\nreview the adoption of these methods for anomaly across various application\ndomains and assess their effectiveness. We have grouped state-of-the-art\nresearch techniques into different categories based on the underlying\nassumptions and approach adopted. Within each category we outline the basic\nanomaly detection technique, along with its variants and present key\nassumptions, to differentiate between normal and anomalous behavior. For each\ncategory, we present we also present the advantages and limitations and discuss\nthe computational complexity of the techniques in real application domains.\nFinally, we outline open issues in research and challenges faced while adopting\nthese techniques.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 21:36:57 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 06:26:15 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Chalapathy", "Raghavendra", "", "University of Sydney and Capital Markets\n  Cooperative Research Centre"], ["Chawla", "Sanjay", "", "Qatar Computing Research\n  Institute"]]}, {"id": "1901.03415", "submitter": "Yun Zeng", "authors": "Yun Zeng", "title": "Context Aware Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a principle for exploring context in machine learning models.\nStarting with a simple assumption that each observation may or may not depend\non its context, a conditional probability distribution is decomposed into two\nparts: context-free and context-sensitive. Then by employing the log-linear\nword production model for relating random variables to their embedding space\nrepresentation and making use of the convexity of natural exponential function,\nwe show that the embedding of an observation can also be decomposed into a\nweighted sum of two vectors, representing its context-free and\ncontext-sensitive parts, respectively. This simple treatment of context\nprovides a unified view of many existing deep learning models, leading to\nrevisions of these models able to achieve significant performance boost.\nSpecifically, our upgraded version of a recent sentence embedding model not\nonly outperforms the original one by a large margin, but also leads to a new,\nprincipled approach for compositing the embeddings of bag-of-words features, as\nwell as a new architecture for modeling attention in deep neural networks. More\nsurprisingly, our new principle provides a novel understanding of the gates and\nequations defined by the long short term memory model, which also leads to a\nnew model that is able to converge significantly faster and achieve much lower\nprediction errors. Furthermore, our principle also inspires a new type of\ngeneric neural network layer that better resembles real biological neurons than\nthe traditional linear mapping plus nonlinear activation based architecture.\nIts multi-layer extension provides a new principle for deep neural networks\nwhich subsumes residual network (ResNet) as its special case, and its extension\nto convolutional neutral network model accounts for irrelevant input (e.g.,\nbackground in an image) in addition to filtering.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 22:12:24 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 17:26:23 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zeng", "Yun", ""]]}, {"id": "1901.03416", "submitter": "Ali Razavi", "authors": "Ali Razavi, A\\\"aron van den Oord, Ben Poole, Oriol Vinyals", "title": "Preventing Posterior Collapse with delta-VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the phenomenon of \"posterior collapse,\" current latent variable\ngenerative models pose a challenging design choice that either weakens the\ncapacity of the decoder or requires augmenting the objective so it does not\nonly maximize the likelihood of the data. In this paper, we propose an\nalternative that utilizes the most powerful generative models as decoders,\nwhilst optimising the variational lower bound all while ensuring that the\nlatent variables preserve and encode useful information. Our proposed\n$\\delta$-VAEs achieve this by constraining the variational family for the\nposterior to have a minimum distance to the prior. For sequential latent\nvariable models, our approach resembles the classic representation learning\napproach of slow feature analysis. We demonstrate the efficacy of our approach\nat modeling text on LM1B and modeling images: learning representations,\nimproving sample quality, and achieving state of the art log-likelihood on\nCIFAR-10 and ImageNet $32\\times 32$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 22:13:15 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Razavi", "Ali", ""], ["Oord", "A\u00e4ron van den", ""], ["Poole", "Ben", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1901.03429", "submitter": "Jorge P\\'erez", "authors": "Jorge P\\'erez, Javier Marinkovi\\'c, Pablo Barcel\\'o", "title": "On the Turing Completeness of Modern Neural Network Architectures", "comments": "ICLR2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternatives to recurrent neural networks, in particular, architectures based\non attention or convolutions, have been gaining momentum for processing input\nsequences. In spite of their relevance, the computational properties of these\nalternatives have not yet been fully explored. We study the computational power\nof two of the most paradigmatic architectures exemplifying these mechanisms:\nthe Transformer (Vaswani et al., 2017) and the Neural GPU (Kaiser & Sutskever,\n2016). We show both models to be Turing complete exclusively based on their\ncapacity to compute and access internal dense representations of the data. In\nparticular, neither the Transformer nor the Neural GPU requires access to an\nexternal memory to become Turing complete. Our study also reveals some minimal\nsets of elements needed to obtain these completeness results.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 23:21:35 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["P\u00e9rez", "Jorge", ""], ["Marinkovi\u0107", "Javier", ""], ["Barcel\u00f3", "Pablo", ""]]}, {"id": "1901.03440", "submitter": "Arash Vahdat", "authors": "Arash Vahdat, Evgeny Andriyash, William G. Macready", "title": "Undirected Graphical Models as Approximate Posteriors", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of the approximate posterior is a critical aspect of\neffective variational autoencoders (VAEs). Poor choices for the approximate\nposterior have a detrimental impact on the generative performance of VAEs due\nto the mismatch with the true posterior. We extend the class of posterior\nmodels that may be learned by using undirected graphical models. We develop an\nefficient method to train undirected approximate posteriors by showing that the\ngradient of the training objective with respect to the parameters of the\nundirected posterior can be computed by backpropagation through Markov chain\nMonte Carlo updates. We apply these gradient estimators for training discrete\nVAEs with Boltzmann machines as approximate posteriors and demonstrate that\nundirected models outperform previous results obtained using directed graphical\nmodels. Our implementation is available at https://github.com/QuadrantAI/dvaess .\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 00:32:21 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 16:02:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Vahdat", "Arash", ""], ["Andriyash", "Evgeny", ""], ["Macready", "William G.", ""]]}, {"id": "1901.03478", "submitter": "Ruimeng Hu", "authors": "Ruimeng Hu", "title": "Deep Learning for Ranking Response Surfaces with Applications to Optimal\n  Stopping Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose deep learning algorithms for ranking response\nsurfaces, with applications to optimal stopping problems in financial\nmathematics. The problem of ranking response surfaces is motivated by\nestimating optimal feedback policy maps in stochastic control problems, aiming\nto efficiently find the index associated to the minimal response across the\nentire continuous input space $\\mathcal{X} \\subseteq \\mathbb{R}^d$. By\nconsidering points in $\\mathcal{X}$ as pixels and indices of the minimal\nsurfaces as labels, we recast the problem as an image segmentation problem,\nwhich assigns a label to every pixel in an image such that pixels with the same\nlabel share certain characteristics. This provides an alternative method for\nefficiently solving the problem instead of using sequential design in our\nprevious work [R. Hu and M. Ludkovski, SIAM/ASA Journal on Uncertainty\nQuantification, 5 (2017), 212--239].\n  Deep learning algorithms are scalable, parallel and model-free, i.e., no\nparametric assumptions needed on the response surfaces. Considering ranking\nresponse surfaces as image segmentation allows one to use a broad class of deep\nneural networks, e.g., UNet, SegNet, DeconvNet, which have been widely applied\nand numerically proved to possess high accuracy in the field. We also\nsystematically study the dependence of deep learning algorithms on the input\ndata generated on uniform grids or by sequential design sampling, and observe\nthat the performance of deep learning is {\\it not} sensitive to the noise and\nlocations (close to/away from boundaries) of training data. We present a few\nexamples including synthetic ones and the Bermudan option pricing problem to\nshow the efficiency and accuracy of this method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 04:51:54 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:35:14 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Hu", "Ruimeng", ""]]}, {"id": "1901.03517", "submitter": "Razvan Marinescu", "authors": "Razvan V. Marinescu, Marco Lorenzi, Stefano B. Blumberg, Alexandra L.\n  Young, Pere P. Morell, Neil P. Oxtoby, Arman Eshaghi, Keir X. Yong, Sebastian\n  J. Crutch, Polina Golland, Daniel C. Alexander (for the Alzheimer's Disease\n  Neuroimaging Initiative)", "title": "Disease Knowledge Transfer across Neurodegenerative Diseases", "comments": "accepted at MICCAI 2019, 13 pages, 5 figures, 2 tables", "journal-ref": "Medical Image Computing and Computer Assisted Intervention 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Disease Knowledge Transfer (DKT), a novel technique for\ntransferring biomarker information between related neurodegenerative diseases.\nDKT infers robust multimodal biomarker trajectories in rare neurodegenerative\ndiseases even when only limited, unimodal data is available, by transferring\ninformation from larger multimodal datasets from common neurodegenerative\ndiseases. DKT is a joint-disease generative model of biomarker progressions,\nwhich exploits biomarker relationships that are shared across diseases. Our\nproposed method allows, for the first time, the estimation of plausible,\nmultimodal biomarker trajectories in Posterior Cortical Atrophy (PCA), a rare\nneurodegenerative disease where only unimodal MRI data is available. For this\nwe train DKT on a combined dataset containing subjects with two distinct\ndiseases and sizes of data available: 1) a larger, multimodal typical AD (tAD)\ndataset from the TADPOLE Challenge, and 2) a smaller unimodal Posterior\nCortical Atrophy (PCA) dataset from the Dementia Research Centre (DRC), for\nwhich only a limited number of Magnetic Resonance Imaging (MRI) scans are\navailable. Although validation is challenging due to lack of data in PCA, we\nvalidate DKT on synthetic data and two patient datasets (TADPOLE and PCA\ncohorts), showing it can estimate the ground truth parameters in the simulation\nand predict unseen biomarkers on the two patient datasets. While we\ndemonstrated DKT on Alzheimer's variants, we note DKT is generalisable to other\nforms of related neurodegenerative diseases. Source code for DKT is available\nonline: https://github.com/mrazvan22/dkt.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 09:11:27 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 14:25:07 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Marinescu", "Razvan V.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Lorenzi", "Marco", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Blumberg", "Stefano B.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Young", "Alexandra L.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Morell", "Pere P.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Oxtoby", "Neil P.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Eshaghi", "Arman", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Yong", "Keir X.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Crutch", "Sebastian J.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Golland", "Polina", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Alexander", "Daniel C.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"]]}, {"id": "1901.03553", "submitter": "Razvan Marinescu", "authors": "Razvan V. Marinescu, Arman Eshaghi, Marco Lorenzi, Alexandra L. Young,\n  Neil P. Oxtoby, Sara Garbarino, Sebastian J. Crutch, Daniel C. Alexander (for\n  the Alzheimer's Disease Neuroimaging Initiative)", "title": "DIVE: A spatiotemporal progression model of brain pathology in\n  neurodegenerative disorders", "comments": "24 pages, 5 figures, 2 tables, 1 algorithm", "journal-ref": "NeuroImage, Volume 192, 15 May 2019, Pages 166-177", "doi": "10.1016/j.neuroimage.2019.02.053", "report-no": null, "categories": "cs.CV cs.LG q-bio.NC q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here we present DIVE: Data-driven Inference of Vertexwise Evolution. DIVE is\nan image-based disease progression model with single-vertex resolution,\ndesigned to reconstruct long-term patterns of brain pathology from short-term\nlongitudinal data sets. DIVE clusters vertex-wise biomarker measurements on the\ncortical surface that have similar temporal dynamics across a patient\npopulation, and concurrently estimates an average trajectory of vertex\nmeasurements in each cluster. DIVE uniquely outputs a parcellation of the\ncortex into areas with common progression patterns, leading to a new signature\nfor individual diseases. DIVE further estimates the disease stage and\nprogression speed for every visit of every subject, potentially enhancing\nstratification for clinical trials or management. On simulated data, DIVE can\nrecover ground truth clusters and their underlying trajectory, provided the\naverage trajectories are sufficiently different between clusters. We\ndemonstrate DIVE on data from two cohorts: the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) and the Dementia Research Centre (DRC), UK, containing\npatients with Posterior Cortical Atrophy (PCA) as well as typical Alzheimer's\ndisease (tAD). DIVE finds similar spatial patterns of atrophy for tAD subjects\nin the two independent datasets (ADNI and DRC), and further reveals distinct\npatterns of pathology in different diseases (tAD vs PCA) and for distinct types\nof biomarker data: cortical thickness from Magnetic Resonance Imaging (MRI) vs\namyloid load from Positron Emission Tomography (PET). Finally, DIVE can be used\nto estimate a fine-grained spatial distribution of pathology in the brain using\nany kind of voxelwise or vertexwise measures including Jacobian compression\nmaps, fractional anisotropy (FA) maps from diffusion imaging or other PET\nmeasures. DIVE source code is available online:\nhttps://github.com/mrazvan22/dive\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 11:13:44 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Marinescu", "Razvan V.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Eshaghi", "Arman", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Lorenzi", "Marco", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Young", "Alexandra L.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Oxtoby", "Neil P.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Garbarino", "Sara", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Crutch", "Sebastian J.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Alexander", "Daniel C.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "1901.03559", "submitter": "Mehdi Mirza", "authors": "Arthur Guez, Mehdi Mirza, Karol Gregor, Rishabh Kabra, S\\'ebastien\n  Racani\\`ere, Th\\'eophane Weber, David Raposo, Adam Santoro, Laurent Orseau,\n  Tom Eccles, Greg Wayne, David Silver, Timothy Lillicrap", "title": "An investigation of model-free planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of reinforcement learning (RL) is facing increasingly challenging\ndomains with combinatorial complexity. For an RL agent to address these\nchallenges, it is essential that it can plan effectively. Prior work has\ntypically utilized an explicit model of the environment, combined with a\nspecific planning algorithm (such as tree search). More recently, a new family\nof methods have been proposed that learn how to plan, by providing the\nstructure for planning via an inductive bias in the function approximator (such\nas a tree structured neural network), trained end-to-end by a model-free RL\nalgorithm. In this paper, we go even further, and demonstrate empirically that\nan entirely model-free approach, without special structure beyond standard\nneural network components such as convolutional networks and LSTMs, can learn\nto exhibit many of the characteristics typically associated with a model-based\nplanner. We measure our agent's effectiveness at planning in terms of its\nability to generalize across a combinatorial and irreversible state space, its\ndata efficiency, and its ability to utilize additional thinking time. We find\nthat our agent has many of the characteristics that one might expect to find in\na planning algorithm. Furthermore, it exceeds the state-of-the-art in\nchallenging combinatorial domains such as Sokoban and outperforms other\nmodel-free approaches that utilize strong inductive biases toward planning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 11:42:51 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 12:39:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Guez", "Arthur", ""], ["Mirza", "Mehdi", ""], ["Gregor", "Karol", ""], ["Kabra", "Rishabh", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Weber", "Th\u00e9ophane", ""], ["Raposo", "David", ""], ["Santoro", "Adam", ""], ["Orseau", "Laurent", ""], ["Eccles", "Tom", ""], ["Wayne", "Greg", ""], ["Silver", "David", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1901.03611", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Yoshua Bengio", "title": "The Benefits of Over-parameterization at Initialization in Deep ReLU\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been noted in existing literature that over-parameterization in ReLU\nnetworks generally improves performance. While there could be several factors\ninvolved behind this, we prove some desirable theoretical properties at\ninitialization which may be enjoyed by ReLU networks. Specifically, it is known\nthat He initialization in deep ReLU networks asymptotically preserves variance\nof activations in the forward pass and variance of gradients in the backward\npass for infinitely wide networks, thus preserving the flow of information in\nboth directions. Our paper goes beyond these results and shows novel properties\nthat hold under He initialization: i) the norm of hidden activation of each\nlayer is equal to the norm of the input, and, ii) the norm of weight gradient\nof each layer is equal to the product of norm of the input vector and the error\nat output layer. These results are derived using the PAC analysis framework,\nand hold true for finitely sized datasets such that the width of the ReLU\nnetwork only needs to be larger than a certain finite lower bound. As we show,\nthis lower bound depends on the depth of the network and the number of samples,\nand by the virtue of being a lower bound, over-parameterized ReLU networks are\nendowed with these desirable properties. For the aforementioned hidden\nactivation norm property under He initialization, we further extend our theory\nand show that this property holds for a finite width network even when the\nnumber of data samples is infinite. Thus we overcome several limitations of\nexisting papers, and show new properties of deep ReLU networks at\ninitialization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 15:16:31 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 23:52:45 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 17:34:31 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Arpit", "Devansh", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1901.03634", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and Frank Nielsen", "title": "Variation Network: Learning High-level Attributes for Controlled Input\n  Manipulation", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Variation Network (VarNet), a generative model\nproviding means to manipulate the high-level attributes of a given input. The\noriginality of our approach is that VarNet is not only capable of handling\npre-defined attributes but can also learn the relevant attributes of the\ndataset by itself. These two settings can also be easily considered at the same\ntime, which makes this model applicable to a wide variety of tasks. Further,\nVarNet has a sound information-theoretic interpretation which grants us with\ninterpretable means to control how these high-level attributes are learned. We\ndemonstrate experimentally that this model is capable of performing interesting\ninput manipulation and that the learned attributes are relevant and meaningful.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 16:23:16 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 13:34:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Nielsen", "Frank", ""]]}, {"id": "1901.03660", "submitter": "Suayder Costa", "authors": "Suayder Milhomem, Tiago da Silva Almeida, Warley Gramacho da Silva,\n  Edeilson Milhomem da Silva and Rafael Lima de Carvalho", "title": "Weightless Neural Network with Transfer Learning to Detect Distress in\n  Asphalt", "comments": "6 pages, 5 figures, published on IJAERS", "journal-ref": "International Journal of Advanced Engineering Research and\n  Science, Page No: 294-299, vol.5,no. 12, date:2018", "doi": "10.22161/ijaers.5.12.40", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The present paper shows a solution to the problem of automatic distress\ndetection, more precisely the detection of holes in paved roads. To do so, the\nproposed solution uses a weightless neural network known as Wisard to decide\nwhether an image of a road has any kind of cracks. In addition, the proposed\narchitecture also shows how the use of transfer learning was able to improve\nthe overall accuracy of the decision system. As a verification step of the\nresearch, an experiment was carried out using images from the streets at the\nFederal University of Tocantins, Brazil. The architecture of the developed\nsolution presents a result of 85.71% accuracy in the dataset, proving to be\nsuperior to approaches of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 09:33:22 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Milhomem", "Suayder", ""], ["Almeida", "Tiago da Silva", ""], ["da Silva", "Warley Gramacho", ""], ["da Silva", "Edeilson Milhomem", ""], ["de Carvalho", "Rafael Lima", ""]]}, {"id": "1901.03662", "submitter": "Andrew Gilman", "authors": "Soren Bouma, Matthew D. M. Pawley, Krista Hupman and Andrew Gilman", "title": "Individual common dolphin identification via metric embedding learning", "comments": "Published in IVCNZ 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo-identification (photo-id) of dolphin individuals is a commonly used\ntechnique in ecological sciences to monitor state and health of individuals, as\nwell as to study the social structure and distribution of a population.\nTraditional photo-id involves a laborious manual process of matching each\ndolphin fin photograph captured in the field to a catalogue of known\nindividuals.\n  We examine this problem in the context of open-set recognition and utilise a\ntriplet loss function to learn a compact representation of fin images in a\nEuclidean embedding, where the Euclidean distance metric represents fin\nsimilarity. We show that this compact representation can be successfully learnt\nfrom a fairly small (in deep learning context) training set and still\ngeneralise well to out-of-sample identities (completely new dolphin\nindividuals), with top-1 and top-5 test set (37 individuals) accuracy of\n$90.5\\pm2$ and $93.6\\pm1$ percent. In the presence of 1200 distractors, top-1\naccuracy dropped by $12\\%$; however, top-5 accuracy saw only a $2.8\\%$ drop\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 02:29:20 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Bouma", "Soren", ""], ["Pawley", "Matthew D. M.", ""], ["Hupman", "Krista", ""], ["Gilman", "Andrew", ""]]}, {"id": "1901.03664", "submitter": "Maximilian Arnold", "authors": "Maximilian Arnold, Sebastian D\\\"orner, Sebastian Cammerer, Sarah Yan,\n  Jakob Hoydis, and Stephan ten Brink", "title": "Enabling FDD Massive MIMO through Deep Learning-based Channel Prediction", "comments": "Extended version of the conference paper submitted to SPAWC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle for widespread deployment of frequency division duplex\n(FDD)-based Massive multiple-input multiple-output (MIMO) communications is the\nlarge signaling overhead for reporting full downlink (DL) channel state\ninformation (CSI) back to the basestation (BS), in order to enable closed-loop\nprecoding. We completely remove this overhead by a deep-learning based channel\nextrapolation (or \"prediction\") approach and demonstrate that a neural network\n(NN) at the BS can infer the DL CSI centered around a frequency $f_\\text{DL}$\nby solely observing uplink (UL) CSI on a different, yet adjacent frequency band\naround $f_\\text{UL}$; no more pilot/reporting overhead is needed than with a\ngenuine time division duplex (TDD)-based system. The rationale is that\nscatterers and the large-scale propagation environment are sufficiently similar\nto allow a NN to learn about the physical connections and constraints between\ntwo neighboring frequency bands, and thus provide a well-operating system even\nwhen classic extrapolation methods, like the Wiener filter (used as a baseline\nfor comparison throughout) fails. We study its performance for various\nstate-of-the-art Massive MIMO channel models, and, even more so, evaluate the\nscheme using actual Massive MIMO channel measurements, rendering it to be\npractically feasible at negligible loss in spectral efficiency when compared to\na genuine TDD-based system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 20:26:39 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Arnold", "Maximilian", ""], ["D\u00f6rner", "Sebastian", ""], ["Cammerer", "Sebastian", ""], ["Yan", "Sarah", ""], ["Hoydis", "Jakob", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1901.03665", "submitter": "Ethan Harris", "authors": "Ethan Harris, Mahesan Niranjan, Jonathon Hare", "title": "A Biologically Inspired Visual Working Memory for Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to look multiple times through a series of pose-adjusted glimpses\nis fundamental to human vision. This critical faculty allows us to understand\nhighly complex visual scenes. Short term memory plays an integral role in\naggregating the information obtained from these glimpses and informing our\ninterpretation of the scene. Computational models have attempted to address\nglimpsing and visual attention but have failed to incorporate the notion of\nmemory. We introduce a novel, biologically inspired visual working memory\narchitecture that we term the Hebb-Rosenblatt memory. We subsequently introduce\na fully differentiable Short Term Attentive Working Memory model (STAWM) which\nuses transformational attention to learn a memory over each image it sees. The\nstate of our Hebb-Rosenblatt memory is embedded in STAWM as the weights space\nof a layer. By projecting different queries through this layer we can obtain\ngoal-oriented latent representations for tasks including classification and\nvisual reconstruction. Our model obtains highly competitive classification\nperformance on MNIST and CIFAR-10. As demonstrated through the CelebA dataset,\nto perform reconstruction the model learns to make a sequence of updates to a\ncanvas which constitute a parts-based representation. Classification with the\nself supervised representation obtained from MNIST is shown to be in line with\nthe state of the art models (none of which use a visual attention mechanism).\nFinally, we show that STAWM can be trained under the dual constraints of\nclassification and reconstruction to provide an interpretable visual sketchpad\nwhich helps open the 'black-box' of deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 09:12:56 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Harris", "Ethan", ""], ["Niranjan", "Mahesan", ""], ["Hare", "Jonathon", ""]]}, {"id": "1901.03674", "submitter": "Qi Cai", "authors": "Qi Cai, Mingyi Hong, Yongxin Chen and Zhaoran Wang", "title": "On the Global Convergence of Imitation Learning: A Case for Linear\n  Quadratic Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the global convergence of generative adversarial imitation learning\nfor linear quadratic regulators, which is posed as minimax optimization. To\naddress the challenges arising from non-convex-concave geometry, we analyze the\nalternating gradient algorithm and establish its Q-linear rate of convergence\nto a unique saddle point, which simultaneously recovers the globally optimal\npolicy and reward function. We hope our results may serve as a small step\ntowards understanding and taming the instability in imitation learning as well\nas in more general non-convex-concave alternating minimax optimization that\narises from reinforcement learning and generative adversarial learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 17:54:47 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Cai", "Qi", ""], ["Hong", "Mingyi", ""], ["Chen", "Yongxin", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1901.03678", "submitter": "Franz J. Kir\\'aly", "authors": "Viktor Kazakov and Franz J. Kir\\'aly", "title": "Machine Learning Automation Toolbox (MLaut)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present MLaut (Machine Learning AUtomation Toolbox) for the\npython data science ecosystem. MLaut automates large-scale evaluation and\nbenchmarking of machine learning algorithms on a large number of datasets.\nMLaut provides a high-level workflow interface to machine algorithm algorithms,\nimplements a local back-end to a database of dataset collections, trained\nalgorithms, and experimental results, and provides easy-to-use interfaces to\nthe scikit-learn and keras modelling libraries. Experiments are easy to set up\nwith default settings in a few lines of code, while remaining fully\ncustomizable to the level of hyper-parameter tuning, pipeline composition, or\ndeep learning architecture.\n  As a principal test case for MLaut, we conducted a large-scale supervised\nclassification study in order to benchmark the performance of a number of\nmachine learning algorithms - to our knowledge also the first larger-scale\nstudy on standard supervised learning data sets to include deep learning\nalgorithms. While corroborating a number of previous findings in literature, we\nfound (within the limitations of our study) that deep neural networks do not\nperform well on basic supervised learning, i.e., outside the more specialized,\nimage-, audio-, or text-based tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:06:05 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Kazakov", "Viktor", ""], ["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "1901.03704", "submitter": "Alejandro Molina", "authors": "Alejandro Molina, Antonio Vergari, Karl Stelzner, Robert Peharz,\n  Pranav Subramani, Nicola Di Mauro, Pascal Poupart, Kristian Kersting", "title": "SPFlow: An Easy and Extensible Library for Deep Probabilistic Learning\n  using Sum-Product Networks", "comments": "4 pages, 1 figure, code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SPFlow, an open-source Python library providing a simple\ninterface to inference, learning and manipulation routines for deep and\ntractable probabilistic models called Sum-Product Networks (SPNs). The library\nallows one to quickly create SPNs both from data and through a domain specific\nlanguage (DSL). It efficiently implements several probabilistic inference\nroutines like computing marginals, conditionals and (approximate) most probable\nexplanations (MPEs) along with sampling as well as utilities for serializing,\nplotting and structure statistics on an SPN. Moreover, many of the algorithms\nproposed in the literature to learn the structure and parameters of SPNs are\nreadily available in SPFlow. Furthermore, SPFlow is extremely extensible and\ncustomizable, allowing users to promptly distill new inference and learning\nroutines by injecting custom code into a lightweight functional-oriented API\nframework. This is achieved in SPFlow by keeping an internal Python\nrepresentation of the graph structure that also enables practical compilation\nof an SPN into a TensorFlow graph, C, CUDA or FPGA custom code, significantly\nspeeding-up computations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 14:34:59 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Molina", "Alejandro", ""], ["Vergari", "Antonio", ""], ["Stelzner", "Karl", ""], ["Peharz", "Robert", ""], ["Subramani", "Pranav", ""], ["Di Mauro", "Nicola", ""], ["Poupart", "Pascal", ""], ["Kersting", "Kristian", ""]]}, {"id": "1901.03707", "submitter": "Davis Gilton", "authors": "Davis Gilton, Greg Ongie, Rebecca Willett", "title": "Neumann Networks for Inverse Problems in Imaging", "comments": "Added further experiments, reorganized proof section, added further\n  references and supporting figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many challenging image processing tasks can be described by an ill-posed\nlinear inverse problem: deblurring, deconvolution, inpainting, compressed\nsensing, and superresolution all lie in this framework. Traditional inverse\nproblem solvers minimize a cost function consisting of a data-fit term, which\nmeasures how well an image matches the observations, and a regularizer, which\nreflects prior knowledge and promotes images with desirable properties like\nsmoothness. Recent advances in machine learning and image processing have\nillustrated that it is often possible to learn a regularizer from training data\nthat can outperform more traditional regularizers. We present an end-to-end,\ndata-driven method of solving inverse problems inspired by the Neumann series,\nwhich we call a Neumann network. Rather than unroll an iterative optimization\nalgorithm, we truncate a Neumann series which directly solves the linear\ninverse problem with a data-driven nonlinear regularizer. The Neumann network\narchitecture outperforms traditional inverse problem solution methods,\nmodel-free deep learning approaches, and state-of-the-art unrolled iterative\nmethods on standard datasets. Finally, when the images belong to a union of\nsubspaces and under appropriate assumptions on the forward model, we prove\nthere exists a Neumann network configuration that well-approximates the optimal\noracle estimator for the inverse problem and demonstrate empirically that the\ntrained Neumann network has the form predicted by theory.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 17:44:22 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 00:25:31 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Gilton", "Davis", ""], ["Ongie", "Greg", ""], ["Willett", "Rebecca", ""]]}, {"id": "1901.03719", "submitter": "Khashayar Khosravi", "authors": "Khashayar Khosravi, Greg Lewis, Vasilis Syrgkanis", "title": "Non-Parametric Inference Adaptive to Intrinsic Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-parametric estimation and inference of conditional moment\nmodels in high dimensions. We show that even when the dimension $D$ of the\nconditioning variable is larger than the sample size $n$, estimation and\ninference is feasible as long as the distribution of the conditioning variable\nhas small intrinsic dimension $d$, as measured by locally low doubling\nmeasures. Our estimation is based on a sub-sampled ensemble of the $k$-nearest\nneighbors ($k$-NN) $Z$-estimator. We show that if the intrinsic dimension of\nthe covariate distribution is equal to $d$, then the finite sample estimation\nerror of our estimator is of order $n^{-1/(d+2)}$ and our estimate is\n$n^{1/(d+2)}$-asymptotically normal, irrespective of $D$. The sub-sampling size\nrequired for achieving these results depends on the unknown intrinsic dimension\n$d$. We propose an adaptive data-driven approach for choosing this parameter\nand prove that it achieves the desired rates. We discuss extensions and\napplications to heterogeneous treatment effect estimation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 19:22:48 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 07:48:02 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 00:18:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Khosravi", "Khashayar", ""], ["Lewis", "Greg", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1901.03732", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "The statistical Minkowski distances: Closed-form formula for Gaussian\n  Mixture Models", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional Minkowski distances are induced by the corresponding\nMinkowski norms in real-valued vector spaces. In this work, we propose novel\nstatistical symmetric distances based on the Minkowski's inequality for\nprobability densities belonging to Lebesgue spaces. These statistical Minkowski\ndistances admit closed-form formula for Gaussian mixture models when\nparameterized by integer exponents. This result extends to arbitrary mixtures\nof exponential families with natural parameter spaces being cones: This\nincludes the binomial, the multinomial, the zero-centered Laplacian, the\nGaussian and the Wishart mixtures, among others. We also derive a Minkowski's\ndiversity index of a normalized weighted set of probability distributions from\nMinkowski's inequality.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 11:17:10 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 12:33:02 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1901.03749", "submitter": "Shilei Fu", "authors": "Shilei Fu, Feng Xu, Ya-Qiu Jin", "title": "Translating SAR to Optical Images for Assisted Interpretation", "comments": "4 pages, 5 figures, 2 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advantages of all-weather and all-day high-resolution imaging,\nSAR remote sensing images are much less viewed and used by general people\nbecause human vision is not adapted to microwave scattering phenomenon.\nHowever, expert interpreters can be trained by compare side-by-side SAR and\noptical images to learn the translation rules from SAR to optical. This paper\nattempts to develop machine intelligence that are trainable with large-volume\nco-registered SAR and optical images to translate SAR image to optical version\nfor assisted SAR interpretation. A novel reciprocal GAN scheme is proposed for\nthis translation task. It is trained and tested on both spaceborne GF-3 and\nairborne UAVSAR images. Comparisons and analyses are presented for datasets of\ndifferent resolutions and polarizations. Results show that the proposed\ntranslation network works well under many scenarios and it could potentially be\nused for assisted SAR interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 08:48:47 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Fu", "Shilei", ""], ["Xu", "Feng", ""], ["Jin", "Ya-Qiu", ""]]}, {"id": "1901.03768", "submitter": "Taejoon Byun", "authors": "Taejoon Byun, Vaibhav Sharma, Abhishek Vijayakumar, Sanjai Rayadurgam,\n  Darren Cofer", "title": "Input Prioritization for Testing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are increasingly being adopted for sensing and\ncontrol functions in a variety of safety and mission-critical systems such as\nself-driving cars, autonomous air vehicles, medical diagnostics, and industrial\nrobotics. Failures of such systems can lead to loss of life or property, which\nnecessitates stringent verification and validation for providing high\nassurance. Though formal verification approaches are being investigated,\ntesting remains the primary technique for assessing the dependability of such\nsystems. Due to the nature of the tasks handled by DNNs, the cost of obtaining\ntest oracle data---the expected output, a.k.a. label, for a given input---is\nhigh, which significantly impacts the amount and quality of testing that can be\nperformed. Thus, prioritizing input data for testing DNNs in meaningful ways to\nreduce the cost of labeling can go a long way in increasing testing efficacy.\nThis paper proposes using gauges of the DNN's sentiment derived from the\ncomputation performed by the model, as a means to identify inputs that are\nlikely to reveal weaknesses. We empirically assessed the efficacy of three such\nsentiment measures for prioritization---confidence, uncertainty, and\nsurprise---and compare their effectiveness in terms of their fault-revealing\ncapability and retraining effectiveness. The results indicate that sentiment\nmeasures can effectively flag inputs that expose unacceptable DNN behavior. For\nMNIST models, the average percentage of inputs correctly flagged ranged from\n88% to 94.8%.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 23:13:47 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Byun", "Taejoon", ""], ["Sharma", "Vaibhav", ""], ["Vijayakumar", "Abhishek", ""], ["Rayadurgam", "Sanjai", ""], ["Cofer", "Darren", ""]]}, {"id": "1901.03793", "submitter": "Eda Okur", "authors": "Eda Okur, Sinem Aslan, Nese Alyuz, Asli Arslan Esme, Ryan S. Baker", "title": "The Importance of Socio-Cultural Differences for Annotating and\n  Detecting the Affective States of Students", "comments": "13th Women in Machine Learning Workshop (WiML 2018), co-located with\n  the 32nd Conference on Neural Information Processing Systems (NeurIPS 2018),\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of real-time affect detection models often depends upon\nobtaining annotated data for supervised learning by employing human experts to\nlabel the student data. One open question in annotating affective data for\naffect detection is whether the labelers (i.e., human experts) need to be\nsocio-culturally similar to the students being labeled, as this impacts the\ncost feasibility of obtaining the labels. In this study, we investigate the\nfollowing research questions: For affective state annotation, how does the\nsocio-cultural background of human expert labelers, compared to the subjects,\nimpact the degree of consensus and distribution of affective states obtained?\nSecondly, how do differences in labeler background impact the performance of\naffect detection models that are trained using these labels?\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 03:50:53 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Okur", "Eda", ""], ["Aslan", "Sinem", ""], ["Alyuz", "Nese", ""], ["Esme", "Asli Arslan", ""], ["Baker", "Ryan S.", ""]]}, {"id": "1901.03802", "submitter": "Sheng-Jun Huang", "authors": "Ying-Peng Tang and Guo-Xiang Li and Sheng-Jun Huang", "title": "ALiPy: Active Learning in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning methods usually require a large set of labeled\nexamples for model training. However, in many real applications, there are\nplentiful unlabeled data but limited labeled data; and the acquisition of\nlabels is costly. Active learning (AL) reduces the labeling cost by iteratively\nselecting the most valuable data to query their labels from the annotator. This\narticle introduces a Python toobox ALiPy for active learning. ALiPy provides a\nmodule based implementation of active learning framework, which allows users to\nconveniently evaluate, compare and analyze the performance of active learning\nmethods. In the toolbox, multiple options are available for each component of\nthe learning framework, including data process, active selection, label query,\nresults visualization, etc. In addition to the implementations of more than 20\nstate-of-the-art active learning algorithms, ALiPy also supports users to\neasily configure and implement their own approaches under different active\nlearning settings, such as AL for multi-label data, AL with noisy annotators,\nAL with different costs and so on. The toolbox is well-documented and\nopen-source on Github, and can be easily installed through PyPI.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 05:32:05 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Tang", "Ying-Peng", ""], ["Li", "Guo-Xiang", ""], ["Huang", "Sheng-Jun", ""]]}, {"id": "1901.03808", "submitter": "Huangxun Chen", "authors": "Huangxun Chen, Chenyu Huang, Qianyi Huang, Qian Zhang, Wei Wang", "title": "ECGadv: Generating Adversarial Electrocardiogram to Misguide Arrhythmia\n  Classification System", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs)-powered Electrocardiogram (ECG) diagnosis systems\nrecently achieve promising progress to take over tedious examinations by\ncardiologists. However, their vulnerability to adversarial attacks still lack\ncomprehensive investigation. The existing attacks in image domain could not be\ndirectly applicable due to the distinct properties of ECGs in visualization and\ndynamic properties. Thus, this paper takes a step to thoroughly explore\nadversarial attacks on the DNN-powered ECG diagnosis system. We analyze the\nproperties of ECGs to design effective attacks schemes under two attacks models\nrespectively. Our results demonstrate the blind spots of DNN-powered diagnosis\nsystems under adversarial attacks, which calls attention to adequate\ncountermeasures.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 06:38:51 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 13:49:38 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 13:17:40 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 10:59:22 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chen", "Huangxun", ""], ["Huang", "Chenyu", ""], ["Huang", "Qianyi", ""], ["Zhang", "Qian", ""], ["Wang", "Wei", ""]]}, {"id": "1901.03829", "submitter": "Furkan Gursoy", "authors": "Furkan Gursoy, Ahmet Onur Durahim", "title": "Predicting Diffusion Reach Probabilities via Representation Learning on\n  Social Networks", "comments": null, "journal-ref": "Proceedings of the 5th International Management Information\n  Systems Conference (2018)", "doi": "10.6084/m9.figshare.7565894", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion reach probability between two nodes on a network is defined as the\nprobability of a cascade originating from one node reaching to another node. An\ninfinite number of cascades would enable calculation of true diffusion reach\nprobabilities between any two nodes. However, there exists only a finite number\nof cascades and one usually has access only to a small portion of all available\ncascades. In this work, we addressed the problem of estimating diffusion reach\nprobabilities given only a limited number of cascades and partial information\nabout underlying network structure. Our proposed strategy employs node\nrepresentation learning to generate and feed node embeddings into machine\nlearning algorithms to create models that predict diffusion reach\nprobabilities. We provide experimental analysis using synthetically generated\ncascades on two real-world social networks. Results show that proposed method\nis superior to using values calculated from available cascades when the portion\nof cascades is small.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 09:05:34 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gursoy", "Furkan", ""], ["Durahim", "Ahmet Onur", ""]]}, {"id": "1901.03838", "submitter": "Aijun Zhang", "authors": "Zebin Yang, Aijun Zhang and Agus Sudjianto", "title": "Enhancing Explainability of Neural Networks through Architecture\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction accuracy and model explainability are the two most important\nobjectives when developing machine learning algorithms to solve real-world\nproblems. The neural networks are known to possess good prediction performance,\nbut lack of sufficient model interpretability. In this paper, we propose to\nenhance the explainability of neural networks through the following\narchitecture constraints: a) sparse additive subnetworks; b) projection pursuit\nwith orthogonality constraint; and c) smooth function approximation. It leads\nto an explainable neural network (xNN) with the superior balance between\nprediction performance and model interpretability. We derive the necessary and\nsufficient identifiability conditions for the proposed xNN model. The multiple\nparameters are simultaneously estimated by a modified mini-batch gradient\ndescent method based on the backpropagation algorithm for calculating the\nderivatives and the Cayley transform for preserving the projection\northogonality. Through simulation study under six different scenarios, we\ncompare the proposed method to several benchmarks including least absolute\nshrinkage and selection operator, support vector machine, random forest,\nextreme learning machine, and multi-layer perceptron. It is shown that the\nproposed xNN model keeps the flexibility of pursuing high prediction accuracy\nwhile attaining improved interpretability. Finally, a real data example is\nemployed as a showcase application.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 10:17:36 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 09:40:57 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yang", "Zebin", ""], ["Zhang", "Aijun", ""], ["Sudjianto", "Agus", ""]]}, {"id": "1901.03860", "submitter": "Muktabh Mayank Srivastava", "authors": "Harshita Seth, Pulkit Kumar, Muktabh Mayank Srivastava", "title": "Prototypical Metric Transfer Learning for Continuous Speech Keyword\n  Spotting With Limited Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords\nin recorded conversations, when a small number of instances of keywords are\navailable in training data. Unlike the more common Keyword Spotting, where an\nalgorithm needs to detect lone keywords or short phrases like \"Alexa\",\n\"Cortana\", \"Hi Alexa!\", \"Whatsup Octavia?\" etc. in speech, CSKS needs to filter\nout embedded words from a continuous flow of speech, ie. spot \"Anna\" and\n\"github\" in \"I know a developer named Anna who can look into this github\nissue.\" Apart from the issue of limited training data availability, CSKS is an\nextremely imbalanced classification problem. We address the limitations of\nsimple keyword spotting baselines for both aforementioned challenges by using a\nnovel combination of loss functions (Prototypical networks' loss and metric\nloss) and transfer learning. Our method improves F1 score by over 10%.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 13:20:54 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Seth", "Harshita", ""], ["Kumar", "Pulkit", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "1901.03868", "submitter": "Manjesh Kumar Hanawal", "authors": "Harshvardhan Tibrewal, Sravan Patchala, Manjesh K. Hanawal and Sumit\n  J. Darak", "title": "Multiplayer Multi-armed Bandits for Optimal Assignment in Heterogeneous\n  Networks", "comments": "Part of this work is accepted for presentation in Infocom 2019 under\n  the title \"Distributed Learning and Optimal Assignment in Multiplayer\n  Heterogeneous Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an ad hoc network where multiple users access the same set of\nchannels. The channel characteristics are unknown and could be different for\neach user (heterogeneous). No controller is available to coordinate channel\nselections by the users, and if multiple users select the same channel, they\ncollide and none of them receive any rate (or reward). For such a completely\ndecentralized network we develop algorithms that aim to achieve optimal network\nthroughput. Due to lack of any direct communication between the users, we allow\neach user to exchange information by transmitting in a specific pattern and\nsense such transmissions from others. However, such transmissions and sensing\nfor information exchange do not add to network throughput. For the wideband\nsensing and narrowband sensing scenarios, we first develop explore-and-commit\nalgorithms that converge to near-optimal allocation with high probability in a\nsmall number of rounds. Building on this, we develop an algorithm that gives\nlogarithmic regret, even when the number of users changes with time. We\nvalidate our claims through extensive experiments and show that our algorithms\nperform significantly better than the state-of-the-art CSM-MAB, dE3 and dE3-TS\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 14:30:57 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 13:03:57 GMT"}, {"version": "v3", "created": "Thu, 15 Aug 2019 11:10:48 GMT"}, {"version": "v4", "created": "Fri, 30 Aug 2019 03:59:20 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tibrewal", "Harshvardhan", ""], ["Patchala", "Sravan", ""], ["Hanawal", "Manjesh K.", ""], ["Darak", "Sumit J.", ""]]}, {"id": "1901.03887", "submitter": "Emanuele Pesce Mr.", "authors": "Emanuele Pesce, Giovanni Montana", "title": "Improving Coordination in Small-Scale Multi-Agent Deep Reinforcement\n  Learning through Memory-driven Communication", "comments": null, "journal-ref": "Machine Learning (2020)", "doi": "10.1007/s10994-019-05864-5", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have recently been used to train\nmultiple interacting agents in a centralised manner whilst keeping their\nexecution decentralised. When the agents can only acquire partial observations\nand are faced with tasks requiring coordination and synchronisation skills,\ninter-agent communication plays an essential role. In this work, we propose a\nframework for multi-agent training using deep deterministic policy gradients\nthat enables concurrent, end-to-end learning of an explicit communication\nprotocol through a memory device. During training, the agents learn to perform\nread and write operations enabling them to infer a shared representation of the\nworld. We empirically demonstrate that concurrent learning of the communication\ndevice and individual policies can improve inter-agent coordination and\nperformance in small-scale systems. Our experimental results show that the\nproposed method achieves superior performance in scenarios with up to six\nagents. We illustrate how different communication patterns can emerge on six\ndifferent tasks of increasing complexity. Furthermore, we study the effects of\ncorrupting the communication channel, provide a visualisation of the\ntime-varying memory content as the underlying task is being solved and validate\nthe building blocks of the proposed memory device through ablation studies.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 18:12:15 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 10:30:21 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:36:46 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Pesce", "Emanuele", ""], ["Montana", "Giovanni", ""]]}, {"id": "1901.03892", "submitter": "Kevin Zhang", "authors": "Kevin Alex Zhang, Alfredo Cuesta-Infante, Lei Xu, Kalyan\n  Veeramachaneni", "title": "SteganoGAN: High Capacity Image Steganography with GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image steganography is a procedure for hiding messages inside pictures. While\nother techniques such as cryptography aim to prevent adversaries from reading\nthe secret message, steganography aims to hide the presence of the message\nitself. In this paper, we propose a novel technique for hiding arbitrary binary\ndata in images using generative adversarial networks which allow us to optimize\nthe perceptual quality of the images produced by our model. We show that our\napproach achieves state-of-the-art payloads of 4.4 bits per pixel, evades\ndetection by steganalysis tools, and is effective on images from multiple\ndatasets. To enable fair comparisons, we have released an open source library\nthat is available online at https://github.com/DAI-Lab/SteganoGAN.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 18:47:38 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 03:39:54 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Zhang", "Kevin Alex", ""], ["Cuesta-Infante", "Alfredo", ""], ["Xu", "Lei", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1901.03896", "submitter": "Talayeh Razzaghi", "authors": "Samuel Li, Talayeh Razzaghi", "title": "Personalized Colorectal Cancer Survivability Prediction with Machine\n  Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the importance of ethnicity in colorectal cancer\nsurvivability prediction using machine learning techniques and the SEER cancer\nincidence database. We compare model performances for 2-year survivability\nprediction and feature importance rankings between Hispanic, White, and mixed\npatient populations. Our models consistently perform better on single-ethnicity\npopulations and provide different feature importance rankings when trained in\ndifferent populations. Additionally, we show our models achieve higher Area\nUnder Curve (AUC) score than the best reported in the literature. We also apply\nimbalanced classification techniques to improve classification performance when\nthe number of patients who have survived from colorectal cancer is much larger\nthan who have not. These results provide evidence in favor for increased\nconsideration of patient ethnicity in cancer survivability prediction, and for\nmore personalized medicine in general.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 20:23:29 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Li", "Samuel", ""], ["Razzaghi", "Talayeh", ""]]}, {"id": "1901.03904", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Zoleikha Jahanbakhsh-Nagadeh, Mohammad-Reza Feizi-Derakhshi, Arash\n  Sharifi", "title": "A Speech Act Classifier for Persian Texts and its Application in\n  Identifying Rumors", "comments": "Published Link: http://jscit.nit.ac.ir/article_103557.html", "journal-ref": "Journal of Soft Computing and Information Technology, 9, 1, 1399\n  (2020), 18-27", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech Acts (SAs) are one of the important areas of pragmatics, which give us\na better understanding of the state of mind of the people and convey an\nintended language function. Knowledge of the SA of a text can be helpful in\nanalyzing that text in natural language processing applications. This study\npresents a dictionary-based statistical technique for Persian SA recognition.\nThe proposed technique classifies a text into seven classes of SA based on four\ncriteria: lexical, syntactic, semantic, and surface features. WordNet as the\ntool for extracting synonym and enriching features dictionary is utilized. To\nevaluate the proposed technique, we utilized four classification methods\nincluding Random Forest (RF), Support Vector Machine (SVM), Naive Bayes (NB),\nand K-Nearest Neighbors (KNN). The experimental results demonstrate that the\nproposed method using RF and SVM as the best classifiers achieved a\nstate-of-the-art performance with an accuracy of 0.95 for classification of\nPersian SAs. Our original vision of this work is introducing an application of\nSA recognition on social media content, especially the common SA in rumors.\nTherefore, the proposed system utilized to determine the common SAs in rumors.\nThe results showed that Persian rumors are often expressed in three SA classes\nincluding narrative, question, and threat, and in some cases with the request\nSA.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 21:54:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 15:08:44 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 08:19:03 GMT"}, {"version": "v4", "created": "Sun, 12 Jul 2020 10:42:12 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jahanbakhsh-Nagadeh", "Zoleikha", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Sharifi", "Arash", ""]]}, {"id": "1901.03905", "submitter": "Lucy Gao", "authors": "Lucy L. Gao, Jacob Bien and Daniela Witten", "title": "Are Clusterings of Multiple Data Views Independent?", "comments": "20 pages, 4 figures, 1 table (main text); 15 pages, 9 figures\n  (supplement)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Pioneer 100 (P100) Wellness Project (Price and others, 2017), multiple\ntypes of data are collected on a single set of healthy participants at multiple\ntimepoints in order to characterize and optimize wellness. One way to do this\nis to identify clusters, or subgroups, among the participants, and then to\ntailor personalized health recommendations to each subgroup. It is tempting to\ncluster the participants using all of the data types and timepoints, in order\nto fully exploit the available information. However, clustering the\nparticipants based on multiple data views implicitly assumes that a single\nunderlying clustering of the participants is shared across all data views. If\nthis assumption does not hold, then clustering the participants using multiple\ndata views may lead to spurious results. In this paper, we seek to evaluate the\nassumption that there is some underlying relationship among the clusterings\nfrom the different data views, by asking the question: are the clusters within\neach data view dependent or independent? We develop a new test for answering\nthis question, which we then apply to clinical, proteomic, and metabolomic\ndata, across two distinct timepoints, from the P100 study. We find that while\nthe subgroups of the participants defined with respect to any single data type\nseem to be dependent across time, the clustering among the participants based\non one data type (e.g. proteomic data) appears not to be associated with the\nclustering based on another data type (e.g. clinical data).\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 21:57:34 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Gao", "Lucy L.", ""], ["Bien", "Jacob", ""], ["Witten", "Daniela", ""]]}, {"id": "1901.03906", "submitter": "Alexander Rakowski", "authors": "Alexander G. Rakowski (1), Petar Veli\\v{c}kovi\\'c (1), Enrico Dall'Ara\n  (2), Pietro Li\\`o (1) ((1) University of Cambridge - Computer Laboratory, (2)\n  University of Sheffield - Department of Oncology & Metabolism)", "title": "ChronoMID - Cross-Modal Neural Networks for 3-D Temporal Medical Imaging\n  Data", "comments": "8 pages, 7 figures, 2 tables", "journal-ref": null, "doi": "10.1371/journal.pone.0228962", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ChronoMID builds on the success of cross-modal convolutional neural networks\n(X-CNNs), making the novel application of the technique to medical imaging\ndata. Specifically, this paper presents and compares alternative approaches -\ntimestamps and difference images - to incorporate temporal information for the\nclassification of bone disease in mice, applied to micro-CT scans of mouse\ntibiae. Whilst much previous work on diseases and disease classification has\nbeen based on mathematical models incorporating domain expertise and the\nexplicit encoding of assumptions, the approaches given here utilise the growing\navailability of computing resources to analyse large datasets and uncover\nsubtle patterns in both space and time. After training on a balanced set of\nover 75000 images, all models incorporating temporal features outperformed a\nstate-of-the-art CNN baseline on an unseen, balanced validation set comprising\nover 20000 images. The top-performing model achieved 99.54% accuracy, compared\nto 73.02% for the CNN baseline.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 21:57:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Rakowski", "Alexander G.", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Dall'Ara", "Enrico", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1901.03909", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein, Kenji Kawaguchi", "title": "Eliminating all bad Local Minima from Loss Landscapes without even\n  adding an Extra Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has noted that all bad local minima can be removed from neural\nnetwork loss landscapes, by adding a single unit with a particular\nparameterization. We show that the core technique from these papers can be used\nto remove all bad local minima from any loss landscape, so long as the global\nminimum has a loss of zero. This procedure does not require the addition of\nauxiliary units, or even that the loss be associated with a neural network. The\nmethod of action involves all bad local minima being converted into bad\n(non-local) minima at infinity in terms of auxiliary parameters.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 22:15:50 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""], ["Kawaguchi", "Kenji", ""]]}, {"id": "1901.03912", "submitter": "Senthil Yogamani", "authors": "Ganesh Sistu, Isabelle Leang and Senthil Yogamani", "title": "Real-time Joint Object Detection and Semantic Segmentation Network for\n  Automated Driving", "comments": "Presented at NeurIPS 2018 Workshop on Machine Learning on the Phone\n  and other Consumer Devices (MLPCD 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) are successfully used for various visual\nperception tasks including bounding box object detection, semantic\nsegmentation, optical flow, depth estimation and visual SLAM. Generally these\ntasks are independently explored and modeled. In this paper, we present a joint\nmulti-task network design for learning object detection and semantic\nsegmentation simultaneously. The main motivation is to achieve real-time\nperformance on a low power embedded SOC by sharing of encoder for both the\ntasks. We construct an efficient architecture using a small ResNet10 like\nencoder which is shared for both decoders. Object detection uses YOLO v2 like\ndecoder and semantic segmentation uses FCN8 like decoder. We evaluate the\nproposed network in two public datasets (KITTI, Cityscapes) and in our private\nfisheye camera dataset, and demonstrate that joint network provides the same\naccuracy as that of separate networks. We further optimize the network to\nachieve 30 fps for 1280x384 resolution image.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 22:25:06 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Sistu", "Ganesh", ""], ["Leang", "Isabelle", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1901.03919", "submitter": "Alexander Litvinenko", "authors": "Vladimir Berikov, Alexander Litvinenko", "title": "Semi-Supervised Regression using Cluster Ensemble and Low-Rank\n  Co-Association Matrix Decomposition under Uncertainties", "comments": "12 pages, 1 figure, 3 tables, submitted to the proceedings of the\n  14th Computer Science Symposium in Russia (CSR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we solve a semi-supervised regression problem. Due to the lack\nof knowledge about the data structure and the presence of random noise, the\nconsidered data model is uncertain. We propose a method which combines graph\nLaplacian regularization and cluster ensemble methodologies. The co-association\nmatrix of the ensemble is calculated on both labeled and unlabeled data; this\nmatrix is used as a similarity matrix in the regularization framework to derive\nthe predicted outputs. We use the low-rank decomposition of the co-association\nmatrix to significantly speedup calculations and reduce memory. Numerical\nexperiments using the Monte Carlo approach demonstrate robustness, efficiency,\nand scalability of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 00:37:08 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 22:28:37 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Berikov", "Vladimir", ""], ["Litvinenko", "Alexander", ""]]}, {"id": "1901.03960", "submitter": "Pai Liu", "authors": "Jingwei Gan, Pai Liu, Rajan K. Chakrabarty", "title": "Introducing a Generative Adversarial Network Model for Lagrangian\n  Trajectory Simulation", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generative adversarial network (GAN) model to simulate the\n3-dimensional Lagrangian motion of particles trapped in the recirculation zone\nof a buoyancy-opposed flame. The GAN model comprises a stochastic recurrent\nneural network, serving as a generator, and a convoluted neural network,\nserving as a discriminator. Adversarial training was performed to the point\nwhere the best-trained discriminator failed to distinguish the ground truth\nfrom the trajectory produced by the best-trained generator. The model\nperformance was then benchmarked against a statistical analysis performed on\nboth the simulated trajectories and the ground truth, with regard to the\naccuracy and generalization criteria.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 11:06:34 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Gan", "Jingwei", ""], ["Liu", "Pai", ""], ["Chakrabarty", "Rajan K.", ""]]}, {"id": "1901.03968", "submitter": "Sahar Yousefi", "authors": "Sahar Yousefi, M. T. Manzuri Shalmani, Antoni B. Chan", "title": "A Fully Bayesian Infinite Generative Model for Dynamic Texture\n  Segmentation", "comments": "38 pages; 15 figures;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative dynamic texture models (GDTMs) are widely used for dynamic texture\n(DT) segmentation in the video sequences. GDTMs represent DTs as a set of\nlinear dynamical systems (LDSs). A major limitation of these models concerns\nthe automatic selection of a proper number of DTs. Dirichlet process mixture\n(DPM) models which have appeared recently as the cornerstone of the\nnon-parametric Bayesian statistics, is an optimistic candidate toward resolving\nthis issue. Under this motivation to resolve the aforementioned drawback, we\npropose a novel non-parametric fully Bayesian approach for DT segmentation,\nformulated on the basis of a joint DPM and GDTM construction. This interaction\ncauses the algorithm to overcome the problem of automatic segmentation\nproperly. We derive the Variational Bayesian Expectation-Maximization (VBEM)\ninference for the proposed model. Moreover, in the E-step of inference, we\napply Rauch-Tung-Striebel smoother (RTSS) algorithm on Variational Bayesian\nLDSs. Ultimately, experiments on different video sequences are performed.\nExperiment results indicate that the proposed algorithm outperforms the\nprevious methods in efficiency and accuracy noticeably.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 12:15:11 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Yousefi", "Sahar", ""], ["Shalmani", "M. T. Manzuri", ""], ["Chan", "Antoni B.", ""]]}, {"id": "1901.03995", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi,\n  George Kour, Jonathan Berant", "title": "Neural network gradient-based learning of black-box function interfaces", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks work well at approximating complicated functions when\nprovided with data and trained by gradient descent methods. At the same time,\nthere is a vast amount of existing functions that programmatically solve\ndifferent tasks in a precise manner eliminating the need for training. In many\ncases, it is possible to decompose a task to a series of functions, of which\nfor some we may prefer to use a neural network to learn the functionality,\nwhile for others the preferred method would be to use existing black-box\nfunctions. We propose a method for end-to-end training of a base neural network\nthat integrates calls to existing black-box functions. We do so by\napproximating the black-box functionality with a differentiable neural network\nin a way that drives the base network to comply with the black-box function\ninterface during the end-to-end optimization process. At inference time, we\nreplace the differentiable estimator with its external black-box\nnon-differentiable counterpart such that the base network output matches the\ninput arguments of the black-box function. Using this \"Estimate and Replace\"\nparadigm, we train a neural network, end to end, to compute the input to\nblack-box functionality while eliminating the need for intermediate labels. We\nshow that by leveraging the existing precise black-box function during\ninference, the integrated model generalizes better than a fully differentiable\nmodel, and learns more efficiently compared to RL-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 14:55:18 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Jacovi", "Alon", ""], ["Hadash", "Guy", ""], ["Kermany", "Einat", ""], ["Carmeli", "Boaz", ""], ["Lavi", "Ofer", ""], ["Kour", "George", ""], ["Berant", "Jonathan", ""]]}, {"id": "1901.04028", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Peibei Shi, Christoph Bergmeir, Hansika Hewamalage,\n  Quoc Tran, Brian Seaman", "title": "Sales Demand Forecast in E-commerce using a Long Short-Term Memory\n  Neural Network Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating accurate and reliable sales forecasts is crucial in the E-commerce\nbusiness. The current state-of-the-art techniques are typically univariate\nmethods, which produce forecasts considering only the historical sales data of\na single product. However, in a situation where large quantities of related\ntime series are available, conditioning the forecast of an individual time\nseries on past behaviour of similar, related time series can be beneficial.\nSince the product assortment hierarchy in an E-commerce platform contains large\nnumbers of related products, in which the sales demand patterns can be\ncorrelated, our attempt is to incorporate this cross-series information in a\nunified model. We achieve this by globally training a Long Short-Term Memory\nnetwork (LSTM) that exploits the non-linear demand relationships available in\nan E-commerce product assortment hierarchy. Aside from the forecasting\nframework, we also propose a systematic pre-processing framework to overcome\nthe challenges in the E-commerce business. We also introduce several product\ngrouping strategies to supplement the LSTM learning schemes, in situations\nwhere sales patterns in a product portfolio are disparate. We empirically\nevaluate the proposed forecasting framework on a real-world online marketplace\ndataset from Walmart.com. Our method achieves competitive results on category\nlevel and super-departmental level datasets, outperforming state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 17:52:06 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 10:08:23 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Bandara", "Kasun", ""], ["Shi", "Peibei", ""], ["Bergmeir", "Christoph", ""], ["Hewamalage", "Hansika", ""], ["Tran", "Quoc", ""], ["Seaman", "Brian", ""]]}, {"id": "1901.04055", "submitter": "Zhixiang Eddie Xu", "authors": "Zhixiang Eddie Xu, Gao Huang, Kilian Q. Weinberger, Alice X. Zheng", "title": "Gradient Boosted Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feature selection algorithm should ideally satisfy four conditions:\nreliably extract relevant features; be able to identify non-linear feature\ninteractions; scale linearly with the number of features and dimensions; allow\nthe incorporation of known sparsity structure. In this work we propose a novel\nfeature selection algorithm, Gradient Boosted Feature Selection (GBFS), which\nsatisfies all four of these requirements. The algorithm is flexible, scalable,\nand surprisingly straight-forward to implement as it is based on a modification\nof Gradient Boosted Trees. We evaluate GBFS on several real world data sets and\nshow that it matches or out-performs other state of the art feature selection\nalgorithms. Yet it scales to larger data set sizes and naturally allows for\ndomain-specific side information.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 20:37:05 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Xu", "Zhixiang Eddie", ""], ["Huang", "Gao", ""], ["Weinberger", "Kilian Q.", ""], ["Zheng", "Alice X.", ""]]}, {"id": "1901.04065", "submitter": "Zhixiang Eddie Xu", "authors": "Zhixiang Eddie Xu, Matt J. Kusner, Kilian Q. Weinberger, Alice X.\n  Zheng", "title": "Gradient Regularized Budgeted Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning transitions increasingly towards real world applications\ncontrolling the test-time cost of algorithms becomes more and more crucial.\nRecent work, such as the Greedy Miser and Speedboost, incorporate test-time\nbudget constraints into the training procedure and learn classifiers that\nprovably stay within budget (in expectation). However, so far, these algorithms\nare limited to the supervised learning scenario where sufficient amounts of\nlabeled data are available. In this paper we investigate the common scenario\nwhere labeled data is scarce but unlabeled data is available in abundance. We\npropose an algorithm that leverages the unlabeled data (through Laplace\nsmoothing) and learns classifiers with budget constraints. Our model, based on\ngradient boosted regression trees (GBRT), is, to our knowledge, the first\nalgorithm for semi-supervised budgeted learning.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 21:09:08 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 01:54:37 GMT"}, {"version": "v3", "created": "Sun, 27 Jan 2019 01:43:01 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Xu", "Zhixiang Eddie", ""], ["Kusner", "Matt J.", ""], ["Weinberger", "Kilian Q.", ""], ["Zheng", "Alice X.", ""]]}, {"id": "1901.04169", "submitter": "Helge Spieker", "authors": "Helge Spieker, Arnaud Gotlieb", "title": "Towards Testing of Deep Learning Systems with Training Set Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Testing the implementation of deep learning systems and their training\nroutines is crucial to maintain a reliable code base. Modern software\ndevelopment employs processes, such as Continuous Integration, in which changes\nto the software are frequently integrated and tested. However, testing the\ntraining routines requires running them and fully training a deep learning\nmodel can be resource-intensive, when using the full data set. Using only a\nsubset of the training data can improve test run time, but can also reduce its\neffectiveness. We evaluate different ways for training set reduction and their\nability to mimic the characteristics of model training with the original full\ndata set. Our results underline the usefulness of training set reduction,\nespecially in resource-constrained environments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 07:55:00 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Spieker", "Helge", ""], ["Gotlieb", "Arnaud", ""]]}, {"id": "1901.04195", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Marco Gori", "title": "Integrating Learning and Reasoning with Deep Logic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is very effective at jointly learning feature representations\nand classification models, especially when dealing with high dimensional input\npatterns. Probabilistic logic reasoning, on the other hand, is capable to take\nconsistent and robust decisions in complex environments. The integration of\ndeep learning and logic reasoning is still an open-research problem and it is\nconsidered to be the key for the development of real intelligent agents. This\npaper presents Deep Logic Models, which are deep graphical models integrating\ndeep learning and logic reasoning both for learning and inference. Deep Logic\nModels create an end-to-end differentiable architecture, where deep learners\nare embedded into a network implementing a continuous relaxation of the logic\nknowledge. The learning process allows to jointly learn the weights of the deep\nlearners and the meta-parameters controlling the high-level reasoning. The\nexperimental results show that the proposed methodology overtakes the\nlimitations of the other approaches that have been proposed to bridge deep\nlearning and reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 09:06:28 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Marra", "Giuseppe", ""], ["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Gori", "Marco", ""]]}, {"id": "1901.04215", "submitter": "Xingrui Yu", "authors": "Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor W. Tsang, Masashi\n  Sugiyama", "title": "How does Disagreement Help Generalization against Label Corruption?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with noisy labels is one of the hottest problems in\nweakly-supervised learning. Based on memorization effects of deep neural\nnetworks, training on small-loss instances becomes very promising for handling\nnoisy labels. This fosters the state-of-the-art approach \"Co-teaching\" that\ncross-trains two deep neural networks using the small-loss trick. However, with\nthe increase of epochs, two networks converge to a consensus and Co-teaching\nreduces to the self-training MentorNet. To tackle this issue, we propose a\nrobust learning paradigm called Co-teaching+, which bridges the \"Update by\nDisagreement\" strategy with the original Co-teaching. First, two networks feed\nforward and predict all data, but keep prediction disagreement data only. Then,\namong such disagreement data, each network selects its small-loss data, but\nback propagates the small-loss data from its peer network and updates its own\nparameters. Empirical results on benchmark datasets demonstrate that\nCo-teaching+ is much superior to many state-of-the-art methods in the\nrobustness of trained models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 10:02:27 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 11:32:14 GMT"}, {"version": "v3", "created": "Sun, 12 May 2019 12:32:12 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Yu", "Xingrui", ""], ["Han", "Bo", ""], ["Yao", "Jiangchao", ""], ["Niu", "Gang", ""], ["Tsang", "Ivor W.", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.04240", "submitter": "Philip Sellars", "authors": "Philip Sellars and Angelica Aviles-Rivero and Nicolas Papadakis and\n  David Coomes and Anita Faul and Carola-Bibane Sch\\\"onlieb", "title": "Semi-supervised Learning with Graphs: Covariance Based Superpixels For\n  Hyperspectral Image Classification", "comments": "Four pages with two figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a graph-based semi-supervised framework for\nhyperspectral image classification. We first introduce a novel superpixel\nalgorithm based on the spectral covariance matrix representation of pixels to\nprovide a better representation of our data. We then construct a superpixel\ngraph, based on carefully considered feature vectors, before performing\nclassification. We demonstrate, through a set of experimental results using two\nbenchmarking datasets, that our approach outperforms three state-of-the-art\nclassification frameworks, especially when an extremely small amount of\nlabelled data is used.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 11:18:27 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 08:43:06 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 16:22:41 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 18:23:41 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Sellars", "Philip", ""], ["Aviles-Rivero", "Angelica", ""], ["Papadakis", "Nicolas", ""], ["Coomes", "David", ""], ["Faul", "Anita", ""], ["Sch\u00f6nlieb", "Carola-Bibane", ""]]}, {"id": "1901.04292", "submitter": "Amin Azari", "authors": "Amin Azari, Mustafa Ozger, and Cicek Cavdar", "title": "Risk-Aware Resource Allocation for URLLC: Challenges and Strategies with\n  Machine Learning", "comments": "IEEE Communications Magazine, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting ultra-reliable low-latency communications (URLLC) is a major\nchallenge of 5G wireless networks. Stringent delay and reliability requirements\nneed to be satisfied for both scheduled and non-scheduled URLLC traffic to\nenable a diverse set of 5G applications. Although physical and media access\ncontrol layer solutions have been investigated to satisfy only scheduled URLLC\ntraffic, there is a lack of study on enabling transmission of non-scheduled\nURLLC traffic, especially in coexistence with the scheduled URLLC traffic.\nMachine learning (ML) is an important enabler for such a co-existence scenario\ndue to its ability to exploit spatial/temporal correlation in user behaviors\nand use of radio resources. Hence, in this paper, we first study the\ncoexistence design challenges, especially the radio resource management (RRM)\nproblem and propose a distributed risk-aware ML solution for RRM. The proposed\nsolution benefits from hybrid orthogonal/non-orthogonal radio resource slicing,\nand proactively regulates the spectrum needed for satisfying delay/reliability\nrequirement of each URLLC traffic type. A case study is introduced to\ninvestigate the potential of the proposed RRM in serving coexisting URLLC\ntraffic types. The results further provide insights on the benefits of\nleveraging intelligent RRM, e.g. a 75% increase in data rate with respect to\nthe conservative design approach for the scheduled traffic is achieved, while\nthe 99.99% reliability of both scheduled and nonscheduled traffic types is\nsatisfied.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 18:33:43 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Azari", "Amin", ""], ["Ozger", "Mustafa", ""], ["Cavdar", "Cicek", ""]]}, {"id": "1901.04295", "submitter": "Sihan Peng", "authors": "Damao Yang, Sihan Peng, He Huang, Hongliang Xue", "title": "On-Demand Video Dispatch Networks: A Scalable End-to-End Learning\n  Approach", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.SY eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a dispatch system to improve the peak service quality of video on\ndemand (VOD). Our system predicts the hot videos during the peak hours of the\nnext day based on the historical requests, and dispatches to the content\ndelivery networks (CDNs) at the previous off-peak time. In order to scale to\nbillions of videos, we build the system with two neural networks, one for video\nclustering and the other for dispatch policy developing. The clustering network\nemploys autoencoder layers and reduces the video number to a fixed value. The\npolicy network employs fully connected layers and ranks the clustered videos\nwith dispatch probabilities. The two networks are coupled with weight-sharing\ntemporal layers, which analyze the video request sequences with convolutional\nand recurrent modules. Therefore, the clustering and dispatch tasks are trained\nin an end-to-end mechanism. The real-world results show that our approach\nachieves an average prediction accuracy of 17%, compared with 3% from the\npresent baseline method, for the same amount of dispatches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 10:58:30 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Yang", "Damao", ""], ["Peng", "Sihan", ""], ["Huang", "He", ""], ["Xue", "Hongliang", ""]]}, {"id": "1901.04321", "submitter": "Thom Lake", "authors": "Thom Lake, Sinead A. Williamson, Alexander T. Hawk, Christopher C.\n  Johnson, Benjamin P. Wing", "title": "Large-scale Collaborative Filtering with Product Embeddings", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of machine learning techniques to large-scale personalized\nrecommendation problems is a challenging task. Such systems must make sense of\nenormous amounts of implicit feedback in order to understand user preferences\nacross numerous product categories. This paper presents a deep learning based\nsolution to this problem within the collaborative filtering with implicit\nfeedback framework. Our approach combines neural attention mechanisms, which\nallow for context dependent weighting of past behavioral signals, with\nrepresentation learning techniques to produce models which obtain extremely\nhigh coverage, can easily incorporate new information as it becomes available,\nand are computationally efficient. Offline experiments demonstrate significant\nperformance improvements when compared to several alternative methods from the\nliterature. Results from an online setting show that the approach compares\nfavorably with current production techniques used to produce personalized\nproduct recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 17:28:59 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Lake", "Thom", ""], ["Williamson", "Sinead A.", ""], ["Hawk", "Alexander T.", ""], ["Johnson", "Christopher C.", ""], ["Wing", "Benjamin P.", ""]]}, {"id": "1901.04345", "submitter": "Johan Pensar", "authors": "Johan Pensar, Yingying Xu, Santeri Puranen, Maiju Pesonen, Yoshiyuki\n  Kabashima, Jukka Corander", "title": "High-dimensional structure learning of binary pairwise Markov networks:\n  A comparative numerical study", "comments": null, "journal-ref": "Computational Statistics & Data Analysis 141, 62-76 (2020)", "doi": "10.1016/j.csda.2019.06.012", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the undirected graph structure of a Markov network from data is a\nproblem that has received a lot of attention during the last few decades. As a\nresult of the general applicability of the model class, a myriad of methods\nhave been developed in parallel in several research fields. Recently, as the\nsize of the considered systems has increased, the focus of new methods has been\nshifted towards the high-dimensional domain. In particular, introduction of the\npseudo-likelihood function has pushed the limits of score-based methods which\nwere originally based on the likelihood function. At the same time, methods\nbased on simple pairwise tests have been developed to meet the challenges\narising from increasingly large data sets in computational biology. Apart from\nbeing applicable to high-dimensional problems, methods based on the\npseudo-likelihood and pairwise tests are fundamentally very different. To\ncompare the accuracy of the different types of methods, an extensive numerical\nstudy is performed on data generated by binary pairwise Markov networks. A\nparallelizable Gibbs sampler, based on restricted Boltzmann machines, is\nproposed as a tool to efficiently sample from sparse high-dimensional networks.\nThe results of the study show that pairwise methods can be more accurate than\npseudo-likelihood methods in settings often encountered in high-dimensional\nstructure learning applications.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 14:26:52 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 07:28:54 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Pensar", "Johan", ""], ["Xu", "Yingying", ""], ["Puranen", "Santeri", ""], ["Pesonen", "Maiju", ""], ["Kabashima", "Yoshiyuki", ""], ["Corander", "Jukka", ""]]}, {"id": "1901.04364", "submitter": "Hao Du", "authors": "Ziyuan Pan, Hao Du, Kee Yuan Ngiam, Fei Wang, Ping Shum, Mengling Feng", "title": "A Self-Correcting Deep Learning Approach to Predict Acute Conditions in\n  Critical Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In critical care, intensivists are required to continuously monitor high\ndimensional vital signs and lab measurements to detect and diagnose acute\npatient conditions. This has always been a challenging task. In this study, we\npropose a novel self-correcting deep learning prediction approach to address\nthis challenge. We focus on an example of the prediction of acute kidney injury\n(AKI). Compared with the existing models, our method has a number of distinct\nfeatures: we utilized the accumulative data of patients in ICU; we developed a\nself-correcting mechanism that feeds errors from the previous predictions back\ninto the network; we also proposed a regularization method that takes into\naccount not only the model's prediction error on the label but also its\nestimation errors on the input data. This mechanism is applied in both\nregression and classification tasks. We compared the performance of our\nproposed method with the conventional deep learning models on two real-world\nclinical datasets and demonstrated that our proposed model constantly\noutperforms these baseline models. In particular, the proposed model achieved\narea under ROC curve at 0.893 on the MIMIC III dataset, and 0.871 on the\nPhilips eICU dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 15:31:34 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Pan", "Ziyuan", ""], ["Du", "Hao", ""], ["Ngiam", "Kee Yuan", ""], ["Wang", "Fei", ""], ["Shum", "Ping", ""], ["Feng", "Mengling", ""]]}, {"id": "1901.04380", "submitter": "Hadrien Lorenzo", "authors": "Hadrien Lorenzo, J\\'er\\^ome Saracco, Rodolphe Thi\\'ebaut", "title": "Supervised Learning for Multi-Block Incomplete Data", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the supervised high dimensional settings with a large number of variables\nand a low number of individuals, one objective is to select the relevant\nvariables and thus to reduce the dimension. That subspace selection is often\nmanaged with supervised tools. However, some data can be missing, compromising\nthe validity of the sub-space selection. We propose a Partial Least Square\n(PLS) based method, called Multi-block Data-Driven sparse PLS mdd-sPLS,\nallowing jointly variable selection and subspace estimation while training and\ntesting missing data imputation through a new algorithm called Koh-Lanta. This\nmethod was challenged through simulations against existing methods such as mean\nimputation, nipals, softImpute and imputeMFA. In the context of supervised\nanalysis of high dimensional data, the proposed method shows the lowest\nprediction error of the response variables. So far this is the only method\ncombining data imputation and response variable prediction. The superiority of\nthe supervised multi-block mdd-sPLS method increases with the intra-block and\ninter-block correlations. The application to a real data-set from a rVSV-ZEBOV\nEbola vaccine trial revealed interesting and biologically relevant results. The\nmethod is implemented in a R-package available on the CRAN and a Python-package\navailable on pypi.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 16:25:41 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Lorenzo", "Hadrien", ""], ["Saracco", "J\u00e9r\u00f4me", ""], ["Thi\u00e9baut", "Rodolphe", ""]]}, {"id": "1901.04420", "submitter": "Magdalini Paschali", "authors": "Magdalini Paschali, Walter Simson, Abhijit Guha Roy, Muhammad Ferjad\n  Naeem, R\\\"udiger G\\\"obl, Christian Wachinger, Nassir Navab", "title": "Data Augmentation with Manifold Exploring Geometric Transformations for\n  Increased Performance and Robustness", "comments": "Under Review for the 26th International Conference on Information\n  Processing in Medical Imaging (IPMI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel augmentation technique that improves not\nonly the performance of deep neural networks on clean test data, but also\nsignificantly increases their robustness to random transformations, both affine\nand projective. Inspired by ManiFool, the augmentation is performed by a\nline-search manifold-exploration method that learns affine geometric\ntransformations that lead to the misclassification on an image, while ensuring\nthat it remains on the same manifold as the training data.\n  This augmentation method populates any training dataset with images that lie\non the border of the manifolds between two-classes and maximizes the variance\nthe network is exposed to during training. Our method was thoroughly evaluated\non the challenging tasks of fine-grained skin lesion classification from\nlimited data, and breast tumor classification of mammograms. Compared with\ntraditional augmentation methods, and with images synthesized by Generative\nAdversarial Networks our method not only achieves state-of-the-art performance\nbut also significantly improves the network's robustness.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 17:30:46 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Paschali", "Magdalini", ""], ["Simson", "Walter", ""], ["Roy", "Abhijit Guha", ""], ["Naeem", "Muhammad Ferjad", ""], ["G\u00f6bl", "R\u00fcdiger", ""], ["Wachinger", "Christian", ""], ["Navab", "Nassir", ""]]}, {"id": "1901.04436", "submitter": "Georgi Dikov", "authors": "Georgi Dikov, Patrick van der Smagt, Justin Bayer", "title": "Bayesian Learning of Neural Network Architectures", "comments": "The 22nd International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a Bayesian method for estimating architectural\nparameters of neural networks, namely layer size and network depth. We do this\nby learning concrete distributions over these parameters. Our results show that\nregular networks with a learnt structure can generalise better on small\ndatasets, while fully stochastic networks can be more robust to parameter\ninitialisation. The proposed method relies on standard neural variational\nlearning and, unlike randomised architecture search, does not require a\nretraining of the model, thus keeping the computational overhead at minimum.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 18:07:18 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 12:09:50 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Dikov", "Georgi", ""], ["van der Smagt", "Patrick", ""], ["Bayer", "Justin", ""]]}, {"id": "1901.04454", "submitter": "Byeonghee Yu", "authors": "Uros Seljak and Byeonghee Yu", "title": "Posterior inference unchained with EL_2O", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO cs.LG physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference of analytically non-tractable posteriors is a difficult\nproblem because of marginalization of correlated variables and stochastic\nmethods such as MCMC and VI are commonly used. We argue that stochastic KL\ndivergence minimization used by MCMC and VI is noisy, and we propose instead\nEL_2O, expectation optimization of L_2 distance squared between the approximate\nlog posterior q and the un-normalized log posterior of p. When sampling from q\nthe solutions agree with stochastic KL divergence minimization based VI in the\nlarge sample limit, however EL_2O method is free of sampling noise, has better\noptimization properties, and requires only as many sample evaluations as the\nnumber of parameters we are optimizing if q covers p. As a consequence,\nincreasing the expressivity of q improves both the quality of results and the\nconvergence rate, allowing EL_2O to approach exact inference. Use of automatic\ndifferentiation methods enables us to develop Hessian, gradient and gradient\nfree versions of the method, which can determine M(M+2)/2+1, M+1 and 1\nparameter(s) of q with a single sample, respectively. EL_2O provides a reliable\nestimate of the quality of the approximating posterior, and converges rapidly\non full rank gaussian approximation for q and extensions beyond it, such as\nnonlinear transformations and gaussian mixtures. These can handle general\nposteriors, while still allowing fast analytic marginalizations. We test it on\nseveral examples, including a realistic 13 dimensional galaxy clustering\nanalysis, showing that it is several orders of magnitude faster than MCMC,\nwhile giving smooth and accurate non-gaussian posteriors, often requiring a few\nto a few dozen of iterations only.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 18:38:23 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 18:01:42 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Seljak", "Uros", ""], ["Yu", "Byeonghee", ""]]}, {"id": "1901.04457", "submitter": "Tim Sullivan", "authors": "C. J. Oates and T. J. Sullivan", "title": "A Modern Retrospective on Probabilistic Numerics", "comments": "23 pages, 2 figures", "journal-ref": "Statistics and Computing 29(6):1335--1351, 2019", "doi": "10.1007/s11222-019-09902-z", "report-no": null, "categories": "math.NA math.HO math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article attempts to place the emergence of probabilistic numerics as a\nmathematical-statistical research field within its historical context and to\nexplore how its gradual development can be related both to applications and to\na modern formal treatment. We highlight in particular the parallel\ncontributions of Sul'din and Larkin in the 1960s and how their pioneering early\nideas have reached a degree of maturity in the intervening period, mediated by\nparadigms such as average-case analysis and information-based complexity. We\nprovide a subjective assessment of the state of research in probabilistic\nnumerics and highlight some difficulties to be addressed by future works.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 18:42:59 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 10:32:46 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 19:39:58 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Oates", "C. J.", ""], ["Sullivan", "T. J.", ""]]}, {"id": "1901.04469", "submitter": "Ayed Alrashdi", "authors": "Ayed M.Alrashdi, Ismail Ben Atitallah, and Tareq Y. Al-Naffouri", "title": "Precise Performance Analysis of the Box-Elastic Net under Matrix\n  Uncertainties", "comments": "arXiv admin note: text overlap with arXiv:1808.04309", "journal-ref": "IEEE Signal Processing Letters, 2019", "doi": "10.1109/LSP.2019.2897215", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this letter, we consider the problem of recovering an unknown sparse\nsignal from noisy linear measurements, using an enhanced version of the popular\nElastic-Net (EN) method. We modify the EN by adding a box-constraint, and we\ncall it the Box-Elastic Net (Box-EN). We assume independent identically\ndistributed (iid) real Gaussian measurement matrix with additive Gaussian\nnoise. In many practical situations, the measurement matrix is not perfectly\nknown, and so we only have a noisy estimate of it. In this work, we precisely\ncharacterize the mean squared error and the probability of support recovery of\nthe Box-Elastic Net in the high-dimensional asymptotic regime. Numerical\nsimulations validate the theoretical predictions derived in the paper and also\nshow that the boxed variant outperforms the standard EN.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 22:32:18 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 18:09:34 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 17:09:30 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 19:02:11 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Alrashdi", "Ayed M.", ""], ["Atitallah", "Ismail Ben", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "1901.04530", "submitter": "Omry Sendik", "authors": "Omry Sendik, Dani Lischinski, Daniel Cohen-Or", "title": "CrossNet: Latent Cross-Consistency for Unpaired Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent GAN-based architectures have been able to deliver impressive\nperformance on the general task of image-to-image translation. In particular,\nit was shown that a wide variety of image translation operators may be learned\nfrom two image sets, containing images from two different domains, without\nestablishing an explicit pairing between the images. This was made possible by\nintroducing clever regularizers to overcome the under-constrained nature of the\nunpaired translation problem. In this work, we introduce a novel architecture\nfor unpaired image translation, and explore several new regularizers enabled by\nit. Specifically, our architecture comprises a pair of GANs, as well as a pair\nof translators between their respective latent spaces. These cross-translators\nenable us to impose several regularizing constraints on the learnt image\ntranslation operator, collectively referred to as latent cross-consistency. Our\nresults show that our proposed architecture and latent cross-consistency\nconstraints are able to outperform the existing state-of-the-art on a variety\nof image translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 19:31:58 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 19:47:34 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sendik", "Omry", ""], ["Lischinski", "Dani", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1901.04555", "submitter": "Zain Nasrullah", "authors": "Zain Nasrullah, Yue Zhao", "title": "Music Artist Classification with Convolutional Recurrent Neural Networks", "comments": "Proceedings of the 2019 International Joint Conference on Neural\n  Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous attempts at music artist classification use frame level audio\nfeatures which summarize frequency content within short intervals of time.\nComparatively, more recent music information retrieval tasks take advantage of\ntemporal structure in audio spectrograms using deep convolutional and recurrent\nmodels. This paper revisits artist classification with this new framework and\nempirically explores the impacts of incorporating temporal structure in the\nfeature representation. To this end, an established classification\narchitecture, a Convolutional Recurrent Neural Network (CRNN), is applied to\nthe artist20 music artist identification dataset under a comprehensive set of\nconditions. These include audio clip length, which is a novel contribution in\nthis work, and previously identified considerations such as dataset split and\nfeature level. Our results improve upon baseline works, verify the influence of\nthe producer effect on classification performance and demonstrate the\ntrade-offs between audio length and training set size. The best performing\nmodel achieves an average F1 score of 0.937 across three independent trials\nwhich is a substantial improvement over the corresponding baseline under\nsimilar conditions. Additionally, to showcase the effectiveness of the CRNN's\nfeature extraction capabilities, we visualize audio samples at the model's\nbottleneck layer demonstrating that learned representations segment into\nclusters belonging to their respective artists.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 20:33:44 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 20:29:11 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Nasrullah", "Zain", ""], ["Zhao", "Yue", ""]]}, {"id": "1901.04562", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff,\n  Christine Luu, Pierre Kreitmann, Jonathan Bischof, Ed H. Chi", "title": "Putting Fairness Principles into Practice: Challenges, Metrics, and\n  Improvements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more researchers have become aware of and passionate about algorithmic\nfairness, there has been an explosion in papers laying out new metrics,\nsuggesting algorithms to address issues, and calling attention to issues in\nexisting applications of machine learning. This research has greatly expanded\nour understanding of the concerns and challenges in deploying machine learning,\nbut there has been much less work in seeing how the rubber meets the road.\n  In this paper we provide a case-study on the application of fairness in\nmachine learning research to a production classification system, and offer new\ninsights in how to measure and address algorithmic fairness issues. We discuss\nopen questions in implementing equality of opportunity and describe our\nfairness metric, conditional equality, that takes into account distributional\ndifferences. Further, we provide a new approach to improve on the fairness\nmetric during model training and demonstrate its efficacy in improving\nperformance for a real-world product\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 21:02:29 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Doshi", "Tulsee", ""], ["Qian", "Hai", ""], ["Woodruff", "Allison", ""], ["Luu", "Christine", ""], ["Kreitmann", "Pierre", ""], ["Bischof", "Jonathan", ""], ["Chi", "Ed H.", ""]]}, {"id": "1901.04592", "submitter": "Chandan Singh", "authors": "W. James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, Bin Yu", "title": "Interpretable machine learning: definitions, methods, and applications", "comments": "11 pages", "journal-ref": "Published in PNAS 2019", "doi": "10.1073/pnas.1900654116", "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models have demonstrated great success in learning complex\npatterns that enable them to make predictions about unobserved data. In\naddition to using models for prediction, the ability to interpret what a model\nhas learned is receiving an increasing amount of attention. However, this\nincreased focus has led to considerable confusion about the notion of\ninterpretability. In particular, it is unclear how the wide array of proposed\ninterpretation methods are related, and what common concepts can be used to\nevaluate them.\n  We aim to address these concerns by defining interpretability in the context\nof machine learning and introducing the Predictive, Descriptive, Relevant (PDR)\nframework for discussing interpretations. The PDR framework provides three\noverarching desiderata for evaluation: predictive accuracy, descriptive\naccuracy and relevancy, with relevancy judged relative to a human audience.\nMoreover, to help manage the deluge of interpretation methods, we introduce a\ncategorization of existing techniques into model-based and post-hoc categories,\nwith sub-groups including sparsity, modularity and simulatability. To\ndemonstrate how practitioners can use the PDR framework to evaluate and\nunderstand interpretations, we provide numerous real-world examples. These\nexamples highlight the often under-appreciated role played by human audiences\nin discussions of interpretability. Finally, based on our framework, we discuss\nlimitations of existing methods and directions for future work. We hope that\nthis work will provide a common vocabulary that will make it easier for both\npractitioners and researchers to discuss and choose from the full range of\ninterpretation methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 22:35:26 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Murdoch", "W. James", ""], ["Singh", "Chandan", ""], ["Kumbier", "Karl", ""], ["Abbasi-Asl", "Reza", ""], ["Yu", "Bin", ""]]}, {"id": "1901.04609", "submitter": "Yuheng Bu", "authors": "Yuheng Bu, Shaofeng Zou, Venugopal V. Veeravalli", "title": "Tightening Mutual Information Based Bounds on Generalization Error", "comments": null, "journal-ref": null, "doi": "10.1109/JSAIT.2020.2991139", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An information-theoretic upper bound on the generalization error of\nsupervised learning algorithms is derived. The bound is constructed in terms of\nthe mutual information between each individual training sample and the output\nof the learning algorithm. The bound is derived under more general conditions\non the loss function than in existing studies; nevertheless, it provides a\ntighter characterization of the generalization error. Examples of learning\nalgorithms are provided to demonstrate the the tightness of the bound, and to\nshow that it has a broad range of applicability. Application to noisy and\niterative algorithms, e.g., stochastic gradient Langevin dynamics (SGLD), is\nalso studied, where the constructed bound provides a tighter characterization\nof the generalization error than existing results. Finally, it is demonstrated\nthat, unlike existing bounds, which are difficult to compute and evaluate\nempirically, the proposed bound can be estimated easily in practice.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 00:04:22 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 16:12:53 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Bu", "Yuheng", ""], ["Zou", "Shaofeng", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1901.04653", "submitter": "Yusuke Tsuzuku", "authors": "Yusuke Tsuzuku, Issei Sato, Masashi Sugiyama", "title": "Normalized Flat Minima: Exploring Scale Invariant Definition of Flat\n  Minima for Neural Networks using PAC-Bayesian Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of flat minima has played a key role in the generalization studies\nof deep learning models. However, existing definitions of the flatness are\nknown to be sensitive to the rescaling of parameters. The issue suggests that\nthe previous definitions of the flatness might not be a good measure of\ngeneralization, because generalization is invariant to such rescalings. In this\npaper, from the PAC-Bayesian perspective, we scrutinize the discussion\nconcerning the flat minima and introduce the notion of normalized flat minima,\nwhich is free from the known scale dependence issues. Additionally, we\nhighlight the scale dependence of existing matrix-norm based generalization\nerror bounds similar to the existing flat minima definitions. Our modified\nnotion of the flatness does not suffer from the insufficiency, either,\nsuggesting it might provide better hierarchy in the hypothesis class.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 04:20:36 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 14:42:30 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Tsuzuku", "Yusuke", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.04670", "submitter": "Xuefeng Peng", "authors": "Xuefeng Peng, Yi Ding, David Wihl, Omer Gottesman, Matthieu\n  Komorowski, Li-wei H. Lehman, Andrew Ross, Aldo Faisal, Finale Doshi-Velez", "title": "Improving Sepsis Treatment Strategies by Combining Deep and Kernel-Based\n  Reinforcement Learning", "comments": "AMIA 2018 Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is the leading cause of mortality in the ICU. It is challenging to\nmanage because individual patients respond differently to treatment. Thus,\ntailoring treatment to the individual patient is essential for the best\noutcomes. In this paper, we take steps toward this goal by applying a\nmixture-of-experts framework to personalize sepsis treatment. The mixture model\nselectively alternates between neighbor-based (kernel) and deep reinforcement\nlearning (DRL) experts depending on patient's current history. On a large\nretrospective cohort, this mixture-based approach outperforms physician, kernel\nonly, and DRL-only experts.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 05:40:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Peng", "Xuefeng", ""], ["Ding", "Yi", ""], ["Wihl", "David", ""], ["Gottesman", "Omer", ""], ["Komorowski", "Matthieu", ""], ["Lehman", "Li-wei H.", ""], ["Ross", "Andrew", ""], ["Faisal", "Aldo", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1901.04676", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, Csaba Szepesv\\'ari, Venkatesh\n  Saligrama", "title": "Online Algorithm for Unsupervised Sensor Selection", "comments": "Accepted at AIStats 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many security and healthcare systems, the detection and diagnosis systems\nuse a sequence of sensors/tests. Each test outputs a prediction of the latent\nstate and carries an inherent cost. However, the correctness of the predictions\ncannot be evaluated since the ground truth annotations may not be available.\nOur objective is to learn strategies for selecting a test that gives the best\ntrade-off between accuracy and costs in such Unsupervised Sensor Selection\n(USS) problems. Clearly, learning is feasible only if ground truth can be\ninferred (explicitly or implicitly) from the problem structure. It is observed\nthat this happens if the problem satisfies the 'Weak Dominance' (WD) property.\nWe set up the USS problem as a stochastic partial monitoring problem and\ndevelop an algorithm with sub-linear regret under the WD property. We argue\nthat our algorithm is optimal and evaluate its performance on problem instances\ngenerated from synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 06:37:21 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 18:05:59 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1901.04684", "submitter": "Huan Zhang", "authors": "Huan Zhang, Hongge Chen, Zhao Song, Duane Boning, Inderjit S. Dhillon,\n  Cho-Jui Hsieh", "title": "The Limitations of Adversarial Training and the Blind-Spot Attack", "comments": "Accepted by International Conference on Learning Representations\n  (ICLR) 2019. Huan Zhang and Hongge Chen contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adversarial training procedure proposed by Madry et al. (2018) is one of\nthe most effective methods to defend against adversarial examples in deep\nneural networks (DNNs). In our paper, we shed some lights on the practicality\nand the hardness of adversarial training by showing that the effectiveness\n(robustness on test set) of adversarial training has a strong correlation with\nthe distance between a test point and the manifold of training data embedded by\nthe network. Test examples that are relatively far away from this manifold are\nmore likely to be vulnerable to adversarial attacks. Consequentially, an\nadversarial training based defense is susceptible to a new class of attacks,\nthe \"blind-spot attack\", where the input images reside in \"blind-spots\" (low\ndensity regions) of the empirical distribution of training data but is still on\nthe ground-truth data manifold. For MNIST, we found that these blind-spots can\nbe easily found by simply scaling and shifting image pixel values. Most\nimportantly, for large datasets with high dimensional and complex data manifold\n(CIFAR, ImageNet, etc), the existence of blind-spots in adversarial training\nmakes defending on any valid test examples difficult due to the curse of\ndimensionality and the scarcity of training data. Additionally, we find that\nblind-spots also exist on provable defenses including (Wong & Kolter, 2018) and\n(Sinha et al., 2018) because these trainable robustness certificates can only\nbe practically optimized on a limited set of training data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 07:21:44 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Song", "Zhao", ""], ["Boning", "Duane", ""], ["Dhillon", "Inderjit S.", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1901.04704", "submitter": "Zhi-Hong Deng", "authors": "Zhi-Hong Deng, Ling Huang, Chang-Dong Wang, Jian-Huang Lai, Philip S.\n  Yu", "title": "DeepCF: A Unified Framework of Representation Learning and Matching\n  Function Learning in Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, recommendation can be viewed as a matching problem, i.e., match\nproper items for proper users. However, due to the huge semantic gap between\nusers and items, it's almost impossible to directly match users and items in\ntheir initial representation spaces. To solve this problem, many methods have\nbeen studied, which can be generally categorized into two types, i.e.,\nrepresentation learning-based CF methods and matching function learning-based\nCF methods. Representation learning-based CF methods try to map users and items\ninto a common representation space. In this case, the higher similarity between\na user and an item in that space implies they match better. Matching function\nlearning-based CF methods try to directly learn the complex matching function\nthat maps user-item pairs to matching scores. Although both methods are well\ndeveloped, they suffer from two fundamental flaws, i.e., the limited\nexpressiveness of dot product and the weakness in capturing low-rank relations\nrespectively. To this end, we propose a general framework named DeepCF, short\nfor Deep Collaborative Filtering, to combine the strengths of the two types of\nmethods and overcome such flaws. Extensive experiments on four publicly\navailable datasets demonstrate the effectiveness of the proposed DeepCF\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 08:25:00 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Deng", "Zhi-Hong", ""], ["Huang", "Ling", ""], ["Wang", "Chang-Dong", ""], ["Lai", "Jian-Huang", ""], ["Yu", "Philip S.", ""]]}, {"id": "1901.04723", "submitter": "Yifei Ma", "authors": "Yifei Ma, Yu-Xiang Wang, Balakrishnan (Murali) Narayanaswamy", "title": "Imitation-Regularized Offline Learning", "comments": "Accepted for publication at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of offline learning in automated decision systems under\nthe contextual bandits model. We are given logged historical data consisting of\ncontexts, (randomized) actions, and (nonnegative) rewards. A common goal is to\nevaluate what would happen if different actions were taken in the same\ncontexts, so as to optimize the action policies accordingly. The typical\napproach to this problem, inverse probability weighted estimation (IPWE)\n[Bottou et al., 2013], requires logged action probabilities, which may be\nmissing in practice due to engineering complications. Even when available,\nsmall action probabilities cause large uncertainty in IPWE, rendering the\ncorresponding results insignificant. To solve both problems, we show how one\ncan use policy improvement (PIL) objectives, regularized by policy imitation\n(IML). We motivate and analyze PIL as an extension to Clipped-IPWE, by showing\nthat both are lower-bound surrogates to the vanilla IPWE. We also formally\nconnect IML to IPWE variance estimation [Swaminathan and Joachims 2015] and\nnatural policy gradients. Without probability logging, our PIL-IML\ninterpretations justify and improve, by reward-weighting, the state-of-art\ncross-entropy (CE) loss that predicts the action items among all action\ncandidates available in the same contexts. With probability logging, our main\ntheoretical contribution connects IML-underfitting to the existence of either\nconfounding variables or model misspecification. We show the value and accuracy\nof our insights by simulations based on Simpson's paradox, standard UCI\nmulticlass-to-bandit conversions and on the Criteo counterfactual analysis\nchallenge dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 09:20:53 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Ma", "Yifei", "", "Murali"], ["Wang", "Yu-Xiang", "", "Murali"], ["Balakrishnan", "", "", "Murali"], ["Narayanaswamy", "", ""]]}, {"id": "1901.04730", "submitter": "Songuel Tolan", "authors": "Song\\\"ul Tolan", "title": "Fair and Unbiased Algorithmic Decision Making: Current State and Future\n  Challenges", "comments": "Background paper to the European Commission's flagship report:\n  \"Artificial Intelligence: A European Perspective\",\n  https://ec.europa.eu/jrc/en/publication/eur-scientific-and-technical-research-reports/artificial-intelligence-european-perspective\n  25 pages, including cover, figures and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms are now frequently used in sensitive contexts\nthat substantially affect the course of human lives, such as credit lending or\ncriminal justice. This is driven by the idea that `objective' machines base\ntheir decisions solely on facts and remain unaffected by human cognitive\nbiases, discriminatory tendencies or emotions. Yet, there is overwhelming\nevidence showing that algorithms can inherit or even perpetuate human biases in\ntheir decision making when they are based on data that contains biased human\ndecisions. This has led to a call for fairness-aware machine learning. However,\nfairness is a complex concept which is also reflected in the attempts to\nformalize fairness for algorithmic decision making. Statistical formalizations\nof fairness lead to a long list of criteria that are each flawed (or harmful\neven) in different contexts. Moreover, inherent tradeoffs in these criteria\nmake it impossible to unify them in one general framework. Thus, fairness\nconstraints in algorithms have to be specific to the domains to which the\nalgorithms are applied. In the future, research in algorithmic decision making\nsystems should be aware of data and developer biases and add a focus on\ntransparency to facilitate regular fairness audits.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 09:40:03 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Tolan", "Song\u00fcl", ""]]}, {"id": "1901.04791", "submitter": "Nikolaos Gianniotis", "authors": "Nikolaos Gianniotis", "title": "Mixed Variational Inference", "comments": "Conference submission, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Laplace approximation has been one of the workhorses of Bayesian\ninference. It often delivers good approximations in practice despite the fact\nthat it does not strictly take into account where the volume of posterior\ndensity lies. Variational approaches avoid this issue by explicitly minimising\nthe Kullback-Leibler divergence DKL between a postulated posterior and the true\n(unnormalised) logarithmic posterior. However, they rely on a closed form DKL\nin order to update the variational parameters. To address this, stochastic\nversions of variational inference have been devised that approximate the\nintractable DKL with a Monte Carlo average. This approximation allows\ncalculating gradients with respect to the variational parameters. However,\nvariational methods often postulate a factorised Gaussian approximating\nposterior. In doing so, they sacrifice a-posteriori correlations. In this work,\nwe propose a method that combines the Laplace approximation with the\nvariational approach. The advantages are that we maintain: applicability on\nnon-conjugate models, posterior correlations and a reduced number of free\nvariational parameters. Numerical experiments demonstrate improvement over the\nLaplace approximation and variational inference with factorised Gaussian\nposteriors.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 12:27:15 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 22:05:59 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 18:11:49 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Gianniotis", "Nikolaos", ""]]}, {"id": "1901.04816", "submitter": "Daniele Ancora", "authors": "Daniele Ancora, Luca Leuzzi", "title": "Learning Direct and Inverse Transmission Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph physics.optics stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear problems appear in a variety of disciplines and their application for\nthe transmission matrix recovery is one of the most stimulating challenges in\nbiomedical imaging. Its knowledge turns any random media into an optical tool\nthat can focus or transmit an image through disorder. Here, converting an\ninput-output problem into a statistical mechanical formulation, we investigate\nhow inference protocols can learn the transmission couplings by\npseudolikelihood maximization. Bridging linear regression and thermodynamics\nlet us propose an innovative framework to pursue the solution of the\nscattering-riddle.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 13:37:24 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 21:36:54 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Ancora", "Daniele", ""], ["Leuzzi", "Luca", ""]]}, {"id": "1901.04824", "submitter": "Detlef Steuer", "authors": "Ursula Garzcarek and Detlef Steuer", "title": "Approaching Ethical Guidelines for Data Scientists", "comments": "18 pages, submitted Nov 12th 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this article is to inspire data scientists to participate in the\ndebate on the impact that their professional work has on society, and to become\nactive in public debates on the digital world as data science professionals.\nHow do ethical principles (e.g., fairness, justice, beneficence, and\nnon-maleficence) relate to our professional lives? What lies in our\nresponsibility as professionals by our expertise in the field? More\nspecifically this article makes an appeal to statisticians to join that debate,\nand to be part of the community that establishes data science as a proper\nprofession in the sense of Airaksinen, a philosopher working on professional\nethics. As we will argue, data science has one of its roots in statistics and\nextends beyond it. To shape the future of statistics, and to take\nresponsibility for the statistical contributions to data science, statisticians\nshould actively engage in the discussions. First the term data science is\ndefined, and the technical changes that have led to a strong influence of data\nscience on society are outlined. Next the systematic approach from CNIL is\nintroduced. Prominent examples are given for ethical issues arising from the\nwork of data scientists. Further we provide reasons why data scientists should\nengage in shaping morality around and to formulate codes of conduct and codes\nof practice for data science. Next we present established ethical guidelines\nfor the related fields of statistics and computing machinery. Thereafter\nnecessary steps in the community to develop professional ethics for data\nscience are described. Finally we give our starting statement for the debate:\nData science is in the focal point of current societal development. Without\nbecoming a profession with professional ethics, data science will fail in\nbuilding trust in its interaction with and its much needed contributions to\nsociety!\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 16:13:27 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Garzcarek", "Ursula", ""], ["Steuer", "Detlef", ""]]}, {"id": "1901.04827", "submitter": "Andr\\'es Felipe L\\'opez-Lopera", "authors": "Andr\\'es F. L\\'opez-Lopera and Fran\\c{c}ois Bachoc and Nicolas\n  Durrande and J\\'er\\'emy Rohmer and D\\'eborah Idier and Olivier Roustant", "title": "Approximating Gaussian Process Emulators with Linear Inequality\n  Constraints and Noisy Observations via MC and MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding inequality constraints (e.g. boundedness, monotonicity, convexity)\ninto Gaussian processes (GPs) can lead to more realistic stochastic emulators.\nDue to the truncated Gaussianity of the posterior, its distribution has to be\napproximated. In this work, we consider Monte Carlo (MC) and Markov Chain Monte\nCarlo (MCMC) methods. However, strictly interpolating the observations may\nentail expensive computations due to highly restrictive sample spaces.\nFurthermore, having (constrained) GP emulators when data are actually noisy is\nalso of interest for real-world implementations. Hence, we introduce a noise\nterm for the relaxation of the interpolation conditions, and we develop the\ncorresponding approximation of GP emulators under linear inequality\nconstraints. We show with various toy examples that the performance of MC and\nMCMC samplers improves when considering noisy observations. Finally, on 2D and\n5D coastal flooding applications, we show that more flexible and realistic GP\nimplementations can be obtained by considering noise effects and by enforcing\nthe (linear) inequality constraints.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:03:31 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 13:09:38 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["L\u00f3pez-Lopera", "Andr\u00e9s F.", ""], ["Bachoc", "Fran\u00e7ois", ""], ["Durrande", "Nicolas", ""], ["Rohmer", "J\u00e9r\u00e9my", ""], ["Idier", "D\u00e9borah", ""], ["Roustant", "Olivier", ""]]}, {"id": "1901.04846", "submitter": "Felix M. Riese", "authors": "Felix M. Riese, Sina Keller", "title": "Soil Texture Classification with 1D Convolutional Neural Networks based\n  on Hyperspectral Data", "comments": "Accepted to the ISPRS Geospatial Week 2019 in Enschede (NL)", "journal-ref": null, "doi": "10.5194/isprs-annals-IV-2-W5-615-2019", "report-no": null, "categories": "cs.CV cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soil texture is important for many environmental processes. In this paper, we\nstudy the classification of soil texture based on hyperspectral data. We\ndevelop and implement three 1-dimensional (1D) convolutional neural networks\n(CNN): the LucasCNN, the LucasResNet which contains an identity block as\nresidual network, and the LucasCoordConv with an additional coordinates layer.\nFurthermore, we modify two existing 1D CNN approaches for the presented\nclassification task. The code of all five CNN approaches is available on GitHub\n(Riese, 2019). We evaluate the performance of the CNN approaches and compare\nthem to a random forest classifier. Thereby, we rely on the freely available\nLUCAS topsoil dataset. The CNN approach with the least depth turns out to be\nthe best performing classifier. The LucasCoordConv achieves the best\nperformance regarding the average accuracy. In future work, we can further\nenhance the introduced LucasCNN, LucasResNet and LucasCoordConv and include\nadditional variables of the rich LUCAS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:29:04 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 16:14:04 GMT"}, {"version": "v3", "created": "Sat, 30 Mar 2019 13:57:12 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Riese", "Felix M.", ""], ["Keller", "Sina", ""]]}, {"id": "1901.04859", "submitter": "Herman Shen", "authors": "Sharad Rawat and M.-H. Herman Shen", "title": "A Novel Topology Optimization Approach using Conditional Deep Learning", "comments": "8 Pages, 6 Figures, 1 Table. arXiv admin note: text overlap with\n  arXiv:1808.02334", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a novel topology optimization approach based on conditional\nWasserstein generative adversarial networks (CWGAN) is developed to replicate\nthe conventional topology optimization algorithms in an extremely\ncomputationally inexpensive way. CWGAN consists of a generator and a\ndiscriminator, both of which are deep convolutional neural networks (CNN). The\nlimited samples of data, quasi-optimal planar structures, needed for training\npurposes are generated using the conventional topology optimization algorithms.\nWith CWGANs, the topology optimization conditions can be set to a required\nvalue before generating samples. CWGAN truncates the global design space by\nintroducing an equality constraint by the designer. The results are validated\nby generating an optimized planar structure using the conventional algorithms\nwith the same settings. A proof of concept is presented which is known to be\nthe first such illustration of fusion of CWGANs and topology optimization.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 15:21:44 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Rawat", "Sharad", ""], ["Shen", "M. -H. Herman", ""]]}, {"id": "1901.04863", "submitter": "Ece Calikus", "authors": "Ece Calikus, Slawomir Nowaczyk, Anita Sant'Anna, Henrik Gadd, Sven\n  Werner", "title": "A data-driven approach for discovering heat load patterns in district\n  heating", "comments": null, "journal-ref": "Applied Energy, 252, p.113409 (2019)", "doi": "10.1016/j.apenergy.2019.113409", "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the heat usage of customers is crucial for effective district\nheating operations and management. Unfortunately, existing knowledge about\ncustomers and their heat load behaviors is quite scarce. Most previous studies\nare limited to small-scale analyses that are not representative enough to\nunderstand the behavior of the overall network. In this work, we propose a\ndata-driven approach that enables large-scale automatic analysis of heat load\npatterns in district heating networks without requiring prior knowledge. Our\nmethod clusters the customer profiles into different groups, extracts their\nrepresentative patterns, and detects unusual customers whose profiles deviate\nsignificantly from the rest of their group. Using our approach, we present the\nfirst large-scale, comprehensive analysis of the heat load patterns by\nconducting a case study on many buildings in six different customer categories\nconnected to two district heating networks in the south of Sweden. The 1222\nbuildings had a total floor space of 3.4 million square meters and used 1540 TJ\nheat during 2016. The results show that the proposed method has a high\npotential to be deployed and used in practice to analyze and understand\ncustomers' heat-use habits.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 10:54:43 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:14:51 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 11:09:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Calikus", "Ece", ""], ["Nowaczyk", "Slawomir", ""], ["Sant'Anna", "Anita", ""], ["Gadd", "Henrik", ""], ["Werner", "Sven", ""]]}, {"id": "1901.04866", "submitter": "James Townsend", "authors": "James Townsend, Tom Bird, David Barber", "title": "Practical Lossless Compression with Latent Variables using Bits Back\n  Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models have seen recent success in many data domains.\nLossless compression is an application of these models which, despite having\nthe potential to be highly useful, has yet to be implemented in a practical\nmanner. We present `Bits Back with ANS' (BB-ANS), a scheme to perform lossless\ncompression with latent variable models at a near optimal rate. We demonstrate\nthis scheme by using it to compress the MNIST dataset with a variational\nauto-encoder model (VAE), achieving compression rates superior to standard\nmethods with only a simple VAE. Given that the scheme is highly amenable to\nparallelization, we conclude that with a sufficiently high quality generative\nmodel this scheme could be used to achieve substantial improvements in\ncompression rate with acceptable running time. We make our implementation\navailable open source at https://github.com/bits-back/bits-back .\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 14:45:47 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Townsend", "James", ""], ["Bird", "Tom", ""], ["Barber", "David", ""]]}, {"id": "1901.04878", "submitter": "Yibo Yang", "authors": "Yibo Yang, Paris Perdikaris", "title": "Conditional deep surrogate models for stochastic, high-dimensional, and\n  multi-fidelity systems", "comments": "37 pages, 11 figures, Submitted to Computational Mechanics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic deep learning methodology that enables the\nconstruction of predictive data-driven surrogates for stochastic systems.\nLeveraging recent advances in variational inference with implicit\ndistributions, we put forth a statistical inference framework that enables the\nend-to-end training of surrogate models on paired input-output observations\nthat may be stochastic in nature, originate from different information sources\nof variable fidelity, or be corrupted by complex noise processes. The resulting\nsurrogates can accommodate high-dimensional inputs and outputs and are able to\nreturn predictions with quantified uncertainty. The effectiveness our approach\nis demonstrated through a series of canonical studies, including the regression\nof noisy data, multi-fidelity modeling of stochastic processes, and uncertainty\npropagation in high-dimensional dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:20:33 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Yang", "Yibo", ""], ["Perdikaris", "Paris", ""]]}, {"id": "1901.04884", "submitter": "Michal Valko", "authors": "Jean-Bastien Grill and Michal Valko and R\\'emi Munos", "title": "Optimistic optimization of a Brownian", "comments": "10 pages, 2 figures", "journal-ref": "Neural Information Processing Systems (NeurIPS 2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of optimizing a Brownian motion. We consider a\n(random) realization $W$ of a Brownian motion with input space in $[0,1]$.\nGiven $W$, our goal is to return an $\\epsilon$-approximation of its maximum\nusing the smallest possible number of function evaluations, the sample\ncomplexity of the algorithm. We provide an algorithm with sample complexity of\norder $\\log^2(1/\\epsilon)$. This improves over previous results of Al-Mharmah\nand Calvin (1996) and Calvin et al. (2017) which provided only polynomial\nrates. Our algorithm is adaptive---each query depends on previous values---and\nis an instance of the optimism-in-the-face-of-uncertainty principle.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:37:11 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Grill", "Jean-Bastien", ""], ["Valko", "Michal", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1901.04889", "submitter": "Yuanyuan Zhang", "authors": "Yuanyuan Zhang, Zi-Rui Wang, Jun Du", "title": "Deep Fusion: An Attention Guided Factorized Bilinear Pooling for\n  Audio-video Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic emotion recognition (AER) is a challenging task due to the abstract\nconcept and multiple expressions of emotion. Although there is no consensus on\na definition, human emotional states usually can be apperceived by auditory and\nvisual systems. Inspired by this cognitive process in human beings, it's\nnatural to simultaneously utilize audio and visual information in AER. However,\nmost traditional fusion approaches only build a linear paradigm, such as\nfeature concatenation and multi-system fusion, which hardly captures complex\nassociation between audio and video. In this paper, we introduce factorized\nbilinear pooling (FBP) to deeply integrate the features of audio and video.\nSpecifically, the features are selected through the embedded attention\nmechanism from respective modalities to obtain the emotion-related regions. The\nwhole pipeline can be completed in a neural network. Validated on the AFEW\ndatabase of the audio-video sub-challenge in EmotiW2018, the proposed approach\nachieves an accuracy of 62.48%, outperforming the state-of-the-art result.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:51:39 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Zhang", "Yuanyuan", ""], ["Wang", "Zi-Rui", ""], ["Du", "Jun", ""]]}, {"id": "1901.04891", "submitter": "Fengjiao Li", "authors": "Fengjiao Li, Jia Liu, Bo Ji", "title": "Combinatorial Sleeping Bandits with Fairness Constraints", "comments": "Fixed one minor mistake in the proofs, which impacts the constant\n  $\\beta_2$ in Theorem 2 only; Updated the reference by adding several highly\n  relevant papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit (MAB) model has been widely adopted for studying many\npractical optimization problems (network resource allocation, ad placement,\ncrowdsourcing, etc.) with unknown parameters. The goal of the player here is to\nmaximize the cumulative reward in the face of uncertainty. However, the basic\nMAB model neglects several important factors of the system in many real-world\napplications, where multiple arms can be simultaneously played and an arm could\nsometimes be \"sleeping\". Besides, ensuring fairness is also a key design\nconcern in practice. To that end, we propose a new Combinatorial Sleeping MAB\nmodel with Fairness constraints, called CSMAB-F, aiming to address the\naforementioned crucial modeling issues. The objective is now to maximize the\nreward while satisfying the fairness requirement of a minimum selection\nfraction for each individual arm. To tackle this new problem, we extend an\nonline learning algorithm, UCB, to deal with a critical tradeoff between\nexploitation and exploration and employ the virtual queue technique to properly\nhandle the fairness constraints. By carefully integrating these two techniques,\nwe develop a new algorithm, called Learning with Fairness Guarantee (LFG), for\nthe CSMAB-F problem. Further, we rigorously prove that not only LFG is\nfeasibility-optimal, but it also has a time-average regret upper bounded by\n$\\frac{N}{2\\eta}+\\frac{\\beta_1\\sqrt{mNT\\log{T}}+\\beta_2 N}{T}$, where N is the\ntotal number of arms, m is the maximum number of arms that can be\nsimultaneously played, T is the time horizon, $\\beta_1$ and $\\beta_2$ are\nconstants, and $\\eta$ is a design parameter that we can tune. Finally, we\nperform extensive simulations to corroborate the effectiveness of the proposed\nalgorithm. Interestingly, the simulation results reveal an important tradeoff\nbetween the regret and the speed of convergence to a point satisfying the\nfairness constraints.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:52:22 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 15:26:50 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 18:06:06 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Li", "Fengjiao", ""], ["Liu", "Jia", ""], ["Ji", "Bo", ""]]}, {"id": "1901.04909", "submitter": "Chris Russell", "authors": "Chris Russell", "title": "Efficient Search for Diverse Coherent Explanations", "comments": "FAT* 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes new search algorithms for counterfactual explanations\nbased upon mixed integer programming. We are concerned with complex data in\nwhich variables may take any value from a contiguous range or an additional set\nof discrete states. We propose a novel set of constraints that we refer to as a\n\"mixed polytope\" and show how this can be used with an integer programming\nsolver to efficiently find coherent counterfactual explanations i.e. solutions\nthat are guaranteed to map back onto the underlying data structure, while\navoiding the need for brute-force enumeration. We also look at the problem of\ndiverse explanations and show how these can be generated within our framework.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 09:25:03 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Russell", "Chris", ""]]}, {"id": "1901.04927", "submitter": "Clement Atzberger", "authors": "Chrisgone Adede, Robert Oboko, Peter Wagacha and Clement Atzberger", "title": "A mixed model approach to drought prediction using artificial neural\n  networks: Case of an operational drought monitoring environment", "comments": "18 pages, 13 figures and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Droughts, with their increasing frequency of occurrence, continue to\nnegatively affect livelihoods and elements at risk. For example, the 2011 in\ndrought in east Africa has caused massive losses document to have cost the\nKenyan economy over $12bn. With the foregoing, the demand for ex-ante drought\nmonitoring systems is ever-increasing. The study uses 10 precipitation and\nvegetation variables that are lagged over 1, 2 and 3-month time-steps to\npredict drought situations. In the model space search for the most predictive\nartificial neural network (ANN) model, as opposed to the traditional greedy\nsearch for the most predictive variables, we use the General Additive Model\n(GAM) approach. Together with a set of assumptions, we thereby reduce the\ncardinality of the space of models. Even though we build a total of 102 GAM\nmodels, only 21 have R2 greater than 0.7 and are thus subjected to the ANN\nprocess. The ANN process itself uses the brute-force approach that\nautomatically partitions the training data into 10 sub-samples, builds the ANN\nmodels in these samples and evaluates their performance using multiple metrics.\nThe results show the superiority of 1-month lag of the variables as compared to\nlonger time lags of 2 and 3 months. The champion ANN model recorded an R2 of\n0.78 in model testing using the out-of-sample data. This illustrates its\nability to be a good predictor of drought situations 1-month ahead.\nInvestigated as a classifier, the champion has a modest accuracy of 66% and a\nmulti-class area under the ROC curve (AUROC) of 89.99%\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 20:16:56 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Adede", "Chrisgone", ""], ["Oboko", "Robert", ""], ["Wagacha", "Peter", ""], ["Atzberger", "Clement", ""]]}, {"id": "1901.04966", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Ofir Nachum", "title": "Identifying and Correcting Label Bias in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets often contain biases which unfairly disadvantage certain groups, and\nclassifiers trained on such datasets can inherit these biases. In this paper,\nwe provide a mathematical formulation of how this bias can arise. We do so by\nassuming the existence of underlying, unknown, and unbiased labels which are\noverwritten by an agent who intends to provide accurate labels but may have\nbiases against certain groups. Despite the fact that we only observe the biased\nlabels, we are able to show that the bias may nevertheless be corrected by\nre-weighting the data points without changing the labels. We show, with\ntheoretical guarantees, that training on the re-weighted dataset corresponds to\ntraining on the unobserved but unbiased labels, thus leading to an unbiased\nmachine learning classifier. Our procedure is fast and robust and can be used\nwith virtually any learning algorithm. We evaluate on a number of standard\nmachine learning fairness datasets and a variety of fairness notions, finding\nthat our method outperforms standard approaches in achieving fair\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 18:40:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Jiang", "Heinrich", ""], ["Nachum", "Ofir", ""]]}, {"id": "1901.04992", "submitter": "Fabrizio Angiulli", "authors": "Fabrizio Angiulli", "title": "CFOF: A Concentration Free Measure for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel notion of outlier, called the Concentration Free Outlier\nFactor, or CFOF. As a main contribution, we formalize the notion of\nconcentration of outlier scores and theoretically prove that CFOF does not\nconcentrate in the Euclidean space for any arbitrary large dimensionality. To\nthe best of our knowledge, there are no other proposals of data analysis\nmeasures related to the Euclidean distance for which it has been provided\ntheoretical evidence that they are immune to the concentration effect. We\ndetermine the closed form of the distribution of CFOF scores in arbitrarily\nlarge dimensionalities and show that the CFOF score of a point depends on its\nsquared norm standard score and on the kurtosis of the data distribution, thus\nproviding a clear and statistically founded characterization of this notion.\nMoreover, we leverage this closed form to provide evidence that the definition\ndoes not suffer of the hubness problem affecting other measures. We prove that\nthe number of CFOF outliers coming from each cluster is proportional to cluster\nsize and kurtosis, a property that we call semi-locality. We determine that\nsemi-locality characterizes existing reverse nearest neighbor-based outlier\ndefinitions, thus clarifying the exact nature of their observed local behavior.\nWe also formally prove that classical distance-based and density-based outliers\nconcentrate both for bounded and unbounded sample sizes and for fixed and\nvariable values of the neighborhood parameter. We introduce the fast-CFOF\nalgorithm for detecting outliers in large high-dimensional dataset. The\nalgorithm has linear cost, supports multi-resolution analysis, and is\nembarrassingly parallel. Experiments highlight that the technique is able to\nefficiently process huge datasets and to deal even with large values of the\nneighborhood parameter, to avoid concentration, and to obtain excellent\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 18:01:32 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 10:43:00 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Angiulli", "Fabrizio", ""]]}, {"id": "1901.04993", "submitter": "Xinli Yu T", "authors": "Xinli Yu, Zheng Chen, Wei-Shih Yang, Xiaohua Hu, Erjia Yan", "title": "Large-Scale Joint Topic, Sentiment & User Preference Analysis for Online\n  Reviews", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2017.8258000", "report-no": null, "categories": "cs.IR cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a non-trivial reconstruction of a previous joint\ntopic-sentiment-preference review model TSPRA with stick-breaking\nrepresentation under the framework of variational inference (VI) and stochastic\nvariational inference (SVI). TSPRA is a Gibbs Sampling based model that solves\ntopics, word sentiments and user preferences altogether and has been shown to\nachieve good performance, but for large data set it can only learn from a\nrelatively small sample. We develop the variational models vTSPRA and svTSPRA\nto improve the time use, and our new approach is capable of processing millions\nof reviews. We rebuild the generative process, improve the rating regression,\nsolve and present the coordinate-ascent updates of variational parameters, and\nshow the time complexity of each iteration is theoretically linear to the\ncorpus size, and the experiments on Amazon data sets show it converges faster\nthan TSPRA and attains better results given the same amount of time. In\naddition, we tune svTSPRA into an online algorithm ovTSPRA that can monitor\noscillations of sentiment and preference overtime. Some interesting\nfluctuations are captured and possible explanations are provided. The results\ngive strong visual evidence that user preference is better treated as an\nindependent factor from sentiment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 20:33:20 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Yu", "Xinli", ""], ["Chen", "Zheng", ""], ["Yang", "Wei-Shih", ""], ["Hu", "Xiaohua", ""], ["Yan", "Erjia", ""]]}, {"id": "1901.04997", "submitter": "Dan Li", "authors": "Dan Li, Dacheng Chen, Lei Shi, Baihong Jin, Jonathan Goh, and\n  See-Kiong Ng", "title": "MAD-GAN: Multivariate Anomaly Detection for Time Series Data with\n  Generative Adversarial Networks", "comments": "This is a pre-print of an on-going work. arXiv admin note: text\n  overlap with arXiv:1809.04758", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of networked sensors and actuators in many real-world systems\nsuch as smart buildings, factories, power plants, and data centers generate\nsubstantial amounts of multivariate time series data for these systems. The\nrich sensor data can be continuously monitored for intrusion events through\nanomaly detection. However, conventional threshold-based anomaly detection\nmethods are inadequate due to the dynamic complexities of these systems, while\nsupervised machine learning methods are unable to exploit the large amounts of\ndata due to the lack of labeled data. On the other hand, current unsupervised\nmachine learning approaches have not fully exploited the spatial-temporal\ncorrelation and other dependencies amongst the multiple variables\n(sensors/actuators) in the system for detecting anomalies. In this work, we\npropose an unsupervised multivariate anomaly detection method based on\nGenerative Adversarial Networks (GANs). Instead of treating each data stream\nindependently, our proposed MAD-GAN framework considers the entire variable set\nconcurrently to capture the latent interactions amongst the variables. We also\nfully exploit both the generator and discriminator produced by the GAN, using a\nnovel anomaly score called DR-score to detect anomalies by discrimination and\nreconstruction. We have tested our proposed MAD-GAN using two recent datasets\ncollected from real-world CPS: the Secure Water Treatment (SWaT) and the Water\nDistribution (WADI) datasets. Our experimental results showed that the proposed\nMAD-GAN is effective in reporting anomalies caused by various cyber-intrusions\ncompared in these complex real-world systems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 08:24:45 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Li", "Dan", ""], ["Chen", "Dacheng", ""], ["Shi", "Lei", ""], ["Jin", "Baihong", ""], ["Goh", "Jonathan", ""], ["Ng", "See-Kiong", ""]]}, {"id": "1901.05049", "submitter": "Miguel de Prado", "authors": "Miguel de Prado, Jing Su, Rabia Saeed, Lorenzo Keller, Noelia Vallez,\n  Andrew Anderson, David Gregg, Luca Benini, Tim Llewellynn, Nabil Ouerhani,\n  Rozenn Dahyot and, Nuria Pazos", "title": "Bonseyes AI Pipeline -- bringing AI to you. End-to-end integration of\n  data, algorithms and deployment tools", "comments": null, "journal-ref": null, "doi": "10.1145/3403572", "report-no": null, "categories": "cs.LG cs.DC cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation of embedded Information and Communication Technology (ICT)\nsystems are collaborative systems able to perform autonomous tasks. The\nremarkable expansion of the embedded ICT market, together with the rise and\nbreakthroughs of Artificial Intelligence (AI), have put the focus on the Edge\nas it stands as one of the keys for the next technological revolution: the\nseamless integration of AI in our daily life. However, training and deployment\nof custom AI solutions on embedded devices require a fine-grained integration\nof data, algorithms, and tools to achieve high accuracy. Such integration\nrequires a high level of expertise that becomes a real bottleneck for small and\nmedium enterprises wanting to deploy AI solutions on the Edge which,\nultimately, slows down the adoption of AI on daily-life applications. In this\nwork, we present a modular AI pipeline as an integrating framework to bring\ndata, algorithms, and deployment tools together. By removing the integration\nbarriers and lowering the required expertise, we can interconnect the different\nstages of tools and provide a modular end-to-end development of AI products for\nembedded devices. Our AI pipeline consists of four modular main steps: i) data\ningestion, ii) model training, iii) deployment optimization and, iv) the IoT\nhub integration. To show the effectiveness of our pipeline, we provide examples\nof different AI applications during each of the steps. Besides, we integrate\nour deployment framework, LPDNN, into the AI pipeline and present its\nlightweight architecture and deployment capabilities for embedded devices.\nFinally, we demonstrate the results of the AI pipeline by showing the\ndeployment of several AI applications such as keyword spotting, image\nclassification and object detection on a set of well-known embedded platforms,\nwhere LPDNN consistently outperforms all other popular deployment frameworks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 21:27:28 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 08:12:04 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 06:41:02 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["de Prado", "Miguel", ""], ["Su", "Jing", ""], ["Saeed", "Rabia", ""], ["Keller", "Lorenzo", ""], ["Vallez", "Noelia", ""], ["Anderson", "Andrew", ""], ["Gregg", "David", ""], ["Benini", "Luca", ""], ["Llewellynn", "Tim", ""], ["Ouerhani", "Nabil", ""], ["and", "Rozenn Dahyot", ""], ["Pazos", "Nuria", ""]]}, {"id": "1901.05051", "submitter": "Pierre-Philippe Dechant", "authors": "Pierre-Philippe Dechant and Yang-Hui He", "title": "Machine-learning a virus assembly fitness landscape", "comments": "13 pages, 4 figures", "journal-ref": "PLoS ONE 16(5): e0250227 (2021)", "doi": "10.1371/journal.pone.0250227", "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic evolutionary fitness landscapes are notoriously difficult to\nconstruct. A recent cutting-edge model of virus assembly consists of a\ndodecahedral capsid with $12$ corresponding packaging signals in three affinity\nbands. This whole genome/phenotype space consisting of $3^{12}$ genomes has\nbeen explored via computationally expensive stochastic assembly models, giving\na fitness landscape in terms of the assembly efficiency. Using latest\nmachine-learning techniques by establishing a neural network, we show that the\nintensive computation can be short-circuited in a matter of minutes to\nastounding accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 12:17:02 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Dechant", "Pierre-Philippe", ""], ["He", "Yang-Hui", ""]]}, {"id": "1901.05052", "submitter": "Jonathan Dumas", "authors": "Jonathan Dumas and Bertrand Corn\\'elusse", "title": "Classification of load forecasting studies by forecasting problem to\n  select load forecasting techniques and methodologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key contribution of this paper is to propose a classification into two\ndimensions of the load forecasting studies to decide which forecasting tools to\nuse in which case. This classification aims to provide a synthetic view of the\nrelevant forecasting techniques and methodologies by forecasting problem. In\naddition, the key principles of the main techniques and methodologies used are\nsummarized along with the reviews of these papers.\n  The classification process relies on two couples of parameters that define a\nforecasting problem. Each article is classified with key information about the\ndataset used and the forecasting tools implemented: the forecasting techniques\n(probabilistic or deterministic) and methodologies, the data cleansing\ntechniques, and the error metrics.\n  The process to select the articles reviewed in this paper was conducted into\ntwo steps. First, a set of load forecasting studies was built based on relevant\nload forecasting reviews and forecasting competitions. The second step\nconsisted in selecting the most relevant studies of this set based on the\nfollowing criteria: the quality of the description of the forecasting\ntechniques and methodologies implemented, the description of the results, and\nthe contributions.\n  This paper can be read in two passes. The first one by identifying the\nforecasting problem of interest to select the corresponding class into one of\nthe four classification tables. Each one references all the articles classified\nacross a forecasting horizon. They provide a synthetic view of the forecasting\ntools used by articles addressing similar forecasting problems. Then, a second\nlevel composed of four Tables summarizes key information about the forecasting\ntools and the results of these studies. The second pass consists in reading the\nkey principles of the main techniques and methodologies of interest and the\nreviews of the articles.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 10:03:16 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 15:05:34 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Dumas", "Jonathan", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "1901.05061", "submitter": "Abhimanyu Sahai", "authors": "Abhimanyu Sahai, Romann Weber, Brian McWilliams", "title": "Spectrogram Feature Losses for Music Source Separation", "comments": "Accepted for presentation at the 27th European Signal Processing\n  Conference (EUSIPCO 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study deep learning-based music source separation, and\nexplore using an alternative loss to the standard spectrogram pixel-level L2\nloss for model training. Our main contribution is in demonstrating that adding\na high-level feature loss term, extracted from the spectrograms using a VGG\nnet, can improve separation quality vis-a-vis a pure pixel-level loss. We show\nthis improvement in the context of the MMDenseNet, a State-of-the-Art deep\nlearning model for this task, for the extraction of drums and vocal sounds from\nsongs in the musdb18 database, covering a broad range of western music genres.\nWe believe that this finding can be generalized and applied to broader machine\nlearning-based systems in the audio domain.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 21:51:12 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 08:10:30 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 19:15:47 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Sahai", "Abhimanyu", ""], ["Weber", "Romann", ""], ["McWilliams", "Brian", ""]]}, {"id": "1901.05101", "submitter": "Jacob Beck", "authors": "Jacob Beck, Zoe Papakipos, Michael Littman", "title": "ReNeg and Backseat Driver: Learning from Demonstration with Continuous\n  Human Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous vehicle (AV) control, allowing mistakes can be quite dangerous\nand costly in the real world. For this reason we investigate methods of\ntraining an AV without allowing the agent to explore and instead having a human\nexplorer collect the data. Supervised learning has been explored for AV\ncontrol, but it encounters the issue of the covariate shift. That is, training\ndata collected from an optimal demonstration consists only of the states\ninduced by the optimal control policy, but at runtime, the trained agent may\nencounter a vastly different state distribution with little relevant training\ndata. To mitigate this issue, we have our human explorer make sub-optimal\ndecisions. In order to have our agent not replicate these sub-optimal\ndecisions, supervised learning requires that we either erase these actions, or\nreplace these action with the correct action. Erasing is wasteful and replacing\nis difficult, since it is not easy to know the correct action without driving.\nWe propose an alternate framework that includes continuous scalar feedback for\neach action, marking which actions we should replicate, which we should avoid,\nand how sure we are. Our framework learns continuous control from sub-optimal\ndemonstration and evaluative feedback collected before training. We find that a\nhuman demonstrator can explore sub-optimal states in a safe manner, while still\ngetting enough gradation to benefit learning. The collection method for data\nand feedback we call \"Backseat Driver.\" We call the more general learning\nframework ReNeg, since it learns a regression from states to actions given\nnegative as well as positive examples. We empirically validate several models\nin the ReNeg framework, testing on lane-following with limited data. We find\nthat the best solution is a generalization of mean-squared error and\noutperforms supervised learning on the positive examples alone.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:20:00 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Beck", "Jacob", ""], ["Papakipos", "Zoe", ""], ["Littman", "Michael", ""]]}, {"id": "1901.05123", "submitter": "Simon Denman", "authors": "Tharindu Fernando, Simon Denman, Sridha Sridharan, Clinton Fookes", "title": "Memory Augmented Deep Generative models for Forecasting the Next Shot\n  Location in Tennis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework for predicting shot location and type\nin tennis. Inspired by recent neuroscience discoveries we incorporate neural\nmemory modules to model the episodic and semantic memory components of a tennis\nplayer. We propose a Semi Supervised Generative Adversarial Network\narchitecture that couples these memory models with the automatic feature\nlearning power of deep neural networks and demonstrate methodologies for\nlearning player level behavioural patterns with the proposed framework. We\nevaluate the effectiveness of the proposed model on tennis tracking data from\nthe 2012 Australian Tennis open and exhibit applications of the proposed method\nin discovering how players adapt their style depending on the match context.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 03:16:28 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""]]}, {"id": "1901.05125", "submitter": "Dan Lu", "authors": "Dan Lu, Daniel Ricciuto", "title": "Efficient surrogate modeling methods for large-scale Earth system models\n  based on machine learning techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving predictive understanding of Earth system variability and change\nrequires data-model integration. Efficient data-model integration for complex\nmodels requires surrogate modeling to reduce model evaluation time. However,\nbuilding a surrogate of a large-scale Earth system model (ESM) with many output\nvariables is computationally intensive because it involves a large number of\nexpensive ESM simulations. In this effort, we propose an efficient surrogate\nmethod capable of using a few ESM runs to build an accurate and\nfast-to-evaluate surrogate system of model outputs over large spatial and\ntemporal domains. We first use singular value decomposition to reduce the\noutput dimensions, and then use Bayesian optimization techniques to generate an\naccurate neural network surrogate model based on limited ESM simulation\nsamples. Our machine learning based surrogate methods can build and evaluate a\nlarge surrogate system of many variables quickly. Thus, whenever the quantities\nof interest change such as a different objective function, a new site, and a\nlonger simulation time, we can simply extract the information of interest from\nthe surrogate system without rebuilding new surrogates, which significantly\nsaves computational efforts. We apply the proposed method to a regional\necosystem model to approximate the relationship between 8 model parameters and\n42660 carbon flux outputs. Results indicate that using only 20 model\nsimulations, we can build an accurate surrogate system of the 42660 variables,\nwhere the consistency between the surrogate prediction and actual model\nsimulation is 0.93 and the mean squared error is 0.02. This highly-accurate and\nfast-to-evaluate surrogate system will greatly enhance the computational\nefficiency in data-model integration to improve predictions and advance our\nunderstanding of the Earth system.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 03:22:38 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Lu", "Dan", ""], ["Ricciuto", "Daniel", ""]]}, {"id": "1901.05147", "submitter": "Anna Guitart", "authors": "Anna Guitart, Pei Pei Chen and \\'Africa Peri\\'a\\~nez", "title": "The Winning Solution to the IEEE CIG 2017 Game Data Mining Competition", "comments": null, "journal-ref": "Machine Learning and Knowledge Extraction, 1(1), 252--264, 2019", "doi": "10.3390/make1010016", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning competitions such as those organized by Kaggle or KDD\nrepresent a useful benchmark for data science research. In this work, we\npresent our winning solution to the Game Data Mining competition hosted at the\n2017 IEEE Conference on Computational Intelligence and Games (CIG 2017). The\ncontest consisted of two tracks, and participants (more than 250, belonging to\nboth industry and academia) were to predict which players would stop playing\nthe game, as well as their remaining lifetime. The data were provided by a\nmajor worldwide video game company, NCSoft, and came from their successful\nmassively multiplayer online game Blade and Soul. Here, we describe the long\nshort-term memory approach and conditional inference survival ensemble model\nthat made us win both tracks of the contest, as well as the validation\nprocedure that we followed in order to prevent overfitting. In particular,\nchoosing a survival method able to deal with censored data was crucial to\naccurately predict the moment in which each player would leave the game, as\ncensoring is inherent in churn. The selected models proved to be robust against\nevolving conditions---since there was a change in the business model of the\ngame (from subscription-based to free-to-play) between the two sample datasets\nprovided---and efficient in terms of time cost. Thanks to these features and\nalso to their a ability to scale to large datasets, our models could be readily\nimplemented in real business settings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 06:10:45 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Guitart", "Anna", ""], ["Chen", "Pei Pei", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1901.05230", "submitter": "Gian Luca Giorgi", "authors": "Gabriel Garau Estarellas, Gian Luca Giorgi, Miguel C. Soriano, and\n  Roberta Zambrini", "title": "Machine learning applied to quantum synchronization-assisted probing", "comments": null, "journal-ref": "Advanced Quantum Technologies 1800085 (2019)", "doi": "10.1002/qute.201800085", "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probing scheme is considered with an accessible and controllable qubit,\nused to probe an out-of equilibrium system consisting of a second qubit\ninteracting with an environment. Quantum spontaneous synchronization between\nthe probe and the system emerges in this model and, by tuning the probe\nfrequency, can occur both in-phase and in anti-phase. We analyze the capability\nof machine learning in this probing scheme based on quantum synchronization. An\nartificial neural network is used to infer, from a probe observable, main\ndissipation features, such as the environment Ohmicity index. The efficiency of\nthe algorithm in the presence of some noise in the dataset is also considered.\nWe show that the performance in either classification and regression is\nsignificantly improved due to the in/anti-phase synchronization transition.\nThis opens the way to the characterization of environments with arbitrary\nspectral densities.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 11:03:23 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Estarellas", "Gabriel Garau", ""], ["Giorgi", "Gian Luca", ""], ["Soriano", "Miguel C.", ""], ["Zambrini", "Roberta", ""]]}, {"id": "1901.05335", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Marco Loog", "title": "A review of domain adaptation without target labels", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": "10.1109/TPAMI.2019.2945942", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation has become a prominent problem setting in machine learning\nand related fields. This review asks the question: how can a classifier learn\nfrom a source domain and generalize to a target domain? We present a\ncategorization of approaches, divided into, what we refer to as, sample-based,\nfeature-based and inference-based methods. Sample-based methods focus on\nweighting individual observations during training based on their importance to\nthe target domain. Feature-based methods revolve around on mapping, projecting\nand representing features such that a source classifier performs well on the\ntarget domain and inference-based methods incorporate adaptation into the\nparameter estimation procedure, for instance through constraints on the\noptimization procedure. Additionally, we review a number of conditions that\nallow for formulating bounds on the cross-domain generalization error. Our\ncategorization highlights recurring ideas and raises questions important to\nfurther research.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:13:29 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 18:12:54 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Loog", "Marco", ""]]}, {"id": "1901.05351", "submitter": "Sephora Madjiheurem", "authors": "Sephora Madjiheurem, Laura Toni", "title": "Representation Learning on Graphs: A Reinforcement Learning Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study value function approximation in reinforcement learning\n(RL) problems with high dimensional state or action spaces via a generalized\nversion of representation policy iteration (RPI). We consider the limitations\nof proto-value functions (PVFs) at accurately approximating the value function\nin low dimensions and we highlight the importance of features learning for an\nimproved low-dimensional value function approximation. Then, we adopt different\nrepresentation learning algorithm on graphs to learn the basis functions that\nbest represent the value function. We empirically show that node2vec, an\nalgorithm for scalable feature learning in networks, and the Variational Graph\nAuto-Encoder constantly outperform the commonly used smooth proto-value\nfunctions in low-dimensional feature space.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:44:13 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 08:15:44 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Madjiheurem", "Sephora", ""], ["Toni", "Laura", ""]]}, {"id": "1901.05353", "submitter": "Benjamin Guedj", "authors": "Benjamin Guedj", "title": "A Primer on PAC-Bayesian Learning", "comments": null, "journal-ref": "Proceedings of the 2nd congress of the Soci\\'et\\'e Math\\'ematique\n  de France, 2019, pp. 391--414", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generalised Bayesian learning algorithms are increasingly popular in machine\nlearning, due to their PAC generalisation properties and flexibility. The\npresent paper aims at providing a self-contained survey on the resulting\nPAC-Bayes framework and some of its main theoretical and algorithmic\ndevelopments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:47:51 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2019 22:12:21 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 21:11:16 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Guedj", "Benjamin", ""]]}, {"id": "1901.05356", "submitter": "Christine Anderson-Cook", "authors": "Christine M. Anderson-Cook, Kary L. Myers, Lu Lu, Michael L. Fugate,\n  Kevin R. Quinlan, Norma Pawley", "title": "How to Host a Data Competition: Statistical Advice for Design and\n  Analysis of a Data Competition", "comments": "36 pages", "journal-ref": null, "doi": "10.1002/sam.11404", "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data competitions rely on real-time leaderboards to rank competitor entries\nand stimulate algorithm improvement. While such competitions have become quite\npopular and prevalent, particularly in supervised learning formats, their\nimplementations by the host are highly variable. Without careful planning, a\nsupervised learning competition is vulnerable to overfitting, where the winning\nsolutions are so closely tuned to the particular set of provided data that they\ncannot generalize to the underlying problem of interest to the host. This paper\noutlines some important considerations for strategically designing relevant and\ninformative data sets to maximize the learning outcome from hosting a\ncompetition based on our experience. It also describes a post-competition\nanalysis that enables robust and efficient assessment of the strengths and\nweaknesses of solutions from different competitors, as well as greater\nunderstanding of the regions of the input space that are well-solved. The\npost-competition analysis, which complements the leaderboard, uses exploratory\ndata analysis and generalized linear models (GLMs). The GLMs not only expand\nthe range of results we can explore, they also provide more detailed analysis\nof individual sub-questions including similarities and differences between\nalgorithms across different types of scenarios, universally easy or hard\nregions of the input space, and different learning objectives. When coupled\nwith a strategically planned data generation approach, the methods provide\nricher and more informative summaries to enhance the interpretation of results\nbeyond just the rankings on the leaderboard. The methods are illustrated with a\nrecently completed competition to evaluate algorithms capable of detecting,\nidentifying, and locating radioactive materials in an urban environment.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:56:19 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Anderson-Cook", "Christine M.", ""], ["Myers", "Kary L.", ""], ["Lu", "Lu", ""], ["Fugate", "Michael L.", ""], ["Quinlan", "Kevin R.", ""], ["Pawley", "Norma", ""]]}, {"id": "1901.05415", "submitter": "Braden Hancock", "authors": "Braden Hancock, Antoine Bordes, Pierre-Emmanuel Mazar\\'e, Jason Weston", "title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of conversations a dialogue agent sees over its lifetime occur\nafter it has already been trained and deployed, leaving a vast store of\npotential training signal untapped. In this work, we propose the self-feeding\nchatbot, a dialogue agent with the ability to extract new training examples\nfrom the conversations it participates in. As our agent engages in\nconversation, it also estimates user satisfaction in its responses. When the\nconversation appears to be going well, the user's responses become new training\nexamples to imitate. When the agent believes it has made a mistake, it asks for\nfeedback; learning to predict the feedback that will be given improves the\nchatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with\nover 131k training examples, we find that learning from dialogue with a\nself-feeding chatbot significantly improves performance, regardless of the\namount of traditional supervision.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:02:44 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 07:03:17 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 03:23:04 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 06:01:04 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Hancock", "Braden", ""], ["Bordes", "Antoine", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Weston", "Jason", ""]]}, {"id": "1901.05498", "submitter": "Yannick Roy", "authors": "Yannick Roy, Hubert Banville, Isabela Albuquerque, Alexandre Gramfort,\n  Tiago H. Falk, Jocelyn Faubert", "title": "Deep learning-based electroencephalography analysis: a systematic review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is a complex signal and can require several\nyears of training to be correctly interpreted. Recently, deep learning (DL) has\nshown great promise in helping make sense of EEG signals due to its capacity to\nlearn good feature representations from raw data. Whether DL truly presents\nadvantages as compared to more traditional EEG processing approaches, however,\nremains an open question. In this work, we review 156 papers that apply DL to\nEEG, published between January 2010 and July 2018, and spanning different\napplication domains such as epilepsy, sleep, brain-computer interfacing, and\ncognitive and affective monitoring. We extract trends and highlight interesting\napproaches in order to inform future research and formulate recommendations.\nVarious data items were extracted for each study pertaining to 1) the data, 2)\nthe preprocessing methodology, 3) the DL design choices, 4) the results, and 5)\nthe reproducibility of the experiments. Our analysis reveals that the amount of\nEEG data used across studies varies from less than ten minutes to thousands of\nhours. As for the model, 40% of the studies used convolutional neural networks\n(CNNs), while 14% used recurrent neural networks (RNNs), most often with a\ntotal of 3 to 10 layers. Moreover, almost one-half of the studies trained their\nmodels on raw or preprocessed EEG time series. Finally, the median gain in\naccuracy of DL approaches over traditional baselines was 5.4% across all\nrelevant studies. More importantly, however, we noticed studies often suffer\nfrom poor reproducibility: a majority of papers would be hard or impossible to\nreproduce given the unavailability of their data and code. To help the field\nprogress, we provide a list of recommendations for future studies and we make\nour summary table of DL and EEG papers available and invite the community to\ncontribute.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:16:50 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 22:09:54 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Roy", "Yannick", ""], ["Banville", "Hubert", ""], ["Albuquerque", "Isabela", ""], ["Gramfort", "Alexandre", ""], ["Falk", "Tiago H.", ""], ["Faubert", "Jocelyn", ""]]}, {"id": "1901.05515", "submitter": "Alexander Golovnev", "authors": "Alexander Golovnev and D\\'avid P\\'al and Bal\\'azs Sz\\\"or\\'enyi", "title": "The information-theoretic value of unlabeled data in semi-supervised\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We quantify the separation between the numbers of labeled examples required\nto learn in two settings: Settings with and without the knowledge of the\ndistribution of the unlabeled data. More specifically, we prove a separation by\n$\\Theta(\\log n)$ multiplicative factor for the class of projections over the\nBoolean hypercube of dimension $n$. We prove that there is no separation for\nthe class of all functions on domain of any size.\n  Learning with the knowledge of the distribution (a.k.a. fixed-distribution\nlearning) can be viewed as an idealized scenario of semi-supervised learning\nwhere the number of unlabeled data points is so great that the unlabeled\ndistribution is known exactly. For this reason, we call the separation the\nvalue of unlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 20:08:01 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 19:03:52 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Golovnev", "Alexander", ""], ["P\u00e1l", "D\u00e1vid", ""], ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", ""]]}, {"id": "1901.05534", "submitter": "Junxian He", "authors": "Junxian He, Daniel Spokoyny, Graham Neubig, Taylor Berg-Kirkpatrick", "title": "Lagging Inference Networks and Posterior Collapse in Variational\n  Autoencoders", "comments": "ICLR 2019 Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) is a popular combination of deep latent\nvariable model and accompanying variational learning technique. By using a\nneural inference network to approximate the model's posterior on latent\nvariables, VAEs efficiently parameterize a lower bound on marginal data\nlikelihood that can be optimized directly via gradient methods. In practice,\nhowever, VAE training often results in a degenerate local optimum known as\n\"posterior collapse\" where the model learns to ignore the latent variable and\nthe approximate posterior mimics the prior. In this paper, we investigate\nposterior collapse from the perspective of training dynamics. We find that\nduring the initial stages of training the inference network fails to\napproximate the model's true posterior, which is a moving target. As a result,\nthe model is encouraged to ignore the latent encoding and posterior collapse\noccurs. Based on this observation, we propose an extremely simple modification\nto VAE training to reduce inference lag: depending on the model's current\nmutual information between latent variable and observation, we aggressively\noptimize the inference network before performing each model update. Despite\nintroducing neither new model components nor significant complexity over basic\nVAE, our approach is able to avoid the problem of collapse that has plagued a\nlarge amount of previous work. Empirically, our approach outperforms strong\nautoregressive baselines on text and image benchmarks in terms of held-out\nlikelihood, and is competitive with more complex techniques for avoiding\ncollapse while being substantially faster.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 21:32:33 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 19:16:09 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["He", "Junxian", ""], ["Spokoyny", "Daniel", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1901.05560", "submitter": "Mingyang Hu", "authors": "Randell Cotta, Mingyang Hu, Dan Jiang and Peizhou Liao", "title": "Off-Policy Evaluation of Probabilistic Identity Data in Lookalike\n  Modeling", "comments": "Accepted by WSDM 2019", "journal-ref": null, "doi": "10.1145/3289600.3291033", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the impact of probabilistically-constructed digital identity data\ncollected from Sep. to Dec. 2017 (approx.), in the context of\nLookalike-targeted campaigns. The backbone of this study is a large set of\nprobabilistically-constructed \"identities\", represented as small bags of\ncookies and mobile ad identifiers with associated metadata, that are likely all\nowned by the same underlying user. The identity data allows to generate\n\"identity-based\", rather than \"identifier-based\", user models, giving a fuller\npicture of the interests of the users underlying the identifiers. We employ\noff-policy techniques to evaluate the potential of identity-powered lookalike\nmodels without incurring the risk of allowing untested models to direct large\namounts of ad spend or the large cost of performing A/B tests. We add to\nhistorical work on off-policy evaluation by noting a significant type of\n\"finite-sample bias\" that occurs for studies combining modestly-sized datasets\nand evaluation metrics involving rare events (e.g., conversions). We illustrate\nthis bias using a simulation study that later informs the handling of inverse\npropensity weights in our analyses on real data. We demonstrate significant\nlift in identity-powered lookalikes versus an identity-ignorant baseline: on\naverage ~70% lift in conversion rate. This rises to factors of ~(4-32)x for\nidentifiers having little data themselves, but that can be inferred to belong\nto users with substantial data to aggregate across identifiers. This implies\nthat identity-powered user modeling is especially important in the context of\nidentifiers having very short lifespans (i.e., frequently churned cookies). Our\nwork motivates and informs the use of probabilistically-constructed identities\nin marketing. It also deepens the canon of examples in which off-policy\nlearning has been employed to evaluate the complex systems of the internet\neconomy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 02:56:36 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Cotta", "Randell", ""], ["Hu", "Mingyang", ""], ["Jiang", "Dan", ""], ["Liao", "Peizhou", ""]]}, {"id": "1901.05577", "submitter": "Neil Veira", "authors": "Thang Doan, Neil Veira, Saibal Ray, Brian Keng", "title": "Generating Realistic Sequences of Customer-level Transactions for Retail\n  Datasets", "comments": "Published at IEEE ICDM Workshop on Data Mining for Services 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to better engage with customers, retailers rely on extensive\ncustomer and product databases which allows them to better understand customer\nbehaviour and purchasing patterns. This has long been a challenging task as\ncustomer modelling is a multi-faceted, noisy and time-dependent problem. The\nmost common way to tackle this problem is indirectly through task-specific\nsupervised learning prediction problems, with relatively little literature on\nmodelling a customer by directly simulating their future transactions. In this\npaper we propose a method for generating realistic sequences of baskets that a\ngiven customer is likely to purchase over a period of time. Customer embedding\nrepresentations are learned using a Recurrent Neural Network (RNN) which takes\ninto account the entire sequence of transaction data. Given the customer state\nat a specific point in time, a Generative Adversarial Network (GAN) is trained\nto generate a plausible basket of products for the following week. The newly\ngenerated basket is then fed back into the RNN to update the customer's state.\nThe GAN is thus used in tandem with the RNN module in a pipeline alternating\nbetween basket generation and customer state updating steps. This allows for\nsampling over a distribution of a customer's future sequence of baskets, which\nthen can be used to gain insight into how to service the customer more\neffectively. The methodology is empirically shown to produce baskets that\nappear similar to real baskets and enjoy many common properties, including\nfrequencies of different product types, brands, and prices. Furthermore, the\ngenerated data is able to replicate most of the strongest sequential patterns\nthat exist between product types in the real data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 01:24:24 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 03:05:24 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Doan", "Thang", ""], ["Veira", "Neil", ""], ["Ray", "Saibal", ""], ["Keng", "Brian", ""]]}, {"id": "1901.05582", "submitter": "Mohammad Samragh", "authors": "Mohammad Samragh, Mojan Javaheripi, Farinaz Koushanfar", "title": "CodeX: Bit-Flexible Encoding for Streaming-based FPGA Acceleration of\n  DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes CodeX, an end-to-end framework that facilitates encoding,\nbitwidth customization, fine-tuning, and implementation of neural networks on\nFPGA platforms. CodeX incorporates nonlinear encoding to the computation flow\nof neural networks to save memory. The encoded features demand significantly\nlower storage compared to the raw full-precision activation values; therefore,\nthe execution flow of CodeX hardware engine is completely performed within the\nFPGA using on-chip streaming buffers with no access to the off-chip DRAM. We\nfurther propose a fully-automated algorithm inspired by reinforcement learning\nwhich determines the customized encoding bitwidth across network layers. CodeX\nfull-stack framework comprises of a compiler which takes a high-level Python\ndescription of an arbitrary neural network architecture. The compiler then\ninstantiates the corresponding elements from CodeX Hardware library for FPGA\nimplementation. Proof-of-concept evaluations on MNIST, SVHN, and CIFAR-10\ndatasets demonstrate an average of 4.65x throughput improvement compared to\nstand-alone weight encoding. We further compare CodeX with six existing\nfull-precision DNN accelerators on ImageNet, showing an average of 3.6x and\n2.54x improvement in throughput and performance-per-watt, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 01:34:26 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Samragh", "Mohammad", ""], ["Javaheripi", "Mojan", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1901.05590", "submitter": "William Whitney", "authors": "William F. Whitney and Rob Fergus", "title": "Disentangling Video with Independent Prediction", "comments": "Presented at the Learning Disentangled Representations: from\n  Perception to Control workshop at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised variational model for disentangling video into\nindependent factors, i.e. each factor's future can be predicted from its past\nwithout considering the others. We show that our approach often learns factors\nwhich are interpretable as objects in a scene.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 02:21:24 GMT"}], "update_date": "2019-01-27", "authors_parsed": [["Whitney", "William F.", ""], ["Fergus", "Rob", ""]]}, {"id": "1901.05593", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Hongming Shan, Mannudeep K. Kalra, Ramandeep Singh, Guhan\n  Qian, Matthew Getzin, Yueyang Teng, Juergen Hahn, and Ge Wang", "title": "Quadratic Autoencoder (Q-AE) for Low-dose CT Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by complexity and diversity of biological neurons, our group\nproposed quadratic neurons by replacing the inner product in current artificial\nneurons with a quadratic operation on input data, thereby enhancing the\ncapability of an individual neuron. Along this direction, we are motivated to\nevaluate the power of quadratic neurons in popular network architectures,\nsimulating human-like learning in the form of quadratic-neuron-based deep\nlearning. Our prior theoretical studies have shown important merits of\nquadratic neurons and networks in representation, efficiency, and\ninterpretability. In this paper, we use quadratic neurons to construct an\nencoder-decoder structure, referred as the quadratic autoencoder, and apply it\nto low-dose CT denoising. The experimental results on the Mayo low-dose CT\ndataset demonstrate the utility of quadratic autoencoder in terms of image\ndenoising and model efficiency. To our best knowledge, this is the first time\nthat the deep learning approach is implemented with a new type of neurons and\ndemonstrates a significant potential in the medical imaging field.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 02:44:54 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 22:49:47 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2019 02:09:34 GMT"}, {"version": "v4", "created": "Thu, 24 Oct 2019 00:17:02 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2019 19:42:27 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Fan", "Fenglei", ""], ["Shan", "Hongming", ""], ["Kalra", "Mannudeep K.", ""], ["Singh", "Ramandeep", ""], ["Qian", "Guhan", ""], ["Getzin", "Matthew", ""], ["Teng", "Yueyang", ""], ["Hahn", "Juergen", ""], ["Wang", "Ge", ""]]}, {"id": "1901.05599", "submitter": "Michael Iuzzolino", "authors": "Michael L. Iuzzolino, Michael E. Walker, Daniel Szafir", "title": "Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails", "comments": "iROS 2018", "journal-ref": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS) (pp. 576-582)", "doi": "10.1109/IROS.2018.8593883", "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots hold promise in many scenarios involving outdoor use, such as\nsearch-and-rescue, wildlife management, and collecting data to improve\nenvironment, climate, and weather forecasting. However, autonomous navigation\nof outdoor trails remains a challenging problem. Recent work has sought to\naddress this issue using deep learning. Although this approach has achieved\nstate-of-the-art results, the deep learning paradigm may be limited due to a\nreliance on large amounts of annotated training data. Collecting and curating\ntraining datasets may not be feasible or practical in many situations,\nespecially as trail conditions may change due to seasonal weather variations,\nstorms, and natural erosion. In this paper, we explore an approach to address\nthis issue through virtual-to-real-world transfer learning using a variety of\ndeep learning models trained to classify the direction of a trail in an image.\nOur approach utilizes synthetic data gathered from virtual environments for\nmodel training, bypassing the need to collect a large amount of real images of\nthe outdoors. We validate our approach in three main ways. First, we\ndemonstrate that our models achieve classification accuracies upwards of 95% on\nour synthetic data set. Next, we utilize our classification models in the\ncontrol system of a simulated robot to demonstrate feasibility. Finally, we\nevaluate our models on real-world trail data and demonstrate the potential of\nvirtual-to-real-world transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 03:11:58 GMT"}], "update_date": "2019-01-27", "authors_parsed": [["Iuzzolino", "Michael L.", ""], ["Walker", "Michael E.", ""], ["Szafir", "Daniel", ""]]}, {"id": "1901.05639", "submitter": "Bernhard Mehlig", "authors": "B. Mehlig", "title": "Machine learning with neural networks", "comments": "Revised version, 285 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lecture notes for my course on machine learning with neural networks that I\nhave given at Gothenburg University and Chalmers Technical University in\nGothenburg, Sweden.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 06:26:32 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 14:01:29 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 13:22:16 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mehlig", "B.", ""]]}, {"id": "1901.05708", "submitter": "Reza Akbarinia", "authors": "Reza Akbarinia and Bertrand Cloez", "title": "Efficient Matrix Profile Computation Using Different Distance Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix profile has been recently proposed as a promising technique to the\nproblem of all-pairs-similarity search on time series. Efficient algorithms\nhave been proposed for computing it, e.g., STAMP, STOMP and SCRIMP++. All these\nalgorithms use the z-normalized Euclidean distance to measure the distance\nbetween subsequences. However, as we observed, for some datasets other\nEuclidean measurements are more useful for knowledge discovery from time\nseries. In this paper, we propose efficient algorithms for computing matrix\nprofile for a general class of Euclidean distances. We first propose a simple\nbut efficient algorithm called AAMP for computing matrix profile with the\n\"pure\" (non-normalized) Euclidean distance. Then, we extend our algorithm for\nthe p-norm distance. We also propose an algorithm, called ACAMP, that uses the\nsame principle as AAMP, but for the case of z-normalized Euclidean distance. We\nimplemented our algorithms, and evaluated their performance through\nexperimentation. The experiments show excellent performance results. For\nexample, they show that AAMP is very efficient for computing matrix profile for\nnon-normalized Euclidean distances. The results also show that the ACAMP\nalgorithm is significantly faster than SCRIMP++ (the state of the art matrix\nprofile algorithm) for the case of z-normalized Euclidean distance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 10:05:37 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Akbarinia", "Reza", ""], ["Cloez", "Bertrand", ""]]}, {"id": "1901.05737", "submitter": "Jan Scholz", "authors": "Jan Scholz", "title": "Genetic Algorithms and the Traveling Salesman Problem a historical\n  Review", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.22632.78088/1", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a highly abstracted view on the historical development of\nGenetic Algorithms for the Traveling Salesman Problem is given. In a meta-data\nanalysis three phases in the development can be distinguished. First\nexponential growth in interest till 1996 can be observed, growth stays linear\ntill 2011 and after that publications deteriorate. These three phases are\nexamined and the major milestones are presented. Lastly an outlook to future\nwork in this field is infered.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 11:35:13 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Scholz", "Jan", ""]]}, {"id": "1901.05744", "submitter": "Philipp Petersen", "authors": "Dominik Alfke, Weston Baines, Jan Blechschmidt, Mauricio J. del Razo\n  Sarmina, Amnon Drory, Dennis Elbr\\\"achter, Nando Farchmin, Matteo Gambara,\n  Silke Glas, Philipp Grohs, Peter Hinz, Danijel Kivaranovic, Christian\n  K\\\"ummerle, Gitta Kutyniok, Sebastian Lunz, Jan Macdonald, Ryan Malthaner,\n  Gregory Naisat, Ariel Neufeld, Philipp Christian Petersen, Rafael\n  Reisenhofer, Jun-Da Sheng, Laura Thesing, Philipp Trunschke, Johannes von\n  Lindheim, David Weber, Melanie Weber", "title": "The Oracle of DLphi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique based on deep learning and set theory which\nyields exceptional classification and prediction results. Having access to a\nsufficiently large amount of labelled training data, our methodology is capable\nof predicting the labels of the test data almost always even if the training\ndata is entirely unrelated to the test data. In other words, we prove in a\nspecific setting that as long as one has access to enough data points, the\nquality of the data is irrelevant.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 12:03:45 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 11:59:11 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Alfke", "Dominik", ""], ["Baines", "Weston", ""], ["Blechschmidt", "Jan", ""], ["Sarmina", "Mauricio J. del Razo", ""], ["Drory", "Amnon", ""], ["Elbr\u00e4chter", "Dennis", ""], ["Farchmin", "Nando", ""], ["Gambara", "Matteo", ""], ["Glas", "Silke", ""], ["Grohs", "Philipp", ""], ["Hinz", "Peter", ""], ["Kivaranovic", "Danijel", ""], ["K\u00fcmmerle", "Christian", ""], ["Kutyniok", "Gitta", ""], ["Lunz", "Sebastian", ""], ["Macdonald", "Jan", ""], ["Malthaner", "Ryan", ""], ["Naisat", "Gregory", ""], ["Neufeld", "Ariel", ""], ["Petersen", "Philipp Christian", ""], ["Reisenhofer", "Rafael", ""], ["Sheng", "Jun-Da", ""], ["Thesing", "Laura", ""], ["Trunschke", "Philipp", ""], ["von Lindheim", "Johannes", ""], ["Weber", "David", ""], ["Weber", "Melanie", ""]]}, {"id": "1901.05761", "submitter": "Hyunjik Kim", "authors": "Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami,\n  Dan Rosenbaum, Oriol Vinyals, Yee Whye Teh", "title": "Attentive Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Processes (NPs) (Garnelo et al 2018a;b) approach regression by\nlearning to map a context set of observed input-output pairs to a distribution\nover regression functions. Each function models the distribution of the output\ngiven an input, conditioned on the context. NPs have the benefit of fitting\nobserved data efficiently with linear complexity in the number of context\ninput-output pairs, and can learn a wide family of conditional distributions;\nthey learn predictive distributions conditioned on context sets of arbitrary\nsize. Nonetheless, we show that NPs suffer a fundamental drawback of\nunderfitting, giving inaccurate predictions at the inputs of the observed data\nthey condition on. We address this issue by incorporating attention into NPs,\nallowing each input location to attend to the relevant context points for the\nprediction. We show that this greatly improves the accuracy of predictions,\nresults in noticeably faster training, and expands the range of functions that\ncan be modelled.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 12:37:26 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 10:49:01 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kim", "Hyunjik", ""], ["Mnih", "Andriy", ""], ["Schwarz", "Jonathan", ""], ["Garnelo", "Marta", ""], ["Eslami", "Ali", ""], ["Rosenbaum", "Dan", ""], ["Vinyals", "Oriol", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1901.05808", "submitter": "Sumanth Chennupati", "authors": "Sumanth Chennupati, Ganesh Sistu, Senthil Yogamani and Samir Rawashdeh", "title": "AuxNet: Auxiliary tasks enhanced Semantic Segmentation for Automated\n  Driving", "comments": "Accepted as a Short Paper for a poster presentation at VISAPP 2019", "journal-ref": null, "doi": "10.5220/0007684106450652", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in automated driving is highly specific to the environment\nand thus semantic segmentation plays a key role in recognizing the objects in\nthe environment around the car. Pixel level classification once considered a\nchallenging task which is now becoming mature to be productized in a car.\nHowever, semantic annotation is time consuming and quite expensive. Synthetic\ndatasets with domain adaptation techniques have been used to alleviate the lack\nof large annotated datasets. In this work, we explore an alternate approach of\nleveraging the annotations of other tasks to improve semantic segmentation.\nRecently, multi-task learning became a popular paradigm in automated driving\nwhich demonstrates joint learning of multiple tasks improves overall\nperformance of each tasks. Motivated by this, we use auxiliary tasks like depth\nestimation to improve the performance of semantic segmentation task. We propose\nadaptive task loss weighting techniques to address scale issues in multi-task\nloss functions which become more crucial in auxiliary tasks. We experimented on\nautomotive datasets including SYNTHIA and KITTI and obtained 3% and 5%\nimprovement in accuracy respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 14:32:06 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Chennupati", "Sumanth", ""], ["Sistu", "Ganesh", ""], ["Yogamani", "Senthil", ""], ["Rawashdeh", "Samir", ""]]}, {"id": "1901.05835", "submitter": "Eda Okur", "authors": "Nese Alyuz, Eda Okur, Utku Genc, Sinem Aslan, Cagri Tanriover, Asli\n  Arslan Esme", "title": "Unobtrusive and Multimodal Approach for Behavioral Engagement Detection\n  of Students", "comments": "12th Women in Machine Learning Workshop (WiML 2017), co-located with\n  the 31st Conference on Neural Information Processing Systems (NeurIPS 2017),\n  Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multimodal approach for detection of students' behavioral\nengagement states (i.e., On-Task vs. Off-Task), based on three unobtrusive\nmodalities: Appearance, Context-Performance, and Mouse. Final behavioral\nengagement states are achieved by fusing modality-specific classifiers at the\ndecision level. Various experiments were conducted on a student dataset\ncollected in an authentic classroom.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 02:32:13 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Alyuz", "Nese", ""], ["Okur", "Eda", ""], ["Genc", "Utku", ""], ["Aslan", "Sinem", ""], ["Tanriover", "Cagri", ""], ["Esme", "Asli Arslan", ""]]}, {"id": "1901.05847", "submitter": "Vaishak Belle", "authors": "Amelie Levray and Vaishak Belle", "title": "Learning Credal Sum-Product Networks", "comments": "Accepted to AKBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic representations, such as Bayesian and Markov networks, are\nfundamental to much of statistical machine learning. Thus, learning\nprobabilistic representations directly from data is a deep challenge, the main\ncomputational bottleneck being inference that is intractable. Tractable\nlearning is a powerful new paradigm that attempts to learn distributions that\nsupport efficient probabilistic querying. By leveraging local structure,\nrepresentations such as sum-product networks (SPNs) can capture high tree-width\nmodels with many hidden layers, essentially a deep architecture, while still\nadmitting a range of probabilistic queries to be computable in time polynomial\nin the network size. While the progress is impressive, numerous data sources\nare incomplete, and in the presence of missing data, structure learning methods\nnonetheless revert to single distributions without characterizing the loss in\nconfidence. In recent work, credal sum-product networks, an imprecise extension\nof sum-product networks, were proposed to capture this robustness angle. In\nthis work, we are interested in how such representations can be learnt and thus\nstudy how the computational machinery underlying tractable learning and\ninference can be generalized for imprecise probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 15:32:12 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 14:41:35 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Levray", "Amelie", ""], ["Belle", "Vaishak", ""]]}, {"id": "1901.05850", "submitter": "Aly El Gamal", "authors": "Sharan Ramjee, Shengtai Ju, Diyu Yang, Xiaoyu Liu, Aly El Gamal,\n  Yonina C. Eldar", "title": "Fast Deep Learning for Automatic Modulation Classification", "comments": "29 pages, 30 figures, submitted to Journal on Selected Areas in\n  Communications - Special Issue on Machine Learning in Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the feasibility and effectiveness of employing\ndeep learning algorithms for automatic recognition of the modulation type of\nreceived wireless communication signals from subsampled data. Recent work\nconsidered a GNU radio-based data set that mimics the imperfections in a real\nwireless channel and uses 10 different modulation types. A Convolutional Neural\nNetwork (CNN) architecture was then developed and shown to achieve performance\nthat exceeds that of expert-based approaches. Here, we continue this line of\nwork and investigate deep neural network architectures that deliver high\nclassification accuracy. We identify three architectures - namely, a\nConvolutional Long Short-term Deep Neural Network (CLDNN), a Long Short-Term\nMemory neural network (LSTM), and a deep Residual Network (ResNet) - that lead\nto typical classification accuracy values around 90% at high SNR. We then study\nalgorithms to reduce the training time by minimizing the size of the training\ndata set, while incurring a minimal loss in classification accuracy. To this\nend, we demonstrate the performance of Principal Component Analysis in\nsignificantly reducing the training time, while maintaining good performance at\nlow SNR. We also investigate subsampling techniques that further reduce the\ntraining time, and pave the way for online classification at high SNR. Finally,\nwe identify representative SNR values for training each of the candidate\narchitectures, and consequently, realize drastic reductions of the training\ntime, with negligible loss in classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:15:50 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Ramjee", "Sharan", ""], ["Ju", "Shengtai", ""], ["Yang", "Diyu", ""], ["Liu", "Xiaoyu", ""], ["Gamal", "Aly El", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1901.05906", "submitter": "Xinyu Hu", "authors": "Xinyu Hu, Paul Szerlip, Theofanis Karaletsos, Rohit Singh", "title": "Applying SVGD to Bayesian Neural Networks for Cyclical Time-Series\n  Prediction and Inference", "comments": "Third workshop on Bayesian Deep Learning (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regression-based BNN model is proposed to predict spatiotemporal quantities\nlike hourly rider demand with calibrated uncertainties. The main contributions\nof this paper are (i) A feed-forward deterministic neural network (DetNN)\narchitecture that predicts cyclical time series data with sensitivity to\nanomalous forecasting events; (ii) A Bayesian framework applying SVGD to train\nlarge neural networks for such tasks, capable of producing time series\npredictions as well as measures of uncertainty surrounding the predictions.\nExperiments show that the proposed BNN reduces average estimation error by 10%\nacross 8 U.S. cities compared to a fine-tuned multilayer perceptron (MLP), and\n4% better than the same network architecture trained without SVGD.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 17:08:59 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Hu", "Xinyu", ""], ["Szerlip", "Paul", ""], ["Karaletsos", "Theofanis", ""], ["Singh", "Rohit", ""]]}, {"id": "1901.05947", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Sudeep Salgia and Qing Zhao", "title": "Stochastic Gradient Descent on a Tree: an Adaptive and Robust Approach\n  to Stochastic Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online minimization of an unknown convex function over the interval $[0,1]$\nis considered under first-order stochastic bandit feedback, which returns a\nrandom realization of the gradient of the function at each query point. Without\nknowing the distribution of the random gradients, a learning algorithm\nsequentially chooses query points with the objective of minimizing regret\ndefined as the expected cumulative loss of the function values at the query\npoints in excess to the minimum value of the function. An approach based on\ndevising a biased random walk on an infinite-depth binary tree constructed\nthrough successive partitioning of the domain of the function is developed.\nEach move of the random walk is guided by a sequential test based on confidence\nbounds on the empirical mean constructed using the law of the iterated\nlogarithm. With no tuning parameters, this learning algorithm is robust to\nheavy-tailed noise with infinite variance and adaptive to unknown function\ncharacteristics (specifically, convex, strongly convex, and nonsmooth). It\nachieves the corresponding optimal regret orders (up to a $\\sqrt{\\log T}$ or a\n$\\log\\log T$ factor) in each class of functions and offers better or matching\nregret orders than the classical stochastic gradient descent approach which\nrequires the knowledge of the function characteristics for tuning the sequence\nof step-sizes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 18:42:39 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 12:41:54 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 10:50:30 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Vakili", "Sattar", ""], ["Salgia", "Sudeep", ""], ["Zhao", "Qing", ""]]}, {"id": "1901.05949", "submitter": "Xuan Luo", "authors": "Taylor Sweet, Austin Rothwell, Xuan Luo", "title": "Machine Learning Techniques for Brand-Influencer Matchmaking on the\n  Instagram Social Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social media revolution has changed the way that brands interact with\nconsumers. Instead of spending their advertising budget on interstate\nbillboards, more and more companies are choosing to partner with so-called\nInternet \"influencers\" --- individuals who have gained a loyal following on\nonline platforms for the high quality of the content they post. Unfortunately,\nit's not always easy for small brands to find the right influencer: someone who\naligns with their corporate image and has not yet grown in popularity to the\npoint of unaffordability. In this paper we sought to develop a system for\nbrand-influencer matchmaking, harnessing the power and flexibility of modern\nmachine learning techniques. The result is an algorithm that can predict the\nmost fruitful brand-influencer partnerships based on the similarity of the\ncontent they post.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 18:44:50 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Sweet", "Taylor", ""], ["Rothwell", "Austin", ""], ["Luo", "Xuan", ""]]}, {"id": "1901.05954", "submitter": "Fedor Zhdanov", "authors": "Fedor Zhdanov", "title": "Diverse mini-batch Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of reducing the amount of labeled training data required\nto train supervised classification models. We approach it by leveraging Active\nLearning, through sequential selection of examples which benefit the model\nmost. Selecting examples one by one is not practical for the amount of training\nexamples required by the modern Deep Learning models. We consider the\nmini-batch Active Learning setting, where several examples are selected at\nonce. We present an approach which takes into account both informativeness of\nthe examples for the model, as well as the diversity of the examples in a\nmini-batch. By using the well studied K-means clustering algorithm, this\napproach scales better than the previously proposed approaches, and achieves\ncomparable or better performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 18:56:50 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Zhdanov", "Fedor", ""]]}, {"id": "1901.05958", "submitter": "Albee Ling", "authors": "Albee Y. Ling, Allison W. Kurian, Jennifer L. Caswell-Jin, George W.\n  Sledge Jr., Nigam H. Shah, Suzanne R. Tamang", "title": "A Semi-Supervised Machine Learning Approach to Detecting Recurrent\n  Metastatic Breast Cancer Cases Using Linked Cancer Registry and Electronic\n  Medical Record Data", "comments": null, "journal-ref": "JAMIA open 2.4 (2019): 528-537", "doi": "10.1093/jamiaopen/ooz040", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: Most cancer data sources lack information on metastatic\nrecurrence. Electronic medical records (EMRs) and population-based cancer\nregistries contain complementary information on cancer treatment and outcomes,\nyet are rarely used synergistically. To enable detection of metastatic breast\ncancer (MBC), we applied a semi-supervised machine learning framework to linked\nEMR-California Cancer Registry (CCR) data. Materials and Methods: We studied\n11,459 female patients treated at Stanford Health Care who received an incident\nbreast cancer diagnosis from 2000-2014. The dataset consisted of structured\ndata and unstructured free-text clinical notes from EMR, linked to CCR, a\ncomponent of the Surveillance, Epidemiology and End Results (SEER) database. We\nextracted information on metastatic disease from patient notes to infer a class\nlabel and then trained a regularized logistic regression model for MBC\nclassification. We evaluated model performance on a gold standard set of set of\n146 patients. Results: There are 495 patients with de novo stage IV MBC, 1,374\npatients initially diagnosed with Stage 0-III disease had recurrent MBC, and\n9,590 had no evidence of metastatis. The median follow-up time is 96.3 months\n(mean 97.8, standard deviation 46.7). The best-performing model incorporated\nboth EMR and CCR features. The area under the receiver-operating characteristic\ncurve=0.925 [95% confidence interval: 0.880-0.969], sensitivity=0.861,\nspecificity=0.878 and overall accuracy=0.870. Discussion and Conclusion: A\nframework for MBC case detection combining EMR and CCR data achieved good\nsensitivity, specificity and discrimination without requiring expert-labeled\nexamples. This approach enables population-based research on how patients die\nfrom cancer and may identify novel predictors of cancer recurrence.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 04:22:52 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ling", "Albee Y.", ""], ["Kurian", "Allison W.", ""], ["Caswell-Jin", "Jennifer L.", ""], ["Sledge", "George W.", "Jr."], ["Shah", "Nigam H.", ""], ["Tamang", "Suzanne R.", ""]]}, {"id": "1901.05995", "submitter": "Thomas Villmann", "authors": "Thomas Villmann and John Ravichandran and Andrea Villmann and David\n  Nebel and Marika Kaden", "title": "Activation Functions for Generalized Learning Vector Quantization - A\n  Performance Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An appropriate choice of the activation function (like ReLU, sigmoid or\nswish) plays an important role in the performance of (deep) multilayer\nperceptrons (MLP) for classification and regression learning. Prototype-based\nclassification learning methods like (generalized) learning vector quantization\n(GLVQ) are powerful alternatives. These models also deal with activation\nfunctions but here they are applied to the so-called classifier function\ninstead. In this paper we investigate successful candidates of activation\nfunctions known for MLPs for application in GLVQ and their influence on the\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 20:12:15 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Villmann", "Thomas", ""], ["Ravichandran", "John", ""], ["Villmann", "Andrea", ""], ["Nebel", "David", ""], ["Kaden", "Marika", ""]]}, {"id": "1901.06003", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Dixin Luo, Hongyuan Zha, Lawrence Carin", "title": "Gromov-Wasserstein Learning for Graph Matching and Node Embedding", "comments": null, "journal-ref": "Thirty-sixth International Conference on Machine Learning 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel Gromov-Wasserstein learning framework is proposed to jointly match\n(align) graphs and learn embedding vectors for the associated graph nodes.\nUsing Gromov-Wasserstein discrepancy, we measure the dissimilarity between two\ngraphs and find their correspondence, according to the learned optimal\ntransport. The node embeddings associated with the two graphs are learned under\nthe guidance of the optimal transport, the distance of which not only reflects\nthe topological structure of each graph but also yields the correspondence\nacross the graphs. These two learning steps are mutually-beneficial, and are\nunified here by minimizing the Gromov-Wasserstein discrepancy with structural\nregularizers. This framework leads to an optimization problem that is solved by\na proximal point method. We apply the proposed method to matching problems in\nreal-world networks, and demonstrate its superior performance compared to\nalternative approaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 20:37:47 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 04:53:42 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Zha", "Hongyuan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1901.06016", "submitter": "Piyush Tagade", "authors": "Saket Mishra and Piyush Tagade", "title": "Learning formation energy of inorganic compounds using matrix variate\n  deep Gaussian process", "comments": "On further analysis, authors found the usage of Gegenbauer polynomial\n  combined with radial distribution function and angular distribution function\n  inappropriate. Authors withdraw the paper due to erroneous use of\n  fingerprinting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future advancement of engineering applications is dependent on design of\nnovel materials with desired properties. Enormous size of known chemical space\nnecessitates use of automated high throughput screening to search the desired\nmaterial. The high throughput screening uses quantum chemistry calculations to\npredict material properties, however, computational complexity of these\ncalculations often imposes prohibitively high cost on the search for desired\nmaterial. This critical bottleneck is resolved by using deep machine learning\nto emulate the quantum computations. However, the deep learning algorithms\nrequire a large training dataset to ensure an acceptable generalization, which\nis often unavailable a-priory. In this paper, we propose a deep Gaussian\nprocess based approach to develop an emulator for quantum calculations. We\nfurther propose a novel molecular descriptor that enables implementation of the\nproposed approach. As demonstrated in this paper, the proposed approach can be\nimplemented using a small dataset. We demonstrate efficacy of our approach for\nprediction of formation energy of inorganic molecules.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 17:08:42 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 15:21:44 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Mishra", "Saket", ""], ["Tagade", "Piyush", ""]]}, {"id": "1901.06020", "submitter": "Yulai Cong", "authors": "Yulai Cong, Miaoyun Zhao, Ke Bai, Lawrence Carin", "title": "GO Gradient for Expectation-Based Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within many machine learning algorithms, a fundamental problem concerns\nefficient calculation of an unbiased gradient wrt parameters $\\gammav$ for\nexpectation-based objectives $\\Ebb_{q_{\\gammav} (\\yv)} [f(\\yv)]$. Most existing\nmethods either (i) suffer from high variance, seeking help from (often)\ncomplicated variance-reduction techniques; or (ii) they only apply to\nreparameterizable continuous random variables and employ a reparameterization\ntrick. To address these limitations, we propose a General and One-sample (GO)\ngradient that (i) applies to many distributions associated with\nnon-reparameterizable continuous or discrete random variables, and (ii) has the\nsame low-variance as the reparameterization trick. We find that the GO gradient\noften works well in practice based on only one Monte Carlo sample (although one\ncan of course use more samples if desired). Alongside the GO gradient, we\ndevelop a means of propagating the chain rule through distributions, yielding\nstatistical back-propagation, coupling neural networks to common random\nvariables.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 22:12:52 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Cong", "Yulai", ""], ["Zhao", "Miaoyun", ""], ["Bai", "Ke", ""], ["Carin", "Lawrence", ""]]}, {"id": "1901.06033", "submitter": "Emile Mathieu", "authors": "Emile Mathieu, Charline Le Lan, Chris J. Maddison, Ryota Tomioka, Yee\n  Whye Teh", "title": "Continuous Hierarchical Representations with Poincar\\'e Variational\n  Auto-Encoders", "comments": "Advances in Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational auto-encoder (VAE) is a popular method for learning a\ngenerative model and embeddings of the data. Many real datasets are\nhierarchically structured. However, traditional VAEs map data in a Euclidean\nlatent space which cannot efficiently embed tree-like structures. Hyperbolic\nspaces with negative curvature can. We therefore endow VAEs with a Poincar\\'e\nball model of hyperbolic geometry as a latent space and rigorously derive the\nnecessary methods to work with two main Gaussian generalisations on that space.\nWe empirically show better generalisation to unseen data than the Euclidean\ncounterpart, and can qualitatively and quantitatively better recover\nhierarchical structures.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 23:23:31 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 17:21:02 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 23:56:20 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Mathieu", "Emile", ""], ["Lan", "Charline Le", ""], ["Maddison", "Chris J.", ""], ["Tomioka", "Ryota", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1901.06053", "submitter": "Mert G\\\"urb\\\"uzbalaban", "authors": "Umut Simsekli, Levent Sagun, Mert Gurbuzbalaban", "title": "A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradient noise (GN) in the stochastic gradient descent (SGD) algorithm is\noften considered to be Gaussian in the large data regime by assuming that the\nclassical central limit theorem (CLT) kicks in. This assumption is often made\nfor mathematical convenience, since it enables SGD to be analyzed as a\nstochastic differential equation (SDE) driven by a Brownian motion. We argue\nthat the Gaussianity assumption might fail to hold in deep learning settings\nand hence render the Brownian motion-based analyses inappropriate. Inspired by\nnon-Gaussian natural phenomena, we consider the GN in a more general context\nand invoke the generalized CLT (GCLT), which suggests that the GN converges to\na heavy-tailed $\\alpha$-stable random variable. Accordingly, we propose to\nanalyze SGD as an SDE driven by a L\\'{e}vy motion. Such SDEs can incur `jumps',\nwhich force the SDE transition from narrow minima to wider minima, as proven by\nexisting metastability theory. To validate the $\\alpha$-stable assumption, we\nconduct extensive experiments on common deep learning architectures and show\nthat in all settings, the GN is highly non-Gaussian and admits heavy-tails. We\nfurther investigate the tail behavior in varying network architectures and\nsizes, loss functions, and datasets. Our results open up a different\nperspective and shed more light on the belief that SGD prefers wide minima.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 01:32:07 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Simsekli", "Umut", ""], ["Sagun", "Levent", ""], ["Gurbuzbalaban", "Mert", ""]]}, {"id": "1901.06054", "submitter": "Wenqing Hu", "authors": "Wenqing Hu, Zhanxing Zhu, Haoyi Xiong, Jun Huan", "title": "Quasi-potential as an implicit regularizer for the loss function in the\n  stochastic gradient descent", "comments": "first and preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We interpret the variational inference of the Stochastic Gradient Descent\n(SGD) as minimizing a new potential function named the\n\\textit{quasi-potential}. We analytically construct the quasi-potential\nfunction in the case when the loss function is convex and admits only one\nglobal minimum point. We show in this case that the quasi-potential function is\nrelated to the noise covariance structure of SGD via a partial differential\nequation of Hamilton-Jacobi type. This relation helps us to show that\nanisotropic noise leads to faster escape than isotropic noise. We then consider\nthe dynamics of SGD in the case when the loss function is non-convex and admits\nseveral different local minima. In this case, we demonstrate an example that\nshows how the noise covariance structure plays a role in \"implicit\nregularization\", a phenomenon in which SGD favors some particular local minimum\npoints. This is done through the relation between the noise covariance\nstructure and the quasi-potential function. Our analysis is based on Large\nDeviations Theory (LDT), and they are validated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 01:45:29 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hu", "Wenqing", ""], ["Zhu", "Zhanxing", ""], ["Xiong", "Haoyi", ""], ["Huan", "Jun", ""]]}, {"id": "1901.06075", "submitter": "Michael Weylandt", "authors": "Michael Weylandt", "title": "Splitting Methods for Convex Bi-Clustering and Co-Clustering", "comments": "To appear in IEEE DSW 2019", "journal-ref": "DSW 2019: Proceedings of the IEEE Data Science Workshop 2019, pp.\n  237-244", "doi": "10.1109/DSW.2019.8755599", "report-no": null, "categories": "stat.ML stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Co-Clustering, the problem of simultaneously identifying clusters across\nmultiple aspects of a data set, is a natural generalization of clustering to\nhigher-order structured data. Recent convex formulations of bi-clustering and\ntensor co-clustering, which shrink estimated centroids together using a convex\nfusion penalty, allow for global optimality guarantees and precise theoretical\nanalysis, but their computational properties have been less well studied. In\nthis note, we present three efficient operator-splitting methods for the convex\nco-clustering problem: a standard two-block ADMM, a Generalized ADMM which\navoids an expensive tensor Sylvester equation in the primal update, and a\nthree-block ADMM based on the operator splitting scheme of Davis and Yin.\nTheoretical complexity analysis suggests, and experimental evidence confirms,\nthat the Generalized ADMM is far more efficient for large problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 03:44:51 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 04:33:32 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 21:41:05 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 18:34:54 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Weylandt", "Michael", ""]]}, {"id": "1901.06077", "submitter": "Wei-Cheng Chang", "authors": "Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, Barnab\\'as P\\'oczos", "title": "Kernel Change-point Detection with Auxiliary Deep Generative Models", "comments": "To appear in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting the emergence of abrupt property changes in time series is a\nchallenging problem. Kernel two-sample test has been studied for this task\nwhich makes fewer assumptions on the distributions than traditional parametric\napproaches. However, selecting kernels is non-trivial in practice. Although\nkernel selection for two-sample test has been studied, the insufficient samples\nin change point detection problem hinder the success of those developed kernel\nselection algorithms. In this paper, we propose KL-CPD, a novel kernel learning\nframework for time series CPD that optimizes a lower bound of test power via an\nauxiliary generative model. With deep kernel parameterization, KL-CPD endows\nkernel two-sample test with the data-driven kernel to detect different types of\nchange-points in real-world applications. The proposed approach significantly\noutperformed other state-of-the-art methods in our comparative evaluation of\nbenchmark datasets and simulation studies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 04:06:58 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Chang", "Wei-Cheng", ""], ["Li", "Chun-Liang", ""], ["Yang", "Yiming", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1901.06082", "submitter": "Benjamin Bloem-Reddy", "authors": "Benjamin Bloem-Reddy, Yee Whye Teh", "title": "Probabilistic symmetries and invariant neural networks", "comments": "Revised structure for clarity; fixed minor mistakes; incorporated\n  reviewer feedback for publication", "journal-ref": "Journal of Machine Learning Research, 21(90):1-61, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Treating neural network inputs and outputs as random variables, we\ncharacterize the structure of neural networks that can be used to model data\nthat are invariant or equivariant under the action of a compact group. Much\nrecent research has been devoted to encoding invariance under symmetry\ntransformations into neural network architectures, in an effort to improve the\nperformance of deep neural networks in data-scarce, non-i.i.d., or unsupervised\nsettings. By considering group invariance from the perspective of probabilistic\nsymmetry, we establish a link between functional and probabilistic symmetry,\nand obtain generative functional representations of probability distributions\nthat are invariant or equivariant under the action of a compact group. Our\nrepresentations completely characterize the structure of neural networks that\ncan be used to model such distributions and yield a general program for\nconstructing invariant stochastic or deterministic neural networks. We\ndemonstrate that examples from the recent literature are special cases, and\ndevelop the details of the general program for exchangeable sequences and\narrays.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 04:32:14 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 19:13:44 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Bloem-Reddy", "Benjamin", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1901.06086", "submitter": "Liang Zhao", "authors": "Tianbing Xu, Andrew Zhang, Liang Zhao", "title": "WALL-E: An Efficient Reinforcement Learning Research Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two halves to RL systems: experience collection time and policy\nlearning time. For a large number of samples in rollouts, experience collection\ntime is the major bottleneck. Thus, it is necessary to speed up the rollout\ngeneration time with multi-process architecture support. Our work, dubbed\nWALL-E, utilizes multiple rollout samplers running in parallel to rapidly\ngenerate experience. Due to our parallel samplers, we experience not only\nfaster convergence times, but also higher average reward thresholds. For\nexample, on the MuJoCo HalfCheetah-v2 task, with $N = 10$ parallel sampler\nprocesses, we are able to achieve much higher average return than those from\nusing only a single process architecture.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 04:54:15 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 06:25:18 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Xu", "Tianbing", ""], ["Zhang", "Andrew", ""], ["Zhao", "Liang", ""]]}, {"id": "1901.06091", "submitter": "Asifullah Khan", "authors": "Uzair Ahmed, Asifullah Khan, Saddam Hussain Khan, Abdul Basit, Irfan\n  Ul Haq, and Yeon Soo Lee", "title": "Transfer Learning and Meta Classification Based Deep Churn Prediction\n  System for Telecom Industry", "comments": "Number of Pages: 10 Number of Figures:4 Number of Tables: 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A churn prediction system guides telecom service providers to reduce revenue\nloss. However, the development of a churn prediction system for a telecom\nindustry is a challenging task, mainly due to the large size of the data, high\ndimensional features, and imbalanced distribution of the data. In this paper,\nwe present a solution to the inherent problems of churn prediction, using the\nconcept of Transfer Learning (TL) and Ensemble-based Meta-Classification. The\nproposed method TL-DeepE is applied in two stages. The first stage employs TL\nby fine-tuning multiple pre-trained Deep Convolution Neural Networks (CNNs).\nTelecom datasets are normally in vector form, which is converted into 2D images\nbecause Deep CNNs have high learning capacity on images. In the second stage,\npredictions from these Deep CNNs are appended to the original feature vector\nand thus are used to build a final feature vector for the high-level Genetic\nProgramming (GP) and AdaBoost based ensemble classifier. Thus, the experiments\nare conducted using various CNNs as base classifiers and the GP-AdaBoost as a\nmeta-classifier. By using 10-fold cross-validation, the performance of the\nproposed TL-DeepE system is compared with existing techniques, for two standard\ntelecommunication datasets; Orange and Cell2cell. Performing experiments on\nOrange and Cell2cell datasets, the prediction accuracy obtained was 75.4% and\n68.2%, while the area under the curve was 0.83 and 0.74, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 05:39:33 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 10:10:02 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Ahmed", "Uzair", ""], ["Khan", "Asifullah", ""], ["Khan", "Saddam Hussain", ""], ["Basit", "Abdul", ""], ["Haq", "Irfan Ul", ""], ["Lee", "Yeon Soo", ""]]}, {"id": "1901.06116", "submitter": "Ji Chen", "authors": "Ji Chen, Dekai Liu, Xiaodong Li", "title": "Nonconvex Rectangular Matrix Completion via Gradient Descent without\n  $\\ell_{2,\\infty}$ Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of nonconvex matrix completion has recently attracted much\nattention in the community of machine learning thanks to its computational\nconvenience. Existing analysis on this problem, however, usually relies on\n$\\ell_{2,\\infty}$ projection or regularization that involves unknown model\nparameters, although they are observed to be unnecessary in numerical\nsimulations, see, e.g., Zheng and Lafferty [2016]. In this paper, we extend the\nanalysis of the vanilla gradient descent for positive semidefinite matrix\ncompletion proposed in Ma et al. [2017] to the rectangular case, and more\nsignificantly, improve the required sampling rate from\n$O(\\operatorname{poly}(\\kappa)\\mu^3 r^3 \\log^3 n/n )$ to $O(\\mu^2 r^2\n\\kappa^{14} \\log n/n )$. Our technical ideas and contributions are potentially\nuseful in improving the leave-one-out analysis in other related problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 07:34:26 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 03:55:18 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 21:44:00 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Chen", "Ji", ""], ["Liu", "Dekai", ""], ["Li", "Xiaodong", ""]]}, {"id": "1901.06125", "submitter": "Dawei Chen", "authors": "Dawei Chen, Cheng Soon Ong, Aditya Krishna Menon", "title": "Cold-start Playlist Recommendation with Multitask Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playlist recommendation involves producing a set of songs that a user might\nenjoy. We investigate this problem in three cold-start scenarios: (i) cold\nplaylists, where we recommend songs to form new personalised playlists for an\nexisting user; (ii) cold users, where we recommend songs to form new playlists\nfor a new user; and (iii) cold songs, where we recommend newly released songs\nto extend users' existing playlists. We propose a flexible multitask learning\nmethod to deal with all three settings. The method learns from user-curated\nplaylists, and encourages songs in a playlist to be ranked higher than those\nthat are not by minimising a bipartite ranking loss. Inspired by an equivalence\nbetween bipartite ranking and binary classification, we show how one can\nefficiently approximate an optimal solution of the multitask learning objective\nby minimising a classification loss. Empirical results on two real playlist\ndatasets show the proposed approach has good performance for cold-start\nplaylist recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 08:14:27 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Chen", "Dawei", ""], ["Ong", "Cheng Soon", ""], ["Menon", "Aditya Krishna", ""]]}, {"id": "1901.06152", "submitter": "Anand Bihari Dr.", "authors": "Chhote Lal Prasad Gupta, Anand Bihari and Sudhakar Tripathi", "title": "Protein Classification using Machine Learning and Statistical\n  Techniques: A Comparative Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent era prediction of enzyme class from an unknown protein is one of\nthe challenging tasks in bioinformatics. Day to day the number of proteins is\nincreases as result the prediction of enzyme class gives a new opportunity to\nbioinformatics scholars. The prime objective of this article is to implement\nthe machine learning classification technique for feature selection and\npredictions also find out an appropriate classification technique for function\nprediction. In this article the seven different classification technique like\nCRT, QUEST, CHAID, C5.0, ANN (Artificial Neural Network), SVM and Bayesian has\nbeen implemented on 4368 protein data that has been extracted from UniprotKB\ndatabank and categories into six different class. The proteins data is high\ndimensional sequence data and contain a maximum of 48 features.To manipulate\nthe high dimensional sequential protein data with different classification\ntechnique, the SPSS has been used as an experimental tool. Different\nclassification techniques give different results for every model and shows that\nthe data are imbalanced for class C4, C5 and C6. The imbalanced data affect the\nperformance of model. In these three classes the precision and recall value is\nvery less or negligible. The experimental results highlight that the C5.0\nclassification technique accuracy is more suited for protein feature\nclassification and predictions. The C5.0 classification technique gives 95.56%\naccuracy and also gives high precision and recall value. Finally, we conclude\nthat the features that is selected can be used for function prediction.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 09:37:21 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Gupta", "Chhote Lal Prasad", ""], ["Bihari", "Anand", ""], ["Tripathi", "Sudhakar", ""]]}, {"id": "1901.06181", "submitter": "Alberto Garcia-Garcia", "authors": "Alberto Garcia-Garcia, Brayan Stiven Zapata-Impata, Sergio\n  Orts-Escolano, Pablo Gil, Jose Garcia-Rodriguez", "title": "TactileGCN: A Graph Convolutional Network for Predicting Grasp Stability\n  with Tactile Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile sensors provide useful contact data during the interaction with an\nobject which can be used to accurately learn to determine the stability of a\ngrasp. Most of the works in the literature represented tactile readings as\nplain feature vectors or matrix-like tactile images, using them to train\nmachine learning models. In this work, we explore an alternative way of\nexploiting tactile information to predict grasp stability by leveraging\ngraph-like representations of tactile data, which preserve the actual spatial\narrangement of the sensor's taxels and their locality. In experimentation, we\ntrained a Graph Neural Network to binary classify grasps as stable or slippery\nones. To train such network and prove its predictive capabilities for the\nproblem at hand, we captured a novel dataset of approximately 5000\nthree-fingered grasps across 41 objects for training and 1000 grasps with 10\nunknown objects for testing. Our experiments prove that this novel approach can\nbe effectively used to predict grasp stability.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 11:08:34 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Garcia-Garcia", "Alberto", ""], ["Zapata-Impata", "Brayan Stiven", ""], ["Orts-Escolano", "Sergio", ""], ["Gil", "Pablo", ""], ["Garcia-Rodriguez", "Jose", ""]]}, {"id": "1901.06201", "submitter": "Giovanni Di Gennaro", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Francesco A. N. Palmieri", "title": "Optimized Realization of Bayesian Networks in Reduced Normal Form using\n  Latent Variable Model", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": "10.1007/s00500-021-05642-3", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks in their Factor Graph Reduced Normal Form (FGrn) are a\npowerful paradigm for implementing inference graphs. Unfortunately, the\ncomputational and memory costs of these networks may be considerable, even for\nrelatively small networks, and this is one of the main reasons why these\nstructures have often been underused in practice. In this work, through a\ndetailed algorithmic and structural analysis, various solutions for cost\nreduction are proposed. An online version of the classic batch learning\nalgorithm is also analyzed, showing very similar results (in an unsupervised\ncontext); which is essential even if multilevel structures are to be built. The\nsolutions proposed, together with the possible online learning algorithm, are\nincluded in a C++ library that is quite efficient, especially if compared to\nthe direct use of the well-known sum-product and Maximum Likelihood (ML)\nalgorithms. The results are discussed with particular reference to a Latent\nVariable Model (LVM) structure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 12:28:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Palmieri", "Francesco A. N.", ""]]}, {"id": "1901.06212", "submitter": "Dmitry Kangin", "authors": "Dmitry Kangin and Nicolas Pugeault", "title": "On-Policy Trust Region Policy Optimisation with Replay Buffers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building upon the recent success of deep reinforcement learning methods, we\ninvestigate the possibility of on-policy reinforcement learning improvement by\nreusing the data from several consecutive policies. On-policy methods bring\nmany benefits, such as ability to evaluate each resulting policy. However, they\nusually discard all the information about the policies which existed before. In\nthis work, we propose adaptation of the replay buffer concept, borrowed from\nthe off-policy learning setting, to create the method, combining advantages of\non- and off-policy learning. To achieve this, the proposed algorithm\ngeneralises the $Q$-, value and advantage functions for data from multiple\npolicies. The method uses trust region optimisation, while avoiding some of the\ncommon problems of the algorithms such as TRPO or ACKTR: it uses\nhyperparameters to replace the trust region selection heuristics, as well as\nthe trainable covariance matrix instead of the fixed one. In many cases, the\nmethod not only improves the results comparing to the state-of-the-art trust\nregion on-policy learning algorithms such as PPO, ACKTR and TRPO, but also with\nrespect to their off-policy counterpart DDPG.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 13:09:18 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Kangin", "Dmitry", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "1901.06237", "submitter": "Sha Lai", "authors": "Mehrnoosh Sameki, Sha Lai, Kate K. Mays, Lei Guo, Prakash Ishwar,\n  Margrit Betke", "title": "BUOCA: Budget-Optimized Crowd Worker Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to concerns about human error in crowdsourcing, it is standard practice\nto collect labels for the same data point from multiple internet workers. We\nhere show that the resulting budget can be used more effectively with a\nflexible worker assignment strategy that asks fewer workers to analyze\neasy-to-label data and more workers to analyze data that requires extra\nscrutiny. Our main contribution is to show how the allocations of the number of\nworkers to a task can be computed optimally based on task features alone,\nwithout using worker profiles. Our target tasks are delineating cells in\nmicroscopy images and analyzing the sentiment toward the 2016 U.S. presidential\ncandidates in tweets. We first propose an algorithm that computes\nbudget-optimized crowd worker allocation (BUOCA). We next train a machine\nlearning system (BUOCA-ML) that predicts an optimal number of crowd workers\nneeded to maximize the accuracy of the labeling. We show that the computed\nallocation can yield large savings in the crowdsourcing budget (up to 49\npercent points) while maintaining labeling accuracy. Finally, we envisage a\nhuman-machine system for performing budget-optimized data analysis at a scale\nbeyond the feasibility of crowdsourcing.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 22:36:41 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Sameki", "Mehrnoosh", ""], ["Lai", "Sha", ""], ["Mays", "Kate K.", ""], ["Guo", "Lei", ""], ["Ishwar", "Prakash", ""], ["Betke", "Margrit", ""]]}, {"id": "1901.06242", "submitter": "Charith Perera", "authors": "Yuchao Zhou, Suparna De, Gideon Ewa, Charith Perera, Klaus Moessner", "title": "Data-driven Air Quality Characterisation for Urban Environments: a Case\n  Study", "comments": "IEEE ACCESS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The economic and social impact of poor air quality in towns and cities is\nincreasingly being recognised, together with the need for effective ways of\ncreating awareness of real-time air quality levels and their impact on human\nhealth. With local authority maintained monitoring stations being\ngeographically sparse and the resultant datasets also featuring missing labels,\ncomputational data-driven mechanisms are needed to address the data sparsity\nchallenge. In this paper, we propose a machine learning-based method to\naccurately predict the Air Quality Index (AQI), using environmental monitoring\ndata together with meteorological measurements. To do so, we develop an air\nquality estimation framework that implements a neural network that is enhanced\nwith a novel Non-linear Autoregressive neural network with exogenous input\n(NARX), especially designed for time series prediction. The framework is\napplied to a case study featuring different monitoring sites in London, with\ncomparisons against other standard machine-learning based predictive algorithms\nshowing the feasibility and robust performance of the proposed method for\ndifferent kinds of areas within an urban region.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 13:40:03 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Zhou", "Yuchao", ""], ["De", "Suparna", ""], ["Ewa", "Gideon", ""], ["Perera", "Charith", ""], ["Moessner", "Klaus", ""]]}, {"id": "1901.06246", "submitter": "Jasper Snoek", "authors": "D Sculley and Jasper Snoek and Alex Wiltschko", "title": "Avoiding a Tragedy of the Commons in the Peer Review Process", "comments": "Appeared in the 2018 Advances in Neural Information Processing\n  Systems Workshop on Critiquing and Correcting Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is the foundation of scientific publication, and the task of\nreviewing has long been seen as a cornerstone of professional service. However,\nthe massive growth in the field of machine learning has put this community\nbenefit under stress, threatening both the sustainability of an effective\nreview process and the overall progress of the field. In this position paper,\nwe argue that a tragedy of the commons outcome may be avoided by emphasizing\nthe professional aspects of this service. In particular, we propose a rubric to\nhold reviewers to an objective standard for review quality. In turn, we also\npropose that reviewers be given appropriate incentive. As one possible such\nincentive, we explore the idea of financial compensation on a per-review basis.\nWe suggest reasonable funding models and thoughts on long term effects.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 15:32:29 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Sculley", "D", ""], ["Snoek", "Jasper", ""], ["Wiltschko", "Alex", ""]]}, {"id": "1901.06247", "submitter": "Xi Liu", "authors": "Xi Liu, Muhe Xie, Xidao Wen, Rui Chen, Yong Ge, Nick Duffield and Na\n  Wang", "title": "Micro- and Macro-Level Churn Analysis of Large-Scale Mobile Games", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.06573", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As mobile devices become more and more popular, mobile gaming has emerged as\na promising market with billion-dollar revenues. A variety of mobile game\nplatforms and services have been developed around the world. A critical\nchallenge for these platforms and services is to understand the churn behavior\nin mobile games, which usually involves churn at micro level (between an app\nand a specific user) and macro level (between an app and all its users).\nAccurate micro-level churn prediction and macro-level churn ranking will\nbenefit many stakeholders such as game developers, advertisers, and platform\noperators. In this paper, we present the first large-scale churn analysis for\nmobile games that supports both micro-level churn prediction and macro-level\nchurn ranking. For micro-level churn prediction, in view of the common\nlimitations of the state-of-the-art methods built upon traditional machine\nlearning models, we devise a novel semi-supervised and inductive embedding\nmodel that jointly learns the prediction function and the embedding function\nfor user-app relationships. We model these two functions by deep neural\nnetworks with a unique edge embedding technique that is able to capture both\ncontextual information and relationship dynamics. We also design a novel\nattributed random walk technique that takes into consideration both topological\nadjacency and attribute similarities. To address macro-level churn ranking, we\npropose to construct a relationship graph with estimated micro-level churn\nprobabilities as edge weights and adapt link analysis algorithms on the graph.\nWe devise a simple algorithm SimSum and adapt two more advanced algorithms\nPageRank and HITS. The performance of our solutions for the two-level churn\nanalysis problems is evaluated on real-world data collected from the Samsung\nGame Launcher platform.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 21:12:21 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Liu", "Xi", ""], ["Xie", "Muhe", ""], ["Wen", "Xidao", ""], ["Chen", "Rui", ""], ["Ge", "Yong", ""], ["Duffield", "Nick", ""], ["Wang", "Na", ""]]}, {"id": "1901.06252", "submitter": "Temitayo Fagbola", "authors": "Temitayo Matthew Fagbola, Ibrahim Adepoju Adeyanju, Olatayo Olaniyan,\n  Adebimpe Esan, Bolaji Omodunbi, Ayodele Oloyede and Funmilola Egbetola", "title": "Development of Mobile-Interfaced Machine Learning-Based Predictive\n  Models for Improving Students Performance in Programming Courses", "comments": "11 pages", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 9, No. 5, 2018", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student performance modelling (SPM) is a critical step to assessing and\nimproving students performances in their learning discourse. However, most\nexisting SPM are based on statistical approaches, which on one hand are based\non probability, depicting that results are based on estimation; and on the\nother hand, actual influences of hidden factors that are peculiar to students,\nlecturers, learning environment and the family, together with their overall\neffect on student performance have not been exhaustively investigated. In this\npaper, Student Performance Models (SPM) for improving students performance in\nprogramming courses were developed using M5P Decision Tree (MDT) and Linear\nRegression Classifier (LRC). The data used was gathered using a structured\nquestionnaire from 295 students in 200 and 300 levels of study who offered Web\nprogramming, C or JAVA at Federal University, Oye-Ekiti, Nigeria between 2012\nand 2016. Hidden factors that are significant to students performance in\nprogramming were identified. The relevant data gathered, normalized, coded and\nprepared as variable and factor datasets, and fed into the MDT algorithm and\nLRC to develop the predictive models. The evaluation results obtained indicate\nthat the variable-based LRC produced the best model in terms of MAE, RMSE, RAE\nand the RRSE having yielded the least values in all the evaluations conducted.\nFurther results obtained established the strong significance of attitude of\nstudents and lecturers, fearful perception of students, erratic power supply,\nuniversity facilities, student health and students attendance to the\nperformance of students in programming courses. The variable-based LRC model\npresented in this paper could provide baseline information about students\nperformance thereby offering better decision making towards improving\nteaching/learning outcomes in programming courses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 12:29:04 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Fagbola", "Temitayo Matthew", ""], ["Adeyanju", "Ibrahim Adepoju", ""], ["Olaniyan", "Olatayo", ""], ["Esan", "Adebimpe", ""], ["Omodunbi", "Bolaji", ""], ["Oloyede", "Ayodele", ""], ["Egbetola", "Funmilola", ""]]}, {"id": "1901.06261", "submitter": "Atin Sood", "authors": "Atin Sood, Benjamin Elder, Benjamin Herta, Chao Xue, Costas Bekas, A.\n  Cristiano I. Malossi, Debashish Saha, Florian Scheidegger, Ganesh\n  Venkataraman, Gegi Thomas, Giovanni Mariani, Hendrik Strobelt, Horst\n  Samulowitz, Martin Wistuba, Matteo Manica, Mihir Choudhury, Rong Yan, Roxana\n  Istrate, Ruchir Puri, Tejaswini Pedapati", "title": "NeuNetS: An Automated Synthesis Engine for Neural Network Design", "comments": "14 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1806.00250", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of neural networks to a vast variety of practical applications is\ntransforming the way AI is applied in practice. Pre-trained neural network\nmodels available through APIs or capability to custom train pre-built neural\nnetwork architectures with customer data has made the consumption of AI by\ndevelopers much simpler and resulted in broad adoption of these complex AI\nmodels. While prebuilt network models exist for certain scenarios, to try and\nmeet the constraints that are unique to each application, AI teams need to\nthink about developing custom neural network architectures that can meet the\ntradeoff between accuracy and memory footprint to achieve the tight constraints\nof their unique use-cases. However, only a small proportion of data science\nteams have the skills and experience needed to create a neural network from\nscratch, and the demand far exceeds the supply. In this paper, we present\nNeuNetS : An automated Neural Network Synthesis engine for custom neural\nnetwork design that is available as part of IBM's AI OpenScale's product.\nNeuNetS is available for both Text and Image domains and can build neural\nnetworks for specific tasks in a fraction of the time it takes today with human\neffort, and with accuracy similar to that of human-designed AI models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 00:23:41 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Sood", "Atin", ""], ["Elder", "Benjamin", ""], ["Herta", "Benjamin", ""], ["Xue", "Chao", ""], ["Bekas", "Costas", ""], ["Malossi", "A. Cristiano I.", ""], ["Saha", "Debashish", ""], ["Scheidegger", "Florian", ""], ["Venkataraman", "Ganesh", ""], ["Thomas", "Gegi", ""], ["Mariani", "Giovanni", ""], ["Strobelt", "Hendrik", ""], ["Samulowitz", "Horst", ""], ["Wistuba", "Martin", ""], ["Manica", "Matteo", ""], ["Choudhury", "Mihir", ""], ["Yan", "Rong", ""], ["Istrate", "Roxana", ""], ["Puri", "Ruchir", ""], ["Pedapati", "Tejaswini", ""]]}, {"id": "1901.06268", "submitter": "Florian Richoux", "authors": "Florian Richoux, Charl\\`ene Servantie, Cynthia Bor\\`es, St\\'ephane\n  T\\'eletch\\'ea", "title": "Comparing two deep learning sequence-based models for protein-protein\n  interaction prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological data are extremely diverse, complex but also quite sparse. The\nrecent developments in deep learning methods are offering new possibilities for\nthe analysis of complex data. However, it is easy to be get a deep learning\nmodel that seems to have good results but is in fact either overfitting the\ntraining data or the validation data. In particular, the fact to overfit the\nvalidation data, called \"information leak\", is almost never treated in papers\nproposing deep learning models to predict protein-protein interactions (PPI).\nIn this work, we compare two carefully designed deep learning models and show\npitfalls to avoid while predicting PPIs through machine learning methods. Our\nbest model predicts accurately more than 78% of human PPI, in very strict\nconditions both for training and testing. The methodology we propose here allow\nus to have strong confidences about the ability of a model to scale up on\nlarger datasets. This would allow sharper models when larger datasets would be\navailable, rather than current models prone to information leaks. Our solid\nmethodological foundations shall be applicable to more organisms and whole\nproteome networks predictions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 04:58:34 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Richoux", "Florian", ""], ["Servantie", "Charl\u00e8ne", ""], ["Bor\u00e8s", "Cynthia", ""], ["T\u00e9letch\u00e9a", "St\u00e9phane", ""]]}, {"id": "1901.06291", "submitter": "Eda Okur", "authors": "Eda Okur, Nese Alyuz, Sinem Aslan, Utku Genc, Cagri Tanriover, Asli\n  Arslan Esme", "title": "Detecting Behavioral Engagement of Students in the Wild Based on\n  Contextual and Visual Data", "comments": "12th Women in Machine Learning Workshop (WiML 2017), co-located with\n  the 31st Conference on Neural Information Processing Systems (NeurIPS 2017),\n  Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To investigate the detection of students' behavioral engagement (On-Task vs.\nOff-Task), we propose a two-phase approach in this study. In Phase 1,\ncontextual logs (URLs) are utilized to assess active usage of the content\nplatform. If there is active use, the appearance information is utilized in\nPhase 2 to infer behavioral engagement. Incorporating the contextual\ninformation improved the overall F1-scores from 0.77 to 0.82. Our\ncross-classroom and cross-platform experiments showed the proposed generic and\nmulti-modal behavioral engagement models' applicability to a different set of\nstudents or different subject areas.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 06:45:56 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Okur", "Eda", ""], ["Alyuz", "Nese", ""], ["Aslan", "Sinem", ""], ["Genc", "Utku", ""], ["Tanriover", "Cagri", ""], ["Esme", "Asli Arslan", ""]]}, {"id": "1901.06314", "submitter": "Yinhao Zhu", "authors": "Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, Paris\n  Perdikaris", "title": "Physics-Constrained Deep Learning for High-dimensional Surrogate\n  Modeling and Uncertainty Quantification without Labeled Data", "comments": "51 pages, 18 figures, submitted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2019.05.024", "report-no": null, "categories": "physics.comp-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate modeling and uncertainty quantification tasks for PDE systems are\nmost often considered as supervised learning problems where input and output\ndata pairs are used for training. The construction of such emulators is by\ndefinition a small data problem which poses challenges to deep learning\napproaches that have been developed to operate in the big data regime. Even in\ncases where such models have been shown to have good predictive capability in\nhigh dimensions, they fail to address constraints in the data implied by the\nPDE model. This paper provides a methodology that incorporates the governing\nequations of the physical model in the loss/likelihood functions. The resulting\nphysics-constrained, deep learning models are trained without any labeled data\n(e.g. employing only input data) and provide comparable predictive responses\nwith data-driven models while obeying the constraints of the problem at hand.\nThis work employs a convolutional encoder-decoder neural network approach as\nwell as a conditional flow-based generative model for the solution of PDEs,\nsurrogate model construction, and uncertainty quantification tasks. The\nmethodology is posed as a minimization problem of the reverse Kullback-Leibler\n(KL) divergence between the model predictive density and the reference\nconditional density, where the later is defined as the Boltzmann-Gibbs\ndistribution at a given inverse temperature with the underlying potential\nrelating to the PDE system of interest. The generalization capability of these\nmodels to out-of-distribution input is considered. Quantification and\ninterpretation of the predictive uncertainty is provided for a number of\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 15:59:30 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zhu", "Yinhao", ""], ["Zabaras", "Nicholas", ""], ["Koutsourelakis", "Phaedon-Stelios", ""], ["Perdikaris", "Paris", ""]]}, {"id": "1901.06328", "submitter": "Andrei Zinovyev Dr.", "authors": "Luca Albergante and Jonathan Bac and Andrei Zinovyev", "title": "Estimating the effective dimension of large biological datasets using\n  Fisher separability analysis", "comments": "8 pages, submitted to IJCNN-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern large-scale datasets are frequently said to be high-dimensional.\nHowever, their data point clouds frequently possess structures, significantly\ndecreasing their intrinsic dimensionality (ID) due to the presence of clusters,\npoints being located close to low-dimensional varieties or fine-grained\nlumping. We test a recently introduced dimensionality estimator, based on\nanalysing the separability properties of data points, on several benchmarks and\nreal biological datasets. We show that the introduced measure of ID has\nperformance competitive with state-of-the-art measures, being efficient across\na wide range of dimensions and performing better in the case of noisy samples.\nMoreover, it allows estimating the intrinsic dimension in situations where the\nintrinsic manifold assumption is not valid.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 16:32:11 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Albergante", "Luca", ""], ["Bac", "Jonathan", ""], ["Zinovyev", "Andrei", ""]]}, {"id": "1901.06355", "submitter": "Laura Beggel", "authors": "Laura Beggel, Michael Pfeiffer, Bernd Bischl", "title": "Robust Anomaly Detection in Images using Adversarial Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliably detecting anomalies in a given set of images is a task of high\npractical relevance for visual quality inspection, surveillance, or medical\nimage analysis. Autoencoder neural networks learn to reconstruct normal images,\nand hence can classify those images as anomalies, where the reconstruction\nerror exceeds some threshold. Here we analyze a fundamental problem of this\napproach when the training set is contaminated with a small fraction of\noutliers. We find that continued training of autoencoders inevitably reduces\nthe reconstruction error of outliers, and hence degrades the anomaly detection\nperformance. In order to counteract this effect, an adversarial autoencoder\narchitecture is adapted, which imposes a prior distribution on the latent\nrepresentation, typically placing anomalies into low likelihood-regions.\nUtilizing the likelihood model, potential anomalies can be identified and\nrejected already during training, which results in an anomaly detector that is\nsignificantly more robust to the presence of outliers during training.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 17:48:15 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Beggel", "Laura", ""], ["Pfeiffer", "Michael", ""], ["Bischl", "Bernd", ""]]}, {"id": "1901.06413", "submitter": "Di Wang", "authors": "Di Wang and Jinhui Xu", "title": "Differentially Private High Dimensional Sparse Covariance Matrix\n  Estimation", "comments": "A short version will be appeared in CISS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of estimating the covariance matrix under\ndifferential privacy, where the underlying covariance matrix is assumed to be\nsparse and of high dimensions. We propose a new method, called DP-Thresholding,\nto achieve a non-trivial $\\ell_2$-norm based error bound, which is\nsignificantly better than the existing ones from adding noise directly to the\nempirical covariance matrix. We also extend the $\\ell_2$-norm based error bound\nto a general $\\ell_w$-norm based one for any $1\\leq w\\leq \\infty$, and show\nthat they share the same upper bound asymptotically. Our approach can be easily\nextended to local differential privacy. Experiments on the synthetic datasets\nshow consistent results with our theoretical claims.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 20:33:10 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 21:47:18 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wang", "Di", ""], ["Xu", "Jinhui", ""]]}, {"id": "1901.06414", "submitter": "Mouloud Belbahri", "authors": "Mouloud Belbahri, Eyy\\\"ub Sari, Sajad Darabi, Vahid Partovi Nia", "title": "Foothill: A Quasiconvex Regularization for Edge Computing of Deep Neural\n  Networks", "comments": "Accepted in 16th International Conference of Image Analysis and\n  Recognition (ICIAR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated success for many supervised\nlearning tasks, ranging from voice recognition, object detection, to image\nclassification. However, their increasing complexity might yield poor\ngeneralization error that make them hard to be deployed on edge devices.\nQuantization is an effective approach to compress DNNs in order to meet these\nconstraints. Using a quasiconvex base function in order to construct a binary\nquantizer helps training binary neural networks (BNNs) and adding noise to the\ninput data or using a concrete regularization function helps to improve\ngeneralization error. Here we introduce foothill function, an infinitely\ndifferentiable quasiconvex function. This regularizer is flexible enough to\ndeform towards $L_1$ and $L_2$ penalties. Foothill can be used as a binary\nquantizer, as a regularizer, or as a loss. In particular, we show this\nregularizer reduces the accuracy gap between BNNs and their full-precision\ncounterpart for image classification on ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 20:39:12 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 12:57:04 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Belbahri", "Mouloud", ""], ["Sari", "Eyy\u00fcb", ""], ["Darabi", "Sajad", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1901.06415", "submitter": "Melvin Wong", "authors": "Melvin Wong and Bilal Farooq", "title": "A bi-partite generative model framework for analyzing and simulating\n  large scale multiple discrete-continuous travel behaviour data", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2019.11.022", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of data-driven demand analysis has led to the increased use of\ngenerative modelling to learn the probabilistic dependencies between random\nvariables. Although their apparent use has mostly been limited to image\nrecognition and classification in recent years, generative machine learning\nalgorithms can be a powerful tool for travel behaviour research by replicating\ntravel behaviour by the underlying properties of data structures. In this\npaper, we examine the use of generative machine learning approach for analyzing\nmultiple discrete-continuous (MDC) travel behaviour data. We provide a\nplausible perspective of how we can exploit the use of machine learning\ntechniques to interpret the underlying heterogeneities in the data. We show\nthat generative models are conceptually similar to the choice selection\nbehaviour process through information entropy and variational Bayesian\ninference. Without loss of generality, we consider a restricted Boltzmann\nmachine (RBM) based algorithm with multiple discrete-continuous layers,\nformulated as a variational Bayesian inference optimization problem. We\nsystematically describe the proposed machine learning algorithm and develop a\nprocess of analyzing travel behaviour data from a generative learning\nperspective. We show parameter stability from model analysis and simulation\ntests on an open dataset with multiple discrete-continuous dimensions from a\ndata size of 293,330 observations. For interpretability, we derive the\nconditional probabilities, elasticities and perform statistical analysis on the\nlatent variables. We show that our model can generate statistically similar\ndata distributions for travel forecasting and prediction and performs better\nthan purely discriminative methods in validation. Our results indicate that\nlatent constructs in generative models can accurately represent the joint\ndistribution consistently on MDC data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 20:42:43 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 14:24:38 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 14:30:53 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wong", "Melvin", ""], ["Farooq", "Bilal", ""]]}, {"id": "1901.06437", "submitter": "Karishma Sharma", "authors": "Karishma Sharma, Feng Qian, He Jiang, Natali Ruchansky, Ming Zhang,\n  Yan Liu", "title": "Combating Fake News: A Survey on Identification and Mitigation\n  Techniques", "comments": null, "journal-ref": "ACM Transactions on Intelligent Systems and Technology, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 22:57:09 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sharma", "Karishma", ""], ["Qian", "Feng", ""], ["Jiang", "He", ""], ["Ruchansky", "Natali", ""], ["Zhang", "Ming", ""], ["Liu", "Yan", ""]]}, {"id": "1901.06469", "submitter": "Jing Zhang", "authors": "Jing Zhang, Jing Tian, Yang Cao, Yuxiang Yang, Xiaobin Xu", "title": "Deep Time-Frequency Representation and Progressive Decision Fusion for\n  ECG Classification", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early recognition of abnormal rhythms in ECG signals is crucial for\nmonitoring and diagnosing patients' cardiac conditions, increasing the success\nrate of the treatment. Classifying abnormal rhythms into exact categories is\nvery challenging due to the broad taxonomy of rhythms, noises and lack of\nlarge-scale real-world annotated data. Different from previous methods that\nutilize hand-crafted features or learn features from the original signal\ndomain, we propose a novel ECG classification method by learning deep\ntime-frequency representation and progressive decision fusion at different\ntemporal scales in an end-to-end manner. First, the ECG wave signal is\ntransformed into the time-frequency domain by using the Short-Time Fourier\nTransform. Next, several scale-specific deep convolutional neural networks are\ntrained on ECG samples of a specific length. Finally, a progressive online\ndecision fusion method is proposed to fuse decisions from the scale-specific\nmodels into a more accurate and stable one. Extensive experiments on both\nsynthetic and real-world ECG datasets demonstrate the effectiveness and\nefficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 05:25:24 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 02:10:38 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 00:36:03 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhang", "Jing", ""], ["Tian", "Jing", ""], ["Cao", "Yang", ""], ["Yang", "Yuxiang", ""], ["Xu", "Xiaobin", ""]]}, {"id": "1901.06483", "submitter": "Vivek Kumar Mr.", "authors": "Vivek Kumar, Manuel Mazzara, Maj. Gen. (Rtd.) Angelo Messina, JooYoung\n  Lee", "title": "A Conjoint Application of Data Mining Techniques for Analysis of Global\n  Terrorist Attacks -- Prevention and Prediction for Combating Terrorism", "comments": "13 pages, 5 Figures, 7 Tables, Proceedings of 6th International\n  Conference in Software Engineering for Defense Applications- SEDA 2018,Rome,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terrorism has become one of the most tedious problems to deal with and a\nprominent threat to mankind. To enhance counter-terrorism, several research\nworks are developing efficient and precise systems, data mining is not an\nexception. Immense data is floating in our lives, though the scarce\navailability of authentic terrorist attack data in the public domain makes it\ncomplicated to fight terrorism. This manuscript focuses on data mining\nclassification techniques and discusses the role of United Nations in\ncounter-terrorism. It analyzes the performance of classifiers such as Lazy\nTree, Multilayer Perceptron, Multiclass and Na\\\"ive Bayes classifiers for\nobserving the trends for terrorist attacks around the world. The database for\nexperiment purpose is created from different public and open access sources for\nyears 1970-2015 comprising of 156,772 reported attacks causing massive losses\nof lives and property. This work enumerates the losses occurred, trends in\nattack frequency and places more prone to it, by considering the attack\nresponsibilities taken as evaluation class.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 08:37:56 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 18:59:43 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 10:08:52 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Kumar", "Vivek", "", "Rtd."], ["Mazzara", "Manuel", "", "Rtd."], ["Gen.", "Maj.", "", "Rtd."], ["Messina", "Angelo", ""], ["Lee", "JooYoung", ""]]}, {"id": "1901.06494", "submitter": "Himanshu Ladia", "authors": "Sourya Dipta Das, Himanshu Ladia, Vaibhav Kumar, Shivansh Mishra", "title": "Writer Independent Offline Signature Recognition Using Ensemble Learning", "comments": "6 pages, 2 figures, International Conference on Data Science, Machine\n  Learning & Applications (ICDSMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of Handwritten Signature Verification has been broadly researched in\nthe last decades, but remains an open research problem. In offline (static)\nsignature verification, the dynamic information of the signature writing\nprocess is lost, and it is difficult to design good feature extractors that can\ndistinguish genuine signatures and skilled forgeries. This verification task is\neven harder in writer independent scenarios which is undeniably fiscal for\nrealistic cases. In this paper, we have proposed an Ensemble model for offline\nwriter, independent signature verification task with Deep learning. We have\nused two CNNs for feature extraction, after that RGBT for classification &\nStacking to generate final prediction vector. We have done extensive\nexperiments on various datasets from various sources to maintain a variance in\nthe dataset. We have achieved the state of the art performance on various\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 09:57:15 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Das", "Sourya Dipta", ""], ["Ladia", "Himanshu", ""], ["Kumar", "Vaibhav", ""], ["Mishra", "Shivansh", ""]]}, {"id": "1901.06523", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu, Yaoyu Zhang, Tao Luo, Yanyang Xiao, Zheng Ma", "title": "Frequency Principle: Fourier Analysis Sheds Light on Deep Neural\n  Networks", "comments": "8 pages, 5 figures, under review", "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0085", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the training process of Deep Neural Networks (DNNs) from the Fourier\nanalysis perspective. We demonstrate a very universal Frequency Principle\n(F-Principle) --- DNNs often fit target functions from low to high frequencies\n--- on high-dimensional benchmark datasets such as MNIST/CIFAR10 and deep\nneural networks such as VGG16. This F-Principle of DNNs is opposite to the\nbehavior of most conventional iterative numerical schemes (e.g., Jacobi\nmethod), which exhibit faster convergence for higher frequencies for various\nscientific computing problems. With a simple theory, we illustrate that this\nF-Principle results from the regularity of the commonly used activation\nfunctions. The F-Principle implies an implicit bias that DNNs tend to fit\ntraining data by a low-frequency function. This understanding provides an\nexplanation of good generalization of DNNs on most real datasets and bad\ngeneralization of DNNs on parity function or randomized dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 13:37:39 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 07:13:27 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 12:14:53 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2019 08:32:15 GMT"}, {"version": "v5", "created": "Fri, 20 Sep 2019 07:39:43 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhang", "Yaoyu", ""], ["Luo", "Tao", ""], ["Xiao", "Yanyang", ""], ["Ma", "Zheng", ""]]}, {"id": "1901.06566", "submitter": "Shaeke Salman", "authors": "Shaeke Salman and Xiuwen Liu", "title": "Overfitting Mechanism and Avoidance in Deep Neural Networks", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assisted by the availability of data and high performance computing, deep\nlearning techniques have achieved breakthroughs and surpassed human performance\nempirically in difficult tasks, including object recognition, speech\nrecognition, and natural language processing. As they are being used in\ncritical applications, understanding underlying mechanisms for their successes\nand limitations is imperative. In this paper, we show that overfitting, one of\nthe fundamental issues in deep neural networks, is due to continuous gradient\nupdating and scale sensitiveness of cross entropy loss. By separating samples\ninto correctly and incorrectly classified ones, we show that they behave very\ndifferently, where the loss decreases in the correct ones and increases in the\nincorrect ones. Furthermore, by analyzing dynamics during training, we propose\na consensus-based classification algorithm that enables us to avoid overfitting\nand significantly improve the classification accuracy especially when the\nnumber of training samples is limited. As each trained neural network depends\non extrinsic factors such as initial values as well as training data, requiring\nconsensus among multiple models reduces extrinsic factors substantially; for\nstatistically independent models, the reduction is exponential. Compared to\nensemble algorithms, the proposed algorithm avoids overgeneralization by not\nclassifying ambiguous inputs. Systematic experimental results demonstrate the\neffectiveness of the proposed algorithm. For example, using only 1000 training\nsamples from MNIST dataset, the proposed algorithm achieves 95% accuracy,\nsignificantly higher than any of the individual models, with 90% of the test\nsamples classified.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 18:08:55 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Salman", "Shaeke", ""], ["Liu", "Xiuwen", ""]]}, {"id": "1901.06569", "submitter": "John Schreck", "authors": "John S. Schreck, Connor W. Coley, Kyle J. M. Bishop", "title": "Learning retrosynthetic planning through self-play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of retrosynthetic planning can be framed as one player game, in\nwhich the chemist (or a computer program) works backwards from a molecular\ntarget to simpler starting materials though a series of choices regarding which\nreactions to perform. This game is challenging as the combinatorial space of\npossible choices is astronomical, and the value of each choice remains\nuncertain until the synthesis plan is completed and its cost evaluated. Here,\nwe address this problem using deep reinforcement learning to identify policies\nthat make (near) optimal reaction choices during each step of retrosynthetic\nplanning. Using simulated experience or self-play, we train neural networks to\nestimate the expected synthesis cost or value of any given molecule based on a\nrepresentation of its molecular structure. We show that learned policies based\non this value network outperform heuristic approaches in synthesizing\nunfamiliar molecules from available starting materials using the fewest number\nof reactions. We discuss how the learned policies described here can be\nincorporated into existing synthesis planning tools and how they can be adapted\nto changes in the synthesis cost objective or material availability.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 18:43:43 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Schreck", "John S.", ""], ["Coley", "Connor W.", ""], ["Bishop", "Kyle J. M.", ""]]}, {"id": "1901.06576", "submitter": "Yinan Zhang", "authors": "Yinan Zhang, Devin Balkcom and Haoxiang Li", "title": "Towards Physically Safe Reinforcement Learning under Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the question of how a previously available control\npolicy $\\pi_s$ can be used as a supervisor to more quickly and safely train a\nnew learned control policy $\\pi_L$ for a robot. A weighted average of the\nsupervisor and learned policies is used during trials, with a heavier weight\ninitially on the supervisor, in order to allow safe and useful physical trials\nwhile the learned policy is still ineffective. During the process, the weight\nis adjusted to favor the learned policy. As weights are adjusted, the learned\nnetwork must compensate so as to give safe and reasonable outputs under the\ndifferent weights. A pioneer network is introduced that pre-learns a policy\nthat performs similarly to the current learned policy under the planned next\nstep for new weights; this pioneer network then replaces the currently learned\nnetwork in the next set of trials. Experiments in OpenAI Gym demonstrate the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 19:16:42 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zhang", "Yinan", ""], ["Balkcom", "Devin", ""], ["Li", "Haoxiang", ""]]}, {"id": "1901.06580", "submitter": "Senthil Yogamani", "authors": "Arindam Das, Saranya Kandan, Senthil Yogamani, Pavel Krizek", "title": "Design of Real-time Semantic Segmentation Decoder for Automated Driving", "comments": "Accepted at VISAPP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation remains a computationally intensive algorithm for\nembedded deployment even with the rapid growth of computation power. Thus\nefficient network design is a critical aspect especially for applications like\nautomated driving which requires real-time performance. Recently, there has\nbeen a lot of research on designing efficient encoders that are mostly task\nagnostic. Unlike image classification and bounding box object detection tasks,\ndecoders are computationally expensive as well for semantic segmentation task.\nIn this work, we focus on efficient design of the segmentation decoder and\nassume that an efficient encoder is already designed to provide shared features\nfor a multi-task learning system. We design a novel efficient non-bottleneck\nlayer and a family of decoders which fit into a small run-time budget using\nVGG10 as efficient encoder. We demonstrate in our dataset that experimentation\nwith various design choices led to an improvement of 10\\% from a baseline\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 19:51:31 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Das", "Arindam", ""], ["Kandan", "Saranya", ""], ["Yogamani", "Senthil", ""], ["Krizek", "Pavel", ""]]}, {"id": "1901.06587", "submitter": "Seyed Mohammadreza Mousavi Kalan", "authors": "Seyed Mohammadreza Mousavi Kalan, Mahdi Soltanolkotabi, and A. Salman\n  Avestimehr", "title": "Fitting ReLUs via SGD and Quantized SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of finding the optimal weights of the\nshallowest of neural networks consisting of a single Rectified Linear Unit\n(ReLU). These functions are of the form $\\mathbf{x}\\rightarrow\n\\max(0,\\langle\\mathbf{w},\\mathbf{x}\\rangle)$ with $\\mathbf{w}\\in\\mathbb{R}^d$\ndenoting the weight vector. We focus on a planted model where the inputs are\nchosen i.i.d. from a Gaussian distribution and the labels are generated\naccording to a planted weight vector. We first show that mini-batch stochastic\ngradient descent when suitably initialized, converges at a geometric rate to\nthe planted model with a number of samples that is optimal up to numerical\nconstants. Next we focus on a parallel implementation where in each iteration\nthe mini-batch gradient is calculated in a distributed manner across multiple\nprocessors and then broadcast to a master or all other processors. To reduce\nthe communication cost in this setting we utilize a Quanitzed Stochastic\nGradient Scheme (QSGD) where the partial gradients are quantized. Perhaps\nunexpectedly, we show that QSGD maintains the fast convergence of SGD to a\nglobally optimal model while significantly reducing the communication cost. We\nfurther corroborate our numerical findings via various experiments including\ndistributed implementations over Amazon EC2.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 21:21:54 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 17:48:22 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kalan", "Seyed Mohammadreza Mousavi", ""], ["Soltanolkotabi", "Mahdi", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1901.06588", "submitter": "Charbel Sakr", "authors": "Charbel Sakr, Naigang Wang, Chia-Yu Chen, Jungwook Choi, Ankur\n  Agrawal, Naresh Shanbhag, Kailash Gopalakrishnan", "title": "Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep\n  Networks", "comments": "Published as a conference paper in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts to reduce the numerical precision of computations in deep learning\ntraining have yielded systems that aggressively quantize weights and\nactivations, yet employ wide high-precision accumulators for partial sums in\ninner-product operations to preserve the quality of convergence. The absence of\nany framework to analyze the precision requirements of partial sum\naccumulations results in conservative design choices. This imposes an\nupper-bound on the reduction of complexity of multiply-accumulate units. We\npresent a statistical approach to analyze the impact of reduced accumulation\nprecision on deep learning training. Observing that a bad choice for\naccumulation precision results in loss of information that manifests itself as\na reduction in variance in an ensemble of partial sums, we derive a set of\nequations that relate this variance to the length of accumulation and the\nminimum number of bits needed for accumulation. We apply our analysis to three\nbenchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet\nAlexNet. In each case, with accumulation precision set in accordance with our\nproposed equations, the networks successfully converge to the single precision\nfloating-point baseline. We also show that reducing accumulation precision\nfurther degrades the quality of the trained network, proving that our equations\nproduce tight bounds. Overall this analysis enables precise tailoring of\ncomputation hardware to the application, yielding area- and power-optimal\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 21:27:28 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sakr", "Charbel", ""], ["Wang", "Naigang", ""], ["Chen", "Chia-Yu", ""], ["Choi", "Jungwook", ""], ["Agrawal", "Ankur", ""], ["Shanbhag", "Naresh", ""], ["Gopalakrishnan", "Kailash", ""]]}, {"id": "1901.06618", "submitter": "Marzyeh Ghassemi", "authors": "Denny Wu, Hirofumi Kobayashi, Charles Ding, Lei Cheng, Keisuke Goda\n  Marzyeh Ghassemi", "title": "Modeling the Biological Pathology Continuum with HSIC-regularized\n  Wasserstein Auto-encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial challenge in image-based modeling of biomedical data is to identify\ntrends and features that separate normality and pathology. In many cases, the\nmorphology of the imaged object exhibits continuous change as it deviates from\nnormality, and thus a generative model can be trained to model this\nmorphological continuum. Moreover, given side information that correlates to\ncertain trend in morphological change, a latent variable model can be\nregularized such that its latent representation reflects this side information.\nIn this work, we use the Wasserstein Auto-encoder to model this pathology\ncontinuum, and apply the Hilbert-Schmitt Independence Criterion (HSIC) to\nenforce dependency between certain latent features and the provided side\ninformation. We experimentally show that the model can provide disentangled and\ninterpretable latent representations and also generate a continuum of\nmorphological changes that corresponds to change in the side information.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 03:40:55 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Wu", "Denny", ""], ["Kobayashi", "Hirofumi", ""], ["Ding", "Charles", ""], ["Cheng", "Lei", ""], ["Ghassemi", "Keisuke Goda Marzyeh", ""]]}, {"id": "1901.06654", "submitter": "Uddeshya Upadhyay", "authors": "Uddeshya Upadhyay, Arjun Jain", "title": "Removal of Batch Effects using Generative Adversarial Networks", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological data analysis processes like Cytometry or Next Generation\nSequencing (NGS) produce massive amounts of data which needs to be processed in\nbatches for down-stream analysis. Such datasets are prone to technical\nvariations due to difference in handling the batches possibly at different\ntimes, by different experimenters or under other different conditions. This\nadds variation to the batches coming from the same source sample. These\nvariations are known as Batch Effects. It is possible that these variations and\nnatural variations due to biology confound but such situations can be avoided\nby performing experiments in a carefully planned manner. Batch effects can\nhamper downstream analysis and may also cause results to be inconclusive. Thus,\nit is essential to correct for these effects. This can be solved using a novel\nGenerative Adversarial Networks (GANs) based framework that is proposed here,\nadvantage of using this framework over other prior approaches is that here it\nis not required to choose a reproducing kernel and define its parameters.\nResults of the framework on a mass cytometry dataset are reported.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 10:29:52 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 12:24:17 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 13:43:19 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Upadhyay", "Uddeshya", ""], ["Jain", "Arjun", ""]]}, {"id": "1901.06656", "submitter": "Arild N{\\o}kland", "authors": "Arild N{\\o}kland and Lars Hiller Eidnes", "title": "Training Neural Networks with Local Error Signals", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training of neural networks for classification is typically\nperformed with a global loss function. The loss function provides a gradient\nfor the output layer, and this gradient is back-propagated to hidden layers to\ndictate an update direction for the weights. An alternative approach is to\ntrain the network with layer-wise loss functions. In this paper we demonstrate,\nfor the first time, that layer-wise training can approach the state-of-the-art\non a variety of image datasets. We use single-layer sub-networks and two\ndifferent supervised loss functions to generate local error signals for the\nhidden layers, and we show that the combination of these losses help with\noptimization in the context of local learning. Using local errors could be a\nstep towards more biologically plausible deep learning because the global error\ndoes not have to be transported back to hidden layers. A completely backprop\nfree variant outperforms previously reported results among methods aiming for\nhigher biological plausibility. Code is available\nhttps://github.com/anokland/local-loss\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 10:59:53 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 18:49:45 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["N\u00f8kland", "Arild", ""], ["Eidnes", "Lars Hiller", ""]]}, {"id": "1901.06708", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Aydin Ghojogh, Mark Crowley, Fakhri Karray", "title": "Fitting A Mixture Distribution to Data: Tutorial", "comments": "12 pages, 9 figures, 1 table. Some typos are corrected in this\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a step-by-step tutorial for fitting a mixture distribution to\ndata. It merely assumes the reader has the background of calculus and linear\nalgebra. Other required background is briefly reviewed before explaining the\nmain algorithm. In explaining the main algorithm, first, fitting a mixture of\ntwo distributions is detailed and examples of fitting two Gaussians and\nPoissons, respectively for continuous and discrete cases, are introduced.\nThereafter, fitting several distributions in general case is explained and\nexamples of several Gaussians (Gaussian Mixture Model) and Poissons are again\nprovided. Model-based clustering, as one of the applications of mixture\ndistributions, is also introduced. Numerical simulations are also provided for\nboth Gaussian and Poisson examples for the sake of better clarification.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:17:40 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 20:49:26 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghojogh", "Aydin", ""], ["Crowley", "Mark", ""], ["Karray", "Fakhri", ""]]}, {"id": "1901.06752", "submitter": "Gang Hu", "authors": "Gang Hu and K.C.S. Kwok", "title": "Predicting wind pressures around circular cylinders using machine\n  learning techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies have been carried out to measure wind pressures around\ncircular cylinders since the early 20th century due to its engineering\nsignificance. Consequently, a large amount of wind pressure data sets have\naccumulated, which presents an excellent opportunity for using machine learning\n(ML) techniques to train models to predict wind pressures around circular\ncylinders. Wind pressures around smooth circular cylinders are a function of\nmainly the Reynolds number (Re), turbulence intensity (Ti) of the incident\nwind, and circumferential angle of the cylinder. Considering these three\nparameters as the inputs, this study trained two ML models to predict mean and\nfluctuating pressures respectively. Three machine learning algorithms including\ndecision tree regressor, random forest, and gradient boosting regression trees\n(GBRT) were tested. The GBRT models exhibited the best performance for\npredicting both mean and fluctuating pressures, and they are capable of making\naccurate predictions for Re ranging from 10^4 to 10^6 and Ti ranging from 0% to\n15%. It is believed that the GBRT models provide very efficient and economical\nalternative to traditional wind tunnel tests and computational fluid dynamic\nsimulations for determining wind pressures around smooth circular cylinders\nwithin the studied Re and Ti range.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 00:04:48 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Hu", "Gang", ""], ["Kwok", "K. C. S.", ""]]}, {"id": "1901.06758", "submitter": "Shuguan Yang", "authors": "Shuguan Yang, Wei Ma, Xidong Pi, Sean Qian", "title": "A deep learning approach to real-time parking occupancy prediction in\n  spatio-temporal networks incorporating multiple spatio-temporal data sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning model is applied for predicting block-level parking occupancy\nin real time. The model leverages Graph-Convolutional Neural Networks (GCNN) to\nextract the spatial relations of traffic flow in large-scale networks, and\nutilizes Recurrent Neural Networks (RNN) with Long-Short Term Memory (LSTM) to\ncapture the temporal features. In addition, the model is capable of taking\nmultiple heterogeneously structured traffic data sources as input, such as\nparking meter transactions, traffic speed, and weather conditions. The model\nperformance is evaluated through a case study in Pittsburgh downtown area. The\nproposed model outperforms other baseline methods including multi-layer LSTM\nand Lasso with an average testing MAPE of 10.6\\% when predicting block-level\nparking occupancies 30 minutes in advance. The case study also shows that, in\ngenerally, the prediction model works better for business areas than for\nrecreational locations. We found that incorporating traffic speed and weather\ninformation can significantly improve the prediction performance. Weather data\nis particularly useful for improving predicting accuracy in recreational areas.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 01:20:27 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 03:55:34 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 19:51:47 GMT"}, {"version": "v4", "created": "Sun, 10 Mar 2019 03:28:01 GMT"}, {"version": "v5", "created": "Sat, 11 May 2019 01:03:43 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Yang", "Shuguan", ""], ["Ma", "Wei", ""], ["Pi", "Xidong", ""], ["Qian", "Sean", ""]]}, {"id": "1901.06764", "submitter": "Rasmus J Kyng", "authors": "Deeksha Adil, Rasmus Kyng, Richard Peng, Sushant Sachdeva", "title": "Iterative Refinement for $\\ell_p$-norm Regression", "comments": "Published in SODA 2019. Was initially submitted to SODA on July 12,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give improved algorithms for the $\\ell_{p}$-regression problem, $\\min_{x}\n\\|x\\|_{p}$ such that $A x=b,$ for all $p \\in (1,2) \\cup (2,\\infty).$ Our\nalgorithms obtain a high accuracy solution in $\\tilde{O}_{p}(m^{\\frac{|p-2|}{2p\n+ |p-2|}}) \\le \\tilde{O}_{p}(m^{\\frac{1}{3}})$ iterations, where each iteration\nrequires solving an $m \\times m$ linear system, $m$ being the dimension of the\nambient space.\n  By maintaining an approximate inverse of the linear systems that we solve in\neach iteration, we give algorithms for solving $\\ell_{p}$-regression to $1 /\n\\text{poly}(n)$ accuracy that run in time $\\tilde{O}_p(m^{\\max\\{\\omega,\n7/3\\}}),$ where $\\omega$ is the matrix multiplication constant. For the current\nbest value of $\\omega > 2.37$, we can thus solve $\\ell_{p}$ regression as fast\nas $\\ell_{2}$ regression, for all constant $p$ bounded away from $1.$\n  Our algorithms can be combined with fast graph Laplacian linear equation\nsolvers to give minimum $\\ell_{p}$-norm flow / voltage solutions to $1 /\n\\text{poly}(n)$ accuracy on an undirected graph with $m$ edges in\n$\\tilde{O}_{p}(m^{1 + \\frac{|p-2|}{2p + |p-2|}}) \\le\n\\tilde{O}_{p}(m^{\\frac{4}{3}})$ time.\n  For sparse graphs and for matrices with similar dimensions, our iteration\ncounts and running times improve on the $p$-norm regression algorithm by\n[Bubeck-Cohen-Lee-Li STOC`18] and general-purpose convex optimization\nalgorithms. At the core of our algorithms is an iterative refinement scheme for\n$\\ell_{p}$-norms, using the smoothed $\\ell_{p}$-norms introduced in the work of\nBubeck et al. Given an initial solution, we construct a problem that seeks to\nminimize a quadratically-smoothed $\\ell_{p}$ norm over a subspace, such that a\ncrude solution to this problem allows us to improve the initial solution by a\nconstant factor, leading to algorithms with fast convergence.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 01:42:53 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Adil", "Deeksha", ""], ["Kyng", "Rasmus", ""], ["Peng", "Richard", ""], ["Sachdeva", "Sushant", ""]]}, {"id": "1901.06803", "submitter": "Sumit Kumar", "authors": "Sumit Kumar, Wenhao Luo, George Kantor, Katia Sycara", "title": "Active Learning with Gaussian Processes for High Throughput Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A looming question that must be solved before robotic plant phenotyping\ncapabilities can have significant impact to crop improvement programs is\nscalability. High Throughput Phenotyping (HTP) uses robotic technologies to\nanalyze crops in order to determine species with favorable traits, however, the\ncurrent practices rely on exhaustive coverage and data collection from the\nentire crop field being monitored under the breeding experiment. This works\nwell in relatively small agricultural fields but can not be scaled to the\nlarger ones, thus limiting the progress of genetics research. In this work, we\npropose an active learning algorithm to enable an autonomous system to collect\nthe most informative samples in order to accurately learn the distribution of\nphenotypes in the field with the help of a Gaussian Process model. We\ndemonstrate the superior performance of our proposed algorithm compared to the\ncurrent practices on sorghum phenotype data collection.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 06:35:02 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kumar", "Sumit", ""], ["Luo", "Wenhao", ""], ["Kantor", "George", ""], ["Sycara", "Katia", ""]]}, {"id": "1901.06827", "submitter": "Lisa Maria Kreusser", "authors": "Lisa Maria Kreusser and Stanley J. Osher and Bao Wang", "title": "A Deterministic Gradient-Based Approach to Avoid Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Loss functions with a large number of saddle points are one of the major\nobstacles for training modern machine learning models efficiently. First-order\nmethods such as gradient descent are usually the methods of choice for training\nmachine learning models. However, these methods converge to saddle points for\ncertain choices of initial guesses. In this paper, we propose a modification of\nthe recently proposed Laplacian smoothing gradient descent [Osher et al.,\narXiv:1806.06317], called modified Laplacian smoothing gradient descent\n(mLSGD), and demonstrate its potential to avoid saddle points without\nsacrificing the convergence rate. Our analysis is based on the attraction\nregion, formed by all starting points for which the considered numerical scheme\nconverges to a saddle point. We investigate the attraction region's dimension\nboth analytically and numerically. For a canonical class of quadratic\nfunctions, we show that the dimension of the attraction region for mLSGD is\nfloor((n-1)/2), and hence it is significantly smaller than that of the gradient\ndescent whose dimension is n-1.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 08:51:18 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 13:26:13 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kreusser", "Lisa Maria", ""], ["Osher", "Stanley J.", ""], ["Wang", "Bao", ""]]}, {"id": "1901.06834", "submitter": "Mahmoud Salamati", "authors": "Mahmoud Salamati, Sadegh Soudjani and Rupak Majumdar", "title": "Perception-in-the-Loop Adversarial Examples", "comments": "13 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable, black box, perception-in-the-loop technique to find\nadversarial examples for deep neural network classifiers. Black box means that\nour procedure only has input-output access to the classifier, and not to the\ninternal structure, parameters, or intermediate confidence values.\nPerception-in-the-loop means that the notion of proximity between inputs can be\ndirectly queried from human participants rather than an arbitrarily chosen\nmetric. Our technique is based on covariance matrix adaptation evolution\nstrategy (CMA-ES), a black box optimization approach. CMA-ES explores the\nsearch space iteratively in a black box manner, by generating populations of\ncandidates according to a distribution, choosing the best candidates according\nto a cost function, and updating the posterior distribution to favor the best\ncandidates. We run CMA-ES using human participants to provide the fitness\nfunction, using the insight that the choice of best candidates in CMA-ES can be\nnaturally modeled as a perception task: pick the top $k$ inputs perceptually\nclosest to a fixed input. We empirically demonstrate that finding adversarial\nexamples is feasible using small populations and few iterations. We compare the\nperformance of CMA-ES on the MNIST benchmark with other black-box approaches\nusing $L_p$ norms as a cost function, and show that it performs favorably both\nin terms of success in finding adversarial examples and in minimizing the\ndistance between the original and the adversarial input. In experiments on the\nMNIST, CIFAR10, and GTSRB benchmarks, we demonstrate that CMA-ES can find\nperceptually similar adversarial inputs with a small number of iterations and\nsmall population sizes when using perception-in-the-loop. Finally, we show that\nnetworks trained specifically to be robust against $L_\\infty$ norm can still be\nsusceptible to perceptually similar adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 09:09:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Salamati", "Mahmoud", ""], ["Soudjani", "Sadegh", ""], ["Majumdar", "Rupak", ""]]}, {"id": "1901.06852", "submitter": "Amr Alexandari", "authors": "Amr Alexandari, Anshul Kundaje, Avanti Shrikumar", "title": "Maximum Likelihood with Bias-Corrected Calibration is Hard-To-Beat at\n  Label Shift Adaptation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Label shift refers to the phenomenon where the prior class probability p(y)\nchanges between the training and test distributions, while the conditional\nprobability p(x|y) stays fixed. Label shift arises in settings like medical\ndiagnosis, where a classifier trained to predict disease given symptoms must be\nadapted to scenarios where the baseline prevalence of the disease is different.\nGiven estimates of p(y|x) from a predictive model, Saerens et al. proposed an\nefficient maximum likelihood algorithm to correct for label shift that does not\nrequire model retraining, but a limiting assumption of this algorithm is that\np(y|x) is calibrated, which is not true of modern neural networks. Recently,\nBlack Box Shift Learning (BBSL) and Regularized Learning under Label Shifts\n(RLLS) have emerged as state-of-the-art techniques to cope with label shift\nwhen a classifier does not output calibrated probabilities, but both methods\nrequire model retraining with importance weights and neither has been\nbenchmarked against maximum likelihood. Here we (1) show that combining maximum\nlikelihood with a type of calibration we call bias-corrected calibration\noutperforms both BBSL and RLLS across diverse datasets and distribution shifts,\n(2) prove that the maximum likelihood objective is concave, and (3) introduce a\nprincipled strategy for estimating source-domain priors that improves\nrobustness to poor calibration. This work demonstrates that the maximum\nlikelihood with appropriate calibration is a formidable and efficient baseline\nfor label shift adaptation; notebooks reproducing experiments available at\nhttps://github.com/kundajelab/labelshiftexperiments\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 10:05:24 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 16:57:19 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 18:36:38 GMT"}, {"version": "v4", "created": "Sat, 25 Jan 2020 01:02:06 GMT"}, {"version": "v5", "created": "Sat, 27 Jun 2020 03:40:09 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Alexandari", "Amr", ""], ["Kundaje", "Anshul", ""], ["Shrikumar", "Avanti", ""]]}, {"id": "1901.06901", "submitter": "Masayuki Ohzeki", "authors": "Masayuki Ohzeki", "title": "Message-passing algorithm of quantum annealing with nonstoquastic\n  Hamiltonian", "comments": "17 pages", "journal-ref": null, "doi": "10.7566/JPSJ.88.061005", "report-no": null, "categories": "cond-mat.dis-nn cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum annealing (QA) is a generic method for solving optimization problems\nusing fictitious quantum fluctuation. The current device performing QA involves\ncontrolling the transverse field; it is classically simulatable by using the\nstandard technique for mapping the quantum spin systems to the classical ones.\nIn this sense, the current system for QA is not powerful despite utilizing\nquantum fluctuation. Hence, we developed a system with a time-dependent\nHamiltonian consisting of a combination of the formulated Ising model and the\n\"driver\" Hamiltonian with only quantum fluctuation. In the previous study, for\na fully connected spin model, quantum fluctuation can be addressed in a\nrelatively simple way. We proved that the fully connected antiferromagnetic\ninteraction can be transformed into a fluctuating transverse field and is thus\nclassically simulatable at sufficiently low temperatures. Using the fluctuating\ntransverse field, we established several ways to simulate part of the\nnonstoquastic Hamiltonian on classical computers. We formulated a\nmessage-passing algorithm in the present study. This algorithm is capable of\nassessing the performance of QA with part of the nonstoquastic Hamiltonian\nhaving a large number of spins. In other words, we developed a different\napproach for simulating the nonstoquastic Hamiltonian without using the quantum\nMonte Carlo technique. Our results were validated by comparison to the results\nobtained by the replica method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 12:14:40 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 00:51:27 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Ohzeki", "Masayuki", ""]]}, {"id": "1901.06950", "submitter": "David Kaltenpoth", "authors": "David Kaltenpoth and Jilles Vreeken", "title": "We Are Not Your Real Parents: Telling Causal from Confounded using MDL", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data over variables $(X_1,...,X_m, Y)$ we consider the problem of\nfinding out whether $X$ jointly causes $Y$ or whether they are all confounded\nby an unobserved latent variable $Z$. To do so, we take an\ninformation-theoretic approach based on Kolmogorov complexity. In a nutshell,\nwe follow the postulate that first encoding the true cause, and then the\neffects given that cause, results in a shorter description than any other\nencoding of the observed variables.\n  The ideal score is not computable, and hence we have to approximate it. We\npropose to do so using the Minimum Description Length (MDL) principle. We\ncompare the MDL scores under the models where $X$ causes $Y$ and where there\nexists a latent variables $Z$ confounding both $X$ and $Y$ and show our scores\nare consistent. To find potential confounders we propose using latent factor\nmodeling, in particular, probabilistic PCA (PPCA).\n  Empirical evaluation on both synthetic and real-world data shows that our\nmethod, CoCa, performs very well -- even when the true generating process of\nthe data is far from the assumptions made by the models we use. Moreover, it is\nrobust as its accuracy goes hand in hand with its confidence.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:09:34 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Kaltenpoth", "David", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1901.06958", "submitter": "Istv\\'an Ketyk\\'o", "authors": "Istv\\'an Ketyk\\'o, Ferenc Kov\\'acs and Kriszti\\'an Zsolt Varga", "title": "Domain Adaptation for sEMG-based Gesture Recognition with Recurrent\n  Neural Networks", "comments": "Typos corrected", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN),\n  Budapest, Hungary, 2019, pp. 1-7", "doi": "10.1109/IJCNN.2019.8852018", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface Electromyography (sEMG/EMG) is to record muscles' electrical activity\nfrom a restricted area of the skin by using electrodes. The sEMG-based gesture\nrecognition is extremely sensitive of inter-session and inter-subject\nvariances. We propose a model and a deep-learning-based domain adaptation\nmethod to approximate the domain shift for recognition accuracy enhancement.\nAnalysis performed on sparse and HighDensity (HD) sEMG public datasets validate\nthat our approach outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:19:01 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 15:51:32 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ketyk\u00f3", "Istv\u00e1n", ""], ["Kov\u00e1cs", "Ferenc", ""], ["Varga", "Kriszti\u00e1n Zsolt", ""]]}, {"id": "1901.06978", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Yu Yang, Qian Yu, Ying Nian Wu", "title": "Network Transplanting (extended abstract)", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  arXiv admin note: substantial text overlap with arXiv:1804.10272", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a new task, i.e., transplanting a\ncategory-and-task-specific neural network to a generic, modular network without\nstrong supervision. We design a functionally interpretable structure for the\ngeneric network. Like building LEGO blocks, we teach the generic network a new\ncategory by directly transplanting the module corresponding to the category\nfrom a pre-trained network with a few or even without sample annotations. Our\nmethod incrementally adds new categories to the generic network but does not\naffect representations of existing categories. In this way, our method breaks\nthe typical bottleneck of learning a net for massive tasks and categories,\ni.e., the requirement of collecting samples for all tasks and categories at the\nsame time before the learning begins. Thus, we use a new distillation\nalgorithm, namely back-distillation, to overcome specific challenges of network\ntransplanting. Our method without training samples even outperformed the\nbaseline with 100 training samples.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:58:28 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zhang", "Quanshi", ""], ["Yang", "Yu", ""], ["Yu", "Qian", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1901.06995", "submitter": "Usman Khan", "authors": "Ran Xin, Dusan Jakovetic, Usman A. Khan", "title": "Distributed Nesterov gradient methods over arbitrary graphs", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2925537", "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we introduce a distributed Nesterov method, termed as\n$\\mathcal{ABN}$, that does not require doubly-stochastic weight matrices.\nInstead, the implementation is based on a simultaneous application of both row-\nand column-stochastic weights that makes this method applicable to arbitrary\n(strongly-connected) graphs. Since constructing column-stochastic weights needs\nadditional information (the number of outgoing neighbors at each agent), not\navailable in certain communication protocols, we derive a variation, termed as\nFROZEN, that only requires row-stochastic weights but at the expense of\nadditional iterations for eigenvector learning. We numerically study these\nalgorithms for various objective functions and network parameters and show that\nthe proposed distributed Nesterov methods achieve acceleration compared to the\ncurrent state-of-the-art methods for distributed optimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 16:43:31 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Xin", "Ran", ""], ["Jakovetic", "Dusan", ""], ["Khan", "Usman A.", ""]]}, {"id": "1901.07002", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Error-Correcting Neural Sequence Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel neural sequence prediction method based on\n\\textit{error-correcting output codes} that avoids exact softmax normalization\nand allows for a tradeoff between speed and performance. Instead of minimizing\nmeasures between the predicted probability distribution and true distribution,\nwe use error-correcting codes to represent both predictions and outputs.\nSecondly, we propose multiple ways to improve accuracy and convergence rates by\nmaximizing the separability between codes that correspond to classes\nproportional to word embedding similarities. Lastly, we introduce our main\ncontribution called \\textit{Latent Variable Mixture Sampling}, a technique that\nis used to mitigate exposure bias, which can be integrated into training latent\nvariable-based neural sequence predictors such as ECOC. This involves mixing\nthe latent codes of past predictions and past targets in one of two ways: (1)\naccording to a predefined sampling schedule or (2) a differentiable sampling\nprocedure whereby the mixing probability is learned throughout training by\nreplacing the greedy argmax operation with a smooth approximation. ECOC-NSP\nleads to consistent improvements on language modelling datasets and the\nproposed Latent Variable mixture sampling methods are found to perform well for\ntext generation tasks such as image captioning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:17:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 21:39:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1901.07010", "submitter": "Reazul Hasan Russel", "authors": "Reazul Hasan Russel", "title": "A Short Survey on Probabilistic Reinforcement Learning", "comments": "7 pages, originally written as a literature survey for PhD candidacy\n  exam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reinforcement learning agent tries to maximize its cumulative payoff by\ninteracting in an unknown environment. It is important for the agent to explore\nsuboptimal actions as well as to pick actions with highest known rewards. Yet,\nin sensitive domains, collecting more data with exploration is not always\npossible, but it is important to find a policy with a certain performance\nguaranty. In this paper, we present a brief survey of methods available in the\nliterature for balancing exploration-exploitation trade off and computing\nrobust solutions from fixed samples in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 17:52:06 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Russel", "Reazul Hasan", ""]]}, {"id": "1901.07017", "submitter": "Nicholas Watters", "authors": "Nicholas Watters, Loic Matthey, Christopher P. Burgess, Alexander\n  Lerchner", "title": "Spatial Broadcast Decoder: A Simple Architecture for Learning\n  Disentangled Representations in VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple neural rendering architecture that helps variational\nautoencoders (VAEs) learn disentangled representations. Instead of the\ndeconvolutional network typically used in the decoder of VAEs, we tile\n(broadcast) the latent vector across space, concatenate fixed X- and\nY-\"coordinate\" channels, and apply a fully convolutional network with 1x1\nstride. This provides an architectural prior for dissociating positional from\nnon-positional features in the latent distribution of VAEs, yet without\nproviding any explicit supervision to this effect. We show that this\narchitecture, which we term the Spatial Broadcast decoder, improves\ndisentangling, reconstruction accuracy, and generalization to held-out regions\nin data space. It provides a particularly dramatic benefit when applied to\ndatasets with small objects. We also emphasize a method for visualizing learned\nlatent spaces that helped us diagnose our models and may prove useful for\nothers aiming to assess data representations. Finally, we show the Spatial\nBroadcast Decoder is complementary to state-of-the-art (SOTA) disentangling\ntechniques and when incorporated improves their performance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 18:08:49 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 10:02:46 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Watters", "Nicholas", ""], ["Matthey", "Loic", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1901.07061", "submitter": "Mohammad Tofighi", "authors": "Mohammad Tofighi, Tiantong Guo, Jairam K.P. Vanamala, and Vishal Monga", "title": "Prior Information Guided Regularized Deep Learning for Cell Nucleus\n  Detection", "comments": "Accepted for Publication", "journal-ref": "IEEE Transactions on Medical Imaging, January 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell nuclei detection is a challenging research topic because of limitations\nin cellular image quality and diversity of nuclear morphology, i.e. varying\nnuclei shapes, sizes, and overlaps between multiple cell nuclei. This has been\na topic of enduring interest with promising recent success shown by deep\nlearning methods. These methods train Convolutional Neural Networks (CNNs) with\na training set of input images and known, labeled nuclei locations. Many such\nmethods are supplemented by spatial or morphological processing. Using a set of\ncanonical cell nuclei shapes, prepared with the help of a domain expert, we\ndevelop a new approach that we call Shape Priors with Convolutional Neural\nNetworks (SP-CNN). We further extend the network to introduce a shape prior\n(SP) layer and then allowing it to become trainable (i.e. optimizable). We call\nthis network tunable SP-CNN (TSP-CNN). In summary, we present new network\nstructures that can incorporate 'expected behavior' of nucleus shapes via two\ncomponents: learnable layers that perform the nucleus detection and a fixed\nprocessing part that guides the learning with prior information. Analytically,\nwe formulate two new regularization terms that are targeted at: 1) learning the\nshapes, 2) reducing false positives while simultaneously encouraging detection\ninside the cell nucleus boundary. Experimental results on two challenging\ndatasets reveal that the proposed SP-CNN and TSP-CNN can outperform\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 20:06:46 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Tofighi", "Mohammad", ""], ["Guo", "Tiantong", ""], ["Vanamala", "Jairam K. P.", ""], ["Monga", "Vishal", ""]]}, {"id": "1901.07114", "submitter": "Tengyuan Liang", "authors": "Xialiang Dou, Tengyuan Liang", "title": "Training Neural Networks as Learning Data-adaptive Kernels: Provable\n  Representation and Approximation Benefits", "comments": "38 pages, 5 figures", "journal-ref": "Journal of the American Statistical Association (2020)", "doi": "10.1080/01621459.2020.1745812", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem: given the data pair $(\\mathbf{x}, \\mathbf{y})$ drawn\nfrom a population with $f_*(x) = \\mathbf{E}[\\mathbf{y} | \\mathbf{x} = x]$,\nspecify a neural network model and run gradient flow on the weights over time\nuntil reaching any stationarity. How does $f_t$, the function computed by the\nneural network at time $t$, relate to $f_*$, in terms of approximation and\nrepresentation? What are the provable benefits of the adaptive representation\nby neural networks compared to the pre-specified fixed basis representation in\nthe classical nonparametric literature? We answer the above questions via a\ndynamic reproducing kernel Hilbert space (RKHS) approach indexed by the\ntraining process of neural networks. Firstly, we show that when reaching any\nlocal stationarity, gradient flow learns an adaptive RKHS representation and\nperforms the global least-squares projection onto the adaptive RKHS,\nsimultaneously. Secondly, we prove that as the RKHS is data-adaptive and\ntask-specific, the residual for $f_*$ lies in a subspace that is potentially\nmuch smaller than the orthogonal complement of the RKHS. The result formalizes\nthe representation and approximation benefits of neural networks. Lastly, we\nshow that the neural network function computed by gradient flow converges to\nthe kernel ridgeless regression with an adaptive kernel, in the limit of\nvanishing regularization. The adaptive kernel viewpoint provides new angles of\nstudying the approximation, representation, generalization, and optimization\nadvantages of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 23:15:16 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 15:03:28 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Dou", "Xialiang", ""], ["Liang", "Tengyuan", ""]]}, {"id": "1901.07132", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Di Li, Danilo Vasconcellos Vargas, Sakurai Kouichi", "title": "Universal Rules for Fooling Deep Neural Networks based Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning based natural language processing techniques are\nbeing extensively used to deal with spam mail, censorship evaluation in social\nnetworks, among others. However, there is only a couple of works evaluating the\nvulnerabilities of such deep neural networks. Here, we go beyond attacks to\ninvestigate, for the first time, universal rules, i.e., rules that are sample\nagnostic and therefore could turn any text sample in an adversarial one. In\nfact, the universal rules do not use any information from the method itself (no\ninformation from the method, gradient information or training dataset\ninformation is used), making them black-box universal attacks. In other words,\nthe universal rules are sample and method agnostic. By proposing a\ncoevolutionary optimization algorithm we show that it is possible to create\nuniversal rules that can automatically craft imperceptible adversarial samples\n(only less than five perturbations which are close to misspelling are inserted\nin the text sample). A comparison with a random search algorithm further\njustifies the strength of the method. Thus, universal rules for fooling\nnetworks are here shown to exist. Hopefully, the results from this work will\nimpact the development of yet more sample and model agnostic attacks as well as\ntheir defenses, culminating in perhaps a new age for artificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 00:54:30 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 05:55:49 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Li", "Di", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Kouichi", "Sakurai", ""]]}, {"id": "1901.07152", "submitter": "Hai Shu", "authors": "Hai Shu, Hongtu Zhu", "title": "Sensitivity Analysis of Deep Neural Networks", "comments": "Accepted by AAAI-19", "journal-ref": "AAAI Conference on Artificial Intelligence (2019), pp. 4943-4950", "doi": "10.1609/aaai.v33i01.33014943", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved superior performance in various\nprediction tasks, but can be very vulnerable to adversarial examples or\nperturbations. Therefore, it is crucial to measure the sensitivity of DNNs to\nvarious forms of perturbations in real applications. We introduce a novel\nperturbation manifold and its associated influence measure to quantify the\neffects of various perturbations on DNN classifiers. Such perturbations include\nvarious external and internal perturbations to input samples and network\nparameters. The proposed measure is motivated by information geometry and\nprovides desirable invariance properties. We demonstrate that our influence\nmeasure is useful for four model building tasks: detecting potential\n'outliers', analyzing the sensitivity of model architectures, comparing network\nsensitivity between training and test sets, and locating vulnerable areas.\nExperiments show reasonably good performance of the proposed measure for the\npopular DNN models ResNet50 and DenseNet121 on CIFAR10 and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 02:14:16 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Shu", "Hai", ""], ["Zhu", "Hongtu", ""]]}, {"id": "1901.07165", "submitter": "Kentaro Fukamizu", "authors": "Kentaro Fukamizu, Masaaki Kondo, Ryuichi Sakamoto", "title": "Generation High resolution 3D model from natural language by Generative\n  Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method of generating high resolution 3D shapes from natural\nlanguage descriptions. To achieve this goal, we propose two steps that\ngenerating low resolution shapes which roughly reflect texts and generating\nhigh resolution shapes which reflect the detail of texts. In a previous paper,\nthe authors have shown a method of generating low resolution shapes. We improve\nit to generate 3D shapes more faithful to natural language and test the\neffectiveness of the method. To generate high resolution 3D shapes, we use the\nframework of Conditional Wasserstein GAN. We propose two roles of Critic\nseparately, which calculate the Wasserstein distance between two probability\ndistribution, so that we achieve generating high quality shapes or acceleration\nof learning speed of model. To evaluate our approach, we performed quantitive\nevaluation with several numerical metrics for Critic models. Our method is\nfirst to realize the generation of high quality model by propagating text\nembedding information to high resolution task when generating 3D model.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 03:50:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Fukamizu", "Kentaro", ""], ["Kondo", "Masaaki", ""], ["Sakamoto", "Ryuichi", ""]]}, {"id": "1901.07186", "submitter": "Glen Berseth", "authors": "Glen Berseth, Christopher J. Pal", "title": "Visual Imitation Learning with Recurrent Siamese Networks", "comments": "PrePrint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It would be desirable for a reinforcement learning (RL) based agent to learn\nbehaviour by merely watching a demonstration. However, defining rewards that\nfacilitate this goal within the RL paradigm remains a challenge. Here we\naddress this problem with Siamese networks, trained to compute distances\nbetween observed behaviours and the agent's behaviours. Given a desired motion\nsuch Siamese networks can be used to provide a reward signal to an RL agent via\nthe distance between the desired motion and the agent's motion. We experiment\nwith an RNN-based comparator model that can compute distances in space and time\nbetween motion clips while training an RL policy to minimize this distance.\nThrough experimentation, we have had also found that the inclusion of\nmulti-task data and an additional image encoding loss helps enforce the\ntemporal consistency. These two components appear to balance reward for\nmatching a specific instance of behaviour versus that behaviour in general.\nFurthermore, we focus here on a particularly challenging form of this problem\nwhere only a single demonstration is provided for a given task -- the one-shot\nlearning setting. We demonstrate our approach on humanoid agents in both 2D\nwith $10$ degrees of freedom (DoF) and 3D with $38$ DoF.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 06:46:19 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 19:30:00 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Berseth", "Glen", ""], ["Pal", "Christopher J.", ""]]}, {"id": "1901.07229", "submitter": "Georgios Arvanitidis", "authors": "Georgios Arvanitidis, S{\\o}ren Hauberg, Philipp Hennig, Michael\n  Schober", "title": "Fast and Robust Shortest Paths on Manifolds Learned from Data", "comments": "Accepted at Artificial Intelligence and Statistics (AISTATS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast, simple and robust algorithm for computing shortest paths\nand distances on Riemannian manifolds learned from data. This amounts to\nsolving a system of ordinary differential equations (ODEs) subject to boundary\nconditions. Here standard solvers perform poorly because they require\nwell-behaved Jacobians of the ODE, and usually, manifolds learned from data\nimply unstable and ill-conditioned Jacobians. Instead, we propose a fixed-point\niteration scheme for solving the ODE that avoids Jacobians. This enhances the\nstability of the solver, while reduces the computational cost. In experiments\ninvolving both Riemannian metric learning and deep generative models we\ndemonstrate significant improvements in speed and stability over both\ngeneral-purpose state-of-the-art solvers as well as over specialized solvers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 09:44:07 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Arvanitidis", "Georgios", ""], ["Hauberg", "S\u00f8ren", ""], ["Hennig", "Philipp", ""], ["Schober", "Michael", ""]]}, {"id": "1901.07277", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot (LMO, CELESTE)", "title": "Minimal penalties and the slope heuristics: a survey", "comments": null, "journal-ref": "Journal de la Societe Fran{\\c c}aise de Statistique, Societe\n  Fran{\\c c}aise de Statistique et Societe Mathematique de France, 2019,\n  Minimal penalties and the slope heuristics: a survey, 160 (3), pp.1-106", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Birg{\\'e} and Massart proposed in 2001 the slope heuristics as a way to\nchoose optimally from data an unknown multiplicative constant in front of a\npenalty. It is built upon the notion of minimal penalty, and it has been\ngeneralized since to some \"minimal-penalty algorithms\". This paper reviews the\ntheoretical results obtained for such algorithms, with a self-contained proof\nin the simplest framework, precise proof ideas for further generalizations, and\na few new results. Explicit connections are made with residual-variance\nestimators-with an original contribution on this topic, showing that for this\ntask the slope heuristics performs almost as well as a residual-based estimator\nwith the best model choice-and some classical algorithms such as L-curve or\nelbow heuristics, Mallows' C p , and Akaike's FPE. Practical issues are also\naddressed, including two new practical definitions of minimal-penalty\nalgorithms that are compared on synthetic data to previously-proposed\ndefinitions. Finally, several conjectures and open problems are suggested as\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 11:58:12 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 12:41:53 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Arlot", "Sylvain", "", "LMO, CELESTE"]]}, {"id": "1901.07295", "submitter": "Tian Xia", "authors": "Tian Xia, Agisilaos Chartsias, Sotirios A. Tsaftaris", "title": "Adversarial Pseudo Healthy Synthesis Needs Pathology Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo healthy synthesis, i.e. the creation of a subject-specific `healthy'\nimage from a pathological one, could be helpful in tasks such as anomaly\ndetection, understanding changes induced by pathology and disease or even as\ndata augmentation. We treat this task as a factor decomposition problem: we aim\nto separate what appears to be healthy and where disease is (as a map). The two\nfactors are then recombined (by a network) to reconstruct the input disease\nimage. We train our models in an adversarial way using either paired or\nunpaired settings, where we pair disease images and maps (as segmentation\nmasks) when available. We quantitatively evaluate the quality of pseudo healthy\nimages. We show in a series of experiments, performed in ISLES and BraTS\ndatasets, that our method is better than conditional GAN and CycleGAN,\nhighlighting challenges in using adversarial methods in the image translation\ntask of pseudo healthy image generation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 20:20:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Xia", "Tian", ""], ["Chartsias", "Agisilaos", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "1901.07298", "submitter": "Jimmy Gaudreault", "authors": "Jimmy Gaudreault, Arunabh Saxena and Hideaki Shimazaki", "title": "Online Estimation of Multiple Dynamic Graphs in Pattern Sequences", "comments": "8 pages, 4 figures v2: IJCNN 2019, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of correlated binary patterns can represent many time-series data\nincluding text, movies, and biological signals. These patterns may be described\nby weighted combinations of a few dominant structures that underpin specific\ninteractions among the binary elements. To extract the dominant correlation\nstructures and their contributions to generating data in a time-dependent\nmanner, we model the dynamics of binary patterns using the state-space model of\nan Ising-type network that is composed of multiple undirected graphs. We\nprovide a sequential Bayes algorithm to estimate the dynamics of weights on the\ngraphs while gaining the graph structures online. This model can uncover\noverlapping graphs underlying the data better than a traditional orthogonal\ndecomposition method, and outperforms an original time-dependent Ising model.\nWe assess the performance of the method by simulated data, and demonstrate that\nspontaneous activity of cultured hippocampal neurons is represented by dynamics\nof multiple graphs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 14:05:53 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 03:38:11 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Gaudreault", "Jimmy", ""], ["Saxena", "Arunabh", ""], ["Shimazaki", "Hideaki", ""]]}, {"id": "1901.07299", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Syed Rafay Hasan, Osman Hasan, Muhammad Shafique", "title": "SIMCom: Statistical Sniffing of Inter-Module Communications for Run-time\n  Hardware Trojan Detection", "comments": null, "journal-ref": "Elsevier Microprocessors and Microsystems, 2020, pp. 103-122", "doi": "10.1016/j.micpro.2020.103122", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely detection of Hardware Trojans (HTs) has become a major challenge for\nsecure integrated circuits. We present a run-time methodology for HT detection\nthat employs a multi-parameter statistical traffic modeling of the\ncommunication channel in a given System-on-Chip (SoC), named as SIMCom. The\nmain idea is to model the communication using multiple side-channel information\nlike the Hurst exponent, the standard deviation of the injection distribution,\nand the hop distribution jointly to accurately identify HT-based online\nanomalies (that affects the communication without affecting the protocols or\ncontrol signals). At design time, our methodology employs a \"property\nspecification language\" to define and embed assertions in the RTL, specifying\nthe correct communication behavior of a given SoC. At run-time, it monitors the\nanomalies in the communication behavior by checking the execution patterns\nagainst these assertions. For illustration, we evaluate SIMCom for three SoCs,\ni.e., SoC1 ( four single-core MC8051 and UART modules), SoC2 (four single-core\nMC8051, AES, ethernet, memctrl, BasicRSA, RS232 modules), and SoC3 (four\nsingle-core LEON3 connected with each other and AES, ethernet, memctrl,\nBasicRSA, RS23s modules microcontrollers). The experimental results show that\nwith the combined analysis of multiple statistical parameters, SIMCom is able\nto detect all the benchmark Trojans (available on trust-hub) with less than 1%\narea and power overhead.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 22:21:45 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 07:36:54 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 20:07:16 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Khalid", "Faiq", ""], ["Hasan", "Syed Rafay", ""], ["Hasan", "Osman", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1901.07300", "submitter": "Alessandro Casa", "authors": "Alessandro Casa, Jos\\'e E. Chac\\'on and Giovanna Menardi", "title": "Modal clustering asymptotics with applications to bandwidth selection", "comments": null, "journal-ref": "Electronic Journal of Statistics, 14(1) 835-856, 2020", "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density-based clustering relies on the idea of linking groups to some\nspecific features of the probability distribution underlying the data. The\nreference to a true, yet unknown, population structure allows to frame the\nclustering problem in a standard inferential setting, where the concept of\nideal population clustering is defined as the partition induced by the true\ndensity function. The nonparametric formulation of this approach, known as\nmodal clustering, draws a correspondence between the groups and the domains of\nattraction of the density modes. Operationally, a nonparametric density\nestimate is required and a proper selection of the amount of smoothing,\ngoverning the shape of the density and hence possibly the modal structure, is\ncrucial to identify the final partition. In this work, we address the issue of\ndensity estimation for modal clustering from an asymptotic perspective. A\nnatural and easy to interpret metric to measure the distance between\ndensity-based partitions is discussed, its asymptotic approximation explored,\nand employed to study the problem of bandwidth selection for nonparametric\nmodal clustering.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 14:06:58 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Casa", "Alessandro", ""], ["Chac\u00f3n", "Jos\u00e9 E.", ""], ["Menardi", "Giovanna", ""]]}, {"id": "1901.07312", "submitter": "Mark Stamp", "authors": "Swapna Vemparala, Fabio Di Troia, Corrado A. Visaggio, Thomas H.\n  Austin, and Mark Stamp", "title": "Malware Detection Using Dynamic Birthmarks", "comments": "Extended version of conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the effectiveness of dynamic analysis techniques\nfor identifying malware, using Hidden Markov Models (HMMs) and Profile Hidden\nMarkov Models (PHMMs), both trained on sequences of API calls. We contrast our\nresults to static analysis using HMMs trained on sequences of opcodes, and show\nthat dynamic analysis achieves significantly stronger results in many cases.\nFurthermore, in contrasting our two dynamic analysis techniques, we find that\nusing PHMMs consistently outperforms our analysis based on HMMs.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 13:50:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Vemparala", "Swapna", ""], ["Di Troia", "Fabio", ""], ["Visaggio", "Corrado A.", ""], ["Austin", "Thomas H.", ""], ["Stamp", "Mark", ""]]}, {"id": "1901.07329", "submitter": "Franziska Horn", "authors": "Franziska Horn, Robert Pack, Michael Rieger", "title": "The autofeat Python Library for Automated Feature Engineering and\n  Selection", "comments": "ECMLPKDD 2019 Workshop on Automating Data Science (ADS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the autofeat Python library, which provides scikit-learn\nstyle linear regression and classification models with automated feature\nengineering and selection capabilities. Complex non-linear machine learning\nmodels, such as neural networks, are in practice often difficult to train and\neven harder to explain to non-statisticians, who require transparent analysis\nresults as a basis for important business decisions. While linear models are\nefficient and intuitive, they generally provide lower prediction accuracies.\nOur library provides a multi-step feature engineering and selection process,\nwhere first a large pool of non-linear features is generated, from which then a\nsmall and robust set of meaningful features is selected, which improve the\nprediction accuracy of a linear model while retaining its interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 14:33:23 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 15:47:09 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 17:34:26 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2020 14:21:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Horn", "Franziska", ""], ["Pack", "Robert", ""], ["Rieger", "Michael", ""]]}, {"id": "1901.07333", "submitter": "Jun Hao", "authors": "Jun Hao", "title": "Multi-agent Reinforcement Learning Embedded Game for the Optimization of\n  Building Energy Control and Power System Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current game-theoretic demand-side management methods focus\nprimarily on the scheduling of home appliances, and the related numerical\nexperiments are analyzed under various scenarios to achieve the corresponding\nNash-equilibrium (NE) and optimal results. However, not much work is conducted\nfor academic or commercial buildings. The methods for optimizing\nacademic-buildings are distinct from the optimal methods for home appliances.\nIn my study, we address a novel methodology to control the operation of\nheating, ventilation, and air conditioning system (HVAC). With the development\nof Artificial Intelligence and computer technologies, reinforcement learning\n(RL) can be implemented in multiple realistic scenarios and help people to\nsolve thousands of real-world problems. Reinforcement Learning, which is\nconsidered as the art of future AI, builds the bridge between agents and\nenvironments through Markov Decision Chain or Neural Network and has seldom\nbeen used in power system. The art of RL is that once the simulator for a\nspecific environment is built, the algorithm can keep learning from the\nenvironment. Therefore, RL is capable of dealing with constantly changing\nsimulator inputs such as power demand, the condition of power system and\noutdoor temperature, etc. Compared with the existing distribution power system\nplanning mechanisms and the related game theoretical methodologies, our\nproposed algorithm can plan and optimize the hourly energy usage, and have the\nability to corporate with even shorter time window if needed.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 08:37:38 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hao", "Jun", ""]]}, {"id": "1901.07334", "submitter": "Matthew Thornton", "authors": "Matthew Thornton, Jithendar Anumula, Shih-Chii Liu", "title": "Reducing state updates via Gaussian-gated LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks can be difficult to train on long sequence data due\nto the well-known vanishing gradient problem. Some architectures incorporate\nmethods to reduce RNN state updates, therefore allowing the network to preserve\nmemory over long temporal intervals. To address these problems of convergence,\nthis paper proposes a timing-gated LSTM RNN model, called the Gaussian-gated\nLSTM (g-LSTM). The time gate controls when a neuron can be updated during\ntraining, enabling longer memory persistence and better error-gradient flow.\nThis model captures long-temporal dependencies better than an LSTM and the time\ngate parameters can be learned even from non-optimal initialization values.\nBecause the time gate limits the updates of the neuron state, the number of\ncomputes needed for the network update is also reduced. By adding a\ncomputational budget term to the training loss, we can obtain a network which\nfurther reduces the number of computes by at least 10x. Finally, by employing a\ntemporal curriculum learning schedule for the g-LSTM, we can reduce the\nconvergence time of the equivalent LSTM network on long sequences.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 14:36:11 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Thornton", "Matthew", ""], ["Anumula", "Jithendar", ""], ["Liu", "Shih-Chii", ""]]}, {"id": "1901.07355", "submitter": "Senthil Yogamani", "authors": "Hazem Rashed, Senthil Yogamani, Ahmad El-Sallab, Pavel Krizek and\n  Mohamed El-Helw", "title": "Optical Flow augmented Semantic Segmentation networks for Automated\n  Driving", "comments": "Accepted for Oral Presentation at VISAPP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion is a dominant cue in automated driving systems. Optical flow is\ntypically computed to detect moving objects and to estimate depth using\ntriangulation. In this paper, our motivation is to leverage the existing dense\noptical flow to improve the performance of semantic segmentation. To provide a\nsystematic study, we construct four different architectures which use RGB only,\nflow only, RGBF concatenated and two-stream RGB + flow. We evaluate these\nnetworks on two automotive datasets namely Virtual KITTI and Cityscapes using\nthe state-of-the-art flow estimator FlowNet v2. We also make use of the ground\ntruth optical flow in Virtual KITTI to serve as an ideal estimator and a\nstandard Farneback optical flow algorithm to study the effect of noise. Using\nthe flow ground truth in Virtual KITTI, two-stream architecture achieves the\nbest results with an improvement of 4% IoU. As expected, there is a large\nimprovement for moving objects like trucks, vans and cars with 38%, 28% and 6%\nincrease in IoU. FlowNet produces an improvement of 2.4% in average IoU with\nlarger improvement in the moving objects corresponding to 26%, 11% and 5% in\ntrucks, vans and cars. In Cityscapes, flow augmentation provided an improvement\nfor moving objects like motorcycle and train with an increase of 17% and 7% in\nIoU.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 19:10:46 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Rashed", "Hazem", ""], ["Yogamani", "Senthil", ""], ["El-Sallab", "Ahmad", ""], ["Krizek", "Pavel", ""], ["El-Helw", "Mohamed", ""]]}, {"id": "1901.07375", "submitter": "Jay Hoon Jung", "authors": "Jay Hoon Jung, Yousun Shin, YoungMin Kwon", "title": "Extension of Convolutional Neural Network with General Image Processing\n  Kernels", "comments": "4 pages, 6 figures", "journal-ref": "TENCON 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied pre-defined kernels also known as filters or masks developed for\nimage processing to convolution neural network. Instead of letting neural\nnetworks find its own kernels, we used 41 different general-purpose kernels of\nblurring, edge detecting, sharpening, discrete cosine transformation, etc. for\nthe first layer of the convolution neural networks. This architecture, thus\nnamed as general filter convolutional neural network (GFNN), can reduce\ntraining time by 30% with a better accuracy compared to the regular\nconvolutional neural network (CNN). GFNN also can be trained to achieve 90%\naccuracy with only 500 samples. Furthermore, even though these kernels are not\nspecialized for the MNIST dataset, we achieved 99.56% accuracy without ensemble\nnor any other special algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 07:44:58 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Jung", "Jay Hoon", ""], ["Shin", "Yousun", ""], ["Kwon", "YoungMin", ""]]}, {"id": "1901.07417", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen", "title": "On Connected Sublevel Sets in Deep Learning", "comments": "Accepted at ICML 2019. More discussions and visualizations are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that every sublevel set of the loss function of a class of\ndeep over-parameterized neural nets with piecewise linear activation functions\nis connected and unbounded. This implies that the loss has no bad local valleys\nand all of its global minima are connected within a unique and potentially very\nlarge global valley.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 15:34:54 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 14:50:44 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Nguyen", "Quynh", ""]]}, {"id": "1901.07445", "submitter": "Lingjiong Zhu", "authors": "Bugra Can, Mert Gurbuzbalaban, Lingjiong Zhu", "title": "Accelerated Linear Convergence of Stochastic Momentum Methods in\n  Wasserstein Distances", "comments": "72 pages", "journal-ref": "International Conference on Machine Learning 2019, 891-901", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum methods such as Polyak's heavy ball (HB) method, Nesterov's\naccelerated gradient (AG) as well as accelerated projected gradient (APG)\nmethod have been commonly used in machine learning practice, but their\nperformance is quite sensitive to noise in the gradients. We study these\nmethods under a first-order stochastic oracle model where noisy estimates of\nthe gradients are available. For strongly convex problems, we show that the\ndistribution of the iterates of AG converges with the accelerated\n$O(\\sqrt{\\kappa}\\log(1/\\varepsilon))$ linear rate to a ball of radius\n$\\varepsilon$ centered at a unique invariant distribution in the 1-Wasserstein\nmetric where $\\kappa$ is the condition number as long as the noise variance is\nsmaller than an explicit upper bound we can provide. Our analysis also\ncertifies linear convergence rates as a function of the stepsize, momentum\nparameter and the noise variance; recovering the accelerated rates in the\nnoiseless case and quantifying the level of noise that can be tolerated to\nachieve a given performance. In the special case of strongly convex quadratic\nobjectives, we can show accelerated linear rates in the $p$-Wasserstein metric\nfor any $p\\geq 1$ with improved sensitivity to noise for both AG and HB through\na non-asymptotic analysis under some additional assumptions on the noise\nstructure. Our analysis for HB and AG also leads to improved non-asymptotic\nconvergence bounds in suboptimality for both deterministic and stochastic\nsettings which is of independent interest. To the best of our knowledge, these\nare the first linear convergence results for stochastic momentum methods under\nthe stochastic oracle model. We also extend our results to the APG method and\nweakly convex functions showing accelerated rates when the noise magnitude is\nsufficiently small.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 16:16:42 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 01:46:55 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Can", "Bugra", ""], ["Gurbuzbalaban", "Mert", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1901.07469", "submitter": "Nilavra Pathak", "authors": "Nilavra Pathak, James Foulds, Nirmalya Roy, Nilanjan Banerjee, Ryan\n  Robucci", "title": "Estimating Buildings' Parameters over Time Including Prior Knowledge", "comments": "11 pages with reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling buildings' heat dynamics is a complex process which depends on\nvarious factors including weather, building thermal capacity, insulation\npreservation, and residents' behavior. Gray-box models offer a causal inference\nof those dynamics expressed in few parameters specific to built environments.\nThese parameters can provide compelling insights into the characteristics of\nbuilding artifacts and have various applications such as forecasting HVAC\nusage, indoor temperature control monitoring of built environments, etc. In\nthis paper, we present a systematic study of modeling buildings' thermal\ncharacteristics and thus derive the parameters of built conditions with a\nBayesian approach. We build a Bayesian state-space model that can adapt and\nincorporate buildings' thermal equations and propose a generalized solution\nthat can easily adapt prior knowledge regarding the parameters. We show that a\nfaster approximate approach using variational inference for parameter\nestimation can provide similar parameters as that of a more time-consuming\nMarkov Chain Monte Carlo (MCMC) approach. We perform extensive evaluations on\ntwo datasets to understand the generative process and show that the Bayesian\napproach is more interpretable. We further study the effects of prior selection\nfor the model parameters and transfer learning, where we learn parameters from\none season and use them to fit the model in the other. We perform extensive\nevaluations on controlled and real data traces to enumerate buildings'\nparameter within a 95% credible interval.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 03:37:32 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 22:47:47 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 23:53:36 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Pathak", "Nilavra", ""], ["Foulds", "James", ""], ["Roy", "Nirmalya", ""], ["Banerjee", "Nilanjan", ""], ["Robucci", "Ryan", ""]]}, {"id": "1901.07484", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Jose C. Principe", "title": "An Exact Reformulation of Feature-Vector-based Radial-Basis-Function\n  Networks for Graph-based Observations", "comments": "Submitted to the IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radial-basis-function networks are traditionally defined for sets of\nvector-based observations. In this short paper, we reformulate such networks so\nthat they can be applied to adjacency-matrix representations of weighted,\ndirected graphs that represent the relationships between object pairs. We\nre-state the sum-of-squares objective function so that it is purely dependent\non entries from the adjacency matrix. From this objective function, we derive a\ngradient descent update for the network weights. We also derive a gradient\nupdate that simulates the repositioning of the radial basis prototypes and\nchanges in the radial basis prototype parameters. An important property of our\nradial basis function networks is that they are guaranteed to yield the same\nresponses as conventional radial-basis networks trained on a corresponding\nvector realization of the relationships encoded by the adjacency-matrix. Such a\nvector realization only needs to provably exist for this property to hold,\nwhich occurs whenever the relationships correspond to distances from some\narbitrary metric applied to a latent set of vectors. We therefore completely\navoid needing to actually construct vectorial realizations via\nmulti-dimensional scaling, which ensures that the underlying relationships are\ntotally preserved.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 17:48:35 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 03:09:26 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1901.07487", "submitter": "Thanh Huy Nguyen", "authors": "Thanh Huy Nguyen, Umut \\c{S}im\\c{s}ekli, Ga\\\"el Richard", "title": "Non-Asymptotic Analysis of Fractional Langevin Monte Carlo for\n  Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on diffusion-based sampling methods have shown that Langevin\nMonte Carlo (LMC) algorithms can be beneficial for non-convex optimization, and\nrigorous theoretical guarantees have been proven for both asymptotic and\nfinite-time regimes. Algorithmically, LMC-based algorithms resemble the\nwell-known gradient descent (GD) algorithm, where the GD recursion is perturbed\nby an additive Gaussian noise whose variance has a particular form. Fractional\nLangevin Monte Carlo (FLMC) is a recently proposed extension of LMC, where the\nGaussian noise is replaced by a heavy-tailed {\\alpha}-stable noise. As opposed\nto its Gaussian counterpart, these heavy-tailed perturbations can incur large\njumps and it has been empirically demonstrated that the choice of\n{\\alpha}-stable noise can provide several advantages in modern machine learning\nproblems, both in optimization and sampling contexts. However, as opposed to\nLMC, only asymptotic convergence properties of FLMC have been yet established.\nIn this study, we analyze the non-asymptotic behavior of FLMC for non-convex\noptimization and prove finite-time bounds for its expected suboptimality. Our\nresults show that the weak-error of FLMC increases faster than LMC, which\nsuggests using smaller step-sizes in FLMC. We finally extend our results to the\ncase where the exact gradients are replaced by stochastic gradients and show\nthat similar results hold in this setting as well.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 17:53:01 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Nguyen", "Thanh Huy", ""], ["\u015eim\u015fekli", "Umut", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "1901.07506", "submitter": "Eli Chien", "authors": "I (Eli) Chien and Olgica Milenkovic", "title": "Regularized Weighted Chebyshev Approximations for Support Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for estimating the support size of an unknown\ndistribution which provably matches the performance bounds of the\nstate-of-the-art techniques in the area and outperforms them in practice. In\nparticular, we present both theoretical and computer simulation results that\nillustrate the utility and performance improvements of our method. The\ntheoretical analysis relies on introducing a new weighted Chebyshev polynomial\napproximation method, jointly optimizing the bias and variance components of\nthe risk, and combining the weighted minmax polynomial approximation method\nwith discretized semi-infinite programming solvers. Such a setting allows for\ncasting the estimation problem as a linear program (LP) with a small number of\nvariables and constraints that may be solved as efficiently as the original\nChebyshev approximation problem. Our technique is tested on synthetic data and\nused to address an important problem in computational biology - estimating the\nnumber of bacterial genera in the human gut. On synthetic datasets, for\npractically relevant sample sizes, we observe significant improvements in the\nvalue of the worst-case risk compared to existing methods. For the\nbioinformatics application, using metagenomic data from the NIH Human Gut and\nthe American Gut Microbiome Projects, we generate a list of frequencies of\nbacterial taxa that allows us to estimate the number of bacterial genera to\napproximately 2300.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:29:02 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 02:02:22 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 15:59:25 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 17:08:28 GMT"}, {"version": "v5", "created": "Fri, 18 Oct 2019 18:05:07 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["I", "", "", "Eli"], ["Chien", "", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1901.07510", "submitter": "J. Fernando Hernandez-Garcia", "authors": "J. Fernando Hernandez-Garcia, Richard S. Sutton", "title": "Understanding Multi-Step Deep Reinforcement Learning: A Systematic Study\n  of the DQN Target", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step methods such as Retrace($\\lambda$) and $n$-step $Q$-learning have\nbecome a crucial component of modern deep reinforcement learning agents. These\nmethods are often evaluated as a part of bigger architectures and their\nevaluations rarely include enough samples to draw statistically significant\nconclusions about their performance. This type of methodology makes it\ndifficult to understand how particular algorithmic details of multi-step\nmethods influence learning. In this paper we combine the $n$-step action-value\nalgorithms Retrace, $Q$-learning, Tree Backup, Sarsa, and $Q(\\sigma)$ with an\narchitecture analogous to DQN. We test the performance of all these algorithms\nin the mountain car environment; this choice of environment allows for faster\ntraining times and larger sample sizes. We present statistical analyses on the\neffects of the off-policy correction, the backup length parameter $n$, and the\nupdate frequency of the target network on the performance of these algorithms.\nOur results show that (1) using off-policy correction can have an adverse\neffect on the performance of Sarsa and $Q(\\sigma)$; (2) increasing the backup\nlength $n$ consistently improved performance across all the different\nalgorithms; and (3) the performance of Sarsa and $Q$-learning was more robust\nto the effect of the target network update frequency than the performance of\nTree Backup, $Q(\\sigma)$, and Retrace in this particular task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:38:04 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 22:11:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Hernandez-Garcia", "J. Fernando", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1901.07535", "submitter": "Chaitanya Chinni", "authors": "Chaitanya Chinni, Abhishek Kulkarni, Dheeraj M. Pai, Kaushik Mitra and\n  Pradeep Kiran Sarvepalli", "title": "Neural Decoder for Topological Codes using Pseudo-Inverse of Parity\n  Check Matrix", "comments": "12 pages, 12 figures, 2 tables, submitted to the 2019 IEEE\n  International Symposium on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the field of deep learning have motivated many\nresearchers to apply these methods to problems in quantum information. Torlai\nand Melko first proposed a decoder for surface codes based on neural networks.\nSince then, many other researchers have applied neural networks to study a\nvariety of problems in the context of decoding. An important development in\nthis regard was due to Varsamopoulos et al. who proposed a two-step decoder\nusing neural networks. Subsequent work of Maskara et al. used the same concept\nfor decoding for various noise models. We propose a similar two-step neural\ndecoder using inverse parity-check matrix for topological color codes. We show\nthat it outperforms the state-of-the-art performance of non-neural decoders for\nindependent Pauli errors noise model on a 2D hexagonal color code. Our final\ndecoder is independent of the noise model and achieves a threshold of $10 \\%$.\nOur result is comparable to the recent work on neural decoder for quantum error\ncorrection by Maskara et al.. It appears that our decoder has significant\nadvantages with respect to training cost and complexity of the network for\nhigher lengths when compared to that of Maskara et al.. Our proposed method can\nalso be extended to arbitrary dimension and other stabilizer codes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 11:42:04 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 18:19:04 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Chinni", "Chaitanya", ""], ["Kulkarni", "Abhishek", ""], ["Pai", "Dheeraj M.", ""], ["Mitra", "Kaushik", ""], ["Sarvepalli", "Pradeep Kiran", ""]]}, {"id": "1901.07538", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Yu Yang, Ying Nian Wu", "title": "Unsupervised Learning of Neural Networks to Explain Neural Networks\n  (extended abstract)", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  arXiv admin note: substantial text overlap with arXiv:1805.07468", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised method to learn a neural network, namely\nan explainer, to interpret a pre-trained convolutional neural network (CNN),\ni.e., the explainer uses interpretable visual concepts to explain features in\nmiddle conv-layers of a CNN. Given feature maps of a conv-layer of the CNN, the\nexplainer performs like an auto-encoder, which decomposes the feature maps into\nobject-part features. The object-part features are learned to reconstruct CNN\nfeatures without much loss of information. We can consider the disentangled\nrepresentations of object parts a paraphrase of CNN features, which help people\nunderstand the knowledge encoded by the CNN. More crucially, we learn the\nexplainer via knowledge distillation without using any annotations of object\nparts or textures for supervision. In experiments, our method was widely used\nto interpret features of different benchmark CNNs, and explainers significantly\nboosted the feature interpretability without hurting the discrimination power\nof the CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 16:03:31 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Zhang", "Quanshi", ""], ["Yang", "Yu", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1901.07592", "submitter": "Christian H\\\"ager", "authors": "Mengke Lian, Christian H\\\"ager, Henry D. Pfister", "title": "What Can Machine Learning Teach Us about Communications?", "comments": "5 pages, 4 figures, paper presented at ITW 2018, corrected version\n  and updated reference list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid improvements in machine learning over the past decade are beginning to\nhave far-reaching effects. For communications, engineers with limited domain\nexpertise can now use off-the-shelf learning packages to design\nhigh-performance systems based on simulations. Prior to the current revolution\nin machine learning, the majority of communication engineers were quite aware\nthat system parameters (such as filter coefficients) could be learned using\nstochastic gradient descent. It was not at all clear, however, that more\ncomplicated parts of the system architecture could be learned as well. In this\npaper, we discuss the application of machine-learning techniques to two\ncommunications problems and focus on what can be learned from the resulting\nsystems. We were pleasantly surprised that the observed gains in one example\nhave a simple explanation that only became clear in hindsight. In essence, deep\nlearning discovered a simple and effective strategy that had not been\nconsidered earlier.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 19:41:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 01:29:07 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Lian", "Mengke", ""], ["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1901.07593", "submitter": "Min Ho Cho", "authors": "Min Ho Cho, Sebastian Kurtek, and Steven N. MacEachern", "title": "Aggregated Pairwise Classification of Statistical Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of shapes is of great interest in diverse areas ranging\nfrom medical imaging to computer vision and beyond. While many statistical\nframeworks have been developed for the classification problem, most are\nstrongly tied to early formulations of the problem - with an object to be\nclassified described as a vector in a relatively low-dimensional Euclidean\nspace. Statistical shape data have two main properties that suggest a need for\na novel approach: (i) shapes are inherently infinite dimensional with strong\ndependence among the positions of nearby points, and (ii) shape space is not\nEuclidean, but is fundamentally curved. To accommodate these features of the\ndata, we work with the square-root velocity function of the curves to provide a\nuseful formal description of the shape, pass to tangent spaces of the manifold\nof shapes at different projection points which effectively separate shapes for\npairwise classification in the training data, and use principal components\nwithin these tangent spaces to reduce dimensionality. We illustrate the impact\nof the projection point and choice of subspace on the misclassification rate\nwith a novel method of combining pairwise classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 19:43:37 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Cho", "Min Ho", ""], ["Kurtek", "Sebastian", ""], ["MacEachern", "Steven N.", ""]]}, {"id": "1901.07598", "submitter": "Anna Breger", "authors": "Anna Breger, Jose Ignacio Orlando, Pavol Harar, Monika D\\\"orfler,\n  Sophie Klimscha, Christoph Grechenig, Bianca S. Gerendas, Ursula\n  Schmidt-Erfurth, Martin Ehler", "title": "On orthogonal projections for dimension reduction and applications in\n  augmented target loss functions for learning problems", "comments": null, "journal-ref": "Journal of Mathematical Imaging and Vision, 2019", "doi": "10.1007/s10851-019-00902-2", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of orthogonal projections on high-dimensional input and target data\nin learning frameworks is studied. First, we investigate the relations between\ntwo standard objectives in dimension reduction, preservation of variance and of\npairwise relative distances. Investigations of their asymptotic correlation as\nwell as numerical experiments show that a projection does usually not satisfy\nboth objectives at once. In a standard classification problem we determine\nprojections on the input data that balance the objectives and compare\nsubsequent results. Next, we extend our application of orthogonal projections\nto deep learning tasks and introduce a general framework of augmented target\nloss functions. These loss functions integrate additional information via\ntransformations and projections of the target data. In two supervised learning\nproblems, clinical image segmentation and music information classification, the\napplication of our proposed augmented target loss functions increase the\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 20:03:38 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 14:59:05 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 16:16:33 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 19:57:22 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Breger", "Anna", ""], ["Orlando", "Jose Ignacio", ""], ["Harar", "Pavol", ""], ["D\u00f6rfler", "Monika", ""], ["Klimscha", "Sophie", ""], ["Grechenig", "Christoph", ""], ["Gerendas", "Bianca S.", ""], ["Schmidt-Erfurth", "Ursula", ""], ["Ehler", "Martin", ""]]}, {"id": "1901.07632", "submitter": "L\\'eo Neufcourt", "authors": "L\\'eo Neufcourt, Yuchen Cao, Witold Nazarewicz, Erik Olsen, Frederi\n  Viens", "title": "Neutron drip line in the Ca region from Bayesian model averaging", "comments": "Supplementary Material available upon request", "journal-ref": "Phys. Rev. Lett. 122, 062502 (2019)", "doi": "10.1103/PhysRevLett.122.062502", "report-no": null, "categories": "nucl-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The region of heavy calcium isotopes forms the frontier of experimental and\ntheoretical nuclear structure research where the basic concepts of nuclear\nphysics are put to stringent test. The recent discovery of the extremely\nneutron-rich nuclei around $^{60}$Ca [Tarasov, 2018] and the experimental\ndetermination of masses for $^{55-57}$Ca (Michimasa, 2018] provide unique\ninformation about the binding energy surface in this region. To assess the\nimpact of these experimental discoveries on the nuclear landscape's extent, we\nuse global mass models and statistical machine learning to make predictions,\nwith quantified levels of certainty, for bound nuclides between Si and Ti.\nUsing a Bayesian model averaging analysis based on Gaussian-process-based\nextrapolations we introduce the posterior probability $p_{ex}$ for each nucleus\nto be bound to neutron emission. We find that extrapolations for drip-line\nlocations, at which the nuclear binding ends, are consistent across the global\nmass models used, in spite of significant variations between their raw\npredictions. In particular, considering the current experimental information\nand current global mass models, we predict that $^{68}$Ca has an average\nposterior probability ${p_{ex}\\approx76}$% to be bound to two-neutron emission\nwhile the nucleus $^{61}$Ca is likely to decay by emitting a neutron\n(${p_{ex}\\approx 46}$ %).\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 22:36:48 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 16:36:53 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Neufcourt", "L\u00e9o", ""], ["Cao", "Yuchen", ""], ["Nazarewicz", "Witold", ""], ["Olsen", "Erik", ""], ["Viens", "Frederi", ""]]}, {"id": "1901.07634", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Phuong Ha Nguyen, Dzung T. Phan, Jayant R. Kalagnanam,\n  Marten van Dijk", "title": "DTN: A Learning Rate Scheme with Convergence Rate of $\\mathcal{O}(1/t)$\n  for SGD", "comments": "This paper has inconsistent results, i.e., we made some failed claims\n  because we did some mistakes for using the test criterion for a series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has some inconsistent results, i.e., we made some failed claims\nbecause we did some mistakes for using the test criterion for a series.\nPrecisely, our claims on the convergence rate of $\\mathcal{O}(1/t)$ of SGD\npresented in Theorem 1, Corollary 1, Theorem 2 and Corollary 2 are wrongly\nderived because they are based on Lemma 5. In Lemma 5, we do not correctly use\nthe test criterion for a series. Hence, the result of Lemma 5 is not valid. We\nwould like to thank the community for pointing out this mistake!\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 22:40:31 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 21:55:19 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 02:01:20 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Nguyen", "Lam M.", ""], ["Nguyen", "Phuong Ha", ""], ["Phan", "Dzung T.", ""], ["Kalagnanam", "Jayant R.", ""], ["van Dijk", "Marten", ""]]}, {"id": "1901.07647", "submitter": "Jong Chul Ye", "authors": "Jong Chul Ye and Woon Kyoung Sung", "title": "Understanding Geometry of Encoder-Decoder CNNs", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder networks using convolutional neural network (CNN)\narchitecture have been extensively used in deep learning literatures thanks to\nits excellent performance for various inverse problems. However, it is still\ndifficult to obtain coherent geometric view why such an architecture gives the\ndesired performance. Inspired by recent theoretical understanding on\ngeneralizability, expressivity and optimization landscape of neural networks,\nas well as the theory of convolutional framelets, here we provide a unified\ntheoretical framework that leads to a better understanding of geometry of\nencoder-decoder CNNs. Our unified mathematical framework shows that\nencoder-decoder CNN architecture is closely related to nonlinear basis\nrepresentation using combinatorial convolution frames, whose expressibility\nincreases exponentially with the network depth. We also demonstrate the\nimportance of skipped connection in terms of expressibility, and optimization\nlandscape.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 23:37:43 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 13:56:00 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Ye", "Jong Chul", ""], ["Sung", "Woon Kyoung", ""]]}, {"id": "1901.07648", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Marten van Dijk, Dzung T. Phan, Phuong Ha Nguyen,\n  Tsui-Wei Weng, Jayant R. Kalagnanam", "title": "Finite-Sum Smooth Optimization with SARAH", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The total complexity (measured as the total number of gradient computations)\nof a stochastic first-order optimization algorithm that finds a first-order\nstationary point of a finite-sum smooth nonconvex objective function\n$F(w)=\\frac{1}{n} \\sum_{i=1}^n f_i(w)$ has been proven to be at least\n$\\Omega(\\sqrt{n}/\\epsilon)$ for $n \\leq \\mathcal{O}(\\epsilon^{-2})$ where\n$\\epsilon$ denotes the attained accuracy $\\mathbb{E}[ \\|\\nabla\nF(\\tilde{w})\\|^2] \\leq \\epsilon$ for the outputted approximation $\\tilde{w}$\n(Fang et al., 2018). In this paper, we provide a convergence analysis for a\nslightly modified version of the SARAH algorithm (Nguyen et al., 2017a;b) and\nachieve total complexity that matches the lower-bound worst case complexity in\n(Fang et al., 2018) up to a constant factor when $n \\leq\n\\mathcal{O}(\\epsilon^{-2})$ for nonconvex problems. For convex optimization, we\npropose SARAH++ with sublinear convergence for general convex and linear\nconvergence for strongly convex problems; and we provide a practical version\nfor which numerical experiments on various datasets show an improved\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 23:45:59 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 03:29:01 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Nguyen", "Lam M.", ""], ["van Dijk", "Marten", ""], ["Phan", "Dzung T.", ""], ["Nguyen", "Phuong Ha", ""], ["Weng", "Tsui-Wei", ""], ["Kalagnanam", "Jayant R.", ""]]}, {"id": "1901.07662", "submitter": "Alix Lh\\'eritier", "authors": "Alix Lh\\'eritier and Fr\\'ed\\'eric Cazals", "title": "Low-Complexity Nonparametric Bayesian Online Prediction with Universal\n  Guarantees", "comments": "Camera-ready version published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel nonparametric online predictor for discrete labels\nconditioned on multivariate continuous features. The predictor is based on a\nfeature space discretization induced by a full-fledged k-d tree with randomly\npicked directions and a recursive Bayesian distribution, which allows to\nautomatically learn the most relevant feature scales characterizing the\nconditional distribution. We prove its pointwise universality, i.e., it\nachieves a normalized log loss performance asymptotically as good as the true\nconditional entropy of the labels given the features. The time complexity to\nprocess the $n$-th sample point is $O(\\log n)$ in probability with respect to\nthe distribution generating the data points, whereas other exact nonparametric\nmethods require to process all past observations. Experiments on challenging\ndatasets show the computational and statistical efficiency of our algorithm in\ncomparison to standard and state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 00:44:30 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 16:16:22 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 14:51:10 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 15:37:37 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lh\u00e9ritier", "Alix", ""], ["Cazals", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1901.07666", "submitter": "Chi-Sing Ho", "authors": "Chi-Sing Ho, Neal Jean, Catherine A. Hogan, Lena Blackmon, Stefanie S.\n  Jeffrey, Mark Holodniy, Niaz Banaei, Amr A. E. Saleh, Stefano Ermon, and\n  Jennifer Dionne", "title": "Rapid identification of pathogenic bacteria using Raman spectroscopy and\n  deep learning", "comments": null, "journal-ref": "Nature Communications 10, 4927 (2019)", "doi": "10.1038/s41467-019-12898-9", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid identification of bacteria is essential to prevent the spread of\ninfectious disease, help combat antimicrobial resistance, and improve patient\noutcomes. Raman optical spectroscopy promises to combine bacterial detection,\nidentification, and antibiotic susceptibility testing in a single step.\nHowever, achieving clinically relevant speeds and accuracies remains\nchallenging due to the weak Raman signal from bacterial cells and the large\nnumber of bacterial species and phenotypes. By amassing the largest known\ndataset of bacterial Raman spectra, we are able to apply state-of-the-art deep\nlearning approaches to identify 30 of the most common bacterial pathogens from\nnoisy Raman spectra, achieving antibiotic treatment identification accuracies\nof 99.0$\\pm$0.1%. This novel approach distinguishes between\nmethicillin-resistant and -susceptible isolates of Staphylococcus aureus (MRSA\nand MSSA) as well as a pair of isogenic MRSA and MSSA that are genetically\nidentical apart from deletion of the mecA resistance gene, indicating the\npotential for culture-free detection of antibiotic resistance. Results from\ninitial clinical validation are promising: using just 10 bacterial spectra from\neach of 25 isolates, we achieve 99.0$\\pm$1.9% species identification accuracy.\nOur combined Raman-deep learning system represents an important\nproof-of-concept for rapid, culture-free identification of bacterial isolates\nand antibiotic resistance and could be readily extended for diagnostics on\nblood, urine, and sputum.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 00:47:42 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 22:31:57 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ho", "Chi-Sing", ""], ["Jean", "Neal", ""], ["Hogan", "Catherine A.", ""], ["Blackmon", "Lena", ""], ["Jeffrey", "Stefanie S.", ""], ["Holodniy", "Mark", ""], ["Banaei", "Niaz", ""], ["Saleh", "Amr A. E.", ""], ["Ermon", "Stefano", ""], ["Dionne", "Jennifer", ""]]}, {"id": "1901.07667", "submitter": "Yeu-Chern Harn", "authors": "Yeu-Chern Harn, Zhenghao Chen, and Vladimir Jojic", "title": "Composition and decomposition of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a composition/decomposition framework for\nadversarially training generative models on composed data - data where each\nsample can be thought of as being constructed from a fixed number of\ncomponents. In our framework, samples are generated by sampling components from\ncomponent generators and feeding these components to a composition function\nwhich combines them into a \"composed sample\". This compositional training\napproach improves the modularity, extensibility and interpretability of\nGenerative Adversarial Networks (GANs) - providing a principled way to\nincrementally construct complex models out of simpler component models, and\nallowing for explicit \"division of responsibility\" between these components.\nUsing this framework, we define a family of learning tasks and evaluate their\nfeasibility on two datasets in two different data modalities (image and text).\nLastly, we derive sufficient conditions such that these compositional\ngenerative models are identifiable. Our work provides a principled approach to\nbuilding on pre-trained generative models or for exploiting the compositional\nnature of data distributions to train extensible and interpretable models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 00:48:45 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Harn", "Yeu-Chern", ""], ["Chen", "Zhenghao", ""], ["Jojic", "Vladimir", ""]]}, {"id": "1901.07675", "submitter": "Herman Shen", "authors": "M.-H. Herman Shen and Liang Chen", "title": "A New CGAN Technique for Constrained Topology Design Optimization", "comments": "14 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1808.02334", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new conditional GAN (named convex relaxing CGAN or\ncrCGAN) to replicate the conventional constrained topology optimization\nalgorithms in an extremely effective and efficient process. The proposed crCGAN\nconsists of a generator and a discriminator, both of which are deep\nconvolutional neural networks (CNN) and the topology design constraint can be\nconditionally set to both the generator and discriminator. In order to improve\nthe training efficiency and accuracy due to the dependency between the training\nimages and the condition, a variety of crCGAN formulation are introduced to\nrelax the non-convex design space. These new formulations were evaluated and\nvalidated via a series of comprehensive experiments. Moreover, a minibatch\ndiscrimination technique was introduced in the crCGAN training process to\nstabilize the convergence and avoid the mode collapse problems. Additional\nverifications were conducted using the state-of-the-art MNIST digits and\nCIFAR-10 images conditioned by class labels. The experimental evaluations\nclearly reveal that the new objective formulation with the minibatch\ndiscrimination training provides not only the accuracy but also the consistency\nof the designs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:12:53 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 17:04:33 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Shen", "M. -H. Herman", ""], ["Chen", "Liang", ""]]}, {"id": "1901.07687", "submitter": "Jianjun Yuan", "authors": "Jianjun Yuan, Andrew Lamperski", "title": "Online Adaptive Principal Component Analysis and Its extensions", "comments": "This paper is accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose algorithms for online principal component analysis (PCA) and\nvariance minimization for adaptive settings. Previous literature has focused on\nupper bounding the static adversarial regret, whose comparator is the optimal\nfixed action in hindsight. However, static regret is not an appropriate metric\nwhen the underlying environment is changing. Instead, we adopt the adaptive\nregret metric from the previous literature and propose online adaptive\nalgorithms for PCA and variance minimization, that have sub-linear adaptive\nregret guarantees. We demonstrate both theoretically and experimentally that\nthe proposed algorithms can adapt to the changing environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 02:06:51 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 21:50:17 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 14:22:05 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Yuan", "Jianjun", ""], ["Lamperski", "Andrew", ""]]}, {"id": "1901.07710", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Takafumi Kanamori, Takashi Takenouchi, Takeru\n  Matsuda", "title": "Unified estimation framework for unnormalized models with statistical\n  efficiency", "comments": "To appear at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parameter estimation of unnormalized models is a challenging problem. The\nmaximum likelihood estimation (MLE) is computationally infeasible for these\nmodels since normalizing constants are not explicitly calculated. Although some\nconsistent estimators have been proposed earlier, the problem of statistical\nefficiency remains. In this study, we propose a unified, statistically\nefficient estimation framework for unnormalized models and several efficient\nestimators, whose asymptotic variance is the same as the MLE. The computational\ncost of these estimators is also reasonable and they can be employed whether\nthe sample space is discrete or continuous. The loss functions of the proposed\nestimators are derived by combining the following two methods: (1)\ndensity-ratio matching using Bregman divergence, and (2) plugging-in\nnonparametric estimators. We also analyze the properties of the proposed\nestimators when the unnormalized models are misspecified. The experimental\nresults demonstrate the advantages of our method over existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 03:40:05 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 17:30:36 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 00:19:01 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Kanamori", "Takafumi", ""], ["Takenouchi", "Takashi", ""], ["Matsuda", "Takeru", ""]]}, {"id": "1901.07714", "submitter": "Li Li", "authors": "Li Li, Minjie Fan, Rishabh Singh, Patrick Riley", "title": "Neural-Guided Symbolic Regression with Asymptotic Constraints", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Knowledge Representation & Reasoning\n  Meets Machine Learning", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic regression is a type of discrete optimization problem that involves\nsearching expressions that fit given data points. In many cases, other\nmathematical constraints about the unknown expression not only provide more\ninformation beyond just values at some inputs, but also effectively constrain\nthe search space. We identify the asymptotic constraints of leading polynomial\npowers as the function approaches zero and infinity as useful constraints and\ncreate a system to use them for symbolic regression. The first part of the\nsystem is a conditional production rule generating neural network which\npreferentially generates production rules to construct expressions with the\ndesired leading powers, producing novel expressions outside the training\ndomain. The second part, which we call Neural-Guided Monte Carlo Tree Search,\nuses the network during a search to find an expression that conforms to a set\nof data points and desired leading powers. Lastly, we provide an extensive\nexperimental validation on thousands of target expressions showing the efficacy\nof our system compared to exiting methods for finding unknown functions outside\nof the training set.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 04:15:10 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 02:51:25 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Li", "Li", ""], ["Fan", "Minjie", ""], ["Singh", "Rishabh", ""], ["Riley", "Patrick", ""]]}, {"id": "1901.07734", "submitter": "Yunjuan Wang", "authors": "Yunjuan Wang and Theja Tulabandhula", "title": "Thompson Sampling for a Fatigue-aware Online Recommendation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider an online recommendation setting, where a platform\nrecommends a sequence of items to its users at every time period. The users\nrespond by selecting one of the items recommended or abandon the platform due\nto fatigue from seeing less useful items. Assuming a parametric stochastic\nmodel of user behavior, which captures positional effects of these items as\nwell as the abandoning behavior of users, the platform's goal is to recommend\nsequences of items that are competitive to the single best sequence of items in\nhindsight, without knowing the true user model a priori. Naively applying a\nstochastic bandit algorithm in this setting leads to an exponential dependence\non the number of items. We propose a new Thompson sampling based algorithm with\nexpected regret that is polynomial in the number of items in this combinatorial\nsetting, and performs extremely well in practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 05:52:10 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 16:26:08 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Wang", "Yunjuan", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1901.07750", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty and Catherine A. Haddad-Zaknoon", "title": "Adaptive Exact Learning of Decision Trees from Membership Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the adaptive learnability of decision trees of depth\nat most $d$ from membership queries. This has many applications in automated\nscientific discovery such as drugs development and software update problem.\nFeldman solves the problem in a randomized polynomial time algorithm that asks\n$\\tilde O(2^{2d})\\log n$ queries and Kushilevitz-Mansour in a deterministic\npolynomial time algorithm that asks $ 2^{18d+o(d)}\\log n$ queries. We improve\nthe query complexity of both algorithms. We give a randomized polynomial time\nalgorithm that asks $\\tilde O(2^{2d}) + 2^{d}\\log n$ queries and a\ndeterministic polynomial time algorithm that asks $2^{5.83d}+2^{2d+o(d)}\\log n$\nqueries.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 07:00:55 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Bshouty", "Nader H.", ""], ["Haddad-Zaknoon", "Catherine A.", ""]]}, {"id": "1901.07752", "submitter": "Nairouz Mrabah", "authors": "Nairouz Mrabah, Naimul Mefraz Khan, Riadh Ksantini, Zied Lachiri", "title": "Deep Clustering with a Dynamic Autoencoder: From Reconstruction towards\n  Centroids Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised learning, there is no apparent straightforward cost function\nthat can capture the significant factors of variations and similarities. Since\nnatural systems have smooth dynamics, an opportunity is lost if an unsupervised\nobjective function remains static during the training process. The absence of\nconcrete supervision suggests that smooth dynamics should be integrated.\nCompared to classical static cost functions, dynamic objective functions allow\nto better make use of the gradual and uncertain knowledge acquired through\npseudo-supervision. In this paper, we propose Dynamic Autoencoder (DynAE), a\nnovel model for deep clustering that overcomes a clustering-reconstruction\ntrade-off, by gradually and smoothly eliminating the reconstruction objective\nfunction in favor of a construction one. Experimental evaluations on benchmark\ndatasets show that our approach achieves state-of-the-art results compared to\nthe most relevant deep clustering methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 07:34:30 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 19:37:41 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:49:38 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 09:28:08 GMT"}, {"version": "v5", "created": "Thu, 2 Jan 2020 23:11:33 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mrabah", "Nairouz", ""], ["Khan", "Naimul Mefraz", ""], ["Ksantini", "Riadh", ""], ["Lachiri", "Zied", ""]]}, {"id": "1901.07761", "submitter": "Yiquan Zhang", "authors": "Yiquan Zhang, Bo Peng, Xiaoyi Zhou, Cheng Xiang and Dalei Wang", "title": "A deep Convolutional Neural Network for topology optimization with\n  strong generalization ability", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a deep Convolutional Neural Network(CNN) with strong\ngeneralization ability for structural topology optimization. The architecture\nof the neural network is made up of encoding and decoding parts, which provide\ndown- and up-sampling operations. In addition, a popular technique, namely\nU-Net, was adopted to improve the performance of the proposed neural network.\nThe input of the neural network is a well-designed tensor with each channel\nincludes different information for the problem, and the output is the layout of\nthe optimal structure. To train the neural network, a large dataset is\ngenerated by a conventional topology optimization approach, i.e. SIMP. The\nperformance of the proposed method was evaluated by comparing its efficiency\nand accuracy with SIMP on a series of typical optimization problems. Results\nshow that a significant reduction in computation cost was achieved with little\nsacrifice on the optimality of design solutions. Furthermore, the proposed\nmethod can intelligently solve problems under boundary conditions not being\nincluded in the training dataset.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 08:11:27 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 17:03:13 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 06:16:34 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zhang", "Yiquan", ""], ["Peng", "Bo", ""], ["Zhou", "Xiaoyi", ""], ["Xiang", "Cheng", ""], ["Wang", "Dalei", ""]]}, {"id": "1901.07777", "submitter": "Henry Gouk", "authors": "Henry Gouk, Bernhard Pfahringer, Eibe Frank", "title": "Stochastic Gradient Trees", "comments": "Accepted at ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for learning decision trees using stochastic gradient\ninformation as the source of supervision. In contrast to previous approaches to\ngradient-based tree learning, our method operates in the incremental learning\nsetting rather than the batch learning setting, and does not make use of soft\nsplits or require the construction of a new tree for every update. We\ndemonstrate how one can apply these decision trees to different problems by\nchanging only the loss function, using classification, regression, and\nmulti-instance learning as example applications. In the experimental\nevaluation, our method performs similarly to standard incremental\nclassification trees, outperforms state of the art incremental regression\ntrees, and achieves comparable performance with batch multi-instance learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 09:12:22 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 22:21:20 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 16:00:58 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gouk", "Henry", ""], ["Pfahringer", "Bernhard", ""], ["Frank", "Eibe", ""]]}, {"id": "1901.07821", "submitter": "Yochai Blau", "authors": "Yochai Blau, Tomer Michaeli", "title": "Rethinking Lossy Compression: The Rate-Distortion-Perception Tradeoff", "comments": "ICML 2019 (long oral presentation), see talk at:\n  https://slideslive.com/38917633/applications-computer-vision", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:675-685, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy compression algorithms are typically designed and analyzed through the\nlens of Shannon's rate-distortion theory, where the goal is to achieve the\nlowest possible distortion (e.g., low MSE or high SSIM) at any given bit rate.\nHowever, in recent years, it has become increasingly accepted that \"low\ndistortion\" is not a synonym for \"high perceptual quality\", and in fact\noptimization of one often comes at the expense of the other. In light of this\nunderstanding, it is natural to seek for a generalization of rate-distortion\ntheory which takes perceptual quality into account. In this paper, we adopt the\nmathematical definition of perceptual quality recently proposed by Blau &\nMichaeli (2018), and use it to study the three-way tradeoff between rate,\ndistortion, and perception. We show that restricting the perceptual quality to\nbe high, generally leads to an elevation of the rate-distortion curve, thus\nnecessitating a sacrifice in either rate or distortion. We prove several\nfundamental properties of this triple-tradeoff, calculate it in closed form for\na Bernoulli source, and illustrate it visually on a toy MNIST example.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 11:13:33 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 20:10:48 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 14:20:20 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 13:01:06 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Blau", "Yochai", ""], ["Michaeli", "Tomer", ""]]}, {"id": "1901.07822", "submitter": "Ilianna Kollia", "authors": "Ilianna Kollia, Andreas-Georgios Stafylopatis, Stefanos Kollias", "title": "Predicting Parkinson's Disease using Latent Information extracted from\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method for medical diagnosis of neurodegenerative\ndiseases, such as Parkinson's, by extracting and using latent information from\ntrained Deep convolutional, or convolutional-recurrent Neural Networks (DNNs).\nIn particular, our approach adopts a combination of transfer learning, k-means\nclustering and k-Nearest Neighbour classification of deep neural network\nlearned representations to provide enriched prediction of the disease based on\nMRI and/or DaT Scan data. A new loss function is introduced and used in the\ntraining of the DNNs, so as to perform adaptation of the generated learned\nrepresentations between data from different medical environments. Results are\npresented using a recently published database of Parkinson's related\ninformation, which was generated and evaluated in a hospital environment.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 11:14:24 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Kollia", "Ilianna", ""], ["Stafylopatis", "Andreas-Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1901.07859", "submitter": "Kai Olav Ellefsen", "authors": "Kai Olav Ellefsen, Charles Patrick Martin and Jim Torresen", "title": "How do Mixture Density RNNs Predict the Future?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaining a better understanding of how and what machine learning systems learn\nis important to increase confidence in their decisions and catalyze further\nresearch. In this paper, we analyze the predictions made by a specific type of\nrecurrent neural network, mixture density RNNs (MD-RNNs). These networks learn\nto model predictions as a combination of multiple Gaussian distributions,\nmaking them particularly interesting for problems where a sequence of inputs\nmay lead to several distinct future possibilities. An example is learning\ninternal models of an environment, where different events may or may not occur,\nbut where the average over different events is not meaningful. By analyzing the\npredictions made by trained MD-RNNs, we find that their different Gaussian\ncomponents have two complementary roles: 1) Separately modeling different\nstochastic events and 2) Separately modeling scenarios governed by different\nrules. These findings increase our understanding of what is learned by\npredictive MD-RNNs, and open up new research directions for further\nunderstanding how we can benefit from their self-organizing model\ndecomposition.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:06:09 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Ellefsen", "Kai Olav", ""], ["Martin", "Charles Patrick", ""], ["Torresen", "Jim", ""]]}, {"id": "1901.07860", "submitter": "Shirli Di-Castro Shashua", "authors": "Shirli Di-Castro Shashua, Shie Mannor", "title": "Trust Region Value Optimization using Kalman Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation is a key process in reinforcement learning. It assesses a\ngiven policy using estimation of the corresponding value function. When using a\nparameterized function to approximate the value, it is common to optimize the\nset of parameters by minimizing the sum of squared Bellman Temporal Differences\nerrors. However, this approach ignores certain distributional properties of\nboth the errors and value parameters. Taking these distributions into account\nin the optimization process can provide useful information on the amount of\nconfidence in value estimation. In this work we propose to optimize the value\nby minimizing a regularized objective function which forms a trust region over\nits parameters. We present a novel optimization method, the Kalman Optimization\nfor Value Approximation (KOVA), based on the Extended Kalman Filter. KOVA\nminimizes the regularized objective function by adopting a Bayesian perspective\nover both the value parameters and noisy observed returns. This distributional\nproperty provides information on parameter uncertainty in addition to value\nestimates. We provide theoretical results of our approach and analyze the\nperformance of our proposed optimizer on domains with large state and action\nspaces.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:09:31 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Shashua", "Shirli Di-Castro", ""], ["Mannor", "Shie", ""]]}, {"id": "1901.07868", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Constant Time Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advancements in graph neural networks (GNNs) have led to\nstate-of-the-art performances in various applications, including\nchemo-informatics, question-answering systems, and recommender systems.\nHowever, scaling up these methods to huge graphs, such as social networks and\nWeb graphs, remains a challenge. In particular, the existing methods for\naccelerating GNNs either are not theoretically guaranteed in terms of the\napproximation error or incur at least a linear time computation cost. In this\nstudy, we reveal the query complexity of the uniform node sampling scheme for\nMessage Passing Neural Networks including GraphSAGE, graph attention networks\n(GATs), and graph convolutional networks (GCNs). Surprisingly, our analysis\nreveals that the complexity of the node sampling method is completely\nindependent of the number of the nodes, edges, and neighbors of the input and\ndepends only on the error tolerance and confidence probability while providing\na theoretical guarantee for the approximation error. To the best of our\nknowledge, this is the first paper to provide a theoretical guarantee of\napproximation for GNNs within constant time. Through experiments with synthetic\nand real-world datasets, we investigated the speed and precision of the node\nsampling scheme and validated our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:25:16 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 14:48:51 GMT"}, {"version": "v3", "created": "Sat, 8 Feb 2020 12:42:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1901.07874", "submitter": "L\\'eonard Torossian", "authors": "L\\'eonard Torossian, Victor Picheny, Robert Faivre, Aur\\'elien\n  Garivier", "title": "A Review on Quantile Regression for Stochastic Computer Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on an empirical study of the main strategies for quantile\nregression in the context of stochastic computer experiments. To ensure\nadequate diversity, six metamodels are presented, divided into three categories\nbased on order statistics, functional approaches, and those of Bayesian\ninspiration. The metamodels are tested on several problems characterized by the\nsize of the training set, the input dimension, the signal-to-noise ratio and\nthe value of the probability density function at the targeted quantile. The\nmetamodels studied reveal good contrasts in our set of experiments, enabling\nseveral patterns to be extracted. Based on our results, guidelines are proposed\nto allow users to select the best method for a given problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:36:32 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 12:56:26 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 10:30:20 GMT"}, {"version": "v4", "created": "Sun, 19 Jan 2020 23:24:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Torossian", "L\u00e9onard", ""], ["Picheny", "Victor", ""], ["Faivre", "Robert", ""], ["Garivier", "Aur\u00e9lien", ""]]}, {"id": "1901.07878", "submitter": "Christian Otto", "authors": "Christian Otto and Sebastian Holzki and Ralph Ewerth", "title": "\"Is this an example image?\" -- Predicting the Relative Abstractness\n  Level of Image and Text", "comments": "14 pages, 6 figures, accepted at ECIR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful multimodal search and retrieval requires the automatic\nunderstanding of semantic cross-modal relations, which, however, is still an\nopen research problem. Previous work has suggested the metrics cross-modal\nmutual information and semantic correlation to model and predict cross-modal\nsemantic relations of image and text. In this paper, we present an approach to\npredict the (cross-modal) relative abstractness level of a given image-text\npair, that is whether the image is an abstraction of the text or vice versa.\nFor this purpose, we introduce a new metric that captures this specific\nrelationship between image and text at the Abstractness Level (ABS). We present\na deep learning approach to predict this metric, which relies on an autoencoder\narchitecture that allows us to significantly reduce the required amount of\nlabeled training data. A comprehensive set of publicly available scientific\ndocuments has been gathered. Experimental results on a challenging test set\ndemonstrate the feasibility of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:42:02 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Otto", "Christian", ""], ["Holzki", "Sebastian", ""], ["Ewerth", "Ralph", ""]]}, {"id": "1901.07884", "submitter": "Sebastian Raschka", "authors": "Wenzhi Cao, Vahid Mirjalili, Sebastian Raschka", "title": "Rank consistent ordinal regression for neural networks with application\n  to age estimation", "comments": "updated to published version", "journal-ref": "Pattern Recognition Letters 140 (2020) 325-331", "doi": "10.1016/j.patrec.2020.11.008", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world prediction tasks, class labels include information about\nthe relative ordering between labels, which is not captured by commonly-used\nloss functions such as multi-category cross-entropy. Recently, the deep\nlearning community adopted ordinal regression frameworks to take such ordering\ninformation into account. Neural networks were equipped with ordinal regression\ncapabilities by transforming ordinal targets into binary classification\nsubtasks. However, this method suffers from inconsistencies among the different\nbinary classifiers. To resolve these inconsistencies, we propose the COnsistent\nRAnk Logits (CORAL) framework with strong theoretical guarantees for\nrank-monotonicity and consistent confidence scores. Moreover, the proposed\nmethod is architecture-agnostic and can extend arbitrary state-of-the-art deep\nneural network classifiers for ordinal regression tasks. The empirical\nevaluation of the proposed rank-consistent method on a range of face-image\ndatasets for age prediction shows a substantial reduction of the prediction\nerror compared to the reference ordinal regression network.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 08:02:25 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 03:35:10 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 06:34:48 GMT"}, {"version": "v4", "created": "Mon, 5 Aug 2019 08:57:14 GMT"}, {"version": "v5", "created": "Tue, 23 Jun 2020 21:28:56 GMT"}, {"version": "v6", "created": "Tue, 8 Sep 2020 23:06:08 GMT"}, {"version": "v7", "created": "Fri, 13 Nov 2020 16:02:31 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Cao", "Wenzhi", ""], ["Mirjalili", "Vahid", ""], ["Raschka", "Sebastian", ""]]}, {"id": "1901.07915", "submitter": "Luca Pion-Tonachini", "authors": "Luca Pion-Tonachini, Ken Kreutz-Delgado, and Scott Makeig", "title": "ICLabel: An automated electroencephalographic independent component\n  classifier, dataset, and website", "comments": "Intended for NeuroImage. Updated from version one with minor\n  editorial and figure changes", "journal-ref": null, "doi": "10.1016/j.neuroimage.2019.05.026", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electroencephalogram (EEG) provides a non-invasive, minimally\nrestrictive, and relatively low cost measure of mesoscale brain dynamics with\nhigh temporal resolution. Although signals recorded in parallel by multiple,\nnear-adjacent EEG scalp electrode channels are highly-correlated and combine\nsignals from many different sources, biological and non-biological, independent\ncomponent analysis (ICA) has been shown to isolate the various source generator\nprocesses underlying those recordings. Independent components (IC) found by ICA\ndecomposition can be manually inspected, selected, and interpreted, but doing\nso requires both time and practice as ICs have no particular order or intrinsic\ninterpretations and therefore require further study of their properties.\nAlternatively, sufficiently-accurate automated IC classifiers can be used to\nclassify ICs into broad source categories, speeding the analysis of EEG studies\nwith many subjects and enabling the use of ICA decomposition in near-real-time\napplications. While many such classifiers have been proposed recently, this\nwork presents the ICLabel project comprised of (1) an IC dataset containing\nspatiotemporal measures for over 200,000 ICs from more than 6,000 EEG\nrecordings, (2) a website for collecting crowdsourced IC labels and educating\nEEG researchers and practitioners about IC interpretation, and (3) the\nautomated ICLabel classifier. The classifier improves upon existing methods in\ntwo ways: by improving the accuracy of the computed label estimates and by\nenhancing its computational efficiency. The ICLabel classifier outperforms or\nperforms comparably to the previous best publicly available method for all\nmeasured IC categories while computing those labels ten times faster than that\nclassifier as shown in a rigorous comparison against all other publicly\navailable EEG IC classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:48:42 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 16:58:49 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Pion-Tonachini", "Luca", ""], ["Kreutz-Delgado", "Ken", ""], ["Makeig", "Scott", ""]]}, {"id": "1901.07922", "submitter": "Vittorio Lippi", "authors": "Vittorio Lippi and Giacomo Ceccarelli", "title": "Incremental Principal Component Analysis Exact implementation and\n  continuity corrections", "comments": "accepted at http://www.icinco.org/", "journal-ref": null, "doi": "10.5220/0007743604730480", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes some applications of an incremental implementation of\nthe principal component analysis (PCA). The algorithm updates the\ntransformation coefficients matrix on-line for each new sample, without the\nneed to keep all the samples in memory. The algorithm is formally equivalent to\nthe usual batch version, in the sense that given a sample set the\ntransformation coefficients at the end of the process are the same. The\nimplications of applying the PCA in real time are discussed with the help of\ndata analysis examples. In particular we focus on the problem of the continuity\nof the PCs during an on-line analysis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:43:19 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 12:48:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Lippi", "Vittorio", ""], ["Ceccarelli", "Giacomo", ""]]}, {"id": "1901.07924", "submitter": "Chao Gan", "authors": "Chao Gan, Jing Yang, Ruida Zhou, Cong Shen", "title": "Online Learning with Diverse User Preferences", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the impact of diverse user preference on\nlearning under the stochastic multi-armed bandit (MAB) framework. We aim to\nshow that when the user preferences are sufficiently diverse and each arm can\nbe optimal for certain users, the O(log T) regret incurred by exploring the\nsub-optimal arms under the standard stochastic MAB setting can be reduced to a\nconstant. Our intuition is that to achieve sub-linear regret, the number of\ntimes an optimal arm being pulled should scale linearly in time; when all arms\nare optimal for certain users and pulled frequently, the estimated arm\nstatistics can quickly converge to their true values, thus reducing the need of\nexploration dramatically. We cast the problem into a stochastic linear bandits\nmodel, where both the users preferences and the state of arms are modeled as\n{independent and identical distributed (i.i.d)} d-dimensional random vectors.\nAfter receiving the user preference vector at the beginning of each time slot,\nthe learner pulls an arm and receives a reward as the linear product of the\npreference vector and the arm state vector. We also assume that the state of\nthe pulled arm is revealed to the learner once its pulled. We propose a\nWeighted Upper Confidence Bound (W-UCB) algorithm and show that it can achieve\na constant regret when the user preferences are sufficiently diverse. The\nperformance of W-UCB under general setups is also completely characterized and\nvalidated with synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:44:12 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 20:10:07 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 17:34:19 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gan", "Chao", ""], ["Yang", "Jing", ""], ["Zhou", "Ruida", ""], ["Shen", "Cong", ""]]}, {"id": "1901.07935", "submitter": "Emma Frejinger", "authors": "Eric Larsen, S\\'ebastien Lachapelle, Yoshua Bengio, Emma Frejinger,\n  Simon Lacoste-Julien and Andrea Lodi", "title": "Predicting Tactical Solutions to Operational Planning Problems under\n  Imperfect Information", "comments": "Same as arXiv:1807.11876, added by mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict tactical solutions to a given operational problem. In this\ncontext, the tactical solution is less detailed than the operational one but it\nhas to be computed in very short time and under imperfect information. The\nproblem is of importance in various applications where tactical and operational\nplanning problems are interrelated and information about the operational\nproblem is revealed over time. This is for instance the case in certain\ncapacity planning and demand management systems.\n  We formulate the problem as a two-stage optimal prediction stochastic program\nwhose solution we predict with a supervised machine learning algorithm. The\ntraining data set consists of a large number of deterministic (second stage)\nproblems generated by controlled probabilistic sampling. The labels are\ncomputed based on solutions to the deterministic problems (solved independently\nand offline) employing appropriate aggregation and subselection methods to\naddress uncertainty. Results on our motivating application in load planning for\nrail transportation show that deep learning algorithms produce highly accurate\npredictions in very short computing time (milliseconds or less). The prediction\naccuracy is comparable to solutions computed by sample average approximation of\nthe stochastic program.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 15:46:00 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 13:55:14 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 14:46:56 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 14:02:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Larsen", "Eric", ""], ["Lachapelle", "S\u00e9bastien", ""], ["Bengio", "Yoshua", ""], ["Frejinger", "Emma", ""], ["Lacoste-Julien", "Simon", ""], ["Lodi", "Andrea", ""]]}, {"id": "1901.07957", "submitter": "Yann Soullard", "authors": "Yann Soullard, Cyprien Ruffino, Thierry Paquet", "title": "CTCModel: a Keras Model for Connectionist Temporal Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report an extension of a Keras Model, called CTCModel, to perform the\nConnectionist Temporal Classification (CTC) in a transparent way. Combined with\nRecurrent Neural Networks, the Connectionist Temporal Classification is the\nreference method for dealing with unsegmented input sequences, i.e. with data\nthat are a couple of observation and label sequences where each label is\nrelated to a subset of observation frames. CTCModel makes use of the CTC\nimplementation in the Tensorflow backend for training and predicting sequences\nof labels using Keras. It consists of three branches made of Keras models: one\nfor training, computing the CTC loss function; one for predicting, providing\nsequences of labels; and one for evaluating that returns standard metrics for\nanalyzing sequences of predictions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 15:39:01 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Soullard", "Yann", ""], ["Ruffino", "Cyprien", ""], ["Paquet", "Thierry", ""]]}, {"id": "1901.07977", "submitter": "Xiaoliang Wan", "authors": "Xiaoliang Wan and Shuangqing Wei", "title": "Coupling the reduced-order model and the generative model for an\n  importance sampling estimator", "comments": null, "journal-ref": "Journal of Computational Physics, 408(2020), 109281", "doi": "10.1016/j.jcp.2020.109281", "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop an importance sampling estimator by coupling the\nreduced-order model and the generative model in a problem setting of\nuncertainty quantification. The target is to estimate the probability that the\nquantity of interest (QoI) in a complex system is beyond a given threshold. To\navoid the prohibitive cost of sampling a large scale system, the reduced-order\nmodel is usually considered for a trade-off between efficiency and accuracy.\nHowever, the Monte Carlo estimator given by the reduced-order model is biased\ndue to the error from dimension reduction. To correct the bias, we still need\nto sample the fine model. An effective technique to reduce the variance\nreduction is importance sampling, where we employ the generative model to\nestimate the distribution of the data from the reduced-order model and use it\nfor the change of measure in the importance sampling estimator. To compensate\nthe approximation errors of the reduced-order model, more data that induce a\nslightly smaller QoI than the threshold need to be included into the training\nset. Although the amount of these data can be controlled by a posterior error\nestimate, redundant data, which may outnumber the effective data, will be kept\ndue to the epistemic uncertainty. To deal with this issue, we introduce a\nweighted empirical distribution to process the data from the reduced-order\nmodel. The generative model is then trained by minimizing the cross entropy\nbetween it and the weighted empirical distribution. We also introduce a penalty\nterm into the objective function to deal with the overfitting for more\nrobustness. Numerical results are presented to demonstrate the effectiveness of\nthe proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:19:55 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Wan", "Xiaoliang", ""], ["Wei", "Shuangqing", ""]]}, {"id": "1901.07984", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Marcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Marco Gori,\n  Luis Lamb", "title": "Typed Graph Networks", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the deep learning community has given growing attention to neural\narchitectures engineered to learn problems in relational domains. Convolutional\nNeural Networks employ parameter sharing over the image domain, tying the\nweights of neural connections on a grid topology and thus enforcing the\nlearning of a number of convolutional kernels. By instantiating trainable\nneural modules and assembling them in varied configurations (apart from grids),\none can enforce parameter sharing over graphs, yielding models which can\neffectively be fed with relational data. In this context, vertices in a graph\ncan be projected into a hyperdimensional real space and iteratively refined\nover many message-passing iterations in an end-to-end differentiable\narchitecture. Architectures of this family have been referred to with several\ndefinitions in the literature, such as Graph Neural Networks, Message-passing\nNeural Networks, Relational Networks and Graph Networks. In this paper, we\nrevisit the original Graph Neural Network model and show that it generalises\nmany of the recent models, which in turn benefit from the insight of thinking\nabout vertex \\textbf{types}. To illustrate the generality of the original\nmodel, we present a Graph Neural Network formalisation, which partitions the\nvertices of a graph into a number of types. Each type represents an entity in\nthe ontology of the problem one wants to learn. This allows - for instance -\none to assign embeddings to edges, hyperedges, and any number of global\nattributes of the graph. As a companion to this paper we provide a\nPython/Tensorflow library to facilitate the development of such architectures,\nwith which we instantiate the formalisation to reproduce a number of models\nproposed in the current literature.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:29:24 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 11:44:20 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 18:07:38 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Prates", "Marcelo O. R.", ""], ["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Gori", "Marco", ""], ["Lamb", "Luis", ""]]}, {"id": "1901.07986", "submitter": "Malik Magdon-Ismail", "authors": "Maksim Tsikhanovich and Malik Magdon-Ismail and Muhammad Ishaq and\n  Vassilis Zikas", "title": "PD-ML-Lite: Private Distributed Machine Learning from Lighweight\n  Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is a major issue in learning from distributed data. Recently the\ncryptographic literature has provided several tools for this task. However,\nthese tools either reduce the quality/accuracy of the learning\nalgorithm---e.g., by adding noise---or they incur a high performance penalty\nand/or involve trusting external authorities.\n  We propose a methodology for {\\sl private distributed machine learning from\nlight-weight cryptography} (in short, PD-ML-Lite). We apply our methodology to\ntwo major ML algorithms, namely non-negative matrix factorization (NMF) and\nsingular value decomposition (SVD). Our resulting protocols are communication\noptimal, achieve the same accuracy as their non-private counterparts, and\nsatisfy a notion of privacy---which we define---that is both intuitive and\nmeasurable. Our approach is to use lightweight cryptographic protocols (secure\nsum and normalized secure sum) to build learning algorithms rather than wrap\ncomplex learning algorithms in a heavy-cost MPC framework.\n  We showcase our algorithms' utility and privacy on several applications: for\nNMF we consider topic modeling and recommender systems, and for SVD, principal\ncomponent regression, and low rank approximation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:34:28 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 20:37:11 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Tsikhanovich", "Maksim", ""], ["Magdon-Ismail", "Malik", ""], ["Ishaq", "Muhammad", ""], ["Zikas", "Vassilis", ""]]}, {"id": "1901.07987", "submitter": "Gianluca Detommaso", "authors": "Gianluca Detommaso, Hanne Hoitzing, Tiangang Cui, Ardavan Alamir", "title": "Stein Variational Online Changepoint Detection with Applications to\n  Hawkes Processes and Neural Networks", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian online changepoint detection (BOCPD) (Adams & MacKay, 2007) offers a\nrigorous and viable way to identify changepoints in complex systems. In this\nwork, we introduce a Stein variational online changepoint detection (SVOCD)\nmethod to provide a computationally tractable generalization of BOCPD beyond\nthe exponential family of probability distributions. We integrate the recently\ndeveloped Stein variational Newton (SVN) method (Detommaso et al., 2018) and\nBOCPD to offer a full online Bayesian treatment for a large number of\nsituations with significant importance in practice. We apply the resulting\nmethod to two challenging and novel applications: Hawkes processes and long\nshort-term memory (LSTM) neural networks. In both cases, we successfully\ndemonstrate the efficacy of our method on real data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:35:00 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 10:15:02 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Detommaso", "Gianluca", ""], ["Hoitzing", "Hanne", ""], ["Cui", "Tiangang", ""], ["Alamir", "Ardavan", ""]]}, {"id": "1901.07988", "submitter": "Ayan Chakrabarti", "authors": "Ayan Chakrabarti, Benjamin Moseley", "title": "Backprop with Approximate Activations for Memory-efficient Network\n  Training", "comments": "Project page at http://projects.ayanc.org/blpa/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training convolutional neural network models is memory intensive since\nback-propagation requires storing activations of all intermediate layers. This\npresents a practical concern when seeking to deploy very deep architectures in\nproduction, especially when models need to be frequently re-trained on updated\ndatasets. In this paper, we propose a new implementation for back-propagation\nthat significantly reduces memory usage, by enabling the use of approximations\nwith negligible computational cost and minimal effect on training performance.\nThe algorithm reuses common buffers to temporarily store full activations and\ncompute the forward pass exactly. It also stores approximate per-layer copies\nof activations, at significant memory savings, that are used in the backward\npass. Compared to simply approximating activations within standard\nback-propagation, our method limits accumulation of errors across layers. This\nallows the use of much lower-precision approximations without affecting\ntraining accuracy. Experiments on CIFAR-10, CIFAR-100, and ImageNet show that\nour method yields performance close to exact training, while storing\nactivations compactly with as low as 4-bit precision.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:40:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 18:00:26 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Chakrabarti", "Ayan", ""], ["Moseley", "Benjamin", ""]]}, {"id": "1901.08013", "submitter": "Fei Qi", "authors": "Fei Qi, Zhaohui Xia, Gaoyang Tang, Hang Yang, Yu Song, Guangrui Qian,\n  Xiong An, Chunhuan Lin, Guangming Shi", "title": "DarwinML: A Graph-based Evolutionary Algorithm for Automated Machine\n  Learning", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging field, Automated Machine Learning (AutoML) aims to reduce or\neliminate manual operations that require expertise in machine learning. In this\npaper, a graph-based architecture is employed to represent flexible\ncombinations of ML models, which provides a large searching space compared to\ntree-based and stacking-based architectures. Based on this, an evolutionary\nalgorithm is proposed to search for the best architecture, where the mutation\nand heredity operators are the key for architecture evolution. With Bayesian\nhyper-parameter optimization, the proposed approach can automate the workflow\nof machine learning. On the PMLB dataset, the proposed approach shows the\nstate-of-the-art performance compared with TPOT, Autostacker, and auto-sklearn.\nSome of the optimized models are with complex structures which are difficult to\nobtain in manual design.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:42:41 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Qi", "Fei", ""], ["Xia", "Zhaohui", ""], ["Tang", "Gaoyang", ""], ["Yang", "Hang", ""], ["Song", "Yu", ""], ["Qian", "Guangrui", ""], ["An", "Xiong", ""], ["Lin", "Chunhuan", ""], ["Shi", "Guangming", ""]]}, {"id": "1901.08019", "submitter": "Vincenzo Crescimanna", "authors": "Vincenzo Crescimanna, Bruce Graham", "title": "An information theoretic approach to the autoencoder", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a variation of the Autoencoder (AE) that explicitly maximizes the\nmutual information between the input data and the hidden representation. The\nproposed model, the InfoMax Autoencoder (IMAE), by construction is able to\nlearn a robust representation and good prototypes of the data. IMAE is compared\nboth theoretically and then computationally with the state of the art models:\nthe Denoising and Contractive Autoencoders in the one-hidden layer setting and\nthe Variational Autoencoder in the multi-layer case. Computational experiments\nare performed with the MNIST and Fashion-MNIST datasets and demonstrate\nparticularly the strong clusterization performance of IMAE.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:29:00 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Crescimanna", "Vincenzo", ""], ["Graham", "Bruce", ""]]}, {"id": "1901.08021", "submitter": "Richard Klima", "authors": "Richard Klima, Daan Bloembergen, Michael Kaisers, Karl Tuyls", "title": "Robust Temporal Difference Learning for Critical Domains", "comments": "AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Q-function operator for temporal difference (TD) learning\nmethods that explicitly encodes robustness against significant rare events\n(SRE) in critical domains. The operator, which we call the $\\kappa$-operator,\nallows to learn a robust policy in a model-based fashion without actually\nobserving the SRE. We introduce single- and multi-agent robust TD methods using\nthe operator $\\kappa$. We prove convergence of the operator to the optimal\nrobust Q-function with respect to the model using the theory of Generalized\nMarkov Decision Processes. In addition we prove convergence to the optimal\nQ-function of the original MDP given that the probability of SREs vanishes.\nEmpirical evaluations demonstrate the superior performance of $\\kappa$-based TD\nmethods both in the early learning phase as well as in the final converged\nstage. In addition we show robustness of the proposed method to small model\nerrors, as well as its applicability in a multi-agent context.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:34:51 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:27:46 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Klima", "Richard", ""], ["Bloembergen", "Daan", ""], ["Kaisers", "Michael", ""], ["Tuyls", "Karl", ""]]}, {"id": "1901.08022", "submitter": "Alireza Fallah", "authors": "Necdet Serhat Aybat, Alireza Fallah, Mert Gurbuzbalaban, Asuman\n  Ozdaglar", "title": "A Universally Optimal Multistage Accelerated Stochastic Gradient Method", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of minimizing a strongly convex, smooth function when we\nhave noisy estimates of its gradient. We propose a novel multistage accelerated\nalgorithm that is universally optimal in the sense that it achieves the optimal\nrate both in the deterministic and stochastic case and operates without\nknowledge of noise characteristics. The algorithm consists of stages that use a\nstochastic version of Nesterov's method with a specific restart and parameters\nselected to achieve the fastest reduction in the bias-variance terms in the\nconvergence rate bounds.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:34:55 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 03:07:57 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 01:08:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Aybat", "Necdet Serhat", ""], ["Fallah", "Alireza", ""], ["Gurbuzbalaban", "Mert", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "1901.08029", "submitter": "Goran Radanovic", "authors": "Goran Radanovic, Rati Devidze, David C. Parkes, Adish Singla", "title": "Learning to Collaborate in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a two-agent MDP framework where agents repeatedly solve a task in\na collaborative setting. We study the problem of designing a learning algorithm\nfor the first agent (A1) that facilitates a successful collaboration even in\ncases when the second agent (A2) is adapting its policy in an unknown way. The\nkey challenge in our setting is that the first agent faces non-stationarity in\nrewards and transitions because of the adaptive behavior of the second agent.\n  We design novel online learning algorithms for agent A1 whose regret decays\nas $O(T^{\\max\\{1-\\frac{3}{7} \\cdot \\alpha, \\frac{1}{4}\\}})$ with $T$ learning\nepisodes provided that the magnitude of agent A2's policy changes between any\ntwo consecutive episodes are upper bounded by $O(T^{-\\alpha})$. Here, the\nparameter $\\alpha$ is assumed to be strictly greater than $0$, and we show that\nthis assumption is necessary provided that the learning parity with noise\nproblem is computationally hard. We show that sub-linear regret of agent A1\nfurther implies near-optimality of the agents' joint return for MDPs that\nmanifest the properties of a smooth game.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 18:03:55 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 03:38:57 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Radanovic", "Goran", ""], ["Devidze", "Rati", ""], ["Parkes", "David C.", ""], ["Singla", "Adish", ""]]}, {"id": "1901.08045", "submitter": "Viktor Yanush", "authors": "Viktor Yanush and Dmitry Kropotov", "title": "Hamiltonian Monte-Carlo for Orthogonal Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling from posterior distributions for Bayesian\nmodels where some parameters are restricted to be orthogonal matrices. Such\nmatrices are sometimes used in neural networks models for reasons of\nregularization and stabilization of training procedures, and also can\nparameterize matrices of bounded rank, positive-definite matrices and others.\nIn \\citet{byrne2013geodesic} authors have already considered sampling from\ndistributions over manifolds using exact geodesic flows in a scheme similar to\nHamiltonian Monte Carlo (HMC). We propose new sampling scheme for a set of\northogonal matrices that is based on the same approach, uses ideas of\nRiemannian optimization and does not require exact computation of geodesic\nflows. The method is theoretically justified by proof of symplecticity for the\nproposed iteration. In experiments we show that the new scheme is comparable or\nfaster in time per iteration and more sample-efficient comparing to\nconventional HMC with explicit orthogonal parameterization and Geodesic\nMonte-Carlo. We also provide promising results of Bayesian ensembling for\northogonal neural networks and low-rank matrix factorization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 18:55:37 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Yanush", "Viktor", ""], ["Kropotov", "Dmitry", ""]]}, {"id": "1901.08057", "submitter": "Hanwen Huang", "authors": "Hanwen Huang", "title": "Large dimensional analysis of general margin based classification\n  methods", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Margin-based classifiers have been popular in both machine learning and\nstatistics for classification problems. Since a large number of classifiers are\navailable, one natural question is which type of classifiers should be used\ngiven a particular classification task. We aim to answering this question by\ninvestigating the asymptotic performance of a family of large-margin\nclassifiers in situations where the data dimension $p$ and the sample $n$ are\nboth large. This family covers a broad range of classifiers including support\nvector machine, distance weighted discrimination, penalized logistic\nregression, and large-margin unified machine as special cases. The asymptotic\nresults are described by a set of nonlinear equations and we observe a close\nmatch of them with Monte Carlo simulation on finite data samples. Our\nanalytical studies shed new light on how to select the best classifier among\nvarious classification methods as well as on how to choose the optimal tuning\nparameters for a given method.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 14:45:08 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Huang", "Hanwen", ""]]}, {"id": "1901.08082", "submitter": "Tommaso Renato Cesari", "authors": "Nicol\\`o Cesa-Bianchi, Tommaso R. Cesari, Claire Monteleoni", "title": "Cooperative Online Learning: Keeping your Neighbors Updated", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an asynchronous online learning setting with a network of agents. At\neach time step, some of the agents are activated, requested to make a\nprediction, and pay the corresponding loss. The loss function is then revealed\nto these agents and also to their neighbors in the network. Our results\ncharacterize how much knowing the network structure affects the regret as a\nfunction of the model of agent activations. When activations are stochastic,\nthe optimal regret (up to constant factors) is shown to be of order\n$\\sqrt{\\alpha T}$, where $T$ is the horizon and $\\alpha$ is the independence\nnumber of the network. We prove that the upper bound is achieved even when\nagents have no information about the network structure. When activations are\nadversarial the situation changes dramatically: if agents ignore the network\nstructure, a $\\Omega(T)$ lower bound on the regret can be proven, showing that\nlearning is impossible. However, when agents can choose to ignore some of their\nneighbors based on the knowledge of the network structure, we prove a\n$O(\\sqrt{\\overline{\\chi} T})$ sublinear regret bound, where $\\overline{\\chi}\n\\ge \\alpha$ is the clique-covering number of the network.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:07:42 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 13:15:25 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 21:30:34 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 18:35:53 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", ""], ["Cesari", "Tommaso R.", ""], ["Monteleoni", "Claire", ""]]}, {"id": "1901.08096", "submitter": "Bryan Lim", "authors": "Bryan Lim, Stefan Zohren, Stephen Roberts", "title": "Recurrent Neural Filters: Learning Independent Bayesian Filtering Steps\n  for Time Series Prediction", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent popularity of deep generative state space models, few\ncomparisons have been made between network architectures and the inference\nsteps of the Bayesian filtering framework -- with most models simultaneously\napproximating both state transition and update steps with a single recurrent\nneural network (RNN). In this paper, we introduce the Recurrent Neural Filter\n(RNF), a novel recurrent autoencoder architecture that learns distinct\nrepresentations for each Bayesian filtering step, captured by a series of\nencoders and decoders. Testing this on three real-world time series datasets,\nwe demonstrate that the decoupled representations learnt not only improve the\naccuracy of one-step-ahead forecasts while providing realistic uncertainty\nestimates, but also facilitate multistep prediction through the separation of\nencoder stages.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:43:06 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:19:09 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 01:35:14 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 22:52:59 GMT"}, {"version": "v5", "created": "Mon, 30 Mar 2020 15:52:06 GMT"}, {"version": "v6", "created": "Sun, 27 Sep 2020 14:26:01 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1901.08098", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Heiko Strathmann, Gunnar R\\\"atsch", "title": "Meta-Learning Mean Functions for Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When fitting Bayesian machine learning models on scarce data, the main\nchallenge is to obtain suitable prior knowledge and encode it into the model.\nRecent advances in meta-learning offer powerful methods for extracting such\nprior knowledge from data acquired in related tasks. When it comes to\nmeta-learning in Gaussian process models, approaches in this setting have\nmostly focused on learning the kernel function of the prior, but not on\nlearning its mean function. In this work, we explore meta-learning the mean\nfunction of a Gaussian process prior. We present analytical and empirical\nevidence that mean function learning can be useful in the meta-learning\nsetting, discuss the risk of overfitting, and draw connections to other\nmeta-learning approaches, such as model agnostic meta-learning and functional\nPCA.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:43:59 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:01:45 GMT"}, {"version": "v3", "created": "Sat, 19 Oct 2019 10:19:53 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 16:55:49 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Fortuin", "Vincent", ""], ["Strathmann", "Heiko", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1901.08106", "submitter": "David Balduzzi", "authors": "David Balduzzi, Marta Garnelo, Yoram Bachrach, Wojciech M. Czarnecki,\n  Julien Perolat, Max Jaderberg, Thore Graepel", "title": "Open-ended Learning in Symmetric Zero-sum Games", "comments": "ICML 2019, final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-sum games such as chess and poker are, abstractly, functions that\nevaluate pairs of agents, for example labeling them `winner' and `loser'. If\nthe game is approximately transitive, then self-play generates sequences of\nagents of increasing strength. However, nontransitive games, such as\nrock-paper-scissors, can exhibit strategic cycles, and there is no longer a\nclear objective -- we want agents to increase in strength, but against whom is\nunclear. In this paper, we introduce a geometric framework for formulating\nagent objectives in zero-sum games, in order to construct adaptive sequences of\nobjectives that yield open-ended learning. The framework allows us to reason\nabout population performance in nontransitive games, and enables the\ndevelopment of a new algorithm (rectified Nash response, PSRO_rN) that uses\ngame-theoretic niching to construct diverse populations of effective agents,\nproducing a stronger set of agents than existing algorithms. We apply PSRO_rN\nto two highly nontransitive resource allocation games and find that PSRO_rN\nconsistently outperforms the existing alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:56:17 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 16:53:45 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Balduzzi", "David", ""], ["Garnelo", "Marta", ""], ["Bachrach", "Yoram", ""], ["Czarnecki", "Wojciech M.", ""], ["Perolat", "Julien", ""], ["Jaderberg", "Max", ""], ["Graepel", "Thore", ""]]}, {"id": "1901.08121", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Xitong Gao, Yiren Zhao, Robert Mullins, Ross Anderson,\n  Cheng-Zhong Xu", "title": "Sitatapatra: Blocking the Transfer of Adversarial Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are widely used to solve classification\ntasks in computer vision. However, they can be tricked into misclassifying\nspecially crafted `adversarial' samples -- and samples built to trick one model\noften work alarmingly well against other models trained on the same task. In\nthis paper we introduce Sitatapatra, a system designed to block the transfer of\nadversarial samples. It diversifies neural networks using a key, as in\ncryptography, and provides a mechanism for detecting attacks. What's more, when\nadversarial samples are detected they can typically be traced back to the\nindividual device that was used to develop them. The run-time overheads are\nminimal permitting the use of Sitatapatra on constrained systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 20:31:54 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 16:32:27 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shumailov", "Ilia", ""], ["Gao", "Xitong", ""], ["Zhao", "Yiren", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1901.08125", "submitter": "Alvaro Ulloa Cerna", "authors": "Alvaro E. Ulloa Cerna, Marios Pattichis, David P. vanMaanen, Linyuan\n  Jing, Aalpen A. Patel, Joshua V. Stough, Christopher M. Haggerty, and Brandon\n  K. Fornwalt", "title": "Interpretable Neural Networks for Predicting Mortality Risk using\n  Multi-modal Electronic Health Records", "comments": "Submitted to IEEE JBHI", "journal-ref": "IEEE Journal of Biomedical and Health Informatics, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interpretable neural network for predicting an important\nclinical outcome (1-year mortality) from multi-modal Electronic Health Record\n(EHR) data. Our approach builds on prior multi-modal machine learning models by\nnow enabling visualization of how individual factors contribute to the overall\noutcome risk, assuming other factors remain constant, which was previously\nimpossible.\n  We demonstrate the value of this approach using a large multi-modal clinical\ndataset including both EHR data and 31,278 echocardiographic videos of the\nheart from 26,793 patients. We generated separate models for (i) clinical data\nonly (CD) (e.g. age, sex, diagnoses and laboratory values), (ii) numeric\nvariables derived from the videos, which we call echocardiography-derived\nmeasures (EDM), and (iii) CD+EDM+raw videos (pixel data). The interpretable\nmulti-modal model maintained performance compared to non-interpretable models\n(Random Forest, XGBoost), and also performed significantly better than a model\nusing a single modality (average AUC=0.82). Clinically relevant insights and\nmulti-modal variable importance rankings were also facilitated by the new\nmodel, which have previously been impossible.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 20:47:40 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Cerna", "Alvaro E. Ulloa", ""], ["Pattichis", "Marios", ""], ["vanMaanen", "David P.", ""], ["Jing", "Linyuan", ""], ["Patel", "Aalpen A.", ""], ["Stough", "Joshua V.", ""], ["Haggerty", "Christopher M.", ""], ["Fornwalt", "Brandon K.", ""]]}, {"id": "1901.08150", "submitter": "Song Bai", "authors": "Song Bai, Feihu Zhang, Philip H.S. Torr", "title": "Hypergraph Convolution and Hypergraph Attention", "comments": "Accepted by Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, graph neural networks have attracted great attention and achieved\nprominent performance in various research fields. Most of those algorithms have\nassumed pairwise relationships of objects of interest. However, in many real\napplications, the relationships between objects are in higher-order, beyond a\npairwise formulation. To efficiently learn deep embeddings on the high-order\ngraph-structured data, we introduce two end-to-end trainable operators to the\nfamily of graph neural networks, i.e., hypergraph convolution and hypergraph\nattention. Whilst hypergraph convolution defines the basic formulation of\nperforming convolution on a hypergraph, hypergraph attention further enhances\nthe capacity of representation learning by leveraging an attention module. With\nthe two operators, a graph neural network is readily extended to a more\nflexible model and applied to diverse applications where non-pairwise\nrelationships are observed. Extensive experimental results with semi-supervised\nnode classification demonstrate the effectiveness of hypergraph convolution and\nhypergraph attention.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:09:21 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 14:44:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bai", "Song", ""], ["Zhang", "Feihu", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1901.08152", "submitter": "Karl Kumbier", "authors": "Bin Yu and Karl Kumbier", "title": "Veridical Data Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building and expanding on principles of statistics, machine learning, and\nscientific inquiry, we propose the predictability, computability, and stability\n(PCS) framework for veridical data science. Our framework, comprised of both a\nworkflow and documentation, aims to provide responsible, reliable,\nreproducible, and transparent results across the entire data science life\ncycle. The PCS workflow uses predictability as a reality check and considers\nthe importance of computation in data collection/storage and algorithm design.\nIt augments predictability and computability with an overarching stability\nprinciple for the data science life cycle. Stability expands on statistical\nuncertainty considerations to assess how human judgment calls impact data\nresults through data and model/algorithm perturbations. Moreover, we develop\ninference procedures that build on PCS, namely PCS perturbation intervals and\nPCS hypothesis testing, to investigate the stability of data results relative\nto problem formulation, data cleaning, modeling decisions, and interpretations.\nWe illustrate PCS inference through neuroscience and genomics projects of our\nown and others and compare it to existing methods in high dimensional, sparse\nlinear model simulations. Over a wide range of misspecified simulation models,\nPCS inference demonstrates favorable performance in terms of ROC curves.\nFinally, we propose PCS documentation based on R Markdown or Jupyter Notebook,\nwith publicly available, reproducible codes and narratives to back up human\nchoices made throughout an analysis. The PCS workflow and documentation are\ndemonstrated in a genomics case study available on Zenodo.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:17:36 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 16:54:17 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2019 21:23:02 GMT"}, {"version": "v4", "created": "Sun, 13 Oct 2019 18:50:02 GMT"}, {"version": "v5", "created": "Tue, 12 Nov 2019 22:26:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yu", "Bin", ""], ["Kumbier", "Karl", ""]]}, {"id": "1901.08159", "submitter": "Amr Sharaf", "authors": "Amr Sharaf, Hal Daum\\'e III", "title": "Meta-Learning for Contextual Bandit Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe MELEE, a meta-learning algorithm for learning a good exploration\npolicy in the interactive contextual bandit setting. Here, an algorithm must\ntake actions based on contexts, and learn based only on a reward signal from\nthe action taken, thereby generating an exploration/exploitation trade-off.\nMELEE addresses this trade-off by learning a good exploration strategy for\noffline tasks based on synthetic data, on which it can simulate the contextual\nbandit setting. Based on these simulations, MELEE uses an imitation learning\nstrategy to learn a good exploration policy that can then be applied to true\ncontextual bandit tasks at test time. We compare MELEE to seven strong baseline\ncontextual bandit algorithms on a set of three hundred real-world datasets, on\nwhich it outperforms alternatives in most settings, especially when differences\nin rewards are large. Finally, we demonstrate the importance of having a rich\nfeature representation for learning how to explore.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:52:13 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Sharaf", "Amr", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1901.08162", "submitter": "Ishita Dasgupta", "authors": "Ishita Dasgupta, Jane Wang, Silvia Chiappa, Jovana Mitrovic, Pedro\n  Ortega, David Raposo, Edward Hughes, Peter Battaglia, Matthew Botvinick, Zeb\n  Kurth-Nelson", "title": "Causal Reasoning from Meta-reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering and exploiting the causal structure in the environment is a\ncrucial challenge for intelligent agents. Here we explore whether causal\nreasoning can emerge via meta-reinforcement learning. We train a recurrent\nnetwork with model-free reinforcement learning to solve a range of problems\nthat each contain causal structure. We find that the trained agent can perform\ncausal reasoning in novel situations in order to obtain rewards. The agent can\nselect informative interventions, draw causal inferences from observational\ndata, and make counterfactual predictions. Although established formal causal\nreasoning algorithms also exist, in this paper we show that such reasoning can\narise from model-free reinforcement learning, and suggest that causal reasoning\nin complex settings may benefit from the more end-to-end learning-based\napproaches presented here. This work also offers new strategies for structured\nexploration in reinforcement learning, by providing agents with the ability to\nperform -- and interpret -- experiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:03:59 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Dasgupta", "Ishita", ""], ["Wang", "Jane", ""], ["Chiappa", "Silvia", ""], ["Mitrovic", "Jovana", ""], ["Ortega", "Pedro", ""], ["Raposo", "David", ""], ["Hughes", "Edward", ""], ["Battaglia", "Peter", ""], ["Botvinick", "Matthew", ""], ["Kurth-Nelson", "Zeb", ""]]}, {"id": "1901.08164", "submitter": "Eugene Belilovsky", "authors": "Eugene Belilovsky, Michael Eickenberg, Edouard Oyallon", "title": "Decoupled Greedy Learning of CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly cited inefficiency of neural network training by back-propagation\nis the update locking problem: each layer must wait for the signal to propagate\nthrough the full network before updating. Several alternatives that can\nalleviate this issue have been proposed. In this context, we consider a\nsimpler, but more effective, substitute that uses minimal feedback, which we\ncall Decoupled Greedy Learning (DGL). It is based on a greedy relaxation of the\njoint training objective, recently shown to be effective in the context of\nConvolutional Neural Networks (CNNs) on large-scale image classification. We\nconsider an optimization of this objective that permits us to decouple the\nlayer training, allowing for layers or modules in networks to be trained with a\npotentially linear parallelization in layers. With the use of a replay buffer\nwe show this approach can be extended to asynchronous settings, where modules\ncan operate with possibly large communication delays. We show theoretically and\nempirically that this approach converges. Then, we empirically find that it can\nlead to better generalization than sequential greedy optimization. We\ndemonstrate the effectiveness of DGL against alternative approaches on the\nCIFAR-10 dataset and on the large-scale ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:20:44 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 22:54:33 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 14:49:17 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 19:19:32 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Belilovsky", "Eugene", ""], ["Eickenberg", "Michael", ""], ["Oyallon", "Edouard", ""]]}, {"id": "1901.08168", "submitter": "Daniel Kunin", "authors": "Daniel Kunin, Jonathan M. Bloom, Aleksandrina Goeva, Cotton Seed", "title": "Loss Landscapes of Regularized Linear Autoencoders", "comments": "12 pages, 8 figures. ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are a deep learning model for representation learning. When\ntrained to minimize the distance between the data and its reconstruction,\nlinear autoencoders (LAEs) learn the subspace spanned by the top principal\ndirections but cannot learn the principal directions themselves. In this paper,\nwe prove that $L_2$-regularized LAEs are symmetric at all critical points and\nlearn the principal directions as the left singular vectors of the decoder. We\nsmoothly parameterize the critical manifold and relate the minima to the MAP\nestimate of probabilistic PCA. We illustrate these results empirically and\nconsider implications for PCA algorithms, computational neuroscience, and the\nalgebraic topology of learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:38:04 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 05:34:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Kunin", "Daniel", ""], ["Bloom", "Jonathan M.", ""], ["Goeva", "Aleksandrina", ""], ["Seed", "Cotton", ""]]}, {"id": "1901.08170", "submitter": "Adil Salim", "authors": "Pascal Bianchi, Walid Hachem and Adil Salim", "title": "A Fully Stochastic Primal-Dual Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new stochastic primal--dual algorithm for solving a composite optimization\nproblem is proposed. It is assumed that all the functions/operators that enter\nthe optimization problem are given as statistical expectations. These\nexpectations are unknown but revealed across time through i.i.d. realizations.\nThe proposed algorithm is proven to converge to a saddle point of the\nLagrangian function. In the framework of the monotone operator theory, the\nconvergence proof relies on recent results on the stochastic Forward Backward\nalgorithm involving random monotone operators. An example of convex\noptimization under stochastic linear constraints is considered.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:40:58 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 10:33:32 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 14:39:47 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 14:51:08 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bianchi", "Pascal", ""], ["Hachem", "Walid", ""], ["Salim", "Adil", ""]]}, {"id": "1901.08177", "submitter": "Matt Amodio", "authors": "Matthew Amodio, Smita Krishnaswamy", "title": "Generating and Aligning from Data Geometries with Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain mapping has attracted substantial attention in recent\nyears due to the success of models based on the cycle-consistency assumption.\nThese models map between two domains by fooling a probabilistic discriminator,\nthereby matching the probability distributions of the real and generated data.\nInstead of this probabilistic approach, we cast the problem in terms of\naligning the geometry of the manifolds of the two domains. We introduce the\nManifold Geometry Matching Generative Adversarial Network (MGM GAN), which adds\ntwo novel mechanisms to facilitate GANs sampling from the geometry of the\nmanifold rather than the density and then aligning two manifold geometries: (1)\nan importance sampling technique that reweights points based on their density\non the manifold, making the discriminator only able to discern geometry and (2)\na penalty adapted from traditional manifold alignment literature that\nexplicitly enforces the geometry to be preserved. The MGM GAN leverages the\nmanifolds arising from a pre-trained autoencoder to bridge the gap between\nformal manifold alignment literature and existing GAN work, and demonstrate the\nadvantages of modeling the manifold geometry over its density.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 00:13:22 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Amodio", "Matthew", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1901.08201", "submitter": "William Caicedo-Torres", "authors": "William Caicedo-Torres and Jairo Gutierrez", "title": "ISeeU: Visually interpretable deep learning for mortality prediction\n  inside the ICU", "comments": null, "journal-ref": "Journal of Biomedical Informatics, 98, 103269 (2019)", "doi": "10.1016/j.jbi.2019.103269", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the performance of Intensive Care Units (ICUs), the field of\nbio-statistics has developed scores which try to predict the likelihood of\nnegative outcomes. These help evaluate the effectiveness of treatments and\nclinical practice, and also help to identify patients with unexpected outcomes.\nHowever, they have been shown by several studies to offer sub-optimal\nperformance. Alternatively, Deep Learning offers state of the art capabilities\nin certain prediction tasks and research suggests deep neural networks are able\nto outperform traditional techniques. Nevertheless, a main impediment for the\nadoption of Deep Learning in healthcare is its reduced interpretability, for in\nthis field it is crucial to gain insight on the why of predictions, to assure\nthat models are actually learning relevant features instead of spurious\ncorrelations. To address this, we propose a deep multi-scale convolutional\narchitecture trained on the Medical Information Mart for Intensive Care III\n(MIMIC-III) for mortality prediction, and the use of concepts from coalitional\ngame theory to construct visual explanations aimed to show how important these\ninputs are deemed by the network. Our results show our model attains state of\nthe art performance while remaining interpretable. Supporting code can be found\nat https://github.com/williamcaicedo/ISeeU.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 02:32:46 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Caicedo-Torres", "William", ""], ["Gutierrez", "Jairo", ""]]}, {"id": "1901.08227", "submitter": "Jianqiao Wangni", "authors": "Jianqiao Wangni, Ke Li, Jianbo Shi, Jitendra Malik", "title": "Trajectory Normalized Gradients for Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers proposed various low-precision gradient compression,\nfor efficient communication in large-scale distributed optimization. Based on\nthese work, we try to reduce the communication complexity from a new direction.\nWe pursue an ideal bijective mapping between two spaces of gradient\ndistribution, so that the mapped gradient carries greater information entropy\nafter the compression. In our setting, all servers should share a reference\ngradient in advance, and they communicate via the normalized gradients, which\nare the subtraction or quotient, between current gradients and the reference.\nTo obtain a reference vector that yields a stronger signal-to-noise ratio,\ndynamically in each iteration, we extract and fuse information from the past\ntrajectory in hindsight, and search for an optimal reference for compression.\nWe name this to be the trajectory-based normalized gradients (TNG). It bridges\nthe research from different societies, like coding, optimization, systems, and\nlearning. It is easy to implement and can universally combine with existing\nalgorithms. Our experiments on benchmarking hard non-convex functions, convex\nproblems like logistic regression demonstrate that TNG is more\ncompression-efficient for communication of distributed optimization of general\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 04:24:31 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Wangni", "Jianqiao", ""], ["Li", "Ke", ""], ["Shi", "Jianbo", ""], ["Malik", "Jitendra", ""]]}, {"id": "1901.08237", "submitter": "Liu Liu", "authors": "Liu Liu, Tianyang Li, Constantine Caramanis", "title": "High Dimensional Robust $M$-Estimation: Arbitrary Corruption and Heavy\n  Tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparsity-constrained $M$-estimation when both\nexplanatory and response variables have heavy tails (bounded 4-th moments), or\na fraction of arbitrary corruptions. We focus on the $k$-sparse,\nhigh-dimensional regime where the number of variables $d$ and the sample size\n$n$ are related through $n \\sim k \\log d$. We define a natural condition we\ncall the Robust Descent Condition (RDC), and show that if a gradient estimator\nsatisfies the RDC, then Robust Hard Thresholding (IHT using this gradient\nestimator), is guaranteed to obtain good statistical rates. The contribution of\nthis paper is in showing that this RDC is a flexible enough concept to recover\nknown results, and obtain new robustness results. Specifically, new results\ninclude: (a) For $k$-sparse high-dimensional linear- and logistic-regression\nwith heavy tail (bounded 4-th moment) explanatory and response variables, a\nlinear-time-computable median-of-means gradient estimator satisfies the RDC,\nand hence Robust Hard Thresholding is minimax optimal; (b) When instead of\nheavy tails we have $O(1/\\sqrt{k}\\log(nd))$-fraction of arbitrary corruptions\nin explanatory and response variables, a near linear-time computable trimmed\ngradient estimator satisfies the RDC, and hence Robust Hard Thresholding is\nminimax optimal. We demonstrate the effectiveness of our approach in sparse\nlinear, logistic regression, and sparse precision matrix estimation on\nsynthetic and real-world US equities data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 05:20:29 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 19:02:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Liu", ""], ["Li", "Tianyang", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1901.08241", "submitter": "Jyoti Prakash Singh", "authors": "Abhinav Kumar and Jyoti Prakash Singh", "title": "Location reference identification from tweets during emergencies: A deep\n  learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Twitter is recently being used during crises to communicate with officials\nand provide rescue and relief operation in real time. The geographical location\ninformation of the event, as well as users, are vitally important in such\nscenarios. The identification of geographic location is one of the challenging\ntasks as the location information fields, such as user location and place name\nof tweets are not reliable. The extraction of location information from tweet\ntext is difficult as it contains a lot of non-standard English, grammatical\nerrors, spelling mistakes, non-standard abbreviations, and so on. This research\naims to extract location words used in the tweet using a Convolutional Neural\nNetwork (CNN) based model. We achieved the exact matching score of 0.929,\nHamming loss of 0.002, and $F_1$-score of 0.96 for the tweets related to the\nearthquake. Our model was able to extract even three- to four-word long\nlocation references which is also evident from the exact matching score of over\n92\\%. The findings of this paper can help in early event localization,\nemergency situations, real-time road traffic management, localized\nadvertisement, and in various location-based services.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 05:54:13 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Kumar", "Abhinav", ""], ["Singh", "Jyoti Prakash", ""]]}, {"id": "1901.08244", "submitter": "Vardan Papyan", "authors": "Vardan Papyan", "title": "Measurements of Three-Level Hierarchical Structure in the Outliers in\n  the Spectrum of Deepnet Hessians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep classifying neural networks. We expose a structure in the\nderivative of the logits with respect to the parameters of the model, which is\nused to explain the existence of outliers in the spectrum of the Hessian.\nPrevious works decomposed the Hessian into two components, attributing the\noutliers to one of them, the so-called Covariance of gradients. We show this\nterm is not a Covariance but a second moment matrix, i.e., it is influenced by\nmeans of gradients. These means possess an additive two-way structure that is\nthe source of the outliers in the spectrum. This structure can be used to\napproximate the principal subspace of the Hessian using certain \"averaging\"\noperations, avoiding the need for high-dimensional eigenanalysis. We\ncorroborate this claim across different datasets, architectures and sample\nsizes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 06:02:40 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Papyan", "Vardan", ""]]}, {"id": "1901.08247", "submitter": "Shen Zhang", "authors": "Shen Zhang, Shibo Zhang, Bingnan Wang, Thomas G. Habetler", "title": "Machine Learning and Deep Learning Algorithms for Bearing Fault\n  Diagnostics -- A Comprehensive Review", "comments": null, "journal-ref": "IEEE Access 8(2020) 29857 - 29881", "doi": "10.1109/ACCESS.2020.2972859", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey paper, we systematically summarize existing literature on\nbearing fault diagnostics with machine learning (ML) and data mining\ntechniques. While conventional ML methods, including artificial neural network\n(ANN), principal component analysis (PCA), support vector machines (SVM), etc.,\nhave been successfully applied to the detection and categorization of bearing\nfaults for decades, recent developments in deep learning (DL) algorithms in the\nlast five years have sparked renewed interest in both industry and academia for\nintelligent machine health monitoring. In this paper, we first provide a brief\nreview of conventional ML methods, before taking a deep dive into the\nstate-of-the-art DL algorithms for bearing fault applications. Specifically,\nthe superiority of DL based methods over conventional ML methods are analyzed\nin terms of fault feature extraction and classification performances; many new\nfunctionalities enabled by DL techniques are also summarized. In addition, to\nobtain a more intuitive insight, a comparative study is conducted on the\nclassification accuracy of different algorithms utilizing the open-source Case\nWestern Reserve University (CWRU) bearing dataset. Finally, to facilitate the\ntransition on applying various DL algorithms to bearing fault diagnostics,\ndetailed recommendations and suggestions are provided for specific application\nconditions such as the setup environment, the data size, and the number of\nsensors and sensor types. Future research directions to further enhance the\nperformance of DL algorithms on health monitoring are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 06:21:03 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 04:22:00 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 20:25:25 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Shen", ""], ["Zhang", "Shibo", ""], ["Wang", "Bingnan", ""], ["Habetler", "Thomas G.", ""]]}, {"id": "1901.08255", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Prateek Yadav, Manik Bhandari, Partha Talukdar", "title": "Confidence-based Graph Convolutional Networks for Semi-Supervised\n  Learning", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting properties of nodes in a graph is an important problem with\napplications in a variety of domains. Graph-based Semi-Supervised Learning\n(SSL) methods aim to address this problem by labeling a small subset of the\nnodes as seeds and then utilizing the graph structure to predict label scores\nfor the rest of the nodes in the graph. Recently, Graph Convolutional Networks\n(GCNs) have achieved impressive performance on the graph-based SSL task. In\naddition to label scores, it is also desirable to have confidence scores\nassociated with them. Unfortunately, confidence estimation in the context of\nGCN has not been previously explored. We fill this important gap in this paper\nand propose ConfGCN, which estimates labels scores along with their confidences\njointly in GCN-based setting. ConfGCN uses these estimated confidences to\ndetermine the influence of one node on another during neighborhood aggregation,\nthereby acquiring anisotropic capabilities. Through extensive analysis and\nexperiments on standard benchmarks, we find that ConfGCN is able to outperform\nstate-of-the-art baselines. We have made ConfGCN's source code available to\nencourage reproducible research.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 06:59:05 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 04:16:31 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Yadav", "Prateek", ""], ["Bhandari", "Manik", ""], ["Talukdar", "Partha", ""]]}, {"id": "1901.08256", "submitter": "Yang You", "authors": "Yang You, Jonathan Hseu, Chris Ying, James Demmel, Kurt Keutzer,\n  Cho-Jui Hsieh", "title": "Large-Batch Training for LSTM and Beyond", "comments": "Preprint. Work in progress. We may update this draft recently", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-batch training approaches have enabled researchers to utilize\nlarge-scale distributed processing and greatly accelerate deep-neural net (DNN)\ntraining. For example, by scaling the batch size from 256 to 32K, researchers\nhave been able to reduce the training time of ResNet50 on ImageNet from 29\nhours to 2.2 minutes (Ying et al., 2018). In this paper, we propose a new\napproach called linear-epoch gradual-warmup (LEGW) for better large-batch\ntraining. With LEGW, we are able to conduct large-batch training for both CNNs\nand RNNs with the Sqrt Scaling scheme. LEGW enables Sqrt Scaling scheme to be\nuseful in practice and as a result we achieve much better results than the\nLinear Scaling learning rate scheme. For LSTM applications, we are able to\nscale the batch size by a factor of 64 without losing accuracy and without\ntuning the hyper-parameters. For CNN applications, LEGW is able to achieve the\nsame accuracy even as we scale the batch size to 32K. LEGW works better than\nprevious large-batch auto-tuning techniques. LEGW achieves a 5.3X average\nspeedup over the baselines for four LSTM-based applications on the same\nhardware. We also provide some theoretical explanations for LEGW.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 07:10:33 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["You", "Yang", ""], ["Hseu", "Jonathan", ""], ["Ying", "Chris", ""], ["Demmel", "James", ""], ["Keutzer", "Kurt", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1901.08275", "submitter": "Masayuki Karasuyama", "authors": "Shion Takeno, Hitoshi Fukuoka, Yuhki Tsukada, Toshiyuki Koyama, Motoki\n  Shiga, Ichiro Takeuchi, and Masayuki Karasuyama", "title": "Multi-fidelity Bayesian Optimization with Max-value Entropy Search and\n  its parallelization", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a standard setting of Bayesian optimization (BO), the objective function\nevaluation is assumed to be highly expensive. Multi-fidelity Bayesian\noptimization (MFBO) accelerates BO by incorporating lower fidelity observations\navailable with a lower sampling cost. In this paper, we focus on the\ninformation-based approach, which is a popular and empirically successful\napproach in BO. For MFBO, however, existing information-based methods are\nplagued by difficulty in estimating the information gain. We propose an\napproach based on max-value entropy search (MES), which greatly facilitates\ncomputations by considering the entropy of the optimal function value instead\nof the optimal input point. We show that, in our multi-fidelity MES (MF-MES),\nmost of additional computations, compared with usual MES, is reduced to\nanalytical computations. Although an additional numerical integration is\nnecessary for the information across different fidelities, this is only in one\ndimensional space, which can be performed efficiently and accurately. Further,\nwe also propose parallelization of MF-MES. Since there exist a variety of\ndifferent sampling costs, queries typically occur asynchronously in MFBO. We\nshow that similar simple computations can be derived for asynchronous parallel\nMFBO. We demonstrate effectiveness of our approach by using benchmark datasets\nand a real-world application to materials science data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:20:21 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 03:16:57 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Takeno", "Shion", ""], ["Fukuoka", "Hitoshi", ""], ["Tsukada", "Yuhki", ""], ["Koyama", "Toshiyuki", ""], ["Shiga", "Motoki", ""], ["Takeuchi", "Ichiro", ""], ["Karasuyama", "Masayuki", ""]]}, {"id": "1901.08276", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Traditional and Heavy-Tailed Self Regularization in Neural Network\n  Models", "comments": "Very abridged version of arXiv:1810.01075", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Matrix Theory (RMT) is applied to analyze the weight matrices of Deep\nNeural Networks (DNNs), including both production quality, pre-trained models\nsuch as AlexNet and Inception, and smaller models trained from scratch, such as\nLeNet5 and a miniature-AlexNet. Empirical and theoretical results clearly\nindicate that the empirical spectral density (ESD) of DNN layer matrices\ndisplays signatures of traditionally-regularized statistical models, even in\nthe absence of exogenously specifying traditional forms of regularization, such\nas Dropout or Weight Norm constraints. Building on recent results in RMT, most\nnotably its extension to Universality classes of Heavy-Tailed matrices, we\ndevelop a theory to identify \\emph{5+1 Phases of Training}, corresponding to\nincreasing amounts of \\emph{Implicit Self-Regularization}. For smaller and/or\nolder DNNs, this Implicit Self-Regularization is like traditional Tikhonov\nregularization, in that there is a `size scale' separating signal from noise.\nFor state-of-the-art DNNs, however, we identify a novel form of\n\\emph{Heavy-Tailed Self-Regularization}, similar to the self-organization seen\nin the statistical physics of disordered systems. This implicit\nSelf-Regularization can depend strongly on the many knobs of the training\nprocess. By exploiting the generalization gap phenomena, we demonstrate that we\ncan cause a small model to exhibit all 5+1 phases of training simply by\nchanging the batch size.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:20:42 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1901.08278", "submitter": "Michael Mahoney", "authors": "Charles H. Martin and Michael W. Mahoney", "title": "Heavy-Tailed Universality Predicts Trends in Test Accuracies for Very\n  Large Pre-Trained Deep Neural Networks", "comments": "Updated as will appear in SDM20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two or more Deep Neural Networks (DNNs) with the same or similar\narchitectures, and trained on the same dataset, but trained with different\nsolvers, parameters, hyper-parameters, regularization, etc., can we predict\nwhich DNN will have the best test accuracy, and can we do so without peeking at\nthe test data? In this paper, we show how to use a new Theory of Heavy-Tailed\nSelf-Regularization (HT-SR) to answer this. HT-SR suggests, among other things,\nthat modern DNNs exhibit what we call Heavy-Tailed Mechanistic Universality\n(HT-MU), meaning that the correlations in the layer weight matrices can be fit\nto a power law (PL) with exponents that lie in common Universality classes from\nHeavy-Tailed Random Matrix Theory (HT-RMT). From this, we develop a Universal\ncapacity control metric that is a weighted average of PL exponents. Rather than\nconsidering small toy NNs, we examine over 50 different, large-scale\npre-trained DNNs, ranging over 15 different architectures, trained on\nImagetNet, each of which has been reported to have different test accuracies.\nWe show that this new capacity metric correlates very well with the reported\ntest accuracies of these DNNs, looking across each architecture\n(VGG16/.../VGG19, ResNet10/.../ResNet152, etc.). We also show how to\napproximate the metric by the more familiar Product Norm capacity measure, as\nthe average of the log Frobenius norm of the layer weight matrices. Our\napproach requires no changes to the underlying DNN or its loss function, it\ndoes not require us to train a model (although it could be used to monitor\ntraining), and it does not even require access to the ImageNet data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:27:03 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 05:24:40 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Martin", "Charles H.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1901.08280", "submitter": "Nikolaos Passalis", "authors": "Nikolaos Passalis, Anastasios Tefas, Juho Kanniainen, Moncef Gabbouj,\n  Alexandros Iosifidis", "title": "Temporal Logistic Neural Bag-of-Features for Financial Time series\n  Forecasting leveraging Limit Order Book Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is a crucial component of many important\napplications, ranging from forecasting the stock markets to energy load\nprediction. The high-dimensionality, velocity and variety of the data collected\nin these applications pose significant and unique challenges that must be\ncarefully addressed for each of them. In this work, a novel Temporal Logistic\nNeural Bag-of-Features approach, that can be used to tackle these challenges,\nis proposed. The proposed method can be effectively combined with deep neural\nnetworks, leading to powerful deep learning models for time series analysis.\nHowever, combining existing BoF formulations with deep feature extractors pose\nsignificant challenges: the distribution of the input features is not\nstationary, tuning the hyper-parameters of the model can be especially\ndifficult and the normalizations involved in the BoF model can cause\nsignificant instabilities during the training process. The proposed method is\ncapable of overcoming these limitations by a employing a novel adaptive scaling\nmechanism and replacing the classical Gaussian-based density estimation\ninvolved in the regular BoF model with a logistic kernel. The effectiveness of\nthe proposed approach is demonstrated using extensive experiments on a\nlarge-scale financial time series dataset that consists of more than 4 million\nlimit orders.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:30:16 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1901.08291", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi, Satoshi Hara, Takanori Maehara", "title": "Faking Fairness via Stealthily Biased Sampling", "comments": "Accepted at the Special Track on AI for Social Impact (AISI) at\n  AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auditing fairness of decision-makers is now in high demand. To respond to\nthis social demand, several fairness auditing tools have been developed. The\nfocus of this study is to raise an awareness of the risk of malicious\ndecision-makers who fake fairness by abusing the auditing tools and thereby\ndeceiving the social communities. The question is whether such a fraud of the\ndecision-maker is detectable so that the society can avoid the risk of fake\nfairness. In this study, we answer this question negatively. We specifically\nput our focus on a situation where the decision-maker publishes a benchmark\ndataset as the evidence of his/her fairness and attempts to deceive a person\nwho uses an auditing tool that computes a fairness metric. To assess the\n(un)detectability of the fraud, we explicitly construct an algorithm, the\nstealthily biased sampling, that can deliberately construct an evil benchmark\ndataset via subsampling. We show that the fraud made by the stealthily based\nsampling is indeed difficult to detect both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:59:32 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 10:48:53 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Hara", "Satoshi", ""], ["Maehara", "Takanori", ""]]}, {"id": "1901.08296", "submitter": "Martin Simonovsky", "authors": "Martin Simonovsky", "title": "Deep Learning on Attributed Graphs: A Journey from Graphs to Their\n  Embeddings and Back", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is a powerful concept for representation of relations between pairs\nof entities. Data with underlying graph structure can be found across many\ndisciplines and there is a natural desire for understanding such data better.\nDeep learning (DL) has achieved significant breakthroughs in a variety of\nmachine learning tasks in recent years, especially where data is structured on\na grid, such as in text, speech, or image understanding. However, surprisingly\nlittle has been done to explore the applicability of DL on arbitrary\ngraph-structured data directly.\n  The goal of this thesis is to investigate architectures for DL on graphs and\nstudy how to transfer, adapt or generalize concepts that work well on\nsequential and image data to this domain. We concentrate on two important\nprimitives: embedding graphs or their nodes into a continuous vector space\nrepresentation (encoding) and, conversely, generating graphs from such vectors\nback (decoding). To that end, we make the following contributions.\n  First, we introduce Edge-Conditioned Convolutions (ECC), a convolution-like\noperation on graphs performed in the spatial domain where filters are\ndynamically generated based on edge attributes. The method is used to encode\ngraphs with arbitrary and varying structure.\n  Second, we propose SuperPoint Graph, an intermediate point cloud\nrepresentation with rich edge attributes encoding the contextual relationship\nbetween object parts. Based on this representation, ECC is employed to segment\nlarge-scale point clouds without major sacrifice in fine details.\n  Third, we present GraphVAE, a graph generator allowing us to decode graphs\nwith variable but upper-bounded number of nodes making use of approximate graph\nmatching for aligning the predictions of an autoencoder with its inputs. The\nmethod is applied to the task of molecule generation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 09:12:33 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Simonovsky", "Martin", ""]]}, {"id": "1901.08334", "submitter": "Anastasia Podosinnikova", "authors": "Anastasia Podosinnikova, Amelia Perry, Alexander Wein, Francis Bach,\n  Alexandre d'Aspremont, David Sontag", "title": "Overcomplete Independent Component Analysis via SDP", "comments": "Appears in: Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2019). 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm for overcomplete independent components analysis\n(ICA), where the number of latent sources k exceeds the dimension p of observed\nvariables. Previous algorithms either suffer from high computational complexity\nor make strong assumptions about the form of the mixing matrix. Our algorithm\ndoes not make any sparsity assumption yet enjoys favorable computational and\ntheoretical properties. Our algorithm consists of two main steps: (a)\nestimation of the Hessians of the cumulant generating function (as opposed to\nthe fourth and higher order cumulants used by most algorithms) and (b) a novel\nsemi-definite programming (SDP) relaxation for recovering a mixing component.\nWe show that this relaxation can be efficiently solved with a projected\naccelerated gradient descent method, which makes the whole algorithm\ncomputationally practical. Moreover, we conjecture that the proposed program\nrecovers a mixing component at the rate k < p^2/4 and prove that a mixing\ncomponent can be recovered with high probability when k < (2 - epsilon) p log p\nwhen the original components are sampled uniformly at random on the hyper\nsphere. Experiments are provided on synthetic data and the CIFAR-10 dataset of\nreal images.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 10:38:11 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Podosinnikova", "Anastasia", ""], ["Perry", "Amelia", ""], ["Wein", "Alexander", ""], ["Bach", "Francis", ""], ["d'Aspremont", "Alexandre", ""], ["Sontag", "David", ""]]}, {"id": "1901.08350", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Seungjin Choi", "title": "On Local Optimizers of Acquisition Functions in Bayesian Optimization", "comments": "16 pages, 3 figures, 1 table. Accepted at the European Conference on\n  Machine Learning and Principles and Practice of Knowledge Discovery in\n  Databases (ECML-PKDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a sample-efficient method for finding a global\noptimum of an expensive-to-evaluate black-box function. A global solution is\nfound by accumulating a pair of query point and its function value, repeating\nthese two procedures: (i) modeling a surrogate function; (ii) maximizing an\nacquisition function to determine where next to query. Convergence guarantees\nare only valid when the global optimizer of the acquisition function is found\nat each round and selected as the next query point. In practice, however, local\noptimizers of an acquisition function are also used, since searching for the\nglobal optimizer is often a non-trivial or time-consuming task. In this paper\nwe consider three popular acquisition functions, PI, EI, and GP-UCB induced by\nGaussian process regression. Then we present a performance analysis on the\nbehavior of local optimizers of those acquisition functions, in terms of {\\em\ninstantaneous regrets} over global optimizers. We also introduce an analysis,\nallowing a local optimization method to start from multiple different initial\nconditions. Numerical experiments confirm the validity of our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 11:11:11 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 04:14:47 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 00:40:25 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 02:48:04 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kim", "Jungtaek", ""], ["Choi", "Seungjin", ""]]}, {"id": "1901.08360", "submitter": "Kamil Nar", "authors": "Kamil Nar, Orhan Ocal, S. Shankar Sastry, Kannan Ramchandran", "title": "Cross-Entropy Loss and Low-Rank Features Have Responsibility for\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural networks are vulnerable to adversarial examples; they\ncan easily misclassify inputs that are imperceptibly different than their\ntraining and test data. In this work, we establish that the use of\ncross-entropy loss function and the low-rank features of the training data have\nresponsibility for the existence of these inputs. Based on this observation, we\nsuggest that addressing adversarial examples requires rethinking the use of\ncross-entropy loss function and looking for an alternative that is more suited\nfor minimization with low-rank features. In this direction, we present a\ntraining scheme called differential training, which uses a loss function\ndefined on the differences between the features of points from opposite\nclasses. We show that differential training can ensure a large margin between\nthe decision boundary of the neural network and the points in the training\ndataset. This larger margin increases the amount of perturbation needed to flip\nthe prediction of the classifier and makes it harder to find an adversarial\nexample with small perturbations. We test differential training on a binary\nclassification task with CIFAR-10 dataset and demonstrate that it radically\nreduces the ratio of images for which an adversarial example could be found --\nnot only in the training dataset, but in the test dataset as well.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 11:29:51 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Nar", "Kamil", ""], ["Ocal", "Orhan", ""], ["Sastry", "S. Shankar", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1901.08361", "submitter": "Tianyu Cui", "authors": "Tianyu Cui, Pekka Marttinen, Samuel Kaski", "title": "Learning Global Pairwise Interactions with Bayesian Neural Networks", "comments": "8 pages", "journal-ref": "Proceedings of the 24th European Conference on Artificial\n  Intelligence (ECAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating global pairwise interaction effects, i.e., the difference between\nthe joint effect and the sum of marginal effects of two input features, with\nuncertainty properly quantified, is centrally important in science\napplications. We propose a non-parametric probabilistic method for detecting\ninteraction effects of unknown form. First, the relationship between the\nfeatures and the output is modelled using a Bayesian neural network, capable of\nrepresenting complex interactions and principled uncertainty. Second,\ninteraction effects and their uncertainty are estimated from the trained model.\nFor the second step, we propose an intuitive global interaction measure:\nBayesian Group Expected Hessian (GEH), which aggregates information of local\ninteractions as captured by the Hessian. GEH provides a natural trade-off\nbetween type I and type II error and, moreover, comes with theoretical\nguarantees ensuring that the estimated interaction effects and their\nuncertainty can be improved by training a more accurate BNN. The method\nempirically outperforms available non-probabilistic alternatives on simulated\nand real-world data. Finally, we demonstrate its ability to detect\ninterpretable interactions between higher-level features (at deeper layers of\nthe neural network).\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 11:30:00 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 17:35:21 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 15:26:54 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Cui", "Tianyu", ""], ["Marttinen", "Pekka", ""], ["Kaski", "Samuel", ""]]}, {"id": "1901.08386", "submitter": "Arghya Roy Chaudhuri", "authors": "Arghya Roy Chaudhuri, Shivaram Kalyanakrishnan", "title": "PAC Identification of Many Good Arms in Stochastic Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of identifying any $k$ out of the best $m$ arms in an\n$n$-armed stochastic multi-armed bandit. Framed in the PAC setting, this\nparticular problem generalises both the problem of `best subset selection' and\nthat of selecting `one out of the best m' arms [arcsk 2017]. In applications\nsuch as crowd-sourcing and drug-designing, identifying a single good solution\nis often not sufficient. Moreover, finding the best subset might be hard due to\nthe presence of many indistinguishably close solutions. Our generalisation of\nidentifying exactly $k$ arms out of the best $m$, where $1 \\leq k \\leq m$,\nserves as a more effective alternative. We present a lower bound on the\nworst-case sample complexity for general $k$, and a fully sequential PAC\nalgorithm, \\GLUCB, which is more sample-efficient on easy instances. Also,\nextending our analysis to infinite-armed bandits, we present a PAC algorithm\nthat is independent of $n$, which identifies an arm from the best $\\rho$\nfraction of arms using at most an additive poly-log number of samples than\ncompared to the lower bound, thereby improving over [arcsk 2017] and\n[Aziz+AKA:2018]. The problem of identifying $k > 1$ distinct arms from the best\n$\\rho$ fraction is not always well-defined; for a special class of this\nproblem, we present lower and upper bounds. Finally, through a reduction, we\nestablish a relation between upper bounds for the `one out of the best $\\rho$'\nproblem for infinite instances and the `one out of the best $m$' problem for\nfinite instances. We conjecture that it is more efficient to solve `small'\nfinite instances using the latter formulation, rather than going through the\nformer.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 12:56:33 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Chaudhuri", "Arghya Roy", ""], ["Kalyanakrishnan", "Shivaram", ""]]}, {"id": "1901.08394", "submitter": "Robin Chan", "authors": "Robin Chan, Matthias Rottmann, Fabian H\\\"uger, Peter Schlicht, Hanno\n  Gottschalk", "title": "Application of Decision Rules for Handling Class Imbalance in Semantic\n  Segmentation", "comments": "11 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of autonomous car driving systems, semantic segmentation is an\nessential component to obtain a full understanding of the car's environment.\nOne difficulty, that occurs while training neural networks for this purpose, is\nclass imbalance of training data. Consequently, a neural network trained on\nunbalanced data in combination with maximum a-posteriori classification may\neasily ignore classes that are rare in terms of their frequency in the dataset.\nHowever, these classes are often of highest interest. We approach such\npotential misclassifications by weighting the posterior class probabilities\nwith the prior class probabilities which in our case are the inverse\nfrequencies of the corresponding classes in the training dataset. More\nprecisely, we adopt a localized method by computing the priors pixel-wise such\nthat the impact can be analyzed at pixel level as well. In our experiments, we\ntrain one network from scratch using a proprietary dataset containing 20,000\nannotated frames of video sequences recorded from street scenes. The evaluation\non our test set shows an increase of average recall with regard to instances of\npedestrians and info signs by $25\\%$ and $23.4\\%$, respectively. In addition,\nwe significantly reduce the non-detection rate for instances of the same\nclasses by $61\\%$ and $38\\%$.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 13:20:25 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Chan", "Robin", ""], ["Rottmann", "Matthias", ""], ["H\u00fcger", "Fabian", ""], ["Schlicht", "Peter", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1901.08396", "submitter": "Bjarne Sievers", "authors": "Jonathan Sauder and Bjarne Sievers", "title": "Self-Supervised Deep Learning on Point Clouds by Reconstructing Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds provide a flexible and natural representation usable in\ncountless applications such as robotics or self-driving cars. Recently, deep\nneural networks operating on raw point cloud data have shown promising results\non supervised learning tasks such as object classification and semantic\nsegmentation. While massive point cloud datasets can be captured using modern\nscanning technology, manually labelling such large 3D point clouds for\nsupervised learning tasks is a cumbersome process. This necessitates methods\nthat can learn from unlabelled data to significantly reduce the number of\nannotated samples needed in supervised learning. We propose a self-supervised\nlearning task for deep learning on raw point cloud data in which a neural\nnetwork is trained to reconstruct point clouds whose parts have been randomly\nrearranged. While solving this task, representations that capture semantic\nproperties of the point cloud are learned. Our method is agnostic of network\narchitecture and outperforms current unsupervised learning approaches in\ndownstream object classification tasks. We show experimentally, that\npre-training with our method before supervised training improves the\nperformance of state-of-the-art models and significantly improves sample\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 13:30:19 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 20:06:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sauder", "Jonathan", ""], ["Sievers", "Bjarne", ""]]}, {"id": "1901.08400", "submitter": "Chongxuan Li", "authors": "Chongxuan Li, Chao Du, Kun Xu, Max Welling, Jun Zhu and Bo Zhang", "title": "To Relieve Your Headache of Training an MRF, Take AdVIL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a black-box algorithm called {\\it Adversarial Variational\nInference and Learning} (AdVIL) to perform inference and learning on a general\nMarkov random field (MRF). AdVIL employs two variational distributions to\napproximately infer the latent variables and estimate the partition function of\nan MRF, respectively. The two variational distributions provide an estimate of\nthe negative log-likelihood of the MRF as a minimax optimization problem, which\nis solved by stochastic gradient descent. AdVIL is proven convergent under\ncertain conditions. On one hand, compared with contrastive divergence, AdVIL\nrequires a minimal assumption about the model structure and can deal with a\nbroader family of MRFs. On the other hand, compared with existing black-box\nmethods, AdVIL provides a tighter estimate of the log partition function and\nachieves much better empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 13:39:57 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 07:56:14 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 02:27:49 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Li", "Chongxuan", ""], ["Du", "Chao", ""], ["Xu", "Kun", ""], ["Welling", "Max", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1901.08428", "submitter": "Mario Lezcano-Casado", "authors": "Mario Lezcano-Casado, David Mart\\'inez-Rubio", "title": "Cheap Orthogonal Constraints in Neural Networks: A Simple\n  Parametrization of the Orthogonal and Unitary Group", "comments": null, "journal-ref": null, "doi": null, "report-no": "PMLR 97:3794-3803", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel approach to perform first-order optimization with\northogonal and unitary constraints. This approach is based on a parametrization\nstemming from Lie group theory through the exponential map. The parametrization\ntransforms the constrained optimization problem into an unconstrained one over\na Euclidean space, for which common first-order optimization methods can be\nused. The theoretical results presented are general enough to cover the special\northogonal group, the unitary group and, in general, any connected compact Lie\ngroup. We discuss how this and other parametrizations can be computed\nefficiently through an implementation trick, making numerically complex\nparametrizations usable at a negligible runtime cost in neural networks. In\nparticular, we apply our results to RNNs with orthogonal recurrent weights,\nyielding a new architecture called expRNN. We demonstrate how our method\nconstitutes a more robust approach to optimization with orthogonal constraints,\nshowing faster, accurate, and more stable convergence in several tasks designed\nto test RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 14:31:48 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 16:21:22 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 16:01:01 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lezcano-Casado", "Mario", ""], ["Mart\u00ednez-Rubio", "David", ""]]}, {"id": "1901.08431", "submitter": "Justin Domke", "authors": "Justin Domke", "title": "Provable Smoothness Guarantees for Black-Box Variational Inference", "comments": "International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box variational inference tries to approximate a complex target\ndistribution though a gradient-based optimization of the parameters of a\nsimpler distribution. Provable convergence guarantees require structural\nproperties of the objective. This paper shows that for location-scale family\napproximations, if the target is M-Lipschitz smooth, then so is the objective,\nif the entropy is excluded. The key proof idea is to describe gradients in a\ncertain inner-product space, thus permitting use of Bessel's inequality. This\nresult gives insight into how to parameterize distributions, gives bounds the\nlocation of the optimal parameters, and is a key ingredient for convergence\nguarantees.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 14:39:15 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 01:23:51 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 21:19:12 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:02:13 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Domke", "Justin", ""]]}, {"id": "1901.08433", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "A XGBoost risk model via feature selection and Bayesian hyper-parameter\n  optimization", "comments": "Accepted by International Journal of Database Management Systems\n  (IJDMS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to explore models based on the extreme gradient boosting\n(XGBoost) approach for business risk classification. Feature selection (FS)\nalgorithms and hyper-parameter optimizations are simultaneously considered\nduring model training. The five most commonly used FS methods including weight\nby Gini, weight by Chi-square, hierarchical variable clustering, weight by\ncorrelation, and weight by information are applied to alleviate the effect of\nredundant features. Two hyper-parameter optimization approaches, random search\n(RS) and Bayesian tree-structured Parzen Estimator (TPE), are applied in\nXGBoost. The effect of different FS and hyper-parameter optimization methods on\nthe model performance are investigated by the Wilcoxon Signed Rank Test. The\nperformance of XGBoost is compared to the traditionally utilized logistic\nregression (LR) model in terms of classification accuracy, area under the curve\n(AUC), recall, and F1 score obtained from the 10-fold cross validation. Results\nshow that hierarchical clustering is the optimal FS method for LR while weight\nby Chi-square achieves the best performance in XG-Boost. Both TPE and RS\noptimization in XGBoost outperform LR significantly. TPE optimization shows a\nsuperiority over RS since it results in a significantly higher accuracy and a\nmarginally higher AUC, recall and F1 score. Furthermore, XGBoost with TPE\ntuning shows a lower variability than the RS method. Finally, the ranking of\nfeature importance based on XGBoost enhances the model interpretation.\nTherefore, XGBoost with Bayesian TPE hyper-parameter optimization serves as an\noperative while powerful approach for business risk modeling.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 14:40:33 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "1901.08437", "submitter": "Sohrab Ferdowsi", "authors": "Sohrab Ferdowsi", "title": "Learning to compress and search visual data in large-scale systems", "comments": "PhD thesis dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of high-dimensional and large-scale representation of visual data\nis addressed from an unsupervised learning perspective. The emphasis is put on\ndiscrete representations, where the description length can be measured in bits\nand hence the model capacity can be controlled. The algorithmic infrastructure\nis developed based on the synthesis and analysis prior models whose\nrate-distortion properties, as well as capacity vs. sample complexity\ntrade-offs are carefully optimized. These models are then extended to\nmulti-layers, namely the RRQ and the ML-STC frameworks, where the latter is\nfurther evolved as a powerful deep neural network architecture with fast and\nsample-efficient training and discrete representations. For the developed\nalgorithms, three important applications are developed. First, the problem of\nlarge-scale similarity search in retrieval systems is addressed, where a\ndouble-stage solution is proposed leading to faster query times and shorter\ndatabase storage. Second, the problem of learned image compression is targeted,\nwhere the proposed models can capture more redundancies from the training\nimages than the conventional compression codecs. Finally, the proposed\nalgorithms are used to solve ill-posed inverse problems. In particular, the\nproblems of image denoising and compressive sensing are addressed with\npromising results.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 14:59:42 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Ferdowsi", "Sohrab", ""]]}, {"id": "1901.08460", "submitter": "Valentina Zantedeschi Dr", "authors": "Valentina Zantedeschi, Aur\\'elien Bellet, Marc Tommasi", "title": "Fully Decentralized Joint Learning of Personalized Models and\n  Collaboration Graphs", "comments": "To appear in the proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fully decentralized machine learning scenario where many\nusers with personal datasets collaborate to learn models through local\npeer-to-peer exchanges, without a central coordinator. We propose to train\npersonalized models that leverage a collaboration graph describing the\nrelationships between user personal tasks, which we learn jointly with the\nmodels. Our fully decentralized optimization procedure alternates between\ntraining nonlinear models given the graph in a greedy boosting manner, and\nupdating the collaboration graph (with controlled sparsity) given the models.\nThroughout the process, users exchange messages only with a small number of\npeers (their direct neighbors when updating the models, and a few random users\nwhen updating the graph), ensuring that the procedure naturally scales with the\nnumber of users. Overall, our approach is communication-efficient and avoids\nexchanging personal data. We provide an extensive analysis of the convergence\nrate, memory and communication complexity of our approach, and demonstrate its\nbenefits compared to competing techniques on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 15:44:42 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 13:33:17 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 21:56:19 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 09:34:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""]]}, {"id": "1901.08469", "submitter": "Yuling Jiao", "authors": "Yuan Gao, Yuling Jiao, Yang Wang, Yao Wang, Can Yang, Shunkang Zhang", "title": "Deep Generative Learning via Variational Gradient Flow", "comments": null, "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework to learn deep generative models via\n\\textbf{V}ariational \\textbf{Gr}adient Fl\\textbf{ow} (VGrow) on probability\nspaces. The evolving distribution that asymptotically converges to the target\ndistribution is governed by a vector field, which is the negative gradient of\nthe first variation of the $f$-divergence between them. We prove that the\nevolving distribution coincides with the pushforward distribution through the\ninfinitesimal time composition of residual maps that are perturbations of the\nidentity map along the vector field. The vector field depends on the density\nratio of the pushforward distribution and the target distribution, which can be\nconsistently learned from a binary classification problem. Connections of our\nproposed VGrow method with other popular methods, such as VAE, GAN and\nflow-based methods, have been established in this framework, gaining new\ninsights of deep generative learning. We also evaluated several commonly used\ndivergences, including Kullback-Leibler, Jensen-Shannon, Jeffrey divergences as\nwell as our newly discovered `logD' divergence which serves as the objective\nfunction of the logD-trick GAN. Experimental results on benchmark datasets\ndemonstrate that VGrow can generate high-fidelity images in a stable and\nefficient manner, achieving competitive performance with state-of-the-art GANs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 16:00:51 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 05:07:38 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 07:12:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gao", "Yuan", ""], ["Jiao", "Yuling", ""], ["Wang", "Yang", ""], ["Wang", "Yao", ""], ["Yang", "Can", ""], ["Zhang", "Shunkang", ""]]}, {"id": "1901.08479", "submitter": "Jaehoon Cha", "authors": "Jaehoon Cha, Kyeong Soo Kim, Sanghyuk Lee", "title": "On the Transformation of Latent Space in Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noting the importance of the latent variables in inference and learning, we\npropose a novel framework for autoencoders based on the homeomorphic\ntransformation of latent variables, which could reduce the distance between\nvectors in the transformed space, while preserving the topological properties\nof the original space, and investigate the effect of the latent space\ntransformation on learning generative models and denoising corrupted data. The\nexperimental results demonstrate that our generative and denoising models based\non the proposed framework can provide better performance than conventional\nvariational and denoising autoencoders due to the transformation, where we\nevaluate the performance of generative and denoising models in terms of the\nHausdorff distance between the sets of training and processed i.e., either\ngenerated or denoised images, which can objectively measure their differences,\nas well as through direct comparison of the visual characteristics of the\nprocessed images.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 16:13:24 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:35:57 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cha", "Jaehoon", ""], ["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""]]}, {"id": "1901.08508", "submitter": "Rithesh Kumar", "authors": "Rithesh Kumar, Sherjil Ozair, Anirudh Goyal, Aaron Courville, Yoshua\n  Bengio", "title": "Maximum Entropy Generators for Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maximum likelihood estimation of energy-based models is a challenging problem\ndue to the intractability of the log-likelihood gradient. In this work, we\npropose learning both the energy function and an amortized approximate sampling\nmechanism using a neural generator network, which provides an efficient\napproximation of the log-likelihood gradient. The resulting objective requires\nmaximizing entropy of the generated samples, which we perform using recently\nproposed nonparametric mutual information estimators. Finally, to stabilize the\nresulting adversarial game, we use a zero-centered gradient penalty derived as\na necessary condition from the score matching literature. The proposed\ntechnique can generate sharp images with Inception and FID scores competitive\nwith recent GAN techniques, does not suffer from mode collapse, and is\ncompetitive with state-of-the-art anomaly detection techniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:03:41 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 18:52:19 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kumar", "Rithesh", ""], ["Ozair", "Sherjil", ""], ["Goyal", "Anirudh", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1901.08511", "submitter": "Sarath Pattathil", "authors": "Aryan Mokhtari, Asuman Ozdaglar, Sarath Pattathil", "title": "A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for\n  Saddle Point Problems: Proximal Point Approach", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider solving saddle point problems using two variants of\nGradient Descent-Ascent algorithms, Extra-gradient (EG) and Optimistic Gradient\nDescent Ascent (OGDA) methods. We show that both of these algorithms admit a\nunified analysis as approximations of the classical proximal point method for\nsolving saddle point problems. This viewpoint enables us to develop a new\nframework for analyzing EG and OGDA for bilinear and strongly convex-strongly\nconcave settings. Moreover, we use the proximal point approximation\ninterpretation to generalize the results for OGDA for a wide range of\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:09:10 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 23:21:27 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 04:08:53 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 16:19:23 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""], ["Pattathil", "Sarath", ""]]}, {"id": "1901.08518", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Yiding Liu, Ying Wei, Xianfeng Tang, Zhenhui Li", "title": "Learning from Multiple Cities: A Meta-Learning Approach for\n  Spatial-Temporal Prediction", "comments": "Accepted by WWW 2019, camera-ready version; Erratum: Chicago taxi\n  results slightly change after fixing the issue in the denormalizing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial-temporal prediction is a fundamental problem for constructing smart\ncity, which is useful for tasks such as traffic control, taxi dispatching, and\nenvironmental policy making. Due to data collection mechanism, it is common to\nsee data collection with unbalanced spatial distributions. For example, some\ncities may release taxi data for multiple years while others only release a few\ndays of data; some regions may have constant water quality data monitored by\nsensors whereas some regions only have a small collection of water samples. In\nthis paper, we tackle the problem of spatial-temporal prediction for the cities\nwith only a short period of data collection. We aim to utilize the long-period\ndata from other cities via transfer learning. Different from previous studies\nthat transfer knowledge from one single source city to a target city, we are\nthe first to leverage information from multiple cities to increase the\nstability of transfer. Specifically, our proposed model is designed as a\nspatial-temporal network with a meta-learning paradigm. The meta-learning\nparadigm learns a well-generalized initialization of the spatial-temporal\nnetwork, which can be effectively adapted to target cities. In addition, a\npattern-based spatial-temporal memory is designed to distill long-term temporal\ninformation (i.e., periodicity). We conduct extensive experiments on two tasks:\ntraffic (taxi and bike) prediction and water quality prediction. The\nexperiments demonstrate the effectiveness of our proposed model over several\ncompetitive baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:24:01 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 11:42:54 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 20:34:16 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Yao", "Huaxiu", ""], ["Liu", "Yiding", ""], ["Wei", "Ying", ""], ["Tang", "Xianfeng", ""], ["Li", "Zhenhui", ""]]}, {"id": "1901.08540", "submitter": "Yongjin Park", "authors": "Yongjin Park, Abhishek Sarkar, Khoi Nguyen, Manolis Kellis", "title": "Causal Mediation Analysis Leveraging Multiple Types of Summary\n  Statistics Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summary statistics of genome-wide association studies (GWAS) teach causal\nrelationship between millions of genetic markers and tens and thousands of\nphenotypes. However, underlying biological mechanisms are yet to be elucidated.\nWe can achieve necessary interpretation of GWAS in a causal mediation\nframework, looking to establish a sparse set of mediators between genetic and\ndownstream variables, but there are several challenges. Unlike existing methods\nrely on strong and unrealistic assumptions, we tackle practical challenges\nwithin a principled summary-based causal inference framework. We analyzed the\nproposed methods in extensive simulations generated from real-world genetic\ndata. We demonstrated only our approach can accurately redeem causal genes,\neven without knowing actual individual-level data, despite the presence of\ncompeting non-causal trails.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:00:32 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Park", "Yongjin", ""], ["Sarkar", "Abhishek", ""], ["Nguyen", "Khoi", ""], ["Kellis", "Manolis", ""]]}, {"id": "1901.08544", "submitter": "Tal Wagner", "authors": "Yihe Dong and Piotr Indyk and Ilya Razenshteyn and Tal Wagner", "title": "Learning Space Partitions for Nearest Neighbor Search", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space partitions of $\\mathbb{R}^d$ underlie a vast and important class of\nfast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical\nwork on NNS for general metric spaces [Andoni, Naor, Nikolov, Razenshteyn,\nWaingarten STOC 2018, FOCS 2018], we develop a new framework for building space\npartitions reducing the problem to balanced graph partitioning followed by\nsupervised classification. We instantiate this general approach with the KaHIP\ngraph partitioner [Sanders, Schulz SEA 2013] and neural networks, respectively,\nto obtain a new partitioning procedure called Neural Locality-Sensitive Hashing\n(Neural LSH). On several standard benchmarks for NNS, our experiments show that\nthe partitions obtained by Neural LSH consistently outperform partitions found\nby quantization-based and tree-based methods as well as classic, data-oblivious\nLSH.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:07:59 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 04:48:38 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 19:22:44 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 02:50:54 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Dong", "Yihe", ""], ["Indyk", "Piotr", ""], ["Razenshteyn", "Ilya", ""], ["Wagner", "Tal", ""]]}, {"id": "1901.08547", "submitter": "Quanshi Zhang", "authors": "Yuxia Geng, Jiaoyan Chen, Ernesto Jimenez-Ruiz, Huajun Chen", "title": "Human-centric Transfer Learning Explanation via Knowledge Graph\n  [Extended Abstract]", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning which aims at utilizing knowledge learned from one problem\n(source domain) to solve another different but related problem (target domain)\nhas attracted wide research attentions. However, the current transfer learning\nmethods are mostly uninterpretable, especially to people without ML expertise.\nIn this extended abstract, we brief introduce two knowledge graph (KG) based\nframeworks towards human understandable transfer learning explanation. The\nfirst one explains the transferability of features learned by Convolutional\nNeural Network (CNN) from one domain to another through pre-training and\nfine-tuning, while the second justifies the model of a target domain predicted\nby models from multiple source domains in zero-shot learning (ZSL). Both\nmethods utilize KG and its reasoning capability to provide rich and human\nunderstandable explanations to the transfer procedure.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:51:15 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Geng", "Yuxia", ""], ["Chen", "Jiaoyan", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Chen", "Huajun", ""]]}, {"id": "1901.08551", "submitter": "Quanshi Zhang", "authors": "KamWoh Ng, Lixin Fan and Chee Seng Chan", "title": "A Universal Logic Operator for Interpretable Deep Convolution Networks", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining neural network computation in terms of probabilistic/fuzzy logical\noperations has attracted much attention due to its simplicity and high\ninterpretability. Different choices of logical operators such as AND, OR and\nXOR give rise to another dimension for network optimization, and in this paper,\nwe study the open problem of learning a universal logical operator without\nprescribing to any logical operations manually. Insightful observations along\nthis exploration furnish deep convolution networks with a novel logical\ninterpretation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:50:24 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Ng", "KamWoh", ""], ["Fan", "Lixin", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1901.08552", "submitter": "Santiago Mazuelas", "authors": "Santiago Mazuelas and Aritz Perez", "title": "General Supervision via Probabilistic Transformations", "comments": null, "journal-ref": "24th European Conference on Artificial Intelligence-ECAI 2020,\n  Aug. 2020, pp. 1348-2354", "doi": "10.3233/FAIA200238", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different types of training data have led to numerous schemes for supervised\nclassification. Current learning techniques are tailored to one specific scheme\nand cannot handle general ensembles of training data. This paper presents a\nunifying framework for supervised classification with general ensembles of\ntraining data, and proposes the learning methodology of generalized robust risk\nminimization (GRRM). The paper shows how current and novel supervision schemes\ncan be addressed under the proposed framework by representing the relationship\nbetween examples at test and training via probabilistic transformations. The\nresults show that GRRM can handle different types of training data in a unified\nmanner, and enable new supervision schemes that aggregate general ensembles of\ntraining data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:18:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Mazuelas", "Santiago", ""], ["Perez", "Aritz", ""]]}, {"id": "1901.08553", "submitter": "Quanshi Zhang", "authors": "Jiseob Kim, Byoung-Tak Zhang", "title": "Data Interpolations in Deep Generative Models under Non-Simply-Connected\n  Manifold Topology", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting the deep generative model's remarkable ability of learning the\ndata-manifold structure, some recent researches proposed a geometric data\ninterpolation method based on the geodesic curves on the learned data-manifold.\nHowever, this interpolation method often gives poor results due to a\ntopological difference between the model and the dataset. The model defines a\nfamily of simply-connected manifolds, whereas the dataset generally contains\ndisconnected regions or holes that make them non-simply-connected. To\ncompensate this difference, we propose a novel density regularizer that make\nthe interpolation path circumvent the holes denoted by low probability density.\nWe confirm that our method gives consistently better interpolation results from\nthe experiments with real-world image datasets.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:48:14 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Kim", "Jiseob", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1901.08554", "submitter": "Quanshi Zhang", "authors": "Ioana Giurgiu, Anika Schumann", "title": "Explainable Failure Predictions with RNN Classifiers based on Time\n  Series Data", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given key performance indicators collected with fine granularity as time\nseries, our aim is to predict and explain failures in storage environments.\nAlthough explainable predictive modeling based on spiky telemetry data is key\nin many domains, current approaches cannot tackle this problem. Deep learning\nmethods suitable for sequence modeling and learning temporal dependencies, such\nas RNNs, are effective, but opaque from an explainability perspective. Our\napproach first extracts the anomalous spikes from time series as events and\nthen builds an RNN classifier with attention mechanisms to embed the\nirregularity and frequency of these events. A preliminary evaluation on real\nworld storage environments shows that our approach can predict failures within\na 3-day prediction window with comparable accuracy as traditional RNN-based\nclassifiers. At the same time it can explain the predictions by returning the\nkey anomalous events which led to those failure predictions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:48:48 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Giurgiu", "Ioana", ""], ["Schumann", "Anika", ""]]}, {"id": "1901.08556", "submitter": "Quanshi Zhang", "authors": "Jianjie Lu, Kai-yu Tong", "title": "Visualized Insights into the Optimization Landscape of Fully\n  Convolutional Networks", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many image processing tasks involve image-to-image mapping, which can be\naddressed well by fully convolutional networks (FCN) without any heavy\npreprocessing. Although empirically designing and training FCNs can achieve\nsatisfactory results, reasons for the improvement in performance are slightly\nambiguous. Our study is to make progress in understanding their generalization\nabilities through visualizing the optimization landscapes. The visualization of\nobjective functions is obtained by choosing a solution and projecting its\nvicinity onto a 3D space. We compare three FCN-based networks (two existing\nmodels and a new proposed in this paper for comparison) on multiple datasets.\nIt has been observed in practice that the connections from the pre-pooled\nfeature maps to the post-upsampled can achieve better results. We investigate\nthe cause and provide experiments to shows that the skip-layer connections in\nFCN can promote flat optimization landscape, which is well known to generalize\nbetter. Additionally, we explore the relationship between the models\ngeneralization ability and loss surface under different batch sizes. Results\nshow that large-batch training makes the model converge to sharp minimizers\nwith chaotic vicinities while small-batch method leads the model to flat\nminimizers with smooth and nearly convex regions. Our work may contribute to\ninsights and analysis for designing and training FCNs.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:49:34 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Lu", "Jianjie", ""], ["Tong", "Kai-yu", ""]]}, {"id": "1901.08557", "submitter": "Umang Bhatt", "authors": "Brian Davis, Umang Bhatt, Kartikeya Bhardwaj, Radu Marculescu, Jos\\'e\n  M. F. Moura", "title": "On Network Science and Mutual Information for Explaining Deep Neural\n  Networks", "comments": "ICASSP 2020 (shorter version appeared at AAAI-19 Workshop on Network\n  Interpretability for Deep Learning)", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053078", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new approach to interpret deep learning models.\nBy coupling mutual information with network science, we explore how information\nflows through feedforward networks. We show that efficiently approximating\nmutual information allows us to create an information measure that quantifies\nhow much information flows between any two neurons of a deep learning model. To\nthat end, we propose NIF, Neural Information Flow, a technique for codifying\ninformation flow that exposes deep learning model internals and provides\nfeature attributions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:47:00 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 00:47:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Davis", "Brian", ""], ["Bhatt", "Umang", ""], ["Bhardwaj", "Kartikeya", ""], ["Marculescu", "Radu", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1901.08558", "submitter": "Quanshi Zhang", "authors": "Philipp Schmidt and Felix Biessmann", "title": "Quantifying Interpretability and Trust in Machine Learning Systems", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions by Machine Learning (ML) models have become ubiquitous. Trusting\nthese decisions requires understanding how algorithms take them. Hence\ninterpretability methods for ML are an active focus of research. A central\nproblem in this context is that both the quality of interpretability methods as\nwell as trust in ML predictions are difficult to measure. Yet evaluations,\ncomparisons and improvements of trust and interpretability require quantifiable\nmeasures. Here we propose a quantitative measure for the quality of\ninterpretability methods. Based on that we derive a quantitative measure of\ntrust in ML decisions. Building on previous work we propose to measure\nintuitive understanding of algorithmic decisions using the information transfer\nrate at which humans replicate ML model predictions. We provide empirical\nevidence from crowdsourcing experiments that the proposed metric robustly\ndifferentiates interpretability methods. The proposed metric also demonstrates\nthe value of interpretability for ML assisted human decision making: in our\nexperiments providing explanations more than doubled productivity in annotation\ntasks. However unbiased human judgement is critical for doctors, judges, policy\nmakers and others. Here we derive a trust metric that identifies when human\ndecisions are overly biased towards ML predictions. Our results complement\nexisting qualitative work on trust and interpretability by quantifiable\nmeasures that can serve as objectives for further improving methods in this\nfield of research.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:46:39 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Schmidt", "Philipp", ""], ["Biessmann", "Felix", ""]]}, {"id": "1901.08560", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Stephen J Roberts, Christopher C Holmes", "title": "Semi-Unsupervised Learning: Clustering and Classifying using\n  Ultra-Sparse Labels", "comments": "8 pages, plus appendix", "journal-ref": "IEEE International Conference on Big Data 2020: Machine Learning\n  on Big Data", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised learning for classification, it is assumed that every\nground truth class of data is present in the small labelled dataset. Many\nreal-world sparsely-labelled datasets are plausibly not of this type. It could\neasily be the case that some classes of data are found only in the unlabelled\ndataset -- perhaps the labelling process was biased -- so we do not have any\nlabelled examples to train on for some classes. We call this learning regime\n$\\textit{semi-unsupervised learning}$, an extreme case of semi-supervised\nlearning, where some classes have no labelled exemplars in the training set.\nFirst, we outline the pitfalls associated with trying to apply deep generative\nmodel (DGM)-based semi-supervised learning algorithms to datasets of this type.\nWe then show how a combination of clustering and semi-supervised learning,\nusing DGMs, can be brought to bear on this problem. We study several different\ndatasets, showing how one can still learn effectively when half of the ground\ntruth classes are entirely unlabelled and the other half are sparsely labelled.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:24:39 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:11:27 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 18:29:14 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Willetts", "Matthew", ""], ["Roberts", "Stephen J", ""], ["Holmes", "Christopher C", ""]]}, {"id": "1901.08562", "submitter": "Osbert Bastani", "authors": "Osbert Bastani", "title": "Sample Complexity of Estimating the Policy Gradient for Nearly\n  Deterministic Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach to learning robot controllers.\nIt has recently been shown that algorithms based on finite-difference estimates\nof the policy gradient are competitive with algorithms based on the policy\ngradient theorem. We propose a theoretical framework for understanding this\nphenomenon. Our key insight is that many dynamical systems (especially those of\ninterest in robot control tasks) are \\emph{nearly deterministic}---i.e., they\ncan be modeled as a deterministic system with a small stochastic perturbation.\nWe show that for such systems, finite-difference estimates of the policy\ngradient can have substantially lower variance than estimates based on the\npolicy gradient theorem. We interpret these results in the context of\ncounterfactual estimation. Finally, we empirically evaluate our insights in an\nexperiment on the inverted pendulum.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:30:20 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 05:10:42 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Bastani", "Osbert", ""]]}, {"id": "1901.08565", "submitter": "Osbert Bastani", "authors": "Halley Young and Osbert Bastani and Mayur Naik", "title": "Learning Neurosymbolic Generative Models via Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant strides have been made toward designing better generative models\nin recent years. Despite this progress, however, state-of-the-art approaches\nare still largely unable to capture complex global structure in data. For\nexample, images of buildings typically contain spatial patterns such as windows\nrepeating at regular intervals; state-of-the-art generative methods can't\neasily reproduce these structures. We propose to address this problem by\nincorporating programs representing global structure into the generative\nmodel---e.g., a 2D for-loop may represent a configuration of windows.\nFurthermore, we propose a framework for learning these models by leveraging\nprogram synthesis to generate training data. On both synthetic and real-world\ndata, we demonstrate that our approach is substantially better than the\nstate-of-the-art at both generating and completing images that contain global\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:33:32 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Young", "Halley", ""], ["Bastani", "Osbert", ""], ["Naik", "Mayur", ""]]}, {"id": "1901.08568", "submitter": "Osbert Bastani", "authors": "Min Wen and Osbert Bastani and Ufuk Topcu", "title": "Fairness with Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that if feedback effects of decisions are ignored,\nthen imposing fairness constraints such as demographic parity or equality of\nopportunity can actually exacerbate unfairness. We propose to address this\nchallenge by modeling feedback effects as the dynamics of a Markov decision\nprocesses (MDPs). First, we define analogs of fairness properties that have\nbeen proposed for supervised learning. Second, we propose algorithms for\nlearning fair decision-making policies for MDPs. We also explore extensions to\nreinforcement learning, where parts of the dynamical system are unknown and\nmust be learned without violating fairness. Finally, we demonstrate the need to\naccount for dynamical effects using simulations on a loan applicant MDP.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:40:05 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Wen", "Min", ""], ["Bastani", "Osbert", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1901.08570", "submitter": "Laurent Schmalen", "authors": "Boris Karanov, Domani\\c{c} Lavery, Polina Bayvel, Laurent Schmalen", "title": "End-to-End Optimized Transmission over Dispersive Intensity-Modulated\n  Channels Using Bidirectional Recurrent Neural Networks", "comments": "accepted for publication in Optics Express", "journal-ref": null, "doi": "10.1364/OE.27.019650", "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an autoencoding sequence-based transceiver for communication over\ndispersive channels with intensity modulation and direct detection (IM/DD),\ndesigned as a bidirectional deep recurrent neural network (BRNN). The receiver\nuses a sliding window technique to allow for efficient data stream estimation.\nWe find that this sliding window BRNN (SBRNN), based on end-to-end deep\nlearning of the communication system, achieves a significant bit-error-rate\nreduction at all examined distances in comparison to previous block-based\nautoencoders implemented as feed-forward neural networks (FFNNs), leading to an\nincrease of the transmission distance. We also compare the end-to-end SBRNN\nwith a state-of-the-art IM/DD solution based on two level pulse amplitude\nmodulation with an FFNN receiver, simultaneously processing multiple received\nsymbols and approximating nonlinear Volterra equalization. Our results show\nthat the SBRNN outperforms such systems at both 42 and 84\\,Gb/s, while training\nfewer parameters. Our novel SBRNN design aims at tailoring the end-to-end deep\nlearning-based systems for communication over nonlinear channels with memory,\nsuch as the optical IM/DD fiber channel.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:41:08 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 12:47:59 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Karanov", "Boris", ""], ["Lavery", "Domani\u00e7", ""], ["Bayvel", "Polina", ""], ["Schmalen", "Laurent", ""]]}, {"id": "1901.08571", "submitter": "Ruiqi Liu", "authors": "Ruiqi Liu, Ganggang Xu, Zuofeng Shang", "title": "Optimal Nonparametric Inference under Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference based on lossy or incomplete samples is of fundamental\nimportance in research areas such as signal/image processing, medical image\nstorage, remote sensing, signal transmission. In this paper, we propose a\nnonparametric testing procedure based on quantized samples. In contrast to the\nclassic nonparametric approach, our method lives on a coarse grid of sample\ninformation and are simple-to-use. Under mild technical conditions, we\nestablish the asymptotic properties of the proposed procedures including\nasymptotic null distribution of the quantization test statistic as well as its\nminimax power optimality. Concrete quantizers are constructed for achieving the\nminimax optimality in practical use. Simulation results and a real data\nanalysis are provided to demonstrate the validity and effectiveness of the\nproposed test. Our work bridges the classical nonparametric inference to modern\nlossy data setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:43:16 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:57:14 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Liu", "Ruiqi", ""], ["Xu", "Ganggang", ""], ["Shang", "Zuofeng", ""]]}, {"id": "1901.08572", "submitter": "Wei Hu", "authors": "Simon S. Du, Wei Hu", "title": "Width Provably Matters in Optimization for Deep Linear Neural Networks", "comments": "In ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for an $L$-layer fully-connected linear neural network, if the\nwidth of every hidden layer is $\\tilde\\Omega (L \\cdot r \\cdot d_{\\mathrm{out}}\n\\cdot \\kappa^3 )$, where $r$ and $\\kappa$ are the rank and the condition number\nof the input data, and $d_{\\mathrm{out}}$ is the output dimension, then\ngradient descent with Gaussian random initialization converges to a global\nminimum at a linear rate. The number of iterations to find an\n$\\epsilon$-suboptimal solution is $O(\\kappa \\log(\\frac{1}{\\epsilon}))$. Our\npolynomial upper bound on the total running time for wide deep linear networks\nand the $\\exp\\left(\\Omega\\left(L\\right)\\right)$ lower bound for narrow deep\nlinear neural networks [Shamir, 2018] together demonstrate that wide layers are\nnecessary for optimizing deep models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:43:16 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 09:38:19 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 04:43:23 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Du", "Simon S.", ""], ["Hu", "Wei", ""]]}, {"id": "1901.08573", "submitter": "Hongyang Zhang", "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric P. Xing and\n  Laurent El Ghaoui and Michael I. Jordan", "title": "Theoretically Principled Trade-off between Robustness and Accuracy", "comments": "Appeared in ICML 2019; the winning methodology of the NeurIPS 2018\n  Adversarial Vision Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a trade-off between robustness and accuracy that serves as a\nguiding principle in the design of defenses against adversarial examples.\nAlthough this problem has been widely studied empirically, much remains unknown\nconcerning the theory underlying this trade-off. In this work, we decompose the\nprediction error for adversarial examples (robust error) as the sum of the\nnatural (classification) error and boundary error, and provide a differentiable\nupper bound using the theory of classification-calibrated loss, which is shown\nto be the tightest possible upper bound uniform over all probability\ndistributions and measurable predictors. Inspired by our theoretical analysis,\nwe also design a new defense method, TRADES, to trade adversarial robustness\noff against accuracy. Our proposed algorithm performs well experimentally in\nreal-world datasets. The methodology is the foundation of our entry to the\nNeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of\n~2,000 submissions, surpassing the runner-up approach by $11.41\\%$ in terms of\nmean $\\ell_2$ perturbation distance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:43:57 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 22:04:23 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 07:04:11 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhang", "Hongyang", ""], ["Yu", "Yaodong", ""], ["Jiao", "Jiantao", ""], ["Xing", "Eric P.", ""], ["Ghaoui", "Laurent El", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1901.08576", "submitter": "Osbert Bastani", "authors": "Carolyn Kim and Osbert Bastani", "title": "Learning Interpretable Models with Causal Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown much promise in helping improve the quality of\nmedical, legal, and economic decision-making. In these applications, machine\nlearning models must satisfy two important criteria: (i) they must be causal,\nsince the goal is typically to predict individual treatment effects, and (ii)\nthey must be interpretable, so that human decision makers can validate and\ntrust the model predictions. There has recently been much progress along each\ndirection independently, yet the state-of-the-art approaches are fundamentally\nincompatible. We propose a framework for learning causal interpretable\nmodels---from observational data---that can be used to predict individual\ntreatment effects. Our framework can be used with any algorithm for learning\ninterpretable models. Furthermore, we prove an error bound on the treatment\neffects predicted by our model. Finally, in an experiment on real-world data,\nwe show that the models trained using our framework significantly outperform a\nnumber of baselines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:48:40 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Kim", "Carolyn", ""], ["Bastani", "Osbert", ""]]}, {"id": "1901.08584", "submitter": "Wei Hu", "authors": "Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Ruosong Wang", "title": "Fine-Grained Analysis of Optimization and Generalization for\n  Overparameterized Two-Layer Neural Networks", "comments": "In ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have cast some light on the mystery of why deep nets fit any\ndata and generalize despite being very overparametrized. This paper analyzes\ntraining and generalization for a simple 2-layer ReLU net with random\ninitialization, and provides the following improvements over recent works:\n  (i) Using a tighter characterization of training speed than recent papers, an\nexplanation for why training a neural net with random labels leads to slower\ntraining, as originally observed in [Zhang et al. ICLR'17].\n  (ii) Generalization bound independent of network size, using a data-dependent\ncomplexity measure. Our measure distinguishes clearly between random labels and\ntrue labels on MNIST and CIFAR, as shown by experiments. Moreover, recent\npapers require sample complexity to increase (slowly) with the size, while our\nsample complexity is completely independent of the network size.\n  (iii) Learnability of a broad class of smooth functions by 2-layer ReLU nets\ntrained via gradient descent.\n  The key idea is to track dynamics of training and generalization via\nproperties of a related kernel.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:58:16 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:22:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Li", "Zhiyuan", ""], ["Wang", "Ruosong", ""]]}, {"id": "1901.08585", "submitter": "Hermina Petric Maretic", "authors": "Hermina Petric Maretic, Mireille El Gheche, Pascal Frossard", "title": "Graph heat mixture model learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph inference methods have recently attracted a great interest from the\nscientific community, due to the large value they bring in data interpretation\nand analysis. However, most of the available state-of-the-art methods focus on\nscenarios where all available data can be explained through the same graph, or\ngroups corresponding to each graph are known a priori. In this paper, we argue\nthat this is not always realistic and we introduce a generative model for mixed\nsignals following a heat diffusion process on multiple graphs. We propose an\nexpectation-maximisation algorithm that can successfully separate signals into\ncorresponding groups, and infer multiple graphs that govern their behaviour. We\ndemonstrate the benefits of our method on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:58:31 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Maretic", "Hermina Petric", ""], ["Gheche", "Mireille El", ""], ["Frossard", "Pascal", ""]]}, {"id": "1901.08612", "submitter": "Tom Zahavy", "authors": "Tom Zahavy and Shie Mannor", "title": "Deep Neural Linear Bandits: Overcoming Catastrophic Forgetting through\n  Likelihood Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the neural-linear bandit model for solving sequential\ndecision-making problems with high dimensional side information. Neural-linear\nbandits leverage the representation power of deep neural networks and combine\nit with efficient exploration mechanisms, designed for linear contextual\nbandits, on top of the last hidden layer. Since the representation is being\noptimized during learning, information regarding exploration with \"old\"\nfeatures is lost. Here, we propose the first limited memory neural-linear\nbandit that is resilient to this phenomenon, which we term catastrophic\nforgetting. We evaluate our method on a variety of real-world data sets,\nincluding regression, classification, and sentiment analysis, and observe that\nour algorithm is resilient to catastrophic forgetting and achieves superior\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:15:17 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 11:55:34 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zahavy", "Tom", ""], ["Mannor", "Shie", ""]]}, {"id": "1901.08621", "submitter": "Mengke Lian", "authors": "Mengke Lian, Fabrizio Carpi, Christian H\\\"ager, Henry D. Pfister", "title": "Learned Belief-Propagation Decoding with Simple Scaling and SNR\n  Adaptation", "comments": "5 pages, 5 figures, submitted to ISIT 2019", "journal-ref": null, "doi": "10.1109/ISIT.2019.8849419", "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the weighted belief-propagation (WBP) decoder recently proposed\nby Nachmani et al. where different weights are introduced for each Tanner graph\nedge and optimized using machine learning techniques. Our focus is on\nsimple-scaling models that use the same weights across certain edges to reduce\nthe storage and computational burden. The main contribution is to show that\nsimple scaling with few parameters often achieves the same gain as the full\nparameterization. Moreover, several training improvements for WBP are proposed.\nFor example, it is shown that minimizing average binary cross-entropy is\nsuboptimal in general in terms of bit error rate (BER) and a new \"soft-BER\"\nloss is proposed which can lead to better performance. We also investigate\nparameter adapter networks (PANs) that learn the relation between the\nsignal-to-noise ratio and the WBP parameters. As an example, for the (32,16)\nReed-Muller code with a highly redundant parity-check matrix, training a PAN\nwith soft-BER loss gives near-maximum-likelihood performance assuming simple\nscaling with only three parameters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:37:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lian", "Mengke", ""], ["Carpi", "Fabrizio", ""], ["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1901.08624", "submitter": "Jiancheng Lyu", "authors": "Jiancheng Lyu, Shuai Zhang, Yingyong Qi, Jack Xin", "title": "AutoShuffleNet: Learning Permutation Matrices via an Exact Lipschitz\n  Continuous Penalty in Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ShuffleNet is a state-of-the-art light weight convolutional neural network\narchitecture. Its basic operations include group, channel-wise convolution and\nchannel shuffling. However, channel shuffling is manually designed empirically.\nMathematically, shuffling is a multiplication by a permutation matrix. In this\npaper, we propose to automate channel shuffling by learning permutation\nmatrices in network training. We introduce an exact Lipschitz continuous\nnon-convex penalty so that it can be incorporated in the stochastic gradient\ndescent to approximate permutation at high precision. Exact permutations are\nobtained by simple rounding at the end of training and are used in inference.\nThe resulting network, referred to as AutoShuffleNet, achieved improved\nclassification accuracies on CIFAR-10 and ImageNet data sets. In addition, we\nfound experimentally that the standard convex relaxation of permutation\nmatrices into stochastic matrices leads to poor performance. We prove\ntheoretically the exactness (error bounds) in recovering permutation matrices\nwhen our penalty function is zero (very small). We present examples of\npermutation optimization through graph matching and two-layer neural network\nmodels where the loss functions are calculated in closed analytical form. In\nthe examples, convex relaxation failed to capture permutations whereas our\npenalty succeeded.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 19:45:53 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Lyu", "Jiancheng", ""], ["Zhang", "Shuai", ""], ["Qi", "Yingyong", ""], ["Xin", "Jack", ""]]}, {"id": "1901.08628", "submitter": "Matth\\\"aus Kleindessner", "authors": "Matth\\\"aus Kleindessner, Pranjal Awasthi, Jamie Morgenstern", "title": "Fair k-Center Clustering for Data Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data summarization we want to choose $k$ prototypes in order to summarize\na data set. We study a setting where the data set comprises several demographic\ngroups and we are restricted to choose $k_i$ prototypes belonging to group $i$.\nA common approach to the problem without the fairness constraint is to optimize\na centroid-based clustering objective such as $k$-center. A natural extension\nthen is to incorporate the fairness constraint into the clustering problem.\nExisting algorithms for doing so run in time super-quadratic in the size of the\ndata set, which is in contrast to the standard $k$-center problem being\napproximable in linear time. In this paper, we resolve this gap by providing a\nsimple approximation algorithm for the $k$-center problem under the fairness\nconstraint with running time linear in the size of the data set and $k$. If the\nnumber of demographic groups is small, the approximation guarantee of our\nalgorithm only incurs a constant-factor overhead.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 20:05:57 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 19:29:06 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kleindessner", "Matth\u00e4us", ""], ["Awasthi", "Pranjal", ""], ["Morgenstern", "Jamie", ""]]}, {"id": "1901.08649", "submitter": "Christopher Grimm", "authors": "Christopher Grimm and Satinder Singh", "title": "Learning Independently-Obtainable Reward Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for learning a set of disentangled reward functions\nthat sum to the original environment reward and are constrained to be\nindependently obtainable. We define independent obtainability in terms of value\nfunctions with respect to obtaining one learned reward while pursuing another\nlearned reward. Empirically, we illustrate that our method can learn meaningful\nreward decompositions in a variety of domains and that these decompositions\nexhibit some form of generalization performance when the environment's reward\nis modified. Theoretically, we derive results about the effect of maximizing\nour method's objective on the resulting reward functions and their\ncorresponding optimal policies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:46:39 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 20:28:12 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 17:26:51 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Grimm", "Christopher", ""], ["Singh", "Satinder", ""]]}, {"id": "1901.08651", "submitter": "Kalifou Ren\\'e Traor\\'e", "authors": "Antonin Raffin, Ashley Hill, Ren\\'e Traor\\'e, Timoth\\'ee Lesort,\n  Natalia D\\'iaz-Rodr\\'iguez, David Filliat", "title": "Decoupling feature extraction from policy learning: assessing benefits\n  of state representation learning in goal based robotics", "comments": "Github repo: https://github.com/araffin/srl-zoo Documentation:\n  https://srl-zoo.readthedocs.io/en/latest/, As part of SRL-Toolbox:\n  https://s-rl-toolbox.readthedocs.io/en/latest/. Accepted to the Workshop on\n  Structure & Priors in Reinforcement Learning at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling end-to-end reinforcement learning to control real robots from vision\npresents a series of challenges, in particular in terms of sample efficiency.\nAgainst end-to-end learning, state representation learning can help learn a\ncompact, efficient and relevant representation of states that speeds up policy\nlearning, reducing the number of samples needed, and that is easier to\ninterpret. We evaluate several state representation learning methods on goal\nbased robotics tasks and propose a new unsupervised model that stacks\nrepresentations and combines strengths of several of these approaches. This\nmethod encodes all the relevant features, performs on par or better than\nend-to-end learning with better sample efficiency, and is robust to\nhyper-parameters change.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:49:49 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 18:51:34 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2019 10:11:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Raffin", "Antonin", ""], ["Hill", "Ashley", ""], ["Traor\u00e9", "Ren\u00e9", ""], ["Lesort", "Timoth\u00e9e", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1901.08652", "submitter": "Jemin Hwangbo", "authors": "Jemin Hwangbo, Joonho Lee, Alexey Dosovitskiy, Dario Bellicoso,\n  Vassilios Tsounis, Vladlen Koltun, and Marco Hutter", "title": "Learning agile and dynamic motor skills for legged robots", "comments": null, "journal-ref": "Science Robotics 4.26 (2019): eaau5872", "doi": "10.1126/scirobotics.aau5872", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legged robots pose one of the greatest challenges in robotics. Dynamic and\nagile maneuvers of animals cannot be imitated by existing methods that are\ncrafted by humans. A compelling alternative is reinforcement learning, which\nrequires minimal craftsmanship and promotes the natural evolution of a control\npolicy. However, so far, reinforcement learning research for legged robots is\nmainly limited to simulation, and only few and comparably simple examples have\nbeen deployed on real systems. The primary reason is that training with real\nrobots, particularly with dynamically balancing systems, is complicated and\nexpensive. In the present work, we introduce a method for training a neural\nnetwork policy in simulation and transferring it to a state-of-the-art legged\nsystem, thereby leveraging fast, automated, and cost-effective data generation\nschemes. The approach is applied to the ANYmal robot, a sophisticated\nmedium-dog-sized quadrupedal system. Using policies trained in simulation, the\nquadrupedal machine achieves locomotion skills that go beyond what had been\nachieved with prior methods: ANYmal is capable of precisely and\nenergy-efficiently following high-level body velocity commands, running faster\nthan before, and recovering from falling even in complex configurations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:50:29 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Hwangbo", "Jemin", ""], ["Lee", "Joonho", ""], ["Dosovitskiy", "Alexey", ""], ["Bellicoso", "Dario", ""], ["Tsounis", "Vassilios", ""], ["Koltun", "Vladlen", ""], ["Hutter", "Marco", ""]]}, {"id": "1901.08654", "submitter": "Lawrence Chan", "authors": "Lawrence Chan, Dylan Hadfield-Menell, Siddhartha Srinivasa, Anca\n  Dragan", "title": "The Assistive Multi-Armed Bandit", "comments": "Accepted to HRI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning preferences implicit in the choices humans make is a well studied\nproblem in both economics and computer science. However, most work makes the\nassumption that humans are acting (noisily) optimally with respect to their\npreferences. Such approaches can fail when people are themselves learning about\nwhat they want. In this work, we introduce the assistive multi-armed bandit,\nwhere a robot assists a human playing a bandit task to maximize cumulative\nreward. In this problem, the human does not know the reward function but can\nlearn it through the rewards received from arm pulls; the robot only observes\nwhich arms the human pulls but not the reward associated with each pull. We\noffer sufficient and necessary conditions for successfully assisting the human\nin this framework. Surprisingly, better human performance in isolation does not\nnecessarily lead to better performance when assisted by the robot: a human\npolicy can do better by effectively communicating its observed rewards to the\nrobot. We conduct proof-of-concept experiments that support these results. We\nsee this work as contributing towards a theory behind algorithms for\nhuman-robot interaction.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:52:01 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Chan", "Lawrence", ""], ["Hadfield-Menell", "Dylan", ""], ["Srinivasa", "Siddhartha", ""], ["Dragan", "Anca", ""]]}, {"id": "1901.08663", "submitter": "Andrei Patrascu", "authors": "Andrei Patrascu", "title": "New nonasymptotic convergence rates of stochastic proximal\n  pointalgorithm for convex optimization problems", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large sectors of the recent optimization literature focused in the last\ndecade on the development of optimal stochastic first order schemes for\nconstrained convex models under progressively relaxed assumptions. Stochastic\nproximal point is an iterative scheme born from the adaptation of proximal\npoint algorithm to noisy stochastic optimization, with a resulting iteration\nrelated to stochastic alternating projections. Inspired by the scalability of\nalternating projection methods, we start from the (linear) regularity\nassumption, typically used in convex feasiblity problems to guarantee the\nlinear convergence of stochastic alternating projection methods, and analyze a\ngeneral weak linear regularity condition which facilitates convergence rate\nboosts in stochastic proximal point schemes. Our applications include many\nnon-strongly convex functions classes often used in machine learning and\nstatistics. Moreover, under weak linear regularity assumption we guarantee\n$\\mathcal{O}\\left(\\frac{1}{k}\\right)$ convergence rate for SPP, in terms of the\ndistance to the optimal set, using only projections onto a simple component\nset. Linear convergence is obtained for interpolation setting, when the optimal\nset of the expected cost is included into the optimal sets of each functional\ncomponent.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 15:10:59 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 08:57:26 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 12:24:13 GMT"}, {"version": "v4", "created": "Sat, 2 May 2020 09:43:30 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Patrascu", "Andrei", ""]]}, {"id": "1901.08665", "submitter": "Aditya Menon", "authors": "Robert C. Williamson, Aditya Krishna Menon", "title": "Fairness risk measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring that classifiers are non-discriminatory or fair with respect to a\nsensitive feature (e.g., race or gender) is a topical problem. Progress in this\ntask requires fixing a definition of fairness, and there have been several\nproposals in this regard over the past few years. Several of these, however,\nassume either binary sensitive features (thus precluding categorical or\nreal-valued sensitive groups), or result in non-convex objectives (thus\nadversely affecting the optimisation landscape). In this paper, we propose a\nnew definition of fairness that generalises some existing proposals, while\nallowing for generic sensitive features and resulting in a convex objective.\nThe key idea is to enforce that the expected losses (or risks) across each\nsubgroup induced by the sensitive feature are commensurate. We show how this\nrelates to the rich literature on risk measures from mathematical finance. As a\nspecial case, this leads to a new convex fairness-aware objective based on\nminimising the conditional value at risk (CVaR).\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 22:15:12 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Williamson", "Robert C.", ""], ["Menon", "Aditya Krishna", ""]]}, {"id": "1901.08668", "submitter": "Matth\\\"aus Kleindessner", "authors": "Matth\\\"aus Kleindessner, Samira Samadi, Pranjal Awasthi, Jamie\n  Morgenstern", "title": "Guarantees for Spectral Clustering with Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the widespread popularity of spectral clustering (SC) for partitioning\ngraph data, we study a version of constrained SC in which we try to incorporate\nthe fairness notion proposed by Chierichetti et al. (2017). According to this\nnotion, a clustering is fair if every demographic group is approximately\nproportionally represented in each cluster. To this end, we develop variants of\nboth normalized and unnormalized constrained SC and show that they help find\nfairer clusterings on both synthetic and real data. We also provide a rigorous\ntheoretical analysis of our algorithms on a natural variant of the stochastic\nblock model, where $h$ groups have strong inter-group connectivity, but also\nexhibit a \"natural\" clustering structure which is fair. We prove that our\nalgorithms can recover this fair clustering with high probability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 22:27:46 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 19:42:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kleindessner", "Matth\u00e4us", ""], ["Samadi", "Samira", ""], ["Awasthi", "Pranjal", ""], ["Morgenstern", "Jamie", ""]]}, {"id": "1901.08669", "submitter": "Peter Richt\\'arik", "authors": "Xu Qian and Zheng Qu and Peter Richt\\'arik", "title": "SAGA with Arbitrary Sampling", "comments": "27 pages, 8 Figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of minimizing the average of a very large number of\nsmooth functions, which is of key importance in training supervised learning\nmodels. One of the most celebrated methods in this context is the SAGA\nalgorithm. Despite years of research on the topic, a general-purpose version of\nSAGA---one that would include arbitrary importance sampling and minibatching\nschemes---does not exist. We remedy this situation and propose a general and\nflexible variant of SAGA following the {\\em arbitrary sampling} paradigm. We\nperform an iteration complexity analysis of the method, largely possible due to\nthe construction of new stochastic Lyapunov functions. We establish linear\nconvergence rates in the smooth and strongly convex regime, and under a\nquadratic functional growth condition (i.e., in a regime not assuming strong\nconvexity). Our rates match those of the primal-dual method Quartz for which an\narbitrary sampling analysis is available, which makes a significant step\ntowards closing the gap in our understanding of complexity of primal and dual\nmethods for finite sum problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 22:37:42 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Qian", "Xu", ""], ["Qu", "Zheng", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1901.08680", "submitter": "Isabela Maria Carneiro de Albuquerque", "authors": "Isabela Albuquerque, Jo\\~ao Monteiro, Thang Doan, Breandan Considine,\n  Tiago Falk, Ioannis Mitliagkas", "title": "Multi-objective training of Generative Adversarial Networks with\n  multiple discriminators", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature has demonstrated promising results for training Generative\nAdversarial Networks by employing a set of discriminators, in contrast to the\ntraditional game involving one generator against a single adversary. Such\nmethods perform single-objective optimization on some simple consolidation of\nthe losses, e.g. an arithmetic average. In this work, we revisit the\nmultiple-discriminator setting by framing the simultaneous minimization of\nlosses provided by different models as a multi-objective optimization problem.\nSpecifically, we evaluate the performance of multiple gradient descent and the\nhypervolume maximization algorithm on a number of different datasets. Moreover,\nwe argue that the previously proposed methods and hypervolume maximization can\nall be seen as variations of multiple gradient descent in which the update\ndirection can be computed efficiently. Our results indicate that hypervolume\nmaximization presents a better compromise between sample quality and\ncomputational cost than previous methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 23:20:11 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Albuquerque", "Isabela", ""], ["Monteiro", "Jo\u00e3o", ""], ["Doan", "Thang", ""], ["Considine", "Breandan", ""], ["Falk", "Tiago", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1901.08689", "submitter": "Samuel Horv\\'ath", "authors": "Dmitry Kovalev and Samuel Horvath and Peter Richtarik", "title": "Don't Jump Through Hoops and Remove Those Loops: SVRG and Katyusha are\n  Better Without the Outer Loop", "comments": "14 pages, 2 algorithms, 9 lemmas, 2 theorems, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic variance-reduced gradient method (SVRG) and its accelerated\nvariant (Katyusha) have attracted enormous attention in the machine learning\ncommunity in the last few years due to their superior theoretical properties\nand empirical behaviour on training supervised machine learning models via the\nempirical risk minimization paradigm. A key structural element in both of these\nmethods is the inclusion of an outer loop at the beginning of which a full pass\nover the training data is made in order to compute the exact gradient, which is\nthen used to construct a variance-reduced estimator of the gradient. In this\nwork we design {\\em loopless variants} of both of these methods. In particular,\nwe remove the outer loop and replace its function by a coin flip performed in\neach iteration designed to trigger, with a small probability, the computation\nof the gradient. We prove that the new methods enjoy the same superior\ntheoretical convergence properties as the original methods. However, we\ndemonstrate through numerical experiments that our methods have substantially\nsuperior practical behavior.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 23:37:52 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 06:03:16 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kovalev", "Dmitry", ""], ["Horvath", "Samuel", ""], ["Richtarik", "Peter", ""]]}, {"id": "1901.08708", "submitter": "Harsh Gupta", "authors": "Harsh Gupta, Seo Taek Kong, R. Srikant, Weina Wang", "title": "Almost Boltzmann Exploration", "comments": "12 pages, 14 figures. Fixed a figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann exploration is widely used in reinforcement learning to provide a\ntrade-off between exploration and exploitation. Recently, in (Cesa-Bianchi et\nal., 2017) it has been shown that pure Boltzmann exploration does not perform\nwell from a regret perspective, even in the simplest setting of stochastic\nmulti-armed bandit (MAB) problems. In this paper, we show that a simple\nmodification to Boltzmann exploration, motivated by a variation of the standard\ndoubling trick, achieves $O(K\\log^{1+\\alpha} T)$ regret for a stochastic MAB\nproblem with $K$ arms, where $\\alpha>0$ is a parameter of the algorithm. This\nimproves on the result in (Cesa-Bianchi et al., 2017), where an algorithm\ninspired by the Gumbel-softmax trick achieves $O(K\\log^2 T)$ regret. We also\nshow that our algorithm achieves $O(\\beta(G) \\log^{1+\\alpha} T)$ regret in\nstochastic MAB problems with graph-structured feedback, without knowledge of\nthe graph structure, where $\\beta(G)$ is the independence number of the\nfeedback graph. Additionally, we present extensive experimental results on real\ndatasets and applications for multi-armed bandits with both traditional bandit\nfeedback and graph-structured feedback. In all cases, our algorithm performs as\nwell or better than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 01:29:24 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 20:45:15 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Gupta", "Harsh", ""], ["Kong", "Seo Taek", ""], ["Srikant", "R.", ""], ["Wang", "Weina", ""]]}, {"id": "1901.08710", "submitter": "Trung Le", "authors": "Trung Le and Dinh Phung", "title": "When Can Neural Networks Learn Connected Decision Regions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has questioned the conditions under which the decision regions\nof a neural network are connected and further showed the implications of the\ncorresponding theory to the problem of adversarial manipulation of classifiers.\nIt has been proven that for a class of activation functions including leaky\nReLU, neural networks having a pyramidal structure, that is no layer has more\nhidden units than the input dimension, produce necessarily connected decision\nregions. In this paper, we advance this important result by further developing\nthe sufficient and necessary conditions under which the decision regions of a\nneural network are connected. We then apply our framework to overcome the\nlimits of existing work and further study the capacity to learn connected\nregions of neural networks for a much wider class of activation functions\nincluding those widely used, namely ReLU, sigmoid, tanh, softlus, and\nexponential linear function.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 01:47:59 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Le", "Trung", ""], ["Phung", "Dinh", ""]]}, {"id": "1901.08730", "submitter": "Sicong Liu", "authors": "Sicong Liu and Anshumali Shrivastava and Junzhao Du and Lin Zhong", "title": "Better accuracy with quantified privacy: representations learned via\n  reconstructive adversarial network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable success of machine learning, especially deep learning, has\nproduced a variety of cloud-based services for mobile users. Such services\nrequire an end user to send data to the service provider, which presents a\nserious challenge to end-user privacy. To address this concern, prior works\neither add noise to the data or send features extracted from the raw data. They\nstruggle to balance between the utility and privacy because added noise reduces\nutility and raw data can be reconstructed from extracted features. This work\nrepresents a methodical departure from prior works: we balance between a\nmeasure of privacy and another of utility by leveraging adversarial learning to\nfind a sweeter tradeoff. We design an encoder that optimizes against the\nreconstruction error (a measure of privacy), adversarially by a Decoder, and\nthe inference accuracy (a measure of utility) by a Classifier. The result is\nRAN, a novel deep model with a new training algorithm that automatically\nextracts features for classification that are both private and useful. It turns\nout that adversarially forcing the extracted features to only conveys the\nintended information required by classification leads to an implicit\nregularization leading to better classification accuracy than the original\nmodel which completely ignores privacy. Thus, we achieve better privacy with\nbetter utility, a surprising possibility in machine learning! We conducted\nextensive experiments on five popular datasets over four training schemes, and\ndemonstrate the superiority of RAN compared with existing alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 04:14:18 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Liu", "Sicong", ""], ["Shrivastava", "Anshumali", ""], ["Du", "Junzhao", ""], ["Zhong", "Lin", ""]]}, {"id": "1901.08740", "submitter": "Pengqian Yu", "authors": "Pengqian Yu, Joon Sern Lee, Ilya Kulyatin, Zekun Shi, Sakyasingha\n  Dasgupta", "title": "Model-based Deep Reinforcement Learning for Dynamic Portfolio\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic portfolio optimization is the process of sequentially allocating\nwealth to a collection of assets in some consecutive trading periods, based on\ninvestors' return-risk profile. Automating this process with machine learning\nremains a challenging problem. Here, we design a deep reinforcement learning\n(RL) architecture with an autonomous trading agent such that, investment\ndecisions and actions are made periodically, based on a global objective, with\nautonomy. In particular, without relying on a purely model-free RL agent, we\ntrain our trading agent using a novel RL architecture consisting of an infused\nprediction module (IPM), a generative adversarial data augmentation module\n(DAM) and a behavior cloning module (BCM). Our model-based approach works with\nboth on-policy or off-policy RL algorithms. We further design the back-testing\nand execution engine which interact with the RL agent in real time. Using\nhistorical {\\em real} financial market data, we simulate trading with practical\nconstraints, and demonstrate that our proposed model is robust, profitable and\nrisk-sensitive, as compared to baseline trading strategies and model-free RL\nagents from prior work.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 04:55:02 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Yu", "Pengqian", ""], ["Lee", "Joon Sern", ""], ["Kulyatin", "Ilya", ""], ["Shi", "Zekun", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1901.08744", "submitter": "Venkatesh Umaashankar Mr", "authors": "Venkatesh Umaashankar and Girish Shanmugam S", "title": "Ask less - Scale Market Research without Annoying Your Customers", "comments": "Accepted and presented in aisgsc2019\n  (http://www.psgtech.edu/aisgsc2019/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market research is generally performed by surveying a representative sample\nof customers with questions that includes contexts such as psycho-graphics,\ndemographics, attitude and product preferences. Survey responses are used to\nsegment the customers into various groups that are useful for targeted\nmarketing and communication. Reducing the number of questions asked to the\ncustomer has utility for businesses to scale the market research to a large\nnumber of customers. In this work, we model this task using Bayesian networks.\nWe demonstrate the effectiveness of our approach using an example market\nsegmentation of broadband customers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 05:43:06 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Umaashankar", "Venkatesh", ""], ["S", "Girish Shanmugam", ""]]}, {"id": "1901.08753", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong and Yi-Hsuan Yang", "title": "Towards a Deeper Understanding of Adversarial Losses under a\n  Discriminative Adversarial Network Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed various adversarial loss functions for training\neither generative or discriminative models. Yet, it remains unclear what\ncertain types of functions are valid adversarial losses, and how these loss\nfunctions perform against one another. In this paper, we aim to gain a deeper\nunderstanding of adversarial losses by decoupling the effects of their\ncomponent functions and regularization terms. We first derive in theory some\nnecessary and sufficient conditions of the component functions such that the\nadversarial loss is a divergence-like measure between the data and the model\ndistributions. In order to systematically compare different adversarial losses,\nwe then propose a new, simple comparative framework, dubbed DANTest, based on\ndiscriminative adversarial networks (DANs). With this framework, we evaluate an\nextensive set of adversarial losses by combining different component functions\nand regularization approaches. Our theoretical and empirical results can\ntogether serve as a reference for choosing or designing adversarial training\nobjectives in future research.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 06:31:52 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 03:24:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1901.08755", "submitter": "Kewei Cheng", "authors": "Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, Dimitrios\n  Papadopoulos, Qiang Yang", "title": "SecureBoost: A Lossless Federated Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The protection of user privacy is an important concern in machine learning,\nas evidenced by the rolling out of the General Data Protection Regulation\n(GDPR) in the European Union (EU) in May 2018. The GDPR is designed to give\nusers more control over their personal data, which motivates us to explore\nmachine learning frameworks for data sharing that do not violate user privacy.\nTo meet this goal, in this paper, we propose a novel lossless\nprivacy-preserving tree-boosting system known as SecureBoost in the setting of\nfederated learning. SecureBoost first conducts entity alignment under a\nprivacy-preserving protocol and then constructs boosting trees across multiple\nparties with a carefully designed encryption strategy. This federated learning\nsystem allows the learning process to be jointly conducted over multiple\nparties with common user samples but different feature sets, which corresponds\nto a vertically partitioned data set. An advantage of SecureBoost is that it\nprovides the same level of accuracy as the non-privacy-preserving approach\nwhile at the same time, reveals no information of each private data provider.\nWe show that the SecureBoost framework is as accurate as other non-federated\ngradient tree-boosting algorithms that require centralized data and thus it is\nhighly scalable and practical for industrial applications such as credit risk\nanalysis. To this end, we discuss information leakage during the protocol\nexecution and propose ways to provably reduce it.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 06:53:11 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 02:44:47 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 05:40:02 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Cheng", "Kewei", ""], ["Fan", "Tao", ""], ["Jin", "Yilun", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Papadopoulos", "Dimitrios", ""], ["Yang", "Qiang", ""]]}, {"id": "1901.08770", "submitter": "Ashish Katiyar", "authors": "Ashish Katiyar, Jessica Hoffmann, Constantine Caramanis", "title": "Robust estimation of tree structured Gaussian Graphical Model", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider jointly Gaussian random variables whose conditional independence\nstructure is specified by a graphical model. If we observe realizations of the\nvariables, we can compute the covariance matrix, and it is well known that the\nsupport of the inverse covariance matrix corresponds to the edges of the\ngraphical model. Instead, suppose we only have noisy observations. If the noise\nat each node is independent, we can compute the sum of the covariance matrix\nand an unknown diagonal. The inverse of this sum is (in general) dense. We ask:\ncan the original independence structure be recovered? We address this question\nfor tree structured graphical models. We prove that this problem is\nunidentifiable, but show that this unidentifiability is limited to a small\nclass of candidate trees. We further present additional constraints under which\nthe problem is identifiable. Finally, we provide an O(n^3) algorithm to find\nthis equivalence class of trees.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:08:02 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Katiyar", "Ashish", ""], ["Hoffmann", "Jessica", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1901.08779", "submitter": "Julian Zimmert", "authors": "Julian Zimmert, Haipeng Luo, Chen-Yu Wei", "title": "Beating Stochastic and Adversarial Semi-bandits Optimally and\n  Simultaneously", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the first general semi-bandit algorithm that simultaneously\nachieves $\\mathcal{O}(\\log T)$ regret for stochastic environments and\n$\\mathcal{O}(\\sqrt{T})$ regret for adversarial environments without knowledge\nof the regime or the number of rounds $T$. The leading problem-dependent\nconstants of our bounds are not only optimal in some worst-case sense studied\npreviously, but also optimal for two concrete instances of semi-bandit\nproblems. Our algorithm and analysis extend the recent work of (Zimmert &\nSeldin, 2019) for the special case of multi-armed bandit, but importantly\nrequires a novel hybrid regularizer designed specifically for semi-bandit.\nExperimental results on synthetic data show that our algorithm indeed performs\nwell uniformly over different environments. We finally provide a preliminary\nextension of our results to the full bandit feedback.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:30:59 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 14:11:13 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zimmert", "Julian", ""], ["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""]]}, {"id": "1901.08788", "submitter": "Julien Mairal", "authors": "Andrei Kulunchakov (Thoth), Julien Mairal (Thoth)", "title": "Estimate Sequences for Stochastic Composite Optimization: Variance\n  Reduction, Acceleration, and Robustness to Noise", "comments": "Journal of Machine Learning Research, Microtome Publishing, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a unified view of gradient-based algorithms for\nstochastic convex composite optimization by extending the concept of estimate\nsequence introduced by Nesterov. More precisely, we interpret a large class of\nstochastic optimization methods as procedures that iteratively minimize a\nsurrogate of the objective, which covers the stochastic gradient descent method\nand variants of the incremental approaches SAGA, SVRG, and MISO/Finito/SDCA.\nThis point of view has several advantages: (i) we provide a simple generic\nproof of convergence for all of the aforementioned methods; (ii) we naturally\nobtain new algorithms with the same guarantees; (iii) we derive generic\nstrategies to make these algorithms robust to stochastic noise, which is useful\nwhen data is corrupted by small random perturbations. Finally, we propose a new\naccelerated stochastic gradient descent algorithm and an accelerated SVRG\nalgorithm with optimal complexity that is robust to stochastic noise.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 09:04:20 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 15:33:38 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 08:47:49 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 14:30:36 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Kulunchakov", "Andrei", "", "Thoth"], ["Mairal", "Julien", "", "Thoth"]]}, {"id": "1901.08798", "submitter": "Hiroshi Kera", "authors": "Hiroshi Kera and Yoshihiko Hasegawa", "title": "Spurious Vanishing Problem in Approximate Vanishing Ideal", "comments": "30 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate vanishing ideal is a concept from computer algebra that studies\nthe algebraic varieties behind perturbed data points. To capture the nonlinear\nstructure of perturbed points, the introduction of approximation to exact\nvanishing ideals plays a critical role. However, such an approximation also\ngives rise to a theoretical problem---the spurious vanishing problem---in the\nbasis construction of approximate vanishing ideals; namely, obtained basis\npolynomials can be approximately vanishing simply because of the small\ncoefficients. In this paper, we propose a first general method that enables\nvarious basis construction algorithms to overcome the spurious vanishing\nproblem. In particular, we integrate coefficient normalization with\npolynomial-based basis constructions, which do not need the proper ordering of\nmonomials to process for basis constructions. We further propose a method that\ntakes advantage of the iterative nature of basis construction so that\ncomputationally costly operations for coefficient normalization can be\ncircumvented. Moreover, a coefficient truncation method is proposed for further\naccelerations. From the experiments, it can be shown that the proposed method\novercomes the spurious vanishing problem, resulting in shorter feature vectors\nwhile sustaining comparable or even lower classification error.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 09:41:26 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 03:33:19 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 05:59:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kera", "Hiroshi", ""], ["Hasegawa", "Yoshihiko", ""]]}, {"id": "1901.08810", "submitter": "Jan Chorowski", "authors": "Jan Chorowski, Ron J. Weiss, Samy Bengio, A\\\"aron van den Oord", "title": "Unsupervised speech representation learning using WaveNet autoencoders", "comments": "Accepted to IEEE TASLP, final version available at\n  http://dx.doi.org/10.1109/TASLP.2019.2938863", "journal-ref": null, "doi": "10.1109/TASLP.2019.2938863", "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of unsupervised extraction of meaningful latent\nrepresentations of speech by applying autoencoding neural networks to speech\nwaveforms. The goal is to learn a representation able to capture high level\nsemantic content from the signal, e.g.\\ phoneme identities, while being\ninvariant to confounding low level details in the signal such as the underlying\npitch contour or background noise. Since the learned representation is tuned to\ncontain only phonetic content, we resort to using a high capacity WaveNet\ndecoder to infer information discarded by the encoder from previous samples.\nMoreover, the behavior of autoencoder models depends on the kind of constraint\nthat is applied to the latent representation. We compare three variants: a\nsimple dimensionality reduction bottleneck, a Gaussian Variational Autoencoder\n(VAE), and a discrete Vector Quantized VAE (VQ-VAE). We analyze the quality of\nlearned representations in terms of speaker independence, the ability to\npredict phonetic content, and the ability to accurately reconstruct individual\nspectrogram frames. Moreover, for discrete encodings extracted using the\nVQ-VAE, we measure the ease of mapping them to phonemes. We introduce a\nregularization scheme that forces the representations to focus on the phonetic\ncontent of the utterance and report performance comparable with the top entries\nin the ZeroSpeech 2017 unsupervised acoustic unit discovery task.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 10:10:12 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 08:31:08 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Chorowski", "Jan", ""], ["Weiss", "Ron J.", ""], ["Bengio", "Samy", ""], ["Oord", "A\u00e4ron van den", ""]]}, {"id": "1901.08814", "submitter": "Damian Gola", "authors": "Damian Gola and Inke R. K\\\"onig", "title": "Empowering individual trait prediction using interactions", "comments": "35 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One component of precision medicine is to construct prediction models with\ntheir predictive ability as high as possible, e.g. to enable individual risk\nprediction. In genetic epidemiology, complex diseases have a polygenic basis\nand a common assumption is that biological and genetic features affect the\noutcome under consideration via interactions. In the case of omics data, the\nuse of standard approaches such as generalized linear models may be suboptimal\nand machine learning methods are appealing to make individual predictions.\nHowever, most of these algorithms focus mostly on main or marginal effects of\nthe single features in a dataset. On the other hand, the detection of\ninteracting features is an active area of research in the realm of genetic\nepidemiology. One big class of algorithms to detect interacting features is\nbased on the multifactor dimensionality reduction (MDR). Here, we extend the\nmodel-based MDR (MB-MDR), a powerful extension of the original MDR algorithm,\nto enable interaction empowered individual prediction. Using a comprehensive\nsimulation study we show that our new algorithm can use information hidden in\ninteractions more efficiently than two other state-of-the-art algorithms,\nnamely the Random Forest and Elastic Net, and clearly outperforms these if\ninteractions are present. The performance of these algorithms is comparable if\nno interactions are present. Further, we show that our new algorithm is\napplicable to real data by comparing the performance of the three algorithms on\na dataset of rheumatoid arthritis cases and healthy controls. As our new\nalgorithm is not only applicable to biological/genetic data but to all datasets\nwith discrete features, it may have practical implications in other\napplications as well, and we made our method available as an R package.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 10:23:30 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Gola", "Damian", ""], ["K\u00f6nig", "Inke R.", ""]]}, {"id": "1901.08817", "submitter": "Cheng Wang", "authors": "Cheng Wang, Mathias Niepert", "title": "State-Regularized Recurrent Neural Networks", "comments": "to appear at ICML2019, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a widely used class of neural architectures.\nThey have, however, two shortcomings. First, it is difficult to understand what\nexactly they learn. Second, they tend to work poorly on sequences requiring\nlong-term memorization, despite having this capacity in principle. We aim to\naddress both shortcomings with a class of recurrent networks that use a\nstochastic state transition mechanism between cell applications. This\nmechanism, which we term state-regularization, makes RNNs transition between a\nfinite set of learnable states. We evaluate state-regularized RNNs on (1)\nregular languages for the purpose of automata extraction; (2) nonregular\nlanguages such as balanced parentheses, palindromes, and the copy task where\nexternal memory is required; and (3) real-word sequence learning tasks for\nsentiment analysis, visual object recognition, and language modeling. We show\nthat state-regularization (a) simplifies the extraction of finite state\nautomata modeling an RNN's state transition dynamics; (b) forces RNNs to\noperate more like automata with external memory and less like finite state\nmachines; (c) makes RNNs have better interpretability and explainability.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 10:28:44 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 07:54:18 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Wang", "Cheng", ""], ["Niepert", "Mathias", ""]]}, {"id": "1901.08827", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos and Marcin Majak", "title": "Bayes metaclassifier and Soft-confusion-matrix classifier in the task of\n  multi-label classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper was to compare soft confusion matrix approach and Bayes\nmetaclassifier under the multi-label classification framework. Although the\nmethods were successfully applied under the multi-label classification\nframework, they have not been compared directly thus far. Such comparison is of\nvital importance because both methods are quite similar as they are both based\non the concept of randomized reference classifier. Since both algorithms were\ndesigned to deal with single-label problems, they are combined with the\nproblem-transformation approach to multi-label classification. Present study\nincluded 29 benchmark datasets and four different base classifiers. The\nalgorithms were compared in terms of 11 quality criteria and the results were\nsubjected to statistical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 11:02:00 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Trajdos", "Pawel", ""], ["Majak", "Marcin", ""]]}, {"id": "1901.08846", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Kun Xu, Chao Du, Ning Chen, Jun Zhu", "title": "Improving Adversarial Robustness via Promoting Ensemble Diversity", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep neural networks have achieved significant progress on various\ntasks, often enhanced by model ensemble, existing high-performance models can\nbe vulnerable to adversarial attacks. Many efforts have been devoted to\nenhancing the robustness of individual networks and then constructing a\nstraightforward ensemble, e.g., by directly averaging the outputs, which\nignores the interaction among networks. This paper presents a new method that\nexplores the interaction among individual networks to improve robustness for\nensemble models. Technically, we define a new notion of ensemble diversity in\nthe adversarial setting as the diversity among non-maximal predictions of\nindividual members, and present an adaptive diversity promoting (ADP)\nregularizer to encourage the diversity, which leads to globally better\nrobustness for the ensemble by making adversarial examples difficult to\ntransfer among individual members. Our method is computationally efficient and\ncompatible with the defense methods acting on individual networks. Empirical\nresults on various datasets verify that our method can improve adversarial\nrobustness while maintaining state-of-the-art accuracy on normal examples.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 11:57:39 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 02:43:53 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 05:49:57 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Pang", "Tianyu", ""], ["Xu", "Kun", ""], ["Du", "Chao", ""], ["Chen", "Ning", ""], ["Zhu", "Jun", ""]]}, {"id": "1901.08898", "submitter": "Xi Chen", "authors": "Xi Chen, Mike Hobson", "title": "Bayesian surrogate learning in dynamic simulator-based regression\n  problems", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of unknown values of parameters (or hidden variables, control\nvariables) that characterise a physical system often relies on the comparison\nof measured data with synthetic data produced by some numerical simulator of\nthe system as the parameter values are varied. This process often encounters\ntwo major difficulties: the generation of synthetic data for each considered\nset of parameter values can be computationally expensive if the system model is\ncomplicated; and the exploration of the parameter space can be inefficient\nand/or incomplete, a typical example being when the exploration becomes trapped\nin a local optimum of the objection function that characterises the mismatch\nbetween the measured and synthetic data. A method to address both these issues\nis presented, whereby: a surrogate model (or proxy), which emulates the\ncomputationally expensive system simulator, is constructed using deep recurrent\nnetworks (DRN); and a nested sampling (NS) algorithm is employed to perform\nefficient and robust exploration of the parameter space. The analysis is\nperformed in a Bayesian context, in which the samples characterise the full\njoint posterior distribution of the parameters, from which parameter estimates\nand uncertainties are easily derived. The proposed approach is compared with\nconventional methods in some numerical examples, for which the results\ndemonstrate that one can accelerate the parameter estimation process by at\nleast an order of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 14:57:48 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Chen", "Xi", ""], ["Hobson", "Mike", ""]]}, {"id": "1901.08907", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo", "title": "Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation", "comments": "In Proceedings of The 2019 Web Conference (WWW 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering often suffers from sparsity and cold start problems\nin real recommendation scenarios, therefore, researchers and engineers usually\nuse side information to address the issues and improve the performance of\nrecommender systems. In this paper, we consider knowledge graphs as the source\nof side information. We propose MKR, a Multi-task feature learning approach for\nKnowledge graph enhanced Recommendation. MKR is a deep end-to-end framework\nthat utilizes knowledge graph embedding task to assist recommendation task. The\ntwo tasks are associated by cross&compress units, which automatically share\nlatent features and learn high-order interactions between items in recommender\nsystems and entities in the knowledge graph. We prove that cross&compress units\nhave sufficient capability of polynomial approximation, and show that MKR is a\ngeneralized framework over several representative methods of recommender\nsystems and multi-task learning. Through extensive experiments on real-world\ndatasets, we demonstrate that MKR achieves substantial gains in movie, book,\nmusic, and news recommendation, over state-of-the-art baselines. MKR is also\nshown to be able to maintain a decent performance even if user-item\ninteractions are sparse.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 11:36:21 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Zhao", "Miao", ""], ["Li", "Wenjie", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""]]}, {"id": "1901.08910", "submitter": "Francois Belletti", "authors": "Francois Belletti, Karthik Lakshmanan, Walid Krichene, Yi-Fan Chen,\n  John Anderson", "title": "Scalable Realistic Recommendation Datasets through Fractal Expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommender System research suffers currently from a disconnect between the\nsize of academic data sets and the scale of industrial production systems. In\norder to bridge that gap we propose to generate more massive user/item\ninteraction data sets by expanding pre-existing public data sets. User/item\nincidence matrices record interactions between users and items on a given\nplatform as a large sparse matrix whose rows correspond to users and whose\ncolumns correspond to items. Our technique expands such matrices to larger\nnumbers of rows (users), columns (items) and non zero values (interactions)\nwhile preserving key higher order statistical properties. We adapt the\nKronecker Graph Theory to user/item incidence matrices and show that the\ncorresponding fractal expansions preserve the fat-tailed distributions of user\nengagements, item popularity and singular value spectra of user/item\ninteraction matrices. Preserving such properties is key to building large\nrealistic synthetic data sets which in turn can be employed reliably to\nbenchmark Recommender Systems and the systems employed to train them. We\nprovide algorithms to produce such expansions and apply them to the MovieLens\n20 million data set comprising 20 million ratings of 27K movies by 138K users.\nThe resulting expanded data set has 10 billion ratings, 864K items and 2\nmillion users in its smaller version and can be scaled up or down. A larger\nversion features 655 billion ratings, 7 million items and 17 million users.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 22:18:25 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 18:37:54 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 19:44:06 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Belletti", "Francois", ""], ["Lakshmanan", "Karthik", ""], ["Krichene", "Walid", ""], ["Chen", "Yi-Fan", ""], ["Anderson", "John", ""]]}, {"id": "1901.08925", "submitter": "Yang You", "authors": "Yang You, Liangwei Li, Baisong Guo, Weiming Wang, Cewu Lu", "title": "Combinational Q-Learning for Dou Di Zhu", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has gained a lot of attention in recent\nyears, and has been proven to be able to play Atari games and Go at or above\nhuman levels. However, those games are assumed to have a small fixed number of\nactions and could be trained with a simple CNN network. In this paper, we study\na special class of Asian popular card games called Dou Di Zhu, in which two\nadversarial groups of agents must consider numerous card combinations at each\ntime step, leading to huge number of actions. We propose a novel method to\nhandle combinatorial actions, which we call combinational Q-learning (CQL). We\nemploy a two-stage network to reduce action space and also leverage\norder-invariant max-pooling operations to extract relationships between\nprimitive actions. Results show that our method prevails over state-of-the art\nmethods like naive Q-learning and A3C. We develop an easy-to-use card game\nenvironments and train all agents adversarially from sractch, with only\nknowledge of game rules and verify that our agents are comparative to humans.\nOur code to reproduce all reported results will be available online.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 08:28:04 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 14:03:30 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["You", "Yang", ""], ["Li", "Liangwei", ""], ["Guo", "Baisong", ""], ["Wang", "Weiming", ""], ["Lu", "Cewu", ""]]}, {"id": "1901.08930", "submitter": "Shubhomoy Das", "authors": "Shubhomoy Das, Md Rakibul Islam, Nitthilan Kannappan Jayakodi,\n  Janardhan Rao Doppa", "title": "Active Anomaly Detection via Ensembles: Insights, Algorithms, and\n  Interpretability", "comments": "47 pages including appendix; code is available at\n  https://github.com/shubhomoydas/ad_examples. arXiv admin note: substantial\n  text overlap with arXiv:1809.06477", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection (AD) task corresponds to identifying the true anomalies\nfrom a given set of data instances. AD algorithms score the data instances and\nproduce a ranked list of candidate anomalies, which are then analyzed by a\nhuman to discover the true anomalies. However, this process can be laborious\nfor the human analyst when the number of false-positives is very high.\nTherefore, in many real-world AD applications including computer security and\nfraud prevention, the anomaly detector must be configurable by the human\nanalyst to minimize the effort on false positives.\n  In this paper, we study the problem of active learning to automatically tune\nensemble of anomaly detectors to maximize the number of true anomalies\ndiscovered. We make four main contributions towards this goal. First, we\npresent an important insight that explains the practical successes of AD\nensembles and how ensembles are naturally suited for active learning. Second,\nwe present several algorithms for active learning with tree-based AD ensembles.\nThese algorithms help us to improve the diversity of discovered anomalies,\ngenerate rule sets for improved interpretability of anomalous instances, and\nadapt to streaming data settings in a principled manner. Third, we present a\nnovel algorithm called GLocalized Anomaly Detection (GLAD) for active learning\nwith generic AD ensembles. GLAD allows end-users to retain the use of simple\nand understandable global anomaly detectors by automatically learning their\nlocal relevance to specific data instances using label feedback. Fourth, we\npresent extensive experiments to evaluate our insights and algorithms. Our\nresults show that in addition to discovering significantly more anomalies than\nstate-of-the-art unsupervised baselines, our active learning algorithms under\nthe streaming-data setup are competitive with the batch setup.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:41:11 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Das", "Shubhomoy", ""], ["Islam", "Md Rakibul", ""], ["Jayakodi", "Nitthilan Kannappan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "1901.08933", "submitter": "Shikun Liu", "authors": "Shikun Liu, Andrew J. Davison, Edward Johns", "title": "Self-Supervised Generalisation with Meta Auxiliary Learning", "comments": "Published at Conference on Neural Information Processing Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with auxiliary tasks can improve the ability of a primary task to\ngeneralise. However, this comes at the cost of manually labelling auxiliary\ndata. We propose a new method which automatically learns appropriate labels for\nan auxiliary task, such that any supervised learning task can be improved\nwithout requiring access to any further data. The approach is to train two\nneural networks: a label-generation network to predict the auxiliary labels,\nand a multi-task network to train the primary task alongside the auxiliary\ntask. The loss for the label-generation network incorporates the loss of the\nmulti-task network, and so this interaction between the two networks can be\nseen as a form of meta learning with a double gradient. We show that our\nproposed method, Meta AuXiliary Learning (MAXL), outperforms single-task\nlearning on 7 image datasets, without requiring any additional data. We also\nshow that MAXL outperforms several other baselines for generating auxiliary\nlabels, and is even competitive when compared with human-defined auxiliary\nlabels. The self-supervised nature of our method leads to a promising new\ndirection towards automated generalisation. Source code can be found at\nhttps://github.com/lorenmt/maxl.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 15:46:59 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:58:15 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 20:37:33 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Liu", "Shikun", ""], ["Davison", "Andrew J.", ""], ["Johns", "Edward", ""]]}, {"id": "1901.08949", "submitter": "Fran\\c{c}ois-Pierre Paty", "authors": "Fran\\c{c}ois-Pierre Paty and Marco Cuturi", "title": "Subspace Robust Wasserstein Distances", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:5072-5081, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making sense of Wasserstein distances between discrete measures in\nhigh-dimensional settings remains a challenge. Recent work has advocated a\ntwo-step approach to improve robustness and facilitate the computation of\noptimal transport, using for instance projections on random real lines, or a\npreliminary quantization of the measures to reduce the size of their support.\nWe propose in this work a \"max-min\" robust variant of the Wasserstein distance\nby considering the maximal possible distance that can be realized between two\nmeasures, assuming they can be projected orthogonally on a lower\n$k$-dimensional subspace. Alternatively, we show that the corresponding\n\"min-max\" OT problem has a tight convex relaxation which can be cast as that of\nfinding an optimal transport plan with a low transportation cost, where the\ncost is alternatively defined as the sum of the $k$ largest eigenvalues of the\nsecond order moment matrix of the displacements (or matchings) corresponding to\nthat plan (the usual OT definition only considers the trace of that matrix). We\nshow that both quantities inherit several favorable properties from the OT\ngeometry. We propose two algorithms to compute the latter formulation using\nentropic regularization, and illustrate the interest of this approach\nempirically.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 16:10:02 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 23:34:46 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2019 18:37:39 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 07:45:01 GMT"}, {"version": "v5", "created": "Mon, 2 Sep 2019 13:43:16 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Paty", "Fran\u00e7ois-Pierre", ""], ["Cuturi", "Marco", ""]]}, {"id": "1901.08958", "submitter": "Zhishen Huang", "authors": "Zhishen Huang, Stephen Becker", "title": "Perturbed Proximal Descent to Escape Saddle Points for Non-convex and\n  Non-smooth Objective Functions", "comments": "arXiv admin note: text overlap with arXiv:1703.00887 by other authors", "journal-ref": "INNS Big Data and Deep Learning 2019 (Sestri Levante, Genova,\n  Italy 16-18 April 2019)", "doi": "10.1007/978-3-030-16841-4_7", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding local minimizers in non-convex and\nnon-smooth optimization. Under the assumption of strict saddle points, positive\nresults have been derived for first-order methods. We present the first known\nresults for the non-smooth case, which requires different analysis and a\ndifferent algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 18:58:12 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Huang", "Zhishen", ""], ["Becker", "Stephen", ""]]}, {"id": "1901.08969", "submitter": "Joao Reis", "authors": "Jo\\~ao Reis and Gil Gon\\c{c}alves", "title": "A Zero-Shot Learning application in Deep Drawing process using\n  Hyper-Process Model", "comments": "25 pages, 8 figures, 2 tables and submitted to ACM Transactions on\n  Intelligent Systems and Technology. arXiv admin note: text overlap with\n  arXiv:1810.10330", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the consequences of passing from mass production to mass customization\nparadigm in the nowadays industrialized world is the need to increase\nflexibility and responsiveness of manufacturing companies. The high-mix /\nlow-volume production forces constant accommodations of unknown product\nvariants, which ultimately leads to high periods of machine calibration. The\ndifficulty related with machine calibration is that experience is required\ntogether with a set of experiments to meet the final product quality.\nUnfortunately, all possible combinations of machine parameters is so high that\nis difficult to build empirical knowledge. Due to this fact, normally trial and\nerror approaches are taken making one-of-a-kind products not viable. Therefore,\na Zero-Shot Learning (ZSL) based approach called hyper-process model (HPM) to\nlearn the relation among multiple tasks is used as a way to shorten the\ncalibration phase. Assuming each product variant is a task to solve, first, a\nshape analysis on data to learn common modes of deformation between tasks is\nmade, and secondly, a mapping between these modes and task descriptions is\nperformed. Ultimately, the present work has two main contributions: 1)\nFormulation of an industrial problem into a ZSL setting where new process\nmodels can be generated for process optimization and 2) the definition of a\nregression problem in the domain of ZSL. For that purpose, a 2-d deep drawing\nsimulated process was used based on data collected from the Abaqus simulator,\nwhere a significant number of process models were collected to test the\neffectiveness of the approach. The obtained results show that is possible to\nlearn new tasks without any available data (both labeled and unlabeled) by\nleveraging information about already existing tasks, allowing to speed up the\ncalibration phase and make a quicker integration of new products into\nmanufacturing systems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 11:35:37 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Reis", "Jo\u00e3o", ""], ["Gon\u00e7alves", "Gil", ""]]}, {"id": "1901.08974", "submitter": "Amit Moscovich", "authors": "Amit Moscovich, Saharon Rosset", "title": "On the cross-validation bias due to unsupervised pre-processing", "comments": "31 pages, 6 figures, 1 table. New sections: (4.2.) Experiments on a\n  real dataset; (6.) Potential impact on model selection; (7.1.) Upper bounds\n  based on stability arguments. Updated Fig. 1. with larger sample sizes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-validation is the de facto standard for predictive model evaluation and\nselection. In proper use, it provides an unbiased estimate of a model's\npredictive performance. However, data sets often undergo various forms of\ndata-dependent preprocessing, such as mean-centering, rescaling, dimensionality\nreduction, and outlier removal. It is often believed that such preprocessing\nstages, if done in an unsupervised manner (that does not incorporate the class\nlabels or response values) are generally safe to do prior to cross-validation.\n  In this paper, we study three commonly-practiced preprocessing procedures\nprior to a regression analysis: (i) variance-based feature selection; (ii)\ngrouping of rare categorical features; and (iii) feature rescaling. We\ndemonstrate that unsupervised preprocessing can, in fact, introduce a\nsubstantial bias into cross-validation estimates and potentially hurt model\nselection. This bias may be either positive or negative and its exact magnitude\ndepends on all the parameters of the problem in an intricate manner. Further\nresearch is needed to understand the real-world impact of this bias across\ndifferent application domains, particularly when dealing with small sample\nsizes and high-dimensional data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 16:43:04 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 20:20:43 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 04:19:30 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 18:42:39 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Moscovich", "Amit", ""], ["Rosset", "Saharon", ""]]}, {"id": "1901.08987", "submitter": "Dar Gilboa", "authors": "Dar Gilboa, Bo Chang, Minmin Chen, Greg Yang, Samuel S. Schoenholz, Ed\n  H. Chi, Jeffrey Pennington", "title": "Dynamical Isometry and a Mean Field Theory of LSTMs and GRUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training recurrent neural networks (RNNs) on long sequence tasks is plagued\nwith difficulties arising from the exponential explosion or vanishing of\nsignals as they propagate forward or backward through the network. Many\ntechniques have been proposed to ameliorate these issues, including various\nalgorithmic and architectural modifications. Two of the most successful RNN\narchitectures, the LSTM and the GRU, do exhibit modest improvements over\nvanilla RNN cells, but they still suffer from instabilities when trained on\nvery long sequences. In this work, we develop a mean field theory of signal\npropagation in LSTMs and GRUs that enables us to calculate the time scales for\nsignal propagation as well as the spectral properties of the state-to-state\nJacobians. By optimizing these quantities in terms of the initialization\nhyperparameters, we derive a novel initialization scheme that eliminates or\nreduces training instabilities. We demonstrate the efficacy of our\ninitialization scheme on multiple sequence tasks, on which it enables\nsuccessful training while a standard initialization either fails completely or\nis orders of magnitude slower. We also observe a beneficial effect on\ngeneralization performance using this new initialization.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 17:05:54 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:10:22 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Gilboa", "Dar", ""], ["Chang", "Bo", ""], ["Chen", "Minmin", ""], ["Yang", "Greg", ""], ["Schoenholz", "Samuel S.", ""], ["Chi", "Ed H.", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "1901.08991", "submitter": "Luis Armando P\\'erez Rey", "authors": "Luis A. P\\'erez Rey, Vlado Menkovski, Jacobus W. Portegies", "title": "Diffusion Variational Autoencoders", "comments": "10 pages, 8 figures Added an appendix with derivation of asymptotic\n  expansion of KL divergence for heat kernel on arbitrary Riemannian manifolds,\n  and an appendix with new experiments on binarized MNIST. Added a previously\n  missing factor in the asymptotic expansion of the heat kernel and corrected a\n  coefficient in asymptotic expansion KL divergence; further minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard Variational Autoencoder, with a Euclidean latent space, is\nstructurally incapable of capturing topological properties of certain datasets.\nTo remove topological obstructions, we introduce Diffusion Variational\nAutoencoders with arbitrary manifolds as a latent space. A Diffusion\nVariational Autoencoder uses transition kernels of Brownian motion on the\nmanifold. In particular, it uses properties of the Brownian motion to implement\nthe reparametrization trick and fast approximations to the KL divergence. We\nshow that the Diffusion Variational Autoencoder is capable of capturing\ntopological properties of synthetic datasets. Additionally, we train MNIST on\nspheres, tori, projective spaces, SO(3), and a torus embedded in R3. Although a\nnatural dataset like MNIST does not have latent variables with a clear-cut\ntopological structure, training it on a manifold can still highlight\ntopological and geometrical properties.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 17:10:25 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 09:10:12 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Rey", "Luis A. P\u00e9rez", ""], ["Menkovski", "Vlado", ""], ["Portegies", "Jacobus W.", ""]]}, {"id": "1901.09006", "submitter": "Martin Engelcke", "authors": "Edward Wagstaff, Fabian B. Fuchs, Martin Engelcke, Ingmar Posner,\n  Michael Osborne", "title": "On the Limitations of Representing Functions on Sets", "comments": "Published at the International Conference on Machine Learning (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on the representation of functions on sets has considered the use\nof summation in a latent space to enforce permutation invariance. In\nparticular, it has been conjectured that the dimension of this latent space may\nremain fixed as the cardinality of the sets under consideration increases.\nHowever, we demonstrate that the analysis leading to this conjecture requires\nmappings which are highly discontinuous and argue that this is only of limited\npractical use. Motivated by this observation, we prove that an implementation\nof this model via continuous mappings (as provided by e.g. neural networks or\nGaussian processes) actually imposes a constraint on the dimensionality of the\nlatent space. Practical universal function representation for set inputs can\nonly be achieved with a latent dimension at least the size of the maximum\nnumber of input elements.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 18:11:52 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 10:12:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wagstaff", "Edward", ""], ["Fuchs", "Fabian B.", ""], ["Engelcke", "Martin", ""], ["Posner", "Ingmar", ""], ["Osborne", "Michael", ""]]}, {"id": "1901.09018", "submitter": "Simon Du", "authors": "Simon S. Du, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal, Miroslav\n  Dud\\'ik, John Langford", "title": "Provably efficient RL with Rich Observations via Latent State Decoding", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the exploration problem in episodic MDPs with rich observations\ngenerated from a small number of latent states. Under certain identifiability\nassumptions, we demonstrate how to estimate a mapping from the observations to\nlatent states inductively through a sequence of regression and clustering\nsteps---where previously decoded latent states provide labels for later\nregression problems---and use it to construct good exploration policies. We\nprovide finite-sample guarantees on the quality of the learned state decoding\nfunction and exploration policies, and complement our theory with an empirical\nevaluation on a class of hard exploration problems. Our method exponentially\nimproves over $Q$-learning with na\\\"ive exploration, even when $Q$-learning has\ncheating access to latent states.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 18:41:27 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 22:59:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Du", "Simon S.", ""], ["Krishnamurthy", "Akshay", ""], ["Jiang", "Nan", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Langford", "John", ""]]}, {"id": "1901.09021", "submitter": "David Rolnick", "authors": "Boris Hanin, David Rolnick", "title": "Complexity of Linear Regions in Deep Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the expressivity of a neural network depends on its\narchitecture, with deeper networks expressing more complex functions. In the\ncase of networks that compute piecewise linear functions, such as those with\nReLU activation, the number of distinct linear regions is a natural measure of\nexpressivity. It is possible to construct networks with merely a single region,\nor for which the number of linear regions grows exponentially with depth; it is\nnot clear where within this range most networks fall in practice, either before\nor after training. In this paper, we provide a mathematical framework to count\nthe number of linear regions of a piecewise linear network and measure the\nvolume of the boundaries between these regions. In particular, we prove that\nfor networks at initialization, the average number of regions along any\none-dimensional subspace grows linearly in the total number of neurons, far\nbelow the exponential upper bound. We also find that the average distance to\nthe nearest region boundary at initialization scales like the inverse of the\nnumber of neurons. Our theory suggests that, even after training, the number of\nlinear regions is far below exponential, an intuition that matches our\nempirical observations. We conclude that the practical expressivity of neural\nnetworks is likely far below that of the theoretical maximum, and that this gap\ncan be quantified.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 18:43:10 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 17:12:14 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Hanin", "Boris", ""], ["Rolnick", "David", ""]]}, {"id": "1901.09024", "submitter": "Seunghoon Hong", "authors": "Dingdong Yang, Seunghoon Hong, Yunseok Jang, Tianchen Zhao, Honglak\n  Lee", "title": "Diversity-Sensitive Conditional Generative Adversarial Networks", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet highly effective method that addresses the\nmode-collapse problem in the Conditional Generative Adversarial Network (cGAN).\nAlthough conditional distributions are multi-modal (i.e., having many modes) in\npractice, most cGAN approaches tend to learn an overly simplified distribution\nwhere an input is always mapped to a single output regardless of variations in\nlatent code. To address such issue, we propose to explicitly regularize the\ngenerator to produce diverse outputs depending on latent codes. The proposed\nregularization is simple, general, and can be easily integrated into most\nconditional GAN objectives. Additionally, explicit regularization on generator\nallows our method to control a balance between visual quality and diversity. We\ndemonstrate the effectiveness of our method on three conditional generation\ntasks: image-to-image translation, image inpainting, and future video\nprediction. We show that simple addition of our regularization to existing\nmodels leads to surprisingly diverse generations, substantially outperforming\nthe previous approaches for multi-modal conditional generation specifically\ndesigned in each individual task.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 18:49:07 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Yang", "Dingdong", ""], ["Hong", "Seunghoon", ""], ["Jang", "Yunseok", ""], ["Zhao", "Tianchen", ""], ["Lee", "Honglak", ""]]}, {"id": "1901.09035", "submitter": "Quanshi Zhang", "authors": "Yinpeng Dong and Fan Bao and Hang Su and Jun Zhu", "title": "Towards Interpretable Deep Neural Networks by Leveraging Adversarial\n  Examples", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sometimes it is not enough for a DNN to produce an outcome. For example, in\napplications such as healthcare, users need to understand the rationale of the\ndecisions. Therefore, it is imperative to develop algorithms to learn models\nwith good interpretability (Doshi-Velez 2017). An important factor that leads\nto the lack of interpretability of DNNs is the ambiguity of neurons, where a\nneuron may fire for various unrelated concepts. This work aims to increase the\ninterpretability of DNNs on the whole image space by reducing the ambiguity of\nneurons. In this paper, we make the following contributions:\n  1) We propose a metric to evaluate the consistency level of neurons in a\nnetwork quantitatively.\n  2) We find that the learned features of neurons are ambiguous by leveraging\nadversarial examples.\n  3) We propose to improve the consistency of neurons on adversarial example\nsubset by an adversarial training algorithm with a consistent loss.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 03:36:58 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Dong", "Yinpeng", ""], ["Bao", "Fan", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1901.09036", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Vasilis Syrgkanis", "title": "Orthogonal Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide non-asymptotic excess risk guarantees for statistical learning in\na setting where the population risk with respect to which we evaluate the\ntarget parameter depends on an unknown nuisance parameter that must be\nestimated from data. We analyze a two-stage sample splitting meta-algorithm\nthat takes as input two arbitrary estimation algorithms: one for the target\nparameter and one for the nuisance parameter. We show that if the population\nrisk satisfies a condition called Neyman orthogonality, the impact of the\nnuisance estimation error on the excess risk bound achieved by the\nmeta-algorithm is of second order. Our theorem is agnostic to the particular\nalgorithms used for the target and nuisance and only makes an assumption on\ntheir individual performance. This enables the use of a plethora of existing\nresults from statistical learning and machine learning to give new guarantees\nfor learning with a nuisance component. Moreover, by focusing on excess risk\nrather than parameter estimation, we can give guarantees under weaker\nassumptions than in previous works and accommodate settings in which the target\nparameter belongs to a complex nonparametric class. We provide conditions on\nthe metric entropy of the nuisance and target classes such that oracle\nrates---rates of the same order as if we knew the nuisance parameter---are\nachieved. We also derive new rates for specific estimation algorithms such as\nvariance-penalized empirical risk minimization, neural network estimation and\nsparse high-dimensional linear model estimation. We highlight the applicability\nof our results in four settings of central importance: 1) heterogeneous\ntreatment effect estimation, 2) offline policy optimization, 3) domain\nadaptation, and 4) learning with missing data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 02:21:24 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 03:12:45 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 00:11:30 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Foster", "Dylan J.", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1901.09047", "submitter": "Julaiti Alafate", "authors": "Julaiti Alafate and Yoav Freund", "title": "Faster Boosting with Smaller Memory", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art implementations of boosting, such as XGBoost and LightGBM,\ncan process large training sets extremely fast. However, this performance\nrequires that the memory size is sufficient to hold a 2-3 multiple of the\ntraining set size. This paper presents an alternative approach to implementing\nthe boosted trees, which achieves a significant speedup over XGBoost and\nLightGBM, especially when the memory size is small. This is achieved using a\ncombination of three techniques: early stopping, effective sample size, and\nstratified sampling. Our experiments demonstrate a 10-100 speedup over XGBoost\nwhen the training data is too large to fit in memory.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 19:04:42 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 22:15:06 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 17:20:07 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Alafate", "Julaiti", ""], ["Freund", "Yoav", ""]]}, {"id": "1901.09054", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Joachim Denzler", "title": "Deep Learning on Small Datasets without Pre-Training using Cosine Loss", "comments": "Presented at WACV 2020", "journal-ref": "2020 IEEE Winter Conference on Applications of Computer Vision\n  (WACV), Snowmass Village, CO, USA, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two things seem to be indisputable in the contemporary deep learning\ndiscourse: 1. The categorical cross-entropy loss after softmax activation is\nthe method of choice for classification. 2. Training a CNN classifier from\nscratch on small datasets does not work well. In contrast to this, we show that\nthe cosine loss function provides significantly better performance than\ncross-entropy on datasets with only a handful of samples per class. For\nexample, the accuracy achieved on the CUB-200-2011 dataset without pre-training\nis by 30% higher than with the cross-entropy loss. Further experiments on other\npopular datasets confirm our findings. Moreover, we demonstrate that\nintegrating prior knowledge in the form of class hierarchies is straightforward\nwith the cosine loss and improves classification performance further.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 19:13:03 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 15:15:46 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["Denzler", "Joachim", ""]]}, {"id": "1901.09060", "submitter": "Roy Adams", "authors": "Roy Adams, Yuelong Ji, Xiaobin Wang, Suchi Saria", "title": "Learning Models from Data with Measurement Error: Tackling\n  Underreporting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurement error in observational datasets can lead to systematic bias in\ninferences based on these datasets. As studies based on observational data are\nincreasingly used to inform decisions with real-world impact, it is critical\nthat we develop a robust set of techniques for analyzing and adjusting for\nthese biases. In this paper we present a method for estimating the distribution\nof an outcome given a binary exposure that is subject to underreporting. Our\nmethod is based on a missing data view of the measurement error problem, where\nthe true exposure is treated as a latent variable that is marginalized out of a\njoint model. We prove three different conditions under which the outcome\ndistribution can still be identified from data containing only error-prone\nobservations of the exposure. We demonstrate this method on synthetic data and\nanalyze its sensitivity to near violations of the identifiability conditions.\nFinally, we use this method to estimate the effects of maternal smoking and\nopioid use during pregnancy on childhood obesity, two import problems from\npublic health. Using the proposed method, we estimate these effects using only\nsubject-reported drug use data and substantially refine the range of estimates\ngenerated by a sensitivity analysis-based approach. Further, the estimates\nproduced by our method are consistent with existing literature on both the\neffects of maternal smoking and the rate at which subjects underreport smoking.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 19:45:18 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Adams", "Roy", ""], ["Ji", "Yuelong", ""], ["Wang", "Xiaobin", ""], ["Saria", "Suchi", ""]]}, {"id": "1901.09068", "submitter": "Zhenxun Zhuang", "authors": "Zhenxun Zhuang, Ashok Cutkosky, Francesco Orabona", "title": "Surrogate Losses for Online Learning of Stepsizes in Stochastic\n  Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) has played a central role in machine\nlearning. However, it requires a carefully hand-picked stepsize for fast\nconvergence, which is notoriously tedious and time-consuming to tune. Over the\nlast several years, a plethora of adaptive gradient-based algorithms have\nemerged to ameliorate this problem. They have proved efficient in reducing the\nlabor of tuning in practice, but many of them lack theoretic guarantees even in\nthe convex setting. In this paper, we propose new surrogate losses to cast the\nproblem of learning the optimal stepsizes for the stochastic optimization of a\nnon-convex smooth objective function onto an online convex optimization\nproblem. This allows the use of no-regret online algorithms to compute optimal\nstepsizes on the fly. In turn, this results in a SGD algorithm with self-tuned\nstepsizes that guarantees convergence rates that are automatically adaptive to\nthe level of noise.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 20:17:39 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:30:18 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Zhuang", "Zhenxun", ""], ["Cutkosky", "Ashok", ""], ["Orabona", "Francesco", ""]]}, {"id": "1901.09069", "submitter": "Felipe Almeida", "authors": "Felipe Almeida and Geraldo Xex\\'eo", "title": "Word Embeddings: A Survey", "comments": "10 pages, 2 tables, 1 image", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work lists and describes the main recent strategies for building\nfixed-length, dense and distributed representations for words, based on the\ndistributional hypothesis. These representations are now commonly called word\nembeddings and, in addition to encoding surprisingly good syntactic and\nsemantic information, have been proven useful as extra features in many\ndownstream NLP tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 20:31:02 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Almeida", "Felipe", ""], ["Xex\u00e9o", "Geraldo", ""]]}, {"id": "1901.09078", "submitter": "David van Dijk", "authors": "David van Dijk, Daniel Burkhardt, Matthew Amodio, Alex Tong, Guy Wolf,\n  Smita Krishnaswamy", "title": "Finding Archetypal Spaces Using Neural Networks", "comments": "9 pages, 10 figures, to be presented at IEEE Big Data 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archetypal analysis is a data decomposition method that describes each\nobservation in a dataset as a convex combination of \"pure types\" or archetypes.\nThese archetypes represent extrema of a data space in which there is a\ntrade-off between features, such as in biology where different combinations of\ntraits provide optimal fitness for different environments. Existing methods for\narchetypal analysis work well when a linear relationship exists between the\nfeature space and the archetypal space. However, such methods are not\napplicable to systems where the feature space is generated non-linearly from\nthe combination of archetypes, such as in biological systems or image\ntransformations. Here, we propose a reformulation of the problem such that the\ngoal is to learn a non-linear transformation of the data into a latent\narchetypal space. To solve this problem, we introduce Archetypal Analysis\nnetwork (AAnet), which is a deep neural network framework for learning and\ngenerating from a latent archetypal representation of data. We demonstrate\nstate-of-the-art recovery of ground-truth archetypes in non-linear data\ndomains, show AAnet can generate from data geometry rather than from data\ndensity, and use AAnet to identify biologically meaningful archetypes in\nsingle-cell gene expression data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 20:44:25 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 19:41:12 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["van Dijk", "David", ""], ["Burkhardt", "Daniel", ""], ["Amodio", "Matthew", ""], ["Tong", "Alex", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1901.09082", "submitter": "Arjun Pakrashi", "authors": "Arjun Pakrashi, Bidyut B. Chaudhuri", "title": "A Kalman filtering induced heuristic optimization based partitional data\n  clustering", "comments": null, "journal-ref": null, "doi": "10.1016/j.ins.2016.07.057", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have regained momentum with recent popularity of data\nmining and knowledge discovery approaches. To obtain good clustering in\nreasonable amount of time, various meta-heuristic approaches and their\nhybridization, sometimes with K-Means technique, have been employed. A Kalman\nFiltering based heuristic approach called Heuristic Kalman Algorithm (HKA) has\nbeen proposed a few years ago, which may be used for optimizing an objective\nfunction in data/feature space. In this paper at first HKA is employed in\npartitional data clustering. Then an improved approach named HKA-K is proposed,\nwhich combines the benefits of global exploration of HKA and the fast\nconvergence of K-Means method. Implemented and tested on several datasets from\nUCI machine learning repository, the results obtained by HKA-K were compared\nwith other hybrid meta-heuristic clustering approaches. It is shown that HKA-K\nis atleast as good as and often better than the other compared algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 21:09:35 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Pakrashi", "Arjun", ""], ["Chaudhuri", "Bidyut B.", ""]]}, {"id": "1901.09085", "submitter": "Sebastian Goldt", "authors": "Sebastian Goldt, Madhu S. Advani, Andrew M. Saxe, Florent Krzakala,\n  Lenka Zdeborov\\'a", "title": "Generalisation dynamics of online learning in over-parameterised neural\n  networks", "comments": "25 pages, 13 figures", "journal-ref": "Presented at the ICML 2019 Workshop on Theoretical Physics for\n  Deep Learning", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve stellar generalisation on a variety of problems,\ndespite often being large enough to easily fit all their training data. Here we\nstudy the generalisation dynamics of two-layer neural networks in a\nteacher-student setup, where one network, the student, is trained using\nstochastic gradient descent (SGD) on data generated by another network, called\nthe teacher. We show how for this problem, the dynamics of SGD are captured by\na set of differential equations. In particular, we demonstrate analytically\nthat the generalisation error of the student increases linearly with the\nnetwork size, with other relevant parameters held constant. Our results\nindicate that achieving good generalisation in neural networks depends on the\ninterplay of at least the algorithm, its learning rate, the model architecture,\nand the data set.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 21:13:15 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Goldt", "Sebastian", ""], ["Advani", "Madhu S.", ""], ["Saxe", "Andrew M.", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1901.09087", "submitter": "Raphael Meyer", "authors": "Raphael Arkady Meyer, Jean Honorio", "title": "Optimality Implies Kernel Sum Classifiers are Statistically Efficient", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel combination of optimization tools with learning theory\nbounds in order to analyze the sample complexity of optimal kernel sum\nclassifiers. This contrasts the typical learning theoretic results which hold\nfor all (potentially suboptimal) classifiers. Our work also justifies\nassumptions made in prior work on multiple kernel learning. As a byproduct of\nour analysis, we also provide a new form of Rademacher complexity for\nhypothesis classes containing only optimal classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 21:20:17 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 23:41:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Meyer", "Raphael Arkady", ""], ["Honorio", "Jean", ""]]}, {"id": "1901.09097", "submitter": "Hesham Mohamed Eraqi", "authors": "Hesham M. Eraqi, Yehya Abouelnaga, Mohamed H. Saad, Mohamed N.\n  Moustafa", "title": "Driver Distraction Identification with an Ensemble of Convolutional\n  Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1706.09498", "journal-ref": "Journal of Advanced Transportation, Machine Learning in\n  Transportation (MLT) Issue, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Health Organization (WHO) reported 1.25 million deaths yearly due\nto road traffic accidents worldwide and the number has been continuously\nincreasing over the last few years. Nearly fifth of these accidents are caused\nby distracted drivers. Existing work of distracted driver detection is\nconcerned with a small set of distractions (mostly, cell phone usage).\nUnreliable ad-hoc methods are often used.In this paper, we present the first\npublicly available dataset for driver distraction identification with more\ndistraction postures than existing alternatives. In addition, we propose a\nreliable deep learning-based solution that achieves a 90% accuracy. The system\nconsists of a genetically-weighted ensemble of convolutional neural networks,\nwe show that a weighted ensemble of classifiers using a genetic algorithm\nyields in a better classification confidence. We also study the effect of\ndifferent visual elements in distraction detection by means of face and hand\nlocalizations, and skin segmentation. Finally, we present a thinned version of\nour ensemble that could achieve 84.64% classification accuracy and operate in a\nreal-time environment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 10:47:00 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Eraqi", "Hesham M.", ""], ["Abouelnaga", "Yehya", ""], ["Saad", "Mohamed H.", ""], ["Moustafa", "Mohamed N.", ""]]}, {"id": "1901.09100", "submitter": "Uri Hadar", "authors": "Uri Hadar, Jingbo Liu, Yury Polyanskiy and Ofer Shayevitz", "title": "Communication Complexity of Estimating Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the communication complexity of the following distributed\nestimation problem. Alice and Bob observe infinitely many iid copies of\n$\\rho$-correlated unit-variance (Gaussian or $\\pm1$ binary) random variables,\nwith unknown $\\rho\\in[-1,1]$. By interactively exchanging $k$ bits, Bob wants\nto produce an estimate $\\hat\\rho$ of $\\rho$. We show that the best possible\nperformance (optimized over interaction protocol $\\Pi$ and estimator $\\hat\n\\rho$) satisfies $\\inf_{\\Pi \\hat\\rho}\\sup_\\rho \\mathbb{E} [|\\rho-\\hat\\rho|^2] =\n\\tfrac{1}{k} (\\frac{1}{2 \\ln 2} + o(1))$. Curiously, the number of samples in\nour achievability scheme is exponential in $k$; by contrast, a naive scheme\nexchanging $k$ samples achieves the same $\\Omega(1/k)$ rate but with a\nsuboptimal prefactor. Our protocol achieving optimal performance is one-way\n(non-interactive). We also prove the $\\Omega(1/k)$ bound even when $\\rho$ is\nrestricted to any small open sub-interval of $[-1,1]$ (i.e. a local minimax\nlower bound). Our proof techniques rely on symmetric strong data-processing\ninequalities and various tensorization techniques from information-theoretic\ninteractive common-randomness extraction. Our results also imply an $\\Omega(n)$\nlower bound on the information complexity of the Gap-Hamming problem, for which\nwe show a direct information-theoretic proof.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:05:20 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 10:32:05 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Hadar", "Uri", ""], ["Liu", "Jingbo", ""], ["Polyanskiy", "Yury", ""], ["Shayevitz", "Ofer", ""]]}, {"id": "1901.09108", "submitter": "Hankui Peng", "authors": "Hankui Peng, Nicos Pavlidis, Idris Eckley, and Ioannis Tsalamanis", "title": "Subspace Clustering of Very Sparse High-Dimensional Data", "comments": "2018 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of clustering collections of very short\ntexts using subspace clustering. This problem arises in many applications such\nas product categorisation, fraud detection, and sentiment analysis. The main\nchallenge lies in the fact that the vectorial representation of short texts is\nboth high-dimensional, due to the large number of unique terms in the corpus,\nand extremely sparse, as each text contains a very small number of words with\nno repetition. We propose a new, simple subspace clustering algorithm that\nrelies on linear algebra to cluster such datasets. Experimental results on\nidentifying product categories from product names obtained from the US Amazon\nwebsite indicate that the algorithm can be competitive against state-of-the-art\nclustering algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:30:20 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Peng", "Hankui", ""], ["Pavlidis", "Nicos", ""], ["Eckley", "Idris", ""], ["Tsalamanis", "Ioannis", ""]]}, {"id": "1901.09109", "submitter": "Davoud Ataee Tarzanagh", "authors": "Parvin Nazari, Davoud Ataee Tarzanagh, George Michailidis", "title": "DADAM: A Consensus-based Distributed Adaptive Gradient Method for Online\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient-based optimization methods such as \\textsc{Adagrad},\n\\textsc{Rmsprop}, and \\textsc{Adam} are widely used in solving large-scale\nmachine learning problems including deep learning. A number of schemes have\nbeen proposed in the literature aiming at parallelizing them, based on\ncommunications of peripheral nodes with a central node, but incur high\ncommunications cost. To address this issue, we develop a novel consensus-based\ndistributed adaptive moment estimation method (\\textsc{Dadam}) for online\noptimization over a decentralized network that enables data parallelization, as\nwell as decentralized computation. The method is particularly useful, since it\ncan accommodate settings where access to local data is allowed. Further, as\nestablished theoretically in this work, it can outperform centralized adaptive\nalgorithms, for certain classes of loss functions used in applications. We\nanalyze the convergence properties of the proposed algorithm and provide a\ndynamic regret bound on the convergence rate of adaptive moment estimation\nmethods in both stochastic and deterministic settings. Empirical results\ndemonstrate that \\textsc{Dadam} works also well in practice and compares\nfavorably to competing online optimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:33:49 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 23:55:07 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 22:16:29 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 17:44:18 GMT"}, {"version": "v5", "created": "Wed, 15 May 2019 21:43:09 GMT"}, {"version": "v6", "created": "Tue, 28 May 2019 21:19:55 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nazari", "Parvin", ""], ["Tarzanagh", "Davoud Ataee", ""], ["Michailidis", "George", ""]]}, {"id": "1901.09113", "submitter": "Kemal Davaslioglu", "authors": "Yi Shi, Yalin E. Sagduyu, Kemal Davaslioglu, and Jason H. Li", "title": "Generative Adversarial Networks for Black-Box API Attacks with Limited\n  Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As online systems based on machine learning are offered to public or paid\nsubscribers via application programming interfaces (APIs), they become\nvulnerable to frequent exploits and attacks. This paper studies adversarial\nmachine learning in the practical case when there are rate limitations on API\ncalls. The adversary launches an exploratory (inference) attack by querying the\nAPI of an online machine learning system (in particular, a classifier) with\ninput data samples, collecting returned labels to build up the training data,\nand training an adversarial classifier that is functionally equivalent and\nstatistically close to the target classifier. The exploratory attack with\nlimited training data is shown to fail to reliably infer the target classifier\nof a real text classifier API that is available online to the public. In\nreturn, a generative adversarial network (GAN) based on deep learning is built\nto generate synthetic training data from a limited number of real training data\nsamples, thereby extending the training data and improving the performance of\nthe inferred classifier. The exploratory attack provides the basis to launch\nthe causative attack (that aims to poison the training process) and evasion\nattack (that aims to fool the classifier into making wrong decisions) by\nselecting training and test data samples, respectively, based on the confidence\nscores obtained from the inferred classifier. These stealth attacks with small\nfootprint (using a small number of API calls) make adversarial machine learning\npractical under the realistic case with limited training data available to the\nadversary.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:56:10 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Li", "Jason H.", ""]]}, {"id": "1901.09118", "submitter": "Michael Bloodgood", "authors": "Michael Altschuler and Michael Bloodgood", "title": "Stopping Active Learning based on Predicted Change of F Measure for Text\n  Classification", "comments": "8 pages, 12 tables; published in Proceedings of the 2019 IEEE 13th\n  International Conference on Semantic Computing (ICSC), Newport Beach, CA,\n  USA, pages 47-54, January 2019", "journal-ref": "In Proceedings of the 2019 IEEE 13th International Conference on\n  Semantic Computing (ICSC), pages 47-54, Newport Beach, CA, USA, January 2019.\n  IEEE", "doi": "10.1109/ICOSC.2019.8665646", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During active learning, an effective stopping method allows users to limit\nthe number of annotations, which is cost effective. In this paper, a new\nstopping method called Predicted Change of F Measure will be introduced that\nattempts to provide the users an estimate of how much performance of the model\nis changing at each iteration. This stopping method can be applied with any\nbase learner. This method is useful for reducing the data annotation bottleneck\nencountered when building text classification systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:01:27 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 23:56:41 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Altschuler", "Michael", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1901.09126", "submitter": "Michael Bloodgood", "authors": "Garrett Beatty, Ethan Kochis and Michael Bloodgood", "title": "The Use of Unlabeled Data versus Labeled Data for Stopping Active\n  Learning for Text Classification", "comments": "8 pages, 4 figures, 3 tables; published in Proceedings of the IEEE\n  13th International Conference on Semantic Computing (ICSC), Newport Beach,\n  CA, USA, pages 287-294, January 2019", "journal-ref": "In Proceedings of the 2019 IEEE 13th International Conference on\n  Semantic Computing (ICSC), pages 287-294, Newport Beach, CA, USA, January\n  2019. IEEE", "doi": "10.1109/ICOSC.2019.8665546", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotation of training data is the major bottleneck in the creation of text\nclassification systems. Active learning is a commonly used technique to reduce\nthe amount of training data one needs to label. A crucial aspect of active\nlearning is determining when to stop labeling data. Three potential sources for\ninforming when to stop active learning are an additional labeled set of data,\nan unlabeled set of data, and the training data that is labeled during the\nprocess of active learning. To date, no one has compared and contrasted the\nadvantages and disadvantages of stopping methods based on these three\ninformation sources. We find that stopping methods that use unlabeled data are\nmore effective than methods that use labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 00:27:02 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 23:36:51 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Beatty", "Garrett", ""], ["Kochis", "Ethan", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1901.09134", "submitter": "Martin Pavlovski", "authors": "Nino Arsov, Martin Pavlovski, Ljupco Kocarev", "title": "Stacking and stability", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stacking is a general approach for combining multiple models toward greater\npredictive accuracy. It has found various application across different domains,\nensuing from its meta-learning nature. Our understanding, nevertheless, on how\nand why stacking works remains intuitive and lacking in theoretical insight. In\nthis paper, we use the stability of learning algorithms as an elemental\nanalysis framework suitable for addressing the issue. To this end, we analyze\nthe hypothesis stability of stacking, bag-stacking, and dag-stacking and\nestablish a connection between bag-stacking and weighted bagging. We show that\nthe hypothesis stability of stacking is a product of the hypothesis stability\nof each of the base models and the combiner. Moreover, in bag-stacking and\ndag-stacking, the hypothesis stability depends on the sampling strategy used to\ngenerate the training set replicates. Our findings suggest that 1) subsampling\nand bootstrap sampling improve the stability of stacking, and 2) stacking\nimproves the stability of both subbagging and bagging.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 01:16:43 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Arsov", "Nino", ""], ["Pavlovski", "Martin", ""], ["Kocarev", "Ljupco", ""]]}, {"id": "1901.09136", "submitter": "Ryan McKenna", "authors": "Ryan McKenna, Daniel Sheldon, Gerome Miklau", "title": "Graphical-model based estimation and inference for differential privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many privacy mechanisms reveal high-level information about a data\ndistribution through noisy measurements. It is common to use this information\nto estimate the answers to new queries. In this work, we provide an approach to\nsolve this estimation problem efficiently using graphical models, which is\nparticularly effective when the distribution is high-dimensional but the\nmeasurements are over low-dimensional marginals. We show that our approach is\nfar more efficient than existing estimation techniques from the privacy\nliterature and that it can improve the accuracy and scalability of many\nstate-of-the-art mechanisms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 01:24:15 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["McKenna", "Ryan", ""], ["Sheldon", "Daniel", ""], ["Miklau", "Gerome", ""]]}, {"id": "1901.09146", "submitter": "Jaeyoung Kim", "authors": "Jaeyoung Kim, Mostafa El-Kharmy and Jungwon Lee", "title": "End-to-End Multi-Task Denoising for joint SDR and PESQ Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning based on a deep neural network recently has achieved\nsubstantial improvement on speech enhancement. Denoising networks learn mapping\nfrom noisy speech to clean one directly, or to a spectrum mask which is the\nratio between clean and noisy spectra. In either case, the network is optimized\nby minimizing mean square error (MSE) between ground-truth labels and\ntime-domain or spectrum output. However, existing schemes have either of two\ncritical issues: spectrum and metric mismatches. The spectrum mismatch is a\nwell known issue that any spectrum modification after short-time Fourier\ntransform (STFT), in general, cannot be fully recovered after inverse\nshort-time Fourier transform (ISTFT). The metric mismatch is that a\nconventional MSE metric is sub-optimal to maximize our target metrics,\nsignal-to-distortion ratio (SDR) and perceptual evaluation of speech quality\n(PESQ). This paper presents a new end-to-end denoising framework with the goal\nof joint SDR and PESQ optimization. First, the network optimization is\nperformed on the time-domain signals after ISTFT to avoid spectrum mismatch.\nSecond, two loss functions which have improved correlations with SDR and PESQ\nmetrics are proposed to minimize metric mismatch. The experimental result\nshowed that the proposed denoising scheme significantly improved both SDR and\nPESQ performance over the existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 02:48:08 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 19:38:57 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Kim", "Jaeyoung", ""], ["El-Kharmy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1901.09149", "submitter": "Matthew Staib", "authors": "Matthew Staib, Sashank J. Reddi, Satyen Kale, Sanjiv Kumar, Suvrit Sra", "title": "Escaping Saddle Points with Adaptive Gradient Methods", "comments": "Update Theorem 4.1 and proof to use martingale concentration bounds,\n  i.e. matrix Freedman", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive methods such as Adam and RMSProp are widely used in deep learning\nbut are not well understood. In this paper, we seek a crisp, clean and precise\ncharacterization of their behavior in nonconvex settings. To this end, we first\nprovide a novel view of adaptive methods as preconditioned SGD, where the\npreconditioner is estimated in an online manner. By studying the preconditioner\non its own, we elucidate its purpose: it rescales the stochastic gradient noise\nto be isotropic near stationary points, which helps escape saddle points.\nFurthermore, we show that adaptive methods can efficiently estimate the\naforementioned preconditioner. By gluing together these two components, we\nprovide the first (to our knowledge) second-order convergence result for any\nadaptive method. The key insight from our analysis is that, compared to SGD,\nadaptive methods escape saddle points faster, and can converge faster overall\nto second-order stationary points.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 03:12:14 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 18:39:59 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Staib", "Matthew", ""], ["Reddi", "Sashank J.", ""], ["Kale", "Satyen", ""], ["Kumar", "Sanjiv", ""], ["Sra", "Suvrit", ""]]}, {"id": "1901.09178", "submitter": "Zhen Wang", "authors": "Zhen Wang, Yuan-Hai Shao, Lan Bai, Chun-Na Li, and Li-Ming Liu", "title": "A general model for plane-based clustering with loss function", "comments": "13 pages, 43 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3016078", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general model for plane-based clustering. The\ngeneral model contains many existing plane-based clustering methods, e.g.,\nk-plane clustering (kPC), proximal plane clustering (PPC), twin support vector\nclustering (TWSVC) and its extensions. Under this general model, one may obtain\nan appropriate clustering method for specific purpose. The general model is a\nprocedure corresponding to an optimization problem, where the optimization\nproblem minimizes the total loss of the samples. Thereinto, the loss of a\nsample derives from both within-cluster and between-cluster. In theory, the\ntermination conditions are discussed, and we prove that the general model\nterminates in a finite number of steps at a local or weak local optimal point.\nFurthermore, based on this general model, we propose a plane-based clustering\nmethod by introducing a new loss function to capture the data distribution\nprecisely. Experimental results on artificial and public available datasets\nverify the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 08:32:48 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Zhen", ""], ["Shao", "Yuan-Hai", ""], ["Bai", "Lan", ""], ["Li", "Chun-Na", ""], ["Liu", "Li-Ming", ""]]}, {"id": "1901.09181", "submitter": "Shiwei Liu", "authors": "Shiwei Liu, Decebal Constantin Mocanu, Amarsagar Reddy Ramapuram\n  Matavalam, Yulong Pei, Mykola Pechenizkiy", "title": "Sparse evolutionary Deep Learning with over one million artificial\n  neurons on commodity hardware", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) have emerged as hot topics in the research\ncommunity. Despite the success of ANNs, it is challenging to train and deploy\nmodern ANNs on commodity hardware due to the ever-increasing model size and the\nunprecedented growth in the data volumes. Particularly for microarray data, the\nvery-high dimensionality and the small number of samples make it difficult for\nmachine learning techniques to handle. Furthermore, specialized hardware such\nas Graphics Processing Unit (GPU) is expensive. Sparse neural networks are the\nleading approaches to address these challenges. However, off-the-shelf sparsity\ninducing techniques either operate from a pre-trained model or enforce the\nsparse structure via binary masks. The training efficiency of sparse neural\nnetworks cannot be obtained practically. In this paper, we introduce a\ntechnique allowing us to train truly sparse neural networks with fixed\nparameter count throughout training. Our experimental results demonstrate that\nour method can be applied directly to handle high dimensional data, while\nachieving higher accuracy than the traditional two phases approaches. Moreover,\nwe have been able to create truly sparse MultiLayer Perceptrons (MLPs) models\nwith over one million neurons and to train them on a typical laptop without\nGPU, this being way beyond what is possible with any state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 09:14:01 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 17:27:54 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 19:17:33 GMT"}, {"version": "v4", "created": "Sat, 16 Jan 2021 01:02:06 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Liu", "Shiwei", ""], ["Mocanu", "Decebal Constantin", ""], ["Matavalam", "Amarsagar Reddy Ramapuram", ""], ["Pei", "Yulong", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1901.09184", "submitter": "Chen Tessler", "authors": "Chen Tessler, Yonathan Efroni and Shie Mannor", "title": "Action Robust Reinforcement Learning and Applications in Continuous\n  Control", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A policy is said to be robust if it maximizes the reward while considering a\nbad, or even adversarial, model. In this work we formalize two new criteria of\nrobustness to action uncertainty. Specifically, we consider two scenarios in\nwhich the agent attempts to perform an action $a$, and (i) with probability\n$\\alpha$, an alternative adversarial action $\\bar a$ is taken, or (ii) an\nadversary adds a perturbation to the selected action in the case of continuous\naction space. We show that our criteria are related to common forms of\nuncertainty in robotics domains, such as the occurrence of abrupt forces, and\nsuggest algorithms in the tabular case. Building on the suggested algorithms,\nwe generalize our approach to deep reinforcement learning (DRL) and provide\nextensive experiments in the various MuJoCo domains. Our experiments show that\nnot only does our approach produce robust policies, but it also improves the\nperformance in the absence of perturbations. This generalization indicates that\naction-robustness can be thought of as implicit regularization in RL problems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 09:37:53 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 14:15:55 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Tessler", "Chen", ""], ["Efroni", "Yonathan", ""], ["Mannor", "Shie", ""]]}, {"id": "1901.09187", "submitter": "Steven Kelk", "authors": "Ricards Marcinkevics, Steven Kelk, Carlo Galuzzi, Berthold Stegemann", "title": "Discovery of Important Subsequences in Electrocardiogram Beats Using the\n  Nearest Neighbour Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of time series data is a well-studied problem with\nnumerous practical applications, such as medical diagnosis and speech\nrecognition. A popular and effective approach is to classify new time series in\nthe same way as their nearest neighbours, whereby proximity is defined using\nDynamic Time Warping (DTW) distance, a measure analogous to sequence alignment\nin bioinformatics. However, practitioners are not only interested in accurate\nclassification, they are also interested in why a time series is classified a\ncertain way. To this end, we introduce here the problem of finding a minimum\nlength subsequence of a time series, the removal of which changes the outcome\nof the classification under the nearest neighbour algorithm with DTW distance.\nInformally, such a subsequence is expected to be relevant for the\nclassification and can be helpful for practitioners in interpreting the\noutcome. We describe a simple but optimized implementation for detecting these\nsubsequences and define an accompanying measure to quantify the relevance of\nevery time point in the time series for the classification. In tests on\nelectrocardiogram data we show that the algorithm allows discovery of important\nsubsequences and can be helpful in detecting abnormalities in cardiac rhythms\ndistinguishing sick from healthy patients.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 09:47:31 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Marcinkevics", "Ricards", ""], ["Kelk", "Steven", ""], ["Galuzzi", "Carlo", ""], ["Stegemann", "Berthold", ""]]}, {"id": "1901.09192", "submitter": "Yonatan Geifman", "authors": "Yonatan Geifman, Ran El-Yaniv", "title": "SelectiveNet: A Deep Neural Network with an Integrated Reject Option", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selective prediction (also known as reject option)\nin deep neural networks, and introduce SelectiveNet, a deep neural architecture\nwith an integrated reject option. Existing rejection mechanisms are based\nmostly on a threshold over the prediction confidence of a pre-trained network.\nIn contrast, SelectiveNet is trained to optimize both classification (or\nregression) and rejection simultaneously, end-to-end. The result is a deep\nneural network that is optimized over the covered domain. In our experiments,\nwe show a consistently improved risk-coverage trade-off over several well-known\nclassification and regression datasets, thus reaching new state-of-the-art\nresults for deep selective classification.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 10:09:16 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 12:44:11 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 06:23:04 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 18:55:09 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Geifman", "Yonatan", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1901.09203", "submitter": "Xiao-Yun Zhou", "authors": "Xiao-Yun Zhou, Jian-Qing Zheng, and Peichao Li, Guang-Zhong Yang", "title": "ACNN: a Full Resolution DCNN for Medical Image Segmentation", "comments": "7 pages, 2 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (DCNNs) are used extensively in medical\nimage segmentation and hence 3D navigation for robot-assisted Minimally\nInvasive Surgeries (MISs). However, current DCNNs usually use down sampling\nlayers for increasing the receptive field and gaining abstract semantic\ninformation. These down sampling layers decrease the spatial dimension of\nfeature maps, which can be detrimental to image segmentation. Atrous\nconvolution is an alternative for the down sampling layer. It increases the\nreceptive field whilst maintains the spatial dimension of feature maps. In this\npaper, a method for effective atrous rate setting is proposed to achieve the\nlargest and fully-covered receptive field with a minimum number of atrous\nconvolutional layers. Furthermore, a new and full resolution DCNN - Atrous\nConvolutional Neural Network (ACNN), which incorporates cascaded atrous\nII-blocks, residual learning and Instance Normalization (IN) is proposed.\nApplication results of the proposed ACNN to Magnetic Resonance Imaging (MRI)\nand Computed Tomography (CT) image segmentation demonstrate that the proposed\nACNN can achieve higher segmentation Intersection over Unions (IoUs) than U-Net\nand Deeplabv3+, but with reduced trainable parameters.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 12:41:05 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 22:53:15 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 22:06:07 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 09:02:37 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Zhou", "Xiao-Yun", ""], ["Zheng", "Jian-Qing", ""], ["Li", "Peichao", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1901.09206", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Wittawat Jitkrittum, Krikamol Muandet, Bernhard\n  Sch\\\"olkopf", "title": "Kernel-Guided Training of Implicit Generative Models with Stability\n  Guarantees", "comments": "This article supersedes arXiv:1901.09206 version 1. The paper is\n  restructured, its writing is improved, and new experiments are added. The\n  main result on stability is unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern implicit generative models such as generative adversarial networks\n(GANs) are generally known to suffer from issues such as instability,\nuninterpretability, and difficulty in assessing their performance. If we see\nthese implicit models as dynamical systems, some of these issues are caused by\nbeing unable to control their behavior in a meaningful way during the course of\ntraining. In this work, we propose a theoretically grounded method to guide the\ntraining trajectories of GANs by augmenting the GAN loss function with a\nkernel-based regularization term that controls local and global discrepancies\nbetween the model and true distributions. This control signal allows us to\ninject prior knowledge into the model. We provide theoretical guarantees on the\nstability of the resulting dynamical system and demonstrate different aspects\nof it via a wide range of experiments.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 13:07:07 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 13:37:45 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Mehrjou", "Arash", ""], ["Jitkrittum", "Wittawat", ""], ["Muandet", "Krikamol", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1901.09207", "submitter": "Ying Wen", "authors": "Ying Wen, Yaodong Yang, Rui Luo, Jun Wang, Wei Pan", "title": "Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of attributing latent mental contents such as beliefs or\nintentions to others. The social skill is critical in daily life for reasoning\nabout the potential consequences of others' behaviors so as to plan ahead. It\nis known that humans use such reasoning ability recursively by considering what\nothers believe about their own beliefs. In this paper, we start from level-$1$\nrecursion and introduce a probabilistic recursive reasoning (PR2) framework for\nmulti-agent reinforcement learning. Our hypothesis is that it is beneficial for\neach agent to account for how the opponents would react to its future\nbehaviors. Under the PR2 framework, we adopt variational Bayes methods to\napproximate the opponents' conditional policies, to which each agent finds the\nbest response and then improve their own policies. We develop\ndecentralized-training-decentralized-execution algorithms, namely PR2-Q and\nPR2-Actor-Critic, that are proved to converge in the self-play scenarios when\nthere exists one Nash equilibrium. Our methods are tested on both the matrix\ngame and the differential game, which have a non-trivial equilibrium where\ncommon gradient-based methods fail to converge. Our experiments show that it is\ncritical to reason about how the opponents believe about what the agent\nbelieves. We expect our work to contribute a new idea of modeling the opponents\nto the multi-agent reinforcement learning community.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 13:08:08 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 11:06:20 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Wang", "Jun", ""], ["Pan", "Wei", ""]]}, {"id": "1901.09229", "submitter": "Xingjian Li", "authors": "Xingjian Li, Haoyi Xiong, Hanchao Wang, Yuxuan Rao, Liping Liu, Zeyu\n  Chen, Jun Huan", "title": "DELTA: DEep Learning Transfer using Feature Map with Attention for\n  Convolutional Networks", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning through fine-tuning a pre-trained neural network with an\nextremely large dataset, such as ImageNet, can significantly accelerate\ntraining while the accuracy is frequently bottlenecked by the limited dataset\nsize of the new target task. To solve the problem, some regularization methods,\nconstraining the outer layer weights of the target network using the starting\npoint as references (SPAR), have been studied. In this paper, we propose a\nnovel regularized transfer learning framework DELTA, namely DEep Learning\nTransfer using Feature Map with Attention. Instead of constraining the weights\nof neural network, DELTA aims to preserve the outer layer outputs of the target\nnetwork. Specifically, in addition to minimizing the empirical loss, DELTA\nintends to align the outer layer outputs of two networks, through constraining\na subset of feature maps that are precisely selected by attention that has been\nlearned in an supervised learning manner. We evaluate DELTA with the\nstate-of-the-art algorithms, including L2 and L2-SP. The experiment results\nshow that our proposed method outperforms these baselines with higher accuracy\nfor new tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 15:07:29 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 06:17:05 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 09:26:19 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 06:00:04 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Li", "Xingjian", ""], ["Xiong", "Haoyi", ""], ["Wang", "Hanchao", ""], ["Rao", "Yuxuan", ""], ["Liu", "Liping", ""], ["Chen", "Zeyu", ""], ["Huan", "Jun", ""]]}, {"id": "1901.09235", "submitter": "Thomas Moreau", "authors": "Thomas Moreau, Alexandre Gramfort", "title": "Distributed Convolutional Dictionary Learning (DiCoDiLe): Pattern\n  Discovery in Large Images and Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional dictionary learning (CDL) estimates shift invariant basis\nadapted to multidimensional data. CDL has proven useful for image denoising or\ninpainting, as well as for pattern discovery on multivariate signals. As\nestimated patterns can be positioned anywhere in signals or images,\noptimization techniques face the difficulty of working in extremely high\ndimensions with millions of pixels or time samples, contrarily to standard\npatch-based dictionary learning. To address this optimization problem, this\nwork proposes a distributed and asynchronous algorithm, employing locally\ngreedy coordinate descent and an asynchronous locking mechanism that does not\nrequire a central server. This algorithm can be used to distribute the\ncomputation on a number of workers which scales linearly with the encoded\nsignal's size. Experiments confirm the scaling properties which allows us to\nlearn patterns on large scales images from the Hubble Space Telescope.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 15:48:38 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Moreau", "Thomas", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1901.09240", "submitter": "Abdul Karim", "authors": "Abdul Karim, Avinash Mishra, M A Hakim Newton, Abdul Sattar", "title": "Efficient Toxicity Prediction via Simple Features Using Shallow Neural\n  Networks and Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toxicity prediction of chemical compounds is a grand challenge. Lately, it\nachieved significant progress in accuracy but using a huge set of features,\nimplementing a complex blackbox technique such as a deep neural network, and\nexploiting enormous computational resources. In this paper, we strongly argue\nfor the models and methods that are simple in machine learning characteristics,\nefficient in computing resource usage, and powerful to achieve very high\naccuracy levels. To demonstrate this, we develop a single task-based chemical\ntoxicity prediction framework using only 2D features that are less compute\nintensive. We effectively use a decision tree to obtain an optimum number of\nfeatures from a collection of thousands of them. We use a shallow neural\nnetwork and jointly optimize it with decision tree taking both network\nparameters and input features into account. Our model needs only a minute on a\nsingle CPU for its training while existing methods using deep neural networks\nneed about 10 min on NVidia Tesla K40 GPU. However, we obtain similar or better\nperformance on several toxicity benchmark tasks. We also develop a cumulative\nfeature ranking method which enables us to identify features that can help\nchemists perform prescreening of toxic compounds effectively.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 16:27:29 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Karim", "Abdul", ""], ["Mishra", "Avinash", ""], ["Newton", "M A Hakim", ""], ["Sattar", "Abdul", ""]]}, {"id": "1901.09249", "submitter": "Paul McNicholas", "authors": "Tyler Roick, Dimitris Karlis and Paul D. McNicholas", "title": "Clustering Discrete-Valued Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a need for the development of models that are able to account for\ndiscreteness in data, along with its time series properties and correlation.\nOur focus falls on INteger-valued AutoRegressive (INAR) type models. The INAR\ntype models can be used in conjunction with existing model-based clustering\ntechniques to cluster discrete-valued time series data. With the use of a\nfinite mixture model, several existing techniques such as the selection of the\nnumber of clusters, estimation using expectation-maximization and model\nselection are applicable. The proposed model is then demonstrated on real data\nto illustrate its clustering applications.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 17:36:51 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 20:10:12 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Roick", "Tyler", ""], ["Karlis", "Dimitris", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1901.09269", "submitter": "Eduard Gorbunov", "authors": "Konstantin Mishchenko and Eduard Gorbunov and Martin Tak\\'a\\v{c} and\n  Peter Richt\\'arik", "title": "Distributed Learning with Compressed Gradient Differences", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large machine learning models requires a distributed computing\napproach, with communication of the model updates being the bottleneck. For\nthis reason, several methods based on the compression (e.g., sparsification\nand/or quantization) of updates were recently proposed, including QSGD\n(Alistarh et al., 2017), TernGrad (Wen et al., 2017), SignSGD (Bernstein et\nal., 2018), and DQGD (Khirirat et al., 2018). However, none of these methods\nare able to learn the gradients, which renders them incapable of converging to\nthe true optimum in the batch mode, incompatible with non-smooth regularizers,\nand slows down their convergence. In this work we propose a new distributed\nlearning method --- DIANA --- which resolves these issues via compression of\ngradient differences. We perform a theoretical analysis in the strongly convex\nand nonconvex settings and show that our rates are superior to existing rates.\nOur analysis of block-quantization and differences between $\\ell_2$ and\n$\\ell_\\infty$ quantization closes the gaps in theory and practice. Finally, by\napplying our analysis technique to TernGrad, we establish the first convergence\nrate for this method.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 19:50:45 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 11:03:04 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Mishchenko", "Konstantin", ""], ["Gorbunov", "Eduard", ""], ["Tak\u00e1\u010d", "Martin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1901.09270", "submitter": "Senthil Yogamani", "authors": "Michal Uricar, David Hurych, Pavel Krizek and Senthil Yogamani", "title": "Challenges in Designing Datasets and Validation for Autonomous Driving", "comments": "Accepted at VISAPP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving is getting a lot of attention in the last decade and will\nbe the hot topic at least until the first successful certification of a car\nwith Level 5 autonomy. There are many public datasets in the academic\ncommunity. However, they are far away from what a robust industrial production\nsystem needs. There is a large gap between academic and industrial setting and\na substantial way from a research prototype, built on public datasets, to a\ndeployable solution which is a challenging task. In this paper, we focus on bad\npractices that often happen in the autonomous driving from an industrial\ndeployment perspective. Data design deserves at least the same amount of\nattention as the model design. There is very little attention paid to these\nissues in the scientific community, and we hope this paper encourages better\nformalization of dataset design. More specifically, we focus on the datasets\ndesign and validation scheme for autonomous driving, where we would like to\nhighlight the common problems, wrong assumptions, and steps towards avoiding\nthem, as well as some open problems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 19:51:59 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Uricar", "Michal", ""], ["Hurych", "David", ""], ["Krizek", "Pavel", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1901.09277", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Weicheng Ye, Dawei Geng, Cynthia Rudin", "title": "Towards Practical Lipschitz Bandits", "comments": "Typo fix. Sorry for the carelessness", "journal-ref": null, "doi": "10.1145/3412815.3416885", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Lipschitz bandit algorithms balance exploration and exploitation,\nand have been used for a variety of important task domains. In this paper, we\npresent a framework for Lipschitz bandit methods that adaptively learns\npartitions of context- and arm-space. Due to this flexibility, the algorithm is\nable to efficiently optimize rewards and minimize regret, by focusing on the\nportions of the space that are most relevant. In our analysis, we link\ntree-based methods to Gaussian processes. In light of our analysis, we design a\nnovel hierarchical Bayesian model for Lipschitz bandit problems. Our\nexperiments show that our algorithms can achieve state-of-the-art performance\nin challenging real-world tasks such as neural network hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 20:53:39 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 02:26:54 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 18:08:50 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 05:10:40 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 12:45:43 GMT"}, {"version": "v6", "created": "Fri, 11 Sep 2020 20:30:09 GMT"}, {"version": "v7", "created": "Thu, 21 Jan 2021 21:10:27 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Wang", "Tianyu", ""], ["Ye", "Weicheng", ""], ["Geng", "Dawei", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1901.09283", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, Courosh Mehanian, J. Nathan Kutz", "title": "Money on the Table: Statistical information ignored by Softmax can\n  improve classifier accuracy", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softmax is a standard final layer used in Neural Nets (NNs) to summarize\ninformation encoded in the trained NN and return a prediction. However, Softmax\nleverages only a subset of the class-specific structure encoded in the trained\nmodel and ignores potentially valuable information: During training, models\nencode an array $D$ of class response distributions, where $D_{ij}$ is the\ndistribution of the $j^{th}$ pre-Softmax readout neuron's responses to the\n$i^{th}$ class. Given a test sample, Softmax implicitly uses only the row of\nthis array $D$ that corresponds to the readout neurons' responses to the\nsample's true class. Leveraging more of this array $D$ can improve classifier\naccuracy, because the likelihoods of two competing classes can be encoded in\nother rows of $D$.\n  To explore this potential resource, we develop a hybrid classifier\n(Softmax-Pooling Hybrid, $SPH$) that uses Softmax on high-scoring samples, but\non low-scoring samples uses a log-likelihood method that pools the information\nfrom the full array $D$. We apply $SPH$ to models trained on a vectorized MNIST\ndataset to varying levels of accuracy. $SPH$ replaces only the final Softmax\nlayer in the trained NN, at test time only. All training is the same as for\nSoftmax. Because the pooling classifier performs better than Softmax on\nlow-scoring samples, $SPH$ reduces test set error by 6% to 23%, using the exact\nsame trained model, whatever the baseline Softmax accuracy. This reduction in\nerror reflects hidden capacity of the trained NN that is left unused by\nSoftmax.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 21:58:28 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 00:52:02 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Mehanian", "Courosh", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1901.09290", "submitter": "Sangkug Lym", "authors": "Sangkug Lym, Esha Choukse, Siavash Zangeneh, Wei Wen, Sujay Sanghavi,\n  Mattan Erez", "title": "PruneTrain: Fast Neural Network Training by Dynamic Sparse Model\n  Reconfiguration", "comments": null, "journal-ref": null, "doi": "10.1145/3295500.3356156", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  State-of-the-art convolutional neural networks (CNNs) used in vision\napplications have large models with numerous weights. Training these models is\nvery compute- and memory-resource intensive. Much research has been done on\npruning or compressing these models to reduce the cost of inference, but little\nwork has addressed the costs of training. We focus precisely on accelerating\ntraining. We propose PruneTrain, a cost-efficient mechanism that gradually\nreduces the training cost during training. PruneTrain uses a structured\ngroup-lasso regularization approach that drives the training optimization\ntoward both high accuracy and small weight values. Small weights can then be\nperiodically removed by reconfiguring the network model to a smaller one. By\nusing a structured-pruning approach and additional reconfiguration techniques\nwe introduce, the pruned model can still be efficiently processed on a GPU\naccelerator. Overall, PruneTrain achieves a reduction of 39% in the end-to-end\ntraining time of ResNet50 for ImageNet by reducing computation cost by 40% in\nFLOPs, memory accesses by 37% for memory bandwidth bound layers, and the\ninter-accelerator communication by 55%.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 23:18:49 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 20:09:43 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 16:38:38 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 14:52:25 GMT"}, {"version": "v5", "created": "Mon, 9 Dec 2019 06:06:16 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lym", "Sangkug", ""], ["Choukse", "Esha", ""], ["Zangeneh", "Siavash", ""], ["Wen", "Wei", ""], ["Sanghavi", "Sujay", ""], ["Erez", "Mattan", ""]]}, {"id": "1901.09294", "submitter": "Jing Zhang", "authors": "Jing Zhang", "title": "Anomaly detecting and ranking of the cloud computing platform by\n  multi-view learning", "comments": "under review for Multimedia tools and applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detecting as an important technical in cloud computing is applied to\nsupport smooth running of the cloud platform. Traditional detecting methods\nbased on statistic, analysis, etc. lead to the high false-alarm rate due to\nnon-adaptive and sensitive parameters setting. We presented an online model for\nanomaly detecting using machine learning theory. However, most existing methods\nbased on machine learning linked all features from difference sub-systems into\na long feature vector directly, which is difficult to both exploit the\ncomplement information between sub-systems and ignore multi-view features\nenhancing the classification performance. Aiming to this problem, the proposed\nmethod automatic fuses multi-view features and optimize the discriminative\nmodel to enhance the accuracy. This model takes advantage of extreme learning\nmachine (ELM) to improve detection efficiency. ELM is the single hidden layer\nneural network, which is transforming iterative solution the output weights to\nsolution of linear equations and avoiding the local optimal solution. Moreover,\nwe rank anomies according to the relationship between samples and the\nclassification boundary, and then assigning weights for ranked anomalies,\nretraining the classification model finally. Our method exploits the complement\ninformation between sub-systems sufficiently, and avoids the influence from\nimbalance dataset, therefore, deal with various challenges from the cloud\ncomputing platform. We deploy the privately cloud platform by Openstack,\nverifying the proposed model and comparing results to the state-of-the-art\nmethods with better efficiency and simplicity.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 00:38:22 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Zhang", "Jing", ""]]}, {"id": "1901.09311", "submitter": "Liwei Wang", "authors": "Kefan Dong, Yuanhao Wang, Xiaoyu Chen, Liwei Wang", "title": "Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon\n  MDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in reinforcement learning is whether model-free\nalgorithms are sample efficient. Recently, Jin et al. \\cite{jin2018q} proposed\na Q-learning algorithm with UCB exploration policy, and proved it has nearly\noptimal regret bound for finite-horizon episodic MDP. In this paper, we adapt\nQ-learning with UCB-exploration bonus to infinite-horizon MDP with discounted\nrewards \\emph{without} accessing a generative model. We show that the\n\\textit{sample complexity of exploration} of our algorithm is bounded by\n$\\tilde{O}({\\frac{SA}{\\epsilon^2(1-\\gamma)^7}})$. This improves the previously\nbest known result of $\\tilde{O}({\\frac{SA}{\\epsilon^4(1-\\gamma)^8}})$ in this\nsetting achieved by delayed Q-learning \\cite{strehl2006pac}, and matches the\nlower bound in terms of $\\epsilon$ as well as $S$ and $A$ except for\nlogarithmic factors.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 03:44:42 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 02:09:54 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Dong", "Kefan", ""], ["Wang", "Yuanhao", ""], ["Chen", "Xiaoyu", ""], ["Wang", "Liwei", ""]]}, {"id": "1901.09314", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee, Jongyeong Lee, Masashi Sugiyama", "title": "On Symmetric Losses for Learning from Corrupted Labels", "comments": "ICML2019 with minor typo fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide a better understanding of a symmetric loss. First,\nwe emphasize that using a symmetric loss is advantageous in the balanced error\nrate (BER) minimization and area under the receiver operating characteristic\ncurve (AUC) maximization from corrupted labels. Second, we prove general\ntheoretical properties of symmetric losses, including a\nclassification-calibration condition, excess risk bound, conditional risk\nminimizer, and AUC-consistency condition. Third, since all nonnegative\nsymmetric losses are non-convex, we propose a convex barrier hinge loss that\nbenefits significantly from the symmetric condition, although it is not\nsymmetric everywhere. Finally, we conduct experiments to validate the relevance\nof the symmetric condition.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 04:44:43 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 14:16:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Lee", "Jongyeong", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.09321", "submitter": "Hongyi Zhang", "authors": "Hongyi Zhang, Yann N. Dauphin, Tengyu Ma", "title": "Fixup Initialization: Residual Learning Without Normalization", "comments": "Updating reference. Accepted for publication at ICLR 2019; see\n  https://openreview.net/forum?id=H1gsz30cKX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers are a staple in state-of-the-art deep neural network\narchitectures. They are widely believed to stabilize training, enable higher\nlearning rate, accelerate convergence and improve generalization, though the\nreason for their effectiveness is still an active research topic. In this work,\nwe challenge the commonly-held beliefs by showing that none of the perceived\nbenefits is unique to normalization. Specifically, we propose fixed-update\ninitialization (Fixup), an initialization motivated by solving the exploding\nand vanishing gradient problem at the beginning of training via properly\nrescaling a standard initialization. We find training residual networks with\nFixup to be as stable as training with normalization -- even for networks with\n10,000 layers. Furthermore, with proper regularization, Fixup enables residual\nnetworks without normalization to achieve state-of-the-art performance in image\nclassification and machine translation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 05:30:11 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 00:31:18 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Zhang", "Hongyi", ""], ["Dauphin", "Yann N.", ""], ["Ma", "Tengyu", ""]]}, {"id": "1901.09326", "submitter": "Chao Qu", "authors": "Chao Qu, Shie Mannor, Huan Xu, Yuan Qi, Le Song, Junwu Xiong", "title": "Value Propagation for Decentralized Networked Deep Multi-agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the networked multi-agent reinforcement learning (MARL) problem\nin a fully decentralized setting, where agents learn to coordinate to achieve\nthe joint success. This problem is widely encountered in many areas including\ntraffic control, distributed control, and smart grids. We assume that the\nreward function for each agent can be different and observed only locally by\nthe agent itself. Furthermore, each agent is located at a node of a\ncommunication network and can exchanges information only with its neighbors.\nUsing softmax temporal consistency and a decentralized optimization method, we\nobtain a principled and data-efficient iterative algorithm. In the first step\nof each iteration, an agent computes its local policy and value gradients and\nthen updates only policy parameters. In the second step, the agent propagates\nto its neighbors the messages based on its value function and then updates its\nown value function. Hence we name the algorithm value propagation. We prove a\nnon-asymptotic convergence rate 1/T with the nonlinear function approximation.\nTo the best of our knowledge, it is the first MARL algorithm with convergence\nguarantee in the control, off-policy and non-linear function approximation\nsetting. We empirically demonstrate the effectiveness of our approach in\nexperiments.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 05:56:42 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 02:21:34 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 05:09:46 GMT"}, {"version": "v4", "created": "Sat, 28 Sep 2019 07:56:33 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Qu", "Chao", ""], ["Mannor", "Shie", ""], ["Xu", "Huan", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""], ["Xiong", "Junwu", ""]]}, {"id": "1901.09330", "submitter": "Haosheng Zou", "authors": "Haosheng Zou, Tongzheng Ren, Dong Yan, Hang Su, Jun Zhu", "title": "Reward Shaping via Meta-Learning", "comments": "first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward shaping is one of the most effective methods to tackle the crucial yet\nchallenging problem of credit assignment in Reinforcement Learning (RL).\nHowever, designing shaping functions usually requires much expert knowledge and\nhand-engineering, and the difficulties are further exacerbated given multiple\nsimilar tasks to solve. In this paper, we consider reward shaping on a\ndistribution of tasks, and propose a general meta-learning framework to\nautomatically learn the efficient reward shaping on newly sampled tasks,\nassuming only shared state space but not necessarily action space. We first\nderive the theoretically optimal reward shaping in terms of credit assignment\nin model-free RL. We then propose a value-based meta-learning algorithm to\nextract an effective prior over the optimal reward shaping. The prior can be\napplied directly to new tasks, or provably adapted to the task-posterior while\nsolving the task within few gradient updates. We demonstrate the effectiveness\nof our shaping through significantly improved learning efficiency and\ninterpretable visualizations across various settings, including notably a\nsuccessful transfer from DQN to DDPG.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 06:38:24 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Zou", "Haosheng", ""], ["Ren", "Tongzheng", ""], ["Yan", "Dong", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1901.09335", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Tal Ben-Nun, Itay Hubara, Niv Giladi, Torsten Hoefler,\n  Daniel Soudry", "title": "Augment your batch: better training with larger batches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-batch SGD is important for scaling training of deep neural networks.\nHowever, without fine-tuning hyperparameter schedules, the generalization of\nthe model may be hampered. We propose to use batch augmentation: replicating\ninstances of samples within the same batch with different data augmentations.\nBatch augmentation acts as a regularizer and an accelerator, increasing both\ngeneralization and performance scaling. We analyze the effect of batch\naugmentation on gradient variance and show that it empirically improves\nconvergence for a wide variety of deep neural networks and datasets. Our\nresults show that batch augmentation reduces the number of necessary SGD\nupdates to achieve the same accuracy as the state-of-the-art. Overall, this\nsimple yet effective method enables faster training and better generalization\nby allowing more computational resources to be used concurrently.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 08:02:26 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hoffer", "Elad", ""], ["Ben-Nun", "Tal", ""], ["Hubara", "Itay", ""], ["Giladi", "Niv", ""], ["Hoefler", "Torsten", ""], ["Soudry", "Daniel", ""]]}, {"id": "1901.09342", "submitter": "Haggai Maron", "authors": "Haggai Maron, Ethan Fetaya, Nimrod Segol, Yaron Lipman", "title": "On the Universality of Invariant Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraining linear layers in neural networks to respect symmetry\ntransformations from a group $G$ is a common design principle for invariant\nnetworks that has found many applications in machine learning.\n  In this paper, we consider a fundamental question that has received little\nattention to date: Can these networks approximate any (continuous) invariant\nfunction?\n  We tackle the rather general case where $G\\leq S_n$ (an arbitrary subgroup of\nthe symmetric group) that acts on $\\mathbb{R}^n$ by permuting coordinates. This\nsetting includes several recent popular invariant networks. We present two main\nresults: First, $G$-invariant networks are universal if high-order tensors are\nallowed. Second, there are groups $G$ for which higher-order tensors are\nunavoidable for obtaining universality.\n  $G$-invariant networks consisting of only first-order tensors are of special\ninterest due to their practical value. We conclude the paper by proving a\nnecessary condition for the universality of $G$-invariant networks that\nincorporate only first-order tensors.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 09:29:59 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 16:33:04 GMT"}, {"version": "v3", "created": "Thu, 2 May 2019 12:33:03 GMT"}, {"version": "v4", "created": "Fri, 3 May 2019 14:06:45 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Maron", "Haggai", ""], ["Fetaya", "Ethan", ""], ["Segol", "Nimrod", ""], ["Lipman", "Yaron", ""]]}, {"id": "1901.09344", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Zhi-Hua Zhou", "title": "Stochastic Approximation of Smooth and Strongly Convex Functions: Beyond\n  the $O(1/T)$ Convergence Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic approximation (SA) is a classical approach for stochastic convex\noptimization. Previous studies have demonstrated that the convergence rate of\nSA can be improved by introducing either smoothness or strong convexity\ncondition. In this paper, we make use of smoothness and strong convexity\nsimultaneously to boost the convergence rate. Let $\\lambda$ be the modulus of\nstrong convexity, $\\kappa$ be the condition number, $F_*$ be the minimal risk,\nand $\\alpha>1$ be some small constant. First, we demonstrate that, in\nexpectation, an $O(1/[\\lambda T^\\alpha] + \\kappa F_*/T)$ risk bound is\nattainable when $T = \\Omega(\\kappa^\\alpha)$. Thus, when $F_*$ is small, the\nconvergence rate could be faster than $O(1/[\\lambda T])$ and approaches\n$O(1/[\\lambda T^\\alpha])$ in the ideal case. Second, to further benefit from\nsmall risk, we show that, in expectation, an $O(1/2^{T/\\kappa}+F_*)$ risk bound\nis achievable. Thus, the excess risk reduces exponentially until reaching\n$O(F_*)$, and if $F_*=0$, we obtain a global linear convergence. Finally, we\nemphasize that our proof is constructive and each risk bound is equipped with\nan efficient stochastic algorithm attaining that bound.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 09:36:58 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Zhang", "Lijun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1901.09346", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, Muhammad Fatih Balin, James Zou", "title": "Concrete Autoencoders for Differentiable Feature Selection and\n  Reconstruction", "comments": "Submitted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concrete autoencoder, an end-to-end differentiable method\nfor global feature selection, which efficiently identifies a subset of the most\ninformative features and simultaneously learns a neural network to reconstruct\nthe input data from the selected features. Our method is unsupervised, and is\nbased on using a concrete selector layer as the encoder and using a standard\nneural network as the decoder. During the training phase, the temperature of\nthe concrete selector layer is gradually decreased, which encourages a\nuser-specified number of discrete features to be learned. During test time, the\nselected features can be used with the decoder network to reconstruct the\nremaining input features. We evaluate concrete autoencoders on a variety of\ndatasets, where they significantly outperform state-of-the-art methods for\nfeature selection and data reconstruction. In particular, on a large-scale gene\nexpression dataset, the concrete autoencoder selects a small subset of genes\nwhose expression levels can be use to impute the expression levels of the\nremaining genes. In doing so, it improves on the current widely-used\nexpert-curated L1000 landmark genes, potentially reducing measurement costs by\n20%. The concrete autoencoder can be implemented by adding just a few lines of\ncode to a standard autoencoder.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 09:48:49 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 04:35:55 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Abid", "Abubakar", ""], ["Balin", "Muhammad Fatih", ""], ["Zou", "James", ""]]}, {"id": "1901.09387", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, Nontawat Charoenphakdee, Han Bao, Voot Tangkaratt,\n  Masashi Sugiyama", "title": "Imitation Learning from Imperfect Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to learn an optimal policy from demonstrations.\nHowever, such demonstrations are often imperfect since collecting optimal ones\nis costly. To effectively learn from imperfect demonstrations, we propose a\nnovel approach that utilizes confidence scores, which describe the quality of\ndemonstrations. More specifically, we propose two confidence-based IL methods,\nnamely two-step importance weighting IL (2IWIL) and generative adversarial IL\nwith imperfect demonstration and confidence (IC-GAIL). We show that confidence\nscores given only to a small portion of sub-optimal demonstrations\nsignificantly improve the performance of IL both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 14:42:53 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 13:47:40 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 01:43:01 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Charoenphakdee", "Nontawat", ""], ["Bao", "Han", ""], ["Tangkaratt", "Voot", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.09392", "submitter": "Chih-Kuan Yeh", "authors": "Chih-Kuan Yeh, Cheng-Yu Hsieh, Arun Sai Suggala, David I. Inouye,\n  Pradeep Ravikumar", "title": "On the (In)fidelity and Sensitivity for Explanations", "comments": "NeurIPS 2019 camera ready, previous version on Arxiv: \"How Sensitive\n  are Sensitivity-Based Explanations\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider objective evaluation measures of saliency explanations for\ncomplex black-box machine learning models. We propose simple robust variants of\ntwo notions that have been considered in recent literature: (in)fidelity, and\nsensitivity. We analyze optimal explanations with respect to both these\nmeasures, and while the optimal explanation for sensitivity is a vacuous\nconstant explanation, the optimal explanation for infidelity is a novel\ncombination of two popular explanation methods. By varying the perturbation\ndistribution that defines infidelity, we obtain novel explanations by\noptimizing infidelity, which we show to out-perform existing explanations in\nboth quantitative and qualitative measurements. Another salient question given\nthese measures is how to modify any given explanation to have better values\nwith respect to these measures. We propose a simple modification based on\nlowering sensitivity, and moreover show that when done appropriately, we could\nsimultaneously improve both sensitivity as well as fidelity.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 15:22:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 03:45:56 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 01:39:45 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 20:39:55 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yeh", "Chih-Kuan", ""], ["Hsieh", "Cheng-Yu", ""], ["Suggala", "Arun Sai", ""], ["Inouye", "David I.", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1901.09401", "submitter": "Robert M. Gower", "authors": "Robert Mansel Gower and Nicolas Loizou and Xun Qian and Alibek\n  Sailanbayev and Egor Shulgin and Peter Richtarik", "title": "SGD: General Analysis and Improved Rates", "comments": "23 pages, 6 figures", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:5200-5209, 2019", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general yet simple theorem describing the convergence of SGD\nunder the arbitrary sampling paradigm. Our theorem describes the convergence of\nan infinite array of variants of SGD, each of which is associated with a\nspecific probability law governing the data selection rule used to form\nmini-batches. This is the first time such an analysis is performed, and most of\nour variants of SGD were never explicitly considered in the literature before.\nOur analysis relies on the recently introduced notion of expected smoothness\nand does not rely on a uniform bound on the variance of the stochastic\ngradients. By specializing our theorem to different mini-batching strategies,\nsuch as sampling with replacement and independent sampling, we derive exact\nexpressions for the stepsize as a function of the mini-batch size. With this we\ncan also determine the mini-batch size that optimizes the total complexity, and\nshow explicitly that as the variance of the stochastic gradient evaluated at\nthe minimum grows, so does the optimal mini-batch size. For zero variance, the\noptimal mini-batch size is one. Moreover, we prove insightful\nstepsize-switching rules which describe when one should switch from a constant\nto a decreasing stepsize regime.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 16:34:02 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 15:50:41 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 17:23:46 GMT"}, {"version": "v4", "created": "Wed, 1 May 2019 11:14:57 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Gower", "Robert Mansel", ""], ["Loizou", "Nicolas", ""], ["Qian", "Xun", ""], ["Sailanbayev", "Alibek", ""], ["Shulgin", "Egor", ""], ["Richtarik", "Peter", ""]]}, {"id": "1901.09415", "submitter": "Javier Antoran", "authors": "Javier Antoran, Antonio Miguel", "title": "Disentangling and Learning Robust Representations with Natural\n  Clustering", "comments": "Accepted at ICMLA 2019", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00125", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations that disentangle the underlying factors of\nvariability in data is an intuitive way to achieve generalization in deep\nmodels. In this work, we address the scenario where generative factors present\na multimodal distribution due to the existence of class distinction in the\ndata. We propose N-VAE, a model which is capable of separating factors of\nvariation which are exclusive to certain classes from factors that are shared\namong classes. This model implements an explicitly compositional latent\nvariable structure by defining a class-conditioned latent space and a shared\nlatent space. We show its usefulness for detecting and disentangling\nclass-dependent generative factors as well as its capacity to generate\nartificial samples which contain characteristics unseen in the training data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 18:15:27 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 13:41:04 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 23:02:11 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Antoran", "Javier", ""], ["Miguel", "Antonio", ""]]}, {"id": "1901.09421", "submitter": "Yuheng Bu", "authors": "Yuheng Bu, Weihao Gao, Shaofeng Zou and Venugopal V. Veeravalli", "title": "Information-Theoretic Understanding of Population Risk Improvement with\n  Model Compression", "comments": "submitted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that model compression can improve the population risk of a\npre-trained model, by studying the tradeoff between the decrease in the\ngeneralization error and the increase in the empirical risk with model\ncompression. We first prove that model compression reduces an\ninformation-theoretic bound on the generalization error; this allows for an\ninterpretation of model compression as a regularization technique to avoid\noverfitting. We then characterize the increase in empirical risk with model\ncompression using rate distortion theory. These results imply that the\npopulation risk could be improved by model compression if the decrease in\ngeneralization error exceeds the increase in empirical risk. We show through a\nlinear regression example that such a decrease in population risk due to model\ncompression is indeed possible. Our theoretical results further suggest that\nthe Hessian-weighted $K$-means clustering compression approach can be improved\nby regularizing the distance between the clustering centers. We provide\nexperiments with neural networks to support our theoretical assertions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 18:59:45 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Bu", "Yuheng", ""], ["Gao", "Weihao", ""], ["Zou", "Shaofeng", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1901.09437", "submitter": "Filip Hanzely", "authors": "Konstantin Mishchenko and Filip Hanzely and Peter Richt\\'arik", "title": "99% of Distributed Optimization is a Waste of Time: The Issue and How to\n  Fix it", "comments": "41 pages, 8 algorithms, 10 theorems, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many popular distributed optimization methods for training machine learning\nmodels fit the following template: a local gradient estimate is computed\nindependently by each worker, then communicated to a master, which subsequently\nperforms averaging. The average is broadcast back to the workers, which use it\nto perform a gradient-type step to update the local version of the model. It is\nalso well known that many such methods, including SGD, SAGA, and accelerated\nSGD for over-parameterized models, do not scale well with the number of\nparallel workers. In this paper we observe that the above template is\nfundamentally inefficient in that too much data is unnecessarily communicated\nby the workers, which slows down the overall system. We propose a fix based on\na new update-sparsification method we develop in this work, which we suggest be\nused on top of existing methods. Namely, we develop a new variant of parallel\nblock coordinate descent based on independent sparsification of the local\ngradient estimates before communication. We demonstrate that with only $m/n$\nblocks sent by each of $n$ workers, where $m$ is the total number of parameter\nblocks, the theoretical iteration complexity of the underlying distributed\nmethods is essentially unaffected. As an illustration, this means that when\n$n=100$ parallel workers are used, the communication of $99\\%$ blocks is\nredundant, and hence a waste of time. Our theoretical claims are supported\nthrough extensive numerical experiments which demonstrate an almost perfect\nmatch with our theory on a number of synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 20:49:24 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:09:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Mishchenko", "Konstantin", ""], ["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1901.09450", "submitter": "Samy Wu Fung", "authors": "Samy Wu Fung, Sanna Tyrv\\\"ainen, Lars Ruthotto, Eldad Haber", "title": "ADMM-SOFTMAX : An ADMM Approach for Multinomial Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ADMM-Softmax, an alternating direction method of multipliers\n(ADMM) for solving multinomial logistic regression (MLR) problems. Our method\nis geared toward supervised classification tasks with many examples and\nfeatures. It decouples the nonlinear optimization problem in MLR into three\nsteps that can be solved efficiently. In particular, each iteration of\nADMM-Softmax consists of a linear least-squares problem, a set of independent\nsmall-scale smooth, convex problems, and a trivial dual variable update.\nSolution of the least-squares problem can be be accelerated by pre-computing a\nfactorization or preconditioner, and the separability in the smooth, convex\nproblem can be easily parallelized across examples. For two image\nclassification problems, we demonstrate that ADMM-Softmax leads to improved\ngeneralization compared to a Newton-Krylov, a quasi Newton, and a stochastic\ngradient descent method.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 22:19:06 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 16:28:20 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Fung", "Samy Wu", ""], ["Tyrv\u00e4inen", "Sanna", ""], ["Ruthotto", "Lars", ""], ["Haber", "Eldad", ""]]}, {"id": "1901.09451", "submitter": "Maria De-Arteaga", "authors": "Maria De-Arteaga, Alexey Romanov, Hanna Wallach, Jennifer Chayes,\n  Christian Borgs, Alexandra Chouldechova, Sahin Geyik, Krishnaram Kenthapadi,\n  Adam Tauman Kalai", "title": "Bias in Bios: A Case Study of Semantic Representation Bias in a\n  High-Stakes Setting", "comments": "Accepted at ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAT*), 2019", "journal-ref": null, "doi": "10.1145/3287560.3287572", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale study of gender bias in occupation classification, a\ntask where the use of machine learning may lead to negative outcomes on\npeoples' lives. We analyze the potential allocation harms that can result from\nsemantic representation bias. To do so, we study the impact on occupation\nclassification of including explicit gender indicators---such as first names\nand pronouns---in different semantic representations of online biographies.\nAdditionally, we quantify the bias that remains when these indicators are\n\"scrubbed,\" and describe proxy behavior that occurs in the absence of explicit\ngender indicators. As we demonstrate, differences in true positive rates\nbetween genders are correlated with existing gender imbalances in occupations,\nwhich may compound these imbalances.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 22:36:16 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Romanov", "Alexey", ""], ["Wallach", "Hanna", ""], ["Chayes", "Jennifer", ""], ["Borgs", "Christian", ""], ["Chouldechova", "Alexandra", ""], ["Geyik", "Sahin", ""], ["Kenthapadi", "Krishnaram", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1901.09453", "submitter": "Han Zhao", "authors": "Han Zhao, Remi Tachet des Combes, Kun Zhang, Geoffrey J. Gordon", "title": "On Learning Invariant Representation for Domain Adaptation", "comments": "Compared with the last version, the current one adds a new corollary\n  for the case of different feature transformations (encoders) on source/target\n  domains. Fix a typo in Fig. 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the ability of deep neural nets to learn rich representations, recent\nadvances in unsupervised domain adaptation have focused on learning\ndomain-invariant features that achieve a small error on the source domain. The\nhope is that the learnt representation, together with the hypothesis learnt\nfrom the source domain, can generalize to the target domain. In this paper, we\nfirst construct a simple counterexample showing that, contrary to common\nbelief, the above conditions are not sufficient to guarantee successful domain\nadaptation. In particular, the counterexample exhibits \\emph{conditional\nshift}: the class-conditional distributions of input features change between\nsource and target domains. To give a sufficient condition for domain\nadaptation, we propose a natural and interpretable generalization upper bound\nthat explicitly takes into account the aforementioned shift. Moreover, we shed\nnew light on the problem by proving an information-theoretic lower bound on the\njoint error of \\emph{any} domain adaptation method that attempts to learn\ninvariant representations. Our result characterizes a fundamental tradeoff\nbetween learning invariant representations and achieving small joint error on\nboth domains when the marginal label distributions differ from source to\ntarget. Finally, we conduct experiments on real-world datasets that corroborate\nour theoretical findings. We believe these insights are helpful in guiding the\nfuture design of domain adaptation and representation learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 22:44:00 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:17:02 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Zhao", "Han", ""], ["Combes", "Remi Tachet des", ""], ["Zhang", "Kun", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1901.09455", "submitter": "Carles Gelada", "authors": "Carles Gelada, Marc G. Bellemare", "title": "Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate\n  Shift", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit the method of off-policy corrections for\nreinforcement learning (COP-TD) pioneered by Hallak et al. (2017). Under this\nmethod, online updates to the value function are reweighted to avoid divergence\nissues typical of off-policy learning. While Hallak et al.'s solution is\nappealing, it cannot easily be transferred to nonlinear function approximation.\nFirst, it requires a projection step onto the probability simplex; second, even\nthough the operator describing the expected behavior of the off-policy learning\nalgorithm is convergent, it is not known to be a contraction mapping, and\nhence, may be more unstable in practice. We address these two issues by\nintroducing a discount factor into COP-TD. We analyze the behavior of\ndiscounted COP-TD and find it better behaved from a theoretical perspective. We\nalso propose an alternative soft normalization penalty that can be minimized\nonline and obviates the need for an explicit projection step. We complement our\nanalysis with an empirical evaluation of the two techniques in an off-policy\nsetting on the game Pong from the Atari domain where we find discounted COP-TD\nto be better behaved in practice than the soft normalization penalty. Finally,\nwe perform a more extensive evaluation of discounted COP-TD in 5 games of the\nAtari domain, where we find performance gains for our approach.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 22:56:50 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Gelada", "Carles", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1901.09462", "submitter": "Davood Karimi", "authors": "Davood Karimi, Golnoosh Samei, Yanan Shao, Septimiu Salcudean", "title": "A deep learning-based method for prostate segmentation in T2-weighted\n  magnetic resonance imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel automatic method for accurate segmentation of the prostate\nin T2-weighted magnetic resonance imaging (MRI). Our method is based on\nconvolutional neural networks (CNNs). Because of the large variability in the\nshape, size, and appearance of the prostate and the scarcity of annotated\ntraining data, we suggest training two separate CNNs. A global CNN will\ndetermine a prostate bounding box, which is then resampled and sent to a local\nCNN for accurate delineation of the prostate boundary. This way, the local CNN\ncan effectively learn to segment the fine details that distinguish the prostate\nfrom the surrounding tissue using the small amount of available training data.\nTo fully exploit the training data, we synthesize additional data by deforming\nthe training images and segmentations using a learned shape model. We apply the\nproposed method on the PROMISE12 challenge dataset and achieve state of the art\nresults. Our proposed method generates accurate, smooth, and artifact-free\nsegmentations. On the test images, we achieve an average Dice score of 90.6\nwith a small standard deviation of 2.2, which is superior to all previous\nmethods. Our two-step segmentation approach and data augmentation strategy may\nbe highly effective in segmentation of other organs from small amounts of\nannotated medical images.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 23:29:09 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 19:22:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Karimi", "Davood", ""], ["Samei", "Golnoosh", ""], ["Shao", "Yanan", ""], ["Salcudean", "Septimiu", ""]]}, {"id": "1901.09465", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao and David Tse", "title": "Deconstructing Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deconstruct the performance of GANs into three components:\n  1. Formulation: we propose a perturbation view of the population target of\nGANs. Building on this interpretation, we show that GANs can be viewed as a\ngeneralization of the robust statistics framework, and propose a novel GAN\narchitecture, termed as Cascade GANs, to provably recover meaningful\nlow-dimensional generator approximations when the real distribution is\nhigh-dimensional and corrupted by outliers.\n  2. Generalization: given a population target of GANs, we design a systematic\nprinciple, projection under admissible distance, to design GANs to meet the\npopulation requirement using finite samples. We implement our principle in\nthree cases to achieve polynomial and sometimes near-optimal sample\ncomplexities: (1) learning an arbitrary generator under an arbitrary\npseudonorm; (2) learning a Gaussian location family under TV distance, where we\nutilize our principle provide a new proof for the optimality of Tukey median\nviewed as GANs; (3) learning a low-dimensional Gaussian approximation of a\nhigh-dimensional arbitrary distribution under Wasserstein distance. We\ndemonstrate a fundamental trade-off in the approximation error and statistical\nerror in GANs, and show how to apply our principle with empirical samples to\npredict how many samples are sufficient for GANs in order not to suffer from\nthe discriminator winning problem.\n  3. Optimization: we demonstrate alternating gradient descent is provably not\nlocally asymptotically stable in optimizing the GAN formulation of PCA. We\ndiagnose the problem as the minimax duality gap being non-zero, and propose a\nnew GAN architecture whose duality gap is zero, where the value of the game is\nequal to the previous minimax value (not the maximin value). We prove the new\nGAN architecture is globally asymptotically stable in optimization under\nalternating gradient descent.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 23:53:32 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 22:11:56 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 22:39:30 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 07:07:40 GMT"}, {"version": "v5", "created": "Sat, 11 May 2019 18:59:04 GMT"}, {"version": "v6", "created": "Fri, 17 May 2019 04:53:36 GMT"}, {"version": "v7", "created": "Mon, 20 May 2019 01:11:05 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Tse", "David", ""]]}, {"id": "1901.09475", "submitter": "Eric Strobl", "authors": "Eric V. Strobl", "title": "Causal Discovery with a Mixture of DAGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal processes in biomedicine may contain cycles, evolve over time or\ndiffer between populations. However, many graphical models cannot accommodate\nthese conditions. We propose to model causation using a mixture of directed\ncyclic graphs (DAGs), where the joint distribution in a population follows a\nDAG at any single point in time but potentially different DAGs across time. We\nalso introduce an algorithm called Causal Inference over Mixtures that uses\nlongitudinal data to infer a graph summarizing the causal relations generated\nfrom a mixture of DAGs. Experiments demonstrate improved performance compared\nto prior approaches.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 00:57:20 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 14:58:23 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Strobl", "Eric V.", ""]]}, {"id": "1901.09490", "submitter": "Sahin Lale", "authors": "Sahin Lale, Kamyar Azizzadenesheli, Anima Anandkumar, Babak Hassibi", "title": "Stochastic Linear Bandits with Hidden Low Rank Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional representations often have a lower dimensional underlying\nstructure. This is particularly the case in many decision making settings. For\nexample, when the representation of actions is generated from a deep neural\nnetwork, it is reasonable to expect a low-rank structure whereas conventional\nstructures like sparsity are not valid anymore. Subspace recovery methods, such\nas Principle Component Analysis (PCA) can find the underlying low-rank\nstructures in the feature space and reduce the complexity of the learning\ntasks. In this work, we propose Projected Stochastic Linear Bandit (PSLB), an\nalgorithm for high dimensional stochastic linear bandits (SLB) when the\nrepresentation of actions has an underlying low-dimensional subspace structure.\nPSLB deploys PCA based projection to iteratively find the low rank structure in\nSLBs. We show that deploying projection methods assures dimensionality\nreduction and results in a tighter regret upper bound that is in terms of the\ndimensionality of the subspace and its properties, rather than the\ndimensionality of the ambient space. We modify the image classification task\ninto the SLB setting and empirically show that, when a pre-trained DNN provides\nthe high dimensional feature representations, deploying PSLB results in\nsignificant reduction of regret and faster convergence to an accurate model\ncompared to state-of-art algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 02:45:01 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lale", "Sahin", ""], ["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Anima", ""], ["Hassibi", "Babak", ""]]}, {"id": "1901.09491", "submitter": "Stanislav Fort", "authors": "Stanislav Fort, Pawe{\\l} Krzysztof Nowak, Stanislaw Jastrzebski, Srini\n  Narayanan", "title": "Stiffness: A New Perspective on Generalization in Neural Networks", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a new perspective on generalization of neural\nnetworks by proposing and investigating the concept of a neural network\nstiffness. We measure how stiff a network is by looking at how a small gradient\nstep in the network's parameters on one example affects the loss on another\nexample. Higher stiffness suggests that a network is learning features that\ngeneralize. In particular, we study how stiffness depends on 1) class\nmembership, 2) distance between data points in the input space, 3) training\niteration, and 4) learning rate. We present experiments on MNIST, FASHION\nMNIST, and CIFAR-10/100 using fully-connected and convolutional neural\nnetworks, as well as on a transformer-based NLP model. We demonstrate the\nconnection between stiffness and generalization, and observe its dependence on\nlearning rate. When training on CIFAR-100, the stiffness matrix exhibits a\ncoarse-grained behavior indicative of the model's awareness of super-class\nmembership. In addition, we measure how stiffness between two data points\ndepends on their mutual input-space distance, and establish the concept of a\ndynamical critical length -- a distance below which a parameter update based on\na data point influences its neighbors.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 02:49:46 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:29:53 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 23:33:57 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Fort", "Stanislav", ""], ["Nowak", "Pawe\u0142 Krzysztof", ""], ["Jastrzebski", "Stanislaw", ""], ["Narayanan", "Srini", ""]]}, {"id": "1901.09493", "submitter": "Anshuman Chhabra", "authors": "Anshuman Chhabra, Abhishek Roy, Prasant Mohapatra", "title": "Strong Black-box Adversarial Attacks on Unsupervised Machine Learning\n  Models", "comments": "We realized that some of the results obtained are not accurate since\n  there was a bug in the approach used", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) models have achieved\nstate-of-the-art performance on multiple learning tasks, from vision to natural\nlanguage modelling. With the growing adoption of ML and DL to many areas of\ncomputer science, recent research has also started focusing on the security\nproperties of these models. There has been a lot of work undertaken to\nunderstand if (deep) neural network architectures are resilient to black-box\nadversarial attacks which craft perturbed input samples that fool the\nclassifier without knowing the architecture used. Recent work has also focused\non the transferability of adversarial attacks and found that adversarial\nattacks are generally easily transferable between models, datasets, and\ntechniques. However, such attacks and their analysis have not been covered from\nthe perspective of unsupervised machine learning algorithms. In this paper, we\nseek to bridge this gap through multiple contributions. We first provide a\nstrong (iterative) black-box adversarial attack that can craft adversarial\nsamples which will be incorrectly clustered irrespective of the choice of\nclustering algorithm. We choose 4 prominent clustering algorithms, and a\nreal-world dataset to show the working of the proposed adversarial algorithm.\nUsing these clustering algorithms we also carry out a simple study of\ncross-technique adversarial attack transferability.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:00:40 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 21:41:45 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 00:37:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chhabra", "Anshuman", ""], ["Roy", "Abhishek", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "1901.09496", "submitter": "Thomas Gebhart", "authors": "Thomas Gebhart, Paul Schrater and Alan Hylton", "title": "Characterizing the Shape of Activation Space in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representations learned by deep neural networks are difficult to\ninterpret in part due to their large parameter space and the complexities\nintroduced by their multi-layer structure. We introduce a method for computing\npersistent homology over the graphical activation structure of neural networks,\nwhich provides access to the task-relevant substructures activated throughout\nthe network for a given input. This topological perspective provides unique\ninsights into the distributed representations encoded by neural networks in\nterms of the shape of their activation structures. We demonstrate the value of\nthis approach by showing an alternative explanation for the existence of\nadversarial examples. By studying the topology of network activations across\nmultiple architectures and datasets, we find that adversarial perturbations do\nnot add activations that target the semantic structure of the adversarial class\nas previously hypothesized. Rather, adversarial examples are explainable as\nalterations to the dominant activation structures induced by the original\nimage, suggesting the class representations learned by deep networks are\nproblematically sparse on the input space.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:10:56 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 14:39:53 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gebhart", "Thomas", ""], ["Schrater", "Paul", ""], ["Hylton", "Alan", ""]]}, {"id": "1901.09503", "submitter": "Yongchan Kwon", "authors": "Yongchan Kwon, Wonyoung Kim, Masashi Sugiyama, Myunghee Cho Paik", "title": "Principled analytic classifier for positive-unlabeled learning via\n  weighted integral probability metric", "comments": "32 pages; Accepted for ACML 2019", "journal-ref": null, "doi": "10.1007/s10994-019-05836-9", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a binary classifier from only positive\nand unlabeled observations (called PU learning). Recent studies in PU learning\nhave shown superior performance theoretically and empirically. However, most\nexisting algorithms may not be suitable for large-scale datasets because they\nface repeated computations of a large Gram matrix or require massive\nhyperparameter optimization. In this paper, we propose a computationally\nefficient and theoretically grounded PU learning algorithm. The proposed PU\nlearning algorithm produces a closed-form classifier when the hypothesis space\nis a closed ball in reproducing kernel Hilbert space. In addition, we establish\nupper bounds of the estimation error and the excess risk. The obtained\nestimation error bound is sharper than existing results and the derived excess\nrisk bound has an explicit form, which vanishes as sample sizes increase.\nFinally, we conduct extensive numerical experiments using both synthetic and\nreal datasets, demonstrating improved accuracy, scalability, and robustness of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:47:43 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 09:35:32 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 09:24:56 GMT"}, {"version": "v4", "created": "Fri, 3 May 2019 16:42:55 GMT"}, {"version": "v5", "created": "Sat, 6 Jul 2019 07:16:09 GMT"}, {"version": "v6", "created": "Thu, 20 Feb 2020 04:03:03 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kwon", "Yongchan", ""], ["Kim", "Wonyoung", ""], ["Sugiyama", "Masashi", ""], ["Paik", "Myunghee Cho", ""]]}, {"id": "1901.09504", "submitter": "Ritchie Zhao", "authors": "Ritchie Zhao, Yuwei Hu, Jordan Dotzel, Christopher De Sa, Zhiru Zhang", "title": "Improving Neural Network Quantization without Retraining using Outlier\n  Channel Splitting", "comments": "10 pages; update to ICML camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization can improve the execution latency and energy efficiency of\nneural networks on both commodity GPUs and specialized accelerators. The\nmajority of existing literature focuses on training quantized DNNs, while this\nwork examines the less-studied topic of quantizing a floating-point model\nwithout (re)training. DNN weights and activations follow a bell-shaped\ndistribution post-training, while practical hardware uses a linear quantization\ngrid. This leads to challenges in dealing with outliers in the distribution.\nPrior work has addressed this by clipping the outliers or using specialized\nhardware. In this work, we propose outlier channel splitting (OCS), which\nduplicates channels containing outliers, then halves the channel values. The\nnetwork remains functionally identical, but affected outliers are moved toward\nthe center of the distribution. OCS requires no additional training and works\non commodity hardware. Experimental evaluation on ImageNet classification and\nlanguage modeling shows that OCS can outperform state-of-the-art clipping\ntechniques with only minor overhead.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 03:50:35 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 03:31:48 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 19:31:45 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhao", "Ritchie", ""], ["Hu", "Yuwei", ""], ["Dotzel", "Jordan", ""], ["De Sa", "Christopher", ""], ["Zhang", "Zhiru", ""]]}, {"id": "1901.09515", "submitter": "Lin Chen", "authors": "Lin Chen, Mingrui Zhang, Hamed Hassani, Amin Karbasi", "title": "Black Box Submodular Maximization: Discrete and Continuous Settings", "comments": "Accepted to AISTATS 2020. First two authors contributed equally to\n  this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of black box continuous submodular\nmaximization where we only have access to the function values and no\ninformation about the derivatives is provided. For a monotone and continuous\nDR-submodular function, and subject to a bounded convex body constraint, we\npropose Black-box Continuous Greedy, a derivative-free algorithm that provably\nachieves the tight $[(1-1/e)OPT-\\epsilon]$ approximation guarantee with\n$O(d/\\epsilon^3)$ function evaluations. We then extend our result to the\nstochastic setting where function values are subject to stochastic zero-mean\nnoise. It is through this stochastic generalization that we revisit the\ndiscrete submodular maximization problem and use the multi-linear extension as\na bridge between discrete and continuous settings. Finally, we extensively\nevaluate the performance of our algorithm on continuous and discrete submodular\nobjective functions using both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 04:53:53 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 20:57:49 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Lin", ""], ["Zhang", "Mingrui", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1901.09517", "submitter": "Harshal Mittal", "authors": "Harshal Mittal, Kartikey Pandey and Yash Kant", "title": "ICLR Reproducibility Challenge Report (Padam : Closing The\n  Generalization Gap Of Adaptive Gradient Methods in Training Deep Neural\n  Networks)", "comments": "ICLR Reproducibility Challenge 2019 Report for Padam (11 pages, 30\n  figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a part of ICLR Reproducibility Challenge 2019, we try to\nreproduce the results in the conference submission PADAM: Closing The\nGeneralization Gap of Adaptive Gradient Methods In Training Deep Neural\nNetworks. Adaptive gradient methods proposed in past demonstrate a degraded\ngeneralization performance than the stochastic gradient descent (SGD) with\nmomentum. The authors try to address this problem by designing a new\noptimization algorithm that bridges the gap between the space of Adaptive\nGradient algorithms and SGD with momentum. With this method a new tunable\nhyperparameter called partially adaptive parameter p is introduced that varies\nbetween [0, 0.5]. We build the proposed optimizer and use it to mirror the\nexperiments performed by the authors. We review and comment on the empirical\nanalysis performed by the authors. Finally, we also propose a future direction\nfor further study of Padam. Our code is available at:\nhttps://github.com/yashkant/Padam-Tensorflow\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 05:00:42 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Mittal", "Harshal", ""], ["Pandey", "Kartikey", ""], ["Kant", "Yash", ""]]}, {"id": "1901.09531", "submitter": "Jonathan Bloom", "authors": "Jonathan M. Bloom", "title": "Secure multi-party linear regression at plaintext speed", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detail distributed algorithms for scalable, secure multiparty linear\nregression and feature selection at essentially the same speed as plaintext\nregression. While the core geometric ideas are simple, the recognition of their\nbroad utility when combined is novel. Our scheme opens the door to efficient\nand secure genome-wide association studies across multiple biobanks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 07:06:12 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 17:57:00 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Bloom", "Jonathan M.", ""]]}, {"id": "1901.09532", "submitter": "Gilles Stoltz", "authors": "Margaux Br\\'eg\\`ere (EDF R\\&D, LMO, SIERRA), Pierre Gaillard (SIERRA),\n  Yannig Goude (EDF R\\&D), Gilles Stoltz (LMO)", "title": "Target Tracking for Contextual Bandits: Application to Demand Side\n  Management", "comments": null, "journal-ref": "ICML 2019 (Thirty-sixth International Conference on Machine\n  Learning), Jun 2019, Long Beach, United States", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a contextual-bandit approach for demand side management by\noffering price incentives. More precisely, a target mean consumption is set at\neach round and the mean consumption is modeled as a complex function of the\ndistribution of prices sent and of some contextual variables such as the\ntemperature, weather, and so on. The performance of our strategies is measured\nin quadratic losses through a regret criterion. We offer $T^{2/3}$ upper bounds\non this regret (up to poly-logarithmic terms)---and even faster rates under\nstronger assumptions---for strategies inspired by standard strategies for\ncontextual bandits (like LinUCB, see Li et al., 2010). Simulations on a real\ndata set gathered by UK Power Networks, in which price incentives were offered,\nshow that our strategies are effective and may indeed manage demand response by\nsuitably picking the price levels.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 07:08:44 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:40:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Br\u00e9g\u00e8re", "Margaux", "", "EDF R\\&D, LMO, SIERRA"], ["Gaillard", "Pierre", "", "SIERRA"], ["Goude", "Yannig", "", "EDF R\\&D"], ["Stoltz", "Gilles", "", "LMO"]]}, {"id": "1901.09541", "submitter": "Kohei Hayashi", "authors": "Kohei Hayashi, Masaaki Imaizumi, Yuichi Yoshida", "title": "On Random Subsampling of Gaussian Process Regression: A Graphon-Based\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study random subsampling of Gaussian process regression,\none of the simplest approximation baselines, from a theoretical perspective.\nAlthough subsampling discards a large part of training data, we show provable\nguarantees on the accuracy of the predictive mean/variance and its\ngeneralization ability. For analysis, we consider embedding kernel matrices\ninto graphons, which encapsulate the difference of the sample size and enables\nus to evaluate the approximation and generalization errors in a unified manner.\nThe experimental results show that the subsampling approximation achieves a\nbetter trade-off regarding accuracy and runtime than the Nystr\\\"{o}m and random\nFourier expansion methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 08:04:24 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hayashi", "Kohei", ""], ["Imaizumi", "Masaaki", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1901.09546", "submitter": "Quanshi Zhang", "authors": "Liyao Xiang, Haotian Ma, Hao Zhang, Yifan Zhang, Jie Ren, Quanshi\n  Zhang", "title": "Interpretable Complex-Valued Neural Networks for Privacy Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have found that an adversary attacker can often infer\nunintended input information from intermediate-layer features. We study the\npossibility of preventing such adversarial inference, yet without too much\naccuracy degradation. We propose a generic method to revise the neural network\nto boost the challenge of inferring input attributes from features, while\nmaintaining highly accurate outputs. In particular, the method transforms\nreal-valued features into complex-valued ones, in which the input is hidden in\na randomized phase of the transformed features. The knowledge of the phase acts\nlike a key, with which any party can easily recover the output from the\nprocessing result, but without which the party can neither recover the output\nnor distinguish the original input. Preliminary experiments on various datasets\nand network structures have shown that our method significantly diminishes the\nadversary's ability in inferring about the input while largely preserves the\nresulting accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 08:21:21 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:17:33 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Xiang", "Liyao", ""], ["Ma", "Haotian", ""], ["Zhang", "Hao", ""], ["Zhang", "Yifan", ""], ["Ren", "Jie", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1901.09557", "submitter": "Pablo Martinez Olmos", "authors": "Pablo S\\'anchez-Mart\\'in, Pablo M. Olmos, Fernando P\\'erez-Cruz", "title": "Out-of-Sample Testing for GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to evaluate GANs, namely EvalGAN. EvalGAN relies on a\ntest set to directly measure the reconstruction quality in the original sample\nspace (no auxiliary networks are necessary), and it also computes the\n(log)likelihood for the reconstructed samples in the test set. Further, EvalGAN\nis agnostic to the GAN algorithm and the dataset. We decided to test it on\nthree state-of-the-art GANs over the well-known CIFAR-10 and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 09:04:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["S\u00e1nchez-Mart\u00edn", "Pablo", ""], ["Olmos", "Pablo M.", ""], ["P\u00e9rez-Cruz", "Fernando", ""]]}, {"id": "1901.09565", "submitter": "Mohsen Abbasi", "authors": "Mohsen Abbasi, Sorelle A. Friedler, Carlos Scheidegger, Suresh\n  Venkatasubramanian", "title": "Fairness in representation: quantifying stereotyping as a\n  representational harm", "comments": "9 pages, 6 figures, Siam International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While harms of allocation have been increasingly studied as part of the\nsubfield of algorithmic fairness, harms of representation have received\nconsiderably less attention. In this paper, we formalize two notions of\nstereotyping and show how they manifest in later allocative harms within the\nmachine learning pipeline. We also propose mitigation strategies and\ndemonstrate their effectiveness on synthetic datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 09:27:14 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Abbasi", "Mohsen", ""], ["Friedler", "Sorelle A.", ""], ["Scheidegger", "Carlos", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1901.09567", "submitter": "Tatiana Makhalova", "authors": "Tatiana Makhalova, Martin Trnecka", "title": "From-Below Boolean Matrix Factorization Algorithm Based on MDL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past few years Boolean matrix factorization (BMF) has become an\nimportant direction in data analysis. The minimum description length principle\n(MDL) was successfully adapted in BMF for the model order selection.\nNevertheless, a BMF algorithm performing good results from the standpoint of\nstandard measures in BMF is missing. In this paper, we propose a novel\nfrom-below Boolean matrix factorization algorithm based on formal concept\nanalysis. The algorithm utilizes the MDL principle as a criterion for the\nfactor selection. On various experiments we show that the proposed algorithm\noutperforms---from different standpoints---existing state-of-the-art BMF\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 09:32:44 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Makhalova", "Tatiana", ""], ["Trnecka", "Martin", ""]]}, {"id": "1901.09583", "submitter": "Yotam Gigi", "authors": "Sella Nevo, Vova Anisimov, Gal Elidan, Ran El-Yaniv, Pete Giencke,\n  Yotam Gigi, Avinatan Hassidim, Zach Moshe, Mor Schlesinger, Guy Shalev, Ajai\n  Tirumali, Ami Wiesel, Oleg Zlydenko and Yossi Matias", "title": "ML for Flood Forecasting at Scale", "comments": "The 2-page paper sent to NeurIPS 2018 AI for social good workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective riverine flood forecasting at scale is hindered by a multitude of\nfactors, most notably the need to rely on human calibration in current\nmethodology, the limited amount of data for a specific location, and the\ncomputational difficulty of building continent/global level models that are\nsufficiently accurate. Machine learning (ML) is primed to be useful in this\nscenario: learned models often surpass human experts in complex\nhigh-dimensional scenarios, and the framework of transfer or multitask learning\nis an appealing solution for leveraging local signals to achieve improved\nglobal performance. We propose to build on these strengths and develop ML\nsystems for timely and accurate riverine flood prediction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 10:23:29 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Nevo", "Sella", ""], ["Anisimov", "Vova", ""], ["Elidan", "Gal", ""], ["El-Yaniv", "Ran", ""], ["Giencke", "Pete", ""], ["Gigi", "Yotam", ""], ["Hassidim", "Avinatan", ""], ["Moshe", "Zach", ""], ["Schlesinger", "Mor", ""], ["Shalev", "Guy", ""], ["Tirumali", "Ajai", ""], ["Wiesel", "Ami", ""], ["Zlydenko", "Oleg", ""], ["Matias", "Yossi", ""]]}, {"id": "1901.09590", "submitter": "Ivana Bala\\v{z}evi\\'c", "authors": "Ivana Bala\\v{z}evi\\'c, Carl Allen and Timothy M. Hospedales", "title": "TuckER: Tensor Factorization for Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-1522", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are structured representations of real world facts. However,\nthey typically contain only a small subset of all possible facts. Link\nprediction is a task of inferring missing facts based on existing ones. We\npropose TuckER, a relatively straightforward but powerful linear model based on\nTucker decomposition of the binary tensor representation of knowledge graph\ntriples. TuckER outperforms previous state-of-the-art models across standard\nlink prediction datasets, acting as a strong baseline for more elaborate\nmodels. We show that TuckER is a fully expressive model, derive sufficient\nbounds on its embedding dimensionalities and demonstrate that several\npreviously introduced linear models can be viewed as special cases of TuckER.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 10:42:26 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 15:36:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Bala\u017eevi\u0107", "Ivana", ""], ["Allen", "Carl", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1901.09613", "submitter": "Sungchul Choi", "authors": "Hongjun Jeon, Wonchul Seo, Eunjeong Lucy Park, Sungchul Choi", "title": "Hybrid Machine Learning Approach to Popularity Prediction of Newly\n  Released Contents for Online Video Streaming Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the industry of video content providers such as VOD and IPTV, predicting\nthe popularity of video contents in advance is critical not only from a\nmarketing perspective but also from a network optimization perspective. By\npredicting whether the content will be successful or not in advance, the\ncontent file, which is large, is efficiently deployed in the proper service\nproviding server, leading to network cost optimization. Many previous studies\nhave done view count prediction research to do this. However, the studies have\nbeen making predictions based on historical view count data from users. In this\ncase, the contents had been published to the users and already deployed on a\nservice server. These approaches make possible to efficiently deploy a content\nalready published but are impossible to use for a content that is not be\npublished. To address the problems, this research proposes a hybrid machine\nlearning approach to the classification model for the popularity prediction of\nnewly video contents which is not published. In this paper, we create a new\nvariable based on the related content of the specific content and divide entire\ndataset by the characteristics of the contents. Next, the prediction is\nperformed using XGBoosting and deep neural net based model according to the\ndata characteristics of the cluster. Our model uses metadata for contents for\nprediction, so we use categorical embedding techniques to solve the sparsity of\ncategorical variables and make them learn efficiently for the deep neural net\nmodel. As well, we use the FTRL-proximal algorithm to solve the problem of the\nview-count volatility of video content. We achieve overall better performance\nthan the previous standalone method with a dataset from one of the top\nstreaming service company.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 11:42:34 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Jeon", "Hongjun", ""], ["Seo", "Wonchul", ""], ["Park", "Eunjeong Lucy", ""], ["Choi", "Sungchul", ""]]}, {"id": "1901.09632", "submitter": "Wlodzislaw Duch", "authors": "W{\\l}odzis{\\l}aw Duch and Rafa{\\l} Adamczak and Yoichi Hayashi", "title": "Neural eliminators and classifiers", "comments": "11 pages, 1 fig", "journal-ref": "Early version presented at 7th International Conference on Neural\n  Information Processing 2000 (ICONIP), Dae-jong, Korea, ed. by Soo-Young Lee,\n  pp. 1029-1034", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification may not be reliable for several reasons: noise in the data,\ninsufficient input information, overlapping distributions and sharp definition\nof classes. Faced with several possibilities neural network may in such cases\nstill be useful if instead of a classification elimination of improbable\nclasses is done. Eliminators may be constructed using classifiers assigning new\ncases to a pool of several classes instead of just one winning class.\nElimination may be done with the help of several classifiers using modified\nerror functions. A real life medical application of neural network is presented\nillustrating the usefulness of elimination.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 12:57:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Duch", "W\u0142odzis\u0142aw", ""], ["Adamczak", "Rafa\u0142", ""], ["Hayashi", "Yoichi", ""]]}, {"id": "1901.09643", "submitter": "Wlodzislaw Duch", "authors": "Tomasz Maszczyk and W{\\l}odzis{\\l}aw Duch", "title": "Support Feature Machines", "comments": "8 pages, 9 figs. More at http://www.is.umk.pl/~duch/cv/WD-topics.html", "journal-ref": "World Congress on Computational Intelligence, IEEE Press, pp.\n  3852-3859, 2010", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines (SVMs) with various kernels have played dominant role\nin machine learning for many years, finding numerous applications. Although\nthey have many attractive features interpretation of their solutions is quite\ndifficult, the use of a single kernel type may not be appropriate in all areas\nof the input space, convergence problems for some kernels are not uncommon, the\nstandard quadratic programming solution has $O(m^3)$ time and $O(m^2)$ space\ncomplexity for $m$ training patterns. Kernel methods work because they\nimplicitly provide new, useful features. Such features, derived from various\nkernels and other vector transformations, may be used directly in any machine\nlearning algorithm, facilitating multiresolution, heterogeneous models of data.\nTherefore Support Feature Machines (SFM) based on linear models in the extended\nfeature spaces, enabling control over selection of support features, give at\nleast as good results as any kernel-based SVMs, removing all problems related\nto interpretation, scaling and convergence. This is demonstrated for a number\nof benchmark datasets analyzed with linear discrimination, SVM, decision trees\nand nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 13:49:19 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Maszczyk", "Tomasz", ""], ["Duch", "W\u0142odzis\u0142aw", ""]]}, {"id": "1901.09656", "submitter": "Aria Nosratinia", "authors": "Hussein Saad and Aria Nosratinia", "title": "EXIT Analysis for Community Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper employs the extrinsic information transfer (EXIT) method, a\ntechnique imported from the analysis of the iterative decoding of error control\ncodes, to study the performance of belief propagation in community detection in\nthe presence of side information. We consider both the detection of a single\n(hidden) community, as well as the problem of identifying two symmetric\ncommunities. For single community detection, this paper demonstrates the\nsuitability of EXIT to predict the asymptotic phase transition for weak\nrecovery. More importantly, EXIT analysis is leveraged to produce useful\ninsights such as the performance of belief propagation near the threshold. For\ntwo symmetric communities, the asymptotic residual error for belief propagation\nis calculated under finite-alphabet side information, generalizing a previous\nresult with noisy labels. EXIT analysis is used to illuminate the effect of\nside information on community detection, its relative importance depending on\nthe correlation of the graphical information with node labels, as well as the\neffect of side information on residual errors.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 21:56:59 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Saad", "Hussein", ""], ["Nosratinia", "Aria", ""]]}, {"id": "1901.09661", "submitter": "Yali Wan", "authors": "Yali Wan, Marina Meila", "title": "Measuring the Robustness of Graph Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a perturbation framework to measure the robustness\nof graph properties. Although there are already perturbation methods proposed\nto tackle this problem, they are limited by the fact that the strength of the\nperturbation cannot be well controlled. We firstly provide a perturbation\nframework on graphs by introducing weights on the nodes, of which the magnitude\nof perturbation can be easily controlled through the variance of the weights.\nMeanwhile, the topology of the graphs are also preserved to avoid\nuncontrollable strength in the perturbation. We then extend the measure of\nrobustness in the robust statistics literature to the graph properties.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 07:43:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wan", "Yali", ""], ["Meila", "Marina", ""]]}, {"id": "1901.09671", "submitter": "Zachary Charles", "authors": "Hongyi Wang, Zachary Charles, Dimitris Papailiopoulos", "title": "ErasureHead: Distributed Gradient Descent without Delays Using\n  Approximate Gradient Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ErasureHead, a new approach for distributed gradient descent (GD)\nthat mitigates system delays by employing approximate gradient coding. Gradient\ncoded distributed GD uses redundancy to exactly recover the gradient at each\niteration from a subset of compute nodes. ErasureHead instead uses approximate\ngradient codes to recover an inexact gradient at each iteration, but with\nhigher delay tolerance. Unlike prior work on gradient coding, we provide a\nperformance analysis that combines both delay and convergence guarantees. We\nestablish that down to a small noise floor, ErasureHead converges as quickly as\ndistributed GD and has faster overall runtime under a probabilistic delay\nmodel. We conduct extensive experiments on real world datasets and distributed\nclusters and demonstrate that our method can lead to significant speedups over\nboth standard and gradient coded GD.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:21:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wang", "Hongyi", ""], ["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1901.09674", "submitter": "Mahdi Khodayar", "authors": "Mahdi Khodayar, Jianhui Wang and Zhaoyu Wang", "title": "Deep Generative Graph Distribution Learning for Synthetic Power Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Power system studies require the topological structures of real-world power\nnetworks; however, such data is confidential due to important security\nconcerns. Thus, power grid synthesis (PGS), i.e., creating realistic power\ngrids that imitate actual power networks, has gained significant attention. In\nthis letter, we cast PGS into a graph distribution learning (GDL) problem where\nthe probability distribution functions (PDFs) of the nodes (buses) and edges\n(lines) are captured. A novel deep GDL (DeepGDL) model is proposed to learn the\ntopological patterns of buses/lines with their physical features (e.g., power\ninjection and line impedance). Having a deep nonlinear recurrent structure,\nDeepGDL understands complex nonlinear topological properties and captures the\ngraph PDF. Sampling from the obtained PDF, we are able to create a large set of\nrealistic networks that all resemble the original power grid. Simulation\nresults show the significant accuracy of our created synthetic power grids in\nterms of various topological metrics and power flow measurements.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 20:55:53 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 19:43:27 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 16:35:09 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Khodayar", "Mahdi", ""], ["Wang", "Jianhui", ""], ["Wang", "Zhaoyu", ""]]}, {"id": "1901.09676", "submitter": "Leihui Chen", "authors": "Ming Gao, Xiangnan He, Leihui Chen, Tingting Liu, Jinglin Zhang and\n  Aoying Zhou", "title": "Learning Vertex Representations for Bipartite Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a widespread increase of interest in network\nrepresentation learning (NRL). By far most research efforts have focused on NRL\nfor homogeneous networks like social networks where vertices are of the same\ntype, or heterogeneous networks like knowledge graphs where vertices (and/or\nedges) are of different types. There has been relatively little research\ndedicated to NRL for bipartite networks. Arguably, generic network embedding\nmethods like node2vec and LINE can also be applied to learn vertex embeddings\nfor bipartite networks by ignoring the vertex type information. However, these\nmethods are suboptimal in doing so, since real-world bipartite networks concern\nthe relationship between two types of entities, which usually exhibit different\nproperties and patterns from other types of network data. For example,\nE-Commerce recommender systems need to capture the collaborative filtering\npatterns between customers and products, and search engines need to consider\nthe matching signals between queries and webpages.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 01:08:42 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 18:47:46 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Gao", "Ming", ""], ["He", "Xiangnan", ""], ["Chen", "Leihui", ""], ["Liu", "Tingting", ""], ["Zhang", "Jinglin", ""], ["Zhou", "Aoying", ""]]}, {"id": "1901.09680", "submitter": "Kshiteesh Hegde", "authors": "Malik Magdon-Ismail, Kshiteesh Hegde", "title": "The Intrinsic Scale of Networks is Small", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define the intrinsic scale at which a network begins to reveal its\nidentity as the scale at which subgraphs in the network (created by a random\nwalk) are distinguishable from similar sized subgraphs in a perturbed copy of\nthe network. We conduct an extensive study of intrinsic scale for several\nnetworks, ranging from structured (e.g. road networks) to ad-hoc and\nunstructured (e.g. crowd sourced information networks), to biological. We find:\n(a) The intrinsic scale is surprisingly small (7-20 vertices), even though the\nnetworks are many orders of magnitude larger. (b) The intrinsic scale\nquantifies ``structure'' in a network -- networks which are explicitly\nconstructed for specific tasks have smaller intrinsic scale. (c) The structure\nat different scales can be fragile (easy to disrupt) or robust.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 03:31:47 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Magdon-Ismail", "Malik", ""], ["Hegde", "Kshiteesh", ""]]}, {"id": "1901.09681", "submitter": "Kshiteesh Hegde", "authors": "Kshiteesh Hegde, Malik Magdon-Ismail", "title": "Network Lens: Node Classification in Topologically Heterogeneous\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of identifying different behaviors occurring in\ndifferent parts of a large heterogenous network. We zoom in to the network\nusing lenses of different sizes to capture the local structure of the network.\nThese network signatures are then weighted to provide a set of predicted labels\nfor every node. We achieve a peak accuracy of $\\sim42\\%$ (random=$11\\%$) on two\nnetworks with $\\sim100,000$ and $\\sim1,000,000$ nodes each. Further, we perform\nbetter than random even when the given node is connected to up to 5 different\ntypes of networks. Finally, we perform this analysis on homogeneous networks\nand show that highly structured networks have high homogeneity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 03:31:54 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hegde", "Kshiteesh", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1901.09697", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Bayesian Differential Privacy for Machine Learning", "comments": "International Conference on Machine Learning (ICML 2020). 15 pages, 5\n  figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional differential privacy is independent of the data distribution.\nHowever, this is not well-matched with the modern machine learning context,\nwhere models are trained on specific data. As a result, achieving meaningful\nprivacy guarantees in ML often excessively reduces accuracy. We propose\nBayesian differential privacy (BDP), which takes into account the data\ndistribution to provide more practical privacy guarantees. We also derive a\ngeneral privacy accounting method under BDP, building upon the well-known\nmoments accountant. Our experiments demonstrate that in-distribution samples in\nclassic machine learning datasets, such as MNIST and CIFAR-10, enjoy\nsignificantly stronger privacy guarantees than postulated by DP, while models\nmaintain high classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:37:17 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 16:52:13 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 14:57:23 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 18:28:40 GMT"}, {"version": "v5", "created": "Wed, 19 Aug 2020 19:05:19 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1901.09699", "submitter": "Chun-Hao Chang", "authors": "Chun-Hao Chang, Mingjie Mai, Anna Goldenberg", "title": "Dynamic Measurement Scheduling for Event Forecasting using Deep RL", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine a patient in critical condition. What and when should be measured to\nforecast detrimental events, especially under the budget constraints? We answer\nthis question by deep reinforcement learning (RL) that jointly minimizes the\nmeasurement cost and maximizes predictive gain, by scheduling\nstrategically-timed measurements. We learn our policy to be dynamically\ndependent on the patient's health history. To scale our framework to\nexponentially large action space, we distribute our reward in a sequential\nsetting that makes the learning easier. In our simulation, our policy\noutperforms heuristic-based scheduling with higher predictive gain and lower\ncost. In a real-world ICU mortality prediction task (MIMIC3), our policies\nreduce the total number of measurements by $31\\%$ or improve predictive gain by\na factor of $3$ as compared to physicians, under the off-policy policy\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:43:58 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 21:59:30 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 21:54:52 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chang", "Chun-Hao", ""], ["Mai", "Mingjie", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1901.09712", "submitter": "Frank Nussbaum", "authors": "Frank Nussbaum, Joachim Giesen", "title": "Ising Models with Latent Conditional Gaussian Variables", "comments": "short version (without proofs) appeared in the Proceedings of the\n  30th International Conference on Algorithmic Learning Theory, PMLR\n  (http://proceedings.mlr.press/v98/nussbaum19a.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ising models describe the joint probability distribution of a vector of\nbinary feature variables. Typically, not all the variables interact with each\nother and one is interested in learning the presumably sparse network structure\nof the interacting variables. However, in the presence of latent variables, the\nconventional method of learning a sparse model might fail. This is because the\nlatent variables induce indirect interactions of the observed variables. In the\ncase of only a few latent conditional Gaussian variables these spurious\ninteractions contribute an additional low-rank component to the interaction\nparameters of the observed Ising model. Therefore, we propose to learn a sparse\n+ low-rank decomposition of the parameters of an Ising model using a convex\nregularized likelihood problem. We show that the same problem can be obtained\nas the dual of a maximum-entropy problem with a new type of relaxation, where\nthe sample means collectively need to match the expected values only up to a\ngiven tolerance. The solution to the convex optimization problem has\nconsistency properties in the high-dimensional setting, where the number of\nobserved binary variables and the number of latent conditional Gaussian\nvariables are allowed to grow with the number of training samples.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:54:47 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 15:07:30 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Nussbaum", "Frank", ""], ["Giesen", "Joachim", ""]]}, {"id": "1901.09715", "submitter": "Lorenzo Dall'Amico", "authors": "Lorenzo Dall'Amico, Romain Couillet, Nicolas Tremblay", "title": "Revisiting the Bethe-Hessian: Improved Community Detection in Sparse\n  Heterogeneous Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most popular, yet still incompletely\nunderstood, methods for community detection on graphs. This article studies\nspectral clustering based on the Bethe-Hessian matrix $H_r = (r^2-1)I_n + D-rA$\nfor sparse heterogeneous graphs (following the degree-corrected stochastic\nblock model) in a two-class setting. For a specific value $r = \\zeta$,\nclustering is shown to be insensitive to the degree heterogeneity. We then\nstudy the behavior of the informative eigenvector of $H_{\\zeta}$ and, as a\nresult, predict the clustering accuracy. The article concludes with an overview\nof the generalization to more than two classes along with extensive simulations\non synthetic and real networks corroborating our findings.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:15:48 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 11:16:26 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 14:49:15 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Dall'Amico", "Lorenzo", ""], ["Couillet", "Romain", ""], ["Tremblay", "Nicolas", ""]]}, {"id": "1901.09720", "submitter": "Pierre Fournier", "authors": "Pierre Fournier, Olivier Sigaud, C\\'edric Colas, Mohamed Chetouani", "title": "CLIC: Curriculum Learning and Imitation for object Control in\n  non-rewarding environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a new reinforcement learning setting where the\nenvironment is non-rewarding, contains several possibly related objects of\nvarious controllability, and where an apt agent Bob acts independently, with\nnon-observable intentions. We argue that this setting defines a realistic\nscenario and we present a generic discrete-state discrete-action model of such\nenvironments. To learn in this environment, we propose an unsupervised\nreinforcement learning agent called CLIC for Curriculum Learning and Imitation\nfor Control. CLIC learns to control individual objects in its environment, and\nimitates Bob's interactions with these objects. It selects objects to focus on\nwhen training and imitating by maximizing its learning progress. We show that\nCLIC is an effective baseline in our new setting. It can effectively observe\nBob to gain control of objects faster, even if Bob is not explicitly teaching.\nIt can also follow Bob when he acts as a mentor and provides ordered\ndemonstrations. Finally, when Bob controls objects that the agent cannot, or in\npresence of a hierarchy between objects in the environment, we show that CLIC\nignores non-reproducible and already mastered interactions with objects,\nresulting in a greater benefit from imitation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 15:00:29 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 08:49:02 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 19:45:33 GMT"}, {"version": "v4", "created": "Mon, 25 Mar 2019 10:04:05 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Fournier", "Pierre", ""], ["Sigaud", "Olivier", ""], ["Colas", "C\u00e9dric", ""], ["Chetouani", "Mohamed", ""]]}, {"id": "1901.09732", "submitter": "L\\'eonard Blier", "authors": "Corentin Tallec and L\\'eonard Blier and Yann Ollivier", "title": "Making Deep Q-learning methods robust to time discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable successes, Deep Reinforcement Learning (DRL) is not robust\nto hyperparameterization, implementation details, or small environment changes\n(Henderson et al. 2017, Zhang et al. 2018). Overcoming such sensitivity is key\nto making DRL applicable to real world problems. In this paper, we identify\nsensitivity to time discretization in near continuous-time environments as a\ncritical factor; this covers, e.g., changing the number of frames per second,\nor the action frequency of the controller. Empirically, we find that\nQ-learning-based approaches such as Deep Q- learning (Mnih et al., 2015) and\nDeep Deterministic Policy Gradient (Lillicrap et al., 2015) collapse with small\ntime steps. Formally, we prove that Q-learning does not exist in continuous\ntime. We detail a principled way to build an off-policy RL algorithm that\nyields similar performances over a wide range of time discretizations, and\nconfirm this robustness empirically.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 15:25:10 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 15:10:27 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Tallec", "Corentin", ""], ["Blier", "L\u00e9onard", ""], ["Ollivier", "Yann", ""]]}, {"id": "1901.09749", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, Hiromi Arai, Olivier Fortineau, S\\'ebastien Gambs,\n  Satoshi Hara, Alain Tapp", "title": "Fairwashing: the risk of rationalization", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box explanation is the problem of explaining how a machine learning\nmodel -- whose internal logic is hidden to the auditor and generally complex --\nproduces its outcomes. Current approaches for solving this problem include\nmodel explanation, outcome explanation as well as model inspection. While these\ntechniques can be beneficial by providing interpretability, they can be used in\na negative manner to perform fairwashing, which we define as promoting the\nfalse perception that a machine learning model respects some ethical values. In\nparticular, we demonstrate that it is possible to systematically rationalize\ndecisions taken by an unfair black-box model using the model explanation as\nwell as the outcome explanation approaches with a given fairness metric. Our\nsolution, LaundryML, is based on a regularized rule list enumeration algorithm\nwhose objective is to search for fair rule lists approximating an unfair\nblack-box model. We empirically evaluate our rationalization technique on\nblack-box models trained on real-world datasets and show that one can obtain\nrule lists with high fidelity to the black-box model while being considerably\nless unfair at the same time.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 15:47:07 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 00:53:41 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 15:12:03 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Arai", "Hiromi", ""], ["Fortineau", "Olivier", ""], ["Gambs", "S\u00e9bastien", ""], ["Hara", "Satoshi", ""], ["Tapp", "Alain", ""]]}, {"id": "1901.09764", "submitter": "Jong Chul Ye", "authors": "Dongwook Lee, Junyoung Kim, Won-Jin Moon, Jong Chul Ye", "title": "CollaGAN : Collaborative GAN for Missing Image Data Imputation", "comments": "CVPR 2019 Camera Ready Version (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications requiring multiple inputs to obtain a desired output, if\nany of the input data is missing, it often introduces large amounts of bias.\nAlthough many techniques have been developed for imputing missing data, the\nimage imputation is still difficult due to complicated nature of natural\nimages. To address this problem, here we proposed a novel framework for missing\nimage data imputation, called Collaborative Generative Adversarial Network\n(CollaGAN). CollaGAN converts an image imputation problem to a multi-domain\nimages-to-image translation task so that a single generator and discriminator\nnetwork can successfully estimate the missing data using the remaining clean\ndata set. We demonstrate that CollaGAN produces the images with a higher visual\nquality compared to the existing competing approaches in various image\nimputation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 16:10:12 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 11:58:57 GMT"}, {"version": "v3", "created": "Mon, 29 Apr 2019 19:46:06 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Lee", "Dongwook", ""], ["Kim", "Junyoung", ""], ["Moon", "Won-Jin", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1901.09813", "submitter": "Carl Allen", "authors": "Carl Allen and Timothy Hospedales", "title": "Analogies Explained: Towards Understanding Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings generated by neural network methods such as word2vec (W2V)\nare well known to exhibit seemingly linear behaviour, e.g. the embeddings of\nanalogy \"woman is to queen as man is to king\" approximately describe a\nparallelogram. This property is particularly intriguing since the embeddings\nare not trained to achieve it. Several explanations have been proposed, but\neach introduces assumptions that do not hold in practice. We derive a\nprobabilistically grounded definition of paraphrasing that we re-interpret as\nword transformation, a mathematical description of \"$w_x$ is to $w_y$\". From\nthese concepts we prove existence of linear relationships between W2V-type\nembeddings that underlie the analogical phenomenon, identifying explicit error\nterms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:04:25 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 19:02:42 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Allen", "Carl", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1901.09821", "submitter": "David Mac\\^edo", "authors": "Andr\\'ea B. Duque, Lu\\~a L\\'azaro J. Santos, David Mac\\^edo, Cleber\n  Zanchettin", "title": "Squeezed Very Deep Convolutional Neural Networks for Text Classification", "comments": null, "journal-ref": "2019 International Conference on Artificial Neural Networks\n  (ICANN)", "doi": "10.1007/978-3-030-30487-4_16", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the research in convolutional neural networks has focused on\nincreasing network depth to improve accuracy, resulting in a massive number of\nparameters which restricts the trained network to platforms with memory and\nprocessing constraints. We propose to modify the structure of the Very Deep\nConvolutional Neural Networks (VDCNN) model to fit mobile platforms constraints\nand keep performance. In this paper, we evaluate the impact of Temporal\nDepthwise Separable Convolutions and Global Average Pooling in the network\nparameters, storage size, and latency. The squeezed model (SVDCNN) is between\n10x and 20x smaller, depending on the network depth, maintaining a maximum size\nof 6MB. Regarding accuracy, the network experiences a loss between 0.4% and\n1.3% and obtains lower latencies compared to the baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:14:12 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Duque", "Andr\u00e9a B.", ""], ["Santos", "Lu\u00e3 L\u00e1zaro J.", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.09827", "submitter": "Li Zhang", "authors": "Li Zhang", "title": "Depth creates no more spurious local minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any convex differentiable loss, a deep linear network has no\nspurious local minima as long as it is true for the two layer case. This\nreduction greatly simplifies the study on the existence of spurious local\nminima in deep linear networks. When applied to the quadratic loss, our result\nimmediately implies the powerful result in [Kawaguchi 2016]. Further, with the\nwork in [Zhou and Liang 2018], we can remove all the assumptions in [Kawaguchi\n2016]. This property holds for more general \"multi-tower\" linear networks too.\nOur proof builds on [Laurent and von Brecht 2018] and develops a new\nperturbation argument to show that any spurious local minimum must have full\nrank, a structural property which can be useful more generally.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:25:27 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 00:44:57 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Li", ""]]}, {"id": "1901.09838", "submitter": "Alexander Jung", "authors": "Alexander Jung, Alfred O. Hero III, Alexandru Mara, Saeed Jahromi,\n  Ayelet Heimowitz, Yonina C. Eldar", "title": "Semi-supervised Learning in Network-Structured Data via Total Variation\n  Minimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2953593", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a method for semi-supervised learning from\npartially-labeled network-structured data. Our approach is based on a graph\nsignal recovery interpretation under a clustering hypothesis that labels of\ndata points belonging to the same well-connected subset (cluster) are similar\nvalued. This lends naturally to learning the labels by total variation (TV)\nminimization, which we solve by applying a recently proposed primal-dual method\nfor non-smooth convex optimization. The resulting algorithm allows for a highly\nscalable implementation using message passing over the underlying empirical\ngraph, which renders the algorithm suitable for big data applications. By\napplying tools of compressed sensing, we derive a sufficient condition on the\nunderlying network structure such that TV minimization recovers clusters in the\nempirical graph of the data. In particular, we show that the proposed\nprimal-dual method amounts to maximizing network flows over the empirical graph\nof the dataset. Moreover, the learning accuracy of the proposed algorithm is\nlinked to the set of network flows between data points having known labels. The\neffectiveness and scalability of our approach is verified by numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:33:54 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 19:23:29 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Jung", "Alexander", ""], ["Hero", "Alfred O.", "III"], ["Mara", "Alexandru", ""], ["Jahromi", "Saeed", ""], ["Heimowitz", "Ayelet", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1901.09839", "submitter": "Jonathan Ish-Horowicz", "authors": "Jonathan Ish-Horowicz, Dana Udwin, Seth Flaxman, Sarah Filippi, Lorin\n  Crawford", "title": "Interpreting Deep Neural Networks Through Variable Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the success of deep neural networks (DNNs) is well-established across a\nvariety of domains, our ability to explain and interpret these methods is\nlimited. Unlike previously proposed local methods which try to explain\nparticular classification decisions, we focus on global interpretability and\nask a universally applicable question: given a trained model, which features\nare the most important? In the context of neural networks, a feature is rarely\nimportant on its own, so our strategy is specifically designed to leverage\npartial covariance structures and incorporate variable dependence into feature\nranking. Our methodological contributions in this paper are two-fold. First, we\npropose an effect size analogue for DNNs that is appropriate for applications\nwith highly collinear predictors (ubiquitous in computer vision). Second, we\nextend the recently proposed \"RelATive cEntrality\" (RATE) measure (Crawford et\nal., 2019) to the Bayesian deep learning setting. RATE applies an information\ntheoretic criterion to the posterior distribution of effect sizes to assess\nfeature significance. We apply our framework to three broad application areas:\ncomputer vision, natural language processing, and social science.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:34:06 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 10:19:25 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 13:47:21 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ish-Horowicz", "Jonathan", ""], ["Udwin", "Dana", ""], ["Flaxman", "Seth", ""], ["Filippi", "Sarah", ""], ["Crawford", "Lorin", ""]]}, {"id": "1901.09847", "submitter": "Sai Praneeth Karimireddy", "authors": "Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian U. Stich, and\n  Martin Jaggi", "title": "Error Feedback Fixes SignSGD and other Gradient Compression Schemes", "comments": "ICML 2019 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign-based algorithms (e.g. signSGD) have been proposed as a biased gradient\ncompression technique to alleviate the communication bottleneck in training\nlarge neural networks across multiple workers. We show simple convex\ncounter-examples where signSGD does not converge to the optimum. Further, even\nwhen it does converge, signSGD may generalize poorly when compared with SGD.\nThese issues arise because of the biased nature of the sign compression\noperator. We then show that using error-feedback, i.e. incorporating the error\nmade by the compression operator into the next step, overcomes these issues. We\nprove that our algorithm EF-SGD with arbitrary compression operator achieves\nthe same rate of convergence as SGD without any additional assumptions. Thus\nEF-SGD achieves gradient compression for free. Our experiments thoroughly\nsubstantiate the theory and show that error-feedback improves both convergence\nand generalization. Code can be found at\n\\url{https://github.com/epfml/error-feedback-SGD}.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:39:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 12:57:30 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Karimireddy", "Sai Praneeth", ""], ["Rebjock", "Quentin", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1901.09849", "submitter": "Vahid Partovi Nia", "authors": "Farnoush Farhadi, Vahid Partovi Nia, Andrea Lodi", "title": "Activation Adaptation in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural network architectures rely on the choice of the activation\nfunction for each hidden layer. Given the activation function, the neural\nnetwork is trained over the bias and the weight parameters. The bias catches\nthe center of the activation, and the weights capture the scale. Here we\npropose to train the network over a shape parameter as well. This view allows\neach neuron to tune its own activation function and adapt the neuron curvature\ntowards a better prediction. This modification only adds one further equation\nto the back-propagation for each neuron. Re-formalizing activation functions as\nCDF generalizes the class of activation function extensively. We aimed at\ngeneralizing an extensive class of activation functions to study: i) skewness\nand ii) smoothness of activation functions. Here we introduce adaptive Gumbel\nactivation function as a bridge between Gumbel and sigmoid. A similar approach\nis used to invent a smooth version of ReLU. Our comparison with common\nactivation functions suggests different data representation especially in early\nneural network layers. This adaptation also provides prediction improvement.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:42:10 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 21:40:39 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Farhadi", "Farnoush", ""], ["Nia", "Vahid Partovi", ""], ["Lodi", "Andrea", ""]]}, {"id": "1901.09878", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah\n  Hanif, Maurizio Martina, Muhammad Shafique", "title": "CapsAttacks: Robust and Imperceptible Adversarial Attacks on Capsule\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks preserve the hierarchical spatial relationships between\nobjects, and thereby bears a potential to surpass the performance of\ntraditional Convolutional Neural Networks (CNNs) in performing tasks like image\nclassification. A large body of work has explored adversarial examples for\nCNNs, but their effectiveness on Capsule Networks has not yet been well\nstudied. In our work, we perform an analysis to study the vulnerabilities in\nCapsule Networks to adversarial attacks. These perturbations, added to the test\ninputs, are small and imperceptible to humans, but can fool the network to\nmispredict. We propose a greedy algorithm to automatically generate targeted\nimperceptible adversarial examples in a black-box attack scenario. We show that\nthis kind of attacks, when applied to the German Traffic Sign Recognition\nBenchmark (GTSRB), mislead Capsule Networks. Moreover, we apply the same kind\nof adversarial attacks to a 5-layer CNN and a 9-layer CNN, and analyze the\noutcome, compared to the Capsule Networks to study differences in their\nbehavior.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 18:50:52 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:52:46 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Marchisio", "Alberto", ""], ["Nanfa", "Giorgio", ""], ["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1901.09881", "submitter": "Robert Cornish", "authors": "Robert Cornish, Paul Vanetti, Alexandre Bouchard-C\\^ot\\'e, George\n  Deligiannidis, Arnaud Doucet", "title": "Scalable Metropolis-Hastings for Exact Bayesian Inference with Large\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference via standard Markov Chain Monte Carlo (MCMC) methods is\ntoo computationally intensive to handle large datasets, since the cost per step\nusually scales like $\\Theta(n)$ in the number of data points $n$. We propose\nthe Scalable Metropolis-Hastings (SMH) kernel that exploits Gaussian\nconcentration of the posterior to require processing on average only $O(1)$ or\neven $O(1/\\sqrt{n})$ data points per step. This scheme is based on a\ncombination of factorized acceptance probabilities, procedures for fast\nsimulation of Bernoulli processes, and control variate ideas. Contrary to many\nMCMC subsampling schemes such as fixed step-size Stochastic Gradient Langevin\nDynamics, our approach is exact insofar as the invariant distribution is the\ntrue posterior and not an approximation to it. We characterise the performance\nof our algorithm theoretically, and give realistic and verifiable conditions\nunder which it is geometrically ergodic. This theory is borne out by empirical\nresults that demonstrate overall performance benefits over standard\nMetropolis-Hastings and various subsampling algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 18:54:11 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 16:40:56 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 22:39:02 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Cornish", "Robert", ""], ["Vanetti", "Paul", ""], ["Bouchard-C\u00f4t\u00e9", "Alexandre", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1901.09887", "submitter": "Bau David", "authors": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B.\n  Tenenbaum, William T. Freeman, Antonio Torralba", "title": "On the Units of GANs (Extended Abstract)", "comments": "In AAAI-19 workshop on Network Interpretability for Deep Learning\n  arXiv admin note: substantial text overlap with arXiv:1811.10597", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have achieved impressive results for\nmany real-world applications. As an active research topic, many GAN variants\nhave emerged with improvements in sample quality and training stability.\nHowever, visualization and understanding of GANs is largely missing. How does a\nGAN represent our visual world internally? What causes the artifacts in GAN\nresults? How do architectural choices affect GAN learning? Answering such\nquestions could enable us to develop new insights and better models. In this\nwork, we present an analytic framework to visualize and understand GANs at the\nunit-, object-, and scene-level. We first identify a group of interpretable\nunits that are closely related to concepts with a segmentation-based network\ndissection method. We quantify the causal effect of interpretable units by\nmeasuring the ability of interventions to control objects in the output.\nFinally, we examine the contextual relationship between these units and their\nsurrounding by inserting the discovered concepts into new images. We show\nseveral practical applications enabled by our framework, from comparing\ninternal representations across different layers, models, and datasets, to\nimproving GANs by locating and removing artifact-causing units, to\ninteractively manipulating objects in the scene. We will open source our\ninteractive tools to help researchers and practitioners better understand their\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:16:54 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 13:37:24 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 04:33:44 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bau", "David", ""], ["Zhu", "Jun-Yan", ""], ["Strobelt", "Hendrik", ""], ["Zhou", "Bolei", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""], ["Torralba", "Antonio", ""]]}, {"id": "1901.09888", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Muhammad Ammad-ud-din, Elena Ivannikova, Suleiman A. Khan, Were\n  Oyomno, Qiang Fu, Kuan Eeik Tan and Adrian Flanagan", "title": "Federated Collaborative Filtering for Privacy-Preserving Personalized\n  Recommendation System", "comments": "12 pages, 2 figures, 2 tables, submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The increasing interest in user privacy is leading to new privacy preserving\nmachine learning paradigms. In the Federated Learning paradigm, a master\nmachine learning model is distributed to user clients, the clients use their\nlocally stored data and model for both inference and calculating model updates.\nThe model updates are sent back and aggregated on the server to update the\nmaster model then redistributed to the clients. In this paradigm, the user data\nnever leaves the client, greatly enhancing the user' privacy, in contrast to\nthe traditional paradigm of collecting, storing and processing user data on a\nbackend server beyond the user's control. In this paper we introduce, as far as\nwe are aware, the first federated implementation of a Collaborative Filter. The\nfederated updates to the model are based on a stochastic gradient approach. As\na classical case study in machine learning, we explore a personalized\nrecommendation system based on users' implicit feedback and demonstrate the\nmethod's applicability to both the MovieLens and an in-house dataset. Empirical\nvalidation confirms a collaborative filter can be federated without a loss of\naccuracy compared to a standard implementation, hence enhancing the user's\nprivacy in a widely used recommender application while maintaining recommender\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:18:38 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ammad-ud-din", "Muhammad", ""], ["Ivannikova", "Elena", ""], ["Khan", "Suleiman A.", ""], ["Oyomno", "Were", ""], ["Fu", "Qiang", ""], ["Tan", "Kuan Eeik", ""], ["Flanagan", "Adrian", ""]]}, {"id": "1901.09890", "submitter": "Yu Cheng", "authors": "Yu Cheng, Mo Yu, Xiaoxiao Guo, Bowen Zhou", "title": "Few-shot Learning with Meta Metric Learners", "comments": "Published in NIPS 2017 workshop on Meta-Learning, arXiv version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot Learning aims to learn classifiers for new classes with only a few\ntraining examples per class. Existing meta-learning or metric-learning based\nfew-shot learning approaches are limited in handling diverse domains with\nvarious number of labels. The meta-learning approaches train a meta learner to\npredict weights of homogeneous-structured task-specific networks, requiring a\nuniform number of classes across tasks. The metric-learning approaches learn\none task-invariant metric for all the tasks, and they fail if the tasks\ndiverge. We propose to deal with these limitations with meta metric learning.\nOur meta metric learning approach consists of task-specific learners, that\nexploit metric learning to handle flexible labels, and a meta learner, that\ndiscovers good parameters and gradient decent to specify the metrics in\ntask-specific learners. Thus the proposed model is able to handle unbalanced\nclasses as well as to generate task-specific metrics. We test our approach in\nthe `$k$-shot $N$-way' few-shot learning setting used in previous work and new\nrealistic few-shot setting with diverse multi-domain tasks and flexible label\nnumbers. Experiments show that our approach attains superior performances in\nboth settings.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 01:55:33 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Cheng", "Yu", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Zhou", "Bowen", ""]]}, {"id": "1901.09892", "submitter": "Xiaolei Liu", "authors": "Xiaolei Liu, Yuheng Luo, Xiaosong Zhang, Qingxin Zhu", "title": "A Black-box Attack on Neural Networks Based on Swarm Evolutionary\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks play an increasingly important role in the field of machine\nlearning and are included in many applications in society. Unfortunately,\nneural networks suffer from adversarial samples generated to attack them.\nHowever, most of the generation approaches either assume that the attacker has\nfull knowledge of the neural network model or are limited by the type of\nattacked model. In this paper, we propose a new approach that generates a\nblack-box attack to neural networks based on the swarm evolutionary algorithm.\nBenefiting from the improvements in the technology and theoretical\ncharacteristics of evolutionary algorithms, our approach has the advantages of\neffectiveness, black-box attack, generality, and randomness. Our experimental\nresults show that both the MNIST images and the CIFAR-10 images can be\nperturbed to successful generate a black-box attack with 100\\% probability on\naverage. In addition, the proposed attack, which is successful on distilled\nneural networks with almost 100\\% probability, is resistant to defensive\ndistillation. The experimental results also indicate that the robustness of the\nartificial intelligence algorithm is related to the complexity of the model and\nthe data set. In addition, we find that the adversarial samples to some extent\nreproduce the characteristics of the sample data learned by the neural network\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 10:25:57 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Liu", "Xiaolei", ""], ["Luo", "Yuheng", ""], ["Zhang", "Xiaosong", ""], ["Zhu", "Qingxin", ""]]}, {"id": "1901.09895", "submitter": "Andrew Melnik", "authors": "Andrew Melnik, Sascha Fleer, Malte Schilling, Helge Ritter", "title": "Modularization of End-to-End Learning: Case Study in Arcade Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex environments and tasks pose a difficult problem for holistic\nend-to-end learning approaches. Decomposition of an environment into\ninteracting controllable and non-controllable objects allows supervised\nlearning for non-controllable objects and universal value function approximator\nlearning for controllable objects. Such decomposition should lead to a shorter\nlearning time and better generalisation capability. Here, we consider\narcade-game environments as sets of interacting objects (controllable,\nnon-controllable) and propose a set of functional modules that are specialized\non mastering different types of interactions in a broad range of environments.\nThe modules utilize regression, supervised learning, and reinforcement learning\nalgorithms. Results of this case study in different Atari games suggest that\nhuman-level performance can be achieved by a learning agent within a human\namount of game experience (10-15 minutes game time) when a proper decomposition\nof an environment or a task is provided. However, automatization of such\ndecomposition remains a challenging problem. This case study shows how a model\nof a causal structure underlying an environment or a task can benefit learning\ntime and generalization capability of the agent, and argues in favor of\nexploiting modular structure in contrast to using pure end-to-end learning\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 05:06:30 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Melnik", "Andrew", ""], ["Fleer", "Sascha", ""], ["Schilling", "Malte", ""], ["Ritter", "Helge", ""]]}, {"id": "1901.09902", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "The CM Algorithm for the Maximum Mutual Information Classifications of\n  Unseen Instances", "comments": "6 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximum Mutual Information (MMI) criterion is different from the Least\nError Rate (LER) criterion. It can reduce failing to report small probability\nevents. This paper introduces the Channels Matching (CM) algorithm for the MMI\nclassifications of unseen instances. It also introduces some semantic\ninformation methods, which base the CM algorithm. In the CM algorithm, label\nlearning is to let the semantic channel match the Shannon channel (Matching I)\nwhereas classifying is to let the Shannon channel match the semantic channel\n(Matching II). We can achieve the MMI classifications by repeating Matching I\nand II. For low-dimensional feature spaces, we only use parameters to construct\nn likelihood functions for n different classes (rather than to construct\npartitioning boundaries as gradient descent) and expresses the boundaries by\nnumerical values. Without searching in parameter spaces, the computation of the\nCM algorithm for low-dimensional feature spaces is very simple and fast. Using\na two-dimensional example, we test the speed and reliability of the CM\nalgorithm by different initial partitions. For most initial partitions, two\niterations can make the mutual information surpass 99% of the convergent MMI.\nThe analysis indicates that for high-dimensional feature spaces, we may combine\nthe CM algorithm with neural networks to improve the MMI classifications for\nfaster and more reliable convergence.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 00:54:59 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1901.09906", "submitter": "Su-Jin Shin", "authors": "Su-Jin Shin, Kyungwoo Song, Il-Chul Moon", "title": "Hierarchically Clustered Representation Learning", "comments": "10 pages, 7 figures, Under review as a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint optimization of representation learning and clustering in the\nembedding space has experienced a breakthrough in recent years. In spite of the\nadvance, clustering with representation learning has been limited to flat-level\ncategories, which often involves cohesive clustering with a focus on instance\nrelations. To overcome the limitations of flat clustering, we introduce\nhierarchically-clustered representation learning (HCRL), which simultaneously\noptimizes representation learning and hierarchical clustering in the embedding\nspace. Compared with a few prior works, HCRL firstly attempts to consider a\ngeneration of deep embeddings from every component of the hierarchy, not just\nleaf components. In addition to obtaining hierarchically clustered embeddings,\nwe can reconstruct data by the various abstraction levels, infer the intrinsic\nhierarchical structure, and learn the level-proportion features. We conducted\nevaluations with image and text domains, and our quantitative analyses showed\ncompetent likelihoods and the best accuracies compared with the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 07:04:19 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 11:25:27 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Shin", "Su-Jin", ""], ["Song", "Kyungwoo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1901.09917", "submitter": "David Watson", "authors": "David S. Watson and Marvin N. Wright", "title": "Testing Conditional Independence in Supervised Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose the conditional predictive impact (CPI), a consistent and unbiased\nestimator of the association between one or several features and a given\noutcome, conditional on a reduced feature set. Building on the knockoff\nframework of Cand\\`es et al. (2018), we develop a novel testing procedure that\nworks in conjunction with any valid knockoff sampler, supervised learning\nalgorithm, and loss function. The CPI can be efficiently computed for\nhigh-dimensional data without any sparsity constraints. We demonstrate\nconvergence criteria for the CPI and develop statistical inference procedures\nfor evaluating its magnitude, significance, and precision. These tests aid in\nfeature and model selection, extending traditional frequentist and Bayesian\ntechniques to general supervised learning tasks. The CPI may also be applied in\ncausal discovery to identify underlying multivariate graph structures. We test\nour method using various algorithms, including linear regression, neural\nnetworks, random forests, and support vector machines. Empirical results show\nthat the CPI compares favorably to alternative variable importance measures and\nother nonparametric tests of conditional independence on a diverse array of\nreal and simulated datasets. Simulations confirm that our inference procedures\nsuccessfully control Type I error and achieve nominal coverage probability. Our\nmethod has been implemented in an R package, cpi, which can be downloaded from\nhttps://github.com/dswatson/cpi.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:12:00 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 21:23:25 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 12:24:04 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 14:42:46 GMT"}, {"version": "v5", "created": "Thu, 13 May 2021 16:09:59 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Watson", "David S.", ""], ["Wright", "Marvin N.", ""]]}, {"id": "1901.09919", "submitter": "Muhammad Osama", "authors": "Muhammad Osama, Dave Zachariah, Thomas B. Sch\\\"on", "title": "Inferring Heterogeneous Causal Effects in Presence of Spatial\n  Confounding", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of inferring the causal effect of an exposure on an\noutcome across space, using observational data. The data is possibly subject to\nunmeasured confounding variables which, in a standard approach, must be\nadjusted for by estimating a nuisance function. Here we develop a method that\neliminates the nuisance function, while mitigating the resulting\nerrors-in-variables. The result is a robust and accurate inference method for\nspatially varying heterogeneous causal effects. The properties of the method\nare demonstrated on synthetic as well as real data from Germany and the US.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:29:34 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 15:19:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Osama", "Muhammad", ""], ["Zachariah", "Dave", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1901.09960", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Kimin Lee and Mantas Mazeika", "title": "Using Pre-Training Can Improve Model Robustness and Uncertainty", "comments": "ICML 2019. PyTorch code here:\n  https://github.com/hendrycks/pre-training Figure 3 updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  He et al. (2018) have called into question the utility of pre-training by\nshowing that training from scratch can often yield similar performance to\npre-training. We show that although pre-training may not improve performance on\ntraditional classification metrics, it improves model robustness and\nuncertainty estimates. Through extensive experiments on adversarial examples,\nlabel corruption, class imbalance, out-of-distribution detection, and\nconfidence calibration, we demonstrate large gains from pre-training and\ncomplementary effects with task-specific methods. We introduce adversarial\npre-training and show approximately a 10% absolute improvement over the\nprevious state-of-the-art in adversarial robustness. In some cases, using\npre-training without task-specific methods also surpasses the state-of-the-art,\nhighlighting the need for pre-training when evaluating future methods on\nrobustness and uncertainty tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:37:07 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 05:52:57 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 16:37:36 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2019 17:14:48 GMT"}, {"version": "v5", "created": "Sun, 20 Oct 2019 20:09:20 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hendrycks", "Dan", ""], ["Lee", "Kimin", ""], ["Mazeika", "Mantas", ""]]}, {"id": "1901.09970", "submitter": "Liyu Gong", "authors": "Liyu Gong, Qiang Cheng", "title": "Lie Group Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an auto-encoder based generative neural network\nmodel whose encoder compresses the inputs into vectors in the tangent space of\na special Lie group manifold: upper triangular positive definite affine\ntransform matrices (UTDATs). UTDATs are representations of Gaussian\ndistributions and can straightforwardly generate Gaussian distributed samples.\nTherefore, the encoder is trained together with a decoder (generator) which\ntakes Gaussian distributed latent vectors as input. Compared with related\ngenerative models such as variational auto-encoder, the proposed model\nincorporates the information on geometric properties of Gaussian distributions.\nAs a special case, we derive an exponential mapping layer for diagonal Gaussian\nUTDATs which eliminates matrix exponential operator compared with general\nexponential mapping in Lie group theory. Moreover, we derive an intrinsic loss\nfor UTDAT Lie group which can be calculated as l-2 loss in the tangent space.\nFurthermore, inspired by the Lie group theory, we propose to use the Lie\nalgebra vectors rather than the raw parameters (e.g. mean) of Gaussian\ndistributions as compressed representations of original inputs. Experimental\nresults verity the effectiveness of the proposed new generative model and the\nbenefits gained from the Lie group structural information of UTDATs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:55:21 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Gong", "Liyu", ""], ["Cheng", "Qiang", ""]]}, {"id": "1901.09972", "submitter": "David Mac\\^edo", "authors": "Jefferson L. P. Lima, David Mac\\^edo, Cleber Zanchettin", "title": "Heartbeat Anomaly Detection using Adversarial Oversampling", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8852242", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular diseases are one of the most common causes of death in the\nworld. Prevention, knowledge of previous cases in the family, and early\ndetection is the best strategy to reduce this fact. Different machine learning\napproaches to automatic diagnostic are being proposed to this task. As in most\nhealth problems, the imbalance between examples and classes is predominant in\nthis problem and affects the performance of the automated solution. In this\npaper, we address the classification of heartbeats images in different\ncardiovascular diseases. We propose a two-dimensional Convolutional Neural\nNetwork for classification after using a InfoGAN architecture for generating\nsynthetic images to unbalanced classes. We call this proposal Adversarial\nOversampling and compare it with the classical oversampling methods as SMOTE,\nADASYN, and RandomOversampling. The results show that the proposed approach\nimproves the classifier performance for the minority classes without harming\nthe performance in the balanced classes.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:55:42 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Lima", "Jefferson L. P.", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.09981", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Moinuddin K. Qureshi", "title": "Improving Adversarial Robustness of Ensembles with Diversity Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are vulnerable to adversarial attacks even in settings\nwhere the attacker has no direct access to the model being attacked. Such\nattacks usually rely on the principle of transferability, whereby an attack\ncrafted on a surrogate model tends to transfer to the target model. We show\nthat an ensemble of models with misaligned loss gradients can provide an\neffective defense against transfer-based attacks. Our key insight is that an\nadversarial example is less likely to fool multiple models in the ensemble if\ntheir loss functions do not increase in a correlated fashion. To this end, we\npropose Diversity Training, a novel method to train an ensemble of models with\nuncorrelated loss functions. We show that our method significantly improves the\nadversarial robustness of ensembles and can also be combined with existing\nmethods to create a stronger defense.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 20:12:15 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Qureshi", "Moinuddin K.", ""]]}, {"id": "1901.09993", "submitter": "Qimai Li", "authors": "Qimai Li, Xiao-Ming Wu, Han Liu, Xiaotong Zhang, Zhichao Guan", "title": "Label Efficient Semi-Supervised Learning via Graph Filtering", "comments": "Accepted by 2019 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based methods have been demonstrated as one of the most effective\napproaches for semi-supervised learning, as they can exploit the connectivity\npatterns between labeled and unlabeled data samples to improve learning\nperformance. However, existing graph-based methods either are limited in their\nability to jointly model graph structures and data features, such as the\nclassical label propagation methods, or require a considerable amount of\nlabeled data for training and validation due to high model complexity, such as\nthe recent neural-network-based methods. In this paper, we address label\nefficient semi-supervised learning from a graph filtering perspective.\nSpecifically, we propose a graph filtering framework that injects graph\nsimilarity into data features by taking them as signals on the graph and\napplying a low-pass graph filter to extract useful data representations for\nclassification, where label efficiency can be achieved by conveniently\nadjusting the strength of the graph filter. Interestingly, this framework\nunifies two seemingly very different methods -- label propagation and graph\nconvolutional networks. Revisiting them under the graph filtering framework\nleads to new insights that improve their modeling capabilities and reduce model\ncomplexity. Experiments on various semi-supervised classification tasks on four\ncitation networks and one knowledge graph and one semi-supervised regression\ntask for zero-shot image recognition validate our findings and proposals.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 20:45:27 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 08:00:15 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 08:22:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Li", "Qimai", ""], ["Wu", "Xiao-Ming", ""], ["Liu", "Han", ""], ["Zhang", "Xiaotong", ""], ["Guan", "Zhichao", ""]]}, {"id": "1901.09997", "submitter": "Albert Berahas", "authors": "Albert S. Berahas, Majid Jahani, Peter Richt\\'arik and Martin\n  Tak\\'a\\v{c}", "title": "Quasi-Newton Methods for Machine Learning: Forget the Past, Just Sample", "comments": "50 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two sampled quasi-Newton methods (sampled LBFGS and sampled LSR1)\nfor solving empirical risk minimization problems that arise in machine\nlearning. Contrary to the classical variants of these methods that sequentially\nbuild Hessian or inverse Hessian approximations as the optimization progresses,\nour proposed methods sample points randomly around the current iterate at every\niteration to produce these approximations. As a result, the approximations\nconstructed make use of more reliable (recent and local) information, and do\nnot depend on past iterate information that could be significantly stale. Our\nproposed algorithms are efficient in terms of accessed data points (epochs) and\nhave enough concurrency to take advantage of parallel/distributed computing\nenvironments. We provide convergence guarantees for our proposed methods.\nNumerical tests on a toy classification problem as well as on popular\nbenchmarking binary classification and neural network training tasks reveal\nthat the methods outperform their classical variants.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 20:47:18 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 21:42:40 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 00:33:57 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 20:54:55 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 00:24:55 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Berahas", "Albert S.", ""], ["Jahani", "Majid", ""], ["Richt\u00e1rik", "Peter", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1901.10002", "submitter": "Harini Suresh", "authors": "Harini Suresh, John V. Guttag", "title": "A Framework for Understanding Sources of Harm throughout the Machine\n  Learning Life Cycle", "comments": "11 pages plus references; updated with corrections to text and\n  figures, new examples, and a more thorough walkthrough of ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) increasingly affects people and society, awareness\nof its potential unwanted consequences has also grown. To anticipate, prevent,\nand mitigate undesirable downstream consequences, it is critical that we\nunderstand when and how harm might be introduced throughout the ML life cycle.\nIn this paper, we provide a framework that identifies seven distinct potential\nsources of downstream harm in machine learning, spanning data collection,\ndevelopment, and deployment. In doing so, we aim to facilitate more productive\nand precise communication around these issues, as well as more direct,\napplication-grounded ways to mitigate them.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 21:00:20 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 22:34:24 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 15:25:42 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 14:16:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Suresh", "Harini", ""], ["Guttag", "John V.", ""]]}, {"id": "1901.10024", "submitter": "Ben Usman", "authors": "Ben Usman, Nick Dufour, Kate Saenko, Chris Bregler", "title": "Cross-Domain Image Manipulation by Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a model that can manipulate individual visual\nattributes of objects in a real scene using examples of how respective\nattribute manipulations affect the output of a simulation. As an example, we\ntrain our model to manipulate the expression of a human face using\nnonphotorealistic 3D renders of a face with varied expression. Our model\nmanages to preserve all other visual attributes of a real face, such as head\norientation, even though this and other attributes are not labeled in either\nreal or synthetic domain. Since our model learns to manipulate a specific\nproperty in isolation using only \"synthetic demonstrations\" of such\nmanipulations without explicitly provided labels, it can be applied to shape,\ntexture, lighting, and other properties that are difficult to measure or\nrepresent as real-valued vectors. We measure the degree to which our model\npreserves other attributes of a real image when a single specific attribute is\nmanipulated. We use digit datasets to analyze how discrepancy in attribute\ndistributions affects the performance of our model, and demonstrate results in\na far more difficult setting: learning to manipulate real human faces using\nnonphotorealistic 3D renders.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 22:49:05 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 15:28:10 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Usman", "Ben", ""], ["Dufour", "Nick", ""], ["Saenko", "Kate", ""], ["Bregler", "Chris", ""]]}, {"id": "1901.10031", "submitter": "Yinlam Chow", "authors": "Yinlam Chow and Ofir Nachum and Aleksandra Faust and Edgar\n  Duenez-Guzman and Mohammad Ghavamzadeh", "title": "Lyapunov-based Safe Policy Optimization for Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study continuous action reinforcement learning problems in which it is\ncrucial that the agent interacts with the environment only through safe\npolicies, i.e.,~policies that do not take the agent to undesirable situations.\nWe formulate these problems as constrained Markov decision processes (CMDPs)\nand present safe policy optimization algorithms that are based on a Lyapunov\napproach to solve them. Our algorithms can use any standard policy gradient\n(PG) method, such as deep deterministic policy gradient (DDPG) or proximal\npolicy optimization (PPO), to train a neural network policy, while guaranteeing\nnear-constraint satisfaction for every policy update by projecting either the\npolicy parameter or the action onto the set of feasible solutions induced by\nthe state-dependent linearized Lyapunov constraints. Compared to the existing\nconstrained PG algorithms, ours are more data efficient as they are able to\nutilize both on-policy and off-policy data. Moreover, our action-projection\nalgorithm often leads to less conservative policy updates and allows for\nnatural integration into an end-to-end PG training pipeline. We evaluate our\nalgorithms and compare them with the state-of-the-art baselines on several\nsimulated (MuJoCo) tasks, as well as a real-world indoor robot navigation\nproblem, demonstrating their effectiveness in terms of balancing performance\nand constraint satisfaction. Videos of the experiments can be found in the\nfollowing link:\nhttps://drive.google.com/file/d/1pzuzFqWIE710bE2U6DmS59AfRzqK2Kek/view?usp=sharing.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 23:14:58 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 20:52:42 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chow", "Yinlam", ""], ["Nachum", "Ofir", ""], ["Faust", "Aleksandra", ""], ["Duenez-Guzman", "Edgar", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1901.10040", "submitter": "Quanshi Zhang", "authors": "Umang Bhatt, Pradeep Ravikumar, Jose M. F. Moura", "title": "Towards Aggregating Weighted Feature Attributions", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches for explaining machine learning models fall into two\ndistinct classes: antecedent event influence and value attribution. The former\nleverages training instances to describe how much influence a training point\nexerts on a test point, while the latter attempts to attribute value to the\nfeatures most pertinent to a given prediction. In this work, we discuss an\nalgorithm, AVA: Aggregate Valuation of Antecedents, that fuses these two\nexplanation classes to form a new approach to feature attribution that not only\nretrieves local explanations but also captures global patterns learned by a\nmodel. Our experimentation convincingly favors weighting and aggregating\nfeature attributions via AVA.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:45:50 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Bhatt", "Umang", ""], ["Ravikumar", "Pradeep", ""], ["Moura", "Jose M. F.", ""]]}, {"id": "1901.10042", "submitter": "Quanshi Zhang", "authors": "Shipeng Xie, Da Chen, Rong Zhang, Hui Xue", "title": "Deep Features Analysis with Attention Networks", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models have recently draw lots of attention, as it\nconsistently produce impressive results in many computer vision tasks such as\nimage classification, object detection, etc. However, interpreting such model\nand show the reason why it performs quite well becomes a challenging question.\nIn this paper, we propose a novel method to interpret the neural network models\nwith attention mechanism. Inspired by the heatmap visualization, we analyze the\nrelation between classification accuracy with the attention based heatmap. An\nimproved attention based method is also included and illustrate that a better\nclassifier can be interpreted by the attention based heatmap.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:44:43 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Xie", "Shipeng", ""], ["Chen", "Da", ""], ["Zhang", "Rong", ""], ["Xue", "Hui", ""]]}, {"id": "1901.10053", "submitter": "Bokun Wang", "authors": "Bokun Wang, Ian Davidson", "title": "Towards Fair Deep Clustering With Multi-State Protected Variables", "comments": "under review as a conference paper at icml 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair clustering under the disparate impact doctrine requires that population\nof each protected group should be approximately equal in every cluster.\nPrevious work investigated a difficult-to-scale pre-processing step for\n$k$-center and $k$-median style algorithms for the special case of this problem\nwhen the number of protected groups is two. In this work, we consider a more\ngeneral and practical setting where there can be many protected groups. To this\nend, we propose Deep Fair Clustering, which learns a discriminative but fair\ncluster assignment function. The experimental results on three public datasets\nwith different types of protected attribute show that our approach can steadily\nimprove the degree of fairness while only having minor loss in terms of\nclustering quality.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 00:38:07 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wang", "Bokun", ""], ["Davidson", "Ian", ""]]}, {"id": "1901.10060", "submitter": "David Brookes", "authors": "David H. Brookes, Hahnbeom Park, Jennifer Listgarten", "title": "Conditioning by adaptive sampling for robust design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new method for design problems wherein the goal is to maximize\nor specify the value of one or more properties of interest. For example, in\nprotein design, one may wish to find the protein sequence that maximizes\nfluorescence. We assume access to one or more, potentially black box,\nstochastic \"oracle\" predictive functions, each of which maps from input (e.g.,\nprotein sequences) design space to a distribution over a property of interest\n(e.g. protein fluorescence). At first glance, this problem can be framed as one\nof optimizing the oracle(s) with respect to the input. However, many\nstate-of-the-art predictive models, such as neural networks, are known to\nsuffer from pathologies, especially for data far from the training\ndistribution. Thus we need to modulate the optimization of the oracle inputs\nwith prior knowledge about what makes `realistic' inputs (e.g., proteins that\nstably fold). Herein, we propose a new method to solve this problem,\nConditioning by Adaptive Sampling, which yields state-of-the-art results on a\nprotein fluorescence problem, as compared to other recently published\napproaches. Formally, our method achieves its success by using model-based\nadaptive sampling to estimate the conditional distribution of the input\nsequences given the desired properties.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 01:15:34 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 22:17:24 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 01:08:33 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 20:59:48 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 19:04:37 GMT"}, {"version": "v6", "created": "Tue, 17 Dec 2019 01:00:57 GMT"}, {"version": "v7", "created": "Mon, 6 Jan 2020 22:48:53 GMT"}, {"version": "v8", "created": "Mon, 10 Feb 2020 19:41:35 GMT"}, {"version": "v9", "created": "Wed, 12 May 2021 00:40:59 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Brookes", "David H.", ""], ["Park", "Hahnbeom", ""], ["Listgarten", "Jennifer", ""]]}, {"id": "1901.10061", "submitter": "Hongjing Zhang", "authors": "Hongjing Zhang, Sugato Basu, Ian Davidson", "title": "A Framework for Deep Constrained Clustering -- Algorithms and Advances", "comments": "Updated for ECML/PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of constrained clustering has been extensively explored by\nresearchers and used by practitioners. Constrained clustering formulations\nexist for popular algorithms such as k-means, mixture models, and spectral\nclustering but have several limitations. A fundamental strength of deep\nlearning is its flexibility, and here we explore a deep learning framework for\nconstrained clustering and in particular explore how it can extend the field of\nconstrained clustering. We show that our framework can not only handle standard\ntogether/apart constraints (without the well documented negative effects\nreported earlier) generated from labeled side information but more complex\nconstraints generated from new types of side information such as continuous\nvalues and high-level domain knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 01:25:39 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 18:20:55 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 18:26:34 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhang", "Hongjing", ""], ["Basu", "Sugato", ""], ["Davidson", "Ian", ""]]}, {"id": "1901.10076", "submitter": "Puoya Tabaghi", "authors": "Puoya Tabaghi, Maarten de Hoop, Ivan Dokmani\\'c", "title": "Learning Schatten--von Neumann Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the learnability of a class of compact operators known as\nSchatten--von Neumann operators. These operators between infinite-dimensional\nfunction spaces play a central role in a variety of applications in learning\ntheory and inverse problems. We address the question of sample complexity of\nlearning Schatten-von Neumann operators and provide an upper bound on the\nnumber of measurements required for the empirical risk minimizer to generalize\nwith arbitrary precision and probability, as a function of class parameter $p$.\nOur results give generalization guarantees for regression of\ninfinite-dimensional signals from infinite-dimensional data. Next, we adapt the\nrepresenter theorem of Abernethy \\emph{et al.} to show that empirical risk\nminimization over an a priori infinite-dimensional, non-compact set, can be\nconverted to a convex finite dimensional optimization problem over a compact\nset. In summary, the class of $p$-Schatten--von Neumann operators is probably\napproximately correct (PAC)-learnable via a practical convex program for any $p\n< \\infty$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 02:44:08 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 17:32:55 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Tabaghi", "Puoya", ""], ["de Hoop", "Maarten", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "1901.10079", "submitter": "Yuan-chin Ivan Chang", "authors": "Zhanfeng Wang and Yumi Kwon and Yuan-chin Ivan Chang", "title": "Active learning for binary classification with variable selection", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computing and communication technologies can make data collection\nprocedures very efficient. However, our ability to analyze large data sets\nand/or to extract information out from them is hard-pressed to keep up with our\ncapacities for data collection. Among these huge data sets, some of them are\nnot collected for any particular research purpose. For a classification\nproblem, this means that the essential label information may not be readily\nobtainable, in the data set in hands, and an extra labeling procedure is\nrequired such that we can have enough label information to be used for\nconstructing a classification model. When the size of a data set is huge, to\nlabel each subject in it will cost a lot in both capital and time. Thus, it is\nan important issue to decide which subjects should be labeled first in order to\nefficiently reduce the training cost/time. Active learning method is a\npromising outlet for this situation, because with the active learning ideas, we\ncan select the unlabeled subjects sequentially without knowing their label\ninformation. In addition, there will be no confirmed information about the\nessential variables for constructing an efficient classification rule. Thus,\nhow to merge a variable selection scheme with an active learning procedure is\nof interest. In this paper, we propose a procedure for building binary\nclassification models when the complete label information is not available in\nthe beginning of the training stage. We study an model-based active learning\nprocedure with sequential variable selection schemes, and discuss the results\nof the proposed procedure from both theoretical and numerical aspects.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 02:57:30 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wang", "Zhanfeng", ""], ["Kwon", "Yumi", ""], ["Chang", "Yuan-chin Ivan", ""]]}, {"id": "1901.10080", "submitter": "Luca Oneto", "authors": "Luca Oneto, Michele Donini, Massimiliano Pontil", "title": "General Fair Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We tackle the problem of algorithmic fairness, where the goal is to avoid the\nunfairly influence of sensitive information, in the general context of\nregression with possible continuous sensitive attributes. We extend the\nframework of fair empirical risk minimization to this general scenario,\ncovering in this way the whole standard supervised learning setting. Our\ngeneralized fairness measure reduces to well known notions of fairness\navailable in literature. We derive learning guarantees for our method, that\nimply in particular its statistical consistency, both in terms of the risk and\nthe fairness measure. We then specialize our approach to kernel methods and\npropose a convex fair estimator in that setting. We test the estimator on a\ncommonly used benchmark dataset (Communities and Crime) and on a new dataset\ncollected at the University of Genova, containing the information of the\nacademic career of five thousand students. The latter dataset provides a\nchallenging real case scenario of unfair behaviour of standard regression\nmethods that benefits from our methodology. The experimental results show that\nour estimator is effective at mitigating the trade-off between accuracy and\nfairness requirements.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 02:57:36 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 21:28:48 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 16:00:37 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Oneto", "Luca", ""], ["Donini", "Michele", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1901.10082", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Zach Kaplan, Daniel Sanz-Alonso", "title": "Variational Characterizations of Local Entropy and Heat Regularization\n  in Deep Learning", "comments": null, "journal-ref": null, "doi": "10.3390/e21050511", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to provide new theoretical and computational\nunderstanding on two loss regularizations employed in deep learning, known as\nlocal entropy and heat regularization. For both regularized losses we introduce\nvariational characterizations that naturally suggest a two-step scheme for\ntheir optimization, based on the iterative shift of a probability density and\nthe calculation of a best Gaussian approximation in Kullback-Leibler\ndivergence. Under this unified light, the optimization schemes for local\nentropy and heat regularized loss differ only over which argument of the\nKullback-Leibler divergence is used to find the best Gaussian approximation.\nLocal entropy corresponds to minimizing over the second argument, and the\nsolution is given by moment matching. This allows to replace traditional\nback-propagation calculation of gradients by sampling algorithms, opening an\navenue for gradient-free, parallelizable training of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 03:12:42 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Kaplan", "Zach", ""], ["Sanz-Alonso", "Daniel", ""]]}, {"id": "1901.10089", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Ryan Murray", "title": "A maximum principle argument for the uniform convergence of graph\n  Laplacian regressors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of methods from partial differential\nequations and the Calculus of variations to study learning problems that are\nregularized using graph Laplacians. Graph Laplacians are a powerful, flexible\nmethod for capturing local and global geometry in many classes of learning\nproblems, and the techniques developed in this paper help to broaden the\nmethodology of studying such problems. In particular, we develop the use of\nmaximum principle arguments to establish asymptotic consistency guarantees\nwithin the context of noise corrupted, non-parametric regression with samples\nliving on an unknown manifold embedded in $\\mathbb{R}^d$. The maximum principle\narguments provide a new technical tool which informs parameter selection by\ngiving concrete error estimates in terms of various regularization parameters.\nA review of learning algorithms which utilize graph Laplacians, as well as\nprevious developments in the use of differential equation and variational\ntechniques to study those algorithms, is given. In addition, new connections\nare drawn between Laplacian methods and other machine learning techniques, such\nas kernel regression and k-nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 03:51:26 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 01:41:33 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 11:30:48 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""]]}, {"id": "1901.10098", "submitter": "Du Xu", "authors": "Di Xu, Manjing Fang, Xia Hong, Junbin Gao", "title": "Sparse Least Squares Low Rank Kernel Machines", "comments": "2019 ICONIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework of least squares support vector machine with low rank\nkernels, referred to as LR-LSSVM, is introduced in this paper. The special\nstructure of low rank kernels with a controlled model size brings sparsity as\nwell as computational efficiency to the proposed model. Meanwhile, a two-step\noptimization algorithm with three different criteria is proposed and various\nexperiments are carried out using the example of the so-call robust RBF kernel\nto validate the model. The experiment results show that the performance of the\nproposed algorithm is comparable or superior to several existing kernel\nmachines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 04:50:59 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 23:59:15 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Xu", "Di", ""], ["Fang", "Manjing", ""], ["Hong", "Xia", ""], ["Gao", "Junbin", ""]]}, {"id": "1901.10106", "submitter": "Sookyung Kim", "authors": "Sookyung Kim, Jungmin M. Lee, Jiwoo Lee, Jihoon Seo", "title": "Deep-dust: Predicting concentrations of fine dust in Seoul using LSTM", "comments": "3 pages, 3 figures, 1 tabel", "journal-ref": "Climate Informatics 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polluting fine dusts in South Korea which are mainly consisted of biomass\nburning and fugitive dust blown from dust belt is significant problem these\ndays. Predicting concentrations of fine dust particles in Seoul is challenging\nbecause they are product of complicate chemical reactions among gaseous\npollutants and also influenced by dynamical interactions between pollutants and\nmultiple climate variables. Elaborating state-of-art time series analysis\ntechniques using deep learning, non-linear interactions between multiple\nvariables can be captured and used to predict future dust concentration. In\nthis work, we propose the LSTM based model to predict hourly concentration of\nfine dust at target location in Seoul based on previous concentration of\npollutants, dust concentrations and climate variables in surrounding area. Our\nresults show that proposed model successfully predicts future dust\nconcentrations at 25 target districts(Gu) in Seoul.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 05:19:52 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kim", "Sookyung", ""], ["Lee", "Jungmin M.", ""], ["Lee", "Jiwoo", ""], ["Seo", "Jihoon", ""]]}, {"id": "1901.10113", "submitter": "Dongqi Han", "authors": "Dongqi Han, Kenji Doya, Jun Tani", "title": "Self-organization of action hierarchy and compositionality by\n  reinforcement learning with recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) for reinforcement learning (RL) have shown\ndistinct advantages, e.g., solving memory-dependent tasks and meta-learning.\nHowever, little effort has been spent on improving RNN architectures and on\nunderstanding the underlying neural mechanisms for performance gain. In this\npaper, we propose a novel, multiple-timescale, stochastic RNN for RL. Empirical\nresults show that the network can autonomously learn to abstract sub-goals and\ncan self-develop an action hierarchy using internal dynamics in a challenging\ncontinuous control task. Furthermore, we show that the self-developed\ncompositionality of the network enhances faster re-learning when adapting to a\nnew task that is a re-composition of previously learned sub-goals, than when\nstarting from scratch. We also found that improved performance can be achieved\nwhen neural activities are subject to stochastic rather than deterministic\ndynamics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 05:34:47 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 07:18:16 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 13:54:51 GMT"}, {"version": "v4", "created": "Fri, 3 May 2019 09:58:53 GMT"}, {"version": "v5", "created": "Thu, 23 May 2019 15:32:04 GMT"}, {"version": "v6", "created": "Tue, 26 Nov 2019 08:31:31 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Han", "Dongqi", ""], ["Doya", "Kenji", ""], ["Tani", "Jun", ""]]}, {"id": "1901.10134", "submitter": "Gunwoong Park", "authors": "Gunwoong Park and Younghwan Kim", "title": "Identifiability of Gaussian Structural Equation Models with Homogeneous\n  and Heterogeneous Error Variances", "comments": "18 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the identifiability assumption of Gaussian linear\nstructural equation models (SEMs) in which each variable is determined by a\nlinear function of its parents plus normally distributed error. It has been\nshown that linear Gaussian structural equation models are fully identifiable if\nall error variances are the same or known. Hence, this work proves the\nidentifiability of Gaussian SEMs with both homogeneous and heterogeneous\nunknown error variances. Our new identifiability assumption exploits not only\nerror variances, but edge weights; hence, it is strictly milder than prior work\non the identifiability result. We further provide a structure learning\nalgorithm that is statistically consistent and computationally feasible, based\non our new assumption. The proposed algorithm assumes that all relevant\nvariables are observed, while it does not assume causal minimality and\nfaithfulness. We verify our theoretical findings through simulations and real\nmultivariate data, and compare our algorithm to state-of-the-art PC, GES and\nGDS algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 06:53:53 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 09:11:41 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 14:20:35 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Park", "Gunwoong", ""], ["Kim", "Younghwan", ""]]}, {"id": "1901.10139", "submitter": "Dhruva Sahrawat", "authors": "Yaman Kumar, Dhruva Sahrawat, Shubham Maheshwari, Debanjan Mahata,\n  Amanda Stent, Yifang Yin, Rajiv Ratn Shah, Roger Zimmermann", "title": "Harnessing GANs for Zero-shot Learning of New Classes in Visual Speech\n  Recognition", "comments": "Accepted for poster presentation at AAAI 2020. Dhruva Sahrawat and\n  Yaman Kumar contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Speech Recognition (VSR) is the process of recognizing or interpreting\nspeech by watching the lip movements of the speaker. Recent machine learning\nbased approaches model VSR as a classification problem; however, the scarcity\nof training data leads to error-prone systems with very low accuracies in\npredicting unseen classes. To solve this problem, we present a novel approach\nto zero-shot learning by generating new classes using Generative Adversarial\nNetworks (GANs), and show how the addition of unseen class samples increases\nthe accuracy of a VSR system by a significant margin of 27% and allows it to\nhandle speaker-independent out-of-vocabulary phrases. We also show that our\nmodels are language agnostic and therefore capable of seamlessly generating,\nusing English training data, videos for a new language (Hindi). To the best of\nour knowledge, this is the first work to show empirical evidence of the use of\nGANs for generating training samples of unseen classes in the domain of VSR,\nhence facilitating zero-shot learning. We make the added videos for new classes\npublicly available along with our code.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 07:08:56 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 08:53:57 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 04:56:09 GMT"}, {"version": "v4", "created": "Thu, 2 Jan 2020 17:22:45 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kumar", "Yaman", ""], ["Sahrawat", "Dhruva", ""], ["Maheshwari", "Shubham", ""], ["Mahata", "Debanjan", ""], ["Stent", "Amanda", ""], ["Yin", "Yifang", ""], ["Shah", "Rajiv Ratn", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1901.10153", "submitter": "Xuekui Zhang", "authors": "Li Xing, Mary Lesperance, and Xuekui Zhang", "title": "Simultaneous prediction of multiple outcomes using revised stacking\n  algorithms", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": "10.1093/bioinformatics/btz531", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: HIV is difficult to treat because its virus mutates at a high\nrate and mutated viruses easily develop resistance to existing drugs. If the\nrelationships between mutations and drug resistances can be determined from\nhistorical data, patients can be provided personalized treatment according to\ntheir own mutation information. The HIV Drug Resistance Database was built to\ninvestigate the relationships. Our goal is to build a model using data in this\ndatabase, which simultaneously predicts the resistance of multiple drugs using\nmutation information from sequences of viruses for any new patient.\n  Results: We propose two variations of a stacking algorithm which borrow\ninformation among multiple prediction tasks to improve multivariate prediction\nperformance. The most attractive feature of our proposed methods is the\nflexibility with which complex multivariate prediction models can be\nconstructed using any univariate prediction models. Using cross-validation\nstudies, we show that our proposed methods outperform other popular\nmultivariate prediction methods.\n  Availability: An R package will be made available.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:02:32 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Xing", "Li", ""], ["Lesperance", "Mary", ""], ["Zhang", "Xuekui", ""]]}, {"id": "1901.10155", "submitter": "Miao Xu", "authors": "Miao Xu and Bingcong Li and Gang Niu and Bo Han and Masashi Sugiyama", "title": "Revisiting Sample Selection Approach to Positive-Unlabeled Learning:\n  Turning Unlabeled Data into Positive rather than Negative", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the early history of positive-unlabeled (PU) learning, the sample\nselection approach, which heuristically selects negative (N) data from U data,\nwas explored extensively. However, this approach was later dominated by the\nimportance reweighting approach, which carefully treats all U data as N data.\nMay there be a new sample selection method that can outperform the latest\nimportance reweighting method in the deep learning age? This paper is devoted\nto answering this question affirmatively---we propose to label large-loss U\ndata as P, based on the memorization properties of deep networks. Since P data\nselected in such a way are biased, we develop a novel learning objective that\ncan handle such biased P data properly. Experiments confirm the superiority of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:15:56 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Xu", "Miao", ""], ["Li", "Bingcong", ""], ["Niu", "Gang", ""], ["Han", "Bo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.10159", "submitter": "Behrooz Ghorbani", "authors": "Behrooz Ghorbani, Shankar Krishnan, Ying Xiao", "title": "An Investigation into Neural Net Optimization via Hessian Eigenvalue\n  Density", "comments": "21 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the dynamics of optimization in deep neural networks, we\ndevelop a tool to study the evolution of the entire Hessian spectrum throughout\nthe optimization process. Using this, we study a number of hypotheses\nconcerning smoothness, curvature, and sharpness in the deep learning\nliterature. We then thoroughly analyze a crucial structural feature of the\nspectra: in non-batch normalized networks, we observe the rapid appearance of\nlarge isolated eigenvalues in the spectrum, along with a surprising\nconcentration of the gradient in the corresponding eigenspaces. In batch\nnormalized networks, these two effects are almost absent. We characterize these\neffects, and explain how they affect optimization speed through both theory and\nexperiments. As part of this work, we adapt advanced tools from numerical\nlinear algebra that allow scalable and accurate estimation of the entire\nHessian spectrum of ImageNet-scale neural networks; this technique may be of\nindependent interest in other applications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:24:10 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ghorbani", "Behrooz", ""], ["Krishnan", "Shankar", ""], ["Xiao", "Ying", ""]]}, {"id": "1901.10173", "submitter": "Yiu-Ming Cheung", "authors": "Yang Lu, Yiu-ming Cheung, Yuan Yan Tang", "title": "Bayes Imbalance Impact Index: A Measure of Class Imbalanced Dataset for\n  Classification Problem", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that imbalance ratio is not the only cause of the\nperformance loss of a classifier in imbalanced data classification. In fact,\nother data factors, such as small disjuncts, noises and overlapping, also play\nthe roles in tandem with imbalance ratio, which makes the problem difficult.\nThus far, the empirical studies have demonstrated the relationship between the\nimbalance ratio and other data factors only. To the best of our knowledge,\nthere is no any measurement about the extent of influence of class imbalance on\nthe classification performance of imbalanced data. Further, it is also unknown\nfor a dataset which data factor is actually the main barrier for\nclassification. In this paper, we focus on Bayes optimal classifier and study\nthe influence of class imbalance from a theoretical perspective. Accordingly,\nwe propose an instance measure called Individual Bayes Imbalance Impact Index\n($IBI^3$) and a data measure called Bayes Imbalance Impact Index ($BI^3$).\n$IBI^3$ and $BI^3$ reflect the extent of influence purely by the factor of\nimbalance in terms of each minority class sample and the whole dataset,\nrespectively. Therefore, $IBI^3$ can be used as an instance complexity measure\nof imbalance and $BI^3$ is a criterion to show the degree of how imbalance\ndeteriorates the classification. As a result, we can therefore use $BI^3$ to\njudge whether it is worth using imbalance recovery methods like sampling or\ncost-sensitive methods to recover the performance loss of a classifier. The\nexperiments show that $IBI^3$ is highly consistent with the increase of\nprediction score made by the imbalance recovery methods and $BI^3$ is highly\nconsistent with the improvement of F1 score made by the imbalance recovery\nmethods on both synthetic and real benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:42:56 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Lu", "Yang", ""], ["Cheung", "Yiu-ming", ""], ["Tang", "Yuan Yan", ""]]}, {"id": "1901.10178", "submitter": "Thomas Lacombe", "authors": "Pierre Nagorny (SYMME), Thomas Lacombe (SYMME), Hugues Favreliere\n  (SYMME), Maurice Pillet (SYMME), Eric Pairel (SYMME), Ronan Le Goff (IPC),\n  Marlene Wali (IPC), Jerome Loureaux (IPC), Patrice Kiener", "title": "Generative Adversarial Networks for geometric surfaces prediction in\n  injection molding", "comments": "IEEE. 2018 IEEE International Conference on Industrial Technology\n  (ICIT), Feb 2018, Lyon, France, http://www.icit2018.org", "journal-ref": "IEEE, 2018 IEEE International Conference on Industrial Technology\n  (ICIT), pp.1514-1519, 2018", "doi": "10.1109/ICIT.2018.8352405", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometrical and appearance quality requirements set the limits of the current\nindustrial performance in injection molding. To guarantee the product's\nquality, it is necessary to adjust the process settings in a closed loop. Those\nadjustments cannot rely on the final quality because a part takes days to be\ngeometrically stable. Thus, the final part geometry must be predicted from\nmeasurements on hot parts. In this paper, we use recent success of Generative\nAdversarial Networks (GAN) with the pix2pix network architecture to predict the\nfinal part geometry, using only hot parts thermographic images, measured right\nafter production. Our dataset is really small, and the GAN learns to translate\nthermography to geometry. We firstly study prediction performances using\ndifferent image similarity comparison algorithms. Moreover, we introduce the\ninnovative use of Discrete Modal Decomposition (DMD) to analyze network\npredictions. The DMD is a geometrical parameterization technique using a modal\nspace projection to geometrically describe surfaces. We study GAN performances\nto retrieve geometrical parameterization of surfaces.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 08:49:59 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Nagorny", "Pierre", "", "SYMME"], ["Lacombe", "Thomas", "", "SYMME"], ["Favreliere", "Hugues", "", "SYMME"], ["Pillet", "Maurice", "", "SYMME"], ["Pairel", "Eric", "", "SYMME"], ["Goff", "Ronan Le", "", "IPC"], ["Wali", "Marlene", "", "IPC"], ["Loureaux", "Jerome", "", "IPC"], ["Kiener", "Patrice", ""]]}, {"id": "1901.10200", "submitter": "Carl Henning Lubba", "authors": "Carl H Lubba and Sarab S Sethi and Philip Knaute and Simon R Schultz\n  and Ben D Fulcher and Nick S Jones", "title": "catch22: CAnonical Time-series CHaracteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Capturing the dynamical properties of time series concisely as interpretable\nfeature vectors can enable efficient clustering and classification for\ntime-series applications across science and industry. Selecting an appropriate\nfeature-based representation of time series for a given application can be\nachieved through systematic comparison across a comprehensive time-series\nfeature library, such as those in the hctsa toolbox. However, this approach is\ncomputationally expensive and involves evaluating many similar features,\nlimiting the widespread adoption of feature-based representations of time\nseries for real-world applications. In this work, we introduce a method to\ninfer small sets of time-series features that (i) exhibit strong classification\nperformance across a given collection of time-series problems, and (ii) are\nminimally redundant. Applying our method to a set of 93 time-series\nclassification datasets (containing over 147000 time series) and using a\nfiltered version of the hctsa feature library (4791 features), we introduce a\ngenerically useful set of 22 CAnonical Time-series CHaracteristics, catch22.\nThis dimensionality reduction, from 4791 to 22, is associated with an\napproximately 1000-fold reduction in computation time and near linear scaling\nwith time-series length, despite an average reduction in classification\naccuracy of just 7%. catch22 captures a diverse and interpretable signature of\ntime series in terms of their properties, including linear and non-linear\nautocorrelation, successive differences, value distributions and outliers, and\nfluctuation scaling properties. We provide an efficient implementation of\ncatch22, accessible from many programming environments, that facilitates\nfeature-based time-series analysis for scientific, industrial, financial and\nmedical applications using a common language of interpretable time-series\nproperties.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 10:06:33 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 12:23:27 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Lubba", "Carl H", ""], ["Sethi", "Sarab S", ""], ["Knaute", "Philip", ""], ["Schultz", "Simon R", ""], ["Fulcher", "Ben D", ""], ["Jones", "Nick S", ""]]}, {"id": "1901.10204", "submitter": "Nicolas Tremblay", "authors": "Nicolas Tremblay, Andreas Loukas", "title": "Approximating Spectral Clustering via Sampling: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering refers to a family of unsupervised learning algorithms\nthat compute a spectral embedding of the original data based on the\neigenvectors of a similarity graph. This non-linear transformation of the data\nis both the key of these algorithms' success and their Achilles heel: forming a\ngraph and computing its dominant eigenvectors can indeed be computationally\nprohibitive when dealing with more that a few tens of thousands of points. In\nthis paper, we review the principal research efforts aiming to reduce this\ncomputational cost. We focus on methods that come with a theoretical control on\nthe clustering performance and incorporate some form of sampling in their\noperation. Such methods abound in the machine learning, numerical linear\nalgebra, and graph signal processing literature and, amongst others, include\nNystr\\\"om-approximation, landmarks, coarsening, coresets, and compressive\nspectral clustering. We present the approximation guarantees available for each\nand discuss practical merits and limitations. Surprisingly, despite the breadth\nof the literature explored, we conclude that there is still a gap between\ntheory and practice: the most scalable methods are only intuitively motivated\nor loosely controlled, whereas those that come with end-to-end guarantees rely\non strong assumptions or enable a limited gain of computation time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 10:27:30 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Tremblay", "Nicolas", ""], ["Loukas", "Andreas", ""]]}, {"id": "1901.10227", "submitter": "Antti Honkela", "authors": "Teppo Niinim\\\"aki, Mikko Heikkil\\\"a, Antti Honkela and Samuel Kaski", "title": "Representation Transfer for Differentially Private Drug Sensitivity\n  Prediction", "comments": "12 pages, 5 figures", "journal-ref": "Bioinformatics 35(14):i218-i224, 2019", "doi": "10.1093/bioinformatics/btz373", "report-no": null, "categories": "q-bio.QM cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Human genomic datasets often contain sensitive information that\nlimits use and sharing of the data. In particular, simple anonymisation\nstrategies fail to provide sufficient level of protection for genomic data,\nbecause the data are inherently identifiable. Differentially private machine\nlearning can help by guaranteeing that the published results do not leak too\nmuch information about any individual data point. Recent research has reached\npromising results on differentially private drug sensitivity prediction using\ngene expression data. Differentially private learning with genomic data is\nchallenging because it is more difficult to guarantee the privacy in high\ndimensions. Dimensionality reduction can help, but if the dimension reduction\nmapping is learned from the data, then it needs to be differentially private\ntoo, which can carry a significant privacy cost. Furthermore, the selection of\nany hyperparameters (such as the target dimensionality) needs to also avoid\nleaking private information.\n  Results: We study an approach that uses a large public dataset of similar\ntype to learn a compact representation for differentially private learning. We\ncompare three representation learning methods: variational autoencoders, PCA\nand random projection. We solve two machine learning tasks on gene expression\nof cancer cell lines: cancer type classification, and drug sensitivity\nprediction. The experiments demonstrate significant benefit from all\nrepresentation learning methods with variational autoencoders providing the\nmost accurate predictions most often. Our results significantly improve over\nprevious state-of-the-art in accuracy of differentially private drug\nsensitivity prediction.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 11:22:24 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Niinim\u00e4ki", "Teppo", ""], ["Heikkil\u00e4", "Mikko", ""], ["Honkela", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "1901.10230", "submitter": "Samuel Wiqvist", "authors": "Samuel Wiqvist, Pierre-Alexandre Mattei, Umberto Picchini, Jes\n  Frellsen", "title": "Partially Exchangeable Networks and Architectures for Learning Summary\n  Statistics in Approximate Bayesian Computation", "comments": "Forthcoming on the Proceedings of ICML 2019. New comparisons with\n  several different networks. We now use the Wasserstein distance to produce\n  comparisons. Code available on GitHub. 16 pages, 5 figures, 21 tables", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:6798--6807, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel family of deep neural architectures, named partially\nexchangeable networks (PENs) that leverage probabilistic symmetries. By design,\nPENs are invariant to block-switch transformations, which characterize the\npartial exchangeability properties of conditionally Markovian processes.\nMoreover, we show that any block-switch invariant function has a PEN-like\nrepresentation. The DeepSets architecture is a special case of PEN and we can\ntherefore also target fully exchangeable data. We employ PENs to learn summary\nstatistics in approximate Bayesian computation (ABC). When comparing PENs to\nprevious deep learning methods for learning summary statistics, our results are\nhighly competitive, both considering time series and static models. Indeed,\nPENs provide more reliable posterior samples even when using less training\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 11:31:31 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 14:19:59 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Wiqvist", "Samuel", ""], ["Mattei", "Pierre-Alexandre", ""], ["Picchini", "Umberto", ""], ["Frellsen", "Jes", ""]]}, {"id": "1901.10232", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Elena Nieddu, Donatella Firmani, Paolo Merialdo", "title": "Multikernel activation functions: formulation and a case study", "comments": "Accepted for presentation at INNS BDDL 2019\n  (https://innsbddl2019.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of activation functions is a growing research area in the field of\nneural networks. In particular, instead of using fixed point-wise functions\n(e.g., the rectified linear unit), several authors have proposed ways of\nlearning these functions directly from the data in a non-parametric fashion. In\nthis paper we focus on the kernel activation function (KAF), a recently\nproposed framework wherein each function is modeled as a one-dimensional kernel\nmodel, whose weights are adapted through standard backpropagation-based\noptimization. One drawback of KAFs is the need to select a single kernel\nfunction and its eventual hyper-parameters. To partially overcome this problem,\nwe motivate an extension of the KAF model, in which multiple kernels are\nlinearly combined at every neuron, inspired by the literature on multiple\nkernel learning. We provide an application of the resulting multi-KAF on a\nrealistic use case, specifically handwritten Latin OCR, on a large dataset\ncollected in the context of the `In Codice Ratio' project. Results show that\nmulti-KAFs can improve the accuracy of the convolutional networks previously\ndeveloped for the task, with faster convergence, even with a smaller number of\noverall parameters.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 11:41:27 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Scardapane", "Simone", ""], ["Nieddu", "Elena", ""], ["Firmani", "Donatella", ""], ["Merialdo", "Paolo", ""]]}, {"id": "1901.10234", "submitter": "Guoji Fu", "authors": "Guoji Fu, Bo Yuan, Qiqi Duan, Xin Yao", "title": "Representation Learning for Heterogeneous Information Networks via\n  Embedding Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) has been widely used to help analyze\nlarge-scale networks through mapping original networks into a low-dimensional\nvector space. However, existing NRL methods ignore the impact of properties of\nrelations on the object relevance in heterogeneous information networks (HINs).\nTo tackle this issue, this paper proposes a new NRL framework, called\nEvent2vec, for HINs to consider both quantities and properties of relations\nduring the representation learning process. Specifically, an event (i.e., a\ncomplete semantic unit) is used to represent the relation among multiple\nobjects, and both event-driven first-order and second-order proximities are\ndefined to measure the object relevance according to the quantities and\nproperties of relations. We theoretically prove how event-driven proximities\ncan be preserved in the embedding space by Event2vec, which utilizes event\nembeddings to facilitate learning the object embeddings. Experimental studies\ndemonstrate the advantages of Event2vec over state-of-the-art algorithms on\nfour real-world datasets and three network analysis tasks (including network\nreconstruction, link prediction, and node classification).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 11:43:55 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 12:40:43 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Fu", "Guoji", ""], ["Yuan", "Bo", ""], ["Duan", "Qiqi", ""], ["Yao", "Xin", ""]]}, {"id": "1901.10251", "submitter": "Orr Krupnik", "authors": "Orr Krupnik, Igor Mordatch, Aviv Tamar", "title": "Multi-Agent Reinforcement Learning with Multi-Step Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider model-based reinforcement learning (MBRL) in 2-agent,\nhigh-fidelity continuous control problems -- an important domain for robots\ninteracting with other agents in the same workspace. For non-trivial dynamical\nsystems, MBRL typically suffers from accumulating errors. Several recent\nstudies have addressed this problem by learning latent variable models for\ntrajectory segments and optimizing over behavior in the latent space. In this\nwork, we investigate whether this approach can be extended to 2-agent\ncompetitive and cooperative settings. The fundamental challenge is how to learn\nmodels that capture interactions between agents, yet are disentangled to allow\nfor optimization of each agent behavior separately. We propose such models\nbased on a disentangled variational auto-encoder, and demonstrate our approach\non a simulated 2-robot manipulation task, where one robot can either help or\ndistract the other. We show that our approach has better sample efficiency than\na strong model-free RL baseline, and can learn both cooperative and adversarial\nbehavior from the same data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 12:29:20 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 01:44:22 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 04:51:13 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Krupnik", "Orr", ""], ["Mordatch", "Igor", ""], ["Tamar", "Aviv", ""]]}, {"id": "1901.10255", "submitter": "Alexandre Araujo", "authors": "Alexandre Araujo, Benjamin Negrevergne, Yann Chevaleyre, Jamal Atif", "title": "Understanding and Training Deep Diagonal Circulant Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study deep diagonal circulant neural networks, that is deep\nneural networks in which weight matrices are the product of diagonal and\ncirculant ones. Besides making a theoretical analysis of their expressivity, we\nintroduced principled techniques for training these models: we devise an\ninitialization scheme and proposed a smart use of non-linearity functions in\norder to train deep diagonal circulant networks. Furthermore, we show that\nthese networks outperform recently introduced deep networks with other types of\nstructured layers. We conduct a thorough experimental study to compare the\nperformance of deep diagonal circulant networks with state of the art models\nbased on structured matrices and with dense models. We show that our models\nachieve better accuracy than other structured approaches while required 2x\nfewer weights as the next best approach. Finally we train deep diagonal\ncirculant networks to build a compact and accurate models on a real world video\nclassification dataset with over 3.8 million training examples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 12:46:35 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 16:53:27 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 13:52:19 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Araujo", "Alexandre", ""], ["Negrevergne", "Benjamin", ""], ["Chevaleyre", "Yann", ""], ["Atif", "Jamal", ""]]}, {"id": "1901.10265", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis and Vijay Keswani", "title": "Implicit Diversity in Image Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies have shown that the people depicted in image search results tend to\nbe of majority groups with respect to socially salient attributes. This skew\ngoes beyond that which already exists in the world - e.g., Kay et al. showed\nthat although 28% of CEOs in US are women, only 10% of the top 100 results for\nCEO in Google Image Search are women. Most existing approaches to correct for\nthis kind of bias assume that the images of people include socially salient\nattribute labels. However, such labels are often unknown. Further, using\nautomated techniques to infer these labels may often not be possible within\nacceptable accuracy ranges, and may not be desirable due to the additional\nbiases this process could incur. We develop a novel approach that takes as\ninput a visibly diverse control set of images and uses this set to select a set\nof images of people in response to a query. The goal is to have a resulting set\nthat is more visibly diverse in a manner that emulates the diversity depicted\nin the control set. Importantly, this approach does not require images to be\nlabelled at any point; effectively, it gives a way to implicitly diversify the\nset of images selected. We provide two variants of our approach: the first is a\nmodification of the MMR algorithm to incorporate the diversity scores, and\nsecond is a more efficient variant that does not consider within-list\nredundancy. We evaluate these approaches empirically on two datasets 1) a new\ndataset containing top Google image results for 96 occupations, for which we\nevaluate gender and skin-tone diversity with respect to occupations and 2) the\nCelebA dataset for which we evaluate gender diversity with respect to facial\nfeatures. Our approaches produce image sets that significantly improve the\nvisible diversity of the results, compared to current Google search and other\ndiverse image summarization algorithms, at a minimal cost to accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:13:16 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:45:53 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 21:00:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""]]}, {"id": "1901.10267", "submitter": "Andreas Berthold Thom", "authors": "Andreas Thom", "title": "Approximation of functions by neural networks", "comments": "4 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of measurable functions on the hypercube by\nfunctions arising from affine neural networks. Our main achievement is an\napproximation of any measurable function $f \\colon W_n \\to [-1,1]$ up to a\nprescribed precision $\\varepsilon>0$ by a bounded number of neurons, depending\nonly on $\\varepsilon$ and not on the function $f$ or $n \\in \\mathbb N$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:19:47 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Thom", "Andreas", ""]]}, {"id": "1901.10275", "submitter": "Mikko Heikkil\\\"a", "authors": "Mikko A. Heikkil\\\"a and Joonas J\\\"alk\\\"o and Onur Dikmen and Antti\n  Honkela", "title": "Differentially Private Markov Chain Monte Carlo", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent developments in differentially private (DP) machine learning and DP\nBayesian learning have enabled learning under strong privacy guarantees for the\ntraining data subjects. In this paper, we further extend the applicability of\nDP Bayesian learning by presenting the first general DP Markov chain Monte\nCarlo (MCMC) algorithm whose privacy-guarantees are not subject to unrealistic\nassumptions on Markov chain convergence and that is applicable to posterior\ninference in arbitrary models. Our algorithm is based on a decomposition of the\nBarker acceptance test that allows evaluating the R\\'enyi DP privacy cost of\nthe accept-reject choice. We further show how to improve the DP guarantee\nthrough data subsampling and approximate acceptance tests.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:34:43 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 13:37:26 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Heikkil\u00e4", "Mikko A.", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Dikmen", "Onur", ""], ["Honkela", "Antti", ""]]}, {"id": "1901.10277", "submitter": "Samuli Laine", "authors": "Samuli Laine, Tero Karras, Jaakko Lehtinen, Timo Aila", "title": "High-Quality Self-Supervised Deep Image Denoising", "comments": "NeurIPS 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel method for training high-quality image denoising models\nbased on unorganized collections of corrupted images. The training does not\nneed access to clean reference images, or explicit pairs of corrupted images,\nand can thus be applied in situations where such data is unacceptably expensive\nor impossible to acquire. We build on a recent technique that removes the need\nfor reference data by employing networks with a \"blind spot\" in the receptive\nfield, and significantly improve two key aspects: image quality and training\nefficiency. Our result quality is on par with state-of-the-art neural network\ndenoisers in the case of i.i.d. additive Gaussian noise, and not far behind\nwith Poisson and impulse noise. We also successfully handle cases where\nparameters of the noise model are variable and/or unknown in both training and\nevaluation data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:37:16 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 09:59:59 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 12:36:21 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Laine", "Samuli", ""], ["Karras", "Tero", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "1901.10281", "submitter": "Michael Giering", "authors": "Oshin Olesegun, Ryan Noraas, Michael Giering, Nagendra Somanath", "title": "Structural Material Property Tailoring Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in robotics, artificial intelligence, and machine learning are\nushering in a new age of automation, as machines match or outperform human\nperformance. Machine intelligence can enable businesses to improve performance\nby reducing errors, improving sensitivity, quality and speed, and in some cases\nachieving outcomes that go beyond current resource capabilities. Relevant\napplications include new product architecture design, rapid material\ncharacterization, and life-cycle management tied with a digital strategy that\nwill enable efficient development of products from cradle to grave. In\naddition, there are also challenges to overcome that must be addressed through\na major, sustained research effort that is based solidly on both inferential\nand computational principles applied to design tailoring of functionally\noptimized structures. Current applications of structural materials in the\naerospace industry demand the highest quality control of material\nmicrostructure, especially for advanced rotational turbomachinery in aircraft\nengines in order to have the best tailored material property. In this paper,\ndeep convolutional neural networks were developed to accurately predict\nprocessing-structure-property relations from materials microstructures images,\nsurpassing current best practices and modeling efforts. The models\nautomatically learn critical features, without the need for manual\nspecification and/or subjective and expensive image analysis. Further, in\ncombination with generative deep learning models, a framework is proposed to\nenable rapid material design space exploration and property identification and\noptimization. The implementation must take account of real-time decision cycles\nand the trade-offs between speed and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:43:57 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Olesegun", "Oshin", ""], ["Noraas", "Ryan", ""], ["Giering", "Michael", ""], ["Somanath", "Nagendra", ""]]}, {"id": "1901.10289", "submitter": "Bernhard Kratzwald", "authors": "Nil-Jana Akpinar, Bernhard Kratzwald, Stefan Feuerriegel", "title": "Sample Complexity Bounds for Recurrent Neural Networks with Application\n  to Combinatorial Graph Problems", "comments": "A two-page summary of this paper has been accepted as a student\n  abstract at AAAI-20, this is the extended full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to predict solutions to real-valued combinatorial graph problems\npromises efficient approximations. As demonstrated based on the NP-hard edge\nclique cover number, recurrent neural networks (RNNs) are particularly suited\nfor this task and can even outperform state-of-the-art heuristics. However, the\ntheoretical framework for estimating real-valued RNNs is understood only\npoorly. As our primary contribution, this is the first work that upper bounds\nthe sample complexity for learning real-valued RNNs. While such derivations\nhave been made earlier for feed-forward and convolutional neural networks, our\nwork presents the first such attempt for recurrent neural networks. Given a\nsingle-layer RNN with $a$ rectified linear units and input of length $b$, we\nshow that a population prediction error of $\\varepsilon$ can be realized with\nat most $\\tilde{\\mathcal{O}}(a^4b/\\varepsilon^2)$ samples. We further derive\ncomparable results for multi-layer RNNs. Accordingly, a size-adaptive RNN fed\nwith graphs of at most $n$ vertices can be learned in\n$\\tilde{\\mathcal{O}}(n^6/\\varepsilon^2)$, i.e., with only a polynomial number\nof samples. For combinatorial graph problems, this provides a theoretical\nfoundation that renders RNNs competitive.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:56:45 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 00:06:20 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Akpinar", "Nil-Jana", ""], ["Kratzwald", "Bernhard", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1901.10310", "submitter": "Nikola Konstantinov", "authors": "Nikola Konstantinov and Christoph Lampert", "title": "Robust Learning from Untrusted Sources", "comments": "Accepted to International Conference on Machine Learning (ICML),\n  2019; Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning methods often require more data for training than a\nsingle expert can provide. Therefore, it has become a standard procedure to\ncollect data from external sources, e.g. via crowdsourcing. Unfortunately, the\nquality of these sources is not always guaranteed. As additional complications,\nthe data might be stored in a distributed way, or might even have to remain\nprivate. In this work, we address the question of how to learn robustly in such\nscenarios. Studying the problem through the lens of statistical learning\ntheory, we derive a procedure that allows for learning from all available\nsources, yet automatically suppresses irrelevant or corrupted data. We show by\nextensive experiments that our method provides significant improvements over\nalternative approaches from robust statistics and distributed optimization.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:33:42 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 16:21:28 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Konstantinov", "Nikola", ""], ["Lampert", "Christoph", ""]]}, {"id": "1901.10314", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Xiaoyang Tan, Yaozhong Gan", "title": "Trust Region-Guided Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal policy optimization (PPO) is one of the most popular deep\nreinforcement learning (RL) methods, achieving state-of-the-art performance\nacross a wide range of challenging tasks. However, as a model-free RL method,\nthe success of PPO relies heavily on the effectiveness of its exploratory\npolicy search. In this paper, we give an in-depth analysis on the exploration\nbehavior of PPO, and show that PPO is prone to suffer from the risk of lack of\nexploration especially under the case of bad initialization, which may lead to\nthe failure of training or being trapped in bad local optima. To address these\nissues, we proposed a novel policy optimization method, named Trust\nRegion-Guided PPO (TRGPPO), which adaptively adjusts the clipping range within\nthe trust region. We formally show that this method not only improves the\nexploration ability within the trust region but enjoys a better performance\nbound compared to the original PPO as well. Extensive experiments verify the\nadvantage of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 14:45:08 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:35:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Tan", "Xiaoyang", ""], ["Gan", "Yaozhong", ""]]}, {"id": "1901.10334", "submitter": "Alper Atamturk", "authors": "Alper Atamturk and Andres Gomez", "title": "Rank-one Convexification for Sparse Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": "BCOL 19.01, IEOR, UC Berkeley", "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse regression models are increasingly prevalent due to their ease of\ninterpretability and superior out-of-sample performance. However, the exact\nmodel of sparse regression with an $\\ell_0$ constraint restricting the support\nof the estimators is a challenging (\\NP-hard) non-convex optimization problem.\nIn this paper, we derive new strong convex relaxations for sparse regression.\nThese relaxations are based on the ideal (convex-hull) formulations for\nrank-one quadratic terms with indicator variables. The new relaxations can be\nformulated as semidefinite optimization problems in an extended space and are\nstronger and more general than the state-of-the-art formulations, including the\nperspective reformulation and formulations with the reverse Huber penalty and\nthe minimax concave penalty functions. Furthermore, the proposed rank-one\nstrengthening can be interpreted as a \\textit{non-separable, non-convex,\nunbiased} sparsity-inducing regularizer, which dynamically adjusts its penalty\naccording to the shape of the error function without inducing bias for the\nsparse solutions. In our computational experiments with benchmark datasets, the\nproposed conic formulations are solved within seconds and result in\nnear-optimal solutions (with 0.4\\% optimality gap) for non-convex\n$\\ell_0$-problems. Moreover, the resulting estimators also outperform\nalternative convex approaches from a statistical perspective, achieving high\nprediction accuracy and good interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 15:12:59 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 18:50:17 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Atamturk", "Alper", ""], ["Gomez", "Andres", ""]]}, {"id": "1901.10338", "submitter": "Daniel Kottke", "authors": "Daniel Kottke, Jim Schellinger, Denis Huseljic, Bernhard Sick", "title": "Limitations of Assessing Active Learning Performance at Runtime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms aim to predict an unknown label (e.g., a quality\nclass) for a new instance (e.g., a product). Therefore, training samples\n(instances and labels) are used to deduct classification hypotheses. Often, it\nis relatively easy to capture instances but the acquisition of the\ncorresponding labels remain difficult or expensive. Active learning algorithms\nselect the most beneficial instances to be labeled to reduce cost. In research,\nthis labeling procedure is simulated and therefore a ground truth is available.\nBut during deployment, active learning is a one-shot problem and an evaluation\nset is not available. Hence, it is not possible to reliably estimate the\nperformance of the classification system during learning and it is difficult to\ndecide when the system fulfills the quality requirements (stopping criteria).\nIn this article, we formalize the task and review existing strategies to assess\nthe performance of an actively trained classifier during training. Furthermore,\nwe identified three major challenges: 1)~to derive a performance distribution,\n2)~to preserve representativeness of the labeled subset, and 3) to correct\nagainst sampling bias induced by an intelligent selection strategy. In a\nqualitative analysis, we evaluate different existing approaches and show that\nnone of them reliably estimates active learning performance stating a major\nchallenge for future research for such systems. All plots and experiments are\nprovided in a Jupyter notebook that is available for download.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 15:26:13 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kottke", "Daniel", ""], ["Schellinger", "Jim", ""], ["Huseljic", "Denis", ""], ["Sick", "Bernhard", ""]]}, {"id": "1901.10348", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Alp Yurtsever, Olivier Fercoq, Volkan Cevher", "title": "Stochastic Frank-Wolfe for Composite Convex Minimization", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad class of convex optimization problems can be formulated as a\nsemidefinite program (SDP), minimization of a convex function over the\npositive-semidefinite cone subject to some affine constraints. The majority of\nclassical SDP solvers are designed for the deterministic setting where problem\ndata is readily available. In this setting, generalized conditional gradient\nmethods (aka Frank-Wolfe-type methods) provide scalable solutions by leveraging\nthe so-called linear minimization oracle instead of the projection onto the\nsemidefinite cone. Most problems in machine learning and modern engineering\napplications, however, contain some degree of stochasticity. In this work, we\npropose the first conditional-gradient-type method for solving stochastic\noptimization problems under affine constraints. Our method guarantees\n$\\mathcal{O}(k^{-1/3})$ convergence rate in expectation on the objective\nresidual and $\\mathcal{O}(k^{-5/12})$ on the feasibility gap.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 15:53:16 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 18:40:10 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 11:10:21 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Locatello", "Francesco", ""], ["Yurtsever", "Alp", ""], ["Fercoq", "Olivier", ""], ["Cevher", "Volkan", ""]]}, {"id": "1901.10356", "submitter": "Nils Kriege", "authors": "Nils M. Kriege, Pierre-Louis Giscard, Franka Bause, Richard C. Wilson", "title": "Computing Optimal Assignments in Linear Time for Approximate Graph\n  Matching", "comments": "IEEE ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an optimal assignment between two sets of objects is a fundamental\nproblem arising in many applications, including the matching of `bag-of-words'\nrepresentations in natural language processing and computer vision. Solving the\nassignment problem typically requires cubic time and its pairwise computation\nis expensive on large datasets. In this paper, we develop an algorithm which\ncan find an optimal assignment in linear time when the cost function between\nobjects is represented by a tree distance. We employ the method to approximate\nthe edit distance between two graphs by matching their vertices in linear time.\nTo this end, we propose two tree distances, the first of which reflects\ndiscrete and structural differences between vertices, and the second of which\ncan be used to compare continuous labels. We verify the effectiveness and\nefficiency of our methods using synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 16:10:15 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 22:23:12 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kriege", "Nils M.", ""], ["Giscard", "Pierre-Louis", ""], ["Bause", "Franka", ""], ["Wilson", "Richard C.", ""]]}, {"id": "1901.10371", "submitter": "Emilio Rafael Balda", "authors": "Peter Langeberg, Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar", "title": "On the Effect of Low-Rank Weights on Adversarial Robustness of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an abundance of works on designing Deep Neural\nNetworks (DNNs) that are robust to adversarial examples. In particular, a\ncentral question is which features of DNNs influence adversarial robustness\nand, therefore, can be to used to design robust DNNs. In this work, this\nproblem is studied through the lens of compression which is captured by the\nlow-rank structure of weight matrices. It is first shown that adversarial\ntraining tends to promote simultaneously low-rank and sparse structure in the\nweight matrices of neural networks. This is measured through the notions of\neffective rank and effective sparsity. In the reverse direction, when the low\nrank structure is promoted by nuclear norm regularization and combined with\nsparsity inducing regularizations, neural networks show significantly improved\nadversarial robustness. The effect of nuclear norm regularization on\nadversarial robustness is paramount when it is applied to convolutional neural\nnetworks. Although still not competing with adversarial training, this result\ncontributes to understanding the key properties of robust classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 16:37:17 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Langeberg", "Peter", ""], ["Balda", "Emilio Rafael", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1901.10400", "submitter": "Cameron Carlin", "authors": "Nicole Fronda, Jessica Asencio, Cameron Carlin, David Ledbetter,\n  Melissa Aczon, Randall Wetzel, Barry Markovitz", "title": "Predicting Individual Responses to Vasoactive Medications in Children\n  with Septic Shock", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Predict individual septic children's personalized physiologic\nresponses to vasoactive titrations by training a Recurrent Neural Network (RNN)\nusing EMR data.\n  Materials and Methods: This study retrospectively analyzed EMR of patients\nadmitted to a pediatric ICU from 2009 to 2017. Data included charted time\nseries vitals, labs, drugs, and interventions of children with septic shock\ntreated with dopamine, epinephrine, or norepinephrine. A RNN was trained to\npredict responses in heart rate (HR), systolic blood pressure (SBP), diastolic\nblood pressure (DBP) and mean arterial pressure (MAP) to 8,640 titrations\nduring 652 septic episodes and evaluated on a holdout set of 3,883 titrations\nduring 254 episodes. A linear regression model using titration data as its sole\ninput was also developed and compared to the RNN model. Evaluation methods\nincluded the correlation coefficient between actual physiologic responses and\nRNN predictions, mean absolute error (MAE), and area under the receiver\noperating characteristic curve (AUC).\n  Results: The actual physiologic responses displayed significant variability\nand were more accurately predicted by the RNN model than by titration alone\n(r=0.20 vs r=0.05, p<0.01). The RNN showed MAE and AUC improvements over the\nlinear model. The RNN's MAEs associated with dopamine and epinephrine were 1-3%\nlower than the linear regression model MAE for HR, SBP, DBP, and MAP. Across\nall vitals vasoactives, the RNN achieved 1-19% AUC improvement over the linear\nmodel.\n  Conclusion: This initial attempt in pediatric critical care to predict\nindividual physiologic responses to vasoactive dose changes in children with\nseptic shock demonstrated an RNN model showed some improvement over a linear\nmodel. While not yet clinically applicable, further development may assist\nclinical administration of vasoactive medications in children with septic\nshock.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 23:43:04 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Fronda", "Nicole", ""], ["Asencio", "Jessica", ""], ["Carlin", "Cameron", ""], ["Ledbetter", "David", ""], ["Aczon", "Melissa", ""], ["Wetzel", "Randall", ""], ["Markovitz", "Barry", ""]]}, {"id": "1901.10417", "submitter": "Przemys{\\l}aw Spurek", "authors": "Szymon Knop, Marcin Mazur, Jacek Tabor, Igor Podolak, Przemys{\\l}aw\n  Spurek", "title": "Sliced generative models", "comments": "11 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss a class of AutoEncoder based generative models based\non one dimensional sliced approach. The idea is based on the reduction of the\ndiscrimination between samples to one-dimensional case. Our experiments show\nthat methods can be divided into two groups. First consists of methods which\nare a modification of standard normality tests, while the second is based on\nclassical distances between samples. It turns out that both groups are correct\ngenerative models, but the second one gives a slightly faster decrease rate of\nFr\\'{e}chet Inception Distance (FID).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 17:34:56 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Knop", "Szymon", ""], ["Mazur", "Marcin", ""], ["Tabor", "Jacek", ""], ["Podolak", "Igor", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "1901.10426", "submitter": "Manuel Pulido", "authors": "Manuel Pulido, Peter Jan vanLeeuwen and Derek J. Posselt", "title": "Kernel embedded nonlinear observational mappings in the variational\n  mapping particle filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some works have suggested methods to combine variational\nprobabilistic inference with Monte Carlo sampling. One promising approach is\nvia local optimal transport. In this approach, a gradient steepest descent\nmethod based on local optimal transport principles is formulated to transform\ndeterministically point samples from an intermediate density to a posterior\ndensity. The local mappings that transform the intermediate densities are\nembedded in a reproducing kernel Hilbert space (RKHS). This variational mapping\nmethod requires the evaluation of the log-posterior density gradient and\ntherefore the adjoint of the observational operator. In this work, we evaluate\nnonlinear observational mappings in the variational mapping method using two\napproximations that avoid the adjoint, an ensemble based approximation in which\nthe gradient is approximated by the particle covariances in the state and\nobservational spaces the so-called ensemble space and an RKHS approximation in\nwhich the observational mapping is embedded in an RKHS and the gradient is\nderived there. The approximations are evaluated for highly nonlinear\nobservational operators and in a low-dimensional chaotic dynamical system. The\nRKHS approximation is shown to be highly successful and superior to the\nensemble approximation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 17:57:23 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Pulido", "Manuel", ""], ["vanLeeuwen", "Peter Jan", ""], ["Posselt", "Derek J.", ""]]}, {"id": "1901.10429", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen, Robert Calderbank, Nikos Deligiannis", "title": "Geometric Matrix Completion with Deep Conditional Random Fields", "comments": "Accepted to IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of completing high-dimensional matrices from a limited set of\nobservations arises in many big data applications, especially, recommender\nsystems. Existing matrix completion models generally follow either a memory- or\na model-based approach, whereas, geometric matrix completion models combine the\nbest from both approaches. Existing deep-learning-based geometric models yield\ngood performance, but, in order to operate, they require a fixed structure\ngraph capturing the relationships among the users and items. This graph is\ntypically constructed by evaluating a pre-defined similarity metric on the\navailable observations or by using side information, e.g., user profiles. In\ncontrast, Markov-random-fields-based models do not require a fixed structure\ngraph but rely on handcrafted features to make predictions. When no side\ninformation is available and the number of available observations becomes very\nlow, existing solutions are pushed to their limits. In this paper, we propose a\ngeometric matrix completion approach that addresses these challenges. We\nconsider matrix completion as a structured prediction problem in a conditional\nrandom field (CRF), which is characterized by a maximum a posterior (MAP)\ninference, and we propose a deep model that predicts the missing entries by\nsolving the MAP inference problem. The proposed model simultaneously learns the\nsimilarities among matrix entries, computes the CRF potentials, and solves the\ninference problem. Its training is performed in an end-to-end manner, with a\nmethod to supervise the learning of entry similarities. Comprehensive\nexperiments demonstrate the superior performance of the proposed model compared\nto various state-of-the-art models on popular benchmark datasets and underline\nits superior capacity to deal with highly incomplete matrices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 17:59:23 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 08:10:04 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Calderbank", "Robert", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1901.10435", "submitter": "Aleksandar Vakanski", "authors": "Y. Liao, A. Vakanski, M. Xian (University of Idaho, USA)", "title": "A Deep Learning Framework for Assessing Physical Rehabilitation\n  Exercises", "comments": "10 pages, 7 figures", "journal-ref": "IEEE Transactions on Neural Systems and Rehabilitation\n  Engineering, vol. 28, no. 2, pp. 1-10, 2020", "doi": "10.1109/TNSRE.2020.2966249", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided assessment of physical rehabilitation entails evaluation of\npatient performance in completing prescribed rehabilitation exercises, based on\nprocessing movement data captured with a sensory system. Despite the essential\nrole of rehabilitation assessment toward improved patient outcomes and reduced\nhealthcare costs, existing approaches lack versatility, robustness, and\npractical relevance. In this paper, we propose a deep learning-based framework\nfor automated assessment of the quality of physical rehabilitation exercises.\nThe main components of the framework are metrics for quantifying movement\nperformance, scoring functions for mapping the performance metrics into\nnumerical scores of movement quality, and deep neural network models for\ngenerating quality scores of input movements via supervised learning. The\nproposed performance metric is defined based on the log-likelihood of a\nGaussian mixture model, and encodes low-dimensional data representation\nobtained with a deep autoencoder network. The proposed deep spatio-temporal\nneural network arranges data into temporal pyramids, and exploits the spatial\ncharacteristics of human movements by using sub-networks to process joint\ndisplacements of individual body parts. The presented framework is validated\nusing a dataset of ten rehabilitation exercises. The significance of this work\nis that it is the first that implements deep neural networks for assessment of\nrehabilitation performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:16:08 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 04:19:37 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 01:34:09 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liao", "Y.", "", "University of Idaho, USA"], ["Vakanski", "A.", "", "University of Idaho, USA"], ["Xian", "M.", "", "University of Idaho, USA"]]}, {"id": "1901.10443", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis and Vijay Keswani", "title": "Improved Adversarial Learning for Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by concerns that machine learning algorithms may introduce\nsignificant bias in classification models, developing fair classifiers has\nbecome an important problem in machine learning research. One important\nparadigm towards this has been providing algorithms for adversarially learning\nfair classifiers (Zhang et al., 2018; Madras et al., 2018). We formulate the\nadversarial learning problem as a multi-objective optimization problem and find\nthe fair model using gradient descent-ascent algorithm with a modified gradient\nupdate step, inspired by the approach of Zhang et al., 2018. We provide\ntheoretical insight and guarantees that formalize the heuristic arguments\npresented previously towards taking such an approach. We test our approach\nempirically on the Adult dataset and synthetic datasets and compare against\nstate of the art algorithms (Celis et al., 2018; Zhang et al., 2018; Zafar et\nal., 2017). The results show that our models and algorithms have comparable or\nbetter accuracy than other algorithms while performing better in terms of\nfairness, as measured using statistical rate or false discovery rate.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:42:49 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""]]}, {"id": "1901.10452", "submitter": "Ahsan Alvi", "authors": "Ahsan S. Alvi, Binxin Ru, Jan Calliess, Stephen J. Roberts, Michael A.\n  Osborne", "title": "Asynchronous Batch Bayesian Optimisation with Improved Local\n  Penalisation", "comments": "Camera-ready version after incorporating reviewers' suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Bayesian optimisation (BO) has been successfully applied to\nhyperparameter tuning using parallel computing, but it is wasteful of\nresources: workers that complete jobs ahead of others are left idle. We address\nthis problem by developing an approach, Penalising Locally for Asynchronous\nBayesian Optimisation on $k$ workers (PLAyBOOK), for asynchronous parallel BO.\nWe demonstrate empirically the efficacy of PLAyBOOK and its variants on\nsynthetic tasks and a real-world problem. We undertake a comparison between\nsynchronous and asynchronous BO, and show that asynchronous BO often\noutperforms synchronous batch BO in both wall-clock time and number of function\nevaluations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:56:59 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 15:36:41 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 14:23:47 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Alvi", "Ahsan S.", ""], ["Ru", "Binxin", ""], ["Calliess", "Jan", ""], ["Roberts", "Stephen J.", ""], ["Osborne", "Michael A.", ""]]}, {"id": "1901.10501", "submitter": "Hao Wang", "authors": "Hao Wang, Berk Ustun, Flavio P. Calmon", "title": "Repairing without Retraining: Avoiding Disparate Impact with\n  Counterfactual Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the performance of a machine learning model varies over groups defined\nby sensitive attributes (e.g., gender or ethnicity), the performance disparity\ncan be expressed in terms of the probability distributions of the input and\noutput variables over each group. In this paper, we exploit this fact to reduce\nthe disparate impact of a fixed classification model over a population of\ninterest. Given a black-box classifier, we aim to eliminate the performance gap\nby perturbing the distribution of input variables for the disadvantaged group.\nWe refer to the perturbed distribution as a counterfactual distribution, and\ncharacterize its properties for common fairness criteria. We introduce a\ndescent algorithm to learn a counterfactual distribution from data. We then\ndiscuss how the estimated distribution can be used to build a data preprocessor\nthat can reduce disparate impact without training a new model. We validate our\napproach through experiments on real-world datasets, showing that it can repair\ndifferent forms of disparity without a significant drop in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 19:21:10 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 15:42:11 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Wang", "Hao", ""], ["Ustun", "Berk", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "1901.10513", "submitter": "Justin Gilmer", "authors": "Nic Ford, Justin Gilmer, Nicolas Carlini, Dogus Cubuk", "title": "Adversarial Examples Are a Natural Consequence of Test Error in Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, the phenomenon of adversarial examples ---\nmaliciously constructed inputs that fool trained machine learning models ---\nhas captured the attention of the research community, especially when the\nadversary is restricted to small modifications of a correctly handled input.\nLess surprisingly, image classifiers also lack human-level performance on\nrandomly corrupted images, such as images with additive Gaussian noise. In this\npaper we provide both empirical and theoretical evidence that these are two\nmanifestations of the same underlying phenomenon, establishing close\nconnections between the adversarial robustness and corruption robustness\nresearch programs. This suggests that improving adversarial robustness should\ngo hand in hand with improving performance in the presence of more general and\nrealistic image corruptions. Based on our results we recommend that future\nadversarial defenses consider evaluating the robustness of their methods to\ndistributional shift with benchmarks such as Imagenet-C.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:01:39 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Ford", "Nic", ""], ["Gilmer", "Justin", ""], ["Carlini", "Nicolas", ""], ["Cubuk", "Dogus", ""]]}, {"id": "1901.10514", "submitter": "Pascal Mettes", "authors": "Pascal Mettes, Elise van der Pol, Cees G. M. Snoek", "title": "Hyperspherical Prototype Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces hyperspherical prototype networks, which unify\nclassification and regression with prototypes on hyperspherical output spaces.\nFor classification, a common approach is to define prototypes as the mean\noutput vector over training examples per class. Here, we propose to use\nhyperspheres as output spaces, with class prototypes defined a priori with\nlarge margin separation. We position prototypes through data-independent\noptimization, with an extension to incorporate priors from class semantics. By\ndoing so, we do not require any prototype updating, we can handle any training\nsize, and the output dimensionality is no longer constrained to the number of\nclasses. Furthermore, we generalize to regression, by optimizing outputs as an\ninterpolation between two prototypes on the hypersphere. Since both tasks are\nnow defined by the same loss function, they can be jointly trained for\nmulti-task problems. Experimentally, we show the benefit of hyperspherical\nprototype networks for classification, regression, and their combination over\nother prototype methods, softmax cross-entropy, and mean squared error\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:05:23 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 10:42:30 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 09:17:20 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Mettes", "Pascal", ""], ["van der Pol", "Elise", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "1901.10517", "submitter": "Sang Michael Xie", "authors": "Sang Michael Xie, Stefano Ermon", "title": "Reparameterizable Subset Sampling via Continuous Relaxations", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning tasks require sampling a subset of items from a\ncollection based on a parameterized distribution. The Gumbel-softmax trick can\nbe used to sample a single item, and allows for low-variance reparameterized\ngradients with respect to the parameters of the underlying distribution.\nHowever, stochastic optimization involving subset sampling is typically not\nreparameterizable. To overcome this limitation, we define a continuous\nrelaxation of subset sampling that provides reparameterization gradients by\ngeneralizing the Gumbel-max trick. We use this approach to sample subsets of\nfeatures in an instance-wise feature selection task for model interpretability,\nsubsets of neighbors to implement a deep stochastic k-nearest neighbors model,\nand sub-sequences of neighbors to implement parametric t-SNE by directly\ncomparing the identities of local neighbors. We improve performance in all\nthese tasks by incorporating subset sampling in end-to-end training.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:09:18 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 03:43:22 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 04:18:53 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 23:26:00 GMT"}, {"version": "v5", "created": "Fri, 26 Feb 2021 19:31:03 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Xie", "Sang Michael", ""], ["Ermon", "Stefano", ""]]}, {"id": "1901.10521", "submitter": "Zhana Kuncheva", "authors": "Zhana Kuncheva and Giovanni Montana", "title": "Spectral Multi-scale Community Detection in Temporal Networks with an\n  Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of temporal networks has a wide area of applications in a world\nof technological advances. An important aspect of temporal network analysis is\nthe discovery of community structures. Real data networks are often very large\nand the communities are observed to have a hierarchical structure referred to\nas multi-scale communities. Changes in the community structure over time might\ntake place either at one scale or across all scales of the community structure.\nThe multilayer formulation of the modularity maximization (MM) method\nintroduced captures the changing multi-scale community structure of temporal\nnetworks. This method introduces a coupling between communities in neighboring\ntime layers by allowing inter-layer connections, while different values of the\nresolution parameter enable the detection of multi-scale communities. However,\nthe range of this parameter's values must be manually selected. When dealing\nwith real life data, communities at one or more scales can go undiscovered if\nappropriate parameter ranges are not selected. A novel Temporal Multi-scale\nCommunity Detection (TMSCD) method overcomes the obstacles mentioned above.\nThis is achieved by using the spectral properties of the temporal network\nrepresented as a multilayer network. In this framework we select automatically\nthe range of relevant scales within which multi-scale community partitions are\nsought.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:19:36 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Kuncheva", "Zhana", ""], ["Montana", "Giovanni", ""]]}, {"id": "1901.10524", "submitter": "Ron Levie", "authors": "Ron Levie, Elvin Isufi, Gitta Kutyniok", "title": "On the Transferability of Spectral Graph Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on spectral filters on graphs, namely filters defined as\nelementwise multiplication in the frequency domain of a graph. In many graph\nsignal processing settings, it is important to transfer a filter from one graph\nto another. One example is in graph convolutional neural networks (ConvNets),\nwhere the dataset consists of signals defined on many different graphs, and the\nlearned filters should generalize to signals on new graphs, not present in the\ntraining set. A necessary condition for transferability (the ability to\ntransfer filters) is stability. Namely, given a graph filter, if we add a small\nperturbation to the graph, then the filter on the perturbed graph is a small\nperturbation of the original filter. It is a common misconception that spectral\nfilters are not stable, and this paper aims at debunking this mistake. We\nintroduce a space of filters, called the Cayley smoothness space, that contains\nthe filters of state-of-the-art spectral filtering methods, and whose filters\ncan approximate any generic spectral filter. For filters in this space, the\nperturbation in the filter is bounded by a constant times the perturbation in\nthe graph, and filters in the Cayley smoothness space are thus termed linearly\nstable. By combining stability with the known property of equivariance, we\nprove that graph spectral filters are transferable.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:29:20 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Levie", "Ron", ""], ["Isufi", "Elvin", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1901.10526", "submitter": "Asa Ben-Hur", "authors": "Ameni Trabelsi, Mohamed Chaabane, Asa Ben Hur", "title": "Comprehensive Evaluation of Deep Learning Architectures for Prediction\n  of DNA/RNA Sequence Binding Specificities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Deep learning architectures have recently demonstrated their\npower in predicting DNA- and RNA-binding specificities. Existing methods fall\ninto three classes: Some are based on Convolutional Neural Networks (CNNs),\nothers use Recurrent Neural Networks (RNNs), and others rely on hybrid\narchitectures combining CNNs and RNNs. However, based on existing studies it is\nstill unclear which deep learning architecture is achieving the best\nperformance. Thus an in-depth analysis and evaluation of the different methods\nis needed to fully evaluate their relative. Results: In this study, We present\na systematic exploration of various deep learning architectures for predicting\nDNA- and RNA-binding specificities. For this purpose, we present deepRAM, an\nend-to-end deep learning tool that provides an implementation of novel and\npreviously proposed architectures; its fully automatic model selection\nprocedure allows us to perform a fair and unbiased comparison of deep learning\narchitectures. We find that an architecture that uses k-mer embedding to\nrepresent the sequence, a convolutional layer and a recurrent layer,\noutperforms all other methods in terms of model accuracy. Our work provides\nguidelines that will assist the practitioner in choosing the best architecture\nfor the task at hand, and provides some insights on the differences between the\nmodels learned by convolutional and recurrent networks. In particular, we find\nthat although recurrent networks improve model accuracy, this comes at the\nexpense of a loss in the interpretability of the features learned by the model.\nAvailability and implementation: The source code for deepRAM is available at\nhttps://github.com/MedChaabane/deepRAM\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:33:52 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Trabelsi", "Ameni", ""], ["Chaabane", "Mohamed", ""], ["Hur", "Asa Ben", ""]]}, {"id": "1901.10539", "submitter": "Arun Thundyill Saseendran", "authors": "Arun Thundyill Saseendran, Lovish Setia, Viren Chhabria, Debrup\n  Chakraborty, Aneek Barman Roy", "title": "Impact of Data Pruning on Machine Learning Algorithm Performance", "comments": "5 pages, 10 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dataset pruning is the process of removing sub-optimal tuples from a dataset\nto improve the learning of a machine learning model. In this paper, we compared\nthe performance of different algorithms, first on an unpruned dataset and then\non an iteratively pruned dataset. The goal was to understand whether an\nalgorithm (say A) on an unpruned dataset performs better than another algorithm\n(say B), will algorithm B perform better on the pruned data or vice-versa. The\ndataset chosen for our analysis is a subset of the largest movie ratings\ndatabase publicly available on the internet, IMDb [1]. The learning objective\nof the model was to predict the categorical rating of a movie among 5 bins:\npoor, average, good, very good, excellent. The results indicated that an\nalgorithm that performed better on an unpruned dataset also performed better on\na pruned dataset.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 19:32:09 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Saseendran", "Arun Thundyill", ""], ["Setia", "Lovish", ""], ["Chhabria", "Viren", ""], ["Chakraborty", "Debrup", ""], ["Roy", "Aneek Barman", ""]]}, {"id": "1901.10548", "submitter": "Zachary Ziegler", "authors": "Zachary M. Ziegler, Alexander M. Rush", "title": "Latent Normalizing Flows for Discrete Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a powerful class of generative models for continuous\nrandom variables, showing both strong model flexibility and the potential for\nnon-autoregressive generation. These benefits are also desired when modeling\ndiscrete random variables such as text, but directly applying normalizing flows\nto discrete sequences poses significant additional challenges. We propose a\nVAE-based generative model which jointly learns a normalizing flow-based\ndistribution in the latent space and a stochastic mapping to an observed\ndiscrete space. In this setting, we find that it is crucial for the flow-based\ndistribution to be highly multimodal. To capture this property, we propose\nseveral normalizing flow architectures to maximize model flexibility.\nExperiments consider common discrete sequence tasks of character-level language\nmodeling and polyphonic music generation. Our results indicate that an\nautoregressive flow-based model can match the performance of a comparable\nautoregressive baseline, and a non-autoregressive flow-based model can improve\ngeneration speed with a penalty to performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:05:46 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 17:41:04 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 17:57:00 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 18:34:05 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ziegler", "Zachary M.", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1901.10557", "submitter": "Radhakrishnan Balu", "authors": "Radhakrishnan Balu and Ajinkya Borle", "title": "Bayesian Networks based Hybrid Quantum-Classical Machine Learning\n  Approach to Elucidate Gene Regulatory Pathways", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a scalable hybrid quantum-classical machine learning framework to\nbuild Bayesian networks (BN) that captures the conditional dependence and\ncausal relationships of random variables. The generation of a BN consists of\nfinding a directed acyclic graph (DAG) and the associated joint probability\ndistribution of the nodes consistent with a given dataset. This is a\ncombinatorial problem of structural learning of the underlying graph, starting\nfrom a single node and building one arc at a time, that fits a given ensemble\nusing maximum likelihood estimators (MLE). It is cast as an optimization\nproblem that consists of a scoring step performed on a classical computer,\npenalties for acyclicity and number of parents allowed constraints, and a\nsearch step implemented using a quantum annealer. We have assumed uniform\npriors in deriving the Bayesian network that can be relaxed by formulating the\nproblem as an estimation Dirichlet parameters. We demonstrate the utility of\nthe framework by applying to the problem of elucidating the gene regulatory\nnetwork for the MAPK/Raf pathway in human T-cells using proteomics data where\nthe concentration of proteins, nodes of the BN, are interpreted as\nprobabilities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:21:08 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Balu", "Radhakrishnan", ""], ["Borle", "Ajinkya", ""]]}, {"id": "1901.10566", "submitter": "Sherri Rose", "authors": "Anna Zink and Sherri Rose", "title": "Fair Regression for Health Care Spending", "comments": "30 pages, 3 figures", "journal-ref": "Biometrics (2020)", "doi": "10.1111/biom.13206", "report-no": null, "categories": "stat.AP cs.CY stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of health care payments to insurance plans has substantial\nconsequences for social policy. Risk adjustment formulas predict spending in\nhealth insurance markets in order to provide fair benefits and health care\ncoverage for all enrollees, regardless of their health status. Unfortunately,\ncurrent risk adjustment formulas are known to underpredict spending for\nspecific groups of enrollees leading to undercompensated payments to health\ninsurers. This incentivizes insurers to design their plans such that\nindividuals in undercompensated groups will be less likely to enroll, impacting\naccess to health care for these groups. To improve risk adjustment formulas for\nundercompensated groups, we expand on concepts from the statistics, computer\nscience, and health economics literature to develop new fair regression methods\nfor continuous outcomes by building fairness considerations directly into the\nobjective function. We additionally propose a novel measure of fairness while\nasserting that a suite of metrics is necessary in order to evaluate risk\nadjustment formulas more fully. Our data application using the IBM MarketScan\nResearch Databases and simulation studies demonstrate that these new fair\nregression methods may lead to massive improvements in group fairness (e.g.,\n98%) with only small reductions in overall fit (e.g., 4%).\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 04:06:50 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 06:11:28 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Zink", "Anna", ""], ["Rose", "Sherri", ""]]}, {"id": "1901.10568", "submitter": "Christopher Aicher", "authors": "Christopher Aicher, Srshti Putcha, Christopher Nemeth, Paul Fearnhead,\n  and Emily B. Fox", "title": "Stochastic Gradient MCMC for Nonlinear State Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State space models (SSMs) provide a flexible framework for modeling complex\ntime series via a latent stochastic process. Inference for nonlinear,\nnon-Gaussian SSMs is often tackled with particle methods that do not scale well\nto long time series. The challenge is two-fold: not only do computations scale\nlinearly with time, as in the linear case, but particle filters additionally\nsuffer from increasing particle degeneracy with longer series. Stochastic\ngradient MCMC methods have been developed to scale inference for hidden Markov\nmodels (HMMs) and linear SSMs using buffered stochastic gradient estimates to\naccount for temporal dependencies. We extend these stochastic gradient\nestimators to nonlinear SSMs using particle methods. We present error bounds\nthat account for both buffering error and particle error in the case of\nnonlinear SSMs that are log-concave in the latent process. We evaluate our\nproposed particle buffered stochastic gradient using SGMCMC for inference on\nboth long sequential synthetic and minute-resolution financial returns data,\ndemonstrating the importance of this class of methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:39:56 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 02:59:19 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Aicher", "Christopher", ""], ["Putcha", "Srshti", ""], ["Nemeth", "Christopher", ""], ["Fearnhead", "Paul", ""], ["Fox", "Emily B.", ""]]}, {"id": "1901.10583", "submitter": "Vithya Yogarajan", "authors": "Vithya Yogarajan, Bernhard Pfahringer and Michael Mayo", "title": "Automatic end-to-end De-identification: Is high accuracy the only\n  metric?", "comments": "17 pages, 1 figure, 7 tables, review journal paper", "journal-ref": "Applied Artificial Intelligence, 2020", "doi": "10.1080/08839514.2020.1718343", "report-no": "04-Feb-2020", "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De-identification of electronic health records (EHR) is a vital step towards\nadvancing health informatics research and maximising the use of available data.\nIt is a two-step process where step one is the identification of protected\nhealth information (PHI), and step two is replacing such PHI with surrogates.\nDespite the recent advances in automatic de-identification of EHR, significant\nobstacles remain if the abundant health data available are to be used to the\nfull potential. Accuracy in de-identification could be considered a necessary,\nbut not sufficient condition for the use of EHR without individual patient\nconsent. We present here a comprehensive review of the progress to date, both\nthe impressive successes in achieving high accuracy and the significant risks\nand challenges that remain. To best of our knowledge, this is the first paper\nto present a complete picture of end-to-end automatic de-identification. We\nreview 18 recently published automatic de-identification systems -designed to\nde-identify EHR in the form of free text- to show the advancements made in\nimproving the overall accuracy of the system, and in identifying individual\nPHI. We argue that despite the improvements in accuracy there remain challenges\nin surrogate generation and replacements of identified PHIs, and the risks\nposed to patient protection and privacy.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 21:51:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yogarajan", "Vithya", ""], ["Pfahringer", "Bernhard", ""], ["Mayo", "Michael", ""]]}, {"id": "1901.10585", "submitter": "Henry Kvinge", "authors": "Henry Kvinge and Elin Farnell and Jingya Li and Yujia Chen", "title": "Rare geometries: revealing rare categories via dimension-driven\n  statistics", "comments": "9 pages. Section IV substantially expanded with minor improvements to\n  other parts of the paper. Two new co-authors responsible for implementation\n  of the algorithm on real data added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many situations, classes of data points of primary interest also happen to\nbe those that are least numerous. A well-known example is detection of\nfraudulent transactions among the collection of all financial transactions, the\nvast majority of which are legitimate. These types of problems fall under the\nlabel of `rare-category detection.' There are two challenging aspects of these\nproblems. The first is a general lack of labeled examples of the rare class and\nthe second is the potential non-separability of the rare class from the\nmajority (in terms of available features). Statistics related to the geometry\nof the rare class (such as its intrinsic dimension) can be significantly\ndifferent from those for the majority class, reflecting the different dynamics\ndriving variation in the different classes. In this paper we present a new\nsupervised learning algorithm that uses a dimension-driven statistic, called\nthe kappa-profile, to classify whether unlabeled points belong to a rare class.\nOur algorithm requires very few labeled examples and is invariant with respect\nto translation so that it performs equivalently on both separable and\nnon-separable classes.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 22:09:42 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 04:36:34 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kvinge", "Henry", ""], ["Farnell", "Elin", ""], ["Li", "Jingya", ""], ["Chen", "Yujia", ""]]}, {"id": "1901.10593", "submitter": "Yawei Zhao", "authors": "Yawei Zhao, Chen Yu, Peilin Zhao, Hanlin Tang, Shuang Qiu, Ji Liu", "title": "Decentralized Online Learning: Take Benefits from Others' Data without\n  Sharing Your Own to Track Global Trend", "comments": "Second version: revise Assumption 1 (there is a typo in the first\n  version); add experiments (see Figure 2); revise Algorithm 1 in a more clear\n  way", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized Online Learning (online learning in decentralized networks)\nattracts more and more attention, since it is believed that Decentralized\nOnline Learning can help the data providers cooperatively better solve their\nonline problems without sharing their private data to a third party or other\nproviders. Typically, the cooperation is achieved by letting the data providers\nexchange their models between neighbors, e.g., recommendation model. However,\nthe best regret bound for a decentralized online learning algorithm is\n$\\Ocal{n\\sqrt{T}}$, where $n$ is the number of nodes (or users) and $T$ is the\nnumber of iterations. This is clearly insignificant since this bound can be\nachieved \\emph{without} any communication in the networks. This reminds us to\nask a fundamental question: \\emph{Can people really get benefit from the\ndecentralized online learning by exchanging information?} In this paper, we\nstudied when and why the communication can help the decentralized online\nlearning to reduce the regret. Specifically, each loss function is\ncharacterized by two components: the adversarial component and the stochastic\ncomponent. Under this characterization, we show that decentralized online\ngradient (DOG) enjoys a regret bound $\\Ocal{n\\sqrt{T}G + \\sqrt{nT}\\sigma}$,\nwhere $G$ measures the magnitude of the adversarial component in the private\ndata (or equivalently the local loss function) and $\\sigma$ measures the\nrandomness within the private data. This regret suggests that people can get\nbenefits from the randomness in the private data by exchanging private\ninformation. Another important contribution of this paper is to consider the\ndynamic regret -- a more practical regret to track users' interest dynamics.\nEmpirical studies are also conducted to validate our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 22:29:27 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 21:47:01 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 00:37:37 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 19:54:56 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Zhao", "Yawei", ""], ["Yu", "Chen", ""], ["Zhao", "Peilin", ""], ["Tang", "Hanlin", ""], ["Qiu", "Shuang", ""], ["Liu", "Ji", ""]]}, {"id": "1901.10603", "submitter": "Charles Frye", "authors": "Charles G. Frye, Neha S. Wadia, Michael R. DeWeese, and Kristofer E.\n  Bouchard", "title": "Numerically Recovering the Critical Points of a Deep Linear Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerically locating the critical points of non-convex surfaces is a\nlong-standing problem central to many fields. Recently, the loss surfaces of\ndeep neural networks have been explored to gain insight into outstanding\nquestions in optimization, generalization, and network architecture design.\nHowever, the degree to which recently-proposed methods for numerically\nrecovering critical points actually do so has not been thoroughly evaluated. In\nthis paper, we examine this issue in a case for which the ground truth is\nknown: the deep linear autoencoder. We investigate two sub-problems associated\nwith numerical critical point identification: first, because of large parameter\ncounts, it is infeasible to find all of the critical points for contemporary\nneural networks, necessitating sampling approaches whose characteristics are\npoorly understood; second, the numerical tolerance for accurately identifying a\ncritical point is unknown, and conservative tolerances are difficult to\nsatisfy. We first identify connections between recently-proposed methods and\nwell-understood methods in other fields, including chemical physics, economics,\nand algebraic geometry. We find that several methods work well at recovering\ncertain information about loss surfaces, but fail to take an unbiased sample of\ncritical points. Furthermore, numerical tolerance must be very strict to ensure\nthat numerically-identified critical points have similar properties to true\nanalytical critical points. We also identify a recently-published Newton method\nfor optimization that outperforms previous methods as a critical point-finding\nalgorithm. We expect our results will guide future attempts to numerically\nstudy critical points in large nonlinear neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 23:05:54 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Frye", "Charles G.", ""], ["Wadia", "Neha S.", ""], ["DeWeese", "Michael R.", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "1901.10604", "submitter": "Chen-Yu Wei", "authors": "S\\'ebastien Bubeck, Yuanzhi Li, Haipeng Luo, Chen-Yu Wei", "title": "Improved Path-length Regret Bounds for Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adaptive regret bounds in terms of the variation of the losses (the\nso-called path-length bounds) for both multi-armed bandit and more generally\nlinear bandit. We first show that the seemingly suboptimal path-length bound of\n(Wei and Luo, 2018) is in fact not improvable for adaptive adversary. Despite\nthis negative result, we then develop two new algorithms, one that strictly\nimproves over (Wei and Luo, 2018) with a smaller path-length measure, and the\nother which improves over (Wei and Luo, 2018) for oblivious adversary when the\npath-length is large. Our algorithms are based on the well-studied optimistic\nmirror descent framework, but importantly with several novel techniques,\nincluding new optimistic predictions, a slight bias towards recently selected\narms, and the use of a hybrid regularizer similar to that of (Bubeck et al.,\n2018).\n  Furthermore, we extend our results to linear bandit by showing a reduction to\nobtaining dynamic regret for a full-information problem, followed by a further\nreduction to convex body chasing. We propose a simple greedy chasing algorithm\nfor squared 2-norm, leading to new dynamic regret results and as a consequence\nthe first path-length regret for general linear bandit as well.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 23:09:37 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 05:07:15 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Li", "Yuanzhi", ""], ["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""]]}, {"id": "1901.10610", "submitter": "Myung Seok Shim", "authors": "Myung Seok Shim, Chenye Zhao, Yang Li, Xuchong Zhang, Wenrui Zhang,\n  Peng Li", "title": "Robust Deep Multi-Modal Sensor Fusion using Fusion Weight Regularization\n  and Target Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor fusion has wide applications in many domains including health care and\nautonomous systems. While the advent of deep learning has enabled promising\nmulti-modal fusion of high-level features and end-to-end sensor fusion\nsolutions, existing deep learning based sensor fusion techniques including deep\ngating architectures are not always resilient, leading to the issue of fusion\nweight inconsistency. We propose deep multi-modal sensor fusion architectures\nwith enhanced robustness particularly under the presence of sensor failures. At\nthe core of our gating architectures are fusion weight regularization and\nfusion target learning operating on auxiliary unimodal sensing networks\nappended to the main fusion model. The proposed regularized gating\narchitectures outperform the existing deep learning architectures with and\nwithout gating under both clean and corrupted sensory inputs resulted from\nsensor failures. The demonstrated improvements are particularly pronounced when\none or more multiple sensory modalities are corrupted.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 23:32:20 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 05:06:28 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 02:38:26 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Shim", "Myung Seok", ""], ["Zhao", "Chenye", ""], ["Li", "Yang", ""], ["Zhang", "Xuchong", ""], ["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "1901.10621", "submitter": "Amin Rasekh", "authors": "Sarin Chandy, Amin Rasekh", "title": "Enhanced Variational Inference with Dyadic Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder is a powerful deep generative model with variational\ninference. The practice of modeling latent variables in the VAE's original\nformulation as normal distributions with a diagonal covariance matrix limits\nthe flexibility to match the true posterior distribution. We propose a new\ntransformation, dyadic transformation (DT), that can model a multivariate\nnormal distribution. DT is a single-stage transformation with low computational\nrequirements. We demonstrate empirically on MNIST dataset that DT enhances the\nposterior flexibility and attains competitive results compared to other VAE\nenhancements.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 00:10:51 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 15:24:29 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Chandy", "Sarin", ""], ["Rasekh", "Amin", ""]]}, {"id": "1901.10622", "submitter": "Muhammed Omer Sayin", "authors": "Muhammed O. Sayin, Chung-Wei Lin, Eunsuk Kang, Shinichi Shiraishi,\n  Tamer Basar", "title": "Reliable Smart Road Signs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a game theoretical adversarial intervention\ndetection mechanism for reliable smart road signs. A future trend in\nintelligent transportation systems is ``smart road signs\" that incorporate\nsmart codes (e.g., visible at infrared) on their surface to provide more\ndetailed information to smart vehicles. Such smart codes make road sign\nclassification problem aligned with communication settings more than\nconventional classification. This enables us to integrate well-established\nresults in communication theory, e.g., error-correction methods, into road sign\nclassification problem. Recently, vision-based road sign classification\nalgorithms have been shown to be vulnerable against (even) small scale\nadversarial interventions that are imperceptible for humans. On the other hand,\nsmart codes constructed via error-correction methods can lead to robustness\nagainst small scale intelligent or random perturbations on them. In the\nrecognition of smart road signs, however, humans are out of the loop since they\ncannot see or interpret them. Therefore, there is no equivalent concept of\nimperceptible perturbations in order to achieve a comparable performance with\nhumans. Robustness against small scale perturbations would not be sufficient\nsince the attacker can attack more aggressively without such a constraint.\nUnder a game theoretical solution concept, we seek to ensure certain measure of\nguarantees against even the worst case (intelligent) attackers that can perturb\nthe signal even at large scale. We provide a randomized detection strategy\nbased on the distance between the decoder output and the received input, i.e.,\nerror rate. Finally, we examine the performance of the proposed scheme over\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 00:19:24 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 04:56:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sayin", "Muhammed O.", ""], ["Lin", "Chung-Wei", ""], ["Kang", "Eunsuk", ""], ["Shiraishi", "Shinichi", ""], ["Basar", "Tamer", ""]]}, {"id": "1901.10632", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov, Leonid E. Fedichkin, Alexander Alodjants", "title": "Predicting quantum advantage by quantum walk with convolutional neural\n  networks", "comments": "10 pages, 5 figures", "journal-ref": "New J. Phys. 21, 125002 (2019)", "doi": "10.1088/1367-2630/ab5c5e", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum walks are at the heart of modern quantum technologies. They allow to\ndeal with quantum transport phenomena and are an advanced tool for constructing\nnovel quantum algorithms. Quantum walks on graphs are fundamentally different\nfrom classical random walks analogs, in particular, they walk faster than\nclassical ones on certain graphs, enabling in these cases quantum algorithmic\napplications and quantum-enhanced energy transfer. However, little is known\nabout the possible advantages on arbitrary graphs not having explicit\nsymmetries. For these graphs one would need to perform simulations of classical\nand quantum walk dynamics to check if the speedup occurs, which could take a\nlong computational time. Here we present a new approach for the solution of the\nquantum speedup problem, which is based on a machine learning algorithm that\npredicts the quantum advantage by just looking at a graph. The convolutional\nneural network, which we designed specifically to learn from graphs, observes\nsimulated examples and learns complex features of graphs that lead to a quantum\nadvantage, allowing to identify graphs that exhibit quantum advantage without\nperforming any quantum walk or random walk simulations. The performance of our\napproach is evaluated for line and random graphs, where classification was\nalways better than random guess even for the most challenging cases. Our\nfindings pave the way to an automated elaboration of novel large-scale quantum\ncircuits utilizing quantum walk based algorithms, and to simulating\nhigh-efficiency energy transfer in biophotonics and material science.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 01:25:36 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 15:07:29 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Fedichkin", "Leonid E.", ""], ["Alodjants", "Alexander", ""]]}, {"id": "1901.10634", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang and Nidhi Hegde", "title": "Privacy-preserving Q-Learning with Functional Noise in Continuous State\n  Spaces", "comments": "Advances in Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider differentially private algorithms for reinforcement learning in\ncontinuous spaces, such that neighboring reward functions are\nindistinguishable. This protects the reward information from being exploited by\nmethods such as inverse reinforcement learning. Existing studies that guarantee\ndifferential privacy are not extendable to infinite state spaces, as the noise\nlevel to ensure privacy will scale accordingly to infinity. Our aim is to\nprotect the value function approximator, without regard to the number of states\nqueried to the function. It is achieved by adding functional noise to the value\nfunction iteratively in the training. We show rigorous privacy guarantees by a\nseries of analyses on the kernel of the noise space, the probabilistic bound of\nsuch noise samples, and the composition over the iterations. We gain insight\ninto the utility analysis by proving the algorithm's approximate optimality\nwhen the state space is discrete. Experiments corroborate our theoretical\nfindings and show improvement over existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 01:31:03 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:36:18 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 08:31:36 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Wang", "Baoxiang", ""], ["Hegde", "Nidhi", ""]]}, {"id": "1901.10647", "submitter": "Jonathan Scarlett", "authors": "Lan V. Truong and Jonathan Scarlett", "title": "Support Recovery in the Phase Retrieval Model: Information-Theoretic\n  Fundamental Limits", "comments": "Accepted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support recovery problem consists of determining a sparse subset of\nvariables that is relevant in generating a set of observations. In this paper,\nwe study the support recovery problem in the phase retrieval model consisting\nof noisy phaseless measurements, which arises in a diverse range of settings\nsuch as optical detection, X-ray crystallography, electron microscopy, and\ncoherent diffractive imaging. Our focus is on information-theoretic fundamental\nlimits under an approximate recovery criterion, considering both discrete and\nGaussian models for the sparse non-zero entries, along with Gaussian\nmeasurement matrices. In both cases, our bounds provide sharp thresholds with\nnear-matching constant factors in several scaling regimes on the sparsity and\nsignal-to-noise ratio. As a key step towards obtaining these results, we\ndevelop new concentration bounds for the conditional information content of\nlog-concave random variables, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 02:24:42 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 03:51:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Truong", "Lan V.", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "1901.10651", "submitter": "Bamdad Hosseini Dr.", "authors": "Nicolas Garcia Trillos, Franca Hoffmann, Bamdad Hosseini", "title": "Geometric structure of graph Laplacian embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.SP math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the spectral clustering procedure for identifying coarse structure\nin a data set $x_1, \\dots, x_n$, and in particular study the geometry of graph\nLaplacian embeddings which form the basis for spectral clustering algorithms.\nMore precisely, we assume that the data is sampled from a mixture model\nsupported on a manifold $\\mathcal{M}$ embedded in $\\mathbb{R}^d$, and pick a\nconnectivity length-scale $\\varepsilon>0$ to construct a kernelized graph\nLaplacian. We introduce a notion of a well-separated mixture model which only\ndepends on the model itself, and prove that when the model is well separated,\nwith high probability the embedded data set concentrates on cones that are\ncentered around orthogonal vectors. Our results are meaningful in the regime\nwhere $\\varepsilon = \\varepsilon(n)$ is allowed to decay to zero at a slow\nenough rate as the number of data points grows. This rate depends on the\nintrinsic dimension of the manifold on which the data is supported.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 02:46:02 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Hoffmann", "Franca", ""], ["Hosseini", "Bamdad", ""]]}, {"id": "1901.10653", "submitter": "Francisco Mena", "authors": "F. A. Mena (Universidad T\\'ecnica Federico Santa Mar\\'ia, Chile), R.\n  \\~Nanculef (Universidad T\\'ecnica Federico Santa Mar\\'ia, Chile)", "title": "Evaluating Bregman Divergences for Probability Learning from Crowd", "comments": "A report of results, 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crowdsourcing scenarios are a good example of having a probability\ndistribution over some categories showing what the people in a global\nperspective thinks. Learn a predictive model of this probability distribution\ncan be of much more valuable that learn only a discriminative model that gives\nthe most likely category of the data. Here we present differents models that\nadapts having probability distribution as target to train a machine learning\nmodel. We focus on the Bregman divergences framework to used as objective\nfunction to minimize. The results show that special care must be taken when\nbuild a objective function and consider a equal optimization on neural network\nin Keras framework.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 02:53:39 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Mena", "F. A.", "", "Universidad T\u00e9cnica Federico Santa Mar\u00eda, Chile"], ["\u00d1anculef", "R.", "", "Universidad T\u00e9cnica Federico Santa Mar\u00eda, Chile"]]}, {"id": "1901.10654", "submitter": "Jongyeong Lee", "authors": "Jongyeong Lee, Nontawat Charoenphakdee, Seiichi Kuroki, Masashi\n  Sugiyama", "title": "Domain Discrepancy Measure for Complex Models in Unsupervised Domain\n  Adaptation", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriately evaluating the discrepancy between domains is essential for the\nsuccess of unsupervised domain adaptation. In this paper, we first point out\nthat existing discrepancy measures are less informative when complex models\nsuch as deep neural networks are used, in addition to the facts that they can\nbe computationally highly demanding and their range of applications is limited\nonly to binary classification. We then propose a novel domain discrepancy\nmeasure, called the paired hypotheses discrepancy (PHD), to overcome these\nshortcomings. PHD is computationally efficient and applicable to multi-class\nclassification. Through generalization error bound analysis, we theoretically\nshow that PHD is effective even for complex models. Finally, we demonstrate the\npractical usefulness of PHD through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 02:56:51 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 09:03:49 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 02:57:05 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Lee", "Jongyeong", ""], ["Charoenphakdee", "Nontawat", ""], ["Kuroki", "Seiichi", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.10655", "submitter": "Nontawat Charoenphakdee", "authors": "Chenri Ni, Nontawat Charoenphakdee, Junya Honda, Masashi Sugiyama", "title": "On the Calibration of Multiclass Classification with Rejection", "comments": "NeurIPS2019 camera-ready, 31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of multiclass classification with rejection, where\na classifier can choose not to make a prediction to avoid critical\nmisclassification. First, we consider an approach based on simultaneous\ntraining of a classifier and a rejector, which achieves the state-of-the-art\nperformance in the binary case. We analyze this approach for the multiclass\ncase and derive a general condition for calibration to the Bayes-optimal\nsolution, which suggests that calibration is hard to achieve by general loss\nfunctions unlike the binary case. Next, we consider another traditional\napproach based on confidence scores, in which the existing work focuses on a\nspecific class of losses. We propose rejection criteria for more general losses\nfor this approach and guarantee calibration to the Bayes-optimal solution.\nFinally, we conduct experiments to validate the relevance of our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 03:06:06 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 03:08:44 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Ni", "Chenri", ""], ["Charoenphakdee", "Nontawat", ""], ["Honda", "Junya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.10657", "submitter": "Qinghai Zheng", "authors": "Qinghai Zheng, Jihua Zhu, Zhongyu Li, Shanmin Pang, Jun Wang, Yaochen\n  Li", "title": "Feature Concatenation Multi-view Subspace Clustering", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.10.074", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering is a learning paradigm based on multi-view data. Since\nstatistic properties of different views are diverse, even incompatible, few\napproaches implement multi-view clustering based on the concatenated features\nstraightforward. However, feature concatenation is a natural way to combine\nmulti-view data. To this end, this paper proposes a novel multi-view subspace\nclustering approach dubbed Feature Concatenation Multi-view Subspace Clustering\n(FCMSC), which boosts the clustering performance by exploring the consensus\ninformation of multi-view data. Specifically, multi-view data are concatenated\ninto a joint representation firstly, then, $l_{2,1}$-norm is integrated into\nthe objective function to deal with the sample-specific and cluster-specific\ncorruptions of multiple views. Moreover, a graph regularized FCMSC is also\nproposed in this paper to explore both the consensus information and\ncomplementary information of multi-view data for clustering. It is noteworthy\nthat the obtained coefficient matrix is not derived by simply applying the\nLow-Rank Representation (LRR) to concatenated features directly. Finally, an\neffective algorithm based on the Augmented Lagrangian Multiplier (ALM) is\ndesigned to optimize the objective functions. Comprehensive experiments on six\nreal-world datasets illustrate the superiority of the proposed methods over\nseveral state-of-the-art approaches for multi-view clustering.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 03:44:22 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 17:33:17 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 04:27:45 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 13:57:32 GMT"}, {"version": "v5", "created": "Thu, 6 Jun 2019 01:24:00 GMT"}, {"version": "v6", "created": "Wed, 24 Mar 2021 12:58:10 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Zheng", "Qinghai", ""], ["Zhu", "Jihua", ""], ["Li", "Zhongyu", ""], ["Pang", "Shanmin", ""], ["Wang", "Jun", ""], ["Li", "Yaochen", ""]]}, {"id": "1901.10668", "submitter": "Shun Liao", "authors": "Shun Liao, Ting Chen, Tian Lin, Denny Zhou, Chong Wang", "title": "Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computations for the softmax function are significantly expensive when the\nnumber of output classes is large. In this paper, we present a novel softmax\ninference speedup method, Doubly Sparse Softmax (DS-Softmax), that leverages\nsparse mixture of sparse experts to efficiently retrieve top-k classes.\nDifferent from most existing methods that require and approximate a fixed\nsoftmax, our method is learning-based and can adapt softmax weights for a\nbetter inference speedup. In particular, our method learns a two-level\nhierarchy which divides entire output class space into several partially\noverlapping experts. Each expert is sparse and only contains a subset of output\nclasses. To find top-k classes, a sparse mixture enables us to find the most\nprobable expert quickly, and the sparse expert enables us to search within a\nsmall-scale softmax. We empirically conduct evaluation on several real-world\ntasks, including neural machine translation, language modeling and image\nclassification, and demonstrate that significant computation reductions can be\nachieved at no performance loss.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 04:22:03 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 17:17:41 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Liao", "Shun", ""], ["Chen", "Ting", ""], ["Lin", "Tian", ""], ["Zhou", "Denny", ""], ["Wang", "Chong", ""]]}, {"id": "1901.10681", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, S\\'ebastien Lef\\`evre, Nicolas Courty, R\\'emi\n  Emonet, Marco K\\\"orner, Romain Tavenard", "title": "End-to-end Learning for Early Classification of Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of time series is a topical issue in machine learning. While\naccuracy stands for the most important evaluation criterion, some applications\nrequire decisions to be made as early as possible. Optimization should then\ntarget a compromise between earliness, i.e., a capacity of providing a decision\nearly in the sequence, and accuracy. In this work, we propose a generic,\nend-to-end trainable framework for early classification of time series. This\nframework embeds a learnable decision mechanism that can be plugged into a wide\nrange of already existing models. We present results obtained with deep neural\nnetworks on a diverse set of time series classification problems. Our approach\ncompares well to state-of-the-art competitors while being easily adaptable by\nany existing neural network topology that evaluates a hidden state at each time\nstep.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 05:51:41 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["Lef\u00e8vre", "S\u00e9bastien", ""], ["Courty", "Nicolas", ""], ["Emonet", "R\u00e9mi", ""], ["K\u00f6rner", "Marco", ""], ["Tavenard", "Romain", ""]]}, {"id": "1901.10691", "submitter": "Casey Chu", "authors": "Casey Chu, Jose Blanchet, Peter Glynn", "title": "Probability Functional Descent: A Unifying Perspective on GANs,\n  Variational Inference, and Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a unifying view of a wide range of problems of interest\nin machine learning by framing them as the minimization of functionals defined\non the space of probability measures. In particular, we show that generative\nadversarial networks, variational inference, and actor-critic methods in\nreinforcement learning can all be seen through the lens of our framework. We\nthen discuss a generic optimization algorithm for our formulation, called\nprobability functional descent (PFD), and show how this algorithm recovers\nexisting methods developed independently in the settings mentioned earlier.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 06:59:11 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 01:43:26 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Chu", "Casey", ""], ["Blanchet", "Jose", ""], ["Glynn", "Peter", ""]]}, {"id": "1901.10738", "submitter": "Jean-Yves Franceschi", "authors": "Jean-Yves Franceschi (MLIA), Aymeric Dieuleveut (CMAP), Martin Jaggi", "title": "Unsupervised Scalable Representation Learning for Multivariate Time\n  Series", "comments": null, "journal-ref": "Thirty-third Conference on Neural Information Processing Systems,\n  Neural Information Processing Systems Foundation, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series constitute a challenging data type for machine learning\nalgorithms, due to their highly variable lengths and sparse labeling in\npractice. In this paper, we tackle this challenge by proposing an unsupervised\nmethod to learn universal embeddings of time series. Unlike previous works, it\nis scalable with respect to their length and we demonstrate the quality,\ntransferability and practicability of the learned representations with thorough\nexperiments and comparisons. To this end, we combine an encoder based on causal\ndilated convolutions with a novel triplet loss employing time-based negative\nsampling, obtaining general-purpose representations for variable length and\nmultivariate time series.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:07:45 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 14:45:05 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 13:38:25 GMT"}, {"version": "v4", "created": "Fri, 3 Jan 2020 14:22:57 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Franceschi", "Jean-Yves", "", "MLIA"], ["Dieuleveut", "Aymeric", "", "CMAP"], ["Jaggi", "Martin", ""]]}, {"id": "1901.10757", "submitter": "Nicolas Gillis", "authors": "Nicolas Gillis, Le Thi Khanh Hien, Valentin Leplat, Vincent Y. F. Tan", "title": "Distributionally Robust and Multi-Objective Nonnegative Matrix\n  Factorization", "comments": "Accepted in IEEE Trans. on Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is a linear dimensionality reduction\ntechnique for analyzing nonnegative data. A key aspect of NMF is the choice of\nthe objective function that depends on the noise model (or statistics of the\nnoise) assumed on the data. In many applications, the noise model is unknown\nand difficult to estimate. In this paper, we define a multi-objective NMF\n(MO-NMF) problem, where several objectives are combined within the same NMF\nmodel. We propose to use Lagrange duality to judiciously optimize for a set of\nweights to be used within the framework of the weighted-sum approach, that is,\nwe minimize a single objective function which is a weighted sum of the all\nobjective functions. We design a simple algorithm based on multiplicative\nupdates to minimize this weighted sum. We show how this can be used to find\ndistributionally robust NMF (DR-NMF) solutions, that is, solutions that\nminimize the largest error among all objectives, using a dual approach solved\nvia a heuristic inspired from the Frank-Wolfe algorithm. We illustrate the\neffectiveness of this approach on synthetic, document and audio data sets. The\nresults show that DR-NMF is robust to our incognizance of the noise model of\nthe NMF problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:41:21 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 08:21:00 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 07:51:30 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Gillis", "Nicolas", ""], ["Hien", "Le Thi Khanh", ""], ["Leplat", "Valentin", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1901.10758", "submitter": "Xiaodong Luo", "authors": "Xiaodong Luo", "title": "Ensemble-based kernel learning for a class of data assimilation problems\n  with imperfect forward simulators", "comments": null, "journal-ref": "PLoS ONE 14(7): e0219247, 2019", "doi": "10.1371/journal.pone.0219247", "report-no": null, "categories": "math.OC physics.data-an physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulator imperfection, often known as model error, is ubiquitous in\npractical data assimilation problems. Despite the enormous efforts dedicated to\naddressing this problem, properly handling simulator imperfection in data\nassimilation remains to be a challenging task. In this work, we propose an\napproach to dealing with simulator imperfection from a point of view of\nfunctional approximation that can be implemented through a certain machine\nlearning method, such as kernel-based learning adopted in the current work. To\nthis end, we start from considering a class of supervised learning problems,\nand then identify similarities between supervised learning and variational data\nassimilation. These similarities found the basis for us to develop an\nensemble-based learning framework to tackle supervised learning problems, while\nachieving various advantages of ensemble-based methods over the variational\nones. After establishing the ensemble-based learning framework, we proceed to\ninvestigate the integration of ensemble-based learning into an ensemble-based\ndata assimilation framework to handle simulator imperfection. In the course of\nour investigations, we also develop a strategy to tackle the issue of\nmulti-modality in supervised-learning problems, and transfer this strategy to\ndata assimilation problems to help improve assimilation performance. For\ndemonstration, we apply the ensemble-based learning framework and the\nintegrated, ensemble-based data assimilation framework to a supervised learning\nproblem and a data assimilation problem with an imperfect forward simulator,\nrespectively. The experiment results indicate that both frameworks achieve good\nperformance in relevant case studies, and that functional approximation through\nmachine learning may serve as a viable way to account for simulator\nimperfection in data assimilation problems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:42:39 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Luo", "Xiaodong", ""]]}, {"id": "1901.10760", "submitter": "Dimche Kostadinov", "authors": "Dimche Kostadinov, Behrooz Razeghi, Taras Holotyak, Slava\n  Voloshynovskiy", "title": "Clustering with Jointly Learned Nonlinear Transforms Over Discriminating\n  Min-Max Similarity/Dissimilarity Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel clustering concept that is based on jointly\nlearned nonlinear transforms (NTs) with priors on the information loss and the\ndiscrimination. We introduce a clustering principle that is based on evaluation\nof a parametric min-max measure for the discriminative prior. The decomposition\nof the prior measure allows to break down the assignment into two steps. In the\nfirst step, we apply NTs to a data point in order to produce candidate NT\nrepresentations. In the second step, we preform the actual assignment by\nevaluating the parametric measure over the candidate NT representations.\nNumerical experiments on image clustering task validate the potential of the\nproposed approach. The evaluation shows advantages in comparison to the\nstate-of-the-art clustering methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:47:40 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Razeghi", "Behrooz", ""], ["Holotyak", "Taras", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1901.10789", "submitter": "Kasper Green Larsen", "authors": "Allan Gr{\\o}nlund, Kasper Green Larsen, Alexander Mathiasen", "title": "Optimal Minimal Margin Maximization with Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting algorithms produce a classifier by iteratively combining base\nhypotheses. It has been observed experimentally that the generalization error\nkeeps improving even after achieving zero training error. One popular\nexplanation attributes this to improvements in margins. A common goal in a long\nline of research, is to maximize the smallest margin using as few base\nhypotheses as possible, culminating with the AdaBoostV algorithm by (R{\\\"a}tsch\nand Warmuth [JMLR'04]). The AdaBoostV algorithm was later conjectured to yield\nan optimal trade-off between number of hypotheses trained and the minimal\nmargin over all training points (Nie et al. [JMLR'13]). Our main contribution\nis a new algorithm refuting this conjecture. Furthermore, we prove a lower\nbound which implies that our new algorithm is optimal.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 12:52:45 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Larsen", "Kasper Green", ""], ["Mathiasen", "Alexander", ""]]}, {"id": "1901.10799", "submitter": "Sebastian Mathias Keller", "authors": "Sebastian Mathias Keller, Maxim Samarin, Mario Wieser, Volker Roth", "title": "Deep Archetypal Analysis", "comments": "Published at the German Conference on Pattern Recognition 2019 (GCPR)", "journal-ref": "41th German Conference on Pattern Recognition, GCPR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Deep Archetypal Analysis\" generates latent representations of\nhigh-dimensional datasets in terms of fractions of intuitively understandable\nbasic entities called archetypes. The proposed method is an extension of linear\n\"Archetypal Analysis\" (AA), an unsupervised method to represent multivariate\ndata points as sparse convex combinations of extremal elements of the dataset.\nUnlike the original formulation of AA, \"Deep AA\" can also handle side\ninformation and provides the ability for data-driven representation learning\nwhich reduces the dependence on expert knowledge. Our method is motivated by\nstudies of evolutionary trade-offs in biology where archetypes are species\nhighly adapted to a single task. Along these lines, we demonstrate that \"Deep\nAA\" also lends itself to the supervised exploration of chemical space, marking\na distinct starting point for de novo molecular design. In the unsupervised\nsetting we show how \"Deep AA\" is used on CelebA to identify archetypal faces.\nThese can then be superimposed in order to generate new faces which inherit\ndominant traits of the archetypes they are based on.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 13:04:53 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 16:37:27 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Keller", "Sebastian Mathias", ""], ["Samarin", "Maxim", ""], ["Wieser", "Mario", ""], ["Roth", "Volker", ""]]}, {"id": "1901.10801", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov, Oleksii Hrinchuk, Ivan Oseledets", "title": "Generalized Tensor Models for Recurrent Neural Networks", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are very successful at solving challenging\nproblems with sequential data. However, this observed efficiency is not yet\nentirely explained by theory. It is known that a certain class of\nmultiplicative RNNs enjoys the property of depth efficiency --- a shallow\nnetwork of exponentially large width is necessary to realize the same score\nfunction as computed by such an RNN. Such networks, however, are not very often\napplied to real life tasks. In this work, we attempt to reduce the gap between\ntheory and practice by extending the theoretical analysis to RNNs which employ\nvarious nonlinearities, such as Rectified Linear Unit (ReLU), and show that\nthey also benefit from properties of universality and depth efficiency. Our\ntheoretical results are verified by a series of extensive computational\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 13:07:40 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Hrinchuk", "Oleksii", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1901.10821", "submitter": "Alireza Nejadettehad", "authors": "Alireza Nejadettehad, Hamid Mahini, Behnam Bahrak", "title": "Short-term Demand Forecasting for Online Car-hailing Services using\n  Recurrent Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1706.06279,\n  arXiv:1804.04176 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term traffic flow prediction is one of the crucial issues in\nintelligent transportation system, which is an important part of smart cities.\nAccurate predictions can enable both the drivers and the passengers to make\nbetter decisions about their travel route, departure time and travel origin\nselection, which can be helpful in traffic management. Multiple models and\nalgorithms based on time series prediction and machine learning were applied to\nthis issue and achieved acceptable results. Recently, the availability of\nsufficient data and computational power, motivates us to improve the prediction\naccuracy via deep-learning approaches. Recurrent neural networks have become\none of the most popular methods for time series forecasting, however, due to\nthe variety of these networks, the question that which type is the most\nappropriate one for this task remains unsolved. In this paper, we use three\nkinds of recurrent neural networks including simple RNN units, GRU and LSTM\nneural network to predict short-term traffic flow. The dataset from TAP30\nCorporation is used for building the models and comparing RNNs with several\nwell-known models, such as DEMA, LASSO and XGBoost. The results show that all\nthree types of RNNs outperform the others, however, more simple RNNs such as\nsimple recurrent units and GRU perform work better than LSTM in terms of\naccuracy and training time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 12:59:00 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Nejadettehad", "Alireza", ""], ["Mahini", "Hamid", ""], ["Bahrak", "Behnam", ""]]}, {"id": "1901.10824", "submitter": "Babajide Ayinde", "authors": "Babajide O. Ayinde and Keishin Nishihama and Jacek M. Zurada", "title": "Diversity Regularized Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two key players in Generative Adversarial Networks (GANs), the\ndiscriminator and generator, are usually parameterized as deep neural networks\n(DNNs). On many generative tasks, GANs achieve state-of-the-art performance but\nare often unstable to train and sometimes miss modes. A typical failure mode is\nthe collapse of the generator to a single parameter configuration where its\noutputs are identical. When this collapse occurs, the gradient of the\ndiscriminator may point in similar directions for many similar points. We\nhypothesize that some of these shortcomings are in part due to primitive and\nredundant features extracted by discriminator and this can easily make the\ntraining stuck. We present a novel approach for regularizing adversarial models\nby enforcing diverse feature learning. In order to do this, both generator and\ndiscriminator are regularized by penalizing both negatively and positively\ncorrelated features according to their differentiation and based on their\nrelative cosine distances. In addition to the gradient information from the\nadversarial loss made available by the discriminator, diversity regularization\nalso ensures that a more stable gradient is provided to update both the\ngenerator and discriminator. Results indicate our regularizer enforces diverse\nfeatures, stabilizes training, and improves image synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 13:44:08 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Ayinde", "Babajide O.", ""], ["Nishihama", "Keishin", ""], ["Zurada", "Jacek M.", ""]]}, {"id": "1901.10826", "submitter": "David Mac\\^edo", "authors": "Jo\\~ao Ant\\^onio Chagas Nunes, David Mac\\^edo, Cleber Zanchettin", "title": "Additive Margin SincNet for Speaker Recognition", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8852112", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker Recognition is a challenging task with essential applications such as\nauthentication, automation, and security. The SincNet is a new deep learning\nbased model which has produced promising results to tackle the mentioned task.\nTo train deep learning systems, the loss function is essential to the network\nperformance. The Softmax loss function is a widely used function in deep\nlearning methods, but it is not the best choice for all kind of problems. For\ndistance-based problems, one new Softmax based loss function called Additive\nMargin Softmax (AM-Softmax) is proving to be a better choice than the\ntraditional Softmax. The AM-Softmax introduces a margin of separation between\nthe classes that forces the samples from the same class to be closer to each\nother and also maximizes the distance between classes. In this paper, we\npropose a new approach for speaker recognition systems called AM-SincNet, which\nis based on the SincNet but uses an improved AM-Softmax layer. The proposed\nmethod is evaluated in the TIMIT dataset and obtained an improvement of\napproximately 40% in the Frame Error Rate compared to SincNet.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 16:16:34 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nunes", "Jo\u00e3o Ant\u00f4nio Chagas", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.10837", "submitter": "Ziyuan Zhong", "authors": "Alexandre Louis Lamy, Ziyuan Zhong, Aditya Krishna Menon, Nakul Verma", "title": "Noise-tolerant fair classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware learning involves designing algorithms that do not\ndiscriminate with respect to some sensitive feature (e.g., race or gender).\nExisting work on the problem operates under the assumption that the sensitive\nfeature available in one's training sample is perfectly reliable. This\nassumption may be violated in many real-world cases: for example, respondents\nto a survey may choose to conceal or obfuscate their group identity out of fear\nof potential discrimination. This poses the question of whether one can still\nlearn fair classifiers given noisy sensitive features. In this paper, we answer\nthe question in the affirmative: we show that if one measures fairness using\nthe mean-difference score, and sensitive features are subject to noise from the\nmutually contaminated learning model, then owing to a simple identity we only\nneed to change the desired fairness-tolerance. The requisite tolerance can be\nestimated by leveraging existing noise-rate estimators from the label noise\nliterature. We finally show that our procedure is empirically effective on two\ncase-studies involving sensitive feature censoring.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 14:11:05 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 18:08:36 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 07:07:43 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 14:44:05 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lamy", "Alexandre Louis", ""], ["Zhong", "Ziyuan", ""], ["Menon", "Aditya Krishna", ""], ["Verma", "Nakul", ""]]}, {"id": "1901.10855", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Maria Luisa Lo Trovato, Fabio Salvatore Leonardi,\n  Giuseppe Leotta, Fabrizio Ruffini and Ciro Lanzetta", "title": "Predictive Maintenance in Photovoltaic Plants with a Big Data Approach", "comments": "Preprint of the 33rd EUPVSEC Proceeding, 25-29 September 2017,\n  Amsterdam. Plenary Presentation", "journal-ref": "33rd European Photovoltaic Solar Energy Conference and Exhibition\n  (EUPVSEC), pages 1895-1900 (2017)", "doi": "10.4229/EUPVSEC20172017-6DP.2.4", "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel and flexible solution for fault prediction based\non data collected from SCADA system. Fault prediction is offered at two\ndifferent levels based on a data-driven approach: (a) generic fault/status\nprediction and (b) specific fault class prediction, implemented by means of two\ndifferent machine learning based modules built on an unsupervised clustering\nalgorithm and a Pattern Recognition Neural Network, respectively. Model has\nbeen assessed on a park of six photovoltaic (PV) plants up to 10 MW and on more\nthan one hundred inverter modules of three different technology brands. The\nresults indicate that the proposed method is effective in (a) predicting\nincipient generic faults up to 7 days in advance with sensitivity up to 95% and\n(b) anticipating damage of specific fault classes with times ranging from few\nhours up to 7 days. The model is easily deployable for on-line monitoring of\nanomalies on new PV plants and technologies, requiring only the availability of\nhistorical SCADA and fault data, fault taxonomy and inverter electrical\ndatasheet. Keywords: Data Mining, Fault Prediction, Inverter Module, Key\nPerformance Indicator, Lost Production\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 16:06:22 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Betti", "Alessandro", ""], ["Trovato", "Maria Luisa Lo", ""], ["Leonardi", "Fabio Salvatore", ""], ["Leotta", "Giuseppe", ""], ["Ruffini", "Fabrizio", ""], ["Lanzetta", "Ciro", ""]]}, {"id": "1901.10860", "submitter": "Karlson Pfannschmidt", "authors": "Karlson Pfannschmidt, Pritha Gupta, Eyke H\\\"ullermeier", "title": "Learning Choice Functions: Concepts and Architectures", "comments": "arXiv admin note: text overlap with arXiv:1803.05796", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning choice functions, which play an important\nrole in various domains of application, most notably in the field of economics.\nFormally, a choice function is a mapping from sets to sets: Given a set of\nchoice alternatives as input, a choice function identifies a subset of most\npreferred elements. Learning choice functions from suitable training data comes\nwith a number of challenges. For example, the sets provided as input and the\nsubsets produced as output can be of any size. Moreover, since the order in\nwhich alternatives are presented is irrelevant, a choice function should be\nsymmetric. Perhaps most importantly, choice functions are naturally\ncontext-dependent, in the sense that the preference in favor of an alternative\nmay depend on what other options are available. We formalize the problem of\nlearning choice functions and present two general approaches based on two\nrepresentations of context-dependent utility functions. Both approaches are\ninstantiated by means of appropriate neural network architectures, and their\nperformance is demonstrated on suitable benchmark tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 12:59:00 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 08:20:39 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 16:37:24 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Pfannschmidt", "Karlson", ""], ["Gupta", "Pritha", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1901.10861", "submitter": "Itay Safran", "authors": "Adi Shamir, Itay Safran, Eyal Ronen, Orr Dunkelman", "title": "A Simple Explanation for the Existence of Adversarial Examples with\n  Small Hamming Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of adversarial examples in which an imperceptible change in the\ninput can fool well trained neural networks was experimentally discovered by\nSzegedy et al in 2013, who called them \"Intriguing properties of neural\nnetworks\". Since then, this topic had become one of the hottest research areas\nwithin machine learning, but the ease with which we can switch between any two\ndecisions in targeted attacks is still far from being understood, and in\nparticular it is not clear which parameters determine the number of input\ncoordinates we have to change in order to mislead the network. In this paper we\ndevelop a simple mathematical framework which enables us to think about this\nbaffling phenomenon from a fresh perspective, turning it into a natural\nconsequence of the geometry of $\\mathbb{R}^n$ with the $L_0$ (Hamming) metric,\nwhich can be quantitatively analyzed. In particular, we explain why we should\nexpect to find targeted adversarial examples with Hamming distance of roughly\n$m$ in arbitrarily deep neural networks which are designed to distinguish\nbetween $m$ input classes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 14:39:32 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Shamir", "Adi", ""], ["Safran", "Itay", ""], ["Ronen", "Eyal", ""], ["Dunkelman", "Orr", ""]]}, {"id": "1901.10864", "submitter": "Jordan Awan", "authors": "Jordan Awan, Ana Kenney, Matthew Reimherr, Aleksandra Slavkovi\\'c", "title": "Benefits and Pitfalls of the Exponential Mechanism with Applications to\n  Hilbert Spaces and Functional PCA", "comments": "13 pages, 5 images, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential mechanism is a fundamental tool of Differential Privacy (DP)\ndue to its strong privacy guarantees and flexibility. We study its extension to\nsettings with summaries based on infinite dimensional outputs such as with\nfunctional data analysis, shape analysis, and nonparametric statistics. We show\nthat one can design the mechanism with respect to a specific base measure over\nthe output space, such as a Guassian process. We provide a positive result that\nestablishes a Central Limit Theorem for the exponential mechanism quite\nbroadly. We also provide an apparent negative result, showing that the\nmagnitude of the noise introduced for privacy is asymptotically non-negligible\nrelative to the statistical estimation error. We develop an \\ep-DP mechanism\nfor functional principal component analysis, applicable in separable Hilbert\nspaces. We demonstrate its performance via simulations and applications to two\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 14:45:01 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Awan", "Jordan", ""], ["Kenney", "Ana", ""], ["Reimherr", "Matthew", ""], ["Slavkovi\u0107", "Aleksandra", ""]]}, {"id": "1901.10868", "submitter": "Alvaro Sierra-Altamiranda", "authors": "Alvaro Sierra-Altamiranda, Hadi Charkhgard, Iman Dayarian, Ali Eshragh\n  and Sorna Javadi", "title": "Learning to Project in Multi-Objective Binary Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the possibility of improving the performance of\nmulti-objective optimization solution approaches using machine learning\ntechniques. Specifically, we focus on multi-objective binary linear programs\nand employ one of the most effective and recently developed criterion space\nsearch algorithms, the so-called KSA, during our study. This algorithm computes\nall nondominated points of a problem with p objectives by searching on a\nprojected criterion space, i.e., a (p-1)-dimensional criterion apace. We\npresent an effective and fast learning approach to identify on which projected\nspace the KSA should work. We also present several generic features/variables\nthat can be used in machine learning techniques for identifying the best\nprojected space. Finally, we present an effective bi-objective optimization\nbased heuristic for selecting the best subset of the features to overcome the\nissue of overfitting in learning. Through an extensive computational study over\n2000 instances of tri-objective Knapsack and Assignment problems, we\ndemonstrate that an improvement of up to 12% in time can be achieved by the\nproposed learning method compared to a random selection of the projected space.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 14:51:24 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Sierra-Altamiranda", "Alvaro", ""], ["Charkhgard", "Hadi", ""], ["Dayarian", "Iman", ""], ["Eshragh", "Ali", ""], ["Javadi", "Sorna", ""]]}, {"id": "1901.10900", "submitter": "Babajide Ayinde", "authors": "Babajide O. Ayinde and Tamer Inanc and Jacek M. Zurada", "title": "On Correlation of Features Extracted by Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundancy in deep neural network (DNN) models has always been one of their\nmost intriguing and important properties. DNNs have been shown to\noverparameterize, or extract a lot of redundant features. In this work, we\nexplore the impact of size (both width and depth), activation function, and\nweight initialization on the susceptibility of deep neural network models to\nextract redundant features. To estimate the number of redundant features in\neach layer, all the features of a given layer are hierarchically clustered\naccording to their relative cosine distances in feature space and a set\nthreshold. It is shown that both network size and activation function are the\ntwo most important components that foster the tendency of DNNs to extract\nredundant features. The concept is illustrated using deep multilayer perceptron\nand convolutional neural networks on MNIST digits recognition and CIFAR-10\ndataset, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:31:35 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Ayinde", "Babajide O.", ""], ["Inanc", "Tamer", ""], ["Zurada", "Jacek M.", ""]]}, {"id": "1901.10902", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Riashat Islam, Daniel Strouse, Zafarali Ahmed, Matthew\n  Botvinick, Hugo Larochelle, Yoshua Bengio, Sergey Levine", "title": "InfoBot: Transfer and Exploration via the Information Bottleneck", "comments": "Accepted at ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge in reinforcement learning is discovering effective\npolicies for tasks where rewards are sparsely distributed. We postulate that in\nthe absence of useful reward signals, an effective exploration strategy should\nseek out {\\it decision states}. These states lie at critical junctions in the\nstate space from where the agent can transition to new, potentially unexplored\nregions. We propose to learn about decision states from prior experience. By\ntraining a goal-conditioned policy with an information bottleneck, we can\nidentify decision states by examining where the model actually leverages the\ngoal state. We find that this simple mechanism effectively identifies decision\nstates, even in partially observed settings. In effect, the model learns the\nsensory cues that correlate with potential subgoals. In new environments, this\nmodel can then identify novel subgoals for further exploration, guiding the\nagent through a sequence of potential decision states and through new regions\nof the state space.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:33:58 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 06:16:10 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 20:57:35 GMT"}, {"version": "v4", "created": "Thu, 4 Apr 2019 05:55:03 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Goyal", "Anirudh", ""], ["Islam", "Riashat", ""], ["Strouse", "Daniel", ""], ["Ahmed", "Zafarali", ""], ["Botvinick", "Matthew", ""], ["Larochelle", "Hugo", ""], ["Bengio", "Yoshua", ""], ["Levine", "Sergey", ""]]}, {"id": "1901.10912", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Rosemary Ke, S\\'ebastien\n  Lachapelle, Olexa Bilaniuk, Anirudh Goyal and Christopher Pal", "title": "A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to meta-learn causal structures based on how fast a learner adapts\nto new distributions arising from sparse distributional changes, e.g. due to\ninterventions, actions of agents and other sources of non-stationarities. We\nshow that under this assumption, the correct causal structural choices lead to\nfaster adaptation to modified distributions because the changes are\nconcentrated in one or just a few mechanisms when the learned knowledge is\nmodularized appropriately. This leads to sparse expected gradients and a lower\neffective number of degrees of freedom needing to be relearned while adapting\nto the change. It motivates using the speed of adaptation to a modified\ndistribution as a meta-learning objective. We demonstrate how this can be used\nto determine the cause-effect relationship between two observed variables. The\ndistributional changes do not need to correspond to standard interventions\n(clamping a variable), and the learner has no direct knowledge of these\ninterventions. We show that causal structures can be parameterized via\ncontinuous variables and learned end-to-end. We then explore how these ideas\ncould be used to also learn an encoder that would map low-level observed\nvariables to unobserved causal variables leading to faster adaptation\nout-of-distribution, learning a representation space where one can satisfy the\nassumptions of independent mechanisms and of small and sparse changes in these\nmechanisms due to actions and non-stationarities.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:47:12 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 19:58:56 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Bengio", "Yoshua", ""], ["Deleu", "Tristan", ""], ["Rahaman", "Nasim", ""], ["Ke", "Rosemary", ""], ["Lachapelle", "S\u00e9bastien", ""], ["Bilaniuk", "Olexa", ""], ["Goyal", "Anirudh", ""], ["Pal", "Christopher", ""]]}, {"id": "1901.10946", "submitter": "Yukai Liu", "authors": "Yukai Liu, Rose Yu, Stephan Zheng, Eric Zhan, Yisong Yue", "title": "NAOMI: Non-Autoregressive Multiresolution Sequence Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing value imputation is a fundamental problem in spatiotemporal modeling,\nfrom motion tracking to the dynamics of physical systems. Deep autoregressive\nmodels suffer from error propagation which becomes catastrophic for imputing\nlong-range sequences. In this paper, we take a non-autoregressive approach and\npropose a novel deep generative model: Non-AutOregressive Multiresolution\nImputation (NAOMI) to impute long-range sequences given arbitrary missing\npatterns. NAOMI exploits the multiresolution structure of spatiotemporal data\nand decodes recursively from coarse to fine-grained resolutions using a\ndivide-and-conquer strategy. We further enhance our model with adversarial\ntraining. When evaluated extensively on benchmark datasets from systems of both\ndeterministic and stochastic dynamics. NAOMI demonstrates significant\nimprovement in imputation accuracy (reducing average prediction error by 60%\ncompared to autoregressive counterparts) and generalization for long range\nsequences.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:51:57 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 06:10:48 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 07:22:40 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Liu", "Yukai", ""], ["Yu", "Rose", ""], ["Zheng", "Stephan", ""], ["Zhan", "Eric", ""], ["Yue", "Yisong", ""]]}, {"id": "1901.10948", "submitter": "David Noever", "authors": "David Noever", "title": "Classifier Suites for Insider Threat Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Better methods to detect insider threats need new anticipatory analytics to\ncapture risky behavior prior to losing data. In search of the best overall\nclassifier, this work empirically scores 88 machine learning algorithms in 16\nmajor families. We extract risk features from the large CERT dataset, which\nblends real network behavior with individual threat narratives. We discover the\npredictive importance of measuring employee sentiment. Among major classifier\nfamilies tested on CERT, the random forest algorithms offer the best choice,\nwith different implementations scoring over 98% accurate. In contrast to more\nobscure or black-box alternatives, random forests are ensembles of many\ndecision trees and thus offer a deep but human-readable set of detection rules\n(>2000 rules). We address performance rankings by penalizing long execution\ntimes against higher median accuracies using cross-fold validation. We address\nthe relative rarity of threats as a case of low signal-to-noise (< 0.02%\nmalicious to benign activities), and then train on both under-sampled and\nover-sampled data which is statistically balanced to identify nefarious actors.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:55:14 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Noever", "David", ""]]}, {"id": "1901.10995", "submitter": "Adrien Ecoffet", "authors": "Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O. Stanley, Jeff\n  Clune", "title": "Go-Explore: a New Approach for Hard-Exploration Problems", "comments": "37 pages, 14 figures; added references to Goyal et al. and Oh et al.,\n  updated reference to Colas et al; updated author emails; point readers to\n  updated paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A grand challenge in reinforcement learning is intelligent exploration,\nespecially when rewards are sparse or deceptive. Two Atari games serve as\nbenchmarks for such hard-exploration domains: Montezuma's Revenge and Pitfall.\nOn both games, current RL algorithms perform poorly, even those with intrinsic\nmotivation, which is the dominant method to improve performance on\nhard-exploration domains. To address this shortfall, we introduce a new\nalgorithm called Go-Explore. It exploits the following principles: (1) remember\npreviously visited states, (2) first return to a promising state (without\nexploration), then explore from it, and (3) solve simulated environments\nthrough any available means (including by introducing determinism), then\nrobustify via imitation learning. The combined effect of these principles is a\ndramatic performance improvement on hard-exploration problems. On Montezuma's\nRevenge, Go-Explore scores a mean of over 43k points, almost 4 times the\nprevious state of the art. Go-Explore can also harness human-provided domain\nknowledge and, when augmented with it, scores a mean of over 650k points on\nMontezuma's Revenge. Its max performance of nearly 18 million surpasses the\nhuman world record, meeting even the strictest definition of \"superhuman\"\nperformance. On Pitfall, Go-Explore with domain knowledge is the first\nalgorithm to score above zero. Its mean score of almost 60k points exceeds\nexpert human performance. Because Go-Explore produces high-performing\ndemonstrations automatically and cheaply, it also outperforms imitation\nlearning work where humans provide solution demonstrations. Go-Explore opens up\nmany new research directions into improving it and weaving its insights into\ncurrent RL algorithms. It may also enable progress on previously unsolvable\nhard-exploration problems in many domains, especially those that harness a\nsimulator during training (e.g. robotics).\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 18:40:37 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:16:49 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 02:10:07 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 21:21:11 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ecoffet", "Adrien", ""], ["Huizinga", "Joost", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "1901.11015", "submitter": "Mateo Rojas-Carulla Mr", "authors": "Mateo Rojas-Carulla, Ilya Tolstikhin, Guillermo Luque, Nicholas\n  Youngblut, Ruth Ley, Bernhard Sch\\\"olkopf", "title": "GeNet: Deep Representations for Metagenomics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GeNet, a method for shotgun metagenomic classification from raw\nDNA sequences that exploits the known hierarchical structure between labels for\ntraining. We provide a comparison with state-of-the-art methods Kraken and\nCentrifuge on datasets obtained from several sequencing technologies, in which\ndataset shift occurs. We show that GeNet obtains competitive precision and good\nrecall, with orders of magnitude less memory requirements. Moreover, we show\nthat a linear model trained on top of representations learned by GeNet achieves\nrecall comparable to state-of-the-art methods on the aforementioned datasets,\nand achieves over 90% accuracy in a challenging pathogen detection problem.\nThis provides evidence of the usefulness of the representations learned by\nGeNet for downstream biological tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 09:48:53 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Rojas-Carulla", "Mateo", ""], ["Tolstikhin", "Ilya", ""], ["Luque", "Guillermo", ""], ["Youngblut", "Nicholas", ""], ["Ley", "Ruth", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1901.11033", "submitter": "Jakob Knollm\\\"uller", "authors": "Jakob Knollm\\\"uller and Torsten A. En{\\ss}lin", "title": "Metric Gaussian Variational Inference", "comments": "Code is part of NIFTy5 release at\n  https://gitlab.mpcdf.mpg.de/ift/NIFTy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.IM cs.LG physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving Bayesian inference problems approximately with variational approaches\ncan provide fast and accurate results. Capturing correlation within the\napproximation requires an explicit parametrization. This intrinsically limits\nthis approach to either moderately dimensional problems, or requiring the\nstrongly simplifying mean-field approach. We propose Metric Gaussian\nVariational Inference (MGVI) as a method that goes beyond mean-field. Here\ncorrelations between all model parameters are taken into account, while still\nscaling linearly in computational time and memory. With this method we achieve\nhigher accuracy and in many cases a significant speedup compared to traditional\nmethods. MGVI is an iterative method that performs a series of Gaussian\napproximations to the posterior. We alternate between approximating the\ncovariance with the inverse Fisher information metric evaluated at an\nintermediate mean estimate and optimizing the KL-divergence for the given\ncovariance with respect to the mean. This procedure is iterated until the\nuncertainty estimate is self-consistent with the mean parameter. We achieve\nlinear scaling by avoiding to store the covariance explicitly at any time.\nInstead we draw samples from the approximating distribution relying on an\nimplicit representation and numerical schemes to approximately solve linear\nequations. Those samples are used to approximate the KL-divergence and its\ngradient. The usage of natural gradient descent allows for rapid convergence.\nFormulating the Bayesian model in standardized coordinates makes MGVI\napplicable to any inference problem with continuous parameters. We demonstrate\nthe high accuracy of MGVI by comparing it to HMC and its fast convergence\nrelative to other established methods in several examples. We investigate\nreal-data applications, as well as synthetic examples of varying size and\ncomplexity and up to a million model parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 19:00:02 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 12:15:19 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 15:02:03 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Knollm\u00fcller", "Jakob", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "1901.11040", "submitter": "Richard Moulton", "authors": "Richard Hugh Moulton and Jakub Zgraja", "title": "The Wilderness Area Data Set: Adapting the Covertype data set for\n  unsupervised learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Benchmark data sets are of vital importance in machine learning research, as\nindicated by the number of repositories that exist to make them publicly\navailable. Although many of these are usable in the stream mining context as\nwell, it is less obvious which data sets can be used to evaluate data stream\nclustering algorithms. We note that the classic Covertype data set's size makes\nit attractive for use in stream mining but unfortunately it is specifically\ndesigned for classification. Here we detail the process of transforming the\nCovertype data set into one amenable for unsupervised learning, which we call\nthe Wilderness Area data set. Our quantitative analysis allows us to conclude\nthat the Wilderness Area data set is more appropriate for unsupervised learning\nthan the original Covertype data set.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 19:00:21 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Moulton", "Richard Hugh", ""], ["Zgraja", "Jakub", ""]]}, {"id": "1901.11058", "submitter": "Neale Ratzlaff", "authors": "Neale Ratzlaff, Li Fuxin", "title": "HyperGAN: A Generative Model for Diverse, Performant Neural Networks", "comments": "11 pages, 10 figures, 6 tables, Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard neural networks are often overconfident when presented with data\noutside the training distribution. We introduce HyperGAN, a new generative\nmodel for learning a distribution of neural network parameters. HyperGAN does\nnot require restrictive assumptions on priors, and networks sampled from it can\nbe used to quickly create very large and diverse ensembles. HyperGAN employs a\nnovel mixer to project prior samples to a latent space with correlated\ndimensions, and samples from the latent space are then used to generate weights\nfor each layer of a deep neural network. We show that HyperGAN can learn to\ngenerate parameters which label the MNIST and CIFAR-10 datasets with\ncompetitive performance to fully supervised learning, while learning a rich\ndistribution of effective parameters. We also show that HyperGAN can also\nprovide better uncertainty estimates than standard ensembles by evaluating on\nout of distribution data as well as adversarial examples.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 19:27:07 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 18:18:40 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 18:38:33 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Ratzlaff", "Neale", ""], ["Fuxin", "Li", ""]]}, {"id": "1901.11074", "submitter": "Adri\\'an Bazaga", "authors": "Adri\\'an Bazaga, M\\`onica Rold\\'an, Carmen Badosa, Cecilia\n  Jim\\'enez-Mallebrera, Josep M. Porta", "title": "A Convolutional Neural Network for the Automatic Diagnosis of Collagen\n  VI related Muscular Dystrophies", "comments": "Submitted for review to Expert Systems With Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of machine learning systems for the diagnosis of rare\ndiseases is challenging mainly due the lack of data to study them. Despite this\nchallenge, this paper proposes a system for the Computer Aided Diagnosis (CAD)\nof low-prevalence, congenital muscular dystrophies from confocal microscopy\nimages. The proposed CAD system relies on a Convolutional Neural Network (CNN)\nwhich performs an independent classification for non-overlapping patches tiling\nthe input image, and generates an overall decision summarizing the individual\ndecisions for the patches on the query image. This decision scheme points to\nthe possibly problematic areas in the input images and provides a global\nquantitative evaluation of the state of the patients, which is fundamental for\ndiagnosis and to monitor the efficiency of therapies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 19:59:33 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Bazaga", "Adri\u00e1n", ""], ["Rold\u00e1n", "M\u00f2nica", ""], ["Badosa", "Carmen", ""], ["Jim\u00e9nez-Mallebrera", "Cecilia", ""], ["Porta", "Josep M.", ""]]}, {"id": "1901.11078", "submitter": "Khashayar Asadi", "authors": "Idris Jeelani, Khashayar Asadi, Hariharan Ramshankar, Kevin Han, Alex\n  Albert", "title": "Real-world Mapping of Gaze Fixations Using Instance Segmentation for\n  Road Construction Safety Applications", "comments": "2019 TRB Annual meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research studies have shown that a large proportion of hazards remain\nunrecognized, which expose construction workers to unanticipated safety risks.\nRecent studies have also found that a strong correlation exists between viewing\npatterns of workers, captured using eye-tracking devices, and their hazard\nrecognition performance. Therefore, it is important to analyze the viewing\npatterns of workers to gain a better understanding of their hazard recognition\nperformance. This paper proposes a method that can automatically map the gaze\nfixations collected using a wearable eye-tracker to the predefined areas of\ninterests. The proposed method detects these areas or objects (i.e., hazards)\nof interests through a computer vision-based segmentation technique and\ntransfer learning. The mapped fixation data is then used to analyze the viewing\nbehaviors of workers and compute their attention distribution. The proposed\nmethod is implemented on an under construction road as a case study to evaluate\nthe performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 20:02:27 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 19:47:25 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Jeelani", "Idris", ""], ["Asadi", "Khashayar", ""], ["Ramshankar", "Hariharan", ""], ["Han", "Kevin", ""], ["Albert", "Alex", ""]]}, {"id": "1901.11084", "submitter": "Clare Lyle", "authors": "Clare Lyle, Pablo Samuel Castro, Marc G. Bellemare", "title": "A Comparative Analysis of Expected and Distributional Reinforcement\n  Learning", "comments": "To appear in the Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their introduction a year ago, distributional approaches to\nreinforcement learning (distributional RL) have produced strong results\nrelative to the standard approach which models expected values (expected RL).\nHowever, aside from convergence guarantees, there have been few theoretical\nresults investigating the reasons behind the improvements distributional RL\nprovides. In this paper we begin the investigation into this fundamental\nquestion by analyzing the differences in the tabular, linear approximation, and\nnon-linear approximation settings. We prove that in many realizations of the\ntabular and linear approximation settings, distributional RL behaves exactly\nthe same as expected RL. In cases where the two methods behave differently,\ndistributional RL can in fact hurt performance when it does not induce\nidentical behaviour. We then continue with an empirical analysis comparing\ndistributional and expected RL methods in control settings with non-linear\napproximators to tease apart where the improvements from distributional RL\nmethods are coming from.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 20:20:27 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 09:24:17 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Lyle", "Clare", ""], ["Castro", "Pablo Samuel", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1901.11117", "submitter": "David So", "authors": "David R. So and Chen Liang and Quoc V. Le", "title": "The Evolved Transformer", "comments": "ICML version with SOTA results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent works have highlighted the strength of the Transformer architecture on\nsequence tasks while, at the same time, neural architecture search (NAS) has\nbegun to outperform human-designed models. Our goal is to apply NAS to search\nfor a better alternative to the Transformer. We first construct a large search\nspace inspired by the recent advances in feed-forward sequence models and then\nrun evolutionary architecture search with warm starting by seeding our initial\npopulation with the Transformer. To directly search on the computationally\nexpensive WMT 2014 English-German translation task, we develop the Progressive\nDynamic Hurdles method, which allows us to dynamically allocate more resources\nto more promising candidate models. The architecture found in our experiments\n-- the Evolved Transformer -- demonstrates consistent improvement over the\nTransformer on four well-established language tasks: WMT 2014 English-German,\nWMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size,\nthe Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8\non WMT'14 English-German; at smaller sizes, it achieves the same quality as the\noriginal \"big\" Transformer with 37.6% less parameters and outperforms the\nTransformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 22:03:01 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 21:35:28 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 22:23:12 GMT"}, {"version": "v4", "created": "Fri, 17 May 2019 19:47:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["So", "David R.", ""], ["Liang", "Chen", ""], ["Le", "Quoc V.", ""]]}, {"id": "1901.11137", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Rianne van den Berg, Max Welling", "title": "Emerging Convolutions for Generative Normalizing Flows", "comments": "Accepted at International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative flows are attractive because they admit exact likelihood\noptimization and efficient image synthesis. Recently, Kingma & Dhariwal (2018)\ndemonstrated with Glow that generative flows are capable of generating high\nquality images. We generalize the 1 x 1 convolutions proposed in Glow to\ninvertible d x d convolutions, which are more flexible since they operate on\nboth channel and spatial axes. We propose two methods to produce invertible\nconvolutions that have receptive fields identical to standard convolutions:\nEmerging convolutions are obtained by chaining specific autoregressive\nconvolutions, and periodic convolutions are decoupled in the frequency domain.\nOur experiments show that the flexibility of d x d convolutions significantly\nimproves the performance of generative flow models on galaxy images, CIFAR10\nand ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:02:37 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 18:04:19 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 08:56:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Berg", "Rianne van den", ""], ["Welling", "Max", ""]]}, {"id": "1901.11141", "submitter": "Forest Yang", "authors": "Forest Yang, Sanmi Koyejo", "title": "On the Consistency of Top-k Surrogate Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top-$k$ error is often employed to evaluate performance for challenging\nclassification tasks in computer vision as it is designed to compensate for\nambiguity in ground truth labels. This practical success motivates our\ntheoretical analysis of consistent top-$k$ classification. Surprisingly, it is\nnot rigorously understood when taking the $k$-argmax of a vector is guaranteed\nto return the $k$-argmax of another vector, though doing so is crucial to\ndescribe Bayes optimality; we do both tasks. Then, we define top-$k$\ncalibration and show it is necessary and sufficient for consistency. Based on\nthe top-$k$ calibration analysis, we propose a class of top-$k$ calibrated\nBregman divergence surrogates. Our analysis continues by showing previously\nproposed hinge-like top-$k$ surrogate losses are not top-$k$ calibrated and\nsuggests no convex hinge loss is top-$k$ calibrated. On the other hand, we\npropose a new hinge loss which is consistent. We explore further, showing our\nhinge loss remains consistent under a restriction to linear functions, while\ncross entropy does not. Finally, we exhibit a differentiable, convex loss\nfunction which is top-$k$ calibrated for specific $k$.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:21:42 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 21:41:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yang", "Forest", ""], ["Koyejo", "Sanmi", ""]]}, {"id": "1901.11143", "submitter": "Tijana Zrnic", "authors": "Tijana Zrnic, Moritz Hardt", "title": "Natural Analysts in Adaptive Data Analysis", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive data analysis is frequently criticized for its pessimistic\ngeneralization guarantees. The source of these pessimistic bounds is a model\nthat permits arbitrary, possibly adversarial analysts that optimally use\ninformation to bias results. While being a central issue in the field, still\nlacking are notions of natural analysts that allow for more optimistic bounds\nfaithful to the reality that typical analysts aren't adversarial.\n  In this work, we propose notions of natural analysts that smoothly\ninterpolate between the optimal non-adaptive bounds and the best-known adaptive\ngeneralization bounds. To accomplish this, we model the analyst's knowledge as\nevolving according to the rules of an unknown dynamical system that takes in\nrevealed information and outputs new statistical queries to the data. This\nallows us to restrict the analyst through different natural control-theoretic\nnotions. One such notion corresponds to a recency bias, formalizing an\ninability to arbitrarily use distant information. Another complementary notion\nformalizes an anchoring bias, a tendency to weight initial information more\nstrongly. Both notions come with quantitative parameters that smoothly\ninterpolate between the non-adaptive case and the fully adaptive case, allowing\nfor a rich spectrum of intermediate analysts that are neither non-adaptive nor\nadversarial.\n  Natural not only from a cognitive perspective, we show that our notions also\ncapture standard optimization methods, like gradient descent in various\nsettings. This gives a new interpretation to the fact that gradient descent\ntends to overfit much less than its adaptive nature might suggest.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:26:01 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 01:28:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zrnic", "Tijana", ""], ["Hardt", "Moritz", ""]]}, {"id": "1901.11149", "submitter": "Ming Lin", "authors": "Ming Lin, Shuang Qiu, Jieping Ye, Xiaomin Song, Qi Qian, Liang Sun,\n  Shenghuo Zhu, Rong Jin", "title": "Which Factorization Machine Modeling is Better: A Theoretical Answer\n  with Optimal Guarantee", "comments": "accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization machine (FM) is a popular machine learning model to capture the\nsecond order feature interactions. The optimal learning guarantee of FM and its\ngeneralized version is not yet developed. For a rank $k$ generalized FM of $d$\ndimensional input, the previous best known sampling complexity is\n$\\mathcal{O}[k^{3}d\\cdot\\mathrm{polylog}(kd)]$ under Gaussian distribution.\nThis bound is sub-optimal comparing to the information theoretical lower bound\n$\\mathcal{O}(kd)$. In this work, we aim to tighten this bound towards optimal\nand generalize the analysis to sub-gaussian distribution. We prove that when\nthe input data satisfies the so-called $\\tau$-Moment Invertible Property, the\nsampling complexity of generalized FM can be improved to\n$\\mathcal{O}[k^{2}d\\cdot\\mathrm{polylog}(kd)/\\tau^{2}]$. When the second order\nself-interaction terms are excluded in the generalized FM, the bound can be\nimproved to the optimal $\\mathcal{O}[kd\\cdot\\mathrm{polylog}(kd)]$ up to the\nlogarithmic factors. Our analysis also suggests that the positive semi-definite\nconstraint in the conventional FM is redundant as it does not improve the\nsampling complexity while making the model difficult to optimize. We evaluate\nour improved FM model in real-time high precision GPS signal calibration task\nto validate its superiority.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:47:21 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Lin", "Ming", ""], ["Qiu", "Shuang", ""], ["Ye", "Jieping", ""], ["Song", "Xiaomin", ""], ["Qian", "Qi", ""], ["Sun", "Liang", ""], ["Zhu", "Shenghuo", ""], ["Jin", "Rong", ""]]}, {"id": "1901.11150", "submitter": "Tomer Koren", "authors": "Rohan Anil, Vineet Gupta, Tomer Koren, Yoram Singer", "title": "Memory-Efficient Adaptive Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient-based optimizers such as Adagrad and Adam are crucial for\nachieving state-of-the-art performance in machine translation and language\nmodeling. However, these methods maintain second-order statistics for each\nparameter, thus introducing significant memory overheads that restrict the size\nof the model being used as well as the number of examples in a mini-batch. We\ndescribe an effective and flexible adaptive optimization method with greatly\nreduced memory overhead. Our method retains the benefits of per-parameter\nadaptivity while allowing significantly larger models and batch sizes. We give\nconvergence guarantees for our method, and demonstrate its effectiveness in\ntraining very large translation and language models with up to 2-fold speedups\ncompared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:51:26 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 22:33:28 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Anil", "Rohan", ""], ["Gupta", "Vineet", ""], ["Koren", "Tomer", ""], ["Singer", "Yoram", ""]]}, {"id": "1901.11152", "submitter": "Ya Ju Fan", "authors": "Ya Ju Fan, Jonathan E. Allen, Sam Ade Jacobs and Brian C. Van Essen", "title": "Distinguishing between Normal and Cancer Cells Using Autoencoder Node\n  Saliency", "comments": "Second Workshop on HPC Applications in Precision Medicine, June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene expression profiles have been widely used to characterize patterns of\ncellular responses to diseases. As data becomes available, scalable learning\ntoolkits become essential to processing large datasets using deep learning\nmodels to model complex biological processes. We present an autoencoder to\ncapture nonlinear relationships recovered from gene expression profiles. The\nautoencoder is a nonlinear dimension reduction technique using an artificial\nneural network, which learns hidden representations of unlabeled data. We train\nthe autoencoder on a large collection of tumor samples from the National Cancer\nInstitute Genomic Data Commons, and obtain a generalized and unsupervised\nlatent representation. We leverage a HPC-focused deep learning toolkit,\nLivermore Big Artificial Neural Network (LBANN) to efficiently parallelize the\ntraining algorithm, reducing computation times from several hours to a few\nminutes. With the trained autoencoder, we generate latent representations of a\nsmall dataset, containing pairs of normal and cancer cells of various tumor\ntypes. A novel measure called autoencoder node saliency (ANS) is introduced to\nidentify the hidden nodes that best differentiate various pairs of cells. We\ncompare our findings of the best classifying nodes with principal component\nanalysis and the visualization of t-distributed stochastic neighbor embedding.\nWe demonstrate that the autoencoder effectively extracts distinct gene features\nfor multiple learning tasks in the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 23:59:20 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Fan", "Ya Ju", ""], ["Allen", "Jonathan E.", ""], ["Jacobs", "Sam Ade", ""], ["Van Essen", "Brian C.", ""]]}, {"id": "1901.11164", "submitter": "Cleison Correia de Amorim", "authors": "Cleison Correia de Amorim, David Mac\\^edo, and Cleber Zanchettin", "title": "Spatial-Temporal Graph Convolutional Networks for Sign Language\n  Recognition", "comments": null, "journal-ref": "2019 International Conference on Artificial Neural Networks\n  (ICANN)", "doi": "10.1007/978-3-030-30493-5_59", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of sign language is a challenging task with an important role\nin society to facilitate the communication of deaf persons. We propose a new\napproach of Spatial-Temporal Graph Convolutional Network to sign language\nrecognition based on the human skeletal movements. The method uses graphs to\ncapture the signs dynamics in two dimensions, spatial and temporal, considering\nthe complex aspects of the language. Additionally, we present a new dataset of\nhuman skeletons for sign language based on ASLLVD to contribute to future\nrelated studies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 01:25:47 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 01:19:54 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["de Amorim", "Cleison Correia", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "1901.11172", "submitter": "Eric Lock", "authors": "Eric F. Lock and Dipankar Bandyopadhyay", "title": "Bayesian nonparametric multiway regression for clustered binomial data", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian nonparametric regression model for data with multiway\n(tensor) structure, motivated by an application to periodontal disease (PD)\ndata. Our outcome is the number of diseased sites measured over four different\ntooth types for each subject, with subject-specific covariates available as\npredictors. The outcomes are not well-characterized by simple parametric\nmodels, so we use a nonparametric approach with a binomial likelihood wherein\nthe latent probabilities are drawn from a mixture with an arbitrary number of\ncomponents, analogous to a Dirichlet Process (DP). We use a flexible probit\nstick-breaking formulation for the component weights that allows for covariate\ndependence and clustering structure in the outcomes. The parameter space for\nthis model is large and multiway: patients $\\times$ tooth types $\\times$\ncovariates $\\times$ components. We reduce its effective dimensionality, and\naccount for the multiway structure, via low-rank assumptions. We illustrate how\nthis can improve performance, and simplify interpretation, while still\nproviding sufficient flexibility. We describe a general and efficient Gibbs\nsampling algorithm for posterior computation. The resulting fit to the PD data\noutperforms competitors, and is interpretable and well-calibrated. An\ninteractive visual of the predictive model is available at\nhttp://ericfrazerlock.com/toothdata/ToothDisplay.html , and the code is\navailable at https://github.com/lockEF/NonparametricMultiway .\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 02:05:07 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Lock", "Eric F.", ""], ["Bandyopadhyay", "Dipankar", ""]]}, {"id": "1901.11173", "submitter": "Anusha Lalitha", "authors": "Anusha Lalitha, Osman Cihan Kilinc, Tara Javidi, Farinaz Koushanfar", "title": "Peer-to-peer Federated Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training a machine learning model over a network\nof nodes in a fully decentralized framework. The nodes take a Bayesian-like\napproach via the introduction of a belief over the model parameter space. We\npropose a distributed learning algorithm in which nodes update their belief by\naggregate information from their one-hop neighbors to learn a model that best\nfits the observations over the entire network. In addition, we also obtain\nsufficient conditions to ensure that the probability of error is small for\nevery node in the network. We discuss approximations required for applying this\nalgorithm to train Deep Neural Networks (DNNs). Experiments on training linear\nregression model and on training a DNN show that the proposed learning rule\nalgorithm provides a significant improvement in the accuracy compared to the\ncase where nodes learn without cooperation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 02:18:45 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Lalitha", "Anusha", ""], ["Kilinc", "Osman Cihan", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1901.11200", "submitter": "Koji Tabata", "authors": "Koji Tabata, Atsuyoshi Nakamura, Junya Honda and Tamiki Komatsuzaki", "title": "A Bad Arm Existence Checking Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a bad arm existing checking problem in which a player's task is to\njudge whether a positive arm exists or not among given K arms by drawing as\nsmall number of arms as possible. Here, an arm is positive if its expected loss\nsuffered by drawing the arm is at least a given threshold. This problem is a\nformalization of diagnosis of disease or machine failure. An interesting\nstructure of this problem is the asymmetry of positive and negative\n(non-positive) arms' roles; finding one positive arm is enough to judge\nexistence while all the arms must be discriminated as negative to judge\nnon-existence. We propose an algorithms with arm selection policy (policy to\ndetermine the next arm to draw) and stopping condition (condition to stop\ndrawing arms) utilizing this asymmetric problem structure and prove its\neffectiveness theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 03:46:06 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Tabata", "Koji", ""], ["Nakamura", "Atsuyoshi", ""], ["Honda", "Junya", ""], ["Komatsuzaki", "Tamiki", ""]]}, {"id": "1901.11212", "submitter": "Tianyu Shi", "authors": "Tianyu Shi, Pin Wang, Ching-Yao Chan, Chonghao Zou", "title": "A Data Driven Method of Optimizing Feedforward Compensator for\n  Autonomous Vehicle", "comments": "This paper have been submitted to the 2019 IEEE Intelligent Vehicle\n  Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reliable controller is critical and essential for the execution of safe and\nsmooth maneuvers of an autonomous vehicle.The controller must be robust to\nexternal disturbances, such as road surface, weather, and wind conditions, and\nso on.It also needs to deal with the internal parametric variations of vehicle\nsub-systems, including power-train efficiency, measurement errors, time\ndelay,so on.Moreover, as in most production vehicles, the low-control commands\nfor the engine, brake, and steering systems are delivered through separate\nelectronic control units.These aforementioned factors introduce opaque and\nineffectiveness issues in controller performance.In this paper, we design a\nfeed-forward compensate process via a data-driven method to model and further\noptimize the controller performance.We apply the principal component analysis\nto the extraction of most influential features.Subsequently,we adopt a time\ndelay neural network and include the accuracy of the predicted error in a\nfuture time horizon.Utilizing the predicted error,we then design a feed-forward\ncompensate process to improve the control performance.Finally,we demonstrate\nthe effectiveness of the proposed feed-forward compensate process in simulation\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 05:06:01 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 09:26:44 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Shi", "Tianyu", ""], ["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""], ["Zou", "Chonghao", ""]]}, {"id": "1901.11213", "submitter": "Muhammad Khan", "authors": "Muhammad Raza Khan, Joshua E. Blumenstock", "title": "Multi-GCN: Graph Convolutional Networks for Multi-View Networks, with\n  Applications to Global Poverty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid expansion of mobile phone networks in developing countries,\nlarge-scale graph machine learning has gained sudden relevance in the study of\nglobal poverty. Recent applications range from humanitarian response and\npoverty estimation to urban planning and epidemic containment. Yet the vast\nmajority of computational tools and algorithms used in these applications do\nnot account for the multi-view nature of social networks: people are related in\nmyriad ways, but most graph learning models treat relations as binary. In this\npaper, we develop a graph-based convolutional network for learning on\nmulti-view networks. We show that this method outperforms state-of-the-art\nsemi-supervised learning algorithms on three different prediction tasks using\nmobile phone datasets from three different developing countries. We also show\nthat, while designed specifically for use in poverty research, the algorithm\nalso outperforms existing benchmarks on a broader set of learning tasks on\nmulti-view networks, including node labelling in citation networks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 05:07:41 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Khan", "Muhammad Raza", ""], ["Blumenstock", "Joshua E.", ""]]}, {"id": "1901.11221", "submitter": "Gi-Soo Kim", "authors": "Gi-Soo Kim, Myunghee Cho Paik", "title": "Contextual Multi-armed Bandit Algorithm for Semiparametric Reward Model", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual multi-armed bandit (MAB) algorithms have been shown promising for\nmaximizing cumulative rewards in sequential decision tasks such as news article\nrecommendation systems, web page ad placement algorithms, and mobile health.\nHowever, most of the proposed contextual MAB algorithms assume linear\nrelationships between the reward and the context of the action. This paper\nproposes a new contextual MAB algorithm for a relaxed, semiparametric reward\nmodel that supports nonstationarity. The proposed method is less restrictive,\neasier to implement and faster than two alternative algorithms that consider\nthe same model, while achieving a tight regret upper bound. We prove that the\nhigh-probability upper bound of the regret incurred by the proposed algorithm\nhas the same order as the Thompson sampling algorithm for linear reward models.\nThe proposed and existing algorithms are evaluated via simulation and also\napplied to Yahoo! news article recommendation log data.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 06:09:17 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Kim", "Gi-Soo", ""], ["Paik", "Myunghee Cho", ""]]}, {"id": "1901.11224", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Quanquan Gu", "title": "Lower Bounds for Smooth Nonconvex Finite-Sum Optimization", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth finite-sum optimization has been widely studied in both convex and\nnonconvex settings. However, existing lower bounds for finite-sum optimization\nare mostly limited to the setting where each component function is (strongly)\nconvex, while the lower bounds for nonconvex finite-sum optimization remain\nlargely unsolved. In this paper, we study the lower bounds for smooth nonconvex\nfinite-sum optimization, where the objective function is the average of $n$\nnonconvex component functions. We prove tight lower bounds for the complexity\nof finding $\\epsilon$-suboptimal point and $\\epsilon$-approximate stationary\npoint in different settings, for a wide regime of the smallest eigenvalue of\nthe Hessian of the objective function (or each component function). Given our\nlower bounds, we can show that existing algorithms including KatyushaX\n(Allen-Zhu, 2018), Natasha (Allen-Zhu, 2017), RapGrad (Lan and Yang, 2018) and\nStagewiseKatyusha (Chen and Yang, 2018) have achieved optimal Incremental\nFirst-order Oracle (IFO) complexity (i.e., number of IFO calls) up to logarithm\nfactors for nonconvex finite-sum optimization. We also point out potential ways\nto further improve these complexity results, in terms of making stronger\nassumptions or by a different convergence analysis.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 06:16:45 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "1901.11261", "submitter": "Yang Shi", "authors": "Yang Shi and Animashree Anandkumar", "title": "Higher-order Count Sketch: Dimensionality Reduction That Retains\n  Efficient Tensor Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketching is a randomized dimensionality-reduction method that aims to\npreserve relevant information in large-scale datasets. Count sketch is a simple\npopular sketch which uses a randomized hash function to achieve compression. In\nthis paper, we propose a novel extension known as Higher-order Count Sketch\n(HCS). While count sketch uses a single hash function, HCS uses multiple\n(smaller) hash functions for sketching. HCS reshapes the input (vector) data\ninto a higher-order tensor and employs a tensor product of the random hash\nfunctions to compute the sketch. This results in an exponential saving (with\nrespect to the order of the tensor) in the memory requirements of the hash\nfunctions, under certain conditions on the input data. Furthermore, when the\ninput data itself has an underlying structure in the form of various tensor\nrepresentations such as the Tucker decomposition, we obtain significant\nadvantages. We derive efficient (approximate) computation of various tensor\noperations such as tensor products and tensor contractions directly on the\nsketched data. Thus, HCS is the first sketch to fully exploit the\nmulti-dimensional nature of higher-order tensors. We apply HCS to tensorized\nneural networks where we replace fully connected layers with sketched tensor\noperations. We achieve nearly state of the art accuracy with significant\ncompression on the image classification benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 08:26:15 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 00:46:54 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 00:14:54 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 01:25:41 GMT"}, {"version": "v5", "created": "Mon, 4 Nov 2019 18:35:49 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shi", "Yang", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1901.11275", "submitter": "Matthieu Geist", "authors": "Matthieu Geist, Bruno Scherrer, Olivier Pietquin", "title": "A Theory of Regularized Markov Decision Processes", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many recent successful (deep) reinforcement learning algorithms make use of\nregularization, generally based on entropy or Kullback-Leibler divergence. We\npropose a general theory of regularized Markov Decision Processes that\ngeneralizes these approaches in two directions: we consider a larger class of\nregularizers, and we consider the general modified policy iteration approach,\nencompassing both policy iteration and value iteration. The core building\nblocks of this theory are a notion of regularized Bellman operator and the\nLegendre-Fenchel transform, a classical tool of convex optimization. This\napproach allows for error propagation analyses of general algorithmic schemes\nof which (possibly variants of) classical algorithms such as Trust Region\nPolicy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic Policy\nProgramming are special cases. This also draws connections to proximal convex\noptimization, especially to Mirror Descent.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 09:10:08 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:44:24 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Geist", "Matthieu", ""], ["Scherrer", "Bruno", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1901.11286", "submitter": "Daniel Rodriguez", "authors": "Raul-Jose Palma-Mendoza and Luis de-Marcos and Daniel Rodriguez and\n  Amparo Alonso-Betanzos", "title": "Distributed Correlation-Based Feature Selection in Spark", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.ins.2018.10.052", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CFS (Correlation-Based Feature Selection) is an FS algorithm that has been\nsuccessfully applied to classification problems in many domains. We describe\nDistributed CFS (DiCFS) as a completely redesigned, scalable, parallel and\ndistributed version of the CFS algorithm, capable of dealing with the large\nvolumes of data typical of big data applications. Two versions of the algorithm\nwere implemented and compared using the Apache Spark cluster computing model,\ncurrently gaining popularity due to its much faster processing times than\nHadoop's MapReduce model. We tested our algorithms on four publicly available\ndatasets, each consisting of a large number of instances and two also\nconsisting of a large number of features. The results show that our algorithms\nwere superior in terms of both time-efficiency and scalability. In leveraging a\ncomputer cluster, they were able to handle larger datasets than the\nnon-distributed WEKA version while maintaining the quality of the results,\ni.e., exactly the same features were returned by our algorithms when compared\nto the original algorithm available in WEKA.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 09:36:04 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Palma-Mendoza", "Raul-Jose", ""], ["de-Marcos", "Luis", ""], ["Rodriguez", "Daniel", ""], ["Alonso-Betanzos", "Amparo", ""]]}, {"id": "1901.11300", "submitter": "Kimin Lee", "authors": "Kimin Lee, Sukmin Yun, Kibok Lee, Honglak Lee, Bo Li, Jinwoo Shin", "title": "Robust Inference via Generative Classifiers for Handling Noisy Labels", "comments": "Accepted in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale datasets may contain significant proportions of noisy (incorrect)\nclass labels, and it is well-known that modern deep neural networks (DNNs)\npoorly generalize from such noisy training datasets. To mitigate the issue, we\npropose a novel inference method, termed Robust Generative classifier (RoG),\napplicable to any discriminative (e.g., softmax) neural classifier pre-trained\non noisy datasets. In particular, we induce a generative classifier on top of\nhidden feature spaces of the pre-trained DNNs, for obtaining a more robust\ndecision boundary. By estimating the parameters of generative classifier using\nthe minimum covariance determinant estimator, we significantly improve the\nclassification accuracy with neither re-training of the deep model nor changing\nits architectures. With the assumption of Gaussian distribution for features,\nwe prove that RoG generalizes better than baselines under noisy labels.\nFinally, we propose the ensemble version of RoG to improve its performance by\ninvestigating the layer-wise characteristics of DNNs. Our extensive\nexperimental results demonstrate the superiority of RoG given different\nlearning models optimized by several training techniques to handle diverse\nscenarios of noisy labels.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 10:41:13 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 20:33:58 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Lee", "Kimin", ""], ["Yun", "Sukmin", ""], ["Lee", "Kibok", ""], ["Lee", "Honglak", ""], ["Li", "Bo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1901.11303", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat, Dymitr Ruta, Bogdan Gabrys", "title": "Hyperbox based machine learning algorithms: A comprehensive survey", "comments": "7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rapid development of digital information, the data volume generated\nby humans and machines is growing exponentially. Along with this trend, machine\nlearning algorithms have been formed and evolved continuously to discover new\ninformation and knowledge from different data sources. Learning algorithms\nusing hyperboxes as fundamental representational and building blocks are a\nbranch of machine learning methods. These algorithms have enormous potential\nfor high scalability and online adaptation of predictors built using hyperbox\ndata representations to the dynamically changing environments and streaming\ndata. This paper aims to give a comprehensive survey of literature on\nhyperbox-based machine learning models. In general, according to the\narchitecture and characteristic features of the resulting models, the existing\nhyperbox-based learning algorithms may be grouped into three major categories:\nfuzzy min-max neural networks, hyperbox-based hybrid models, and other\nalgorithms based on hyperbox representations. Within each of these groups, this\npaper shows a brief description of the structure of models, associated learning\nalgorithms, and an analysis of their advantages and drawbacks. Main\napplications of these hyperbox-based models to the real-world problems are also\ndescribed in this paper. Finally, we discuss some open problems and identify\npotential future research directions in this field.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 11:10:29 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 23:24:01 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 00:53:31 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Ruta", "Dymitr", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "1901.11311", "submitter": "Christian Walder Dr", "authors": "Christian J. Walder and Paul Roussel and Richard Nock and Cheng Soon\n  Ong and Masashi Sugiyama", "title": "New Tricks for Estimating Gradients of Expectations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a family of Monte Carlo estimators for gradients of expectations\nwhich is related to the log-derivative trick, but involves pairwise\ninteractions between samples. The first of these comes from either a)\nintroducing and approximating an integral representation based on the\nfundamental theorem of calculus, or b) applying the reparameterisation trick to\nan implicit parameterisation under infinitesimal perturbation of the\nparameters. From the former perspective we generalise to a reproducing kernel\nHilbert space representation, giving rise to locality parameter in the pairwise\ninteractions mentioned above. The resulting estimators are unbiased and shown\nto offer an independent component of useful information in comparison with the\nlog-derivative estimator. Promising analytical and numerical examples confirm\nthe intuitions behind the new estimators.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 11:33:47 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 16:26:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Walder", "Christian J.", ""], ["Roussel", "Paul", ""], ["Nock", "Richard", ""], ["Ong", "Cheng Soon", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.11331", "submitter": "Masahiro Kobayashi", "authors": "Masahiro Kobayashi and Kazuho Watanabe", "title": "Generalized Dirichlet-process-means for $f$-separable distortion\n  measures", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.03.123", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  DP-means clustering was obtained as an extension of $K$-means clustering.\nWhile it is implemented with a simple and efficient algorithm, it can estimate\nthe number of clusters simultaneously. However, DP-means is specifically\ndesigned for the average distortion measure. Therefore, it is vulnerable to\noutliers in data, and can cause large maximum distortion in clusters. In this\nwork, we extend the objective function of the DP-means to $f$-separable\ndistortion measures and propose a unified learning algorithm to overcome the\nabove problems by selecting the function $f$. Further, the influence function\nof the estimated cluster center is analyzed to evaluate the robustness against\noutliers. We demonstrate the performance of the generalized method by numerical\nexperiments using real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 12:36:59 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 03:12:40 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 09:02:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Kobayashi", "Masahiro", ""], ["Watanabe", "Kazuho", ""]]}, {"id": "1901.11332", "submitter": "Victoria Mingote Bueno", "authors": "Victoria Mingote, Antonio Miguel, Alfonso Ortega, Eduardo Lleida", "title": "Optimization of the Area Under the ROC Curve using Neural Network\n  Supervectors for Text-Dependent Speaker Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores two techniques to improve the performance of\ntext-dependent speaker verification systems based on deep neural networks.\nFirstly, we propose a general alignment mechanism to keep the temporal\nstructure of each phrase and obtain a supervector with the speaker and phrase\ninformation, since both are relevant for a text-dependent verification. As we\nshow, it is possible to use different alignment techniques to replace the\nglobal average pooling providing significant gains in performance. Moreover, we\nalso present a novel back-end approach to train a neural network for detection\ntasks by optimizing the Area Under the Curve (AUC) as an alternative to the\nusual triplet loss function, so the system is end-to-end, with a cost function\nclose to our desired measure of performance. As we can see in the experimental\nsection, this approach improves the system performance, since our triplet\nneural network based on an approximation of the AUC (aAUC) learns how to\ndiscriminate between pairs of examples from the same identity and pairs of\ndifferent identities. The different alignment techniques to produce\nsupervectors in addition to the new back-end approach were tested on the\nRSR2015-Part I database for text-dependent speaker verification, providing\ncompetitive results compared to similar size networks using the global average\npooling to extract supervectors and using a simple back-end or triplet loss\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 12:37:57 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 14:41:41 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Mingote", "Victoria", ""], ["Miguel", "Antonio", ""], ["Ortega", "Alfonso", ""], ["Lleida", "Eduardo", ""]]}, {"id": "1901.11351", "submitter": "Taira Tsuchiya", "authors": "Taira Tsuchiya, Nontawat Charoenphakdee, Issei Sato, Masashi Sugiyama", "title": "Semi-Supervised Ordinal Regression Based on Empirical Risk Minimization", "comments": "38 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal regression is aimed at predicting an ordinal class label. In this\npaper, we consider its semi-supervised formulation, in which we have unlabeled\ndata along with ordinal-labeled data to train an ordinal regressor. There are\nseveral metrics to evaluate the performance of ordinal regression, such as the\nmean absolute error, mean zero-one error, and mean squared error. However, the\nexisting studies do not take the evaluation metric into account, have a\nrestriction on the model choice, and have no theoretical guarantee. To overcome\nthese problems, we propose a novel generic framework for semi-supervised\nordinal regression based on the empirical risk minimization principle that is\napplicable to optimizing all of the metrics mentioned above. Besides, our\nframework has flexible choices of models, surrogate losses, and optimization\nalgorithms without the common geometric assumption on unlabeled data such as\nthe cluster assumption or manifold assumption. We further provide an estimation\nerror bound to show that our risk estimator is consistent. Finally, we conduct\nexperiments to show the usefulness of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 13:38:00 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 10:32:46 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 12:44:47 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Tsuchiya", "Taira", ""], ["Charoenphakdee", "Nontawat", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1901.11352", "submitter": "Jaweria Amjad", "authors": "Jaweria Amjad, Zhaoyan Lyu, Miguel R. D. Rodrigues", "title": "Deep Learning for Inverse Problems: Bounds and Regularizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems arise in a number of domains such as medical imaging, remote\nsensing, and many more, relying on the use of advanced signal and image\nprocessing approaches -- such as sparsity-driven techniques -- to determine\ntheir solution. This paper instead studies the use of deep learning approaches\nto approximate the solution of inverse problems. In particular, the paper\nprovides a new generalization bound, depending on key quantity associated with\na deep neural network -- its Jacobian matrix -- that also leads to a number of\ncomputationally efficient regularization strategies applicable to inverse\nproblems. The paper also tests the proposed regularization strategies in a\nnumber of inverse problems including image super-resolution ones. Our numerical\nresults conducted on various datasets show that both fully connected and\nconvolutional neural networks regularized using the regularization or proxy\nregularization strategies originating from our theory exhibit much better\nperformance than deep networks regularized with standard approaches such as\nweight-decay.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 13:39:47 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Amjad", "Jaweria", ""], ["Lyu", "Zhaoyan", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "1901.11356", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Jonathan Schwarz, Alexander G. de G. Matthews,\n  Razvan Pascanu, Yee Whye Teh", "title": "Functional Regularisation for Continual Learning with Gaussian Processes", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for Continual Learning (CL) based on Bayesian\ninference over the function space rather than the parameters of a deep neural\nnetwork. This method, referred to as functional regularisation for Continual\nLearning, avoids forgetting a previous task by constructing and memorising an\napproximate posterior belief over the underlying task-specific function. To\nachieve this we rely on a Gaussian process obtained by treating the weights of\nthe last layer of a neural network as random and Gaussian distributed. Then,\nthe training algorithm sequentially encounters tasks and constructs posterior\nbeliefs over the task-specific functions by using inducing point sparse\nGaussian process methods. At each step a new task is first learnt and then a\nsummary is constructed consisting of (i) inducing inputs -- a fixed-size subset\nof the task inputs selected such that it optimally represents the task -- and\n(ii) a posterior distribution over the function values at these inputs. This\nsummary then regularises learning of future tasks, through Kullback-Leibler\nregularisation terms. Our method thus unites approaches focused on\n(pseudo-)rehearsal with those derived from a sequential Bayesian inference\nperspective in a principled way, leading to strong results on accepted\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 13:51:27 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 17:49:51 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 14:06:46 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 16:05:28 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Schwarz", "Jonathan", ""], ["Matthews", "Alexander G. de G.", ""], ["Pascanu", "Razvan", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1901.11365", "submitter": "Joshua Batson", "authors": "Joshua Batson, Loic Royer", "title": "Noise2Self: Blind Denoising by Self-Supervision", "comments": "10 pages, 6 figures, and supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for denoising high-dimensional measurements\nwhich requires no prior on the signal, no estimate of the noise, and no clean\ntraining data. The only assumption is that the noise exhibits statistical\nindependence across different dimensions of the measurement, while the true\nsignal exhibits some correlation. For a broad class of functions\n(\"$\\mathcal{J}$-invariant\"), it is then possible to estimate the performance of\na denoiser from noisy data alone. This allows us to calibrate\n$\\mathcal{J}$-invariant versions of any parameterised denoising algorithm, from\nthe single hyperparameter of a median filter to the millions of weights of a\ndeep neural network. We demonstrate this on natural image and microscopy data,\nwhere we exploit noise independence between pixels, and on single-cell gene\nexpression data, where we exploit independence between detections of individual\nmolecules. This framework generalizes recent work on training neural nets from\nnoisy images and on cross-validation for matrix factorization.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 18:05:47 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 23:46:25 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Batson", "Joshua", ""], ["Royer", "Loic", ""]]}, {"id": "1901.11373", "submitter": "Dani Yogatama", "authors": "Dani Yogatama, Cyprien de Masson d'Autume, Jerome Connor, Tomas\n  Kocisky, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei\n  Yu, Chris Dyer, Phil Blunsom", "title": "Learning and Evaluating General Linguistic Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define general linguistic intelligence as the ability to reuse previously\nacquired knowledge about a language's lexicon, syntax, semantics, and pragmatic\nconventions to adapt to new tasks quickly. Using this definition, we analyze\nstate-of-the-art natural language understanding models and conduct an extensive\nempirical investigation to evaluate them against these criteria through a\nseries of experiments that assess the task-independence of the knowledge being\nacquired by the learning process. In addition to task performance, we propose a\nnew evaluation metric based on an online encoding of the test data that\nquantifies how quickly an existing agent (model) learns a new task. Our results\nshow that while the field has made impressive progress in terms of model\narchitectures that generalize to many tasks, these models still require a lot\nof in-domain training examples (e.g., for fine tuning, training task-specific\nmodules), and are prone to catastrophic forgetting. Moreover, we find that far\nfrom solving general tasks (e.g., document question answering), our models are\noverfitting to the quirks of particular datasets (e.g., SQuAD). We discuss\nmissing components and conjecture on how to make progress toward general\nlinguistic intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 14:29:35 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Yogatama", "Dani", ""], ["d'Autume", "Cyprien de Masson", ""], ["Connor", "Jerome", ""], ["Kocisky", "Tomas", ""], ["Chrzanowski", "Mike", ""], ["Kong", "Lingpeng", ""], ["Lazaridou", "Angeliki", ""], ["Ling", "Wang", ""], ["Yu", "Lei", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""]]}, {"id": "1901.11379", "submitter": "Yijun Tian", "authors": "Yijun Tian", "title": "TUNet: Incorporating segmentation maps to improve classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the localization of specific protein in human cells is important\nfor understanding cellular functions and biological processes of underlying\ndiseases. Among imaging techniques, high-throughput fluorescence microscopy\nimaging is an efficient biotechnology to stain the protein of interest in a\ncell. In this work, we present a novel classification model Twin U-Net (TUNet)\nfor processing and classifying the belonging of protein in the Atlas images.\nSeveral notable Deep Learning models including GoogleNet and Resnet have been\nemployed for comparison. Results have shown that our system obtaining\ncompetitive performance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 23:58:03 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Tian", "Yijun", ""]]}, {"id": "1901.11384", "submitter": "Isabela Maria Carneiro de Albuquerque", "authors": "Isabela Albuquerque, Jo\\~ao Monteiro, Tiago H. Falk", "title": "Learning to navigate image manifolds induced by generative adversarial\n  networks for unsupervised video generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a two-step framework for generative modeling of\ntemporal data. Specifically, the generative adversarial networks (GANs) setting\nis employed to generate synthetic scenes of moving objects. To do so, we\npropose a two-step training scheme within which: a generator of static frames\nis trained first. Afterwards, a recurrent model is trained with the goal of\nproviding a sequence of inputs to the previously trained frames generator, thus\nyielding scenes which look natural. The adversarial setting is employed in both\ntraining steps. However, with the aim of avoiding known training instabilities\nin GANs, a multiple discriminator approach is used to train both models.\nResults in the studied video dataset indicate that, by employing such an\napproach, the recurrent part is able to learn how to coherently navigate the\nimage manifold induced by the frames generator, thus yielding more\nnatural-looking scenes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 23:21:08 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Albuquerque", "Isabela", ""], ["Monteiro", "Jo\u00e3o", ""], ["Falk", "Tiago H.", ""]]}, {"id": "1901.11390", "submitter": "Christopher Burgess", "authors": "Christopher P. Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra,\n  Irina Higgins, Matt Botvinick, Alexander Lerchner", "title": "MONet: Unsupervised Scene Decomposition and Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to decompose scenes in terms of abstract building blocks is\ncrucial for general intelligence. Where those basic building blocks share\nmeaningful properties, interactions and other regularities across scenes, such\ndecompositions can simplify reasoning and facilitate imagination of novel\nscenarios. In particular, representing perceptual observations in terms of\nentities should improve data efficiency and transfer performance on a wide\nrange of tasks. Thus we need models capable of discovering useful\ndecompositions of scenes by identifying units with such regularities and\nrepresenting them in a common format. To address this problem, we have\ndeveloped the Multi-Object Network (MONet). In this model, a VAE is trained\nend-to-end together with a recurrent attention network -- in a purely\nunsupervised manner -- to provide attention masks around, and reconstructions\nof, regions of images. We show that this model is capable of learning to\ndecompose and represent challenging 3D scenes into semantically meaningful\ncomponents, such as objects and background elements.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 18:55:34 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Burgess", "Christopher P.", ""], ["Matthey", "Loic", ""], ["Watters", "Nicholas", ""], ["Kabra", "Rishabh", ""], ["Higgins", "Irina", ""], ["Botvinick", "Matt", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1901.11397", "submitter": "Abby Stylianou", "authors": "Abby Stylianou, Hong Xuan, Maya Shende, Jonathan Brandt, Richard\n  Souvenir, Robert Pless", "title": "Hotels-50K: A Global Hotel Recognition Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing a hotel from an image of a hotel room is important for human\ntrafficking investigations. Images directly link victims to places and can help\nverify where victims have been trafficked, and where their traffickers might\nmove them or others in the future. Recognizing the hotel from images is\nchallenging because of low image quality, uncommon camera perspectives, large\nocclusions (often the victim), and the similarity of objects (e.g., furniture,\nart, bedding) across different hotel rooms.\n  To support efforts towards this hotel recognition task, we have curated a\ndataset of over 1 million annotated hotel room images from 50,000 hotels. These\nimages include professionally captured photographs from travel websites and\ncrowd-sourced images from a mobile application, which are more similar to the\ntypes of images analyzed in real-world investigations. We present a baseline\napproach based on a standard network architecture and a collection of\ndata-augmentation approaches tuned to this problem domain.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 22:22:46 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Stylianou", "Abby", ""], ["Xuan", "Hong", ""], ["Shende", "Maya", ""], ["Brandt", "Jonathan", ""], ["Souvenir", "Richard", ""], ["Pless", "Robert", ""]]}, {"id": "1901.11399", "submitter": "Kai Sheng Tai", "authors": "Kai Sheng Tai, Peter Bailis, Gregory Valiant", "title": "Equivariant Transformer Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can prior knowledge on the transformation invariances of a domain be\nincorporated into the architecture of a neural network? We propose Equivariant\nTransformers (ETs), a family of differentiable image-to-image mappings that\nimprove the robustness of models towards pre-defined continuous transformation\ngroups. Through the use of specially-derived canonical coordinate systems, ETs\nincorporate functions that are equivariant by construction with respect to\nthese transformations. We show empirically that ETs can be flexibly composed to\nimprove model robustness towards more complicated transformation groups in\nseveral parameters. On a real-world image classification task, ETs improve the\nsample efficiency of ResNet classifiers, achieving relative improvements in\nerror rate of up to 15% in the limited data regime while increasing model\nparameter count by less than 1%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:29:48 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 20:36:43 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tai", "Kai Sheng", ""], ["Bailis", "Peter", ""], ["Valiant", "Gregory", ""]]}, {"id": "1901.11409", "submitter": "Vighnesh Birodkar", "authors": "Vighnesh Birodkar, Hossein Mobahi, Samy Bengio", "title": "Semantic Redundancies in Image-Classification Datasets: The 10% You\n  Don't Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large datasets have been crucial to the success of deep learning models in\nthe recent years, which keep performing better as they are trained with more\nlabelled data. While there have been sustained efforts to make these models\nmore data-efficient, the potential benefit of understanding the data itself, is\nlargely untapped. Specifically, focusing on object recognition tasks, we wonder\nif for common benchmark datasets we can do better than random subsets of the\ndata and find a subset that can generalize on par with the full dataset when\ntrained on. To our knowledge, this is the first result that can find notable\nredundancies in CIFAR-10 and ImageNet datasets (at least 10%). Interestingly,\nwe observe semantic correlations between required and redundant images. We hope\nthat our findings can motivate further research into identifying additional\nredundancies and exploiting them for more efficient training or\ndata-collection.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 18:27:37 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Birodkar", "Vighnesh", ""], ["Mobahi", "Hossein", ""], ["Bengio", "Samy", ""]]}, {"id": "1901.11417", "submitter": "Michalis Michaelides", "authors": "Michalis Michaelides, Jane Hillston, Guido Sanguinetti", "title": "Geometric fluid approximation for general continuous-time Markov chains", "comments": null, "journal-ref": "Proc. R. Soc. A 475:2229 (2019)", "doi": "10.1098/rspa.2019.0100", "report-no": null, "categories": "eess.SY cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluid approximations have seen great success in approximating the macro-scale\nbehaviour of Markov systems with a large number of discrete states. However,\nthese methods rely on the continuous-time Markov chain (CTMC) having a\nparticular population structure which suggests a natural continuous state-space\nendowed with a dynamics for the approximating process. We construct here a\ngeneral method based on spectral analysis of the transition matrix of the CTMC,\nwithout the need for a population structure. Specifically, we use the popular\nmanifold learning method of diffusion maps to analyse the transition matrix as\nthe operator of a hidden continuous process. An embedding of states in a\ncontinuous space is recovered, and the space is endowed with a drift vector\nfield inferred via Gaussian process regression. In this manner, we construct an\nODE whose solution approximates the evolution of the CTMC mean, mapped onto the\ncontinuous space (known as the fluid limit).\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:12:59 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 17:49:32 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Michaelides", "Michalis", ""], ["Hillston", "Jane", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1901.11418", "submitter": "Weisi Guo", "authors": "Zhuangkun Wei, Bin Li, Weisi Guo, Wenxiu Hu, Chenglin Zhao", "title": "Sequential Bayesian Detection of Spike Activities from Fluorescence\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting and detecting spike activities from the fluorescence observations\nis an important step in understanding how neuron systems work. The main\nchallenge lies in that the combination of the ambient noise with dynamic\nbaseline fluctuation, often contaminates the observations, thereby\ndeteriorating the reliability of spike detection. This may be even worse in the\nface of the nonlinear biological process, the coupling interactions between\nspikes and baseline, and the unknown critical parameters of an underlying\nphysiological model, in which erroneous estimations of parameters will affect\nthe detection of spikes causing further error propagation. In this paper, we\npropose a random finite set (RFS) based Bayesian approach. The dynamic\nbehaviors of spike sequence, fluctuated baseline and unknown parameters are\nformulated as one RFS. This RFS state is capable of distinguishing the hidden\nactive/silent states induced by spike and non-spike activities respectively,\nthereby \\emph{negating the interaction role} played by spikes and other\nfactors. Then, premised on the RFS states, a Bayesian inference scheme is\ndesigned to simultaneously estimate the model parameters, baseline, and crucial\nspike activities. Our results demonstrate that the proposed scheme can gain an\nextra $12\\%$ detection accuracy in comparison with the state-of-the-art MLSpike\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:14:28 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Wei", "Zhuangkun", ""], ["Li", "Bin", ""], ["Guo", "Weisi", ""], ["Hu", "Wenxiu", ""], ["Zhao", "Chenglin", ""]]}, {"id": "1901.11422", "submitter": "Weisi Guo", "authors": "Zhuangkun Wei, Weisi Guo, Bin Li, Jerome Charmet, Chenglin Zhao", "title": "High-dimensional Metric Combining for Non-coherent Molecular Signal\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In emerging Internet-of-Nano-Thing (IoNT), information will be embedded and\nconveyed in the form of molecules through complex and diffusive medias. One\nmain challenge lies in the long-tail nature of the channel response causing\ninter-symbol-interference (ISI), which deteriorates the detection performance.\nIf the channel is unknown, we cannot easily achieve traditional coherent\nchannel estimation and cancellation, and the impact of ISI will be more severe.\nIn this paper, we develop a novel high-dimensional non-coherent scheme for\nblind detection of molecular signals. We achieve this in a higher-dimensional\nmetric space by combining different non-coherent metrics that exploit the\ntransient features of the signals. By deducing the theoretical bit error rate\n(BER) for any constructed high-dimensional non-coherent metric, we prove that,\nhigher dimensionality always achieves a lower BER in the same sample space.\nThen, we design a generalised blind detection algorithm that utilizes the\nParzen approximation and its probabilistic neural network (Parzen-PNN) to\ndetect information bits. Taking advantages of its fast convergence and parallel\nimplementation, our proposed scheme can meet the needs of detection accuracy\nand real-time computing. Numerical simulations demonstrate that our proposed\nscheme can gain 10dB BER compared with other state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:20:43 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Wei", "Zhuangkun", ""], ["Guo", "Weisi", ""], ["Li", "Bin", ""], ["Charmet", "Jerome", ""], ["Zhao", "Chenglin", ""]]}, {"id": "1901.11436", "submitter": "William Wilkinson", "authors": "William J. Wilkinson, Michael Riis Andersen, Joshua D. Reiss, Dan\n  Stowell, Arno Solin", "title": "End-to-End Probabilistic Inference for Nonstationary Audio Analysis", "comments": "Accepted to the Thirty-sixth International Conference on Machine\n  Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical audio signal processing pipeline includes multiple disjoint\nanalysis stages, including calculation of a time-frequency representation\nfollowed by spectrogram-based feature analysis. We show how time-frequency\nanalysis and nonnegative matrix factorisation can be jointly formulated as a\nspectral mixture Gaussian process model with nonstationary priors over the\namplitude variance parameters. Further, we formulate this nonlinear model's\nstate space representation, making it amenable to infinite-horizon Gaussian\nprocess regression with approximate inference via expectation propagation,\nwhich scales linearly in the number of time steps and quadratically in the\nstate dimensionality. By doing so, we are able to process audio signals with\nhundreds of thousands of data points. We demonstrate, on various tasks with\nempirical data, how this inference scheme outperforms more standard techniques\nthat rely on extended Kalman filtering.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:47:47 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 14:40:07 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 17:59:11 GMT"}, {"version": "v4", "created": "Tue, 23 Apr 2019 15:49:36 GMT"}, {"version": "v5", "created": "Sat, 27 Apr 2019 11:47:55 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wilkinson", "William J.", ""], ["Andersen", "Michael Riis", ""], ["Reiss", "Joshua D.", ""], ["Stowell", "Dan", ""], ["Solin", "Arno", ""]]}, {"id": "1901.11440", "submitter": "Garrett Goodman", "authors": "William Romine, Tanvi Banerjee, Garrett Goodman", "title": "Toward Sensor-based Sleep Monitoring with Electrodermal Activity\n  Measures", "comments": "9 pages, 1 figure, 1 table, journal", "journal-ref": "Sensors 2019, 19(6), 1417", "doi": "10.3390/s19061417", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use self-report and electrodermal activity (EDA) wearable sensor data from\n77 nights of sleep on six participants to test the efficacy of EDA data for\nsleep monitoring. We used factor analysis to find latent factors in the EDA\ndata, and causal model search to find the most probable graphical model\naccounting for self-reported sleep efficiency (SE), sleep quality (SQ), and the\nlatent EDA factors. Structural equation modeling was used to confirm fit of the\nextracted graph. Based on the generated graph, logistic regression and naive\nBayes models were used to test the efficacy of the EDA data in predicting SE\nand SQ. Six EDA features extracted from the total signal over a night's sleep\ncould be explained by two latent factors, EDA Magnitude and EDA Storms. EDA\nMagnitude performed as a strong predictor for SE to aid detection of\nsubstantial changes in time asleep. The performance of EDA Magnitured and SE in\nclassifying SQ showed promise for wearable sleep monitoring applications.\nHowever, our data suggest that obtaining a more accurate sensor-based measure\nof SE will be necessary before smaller changes in SQ can be detected from EDA\nsensor data alone.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:00:32 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Romine", "William", ""], ["Banerjee", "Tanvi", ""], ["Goodman", "Garrett", ""]]}, {"id": "1901.11448", "submitter": "Wei Zhou", "authors": "Yiying Li, Yongxin Yang, Wei Zhou and Timothy M. Hospedales", "title": "Feature-Critic Networks for Heterogeneous Domain Generalization", "comments": "Presented at ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, Long Beach, California, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well known domain shift issue causes model performance to degrade when\ndeployed to a new target domain with different statistics to training. Domain\nadaptation techniques alleviate this, but need some instances from the target\ndomain to drive adaptation. Domain generalisation is the recently topical\nproblem of learning a model that generalises to unseen domains out of the box,\nand various approaches aim to train a domain-invariant feature extractor,\ntypically by adding some manually designed losses. In this work, we propose a\nlearning to learn approach, where the auxiliary loss that helps generalisation\nis itself learned. Beyond conventional domain generalisation, we consider a\nmore challenging setting of heterogeneous domain generalisation, where the\nunseen domains do not share label space with the seen ones, and the goal is to\ntrain a feature representation that is useful off-the-shelf for novel data and\nnovel categories. Experimental evaluation demonstrates that our method\noutperforms state-of-the-art solutions in both settings.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:08:09 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 02:02:54 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 04:59:40 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Li", "Yiying", ""], ["Yang", "Yongxin", ""], ["Zhou", "Wei", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1901.11457", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Improving SGD convergence by online linear regression of gradients in\n  multiple statistically relevant directions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are usually trained with stochastic gradient descent\n(SGD), which minimizes objective function using very rough approximations of\ngradient, only averaging to the real gradient. Standard approaches like\nmomentum or ADAM only consider a single direction, and do not try to model\ndistance from extremum - neglecting valuable information from calculated\nsequence of gradients, often stagnating in some suboptimal plateau. Second\norder methods could exploit these missed opportunities, however, beside\nsuffering from very large cost and numerical instabilities, many of them\nattract to suboptimal points like saddles due to negligence of signs of\ncurvatures (as eigenvalues of Hessian).\n  Saddle-free Newton method (SFN)~\\cite{SFN} is a rare example of addressing\nthis issue - changes saddle attraction into repulsion, and was shown to provide\nessential improvement for final value this way. However, it neglects noise\nwhile modelling second order behavior, focuses on Krylov subspace for numerical\nreasons, and requires costly eigendecomposion.\n  Maintaining SFN advantages, there are proposed inexpensive ways for\nexploiting these opportunities. Second order behavior is linear dependence of\nfirst derivative - we can optimally estimate it from sequence of noisy\ngradients with least square linear regression, in online setting here: with\nweakening weights of old gradients. Statistically relevant subspace is\nsuggested by PCA of recent noisy gradients - in online setting it can be made\nby slowly rotating considered directions toward new gradients, gradually\nreplacing old directions with recent statistically relevant. Eigendecomposition\ncan be also performed online: with regularly performed step of QR method to\nmaintain diagonal Hessian. Outside the second order modeled subspace we can\nsimultaneously perform gradient descent.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:30:41 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 10:04:16 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 15:07:30 GMT"}, {"version": "v4", "created": "Wed, 10 Apr 2019 16:07:25 GMT"}, {"version": "v5", "created": "Sun, 14 Apr 2019 14:16:15 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1901.11458", "submitter": "Jayadeva", "authors": "Mayank Sharma, Aayush Yadav, Sumit Soman, Jayadeva", "title": "Effect of Various Regularizers on Model Complexities of Neural Networks\n  in Presence of Input Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are over-parameterized, which implies that the number of\nparameters are much larger than the number of samples used to train the\nnetwork. Even in such a regime deep architectures do not overfit. This\nphenomenon is an active area of research and many theories have been proposed\ntrying to understand this peculiar observation. These include the Vapnik\nChervonenkis (VC) dimension bounds and Rademacher complexity bounds which show\nthat the capacity of the network is characterized by the norm of weights rather\nthan the number of parameters. However, the effect of input noise on these\nmeasures for shallow and deep architectures has not been studied. In this\npaper, we analyze the effects of various regularization schemes on the\ncomplexity of a neural network which we characterize with the loss, $L_2$ norm\nof the weights, Rademacher complexities (Directly Approximately Regularizing\nComplexity-DARC1), VC dimension based Low Complexity Neural Network (LCNN) when\nsubject to varying degrees of Gaussian input noise. We show that $L_2$\nregularization leads to a simpler hypothesis class and better generalization\nfollowed by DARC1 regularizer, both for shallow as well as deeper\narchitectures. Jacobian regularizer works well for shallow architectures with\nhigh level of input noises. Spectral normalization attains highest test set\naccuracies both for shallow and deeper architectures. We also show that Dropout\nalone does not perform well in presence of input noise. Finally, we show that\ndeeper architectures are robust to input noise as opposed to their shallow\ncounterparts.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:31:30 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Sharma", "Mayank", ""], ["Yadav", "Aayush", ""], ["Soman", "Sumit", ""], ["Jayadeva", "", ""]]}, {"id": "1901.11459", "submitter": "Fabrizio Sebastiani", "authors": "Andrea Esuli, Alejandro Moreo, Fabrizio Sebastiani", "title": "Funnelling: A New Ensemble Method for Heterogeneous Transfer Learning\n  and its Application to Cross-Lingual Text Classification", "comments": "28 pages, 4 figures", "journal-ref": "Forthcoming in the ACM Transactions on Information Systems, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual Text Classification (CLC) consists of automatically\nclassifying, according to a common set C of classes, documents each written in\none of a set of languages L, and doing so more accurately than when naively\nclassifying each document via its corresponding language-specific classifier.\nIn order to obtain an increase in the classification accuracy for a given\nlanguage, the system thus needs to also leverage the training examples written\nin the other languages. We tackle multilabel CLC via funnelling, a new ensemble\nlearning method that we propose here. Funnelling consists of generating a\ntwo-tier classification system where all documents, irrespectively of language,\nare classified by the same (2nd-tier) classifier. For this classifier all\ndocuments are represented in a common, language-independent feature space\nconsisting of the posterior probabilities generated by 1st-tier,\nlanguage-dependent classifiers. This allows the classification of all test\ndocuments, of any language, to benefit from the information present in all\ntraining documents, of any language. We present substantial experiments, run on\npublicly available multilingual text collections, in which funnelling is shown\nto significantly outperform a number of state-of-the-art baselines. All code\nand datasets (in vector form) are made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:32:08 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 16:06:09 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Esuli", "Andrea", ""], ["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1901.11463", "submitter": "Sixie Yu", "authors": "Sixie Yu, Yevgeniy Vorobeychik", "title": "Distributionally Robust Removal of Malicious Nodes from Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in networked systems is detection and removal of\nsuspected malicious nodes. A crucial consideration in such settings is the\nuncertainty endemic in detection, coupled with considerations of network\nconnectivity, which impose indirect costs from mistakely removing benign nodes\nas well as failing to remove malicious nodes. A recent approach proposed to\naddress this problem directly tackles these considerations, but has a\nsignificant limitation: it assumes that the decision maker has accurate\nknowledge of the joint maliciousness probability of the nodes on the network.\nThis is clearly not the case in practice, where such a distribution is at best\nan estimate from limited evidence. To address this problem, we propose a\ndistributionally robust framework for optimal node removal. While the problem\nis NP-Hard, we propose a principled algorithmic technique for solving it\napproximately based on duality combined with Semidefinite Programming\nrelaxation. A combination of both theoretical and empirical analysis, the\nlatter using both synthetic and real data, provide strong evidence that our\nalgorithmic approach is highly effective and, in particular, is significantly\nmore robust than the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:40:27 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Yu", "Sixie", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1901.11478", "submitter": "Francesco Foglino", "authors": "Francesco Foglino, Christiano Coletto Christakou, Matteo Leonetti", "title": "An Optimization Framework for Task Sequencing in Curriculum Learning", "comments": "Proceedings of 9th Joint IEEE International Conference on Development\n  and Learning and on Epigenetic Robotics (ICDL-EpiRob)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning in reinforcement learning is used to shape exploration by\npresenting the agent with increasingly complex tasks. The idea of curriculum\nlearning has been largely applied in both animal training and pedagogy. In\nreinforcement learning, all previous task sequencing methods have shaped\nexploration with the objective of reducing the time to reach a given\nperformance level. We propose novel uses of curriculum learning, which arise\nfrom choosing different objective functions. Furthermore, we define a general\noptimization framework for task sequencing and evaluate the performance of\npopular metaheuristic search methods on several tasks. We show that curriculum\nlearning can be successfully used to: improve the initial performance, take\nfewer suboptimal actions during exploration, and discover better policies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 17:08:27 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 13:50:49 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 14:56:44 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Foglino", "Francesco", ""], ["Christakou", "Christiano Coletto", ""], ["Leonetti", "Matteo", ""]]}, {"id": "1901.11492", "submitter": "Quanshi Zhang", "authors": "Kushal Chawla, Kundan Krishna, Balaji Vasan Srinivasan", "title": "Improving generation quality of pointer networks via guided attention", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointer generator networks have been used successfully for abstractive\nsummarization. Along with the capability to generate novel words, it also\nallows the model to copy from the input text to handle out-of-vocabulary words.\nIn this paper, we point out two key shortcomings of the summaries generated\nwith this framework via manual inspection, statistical analysis and human\nevaluation. The first shortcoming is the extractive nature of the generated\nsummaries, since the network eventually learns to copy from the input article\nmost of the times, affecting the abstractive nature of the generated summaries.\nThe second shortcoming is the factual inaccuracies in the generated text\ndespite grammatical correctness. Our analysis indicates that this arises due to\nincorrect attention transition between different parts of the article. We\npropose an initial attempt towards addressing both these shortcomings by\nexternally appending traditional linguistic information parsed from the input\ntext, thereby teaching networks on the structure of the underlying text.\nResults indicate feasibility and potential of such additional cues for improved\ngeneration.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:50:58 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Chawla", "Kushal", ""], ["Krishna", "Kundan", ""], ["Srinivasan", "Balaji Vasan", ""]]}, {"id": "1901.11503", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, Wen Sun, J. Andrew Bagnell", "title": "Contrasting Exploration in Parameter and Action Space: A Zeroth-Order\n  Optimization Perspective", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box optimizers that explore in parameter space have often been shown to\noutperform more sophisticated action space exploration methods developed\nspecifically for the reinforcement learning problem. We examine these black-box\nmethods closely to identify situations in which they are worse than action\nspace exploration methods and those in which they are superior. Through simple\ntheoretical analyses, we prove that complexity of exploration in parameter\nspace depends on the dimensionality of parameter space, while complexity of\nexploration in action space depends on both the dimensionality of action space\nand horizon length. This is also demonstrated empirically by comparing simple\nexploration methods on several model problems, including Contextual Bandit,\nLinear Regression and Reinforcement Learning in continuous control.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:05:05 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Vemula", "Anirudh", ""], ["Sun", "Wen", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1901.11512", "submitter": "Raed Al Kontar", "authors": "Raed Kontar, Garvesh Raskutti, Shiyu Zhou", "title": "Minimizing Negative Transfer of Knowledge in Multivariate Gaussian\n  Processes: A Scalable and Regularized Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increasing interest in the multivariate Gaussian\nprocess (MGP) which extends the Gaussian process (GP) to deal with multiple\noutputs. One approach to construct the MGP and account for non-trivial\ncommonalities amongst outputs employs a convolution process (CP). The CP is\nbased on the idea of sharing latent functions across several convolutions.\nDespite the elegance of the CP construction, it provides new challenges that\nneed yet to be tackled. First, even with a moderate number of outputs, model\nbuilding is extremely prohibitive due to the huge increase in computational\ndemands and number of parameters to be estimated. Second, the negative transfer\nof knowledge may occur when some outputs do not share commonalities. In this\npaper we address these issues. We propose a regularized pairwise modeling\napproach for the MGP established using CP. The key feature of our approach is\nto distribute the estimation of the full multivariate model into a group of\nbivariate GPs which are individually built. Interestingly pairwise modeling\nturns out to possess unique characteristics, which allows us to tackle the\nchallenge of negative transfer through penalizing the latent function that\nfacilitates information sharing in each bivariate model. Predictions are then\nmade through combining predictions from the bivariate models within a Bayesian\nframework. The proposed method has excellent scalability when the number of\noutputs is large and minimizes the negative transfer of knowledge between\nuncorrelated outputs. Statistical guarantees for the proposed method are\nstudied and its advantageous features are demonstrated through numerical\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:29:16 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 17:02:23 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kontar", "Raed", ""], ["Raskutti", "Garvesh", ""], ["Zhou", "Shiyu", ""]]}, {"id": "1901.11515", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Kirthevasan Kandasamy, Barnabas Poczos, Jeff\n  Schneider, Eric Xing", "title": "ProBO: Versatile Bayesian Optimization Using Any Probabilistic\n  Programming Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing an expensive-to-query function is a common task in science and\nengineering, where it is beneficial to keep the number of queries to a minimum.\nA popular strategy is Bayesian optimization (BO), which leverages probabilistic\nmodels for this task. Most BO today uses Gaussian processes (GPs), or a few\nother surrogate models. However, there is a broad set of Bayesian modeling\ntechniques that could be used to capture complex systems and reduce the number\nof queries in BO. Probabilistic programming languages (PPLs) are modern tools\nthat allow for flexible model definition, prior specification, model\ncomposition, and automatic inference. In this paper, we develop ProBO, a BO\nprocedure that uses only standard operations common to most PPLs. This allows a\nuser to drop in a model built with an arbitrary PPL and use it directly in BO.\nWe describe acquisition functions for ProBO, and strategies for efficiently\noptimizing these functions given complex models or costly inference procedures.\nUsing existing PPLs, we implement new models to aid in a few challenging\noptimization settings, and demonstrate these on model hyperparameter and\narchitecture search tasks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:35:56 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 17:49:10 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Neiswanger", "Willie", ""], ["Kandasamy", "Kirthevasan", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""], ["Xing", "Eric", ""]]}, {"id": "1901.11518", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Quanquan Gu", "title": "Stochastic Recursive Variance-Reduced Cubic Regularization Methods", "comments": "34 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Variance-Reduced Cubic regularization (SVRC) algorithms have\nreceived increasing attention due to its improved gradient/Hessian complexities\n(i.e., number of queries to stochastic gradient/Hessian oracles) to find local\nminima for nonconvex finite-sum optimization. However, it is unclear whether\nexisting SVRC algorithms can be further improved. Moreover, the semi-stochastic\nHessian estimator adopted in existing SVRC algorithms prevents the use of\nHessian-vector product-based fast cubic subproblem solvers, which makes SVRC\nalgorithms computationally intractable for high-dimensional problems. In this\npaper, we first present a Stochastic Recursive Variance-Reduced Cubic\nregularization method (SRVRC) using a recursively updated semi-stochastic\ngradient and Hessian estimators. It enjoys improved gradient and Hessian\ncomplexities to find an $(\\epsilon, \\sqrt{\\epsilon})$-approximate local\nminimum, and outperforms the state-of-the-art SVRC algorithms. Built upon\nSRVRC, we further propose a Hessian-free SRVRC algorithm, namely\nSRVRC$_{\\text{free}}$, which only requires stochastic gradient and\nHessian-vector product computations, and achieves $\\tilde O(dn\\epsilon^{-2}\n\\land d\\epsilon^{-3})$ runtime complexity, where $n$ is the number of component\nfunctions in the finite-sum structure, $d$ is the problem dimension, and\n$\\epsilon$ is the optimization precision. This outperforms the best-known\nruntime complexity $\\tilde O(d\\epsilon^{-3.5})$ achieved by stochastic cubic\nregularization algorithm proposed in Tripuraneni et al. 2018.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:40:48 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:32:04 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "1901.11524", "submitter": "Robert Dadashi", "authors": "Robert Dadashi, Adrien Ali Ta\\\"iga, Nicolas Le Roux, Dale Schuurmans,\n  Marc G. Bellemare", "title": "The Value Function Polytope in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish geometric and topological properties of the space of value\nfunctions in finite state-action Markov decision processes. Our main\ncontribution is the characterization of the nature of its shape: a general\npolytope (Aigner et al., 2010). To demonstrate this result, we exhibit several\nproperties of the structural relationship between policies and value functions\nincluding the line theorem, which shows that the value functions of policies\nconstrained on all but one state describe a line segment. Finally, we use this\nnovel perspective to introduce visualizations to enhance the understanding of\nthe dynamics of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:45:04 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 17:47:59 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 18:22:34 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dadashi", "Robert", ""], ["Ta\u00efga", "Adrien Ali", ""], ["Roux", "Nicolas Le", ""], ["Schuurmans", "Dale", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1901.11530", "submitter": "Marc G. Bellemare", "authors": "Marc G. Bellemare, Will Dabney, Robert Dadashi, Adrien Ali Taiga,\n  Pablo Samuel Castro, Nicolas Le Roux, Dale Schuurmans, Tor Lattimore, Clare\n  Lyle", "title": "A Geometric Perspective on Optimal Representations for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new perspective on representation learning in reinforcement\nlearning based on geometric properties of the space of value functions. We\nleverage this perspective to provide formal evidence regarding the usefulness\nof value functions as auxiliary tasks. Our formulation considers adapting the\nrepresentation to minimize the (linear) approximation of the value function of\nall stationary policies for a given environment. We show that this optimization\nreduces to making accurate predictions regarding a special class of value\nfunctions which we call adversarial value functions (AVFs). We demonstrate that\nusing value functions as auxiliary tasks corresponds to an expected-error\nrelaxation of our formulation, with AVFs a natural candidate, and identify a\nclose relationship with proto-value functions (Mahadevan, 2005). We highlight\ncharacteristics of AVFs and their usefulness as auxiliary tasks in a series of\nexperiments on the four-room domain.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:52:40 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 00:35:07 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Bellemare", "Marc G.", ""], ["Dabney", "Will", ""], ["Dadashi", "Robert", ""], ["Taiga", "Adrien Ali", ""], ["Castro", "Pablo Samuel", ""], ["Roux", "Nicolas Le", ""], ["Schuurmans", "Dale", ""], ["Lattimore", "Tor", ""], ["Lyle", "Clare", ""]]}]