[{"id": "2003.00007", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Yan Han, Ahmed H Tewfik", "title": "Generating EEG features from Acoustic features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate predicting electroencephalograpgy (EEG) features\nfrom acoustic features using recurrent neural network (RNN) based regression\nmodel and generative adversarial network (GAN). We predict various types of EEG\nfeatures from acoustic features. We compare our results with the previously\nstudied problem on speech synthesis using EEG and our results demonstrate that\nEEG features can be generated from acoustic features with lower root mean\nsquare error (RMSE), normalized RMSE values compared to generating acoustic\nfeatures from EEG features (ie: speech synthesis using EEG) when tested using\nthe same data sets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 16:44:08 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 01:33:53 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Han", "Yan", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "2003.00009", "submitter": "Carlo Vittorio Cannistraci", "authors": "Yan Ge, Philipp Rosendahl, Claudio Dur\\'an, Nicole T\\\"opfner, Sara\n  Ciucci, Jochen Guck, and Carlo Vittorio Cannistraci", "title": "Cell Mechanics Based Computational Classification of Red Blood Cells Via\n  Machine Intelligence Applied to Morpho-Rheological Markers", "comments": "13 pages, 3 figures, 4 tables", "journal-ref": "IEEE/ACM Trans. Comput. Biol. Bioinform (2019)", "doi": "10.1109/TCBB.2019.2945762", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite fluorescent cell-labelling being widely employed in biomedical\nstudies, some of its drawbacks are inevitable, with unsuitable fluorescent\nprobes or probes inducing a functional change being the main limitations.\nConsequently, the demand for and development of label-free methodologies to\nclassify cells is strong and its impact on precision medicine is relevant.\nTowards this end, high-throughput techniques for cell mechanical phenotyping\nhave been proposed to get a multidimensional biophysical characterization of\nsingle cells. With this motivation, our goal here is to investigate the extent\nto which an unsupervised machine learning methodology, which is applied\nexclusively on morpho-rheological markers obtained by real-time deformability\nand fluorescence cytometry (RT-FDC), can address the difficult task of\nproviding label-free discrimination of reticulocytes from mature red blood\ncells. We focused on this problem, since the characterization of reticulocytes\n(their percentage and cellular features) in the blood is vital in multiple\nhuman disease conditions, especially bone-marrow disorders such as anemia and\nleukemia. Our approach reports promising label-free results in the\nclassification of reticulocytes from mature red blood cells, and it represents\na step forward in the development of high-throughput morpho-rheological-based\nmethodologies for the computational categorization of single cells. Besides,\nour methodology can be an alternative but also a complementary method to\nintegrate with existing cell-labelling techniques.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:11:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ge", "Yan", ""], ["Rosendahl", "Philipp", ""], ["Dur\u00e1n", "Claudio", ""], ["T\u00f6pfner", "Nicole", ""], ["Ciucci", "Sara", ""], ["Guck", "Jochen", ""], ["Cannistraci", "Carlo Vittorio", ""]]}, {"id": "2003.00040", "submitter": "Javier Carnerero-Cano", "authors": "Javier Carnerero-Cano, Luis Mu\\~noz-Gonz\\'alez, Phillippa Spencer and\n  Emil C. Lupu", "title": "Regularisation Can Mitigate Poisoning Attacks: A Novel Analysis Based on\n  Multiobjective Bilevel Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where a\nfraction of the training data is manipulated to deliberately degrade the\nalgorithms' performance. Optimal poisoning attacks, which can be formulated as\nbilevel optimisation problems, help to assess the robustness of learning\nalgorithms in worst-case scenarios. However, current attacks against algorithms\nwith hyperparameters typically assume that these hyperparameters remain\nconstant ignoring the effect the attack has on them. We show that this approach\nleads to an overly pessimistic view of the robustness of the algorithms. We\npropose a novel optimal attack formulation that considers the effect of the\nattack on the hyperparameters by modelling the attack as a multiobjective\nbilevel optimisation problem. We apply this novel attack formulation to ML\nclassifiers using $L_2$ regularisation and show that, in contrast to results\npreviously reported, $L_2$ regularisation enhances the stability of the\nlearning algorithms and helps to mitigate the attacks. Our empirical evaluation\non different datasets confirms the limitations of previous strategies,\nevidences the benefits of using $L_2$ regularisation to dampen the effect of\npoisoning attacks and shows how the regularisation hyperparameter increases\nwith the fraction of poisoning points.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 19:46:10 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 13:44:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Carnerero-Cano", "Javier", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Spencer", "Phillippa", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2003.00043", "submitter": "Irene Epifanio", "authors": "Ismael Cabero, Irene Epifanio", "title": "Finding archetypal patterns for binary questionnaires", "comments": null, "journal-ref": "SORT, 44(1): 39-66. 2020", "doi": "10.2436/20.8080.02.94", "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Archetypal analysis is an exploratory tool that explains a set of\nobservations as mixtures of pure (extreme) patterns. If the patterns are actual\nobservations of the sample, we refer to them as archetypoids. For the first\ntime, we propose to use archetypoid analysis for binary observations. This tool\ncan contribute to the understanding of a binary data set, as in the\nmultivariate case. We illustrate the advantages of the proposed methodology in\na simulation study and two applications, one exploring objects (rows) and the\nother exploring items (columns). One is related to determining student skill\nset profiles and the other to describing item response functions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 20:01:24 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Cabero", "Ismael", ""], ["Epifanio", "Irene", ""]]}, {"id": "2003.00063", "submitter": "Gustavo Assun\\c{c}\\~ao", "authors": "Gustavo Assun\\c{c}\\~ao, Nuno Gon\\c{c}alves, Paulo Menezes", "title": "Bio-Inspired Modality Fusion for Active Speaker Detection", "comments": null, "journal-ref": "Appl. Sci. 2021, 11(8), 3397", "doi": "10.3390/app11083397", "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human beings have developed fantastic abilities to integrate information from\nvarious sensory sources exploring their inherent complementarity. Perceptual\ncapabilities are therefore heightened, enabling, for instance, the well-known\n\"cocktail party\" and McGurk effects, i.e., speech disambiguation from a panoply\nof sound signals. This fusion ability is also key in refining the perception of\nsound source location, as in distinguishing whose voice is being heard in a\ngroup conversation. Furthermore, neuroscience has successfully identified the\nsuperior colliculus region in the brain as the one responsible for this\nmodality fusion, with a handful of biological models having been proposed to\napproach its underlying neurophysiological process. Deriving inspiration from\none of these models, this paper presents a methodology for effectively fusing\ncorrelated auditory and visual information for active speaker detection. Such\nan ability can have a wide range of applications, from teleconferencing systems\nto social robotics. The detection approach initially routes auditory and visual\ninformation through two specialized neural network structures. The resulting\nembeddings are fused via a novel layer based on the superior colliculus, whose\ntopological structure emulates spatial neuron cross-mapping of unimodal\nperceptual fields. The validation process employed two publicly available\ndatasets, with achieved results confirming and greatly surpassing initial\nexpectations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 20:56:24 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 11:05:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Assun\u00e7\u00e3o", "Gustavo", ""], ["Gon\u00e7alves", "Nuno", ""], ["Menezes", "Paulo", ""]]}, {"id": "2003.00075", "submitter": "Kambiz Azarian", "authors": "Kambiz Azarian, Yash Bhalgat, Jinwon Lee and Tijmen Blankevoort", "title": "Learned Threshold Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel differentiable method for unstructured weight\npruning of deep neural networks. Our learned-threshold pruning (LTP) method\nlearns per-layer thresholds via gradient descent, unlike conventional methods\nwhere they are set as input. Making thresholds trainable also makes LTP\ncomputationally efficient, hence scalable to deeper networks. For example, it\ntakes $30$ epochs for LTP to prune ResNet50 on ImageNet by a factor of $9.1$.\nThis is in contrast to other methods that search for per-layer thresholds via a\ncomputationally intensive iterative pruning and fine-tuning process.\nAdditionally, with a novel differentiable $L_0$ regularization, LTP is able to\noperate effectively on architectures with batch-normalization. This is\nimportant since $L_1$ and $L_2$ penalties lose their regularizing effect in\nnetworks with batch-normalization. Finally, LTP generates a trail of\nprogressively sparser networks from which the desired pruned network can be\npicked based on sparsity and performance requirements. These features allow LTP\nto achieve competitive compression rates on ImageNet networks such as AlexNet\n($26.4\\times$ compression with $79.1\\%$ Top-5 accuracy) and ResNet50\n($9.1\\times$ compression with $92.0\\%$ Top-5 accuracy). We also show that LTP\neffectively prunes modern \\textit{compact} architectures, such as EfficientNet,\nMobileNetV2 and MixNet.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 21:32:39 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 02:36:29 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Azarian", "Kambiz", ""], ["Bhalgat", "Yash", ""], ["Lee", "Jinwon", ""], ["Blankevoort", "Tijmen", ""]]}, {"id": "2003.00083", "submitter": "Heejong Bong", "authors": "Heejong Bong, Wanshan Li, Shamindra Shrotriya, Alessandro Rinaldo", "title": "Nonparametric Estimation in the Dynamic Bradley-Terry Model", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a time-varying generalization of the Bradley-Terry model that\nallows for nonparametric modeling of dynamic global rankings of distinct teams.\nWe develop a novel estimator that relies on kernel smoothing to pre-process the\npairwise comparisons over time and is applicable in sparse settings where the\nBradley-Terry may not be fit. We obtain necessary and sufficient conditions for\nthe existence and uniqueness of our estimator. We also derive time-varying\noracle bounds for both the estimation error and the excess risk in the\nmodel-agnostic setting where the Bradley-Terry model is not necessarily the\ntrue data generating process. We thoroughly test the practical effectiveness of\nour model using both simulated and real world data and suggest an efficient\ndata-driven approach for bandwidth tuning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 21:52:49 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bong", "Heejong", ""], ["Li", "Wanshan", ""], ["Shrotriya", "Shamindra", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "2003.00108", "submitter": "Mufti Mahmud", "authors": "Mufti Mahmud, M Shamim Kaiser, Amir Hussain", "title": "Deep Learning in Mining Biological Data", "comments": "36 pages, 8 figures, and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advancements in data acquisition tools allowed life\nscientists to acquire multimodal data from different biological application\ndomains. Broadly categorized in three types (i.e., sequences, images, and\nsignals), these data are huge in amount and complex in nature. Mining such an\nenormous amount of data for pattern recognition is a big challenge and requires\nsophisticated data-intensive machine learning techniques. Artificial neural\nnetwork-based learning systems are well known for their pattern recognition\ncapabilities and lately their deep architectures - known as deep learning (DL)\n- have been successfully applied to solve many complex pattern recognition\nproblems. Highlighting the role of DL in recognizing patterns in biological\ndata, this article provides - applications of DL to biological sequences,\nimages, and signals data; overview of open access sources of these data;\ndescription of open source DL tools applicable on these data; and comparison of\nthese tools from qualitative and quantitative perspectives. At the end, it\noutlines some open research challenges in mining biological data and puts\nforward a number of possible future perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:14:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mahmud", "Mufti", ""], ["Kaiser", "M Shamim", ""], ["Hussain", "Amir", ""]]}, {"id": "2003.00113", "submitter": "Bowen Gang", "authors": "Bowen Gang, Wenguang Sun, and Weinan Wang", "title": "Structure-Adaptive Sequential Testing for Online False Discovery Rate\n  Control", "comments": "45 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the online testing of a stream of hypotheses where a real--time\ndecision must be made before the next data point arrives. The error rate is\nrequired to be controlled at {all} decision points. Conventional\n\\emph{simultaneous testing rules} are no longer applicable due to the more\nstringent error constraints and absence of future data. Moreover, the online\ndecision--making process may come to a halt when the total error budget, or\nalpha--wealth, is exhausted. This work develops a new class of\nstructure--adaptive sequential testing (SAST) rules for online false discover\nrate (FDR) control. A key element in our proposal is a new alpha--investment\nalgorithm that precisely characterizes the gains and losses in sequential\ndecision making. SAST captures time varying structures of the data stream,\nlearns the optimal threshold adaptively in an ongoing manner and optimizes the\nalpha-wealth allocation across different time periods. We present theory and\nnumerical results to show that the proposed method is valid for online FDR\ncontrol and achieves substantial power gain over existing online testing rules.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:16:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gang", "Bowen", ""], ["Sun", "Wenguang", ""], ["Wang", "Weinan", ""]]}, {"id": "2003.00120", "submitter": "Zhikuan Zhao", "authors": "Zhuolin Yang, Zhikuan Zhao, Hengzhi Pei, Boxin Wang, Bojan Karlas, Ji\n  Liu, Heng Guo, Bo Li and Ce Zhang", "title": "End-to-end Robustness for Sensing-Reasoning Machine Learning Pipelines", "comments": "43 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) being applied to many mission-critical scenarios,\ncertifying ML model robustness becomes increasingly important. Many previous\nworks focuses on the robustness of independent ML and ensemble models, and can\nonly certify a very small magnitude of the adversarial perturbation. In this\npaper, we take a different viewpoint and improve learning robustness by going\nbeyond independent ML and ensemble models. We aim at promoting the generic\nSensing-Reasoning machine learning pipeline which contains both the sensing\n(e.g. deep neural networks) and reasoning (e.g. Markov logic networks (MLN))\ncomponents enriched with domain knowledge. Can domain knowledge help improve\nlearning robustness? Can we formally certify the end-to-end robustness of such\nan ML pipeline?\n  We first theoretically analyze the computational complexity of checking the\nprovable robustness in the reasoning component. We then derive the provable\nrobustness bound for several concrete reasoning components. We show that for\nreasoning components such as MLN and a specific family of Bayesian networks it\nis possible to certify the robustness of the whole pipeline even with a large\nmagnitude of perturbation which cannot be certified by existing work. Finally,\nwe conduct extensive real-world experiments on large scale datasets to evaluate\nthe certified robustness for Sensing-Reasoning ML pipelines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:41:58 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 23:30:03 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yang", "Zhuolin", ""], ["Zhao", "Zhikuan", ""], ["Pei", "Hengzhi", ""], ["Wang", "Boxin", ""], ["Karlas", "Bojan", ""], ["Liu", "Ji", ""], ["Guo", "Heng", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""]]}, {"id": "2003.00122", "submitter": "Ping-En Lu", "authors": "Yi-Cheng Chen, Ping-En Lu, Cheng-Shang Chang, and Tzu-Hsuan Liu", "title": "A Time-dependent SIR model for COVID-19 with Undetectable Infected\n  Persons", "comments": "18 pages, 12 figures, 2 table, Parts of the codes used in this paper\n  will be placed on GitHub\n  (https://github.com/PingEnLu/Time-dependent_SIR_COVID-19), The latest version\n  will be placed on\n  http://gibbs1.ee.nthu.edu.tw/A_TIME_DEPENDENT_SIR_MODEL_FOR_COVID_19.PDF", "journal-ref": null, "doi": "10.1109/TNSE.2020.3024723", "report-no": null, "categories": "q-bio.PE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we conduct mathematical and numerical analyses to address the\nfollowing crucial questions for COVID-19: (Q1) Is it possible to contain\nCOVID-19? (Q2) When will be the peak and the end of the epidemic? (Q3) How do\nthe asymptomatic infections affect the spread of disease? (Q4) What is the\nratio of the population that needs to be infected to achieve herd immunity?\n(Q5) How effective are the social distancing approaches? (Q6) What is the ratio\nof the population infected in the long run? For (Q1) and (Q2), we propose a\ntime-dependent susceptible-infected-recovered (SIR) model that tracks 2 time\nseries: (i) the transmission rate at time t and (ii) the recovering rate at\ntime t. Such an approach is more adaptive than traditional static SIR models\nand more robust than direct estimation methods. Using the data provided by\nChina, we show that the one-day prediction errors for the numbers of confirmed\ncases are almost in 3%, and the total number of confirmed cases is precisely\npredicted. Also, the turning point, defined as the day that the transmission\nrate is less than the recovering rate can be accurately predicted. After that\nday, the basic reproduction number $R_0$ is less than 1. For (Q3), we extend\nour SIR model by considering 2 types of infected persons: detectable and\nundetectable infected persons. Whether there is an outbreak in such a model is\ncharacterized by the spectral radius of a 2 by 2 matrix that is closely related\nto $R_0$. For (Q4), we show that herd immunity can be achieved after at least\n1-1/$R_0$ fraction of individuals being infected. For (Q5) and (Q6), we analyze\nthe independent cascade (IC) model for disease propagation in a configuration\nrandom graph. By relating the propagation probabilities in the IC model to the\ntransmission rates and recovering rates in the SIR model, we show 2 approaches\nof social distancing that can lead to a reduction of $R_0$.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:44:13 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 19:42:26 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 12:11:48 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 16:28:35 GMT"}, {"version": "v5", "created": "Sat, 11 Apr 2020 14:35:37 GMT"}, {"version": "v6", "created": "Tue, 28 Apr 2020 12:36:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Yi-Cheng", ""], ["Lu", "Ping-En", ""], ["Chang", "Cheng-Shang", ""], ["Liu", "Tzu-Hsuan", ""]]}, {"id": "2003.00129", "submitter": "Duc P. Truong", "authors": "Duc P. Truong, Erik Skau, Vladimir I. Valtchinov, Boian S. Alexandrov", "title": "Determination of Latent Dimensionality in International Trade Flow", "comments": null, "journal-ref": null, "doi": "10.1088/2632-2153/aba9ee", "report-no": null, "categories": "cs.LG cs.IR econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, high-dimensional data is ubiquitous in data science, which\nnecessitates the development of techniques to decompose and interpret such\nmultidimensional (aka tensor) datasets. Finding a low dimensional\nrepresentation of the data, that is, its inherent structure, is one of the\napproaches that can serve to understand the dynamics of low dimensional latent\nfeatures hidden in the data. Nonnegative RESCAL is one such technique,\nparticularly well suited to analyze self-relational data, such as dynamic\nnetworks found in international trade flows. Nonnegative RESCAL computes a low\ndimensional tensor representation by finding the latent space containing\nmultiple modalities. Estimating the dimensionality of this latent space is\ncrucial for extracting meaningful latent features. Here, to determine the\ndimensionality of the latent space with nonnegative RESCAL, we propose a latent\ndimension determination method which is based on clustering of the solutions of\nmultiple realizations of nonnegative RESCAL decompositions. We demonstrate the\nperformance of our model selection method on synthetic data and then we apply\nour method to decompose a network of international trade flows data from\nInternational Monetary Fund and validate the resulting features against\nempirical facts from economic literature.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 00:06:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Truong", "Duc P.", ""], ["Skau", "Erik", ""], ["Valtchinov", "Vladimir I.", ""], ["Alexandrov", "Boian S.", ""]]}, {"id": "2003.00146", "submitter": "Ahmed Taha Elthakeb", "authors": "Ahmed T. Elthakeb, Prannoy Pilligundla, Fatemehsadat Mireshghallah,\n  Tarek Elgindi, Charles-Alban Deledalle, Hadi Esmaeilzadeh", "title": "WaveQ: Gradient-Based Deep Quantization of Neural Networks through\n  Sinusoidal Adaptive Regularization", "comments": "Preliminary work. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks make their ways into different domains, their compute\nefficiency is becoming a first-order constraint. Deep quantization, which\nreduces the bitwidth of the operations (below 8 bits), offers a unique\nopportunity as it can reduce both the storage and compute requirements of the\nnetwork super-linearly. However, if not employed with diligence, this can lead\nto significant accuracy loss. Due to the strong inter-dependence between layers\nand exhibiting different characteristics across the same network, choosing an\noptimal bitwidth per layer granularity is not a straight forward. As such, deep\nquantization opens a large hyper-parameter space, the exploration of which is a\nmajor challenge. We propose a novel sinusoidal regularization, called SINAREQ,\nfor deep quantized training. Leveraging the sinusoidal properties, we seek to\nlearn multiple quantization parameterization in conjunction during\ngradient-based training process. Specifically, we learn (i) a per-layer\nquantization bitwidth along with (ii) a scale factor through learning the\nperiod of the sinusoidal function. At the same time, we exploit the\nperiodicity, differentiability, and the local convexity profile in sinusoidal\nfunctions to automatically propel (iii) network weights towards values\nquantized at levels that are jointly determined. We show how SINAREQ balance\ncompute efficiency and accuracy, and provide a heterogeneous bitwidth\nassignment for quantization of a large variety of deep networks (AlexNet,\nCIFAR-10, MobileNet, ResNet-18, ResNet-20, SVHN, and VGG-11) that virtually\npreserves the accuracy. Furthermore, we carry out experimentation using fixed\nhomogenous bitwidths with 3- to 5-bit assignment and show the versatility of\nSINAREQ in enhancing quantized training algorithms (DoReFa and WRPN) with about\n4.8% accuracy improvements on average, and then outperforming multiple\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 01:19:55 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 10:39:34 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Elthakeb", "Ahmed T.", ""], ["Pilligundla", "Prannoy", ""], ["Mireshghallah", "Fatemehsadat", ""], ["Elgindi", "Tarek", ""], ["Deledalle", "Charles-Alban", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2003.00152", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, David J. Schwab, and Ari S. Morcos", "title": "Training BatchNorm and Only BatchNorm: On the Expressive Power of Random\n  Features in CNNs", "comments": "Published in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of deep learning techniques from style transfer to multitask\nlearning rely on training affine transformations of features. Most prominent\namong these is the popular feature normalization technique BatchNorm, which\nnormalizes activations and then subsequently applies a learned affine\ntransform. In this paper, we aim to understand the role and expressive power of\naffine parameters used to transform features in this way. To isolate the\ncontribution of these parameters from that of the learned features they\ntransform, we investigate the performance achieved when training only these\nparameters in BatchNorm and freezing all weights at their random\ninitializations. Doing so leads to surprisingly high performance considering\nthe significant limitations that this style of training imposes. For example,\nsufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5)\naccuracy in this configuration, far higher than when training an equivalent\nnumber of randomly chosen parameters elsewhere in the network. BatchNorm\nachieves this performance in part by naturally learning to disable around a\nthird of the random features. Not only do these results highlight the\nexpressive power of affine parameters in deep learning, but - in a broader\nsense - they characterize the expressive power of neural networks constructed\nsimply by shifting and rescaling random features.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 01:57:37 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:52:52 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 21:48:35 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Frankle", "Jonathan", ""], ["Schwab", "David J.", ""], ["Morcos", "Ari S.", ""]]}, {"id": "2003.00162", "submitter": "Cong Shen", "authors": "Chengshuai Shi, Wei Xiong, Cong Shen, Jing Yang", "title": "Decentralized Multi-player Multi-armed Bandits with No Collision\n  Information", "comments": "17 pages, 11 figures. Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized stochastic multi-player multi-armed bandit (MP-MAB)\nproblem, where the collision information is not available to the players, is\nstudied in this paper. Building on the seminal work of Boursier and Perchet\n(2019), we propose error correction synchronization involving communication\n(EC-SIC), whose regret is shown to approach that of the centralized stochastic\nMP-MAB with collision information. By recognizing that the communication phase\nwithout collision information corresponds to the Z-channel model in information\ntheory, the proposed EC-SIC algorithm applies optimal error correction coding\nfor the communication of reward statistics. A fixed message length, as opposed\nto the logarithmically growing one in Boursier and Perchet (2019), also plays a\ncrucial role in controlling the communication loss. Experiments with practical\nZ-channel codes, such as repetition code, flip code and modified Hamming code,\ndemonstrate the superiority of EC-SIC in both synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 02:38:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Shi", "Chengshuai", ""], ["Xiong", "Wei", ""], ["Shen", "Cong", ""], ["Yang", "Jing", ""]]}, {"id": "2003.00179", "submitter": "Wendyam Eric Lionel Ilboudo", "authors": "Wendyam Eric Lionel Ilboudo, Taisuke Kobayashi, and Kenji Sugimoto", "title": "TAdam: A Robust Stochastic Gradient Optimizer", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms aim to find patterns from observations, which may\ninclude some noise, especially in robotics domain. To perform well even with\nsuch noise, we expect them to be able to detect outliers and discard them when\nneeded. We therefore propose a new stochastic gradient optimization method,\nwhose robustness is directly built in the algorithm, using the robust student-t\ndistribution as its core idea. Adam, the popular optimization method, is\nmodified with our method and the resultant optimizer, so-called TAdam, is shown\nto effectively outperform Adam in terms of robustness against noise on diverse\ntask, ranging from regression and classification to reinforcement learning\nproblems. The implementation of our algorithm can be found at\nhttps://github.com/Mahoumaru/TAdam.git\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 04:32:36 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 03:50:48 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ilboudo", "Wendyam Eric Lionel", ""], ["Kobayashi", "Taisuke", ""], ["Sugimoto", "Kenji", ""]]}, {"id": "2003.00189", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Max Simchowitz", "title": "Logarithmic Regret for Adversarial Online Control", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm for online linear-quadratic control in a known\nsystem subject to adversarial disturbances. Existing regret bounds for this\nsetting scale as $\\sqrt{T}$ unless strong stochastic assumptions are imposed on\nthe disturbance process. We give the first algorithm with logarithmic regret\nfor arbitrary adversarial disturbance sequences, provided the state and control\ncosts are given by known quadratic functions. Our algorithm and analysis use a\ncharacterization for the optimal offline control law to reduce the online\ncontrol problem to (delayed) online learning with approximate advantage\nfunctions. Compared to previous techniques, our approach does not need to\ncontrol movement costs for the iterates, leading to logarithmic regret.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 06:29:19 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 04:19:06 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 08:17:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Foster", "Dylan J.", ""], ["Simchowitz", "Max", ""]]}, {"id": "2003.00193", "submitter": "Ruqi Zhang", "authors": "Ruqi Zhang, A. Feder Cooper, Christopher De Sa", "title": "AMAGOLD: Amortized Metropolis Adjustment for Efficient Stochastic\n  Gradient MCMC", "comments": "Published at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Hamiltonian Monte Carlo (SGHMC) is an efficient method\nfor sampling from continuous distributions. It is a faster alternative to HMC:\ninstead of using the whole dataset at each iteration, SGHMC uses only a\nsubsample. This improves performance, but introduces bias that can cause SGHMC\nto converge to the wrong distribution. One can prevent this using a step size\nthat decays to zero, but such a step size schedule can drastically slow down\nconvergence. To address this tension, we propose a novel second-order SG-MCMC\nalgorithm---AMAGOLD---that infrequently uses Metropolis-Hastings (M-H)\ncorrections to remove bias. The infrequency of corrections amortizes their\ncost. We prove AMAGOLD converges to the target distribution with a fixed,\nrather than a diminishing, step size, and that its convergence rate is at most\na constant factor slower than a full-batch baseline. We empirically demonstrate\nAMAGOLD's effectiveness on synthetic distributions, Bayesian logistic\nregression, and Bayesian neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 06:57:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Ruqi", ""], ["Cooper", "A. Feder", ""], ["De Sa", "Christopher", ""]]}, {"id": "2003.00218", "submitter": "Xuan Su", "authors": "Xuan Su, Wee Sun Lee, Zhen Zhang", "title": "Multiplicative Gaussian Particle Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new sampling-based approach for approximate inference in\nfiltering problems. Instead of approximating conditional distributions with a\nfinite set of states, as done in particle filters, our approach approximates\nthe distribution with a weighted sum of functions from a set of continuous\nfunctions. Central to the approach is the use of sampling to approximate\nmultiplications in the Bayes filter. We provide theoretical analysis, giving\nconditions for sampling to give good approximation. We next specialize to the\ncase of weighted sums of Gaussians, and show how properties of Gaussians enable\nclosed-form transition and efficient multiplication. Lastly, we conduct\npreliminary experiments on a robot localization problem and compare performance\nwith the particle filter, to demonstrate the potential of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 09:19:38 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Su", "Xuan", ""], ["Lee", "Wee Sun", ""], ["Zhang", "Zhen", ""]]}, {"id": "2003.00223", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "Deep differentiable forest with sparse attention for the tabular data", "comments": "6 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general architecture of deep differentiable forest and its\nsparse attention mechanism. The differentiable forest has the advantages of\nboth trees and neural networks. Its structure is a simple binary tree, easy to\nuse and understand. It has full differentiability and all variables are\nlearnable parameters. We would train it by the gradient-based optimization\nmethod, which shows great power in the training of deep CNN. We find and\nanalyze the attention mechanism in the differentiable forest. That is, each\ndecision depends on only a few important features, and others are irrelevant.\nThe attention is always sparse. Based on this observation, we improve its\nsparsity by data-aware initialization. We use the attribute importance to\ninitialize the attention weight. Then the learned weight is much sparse than\nthat from random initialization. Our experiment on some large tabular dataset\nshows differentiable forest has higher accuracy than GBDT, which is the state\nof art algorithm for tabular datasets. The source codes are available at\nhttps://github.com/closest-git/QuantumForest\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 09:47:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2003.00226", "submitter": "Padraig Corcoran", "authors": "Padraig Corcoran", "title": "An End-to-End Graph Convolutional Kernel Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel kernel-based support vector machine (SVM) for graph classification is\nproposed. The SVM feature space mapping consists of a sequence of graph\nconvolutional layers, which generates a vector space representation for each\nvertex, followed by a pooling layer which generates a reproducing kernel\nHilbert space (RKHS) representation for the graph. The use of a RKHS offers the\nability to implicitly operate in this space using a kernel function without the\ncomputational complexity of explicitly mapping into it. The proposed model is\ntrained in a supervised end-to-end manner whereby the convolutional layers, the\nkernel function and SVM parameters are jointly optimized with respect to a\nregularized classification loss. This approach is distinct from existing\nkernel-based graph classification models which instead either use feature\nengineering or unsupervised learning to define the kernel function.\nExperimental results demonstrate that the proposed model outperforms existing\ndeep learning baseline models on a number of datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 09:57:42 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 11:35:45 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Corcoran", "Padraig", ""]]}, {"id": "2003.00248", "submitter": "Akihiro Yabe", "authors": "Akihiro Yabe and Takanori Maehara", "title": "Tightly Robust Optimization via Empirical Domain Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven decision-making is performed by solving a parameterized\noptimization problem, and the optimal decision is given by an optimal solution\nfor unknown true parameters. We often need a solution that satisfies true\nconstraints even though these are unknown. Robust optimization is employed to\nobtain such a solution, where the uncertainty of the parameter is represented\nby an ellipsoid, and the scale of robustness is controlled by a coefficient. In\nthis study, we propose an algorithm to determine the scale such that the\nsolution has a good objective value and satisfies the true constraints with a\ngiven confidence probability. Under some regularity conditions, the scale\nobtained by our algorithm is asymptotically $O(1/\\sqrt{n})$, whereas the scale\nobtained by a standard approach is $O(\\sqrt{d/n})$. This means that our\nalgorithm is less affected by the dimensionality of the parameters.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 12:24:56 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Yabe", "Akihiro", ""], ["Maehara", "Takanori", ""]]}, {"id": "2003.00260", "submitter": "Jens Braband", "authors": "Jens Braband and Hendrik Sch\\\"abe", "title": "On Safety Assessment of Artificial Intelligence", "comments": "16 pages, 7 figures", "journal-ref": "Dependability, vol. 20 no. 4, 2020", "doi": "10.21683/1729-2646-2020-20-4-25-34", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss how systems with Artificial Intelligence (AI) can\nundergo safety assessment. This is relevant, if AI is used in safety related\napplications. Taking a deeper look into AI models, we show, that many models of\nartificial intelligence, in particular machine learning, are statistical\nmodels. Safety assessment would then have t o concentrate on the model that is\nused in AI, besides the normal assessment procedure. Part of the budget of\ndangerous random failures for the relevant safety integrity level needs to be\nused for the probabilistic faulty behavior of the AI system. We demonstrate our\nthoughts with a simple example and propose a research challenge that may be\ndecisive for the use of AI in safety related systems.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 14:05:28 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Braband", "Jens", ""], ["Sch\u00e4be", "Hendrik", ""]]}, {"id": "2003.00264", "submitter": "Fengqi You", "authors": "Akshay Ajagekar, Fengqi You", "title": "Quantum Computing Assisted Deep Learning for Fault Detection and\n  Diagnosis in Industrial Process Systems", "comments": null, "journal-ref": "Comp. Chem. Eng., 143 (2020), pp. 107119", "doi": "10.1016/j.compchemeng.2020.107119", "report-no": null, "categories": "quant-ph cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing (QC) and deep learning techniques have attracted widespread\nattention in the recent years. This paper proposes QC-based deep learning\nmethods for fault diagnosis that exploit their unique capabilities to overcome\nthe computational challenges faced by conventional data-driven approaches\nperformed on classical computers. Deep belief networks are integrated into the\nproposed fault diagnosis model and are used to extract features at different\nlevels for normal and faulty process operations. The QC-based fault diagnosis\nmodel uses a quantum computing assisted generative training process followed by\ndiscriminative training to address the shortcomings of classical algorithms. To\ndemonstrate its applicability and efficiency, the proposed fault diagnosis\nmethod is applied to process monitoring of continuous stirred tank reactor\n(CSTR) and Tennessee Eastman (TE) process. The proposed QC-based deep learning\napproach enjoys superior fault detection and diagnosis performance with\nobtained average fault detection rates of 79.2% and 99.39% for CSTR and TE\nprocess, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 14:18:33 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 02:44:48 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Ajagekar", "Akshay", ""], ["You", "Fengqi", ""]]}, {"id": "2003.00269", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott A. Sisson", "title": "Online Binary Space Partitioning Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Binary Space Partitioning-Tree~(BSP-Tree) process was recently proposed\nas an efficient strategy for space partitioning tasks. Because it uses more\nthan one dimension to partition the space, the BSP-Tree Process is more\nefficient and flexible than conventional axis-aligned cutting strategies.\nHowever, due to its batch learning setting, it is not well suited to\nlarge-scale classification and regression problems. In this paper, we develop\nan online BSP-Forest framework to address this limitation. With the arrival of\nnew data, the resulting online algorithm can simultaneously expand the space\ncoverage and refine the partition structure, with guaranteed universal\nconsistency for both classification and regression problems. The effectiveness\nand competitive performance of the online BSP-Forest is verified via\nsimulations on real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 14:35:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2003.00295", "submitter": "Zachary Charles", "authors": "Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith\n  Rush, Jakub Kone\\v{c}n\\'y, Sanjiv Kumar, H. Brendan McMahan", "title": "Adaptive Federated Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed machine learning paradigm in which a\nlarge number of clients coordinate with a central server to learn a model\nwithout sharing their own training data. Standard federated optimization\nmethods such as Federated Averaging (FedAvg) are often difficult to tune and\nexhibit unfavorable convergence behavior. In non-federated settings, adaptive\noptimization methods have had notable success in combating such issues. In this\nwork, we propose federated versions of adaptive optimizers, including Adagrad,\nAdam, and Yogi, and analyze their convergence in the presence of heterogeneous\ndata for general non-convex settings. Our results highlight the interplay\nbetween client heterogeneity and communication efficiency. We also perform\nextensive experiments on these methods and show that the use of adaptive\noptimizers can significantly improve the performance of federated learning.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 16:37:29 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 23:31:57 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 17:37:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Reddi", "Sashank", ""], ["Charles", "Zachary", ""], ["Zaheer", "Manzil", ""], ["Garrett", "Zachary", ""], ["Rush", "Keith", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Kumar", "Sanjiv", ""], ["McMahan", "H. Brendan", ""]]}, {"id": "2003.00304", "submitter": "Woojay Jeon", "authors": "Woojay Jeon, Leo Liu, Henry Mason", "title": "Voice trigger detection from LVCSR hypothesis lattices using\n  bidirectional lattice recurrent neural networks", "comments": "Presented at IEEE ICASSP, May 2019", "journal-ref": "ICASSP 2019 - 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), Brighton, United Kingdom, 2019, pp.\n  6356-6360", "doi": "10.1109/ICASSP.2019.8682617", "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to reduce false voice triggers of a speech-enabled\npersonal assistant by post-processing the hypothesis lattice of a server-side\nlarge-vocabulary continuous speech recognizer (LVCSR) via a neural network. We\nfirst discuss how an estimate of the posterior probability of the trigger\nphrase can be obtained from the hypothesis lattice using known techniques to\nperform detection, then investigate a statistical model that processes the\nlattice in a more explicitly data-driven, discriminative manner. We propose\nusing a Bidirectional Lattice Recurrent Neural Network (LatticeRNN) for the\ntask, and show that it can significantly improve detection accuracy over using\nthe 1-best result or the posterior.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 17:02:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Jeon", "Woojay", ""], ["Liu", "Leo", ""], ["Mason", "Henry", ""]]}, {"id": "2003.00306", "submitter": "Boris Muzellec", "authors": "Boris Muzellec, Kanji Sato, Mathurin Massias, Taiji Suzuki", "title": "Dimension-free convergence rates for gradient Langevin dynamics in RKHS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Langevin dynamics (GLD) and stochastic GLD (SGLD) have attracted\nconsiderable attention lately, as a way to provide convergence guarantees in a\nnon-convex setting. However, the known rates grow exponentially with the\ndimension of the space. In this work, we provide a convergence analysis of GLD\nand SGLD when the optimization space is an infinite dimensional Hilbert space.\nMore precisely, we derive non-asymptotic, dimension-free convergence rates for\nGLD/SGLD when performing regularized non-convex optimization in a reproducing\nkernel Hilbert space. Amongst others, the convergence analysis relies on the\nproperties of a stochastic differential equation, its discrete time Galerkin\napproximation and the geometric ergodicity of the associated Markov chains.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 10:05:35 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Muzellec", "Boris", ""], ["Sato", "Kanji", ""], ["Massias", "Mathurin", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2003.00307", "submitter": "Chaoyue Liu", "authors": "Chaoyue Liu, Libin Zhu, Mikhail Belkin", "title": "Loss landscapes and optimization in over-parameterized non-linear\n  systems and neural networks", "comments": "The discussion on transition to linearity in Version 1 has been moved\n  to arXiv:2010.01092 (appeared in NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning is due, to a large extent, to the remarkable\neffectiveness of gradient-based optimization methods applied to large neural\nnetworks. The purpose of this work is to propose a modern view and a general\nmathematical framework for loss landscapes and efficient optimization in\nover-parameterized machine learning models and systems of non-linear equations,\na setting that includes over-parameterized deep neural networks. Our starting\nobservation is that optimization problems corresponding to such systems are\ngenerally not convex, even locally. We argue that instead they satisfy PL$^*$,\na variant of the Polyak-Lojasiewicz condition on most (but not all) of the\nparameter space, which guarantees both the existence of solutions and efficient\noptimization by (stochastic) gradient descent (SGD/GD). The PL$^*$ condition of\nthese systems is closely related to the condition number of the tangent kernel\nassociated to a non-linear system showing how a PL$^*$-based non-linear theory\nparallels classical analyses of over-parameterized linear equations. We show\nthat wide neural networks satisfy the PL$^*$ condition, which explains the\n(S)GD convergence to a global minimum. Finally we propose a relaxation of the\nPL$^*$ condition applicable to \"almost\" over-parameterized systems.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 17:18:28 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 19:22:33 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Liu", "Chaoyue", ""], ["Zhu", "Libin", ""], ["Belkin", "Mikhail", ""]]}, {"id": "2003.00335", "submitter": "Isay Katsman", "authors": "Aaron Lou, Isay Katsman, Qingxuan Jiang, Serge Belongie, Ser-Nam Lim,\n  Christopher De Sa", "title": "Differentiating through the Fr\\'echet Mean", "comments": "ICML 2020 camera-ready; updated Algorithm 1 typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep representation learning on Riemannian manifolds\nextend classical deep learning operations to better capture the geometry of the\nmanifold. One possible extension is the Fr\\'echet mean, the generalization of\nthe Euclidean mean; however, it has been difficult to apply because it lacks a\nclosed form with an easily computable derivative. In this paper, we show how to\ndifferentiate through the Fr\\'echet mean for arbitrary Riemannian manifolds.\nThen, focusing on hyperbolic space, we derive explicit gradient expressions and\na fast, accurate, and hyperparameter-free Fr\\'echet mean solver. This fully\nintegrates the Fr\\'echet mean into the hyperbolic neural network pipeline. To\ndemonstrate this integration, we present two case studies. First, we apply our\nFr\\'echet mean to the existing Hyperbolic Graph Convolutional Network,\nreplacing its projected aggregation to obtain state-of-the-art results on\ndatasets with high hyperbolicity. Second, to demonstrate the Fr\\'echet mean's\ncapacity to generalize Euclidean neural network operations, we develop a\nhyperbolic batch normalization method that gives an improvement parallel to the\none observed in the Euclidean setting.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 19:49:38 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 04:17:54 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 18:07:56 GMT"}, {"version": "v4", "created": "Mon, 5 Jul 2021 23:47:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lou", "Aaron", ""], ["Katsman", "Isay", ""], ["Jiang", "Qingxuan", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""], ["De Sa", "Christopher", ""]]}, {"id": "2003.00343", "submitter": "Sangdon Park", "authors": "Sangdon Park, Osbert Bastani, James Weimer, Insup Lee", "title": "Calibrated Prediction with Covariate Shift via Unsupervised Domain\n  Adaptation", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable uncertainty estimates are an important tool for helping autonomous\nagents or human decision makers understand and leverage predictive models.\nHowever, existing approaches to estimating uncertainty largely ignore the\npossibility of covariate shift--i.e., where the real-world data distribution\nmay differ from the training distribution. As a consequence, existing\nalgorithms can overestimate certainty, possibly yielding a false sense of\nconfidence in the predictive model. We propose an algorithm for calibrating\npredictions that accounts for the possibility of covariate shift, given labeled\nexamples from the training distribution and unlabeled examples from the\nreal-world distribution. Our algorithm uses importance weighting to correct for\nthe shift from the training to the real-world distribution. However, importance\nweighting relies on the training and real-world distributions to be\nsufficiently close. Building on ideas from domain adaptation, we additionally\nlearn a feature map that tries to equalize these two distributions. In an\nempirical evaluation, we show that our proposed approach outperforms existing\napproaches to calibrated prediction when there is covariate shift.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 20:31:04 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:09:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Park", "Sangdon", ""], ["Bastani", "Osbert", ""], ["Weimer", "James", ""], ["Lee", "Insup", ""]]}, {"id": "2003.00355", "submitter": "Paidamoyo Chapfuwa", "authors": "Paidamoyo Chapfuwa, Chunyuan Li, Nikhil Mehta, Lawrence Carin, Ricardo\n  Henao", "title": "Survival Cluster Analysis", "comments": "Accepted at ACM CHIL 2020. Code: this https URL,\n  https://github.com/paidamoyo/survival_cluster_analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conventional survival analysis approaches estimate risk scores or\nindividualized time-to-event distributions conditioned on covariates. In\npractice, there is often great population-level phenotypic heterogeneity,\nresulting from (unknown) subpopulations with diverse risk profiles or survival\ndistributions. As a result, there is an unmet need in survival analysis for\nidentifying subpopulations with distinct risk profiles, while jointly\naccounting for accurate individualized time-to-event predictions. An approach\nthat addresses this need is likely to improve characterization of individual\noutcomes by leveraging regularities in subpopulations, thus accounting for\npopulation-level heterogeneity. In this paper, we propose a Bayesian\nnonparametrics approach that represents observations (subjects) in a clustered\nlatent space, and encourages accurate time-to-event predictions and clusters\n(subpopulations) with distinct risk profiles. Experiments on real-world\ndatasets show consistent improvements in predictive performance and\ninterpretability relative to existing state-of-the-art survival analysis\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 22:41:21 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chapfuwa", "Paidamoyo", ""], ["Li", "Chunyuan", ""], ["Mehta", "Nikhil", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "2003.00359", "submitter": "Xiao Xu", "authors": "Xiao Xu, Fang Dong, Yanghua Li, Shaojian He, Xin Li", "title": "Contextual-Bandit Based Personalized Recommendation with Time-Varying\n  User Interests", "comments": "Accepted by AAAI 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A contextual bandit problem is studied in a highly non-stationary\nenvironment, which is ubiquitous in various recommender systems due to the\ntime-varying interests of users. Two models with disjoint and hybrid payoffs\nare considered to characterize the phenomenon that users' preferences towards\ndifferent items vary differently over time. In the disjoint payoff model, the\nreward of playing an arm is determined by an arm-specific preference vector,\nwhich is piecewise-stationary with asynchronous and distinct changes across\ndifferent arms. An efficient learning algorithm that is adaptive to abrupt\nreward changes is proposed and theoretical regret analysis is provided to show\nthat a sublinear scaling of regret in the time length $T$ is achieved. The\nalgorithm is further extended to a more general setting with hybrid payoffs\nwhere the reward of playing an arm is determined by both an arm-specific\npreference vector and a joint coefficient vector shared by all arms. Empirical\nexperiments are conducted on real-world datasets to verify the advantages of\nthe proposed learning algorithms against baseline ones in both settings.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 22:59:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Xiao", ""], ["Dong", "Fang", ""], ["Li", "Yanghua", ""], ["He", "Shaojian", ""], ["Li", "Xin", ""]]}, {"id": "2003.00360", "submitter": "Ryan McNellis", "authors": "Adam N. Elmachtoub, Jason Cheuk Nam Liang, Ryan McNellis", "title": "Decision Trees for Decision-Making under the Predict-then-Optimize\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of decision trees for decision-making problems under the\npredict-then-optimize framework. That is, we would like to first use a decision\ntree to predict unknown input parameters of an optimization problem, and then\nmake decisions by solving the optimization problem using the predicted\nparameters. A natural loss function in this framework is to measure the\nsuboptimality of the decisions induced by the predicted input parameters, as\nopposed to measuring loss using input parameter prediction error. This natural\nloss function is known in the literature as the Smart Predict-then-Optimize\n(SPO) loss, and we propose a tractable methodology called SPO Trees (SPOTs) for\ntraining decision trees under this loss. SPOTs benefit from the\ninterpretability of decision trees, providing an interpretable segmentation of\ncontextual features into groups with distinct optimal solutions to the\noptimization problem of interest. We conduct several numerical experiments on\nsynthetic and real data including the prediction of travel times for shortest\npath problems and predicting click probabilities for news article\nrecommendation. We demonstrate on these datasets that SPOTs simultaneously\nprovide higher quality decisions and significantly lower model complexity than\nother machine learning approaches (e.g., CART) trained to minimize prediction\nerror.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 23:04:59 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 01:06:31 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Elmachtoub", "Adam N.", ""], ["Liang", "Jason Cheuk Nam", ""], ["McNellis", "Ryan", ""]]}, {"id": "2003.00365", "submitter": "Semih Cayci", "authors": "Semih Cayci, Atilla Eryilmaz, R. Srikant", "title": "Budget-Constrained Bandits over General Cost and Reward Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a budget-constrained bandit problem where each arm pull incurs a\nrandom cost, and yields a random reward in return. The objective is to maximize\nthe total expected reward under a budget constraint on the total cost. The\nmodel is general in the sense that it allows correlated and potentially\nheavy-tailed cost-reward pairs that can take on negative values as required by\nmany applications. We show that if moments of order $(2+\\gamma)$ for some\n$\\gamma > 0$ exist for all cost-reward pairs, $O(\\log B)$ regret is achievable\nfor a budget $B>0$. In order to achieve tight regret bounds, we propose\nalgorithms that exploit the correlation between the cost and reward of each arm\nby extracting the common information via linear minimum mean-square error\nestimation. We prove a regret lower bound for this problem, and show that the\nproposed algorithms achieve tight problem-dependent regret bounds, which are\noptimal up to a universal constant factor in the case of jointly Gaussian cost\nand reward pairs.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 23:50:08 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Cayci", "Semih", ""], ["Eryilmaz", "Atilla", ""], ["Srikant", "R.", ""]]}, {"id": "2003.00370", "submitter": "Masashi Okada Dr", "authors": "Masashi Okada and Norio Kosaka and Tadahiro Taniguchi", "title": "PlaNet of the Bayesians: Reconsidering and Improving Deep Planning\n  Network by Incorporating Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we propose an extension of the Deep Planning Network\n(PlaNet), also referred to as PlaNet of the Bayesians (PlaNet-Bayes). There has\nbeen a growing demand in model predictive control (MPC) in partially observable\nenvironments in which complete information is unavailable because of, for\nexample, lack of expensive sensors. PlaNet is a promising solution to realize\nsuch latent MPC, as it is used to train state-space models via model-based\nreinforcement learning (MBRL) and to conduct planning in the latent space.\nHowever, recent state-of-the-art strategies mentioned in MBRR literature, such\nas involving uncertainty into training and planning, have not been considered,\nsignificantly suppressing the training performance. The proposed extension is\nto make PlaNet uncertainty-aware on the basis of Bayesian inference, in which\nboth model and action uncertainty are incorporated. Uncertainty in latent\nmodels is represented using a neural network ensemble to approximately infer\nmodel posteriors. The ensemble of optimal action candidates is also employed to\ncapture multimodal uncertainty in the optimality. The concept of the action\nensemble relies on a general variational inference MPC (VI-MPC) framework and\nits instance, probabilistic action ensemble with trajectory sampling (PaETS).\nIn this paper, we extend VI-MPC and PaETS, which have been originally\nintroduced in previous literature, to address partially observable cases. We\nexperimentally compare the performances on continuous control tasks, and\nconclude that our method can consistently improve the asymptotic performance\ncompared with PlaNet.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 00:46:36 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Okada", "Masashi", ""], ["Kosaka", "Norio", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2003.00371", "submitter": "Bradley Price", "authors": "Bradley S. Price and Aaron J. Molstad and Ben Sherwood", "title": "Estimating Multiple Precision Matrices with Cluster Fusion\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a penalized likelihood framework for estimating multiple precision\nmatrices from different classes. Most existing methods either incorporate no\ninformation on relationships between the precision matrices, or require this\ninformation be known a priori. The framework proposed in this article allows\nfor simultaneous estimation of the precision matrices and relationships between\nthe precision matrices, jointly. Sparse and non-sparse estimators are proposed,\nboth of which require solving a non-convex optimization problem. To compute our\nproposed estimators, we use an iterative algorithm which alternates between a\nconvex optimization problem solved by blockwise coordinate descent and a\nk-means clustering problem. Blockwise updates for computing the sparse\nestimator require solving an elastic net penalized precision matrix estimation\nproblem, which we solve using a proximal gradient descent algorithm. We prove\nthat this subalgorithm has a linear rate of convergence. In simulation studies\nand two real data applications, we show that our method can outperform\ncompetitors that ignore relevant relationships between precision matrices and\nperforms similarly to methods which use prior information often uknown in\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 01:03:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Price", "Bradley S.", ""], ["Molstad", "Aaron J.", ""], ["Sherwood", "Ben", ""]]}, {"id": "2003.00378", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Jinghui Chen, Quanquan Gu, David Evans", "title": "Understanding the Intrinsic Robustness of Image Distributions using\n  Conditional Generative Models", "comments": "14 pages, 2 figures, 5 tables, AISTATS final paper reformatted for\n  readability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting with Gilmer et al. (2018), several works have demonstrated the\ninevitability of adversarial examples based on different assumptions about the\nunderlying input probability space. It remains unclear, however, whether these\nresults apply to natural image distributions. In this work, we assume the\nunderlying data distribution is captured by some conditional generative model,\nand prove intrinsic robustness bounds for a general class of classifiers, which\nsolves an open problem in Fawzi et al. (2018). Building upon the\nstate-of-the-art conditional generative models, we study the intrinsic\nrobustness of two common image benchmarks under $\\ell_2$ perturbations, and\nshow the existence of a large gap between the robustness limits implied by our\ntheory and the adversarial robustness achieved by current state-of-the-art\nrobust models. Code for all our experiments is available at\nhttps://github.com/xiaozhanguva/Intrinsic-Rob.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 01:45:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Chen", "Jinghui", ""], ["Gu", "Quanquan", ""], ["Evans", "David", ""]]}, {"id": "2003.00381", "submitter": "Edwin Dalmaijer", "authors": "E. S. Dalmaijer, C. L. Nord, and D. E. Astle", "title": "Statistical power for cluster analysis", "comments": "53 pages, 13 figures, 5 tables; for code and data see:\n  https://www.github.com/esdalmaijer/cluster_power", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cluster algorithms are increasingly popular in biomedical research due to\ntheir compelling ability to identify discrete subgroups in data, and their\nincreasing accessibility in mainstream software. While guidelines exist for\nalgorithm selection and outcome evaluation, there are no firmly established\nways of computing a priori statistical power for cluster analysis. Here, we\nestimated power and accuracy for common analysis pipelines through simulation.\nWe varied subgroup size, number, separation (effect size), and covariance\nstructure. We then subjected generated datasets to dimensionality reduction\n(none, multidimensional scaling, or UMAP) and cluster algorithms (k-means,\nagglomerative hierarchical clustering with Ward or average linkage and\nEuclidean or cosine distance, HDBSCAN). Finally, we compared the statistical\npower of discrete (k-means), \"fuzzy\" (c-means), and finite mixture modelling\napproaches (which include latent profile and latent class analysis). We found\nthat outcomes were driven by large effect sizes or the accumulation of many\nsmaller effects across features, and were unaffected by differences in\ncovariance structure. Sufficient statistical power was achieved with relatively\nsmall samples (N=20 per subgroup), provided cluster separation is large\n({\\Delta}=4). Fuzzy clustering provided a more parsimonious and powerful\nalternative for identifying separable multivariate normal distributions,\nparticularly those with slightly lower centroid separation ({\\Delta}=3).\nOverall, we recommend that researchers 1) only apply cluster analysis when\nlarge subgroup separation is expected, 2) aim for sample sizes of N=20 to N=30\nper expected subgroup, 3) use multidimensional scaling to improve cluster\nseparation, and 4) use fuzzy clustering or finite mixture modelling approaches\nthat are more powerful and more parsimonious with partially overlapping\nmultivariate normal distributions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 02:43:15 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 16:32:34 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 15:21:57 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Dalmaijer", "E. S.", ""], ["Nord", "C. L.", ""], ["Astle", "D. E.", ""]]}, {"id": "2003.00394", "submitter": "Stefano Peluchetti", "authors": "Stefano Favaro, Sandra Fortini, Stefano Peluchetti", "title": "Stable behaviour of infinitely wide deep neural networks", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider fully connected feed-forward deep neural networks (NNs) where\nweights and biases are independent and identically distributed as symmetric\ncentered stable distributions. Then, we show that the infinite wide limit of\nthe NN, under suitable scaling on the weights, is a stochastic process whose\nfinite-dimensional distributions are multivariate stable distributions. The\nlimiting process is referred to as the stable process, and it generalizes the\nclass of Gaussian processes recently obtained as infinite wide limits of NNs\n(Matthews at al., 2018b). Parameters of the stable process can be computed via\nan explicit recursion over the layers of the network. Our result contributes to\nthe theory of fully connected feed-forward deep NNs, and it paves the way to\nexpand recent lines of research that rely on Gaussian infinite wide limits.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 04:07:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Favaro", "Stefano", ""], ["Fortini", "Sandra", ""], ["Peluchetti", "Stefano", ""]]}, {"id": "2003.00402", "submitter": "Ryo Kamoi", "authors": "Ryo Kamoi, Kei Kobayashi", "title": "Why is the Mahalanobis Distance Effective for Anomaly Detection?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mahalanobis distance-based confidence score, a recently proposed anomaly\ndetection method for pre-trained neural classifiers, achieves state-of-the-art\nperformance on both out-of-distribution (OoD) and adversarial examples\ndetection. This work analyzes why this method exhibits such strong performance\nin practical settings while imposing an implausible assumption; namely, that\nclass conditional distributions of pre-trained features have tied covariance.\nAlthough the Mahalanobis distance-based method is claimed to be motivated by\nclassification prediction confidence, we find that its superior performance\nstems from information not useful for classification. This suggests that the\nreason the Mahalanobis confidence score works so well is mistaken, and makes\nuse of different information from ODIN, another popular OoD detection method\nbased on prediction confidence. This perspective motivates us to combine these\ntwo methods, and the combined detector exhibits improved performance and\nrobustness. These findings provide insight into the behavior of neural\nclassifiers in response to anomalous inputs.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 04:48:36 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:42:33 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Kamoi", "Ryo", ""], ["Kobayashi", "Kei", ""]]}, {"id": "2003.00415", "submitter": "Muaaz Zakria", "authors": "Muhammad Asim and Muaaz Zakria", "title": "Advanced kNN: A Mature Machine Learning Series", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-nearest neighbour (kNN) is one of the most prominent, simple and basic\nalgorithm used in machine learning and data mining. However, kNN has limited\nprediction ability, i.e., kNN cannot predict any instance correctly if it does\nnot belong to any of the predefined classes in the training data set. The\npurpose of this paper is to suggest an Advanced kNN (A-kNN) algorithm that will\nbe able to classify an instance as unknown, after verifying that it does not\nbelong to any of the predefined classes. Performance of kNN and A-kNN is\ncompared on three different data sets namely iris plant data set, BUPA liver\ndisorder data set, and Alpha Beta detection data set. Results of A-kNN are\nsignificantly accurate for detecting unknown instances.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 06:11:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Asim", "Muhammad", ""], ["Zakria", "Muaaz", ""]]}, {"id": "2003.00429", "submitter": "Xinwei Chen", "authors": "Xinwei Chen, Ali Taleb Zadeh Kasgari and Walid Saad", "title": "Deep Learning for Content-based Personalized Viewport Prediction of\n  360-Degree VR Videos", "comments": null, "journal-ref": null, "doi": "10.1109/LNET.2020.2977124", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of head movement prediction for virtual reality\nvideos is studied. In the considered model, a deep learning network is\nintroduced to leverage position data as well as video frame content to predict\nfuture head movement. For optimizing data input into this neural network, data\nsample rate, reduced data, and long-period prediction length are also explored\nfor this model. Simulation results show that the proposed approach yields\n16.1\\% improvement in terms of prediction accuracy compared to a baseline\napproach that relies only on the position data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 07:31:50 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Xinwei", ""], ["Kasgari", "Ali Taleb Zadeh", ""], ["Saad", "Walid", ""]]}, {"id": "2003.00433", "submitter": "Xingyu Sha", "authors": "Xingyu Sha, Jiaqi Zhang, Keyou You, Kaiqing Zhang and Tamer Ba\\c{s}ar", "title": "Fully Asynchronous Policy Evaluation in Distributed Reinforcement\n  Learning over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a \\emph{fully asynchronous} scheme for the policy\nevaluation problem of distributed reinforcement learning (DisRL) over directed\npeer-to-peer networks. Without waiting for any other node of the network, each\nnode can locally update its value function at any time by using (possibly\ndelayed) information from its neighbors. This is in sharp contrast to the\ngossip-based scheme where a pair of nodes concurrently update. Though the fully\nasynchronous setting involves a difficult multi-timescale decision problem, we\ndesign a novel stochastic average gradient (SAG) based distributed algorithm\nand develop a push-pull augmented graph approach to prove its exact convergence\nat a linear rate of $\\mathcal{O}(c^k)$ where $c\\in(0,1)$ and $k$ increases by\none no matter on which node updates. Finally, numerical experiments validate\nthat our method speeds up linearly with respect to the number of nodes, and is\nrobust to straggler nodes.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 08:12:08 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 12:50:02 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 16:45:28 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Sha", "Xingyu", ""], ["Zhang", "Jiaqi", ""], ["You", "Keyou", ""], ["Zhang", "Kaiqing", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2003.00470", "submitter": "Takuya Isomura", "authors": "Takuya Isomura, Taro Toyoizumi", "title": "Dimensionality reduction to maximize prediction generalization\n  capability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops an analytically solvable unsupervised learning scheme that\nextracts the most informative components for predicting future inputs, termed\npredictive principal component analysis (PredPCA). Our scheme can effectively\nremove unpredictable observation noise and globally minimize the test\nprediction error. Mathematical analyses demonstrate that, with sufficiently\nhigh-dimensional observations that are generated by a linear or nonlinear\nsystem, PredPCA can identify the optimal hidden state representation, true\nsystem parameters, and true hidden state dimensionality, with a global\nconvergence guarantee. We demonstrate the performance of PredPCA by using\nsequential visual inputs comprising hand-digits, rotating 3D objects, and\nnatural scenes. It reliably and accurately estimates distinct hidden states and\npredicts future outcomes of previously unseen test input data, even in the\npresence of considerable observation noise. The simple model structure and low\ncomputational cost of PredPCA make it highly desirable as a learning scheme for\nbiological neural networks and neuromorphic chips.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:04:59 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Isomura", "Takuya", ""], ["Toyoizumi", "Taro", ""]]}, {"id": "2003.00474", "submitter": "Yue Xu", "authors": "Yue Xu, Feng Yin, Wenjun Xu, Chia-Han Lee, Jiaru Lin, Shuguang Cui", "title": "Scalable Learning Paradigms for Data-Driven Wireless Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The marriage of wireless big data and machine learning techniques\nrevolutionizes the wireless system by the data-driven philosophy. However, the\never exploding data volume and model complexity will limit centralized\nsolutions to learn and respond within a reasonable time. Therefore, scalability\nbecomes a critical issue to be solved. In this article, we aim to provide a\nsystematic discussion on the building blocks of scalable data-driven wireless\nnetworks. On one hand, we discuss the forward-looking architecture and\ncomputing framework of scalable data-driven systems from a global perspective.\nOn the other hand, we discuss the learning algorithms and model training\nstrategies performed at each individual node from a local perspective. We also\nhighlight several promising research directions in the context of scalable\ndata-driven wireless communications to inspire future research.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:13:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Yue", ""], ["Yin", "Feng", ""], ["Xu", "Wenjun", ""], ["Lee", "Chia-Han", ""], ["Lin", "Jiaru", ""], ["Cui", "Shuguang", ""]]}, {"id": "2003.00484", "submitter": "Alexander Jung", "authors": "Alexander Jung and Pedro H. J. Nardelli", "title": "An Information-Theoretic Approach to Personalized Explainable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.2993176", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated decision making is used routinely throughout our everyday life.\nRecommender systems decide which jobs, movies, or other user profiles might be\ninteresting to us. Spell checkers help us to make good use of language. Fraud\ndetection systems decide if a credit card transactions should be verified more\nclosely. Many of these decision making systems use machine learning methods\nthat fit complex models to massive datasets. The successful deployment of\nmachine learning (ML) methods to many (critical) application domains crucially\ndepends on its explainability. Indeed, humans have a strong desire to get\nexplanations that resolve the uncertainty about experienced phenomena like the\npredictions and decisions obtained from ML methods. Explainable ML is\nchallenging since explanations must be tailored (personalized) to individual\nusers with varying backgrounds. Some users might have received university-level\neducation in ML, while other users might have no formal training in linear\nalgebra. Linear regression with few features might be perfectly interpretable\nfor the first group but might be considered a black-box by the latter. We\npropose a simple probabilistic model for the predictions and user knowledge.\nThis model allows to study explainable ML using information theory. Explaining\nis here considered as the task of reducing the \"surprise\" incurred by a\nprediction. We quantify the effect of an explanation by the conditional mutual\ninformation between the explanation and prediction, given the user background.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 13:06:29 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 14:38:49 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Jung", "Alexander", ""], ["Nardelli", "Pedro H. J.", ""]]}, {"id": "2003.00497", "submitter": "Yang Yu", "authors": "Chao Wang, Ruo-Ze Liu, Han-Jia Ye, Yang Yu", "title": "Novelty-Prepared Few-Shot Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification algorithms can alleviate the data scarceness issue,\nwhich is vital in many real-world problems, by adopting models pre-trained from\nabundant data in other domains. However, the pre-training process was commonly\nunaware of the future adaptation to other concept classes. We disclose that a\nclassically fully trained feature extractor can leave little embedding space\nfor unseen classes, which keeps the model from well-fitting the new classes. In\nthis work, we propose to use a novelty-prepared loss function, called\nself-compacting softmax loss (SSL), for few-shot classification. The SSL can\nprevent the full occupancy of the embedding space. Thus the model is more\nprepared to learn new classes. In experiments on CUB-200-2011 and mini-ImageNet\ndatasets, we show that SSL leads to significant improvement of the\nstate-of-the-art performance. This work may shed some light on considering the\nmodel capacity for few-shot classification tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 14:44:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wang", "Chao", ""], ["Liu", "Ruo-Ze", ""], ["Ye", "Han-Jia", ""], ["Yu", "Yang", ""]]}, {"id": "2003.00534", "submitter": "Dongsheng Ding", "authors": "Dongsheng Ding, Xiaohan Wei, Zhuoran Yang, Zhaoran Wang, Mihailo R.\n  Jovanovi\\'c", "title": "Provably Efficient Safe Exploration via Primal-Dual Policy Optimization", "comments": "44 pages. We have revised the linear MDP assumption and fixed a bug\n  in our previous proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Safe Reinforcement Learning (SRL) problem using the Constrained\nMarkov Decision Process (CMDP) formulation in which an agent aims to maximize\nthe expected total reward subject to a safety constraint on the expected total\nvalue of a utility function. We focus on an episodic setting with the function\napproximation where the Markov transition kernels have a linear structure but\ndo not impose any additional assumptions on the sampling model. Designing SRL\nalgorithms with provable computational and statistical efficiency is\nparticularly challenging under this setting because of the need to incorporate\nboth the safety constraint and the function approximation into the fundamental\nexploitation/exploration tradeoff. To this end, we present an\n\\underline{O}ptimistic \\underline{P}rimal-\\underline{D}ual Proximal Policy\n\\underline{OP}timization (OPDOP) algorithm where the value function is\nestimated by combining the least-squares policy evaluation and an additional\nbonus term for safe exploration. We prove that the proposed algorithm achieves\nan $\\tilde{O}(d H^{2.5}\\sqrt{T})$ regret and an $\\tilde{O}(d H^{2.5}\\sqrt{T})$\nconstraint violation, where $d$ is the dimension of the feature mapping, $H$ is\nthe horizon of each episode, and $T$ is the total number of steps. These bounds\nhold when the reward/utility functions are fixed but the feedback after each\nepisode is bandit. Our bounds depend on the capacity of the state-action space\nonly through the dimension of the feature mapping and thus our results hold\neven when the number of states goes to infinity. To the best of our knowledge,\nwe provide the first provably efficient online policy optimization algorithm\nfor CMDP with safe exploration in the function approximation setting.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 17:47:03 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 02:35:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ding", "Dongsheng", ""], ["Wei", "Xiaohan", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "2003.00541", "submitter": "Syed Anwar", "authors": "Ismail Irmakci, Syed Muhammad Anwar, Drew A. Torigian, and Ulas Bagci", "title": "Deep Learning for Musculoskeletal Image Analysis", "comments": "Invited Paper, ASILOMAR 2019, TP4b: Machine Learning Advances in\n  Computational Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis, prognosis, and treatment of patients with musculoskeletal\n(MSK) disorders require radiology imaging (using computed tomography, magnetic\nresonance imaging(MRI), and ultrasound) and their precise analysis by expert\nradiologists. Radiology scans can also help assessment of metabolic health,\naging, and diabetes. This study presents how machinelearning, specifically deep\nlearning methods, can be used for rapidand accurate image analysis of MRI\nscans, an unmet clinicalneed in MSK radiology. As a challenging example, we\nfocus on automatic analysis of knee images from MRI scans and study machine\nlearning classification of various abnormalities including meniscus and\nanterior cruciate ligament tears. Using widely used convolutional neural\nnetwork (CNN) based architectures, we comparatively evaluated the knee\nabnormality classification performances of different neural network\narchitectures under limited imaging data regime and compared single and\nmulti-view imaging when classifying the abnormalities. Promising results\nindicated the potential use of multi-view deep learning based classification of\nMSK abnormalities in routine clinical assessment.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 18:13:59 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Irmakci", "Ismail", ""], ["Anwar", "Syed Muhammad", ""], ["Torigian", "Drew A.", ""], ["Bagci", "Ulas", ""]]}, {"id": "2003.00553", "submitter": "George Dasoulas", "authors": "George Dasoulas, Giannis Nikolentzos, Kevin Scaman, Aladin Virmaux,\n  Michalis Vazirgiannis", "title": "Ego-based Entropy Measures for Structural Representations", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex networks, nodes that share similar structural characteristics\noften exhibit similar roles (e.g type of users in a social network or the\nhierarchical position of employees in a company). In order to leverage this\nrelationship, a growing literature proposed latent representations that\nidentify structurally equivalent nodes. However, most of the existing methods\nrequire high time and space complexity. In this paper, we propose VNEstruct, a\nsimple approach for generating low-dimensional structural node embeddings, that\nis both time efficient and robust to perturbations of the graph structure. The\nproposed approach focuses on the local neighborhood of each node and employs\nthe Von Neumann entropy, an information-theoretic tool, to extract features\nthat capture the neighborhood's topology. Moreover, on graph classification\ntasks, we suggest the utilization of the generated structural embeddings for\nthe transformation of an attributed graph structure into a set of augmented\nnode attributes. Empirically, we observe that the proposed approach exhibits\nrobustness on structural role identification tasks and state-of-the-art\nperformance on graph classification tasks, while maintaining very high\ncomputational speed.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 18:58:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Dasoulas", "George", ""], ["Nikolentzos", "Giannis", ""], ["Scaman", "Kevin", ""], ["Virmaux", "Aladin", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2003.00563", "submitter": "Roi Livni", "authors": "Mark Bun and Roi Livni and Shay Moran", "title": "An Equivalence Between Private Classification and Online Prediction", "comments": "An earlier version of this manuscript claimed an upper bound over the\n  sample complexity that is exponential in the Littlestone dimension. The\n  argument was erranous, and the current version contains a correction, which\n  leads to double-exponential dependence in the Littlestone-dimension", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that every concept class with finite Littlestone dimension can be\nlearned by an (approximate) differentially-private algorithm. This answers an\nopen question of Alon et al. (STOC 2019) who proved the converse statement\n(this question was also asked by Neel et al.~(FOCS 2019)). Together these two\nresults yield an equivalence between online learnability and private PAC\nlearnability.\n  We introduce a new notion of algorithmic stability called \"global stability\"\nwhich is essential to our proof and may be of independent interest. We also\ndiscuss an application of our results to boosting the privacy and accuracy\nparameters of differentially-private learners.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 19:20:37 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 03:50:38 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:52:13 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Bun", "Mark", ""], ["Livni", "Roi", ""], ["Moran", "Shay", ""]]}, {"id": "2003.00585", "submitter": "Margaux Br\\'eg\\`ere", "authors": "Margaux Br\\'eg\\`ere and Malo Huard", "title": "Online Hierarchical Forecasting for Power Consumption Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the forecasting of the power consumptions of a population of\nhouseholds and of subpopulations thereof. These subpopulations are built\naccording to location, to exogenous information and/or to profiles we\ndetermined from historical households consumption time series. Thus, we aim to\nforecast the electricity consumption time series at several levels of\nhouseholds aggregation. These time series are linked through some summation\nconstraints which induce a hierarchy. Our approach consists in three steps:\nfeature generation, aggregation and projection. Firstly (feature generation\nstep), we build, for each considering group for households, a benchmark\nforecast (called features), using random forests or generalized additive\nmodels. Secondly (aggregation step), aggregation algorithms, run in parallel,\naggregate these forecasts and provide new predictions. Finally (projection\nstep), we use the summation constraints induced by the time series underlying\nhierarchy to re-conciliate the forecasts by projecting them in a well-chosen\nlinear subspace. We provide some theoretical guaranties on the average\nprediction error of this methodology, through the minimization of a quantity\ncalled regret. We also test our approach on households power consumption data\ncollected in Great Britain by multiple energy providers in the Energy Demand\nResearch Project context. We build and compare various population segmentations\nfor the evaluation of our approach performance.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 21:01:59 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Br\u00e9g\u00e8re", "Margaux", ""], ["Huard", "Malo", ""]]}, {"id": "2003.00602", "submitter": "Monica Ribero", "authors": "M\\'onica Ribero, Jette Henderson, Sinead Williamson, Haris Vikalo", "title": "Federating Recommendations Using Differentially Private Prototypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods allow us to make recommendations to users in\napplications across fields including entertainment, dating, and commerce, by\nexploiting similarities in users' interaction patterns. However, in domains\nthat demand protection of personally sensitive data, such as medicine or\nbanking, how can we learn such a model without accessing the sensitive data,\nand without inadvertently leaking private information? We propose a new\nfederated approach to learning global and local private models for\nrecommendation without collecting raw data, user statistics, or information\nabout personal preferences. Our method produces a set of prototypes that allows\nus to infer global behavioral patterns, while providing differential privacy\nguarantees for users in any database of the system. By requiring only two\nrounds of communication, we both reduce the communication costs and avoid the\nexcessive privacy loss associated with iterative procedures. We test our\nframework on synthetic data as well as real federated medical data and\nMovielens ratings data. We show local adaptation of the global model allows our\nmethod to outperform centralized matrix-factorization-based recommender system\nmodels, both in terms of accuracy of matrix reconstruction and in terms of\nrelevance of the recommendations, while maintaining provable privacy\nguarantees. We also show that our method is more robust and is characterized by\nsmaller variance than individual models learned by independent entities.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 22:21:31 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ribero", "M\u00f3nica", ""], ["Henderson", "Jette", ""], ["Williamson", "Sinead", ""], ["Vikalo", "Haris", ""]]}, {"id": "2003.00605", "submitter": "Jun Han Mr", "authors": "Jun Han, Fan Ding, Xianglong Liu, Lorenzo Torresani, Jian Peng, Qiang\n  Liu", "title": "Stein Variational Inference for Discrete Distributions", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based approximate inference methods, such as Stein variational\ngradient descent (SVGD), provide simple and general-purpose inference engines\nfor differentiable continuous distributions. However, existing forms of SVGD\ncannot be directly applied to discrete distributions. In this work, we fill\nthis gap by proposing a simple yet general framework that transforms discrete\ndistributions to equivalent piecewise continuous distributions, on which the\ngradient-free SVGD is applied to perform efficient approximate inference. The\nempirical results show that our method outperforms traditional algorithms such\nas Gibbs sampling and discontinuous Hamiltonian Monte Carlo on various\nchallenging benchmarks of discrete graphical models. We demonstrate that our\nmethod provides a promising tool for learning ensembles of binarized neural\nnetwork (BNN), outperforming other widely used ensemble methods on learning\nbinarized AlexNet on CIFAR-10 dataset. In addition, such transform can be\nstraightforwardly employed in gradient-free kernelized Stein discrepancy to\nperform goodness-of-fit (GOF) test on discrete distributions. Our proposed\nmethod outperforms existing GOF test methods for intractable discrete\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 22:45:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Han", "Jun", ""], ["Ding", "Fan", ""], ["Liu", "Xianglong", ""], ["Torresani", "Lorenzo", ""], ["Peng", "Jian", ""], ["Liu", "Qiang", ""]]}, {"id": "2003.00608", "submitter": "Dongrui Wu", "authors": "Dongrui Wu", "title": "MBGD-RDA Training and Rule Pruning for Concise TSK Fuzzy Regression\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effectively train Takagi-Sugeno-Kang (TSK) fuzzy systems for regression\nproblems, a Mini-Batch Gradient Descent with Regularization, DropRule, and\nAdaBound (MBGD-RDA) algorithm was recently proposed. It has demonstrated\nsuperior performances; however, there are also some limitations, e.g., it does\nnot allow the user to specify the number of rules directly, and only Gaussian\nMFs can be used. This paper proposes two variants of MBGD-RDA to remedy these\nlimitations, and show that they outperform the original MBGD-RDA and the\nclassical ANFIS algorithms with the same number of rules. Furthermore, we also\npropose a rule pruning algorithm for TSK fuzzy systems, which can reduce the\nnumber of rules without significantly sacrificing the regression performance.\nExperiments showed that the rules obtained from pruning are generally better\nthan training them from scratch directly, especially when Gaussian MFs are\nused.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 23:18:39 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 17:09:50 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wu", "Dongrui", ""]]}, {"id": "2003.00617", "submitter": "Lester Mackey", "authors": "Ashia Wilson, Maximilian Kasy, Lester Mackey", "title": "Approximate Cross-validation: Guarantees for Model Assessment and\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-validation (CV) is a popular approach for assessing and selecting\npredictive models. However, when the number of folds is large, CV suffers from\na need to repeatedly refit a learning procedure on a large number of training\ndatasets. Recent work in empirical risk minimization (ERM) approximates the\nexpensive refitting with a single Newton step warm-started from the full\ntraining set optimizer. While this can greatly reduce runtime, several open\nquestions remain including whether these approximations lead to faithful model\nselection and whether they are suitable for non-smooth objectives. We address\nthese questions with three main contributions: (i) we provide uniform\nnon-asymptotic, deterministic model assessment guarantees for approximate CV;\n(ii) we show that (roughly) the same conditions also guarantee model selection\nperformance comparable to CV; (iii) we provide a proximal Newton extension of\nthe approximate CV framework for non-smooth prediction problems and develop\nimproved assessment guarantees for problems such as l1-regularized ERM.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 00:30:00 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 02:03:47 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wilson", "Ashia", ""], ["Kasy", "Maximilian", ""], ["Mackey", "Lester", ""]]}, {"id": "2003.00627", "submitter": "Mahak Goindani", "authors": "Mahak Goindani, Jennifer Neville", "title": "Cluster-Based Social Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Reinforcement Learning methods, which model agents in large networks,\nare useful for fake news mitigation, personalized teaching/healthcare, and\nviral marketing, but it is challenging to incorporate inter-agent dependencies\ninto the models effectively due to network size and sparse interaction data.\nPrevious social RL approaches either ignore agents dependencies or model them\nin a computationally intensive manner. In this work, we incorporate agent\ndependencies efficiently in a compact model by clustering users (based on their\npayoff and contribution to the goal) and combine this with a method to easily\nderive personalized agent-level policies from cluster-level policies. We also\npropose a dynamic clustering approach that captures changing user behavior.\nExperiments on real-world datasets illustrate that our proposed approach learns\nmore accurate policy estimates and converges more quickly, compared to several\nbaselines that do not use agent correlations or only use static clusters.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 01:55:05 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 18:46:08 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Goindani", "Mahak", ""], ["Neville", "Jennifer", ""]]}, {"id": "2003.00628", "submitter": "Cristian Camilo Beltran Hernandez", "authors": "Cristian Camilo Beltran-Hernandez, Damien Petit, Ixchel G.\n  Ramirez-Alpizar, Takayuki Nishi, Shinichi Kikuchi, Takamitsu Matsubara,\n  Kensuke Harada", "title": "Learning Force Control for Contact-rich Manipulation Tasks with Rigid\n  Position-controlled Robots", "comments": "8 pages, 9 figures, version accepted for IROS RA-L 2020, for\n  associated video file, see https://youtu.be/4wdIhQxD6cA", "journal-ref": null, "doi": "10.1109/LRA.2020.3010739", "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) methods have been proven successful in solving\nmanipulation tasks autonomously. However, RL is still not widely adopted on\nreal robotic systems because working with real hardware entails additional\nchallenges, especially when using rigid position-controlled manipulators. These\nchallenges include the need for a robust controller to avoid undesired\nbehavior, that risk damaging the robot and its environment, and constant\nsupervision from a human operator. The main contributions of this work are,\nfirst, we proposed a learning-based force control framework combining RL\ntechniques with traditional force control. Within said control scheme, we\nimplemented two different conventional approaches to achieve force control with\nposition-controlled robots; one is a modified parallel position/force control,\nand the other is an admittance control. Secondly, we empirically study both\ncontrol schemes when used as the action space of the RL agent. Thirdly, we\ndeveloped a fail-safe mechanism for safely training an RL agent on manipulation\ntasks using a real rigid robot manipulator. The proposed methods are validated\non simulation and a real robot, an UR3 e-series robotic arm.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 01:58:03 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 02:53:33 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 02:39:28 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Beltran-Hernandez", "Cristian Camilo", ""], ["Petit", "Damien", ""], ["Ramirez-Alpizar", "Ixchel G.", ""], ["Nishi", "Takayuki", ""], ["Kikuchi", "Shinichi", ""], ["Matsubara", "Takamitsu", ""], ["Harada", "Kensuke", ""]]}, {"id": "2003.00631", "submitter": "Bao Wang", "authors": "Thu Dinh, Bao Wang, Andrea L. Bertozzi, and Stanley J. Osher", "title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism\n  Principled Robust Deep Neural Nets", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural nets (DNNs) compression is crucial for adaptation to mobile\ndevices. Though many successful algorithms exist to compress naturally trained\nDNNs, developing efficient and stable compression algorithms for robustly\ntrained DNNs remains widely open. In this paper, we focus on a co-design of\nefficient DNN compression algorithms and sparse neural architectures for robust\nand accurate deep learning. Such a co-design enables us to advance the goal of\naccommodating both sparsity and robustness. With this objective in mind, we\nleverage the relaxed augmented Lagrangian based algorithms to prune the weights\nof adversarially trained DNNs, at both structured and unstructured levels.\nUsing a Feynman-Kac formalism principled robust and sparse DNNs, we can at\nleast double the channel sparsity of the adversarially trained ResNet20 for\nCIFAR10 classification, meanwhile, improve the natural accuracy by $8.69$\\% and\nthe robust accuracy under the benchmark $20$ iterations of IFGSM attack by\n$5.42$\\%. The code is available at\n\\url{https://github.com/BaoWangMath/rvsm-rgsm-admm}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 02:18:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Dinh", "Thu", ""], ["Wang", "Bao", ""], ["Bertozzi", "Andrea L.", ""], ["Osher", "Stanley J.", ""]]}, {"id": "2003.00638", "submitter": "Chenhao Niu", "authors": "Chenhao Niu, Yang Song, Jiaming Song, Shengjia Zhao, Aditya Grover,\n  Stefano Ermon", "title": "Permutation Invariant Graph Generation via Score-Based Generative\n  Modeling", "comments": "14 pages, AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning generative models for graph-structured data is challenging because\ngraphs are discrete, combinatorial, and the underlying data distribution is\ninvariant to the ordering of nodes. However, most of the existing generative\nmodels for graphs are not invariant to the chosen ordering, which might lead to\nan undesirable bias in the learned distribution. To address this difficulty, we\npropose a permutation invariant approach to modeling graphs, using the recent\nframework of score-based generative modeling. In particular, we design a\npermutation equivariant, multi-channel graph neural network to model the\ngradient of the data distribution at the input graph (a.k.a., the score\nfunction). This permutation equivariant model of gradients implicitly defines a\npermutation invariant distribution for graphs. We train this graph neural\nnetwork with score matching and sample from it with annealed Langevin dynamics.\nIn our experiments, we first demonstrate the capacity of this new architecture\nin learning discrete graph algorithms. For graph generation, we find that our\nlearning approach achieves better or comparable results to existing models on\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:06:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Niu", "Chenhao", ""], ["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Zhao", "Shengjia", ""], ["Grover", "Aditya", ""], ["Ermon", "Stefano", ""]]}, {"id": "2003.00646", "submitter": "Piyush Jain", "authors": "Piyush Jain, Sean C P Coogan, Sriram Ganapathi Subramanian, Mark\n  Crowley, Steve Taylor, Mike D Flannigan", "title": "A review of machine learning applications in wildfire science and\n  management", "comments": "83 pages, 4 figures, 3 tables", "journal-ref": "Environmental Reviews. 28(4): 478-505, 2020", "doi": "10.1139/er-2020-0019", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence has been applied in wildfire science and management\nsince the 1990s, with early applications including neural networks and expert\nsystems. Since then the field has rapidly progressed congruently with the wide\nadoption of machine learning (ML) in the environmental sciences. Here, we\npresent a scoping review of ML in wildfire science and management. Our\nobjective is to improve awareness of ML among wildfire scientists and managers,\nas well as illustrate the challenging range of problems in wildfire science\navailable to data scientists. We first present an overview of popular ML\napproaches used in wildfire science to date, and then review their use in\nwildfire science within six problem domains: 1) fuels characterization, fire\ndetection, and mapping; 2) fire weather and climate change; 3) fire occurrence,\nsusceptibility, and risk; 4) fire behavior prediction; 5) fire effects; and 6)\nfire management. We also discuss the advantages and limitations of various ML\napproaches and identify opportunities for future advances in wildfire science\nand management within a data science context. We identified 298 relevant\npublications, where the most frequently used ML methods included random\nforests, MaxEnt, artificial neural networks, decision trees, support vector\nmachines, and genetic algorithms. There exists opportunities to apply more\ncurrent ML methods (e.g., deep learning and agent based learning) in wildfire\nscience. However, despite the ability of ML models to learn on their own,\nexpertise in wildfire science is necessary to ensure realistic modelling of\nfire processes across multiple scales, while the complexity of some ML methods\nrequires sophisticated knowledge for their application. Finally, we stress that\nthe wildfire research and management community plays an active role in\nproviding relevant, high quality data for use by practitioners of ML methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:59:38 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 14:24:18 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Jain", "Piyush", ""], ["Coogan", "Sean C P", ""], ["Subramanian", "Sriram Ganapathi", ""], ["Crowley", "Mark", ""], ["Taylor", "Steve", ""], ["Flannigan", "Mike D", ""]]}, {"id": "2003.00652", "submitter": "Mucong Ding", "authors": "Mucong Ding, Constantinos Daskalakis, Soheil Feizi", "title": "GANs with Conditional Independence Graphs: On Subadditivity of\n  Probability Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are modern methods to learn the\nunderlying distribution of a data set. GANs have been widely used in sample\nsynthesis, de-noising, domain transfer, etc. GANs, however, are designed in a\nmodel-free fashion where no additional information about the underlying\ndistribution is available. In many applications, however, practitioners have\naccess to the underlying independence graph of the variables, either as a\nBayesian network or a Markov Random Field (MRF). We ask: how can one use this\nadditional information in designing model-based GANs? In this paper, we provide\ntheoretical foundations to answer this question by studying subadditivity\nproperties of probability divergences, which establish upper bounds on the\ndistance between two high-dimensional distributions by the sum of distances\nbetween their marginals over (local) neighborhoods of the graphical structure\nof the Bayes-net or the MRF. We prove that several popular probability\ndivergences satisfy some notion of subadditivity under mild conditions. These\nresults lead to a principled design of a model-based GAN that uses a set of\nsimple discriminators on the neighborhoods of the Bayes-net/MRF, rather than a\ngiant discriminator on the entire network, providing significant statistical\nand computational benefits. Our experiments on synthetic and real-world\ndatasets demonstrate the benefits of our principled design of model-based GANs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:31:22 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 05:12:37 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 23:51:23 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Ding", "Mucong", ""], ["Daskalakis", "Constantinos", ""], ["Feizi", "Soheil", ""]]}, {"id": "2003.00653", "submitter": "Wei Jin", "authors": "Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, Shuiwang Ji, Charu Aggarwal and\n  Jiliang Tang", "title": "Adversarial Attacks and Defenses on Graphs: A Review, A Tool and\n  Empirical Studies", "comments": "Accepted by SIGKDD Explorations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) have achieved significant performance in various\ntasks. However, recent studies have shown that DNNs can be easily fooled by\nsmall perturbation on the input, called adversarial attacks. As the extensions\nof DNNs to graphs, Graph Neural Networks (GNNs) have been demonstrated to\ninherit this vulnerability. Adversary can mislead GNNs to give wrong\npredictions by modifying the graph structure such as manipulating a few edges.\nThis vulnerability has arisen tremendous concerns for adapting GNNs in\nsafety-critical applications and has attracted increasing research attention in\nrecent years. Thus, it is necessary and timely to provide a comprehensive\noverview of existing graph adversarial attacks and the countermeasures. In this\nsurvey, we categorize existing attacks and defenses, and review the\ncorresponding state-of-the-art methods. Furthermore, we have developed a\nrepository with representative algorithms\n(https://github.com/DSE-MSU/DeepRobust/tree/master/deeprobust/graph). The\nrepository enables us to conduct empirical studies to deepen our understandings\non attacks and defenses on graphs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:32:38 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 18:31:56 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 17:21:00 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jin", "Wei", ""], ["Li", "Yaxin", ""], ["Xu", "Han", ""], ["Wang", "Yiqi", ""], ["Ji", "Shuiwang", ""], ["Aggarwal", "Charu", ""], ["Tang", "Jiliang", ""]]}, {"id": "2003.00655", "submitter": "Eunji Jun", "authors": "Eunji Jun, Ahmad Wisnu Mulyadi, Jaehun Choi, Heung-Il Suk", "title": "Uncertainty-Gated Stochastic Sequential Model for EHR Mortality\n  Prediction", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) are characterized as non-stationary,\nheterogeneous, noisy, and sparse data; therefore, it is challenging to learn\nthe regularities or patterns inherent within them. In particular, sparseness\ncaused mostly by many missing values has attracted the attention of\nresearchers, who have attempted to find a better use of all available samples\nfor determining the solution of a primary target task through the defining a\nsecondary imputation problem. Methodologically, existing methods, either\ndeterministic or stochastic, have applied different assumptions to impute\nmissing values. However, once the missing values are imputed, most existing\nmethods do not consider the fidelity or confidence of the imputed values in the\nmodeling of downstream tasks. Undoubtedly, an erroneous or improper imputation\nof missing variables can cause difficulties in modeling as well as a degraded\nperformance. In this study, we present a novel variational recurrent network\nthat (i) estimates the distribution of missing variables allowing to represent\nuncertainty in the imputed values, (ii) updates hidden states by explicitly\napplying fidelity based on a variance of the imputed values during a recurrence\n(i.e., uncertainty propagation over time), and (iii) predicts the possibility\nof in-hospital mortality. It is noteworthy that our model can conduct these\nprocedures in a single stream and learn all network parameters jointly in an\nend-to-end manner. We validated the effectiveness of our method using the\npublic datasets of MIMIC-III and PhysioNet challenge 2012 by comparing with and\noutperforming other state-of-the-art methods for mortality prediction\nconsidered in our experiments. In addition, we identified the behavior of the\nmodel that well represented the uncertainties for the imputed estimates, which\nindicated a high correlation between the calculated MAE and the uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:41:28 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Jun", "Eunji", ""], ["Mulyadi", "Ahmad Wisnu", ""], ["Choi", "Jaehun", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2003.00659", "submitter": "Shinsuke Koyama", "authors": "Shinsuke Koyama and Shigeru Shinomoto", "title": "The statistical physics of discovering exogenous and endogenous factors\n  in a chain of events", "comments": "17 pages, 7 figures", "journal-ref": "Phys. Rev. Research 2, 043358 (2020)", "doi": "10.1103/PhysRevResearch.2.043358", "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event occurrence is not only subject to the environmental changes, but is\nalso facilitated by the events that have occurred in a system. Here, we develop\na method for estimating such extrinsic and intrinsic factors from a single\nseries of event-occurrence times. The analysis is performed using a model that\ncombines the inhomogeneous Poisson process and the Hawkes process, which\nrepresent exogenous fluctuations and endogenous chain-reaction mechanisms,\nrespectively. The model is fit to a given dataset by minimizing the free\nenergy, for which statistical physics and a path-integral method are utilized.\nBecause the process of event occurrence is stochastic, parameter estimation is\ninevitably accompanied by errors, and it can ultimately occur that exogenous\nand endogenous factors cannot be captured even with the best estimator. We\nobtained four regimes categorized according to whether respective factors are\ndetected. By applying the analytical method to real time series of debate in a\nsocial-networking service, we have observed that the estimated exogenous and\nendogenous factors are close to the first comments and the follow-up comments,\nrespectively. This method is general and applicable to a variety of data, and\nwe have provided an application program, by which anyone can analyze any series\nof event times.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:55:41 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Koyama", "Shinsuke", ""], ["Shinomoto", "Shigeru", ""]]}, {"id": "2003.00660", "submitter": "Shuang Qiu", "authors": "Shuang Qiu, Xiaohan Wei, Zhuoran Yang, Jieping Ye, Zhaoran Wang", "title": "Upper Confidence Primal-Dual Reinforcement Learning for CMDP with\n  Adversarial Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning for episodic stochastically constrained Markov\ndecision processes (CMDP), which plays a central role in ensuring the safety of\nreinforcement learning. Here the loss function can vary arbitrarily across the\nepisodes, whereas both the loss received and the budget consumption are\nrevealed at the end of each episode. Previous works solve this problem under\nthe restrictive assumption that the transition model of the Markov decision\nprocesses (MDP) is known a priori and establish regret bounds that depend\npolynomially on the cardinalities of the state space $\\mathcal{S}$ and the\naction space $\\mathcal{A}$. In this work, we propose a new \\emph{upper\nconfidence primal-dual} algorithm, which only requires the trajectories sampled\nfrom the transition model. In particular, we prove that the proposed algorithm\nachieves $\\widetilde{\\mathcal{O}}(L|\\mathcal{S}|\\sqrt{|\\mathcal{A}|T})$ upper\nbounds of both the regret and the constraint violation, where $L$ is the length\nof each episode. Our analysis incorporates a new high-probability drift\nanalysis of Lagrange multiplier processes into the celebrated regret analysis\nof upper confidence reinforcement learning, which demonstrates the power of\n\"optimism in the face of uncertainty\" in constrained online learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 05:02:23 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 07:33:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Qiu", "Shuang", ""], ["Wei", "Xiaohan", ""], ["Yang", "Zhuoran", ""], ["Ye", "Jieping", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2003.00662", "submitter": "Ahmad Wisnu Mulyadi", "authors": "Ahmad Wisnu Mulyadi, Eunji Jun, Heung-Il Suk", "title": "Uncertainty-Aware Variational-Recurrent Imputation Network for Clinical\n  Time Series", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) consist of longitudinal clinical observations\nportrayed with sparsity, irregularity, and high-dimensionality, which become\nmajor obstacles in drawing reliable downstream clinical outcomes. Although\nthere exist great numbers of imputation methods to tackle these issues, most of\nthem ignore correlated features, temporal dynamics and entirely set aside the\nuncertainty. Since the missing value estimates involve the risk of being\ninaccurate, it is appropriate for the method to handle the less certain\ninformation differently than the reliable data. In that regard, we can use the\nuncertainties in estimating the missing values as the fidelity score to be\nfurther utilized to alleviate the risk of biased missing value estimates. In\nthis work, we propose a novel variational-recurrent imputation network, which\nunifies an imputation and a prediction network by taking into account the\ncorrelated features, temporal dynamics, as well as the uncertainty.\nSpecifically, we leverage the deep generative model in the imputation, which is\nbased on the distribution among variables, and a recurrent imputation network\nto exploit the temporal relations, in conjunction with utilization of the\nuncertainty. We validated the effectiveness of our proposed model on two\npublicly available real-world EHR datasets: PhysioNet Challenge 2012 and\nMIMIC-III, and compared the results with other competing state-of-the-art\nmethods in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 05:12:38 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 13:53:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mulyadi", "Ahmad Wisnu", ""], ["Jun", "Eunji", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2003.00677", "submitter": "Houjie Wang", "authors": "Xiaoxian Tang, Houjie Wang, Ruriko Yoshida", "title": "Tropical Support Vector Machine and its Applications to Phylogenomics", "comments": "27 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data in genome-wide phylogenetic analysis (phylogenomics) is essentially\nmultidimensional, posing a major challenge to human comprehension and\ncomputational analysis. Also, we can not directly apply statistical learning\nmodels in data science to a set of phylogenetic trees since the space of\nphylogenetic trees is not Euclidean. In fact, the space of phylogenetic trees\nis a tropical Grassmannian in terms of max-plus algebra. Therefore, to classify\nmulti-locus data sets for phylogenetic analysis, we propose tropical support\nvector machines (SVMs). Like classical SVMs, a tropical SVM is a discriminative\nclassifier defined by the tropical hyperplane which maximizes the minimum\ntropical distance from data points to itself in order to separate these data\npoints into sectors (half-spaces) in the tropical projective torus. Both hard\nmargin tropical SVMs and soft margin tropical SVMs can be formulated as linear\nprogramming problems. We focus on classifying two categories of data, and we\nstudy a simpler case by assuming the data points from the same category ideally\nstay in the same sector of a tropical separating hyperplane. For hard margin\ntropical SVMs, we prove the necessary and sufficient conditions for two\ncategories of data points to be separated, and we show an explicit formula for\nthe optimal value of the feasible linear programming problem. For soft margin\ntropical SVMs, we develop novel methods to compute an optimal tropical\nseparating hyperplane. Computational experiments show our methods work well. We\nend this paper with open problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 05:47:38 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 18:24:18 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Tang", "Xiaoxian", ""], ["Wang", "Houjie", ""], ["Yoshida", "Ruriko", ""]]}, {"id": "2003.00688", "submitter": "David Krueger", "authors": "David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang,\n  Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville", "title": "Out-of-Distribution Generalization via Risk Extrapolation (REx)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional shift is one of the major obstacles when transferring machine\nlearning prediction systems from the lab to the real world. To tackle this\nproblem, we assume that variation across training domains is representative of\nthe variation we might encounter at test time, but also that shifts at test\ntime may be more extreme in magnitude. In particular, we show that reducing\ndifferences in risk across training domains can reduce a model's sensitivity to\na wide range of extreme distributional shifts, including the challenging\nsetting where the input contains both causal and anti-causal elements. We\nmotivate this approach, Risk Extrapolation (REx), as a form of robust\noptimization over a perturbation set of extrapolated domains (MM-REx), and\npropose a penalty on the variance of training risks (V-REx) as a simpler\nvariant. We prove that variants of REx can recover the causal mechanisms of the\ntargets, while also providing some robustness to changes in the input\ndistribution (\"covariate shift\"). By appropriately trading-off robustness to\ncausally induced distributional shifts and covariate shift, REx is able to\noutperform alternative methods such as Invariant Risk Minimization in\nsituations where these types of shift co-occur.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 06:29:50 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 04:15:23 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 22:57:37 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 21:46:28 GMT"}, {"version": "v5", "created": "Thu, 25 Feb 2021 17:53:07 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Krueger", "David", ""], ["Caballero", "Ethan", ""], ["Jacobsen", "Joern-Henrik", ""], ["Zhang", "Amy", ""], ["Binas", "Jonathan", ""], ["Zhang", "Dinghuai", ""], ["Priol", "Remi Le", ""], ["Courville", "Aaron", ""]]}, {"id": "2003.00704", "submitter": "David Tolpin", "authors": "David Tolpin, Yuan Zhou, Hongseok Yang", "title": "Stochastically Differentiable Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programs with mixed support (both continuous and discrete\nlatent random variables) commonly appear in many probabilistic programming\nsystems (PPSs). However, the existence of the discrete random variables\nprohibits many basic gradient-based inference engines, which makes the\ninference procedure on such models particularly challenging. Existing PPSs\neither require the user to manually marginalize out the discrete variables or\nto perform a composing inference by running inference separately on discrete\nand continuous variables. The former is infeasible in most cases whereas the\nlatter has some fundamental shortcomings. We present a novel approach to run\ninference efficiently and robustly in such programs using stochastic gradient\nMarkov Chain Monte Carlo family of algorithms. We compare our stochastic\ngradient-based inference algorithm against conventional baselines in several\nimportant cases of probabilistic programs with mixed support, and demonstrate\nthat it outperforms existing composing inference baselines and works almost as\nwell as inference in marginalized versions of the programs, but with less\nprogramming effort and at a lower computation cost.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 08:04:41 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 14:06:30 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Tolpin", "David", ""], ["Zhou", "Yuan", ""], ["Yang", "Hongseok", ""]]}, {"id": "2003.00722", "submitter": "Junfeng Wen", "authors": "Junfeng Wen, Bo Dai, Lihong Li, Dale Schuurmans", "title": "Batch Stationary Distribution Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating the stationary distribution of an\nergodic Markov chain given a set of sampled transitions. Classical\nsimulation-based approaches assume access to the underlying process so that\ntrajectories of sufficient length can be gathered to approximate stationary\nsampling. Instead, we consider an alternative setting where a fixed set of\ntransitions has been collected beforehand, by a separate, possibly unknown\nprocedure. The goal is still to estimate properties of the stationary\ndistribution, but without additional access to the underlying system. We\npropose a consistent estimator that is based on recovering a correction ratio\nfunction over the given data. In particular, we develop a variational power\nmethod (VPM) that provides provably consistent estimates under general\nconditions. In addition to unifying a number of existing approaches from\ndifferent subfields, we also find that VPM yields significantly better\nestimates across a range of problems, including queueing, stochastic\ndifferential equations, post-processing MCMC, and off-policy evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 09:10:01 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wen", "Junfeng", ""], ["Dai", "Bo", ""], ["Li", "Lihong", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2003.00738", "submitter": "Yuka Hashimoto", "authors": "Yuka Hashimoto, Isao Ishikawa, Masahiro Ikeda, Fuyuta Komura, Takeshi\n  Katsura, Yoshinobu Kawahara", "title": "Analysis via Orthonormal Systems in Reproducing Kernel Hilbert\n  $C^*$-Modules and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have been among the most popular techniques in machine\nlearning, where learning tasks are solved using the property of reproducing\nkernel Hilbert space (RKHS). In this paper, we propose a novel data analysis\nframework with reproducing kernel Hilbert $C^*$-module (RKHM), which is another\ngeneralization of RKHS than vector-valued RKHS (vv-RKHS). Analysis with RKHMs\nenables us to deal with structures among variables more explicitly than\nvv-RKHS. We show the theoretical validity for the construction of orthonormal\nsystems in Hilbert $C^*$-modules, and derive concrete procedures for\northonormalization in RKHMs with those theoretical properties in numerical\ncomputations. Moreover, we apply those to generalize with RKHM kernel principal\ncomponent analysis and the analysis of dynamical systems with Perron-Frobenius\noperators. The empirical performance of our methods is also investigated by\nusing synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:01:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hashimoto", "Yuka", ""], ["Ishikawa", "Isao", ""], ["Ikeda", "Masahiro", ""], ["Komura", "Fuyuta", ""], ["Katsura", "Takeshi", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2003.00777", "submitter": "Ioannis Panageas", "authors": "Vaggos Chatziafratis and Sai Ganesh Nagarajan and Ioannis Panageas", "title": "Better Depth-Width Trade-offs for Neural Networks through the lens of\n  Dynamical Systems", "comments": "Appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressivity of neural networks as a function of their depth, width and\ntype of activation units has been an important question in deep learning\ntheory. Recently, depth separation results for ReLU networks were obtained via\na new connection with dynamical systems, using a generalized notion of fixed\npoints of a continuous map $f$, called periodic points. In this work, we\nstrengthen the connection with dynamical systems and we improve the existing\nwidth lower bounds along several aspects. Our first main result is\nperiod-specific width lower bounds that hold under the stronger notion of\n$L^1$-approximation error, instead of the weaker classification error. Our\nsecond contribution is that we provide sharper width lower bounds, still\nyielding meaningful exponential depth-width separations, in regimes where\nprevious results wouldn't apply. A byproduct of our results is that there\nexists a universal constant characterizing the depth-width trade-offs, as long\nas $f$ has odd periods. Technically, our results follow by unveiling a tighter\nconnection between the following three quantities of a given function: its\nperiod, its Lipschitz constant and the growth rate of the number of\noscillations arising under compositions of the function $f$ with itself.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 11:36:26 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 10:49:10 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chatziafratis", "Vaggos", ""], ["Nagarajan", "Sai Ganesh", ""], ["Panageas", "Ioannis", ""]]}, {"id": "2003.00799", "submitter": "Edward Hughes", "authors": "Edward Hughes, Thomas W. Anthony, Tom Eccles, Joel Z. Leibo, David\n  Balduzzi, Yoram Bachrach", "title": "Learning to Resolve Alliance Dilemmas in Many-Player Zero-Sum Games", "comments": "Accepted for publication at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-sum games have long guided artificial intelligence research, since they\npossess both a rich strategy space of best-responses and a clear evaluation\nmetric. What's more, competition is a vital mechanism in many real-world\nmulti-agent systems capable of generating intelligent innovations: Darwinian\nevolution, the market economy and the AlphaZero algorithm, to name a few. In\ntwo-player zero-sum games, the challenge is usually viewed as finding Nash\nequilibrium strategies, safeguarding against exploitation regardless of the\nopponent. While this captures the intricacies of chess or Go, it avoids the\nnotion of cooperation with co-players, a hallmark of the major transitions\nleading from unicellular organisms to human civilization. Beyond two players,\nalliance formation often confers an advantage; however this requires trust,\nnamely the promise of mutual cooperation in the face of incentives to defect.\nSuccessful play therefore requires adaptation to co-players rather than the\npursuit of non-exploitability. Here we argue that a systematic study of\nmany-player zero-sum games is a crucial element of artificial intelligence\nresearch. Using symmetric zero-sum matrix games, we demonstrate formally that\nalliance formation may be seen as a social dilemma, and empirically that\nna\\\"ive multi-agent reinforcement learning therefore fails to form alliances.\nWe introduce a toy model of economic competition, and show how reinforcement\nlearning may be augmented with a peer-to-peer contract mechanism to discover\nand enforce alliances. Finally, we generalize our agent model to incorporate\ntemporally-extended contracts, presenting opportunities for further work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:32:31 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hughes", "Edward", ""], ["Anthony", "Thomas W.", ""], ["Eccles", "Tom", ""], ["Leibo", "Joel Z.", ""], ["Balduzzi", "David", ""], ["Bachrach", "Yoram", ""]]}, {"id": "2003.00800", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Benedetto Michelozzi, Andrea Bracci and Andrea\n  Masini", "title": "Real-Time target detection in maritime scenarios based on YOLOv3 model", "comments": "Paper presented at the 9th International Symposium on Optronics in\n  Defence & Security, 28-30 January 2020 (OPTRO2020, Paris). Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work a novel ships dataset is proposed consisting of more than 56k\nimages of marine vessels collected by means of web-scraping and including 12\nship categories. A YOLOv3 single-stage detector based on Keras API is built on\ntop of this dataset. Current results on four categories (cargo ship, naval\nship, oil ship and tug ship) show Average Precision up to 96% for Intersection\nover Union (IoU) of 0.5 and satisfactory detection performances up to IoU of\n0.8. A Data Analytics GUI service based on QT framework and Darknet-53 engine\nis also implemented in order to simplify the deployment process and analyse\nmassive amount of images even for people without Data Science expertise.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:25:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Betti", "Alessandro", ""], ["Michelozzi", "Benedetto", ""], ["Bracci", "Andrea", ""], ["Masini", "Andrea", ""]]}, {"id": "2003.00808", "submitter": "Ammarah Farooq", "authors": "Ammarah Farooq, Muhammad Awais, Fei Yan, Josef Kittler, Ali Akbari,\n  and Syed Safwan Khalid", "title": "A Convolutional Baseline for Person Re-Identification Using Vision and\n  Language Descriptions", "comments": "12 pages including references, currently under review in IEEE\n  transactions on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical person re-identification approaches assume that a person of\ninterest has appeared across different cameras and can be queried by one of the\nexisting images. However, in real-world surveillance scenarios, frequently no\nvisual information will be available about the queried person. In such\nscenarios, a natural language description of the person by a witness will\nprovide the only source of information for retrieval. In this work, person\nre-identification using both vision and language information is addressed under\nall possible gallery and query scenarios. A two stream deep convolutional\nneural network framework supervised by cross entropy loss is presented. The\nweights connecting the second last layer to the last layer with class\nprobabilities, i.e., logits of softmax layer are shared in both networks.\nCanonical Correlation Analysis is performed to enhance the correlation between\nthe two modalities in a joint latent embedding space. To investigate the\nbenefits of the proposed approach, a new testing protocol under a multi modal\nReID setting is proposed for the test split of the CUHK-PEDES and CUHK-SYSU\nbenchmarks. The experimental results verify the merits of the proposed system.\nThe learnt visual representations are more robust and perform 22\\% better\nduring retrieval as compared to a single modality system. The retrieval with a\nmulti modal query greatly enhances the re-identification capability of the\nsystem quantitatively as well as qualitatively.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:12:02 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Farooq", "Ammarah", ""], ["Awais", "Muhammad", ""], ["Yan", "Fei", ""], ["Kittler", "Josef", ""], ["Akbari", "Ali", ""], ["Khalid", "Syed Safwan", ""]]}, {"id": "2003.00823", "submitter": "Dipesh Tamboli", "authors": "Abhijeet Patil, Dipesh Tamboli, Swati Meena, Deepak Anand, Amit Sethi", "title": "Breast Cancer Histopathology Image Classification and Localization using\n  Multiple Instance Learning", "comments": "Accepted in 2019 5th IEEE International WIE Conference on Electrical\n  and Computer Engineering (WIECON-ECE) and Awarded as best paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer has the highest mortality among cancers in women.\nComputer-aided pathology to analyze microscopic histopathology images for\ndiagnosis with an increasing number of breast cancer patients can bring the\ncost and delays of diagnosis down. Deep learning in histopathology has\nattracted attention over the last decade of achieving state-of-the-art\nperformance in classification and localization tasks. The convolutional neural\nnetwork, a deep learning framework, provides remarkable results in tissue\nimages analysis, but lacks in providing interpretation and reasoning behind the\ndecisions. We aim to provide a better interpretation of classification results\nby providing localization on microscopic histopathology images. We frame the\nimage classification problem as weakly supervised multiple instance learning\nproblem where an image is collection of patches i.e. instances. Attention-based\nmultiple instance learning (A-MIL) learns attention on the patches from the\nimage to localize the malignant and normal regions in an image and use them to\nclassify the image. We present classification and localization results on two\npublicly available BreakHIS and BACH dataset. The classification and\nvisualization results are compared with other recent techniques. The proposed\nmethod achieves better localization results without compromising classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 10:29:16 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Patil", "Abhijeet", ""], ["Tamboli", "Dipesh", ""], ["Meena", "Swati", ""], ["Anand", "Deepak", ""], ["Sethi", "Amit", ""]]}, {"id": "2003.00824", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, Ni Lao", "title": "Multi-Scale Representation Learning for Spatial Feature Distributions\n  using Grid Cells", "comments": "15 pages; Accepted to ICLR 2020 as a spotlight paper", "journal-ref": "ICLR 2020, Apr. 26 - 30, 2020, Addis Ababa, ETHIOPIA", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text encoding models have recently fueled substantial progress\nin NLP. The key idea is to use neural networks to convert words in texts to\nvector space representations based on word positions in a sentence and their\ncontexts, which are suitable for end-to-end training of downstream tasks. We\nsee a strikingly similar situation in spatial analysis, which focuses on\nincorporating both absolute positions and spatial contexts of geographic\nobjects such as POIs into models. A general-purpose representation model for\nspace is valuable for a multitude of tasks. However, no such general model\nexists to date beyond simply applying discretization or feed-forward nets to\ncoordinates, and little effort has been put into jointly modeling distributions\nwith vastly different characteristics, which commonly emerges from GIS data.\nMeanwhile, Nobel Prize-winning Neuroscience research shows that grid cells in\nmammals provide a multi-scale periodic representation that functions as a\nmetric for location encoding and is critical for recognizing places and for\npath-integration. Therefore, we propose a representation learning model called\nSpace2Vec to encode the absolute positions and spatial relationships of places.\nWe conduct experiments on two real-world geographic data for two different\ntasks: 1) predicting types of POIs given their positions and context, 2) image\nclassification leveraging their geo-locations. Results show that because of its\nmulti-scale representations, Space2Vec outperforms well-established ML\napproaches such as RBF kernels, multi-layer feed-forward nets, and tile\nembedding approaches for location modeling and image classification tasks.\nDetailed analysis shows that all baselines can at most well handle distribution\nat one scale but show poor performances in other scales. In contrast,\nSpace2Vec's multi-scale representation can handle distributions at different\nscales.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:22:18 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Yan", "Bo", ""], ["Zhu", "Rui", ""], ["Cai", "Ling", ""], ["Lao", "Ni", ""]]}, {"id": "2003.00826", "submitter": "Muhammed Sit", "authors": "Akshat Gautam, Muhammed Sit and Ibrahim Demir", "title": "Realistic River Image Synthesis using Deep Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrated a practical application of realistic river\nimage generation using deep learning. Specifically, we explored a generative\nadversarial network (GAN) model capable of generating high-resolution and\nrealistic river images that can be used to support modeling and analysis in\nsurface water estimation, river meandering, wetland loss, and other\nhydrological research studies. First, we have created an extensive repository\nof overhead river images to be used in training. Second, we incorporated the\nProgressive Growing GAN (PGGAN), a network architecture that iteratively trains\nsmaller-resolution GANs to gradually build up to a very high resolution to\ngenerate high quality (i.e., 1024x1024) synthetic river imagery. With simpler\nGAN architectures, difficulties arose in terms of exponential increase of\ntraining time and vanishing/exploding gradient issues, which the PGGAN\nimplementation seemed to significantly reduce. The results presented in this\nstudy show great promise in generating high-quality images and capturing the\ndetails of river structure and flow to support hydrological research, which\noften requires extensive imagery for model performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:49:33 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 04:46:50 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 21:02:06 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Gautam", "Akshat", ""], ["Sit", "Muhammed", ""], ["Demir", "Ibrahim", ""]]}, {"id": "2003.00827", "submitter": "Laleh Seyyed-Kalantari", "authors": "Laleh Seyyed-Kalantari, Guanxiong Liu, Matthew McDermott, Irene Y.\n  Chen, Marzyeh Ghassemi", "title": "CheXclusion: Fairness gaps in deep chest X-ray classifiers", "comments": "Paper is accepted in Pacific Symposium on Biocomputing 2021\n  (PSB2021). Code can be found at, https://github.com/LalehSeyyed/CheXclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have received much attention recently for their\nability to achieve expert-level performance on clinical tasks, particularly in\nmedical imaging. Here, we examine the extent to which state-of-the-art deep\nlearning classifiers trained to yield diagnostic labels from X-ray images are\nbiased with respect to protected attributes. We train convolution neural\nnetworks to predict 14 diagnostic labels in 3 prominent public chest X-ray\ndatasets: MIMIC-CXR, Chest-Xray8, CheXpert, as well as a multi-site aggregation\nof all those datasets. We evaluate the TPR disparity -- the difference in true\npositive rates (TPR) -- among different protected attributes such as patient\nsex, age, race, and insurance type as a proxy for socioeconomic status. We\ndemonstrate that TPR disparities exist in the state-of-the-art classifiers in\nall datasets, for all clinical tasks, and all subgroups. A multi-source dataset\ncorresponds to the smallest disparities, suggesting one way to reduce bias. We\nfind that TPR disparities are not significantly correlated with a subgroup's\nproportional disease burden. As clinical models move from papers to products,\nwe encourage clinical decision makers to carefully audit for algorithmic\ndisparities prior to deployment. Our code can be found at,\nhttps://github.com/LalehSeyyed/CheXclusion\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:08:12 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:26:20 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Seyyed-Kalantari", "Laleh", ""], ["Liu", "Guanxiong", ""], ["McDermott", "Matthew", ""], ["Chen", "Irene Y.", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2003.00830", "submitter": "Mostafa El-Khamy", "authors": "Qingfeng Liu, Mostafa El-Khamy, Dongwoon Bai, Jungwon Lee", "title": "GSANet: Semantic Segmentation with Global and Selective Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep learning architecture for semantic\nsegmentation. The proposed Global and Selective Attention Network (GSANet)\nfeatures Atrous Spatial Pyramid Pooling (ASPP) with a novel sparsemax global\nattention and a novel selective attention that deploys a condensation and\ndiffusion mechanism to aggregate the multi-scale contextual information from\nthe extracted deep features. A selective attention decoder is also proposed to\nprocess the GSA-ASPP outputs for optimizing the softmax volume. We are the\nfirst to benchmark the performance of semantic segmentation networks with the\nlow-complexity feature extraction network (FXN) MobileNetEdge, that is\noptimized for low latency on edge devices. We show that GSANet can result in\nmore accurate segmentation with MobileNetEdge, as well as with strong FXNs,\nsuch as Xception. GSANet improves the state-of-art semantic segmentation\naccuracy on both the ADE20k and the Cityscapes datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:09:42 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Liu", "Qingfeng", ""], ["El-Khamy", "Mostafa", ""], ["Bai", "Dongwoon", ""], ["Lee", "Jungwon", ""]]}, {"id": "2003.00842", "submitter": "Changmin Wu", "authors": "Changmin Wu, Giannis Nikolentzos, Michalis Vazirgiannis", "title": "EvoNet: A Neural Network for Predicting the Evolution of Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks for structured data like graphs have been studied extensively\nin recent years. To date, the bulk of research activity has focused mainly on\nstatic graphs. However, most real-world networks are dynamic since their\ntopology tends to change over time. Predicting the evolution of dynamic graphs\nis a task of high significance in the area of graph mining. Despite its\npractical importance, the task has not been explored in depth so far, mainly\ndue to its challenging nature. In this paper, we propose a model that predicts\nthe evolution of dynamic graphs. Specifically, we use a graph neural network\nalong with a recurrent architecture to capture the temporal evolution patterns\nof dynamic graphs. Then, we employ a generative model which predicts the\ntopology of the graph at the next time step and constructs a graph instance\nthat corresponds to that topology. We evaluate the proposed model on several\nartificial datasets following common network evolving dynamics, as well as on\nreal-world datasets. Results demonstrate the effectiveness of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:59:05 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wu", "Changmin", ""], ["Nikolentzos", "Giannis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2003.00844", "submitter": "Kirankumar Shiragur", "authors": "Moses Charikar, Kirankumar Shiragur, Aaron Sidford", "title": "A General Framework for Symmetric Property Estimation", "comments": "Published in Neural Information Processing Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a general framework for estimating symmetric\nproperties of distributions from i.i.d. samples. For a broad class of symmetric\nproperties we identify the easy region where empirical estimation works and the\ndifficult region where more complex estimators are required. We show that by\napproximately computing the profile maximum likelihood (PML) distribution\n\\cite{ADOS16} in this difficult region we obtain a symmetric property\nestimation framework that is sample complexity optimal for many properties in a\nbroader parameter regime than previous universal estimation approaches based on\nPML. The resulting algorithms based on these pseudo PML distributions are also\nmore practical.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:00:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Charikar", "Moses", ""], ["Shiragur", "Kirankumar", ""], ["Sidford", "Aaron", ""]]}, {"id": "2003.00845", "submitter": "Samarth Bharadwaj", "authors": "Saneem Ahmed Chemmengath (1), Soumava Paul (2), Samarth Bharadwaj (1),\n  Suranjana Samanta, Karthik Sankaranarayanan ((1) IBM Research, (2) IIT\n  Kharagpur)", "title": "Addressing target shift in zero-shot learning using grouped adversarial\n  learning", "comments": "Under submission at Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) algorithms typically work by exploiting attribute\ncorrelations to be able to make predictions in unseen classes. However, these\ncorrelations do not remain intact at test time in most practical settings and\nthe resulting change in these correlations lead to adverse effects on zero-shot\nlearning performance. In this paper, we present a new paradigm for ZSL that:\n(i) utilizes the class-attribute mapping of unseen classes to estimate the\nchange in target distribution (target shift), and (ii) propose a novel\ntechnique called grouped Adversarial Learning (gAL) to reduce negative effects\nof this shift. Our approach is widely applicable for several existing ZSL\nalgorithms, including those with implicit attribute predictions. We apply the\nproposed technique ($g$AL) on three popular ZSL algorithms: ALE, SJE, and\nDEVISE, and show performance improvements on 4 popular ZSL datasets: AwA2, aPY,\nCUB and SUN. We obtain SOTA results on SUN and aPY datasets and achieve\ncomparable results on AwA2.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:00:27 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 11:38:50 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chemmengath", "Saneem Ahmed", ""], ["Paul", "Soumava", ""], ["Bharadwaj", "Samarth", ""], ["Samanta", "Suranjana", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "2003.00848", "submitter": "Yao Mu", "authors": "Yao Mu, Shengbo Eben Li, Chang Liu, Qi Sun, Bingbing Nie, Bo Cheng,\n  and Baiyu Peng", "title": "Mixed Reinforcement Learning with Additive Stochastic Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) methods often rely on massive exploration data to\nsearch optimal policies, and suffer from poor sampling efficiency. This paper\npresents a mixed reinforcement learning (mixed RL) algorithm by simultaneously\nusing dual representations of environmental dynamics to search the optimal\npolicy with the purpose of improving both learning accuracy and training speed.\nThe dual representations indicate the environmental model and the state-action\ndata: the former can accelerate the learning process of RL, while its inherent\nmodel uncertainty generally leads to worse policy accuracy than the latter,\nwhich comes from direct measurements of states and actions. In the framework\ndesign of the mixed RL, the compensation of the additive stochastic model\nuncertainty is embedded inside the policy iteration RL framework by using\nexplored state-action data via iterative Bayesian estimator (IBE). The optimal\npolicy is then computed in an iterative way by alternating between policy\nevaluation (PEV) and policy improvement (PIM). The convergence of the mixed RL\nis proved using the Bellman's principle of optimality, and the recursive\nstability of the generated policy is proved via the Lyapunov's direct method.\nThe effectiveness of the mixed RL is demonstrated by a typical optimal control\nproblem of stochastic non-affine nonlinear systems (i.e., double lane change\ntask with an automated vehicle).\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:02:34 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Mu", "Yao", ""], ["Li", "Shengbo Eben", ""], ["Liu", "Chang", ""], ["Sun", "Qi", ""], ["Nie", "Bingbing", ""], ["Cheng", "Bo", ""], ["Peng", "Baiyu", ""]]}, {"id": "2003.00856", "submitter": "Chenxi Xiao", "authors": "Chenxi Xiao and Juan Wachs", "title": "Triangle-Net: Towards Robustness in Point Cloud Classification", "comments": "Submitted to ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object recognition is becoming a key desired capability for many computer\nvision systems such as autonomous vehicles, service robots and surveillance\ndrones to operate more effectively in unstructured environments. These\nreal-time systems require effective classification methods that are robust to\nsampling resolution, measurement noise, and pose configuration of the objects.\nPrevious research has shown that sparsity, rotation and positional variance of\npoints can lead to a significant drop in the performance of point cloud based\nclassification techniques. In this regard, we propose a novel approach for 3D\nclassification that takes sparse point clouds as input and learns a model that\nis robust to rotational and positional variance as well as point sparsity. To\nthis end, we introduce new feature descriptors which are fed as an input to our\nproposed neural network in order to learn a robust latent representation of the\n3D object. We show that such latent representations can significantly improve\nthe performance of object classification and retrieval. Further, we show that\nour approach outperforms PointNet and 3DmFV by 34.4% and 27.4% respectively in\nclassification tasks using sparse point clouds of only 16 points under\narbitrary SO(3) rotation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 20:42:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xiao", "Chenxi", ""], ["Wachs", "Juan", ""]]}, {"id": "2003.00865", "submitter": "Sakshi Udeshi", "authors": "Ezekiel Soremekun, Sakshi Udeshi and Sudipta Chattopadhyay", "title": "Exposing Backdoors in Robust Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The introduction of robust optimisation has pushed the state-of-the-art in\ndefending against adversarial attacks. However, the behaviour of such\noptimisation has not been studied in the light of a fundamentally different\nclass of attacks called backdoors. In this paper, we demonstrate that\nadversarially robust models are susceptible to backdoor attacks. Subsequently,\nwe observe that backdoors are reflected in the feature representation of such\nmodels. Then, this observation is leveraged to detect backdoor-infected models\nvia a detection technique called AEGIS. Specifically, AEGIS uses feature\nclustering to effectively detect backdoor-infected robust Deep Neural Networks\n(DNNs). In our evaluation of several visible and hidden backdoor triggers on\nmajor classification tasks using CIFAR-10, MNIST and FMNIST datasets, AEGIS\neffectively detects robust DNNs infected with backdoors. AEGIS detects a\nbackdoor-infected model with 91.6% accuracy, without any false positives.\nFurthermore, AEGIS detects the targeted class in the backdoor-infected model\nwith a reasonably low (11.1%) false positive rate. Our investigation reveals\nthat salient features of adversarially robust DNNs break the stealthy nature of\nbackdoor attacks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 04:45:26 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:15:36 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 07:02:14 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Soremekun", "Ezekiel", ""], ["Udeshi", "Sakshi", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "2003.00868", "submitter": "Wujie Wang", "authors": "Wujie Wang, Simon Axelrod, Rafael G\\'omez-Bombarelli", "title": "Differentiable Molecular Simulations for Control and Learning", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics simulations use statistical mechanics at the atomistic\nscale to enable both the elucidation of fundamental mechanisms and the\nengineering of matter for desired tasks. The behavior of molecular systems at\nthe microscale is typically simulated with differential equations parameterized\nby a Hamiltonian, or energy function. The Hamiltonian describes the state of\nthe system and its interactions with the environment. In order to derive\npredictive microscopic models, one wishes to infer a molecular Hamiltonian that\nagrees with observed macroscopic quantities. From the perspective of\nengineering, one wishes to control the Hamiltonian to achieve desired\nsimulation outcomes and structures, as in self-assembly and optical control, to\nthen realize systems with the desired Hamiltonian in the lab. In both cases,\nthe goal is to modify the Hamiltonian such that emergent properties of the\nsimulated system match a given target. We demonstrate how this can be achieved\nusing differentiable simulations where bulk target observables and simulation\noutcomes can be analytically differentiated with respect to Hamiltonians,\nopening up new routes for parameterizing Hamiltonians to infer macroscopic\nmodels and develop control protocols.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:35:19 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 00:14:43 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Wang", "Wujie", ""], ["Axelrod", "Simon", ""], ["G\u00f3mez-Bombarelli", "Rafael", ""]]}, {"id": "2003.00874", "submitter": "Jinfu Lin", "authors": "Xiaojian He, Jinfu Lin, Junming Shen", "title": "Weakly-supervised Object Localization for Few-shot Learning and\n  Fine-grained Few-shot Learning", "comments": "8 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning (FSL) aims to learn novel visual categories from very few\nsamples, which is a challenging problem in real-world applications. Many\nmethods of few-shot classification work well on general images to learn global\nrepresentation. However, they can not deal with fine-grained categories well at\nthe same time due to a lack of subtle and local information. We argue that\nlocalization is an efficient approach because it directly provides the\ndiscriminative regions, which is critical for both general classification and\nfine-grained classification in a low data regime. In this paper, we propose a\nSelf-Attention Based Complementary Module (SAC Module) to fulfill the\nweakly-supervised object localization, and more importantly produce the\nactivated masks for selecting discriminative deep descriptors for few-shot\nclassification. Based on each selected deep descriptor, Semantic Alignment\nModule (SAM) calculates the semantic alignment distance between the query and\nsupport images to boost classification performance. Extensive experiments show\nour method outperforms the state-of-the-art methods on benchmark datasets under\nvarious settings, especially on the fine-grained few-shot tasks. Besides, our\nmethod achieves superior performance over previous methods when training the\nmodel on miniImageNet and evaluating it on the different datasets,\ndemonstrating its superior generalization capacity. Extra visualization shows\nthe proposed method can localize the key objects more interval.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:07:05 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 13:27:47 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 02:50:57 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["He", "Xiaojian", ""], ["Lin", "Jinfu", ""], ["Shen", "Junming", ""]]}, {"id": "2003.00875", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "Predicting TUG score from gait characteristics with video analysis and\n  machine learning", "comments": "Experimental results and discussion are revised. The code for\n  estimating copula entropy is available at https://github.com/majianthu/copent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fall is a leading cause of death which suffers the elderly and society. Timed\nUp and Go (TUG) test is a common tool for fall risk assessment. In this paper,\nwe propose a method for predicting TUG score from gait characteristics\nextracted from video with computer vision and machine learning technologies.\nFirst, 3D pose is estimated from video captured with 2D and 3D cameras during\nhuman motion and then a group of gait characteristics are computed from 3D pose\nseries. After that, copula entropy is used to select those characteristics\nwhich are mostly associated with TUG score. Finally, the selected\ncharacteristics are fed into the predictive models to predict TUG score.\nExperiments on real world data demonstrated the effectiveness of the proposed\nmethod. As a byproduct, the associations between TUG score and several gait\ncharacteristics are discovered, which laid the scientific foundation of the\nproposed method and make the predictive models such built interpretable to\nclinical users.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:27:37 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 11:34:58 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "2003.00877", "submitter": "Chuanxing Geng", "authors": "Chuanxing Geng, Zhenghao Tan, Songcan Chen", "title": "A Multi-view Perspective of Self-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a newly emerging unsupervised learning paradigm, self-supervised learning\n(SSL) recently gained widespread attention, which usually introduces a pretext\ntask without manual annotation of data. With its help, SSL effectively learns\nthe feature representation beneficial for downstream tasks. Thus the pretext\ntask plays a key role. However, the study of its design, especially its essence\ncurrently is still open. In this paper, we borrow a multi-view perspective to\ndecouple a class of popular pretext tasks into a combination of view data\naugmentation (VDA) and view label classification (VLC), where we attempt to\nexplore the essence of such pretext task while providing some insights into its\ndesign. Specifically, a simple multi-view learning framework is specially\ndesigned (SSL-MV), which assists the feature learning of downstream tasks\n(original view) through the same tasks on the augmented views. SSL-MV focuses\non VDA while abandons VLC, empirically uncovering that it is VDA rather than\ngenerally considered VLC that dominates the performance of such SSL.\nAdditionally, thanks to replacing VLC with VDA tasks, SSL-MV also enables an\nintegrated inference combining the predictions from the augmented views,\nfurther improving the performance. Experiments on several benchmark datasets\ndemonstrate its advantages.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 13:26:00 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 04:20:00 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Geng", "Chuanxing", ""], ["Tan", "Zhenghao", ""], ["Chen", "Songcan", ""]]}, {"id": "2003.00878", "submitter": "Ziyue Xiang", "authors": "Daniel E. Acuna and Ziyue Xiang", "title": "Estimating a Null Model of Scientific Image Reuse to Support Research\n  Integrity Investigations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When there is a suspicious figure reuse case in science, research integrity\ninvestigators often find it difficult to rebut authors claiming that \"it\nhappened by chance\". In other words, when there is a \"collision\" of image\nfeatures, it is difficult to justify whether it appears rarely or not. In this\narticle, we provide a method to predict the rarity of an image feature by\nstatistically estimating the chance of it randomly occurring across all\nscientific imagery. Our method is based on high-dimensional density estimation\nof ORB features using 7+ million images in the PubMed Open Access Subset\ndataset. We show that this method can lead to meaningful feedback during\nresearch integrity investigations by providing a null hypothesis for scientific\nimage reuse and thus a p-value during deliberations. We apply the model to a\nsample of increasingly complex imagery and confirm that it produces\ndecreasingly smaller p-values as expected. We discuss applications to research\nintegrity investigations as well as future work.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 02:41:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Acuna", "Daniel E.", ""], ["Xiang", "Ziyue", ""]]}, {"id": "2003.00880", "submitter": "Stanton Price", "authors": "Stanton R. Price, Steven R. Price, Derek T. Anderson", "title": "Introducing Fuzzy Layers for Deep Learning", "comments": "6 pages, 4 figures, published in 2019 IEEE International Conference\n  on Fuzzy Systems (FUZZ-IEEE)", "journal-ref": "IEEE International Conference on Fuzzy Systems (FUZZ-IEEE), New\n  Orleans, LA, USA, 2019, pp. 1-6", "doi": "10.1109/FUZZ-IEEE.2019.8858790", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art technologies developed in recent years have been\ninfluenced by machine learning to some extent. Most popular at the time of this\nwriting are artificial intelligence methodologies that fall under the umbrella\nof deep learning. Deep learning has been shown across many applications to be\nextremely powerful and capable of handling problems that possess great\ncomplexity and difficulty. In this work, we introduce a new layer to deep\nlearning: the fuzzy layer. Traditionally, the network architecture of neural\nnetworks is composed of an input layer, some combination of hidden layers, and\nan output layer. We propose the introduction of fuzzy layers into the deep\nlearning architecture to exploit the powerful aggregation properties expressed\nthrough fuzzy methodologies, such as the Choquet and Sugueno fuzzy integrals.\nTo date, fuzzy approaches taken to deep learning have been through the\napplication of various fusion strategies at the decision level to aggregate\noutputs from state-of-the-art pre-trained models, e.g., AlexNet, VGG16,\nGoogLeNet, Inception-v3, ResNet-18, etc. While these strategies have been shown\nto improve accuracy performance for image classification tasks, none have\nexplored the use of fuzzified intermediate, or hidden, layers. Herein, we\npresent a new deep learning strategy that incorporates fuzzy strategies into\nthe deep learning architecture focused on the application of semantic\nsegmentation using per-pixel classification. Experiments are conducted on a\nbenchmark data set as well as a data set collected via an unmanned aerial\nsystem at a U.S. Army test site for the task of automatic road segmentation,\nand preliminary results are promising.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:33:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Price", "Stanton R.", ""], ["Price", "Steven R.", ""], ["Anderson", "Derek T.", ""]]}, {"id": "2003.00882", "submitter": "Freddie Bickford Smith", "authors": "Freddie Bickford Smith, Xiaoliang Luo, Brett D. Roads, Bradley C. Love", "title": "The perceptual boost of visual attention is task-dependent in\n  naturalistic settings", "comments": "Published as a workshop paper at \"Bridging AI and Cognitive Science\"\n  (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-down attention allows people to focus on task-relevant visual\ninformation. Is the resulting perceptual boost task-dependent in naturalistic\nsettings? We aim to answer this with a large-scale computational experiment.\nFirst, we design a collection of visual tasks, each consisting of classifying\nimages from a chosen task set (subset of ImageNet categories). The nature of a\ntask is determined by which categories are included in the task set. Second, on\neach task we train an attention-augmented neural network and then compare its\naccuracy to that of a baseline network. We show that the perceptual boost of\nattention is stronger with increasing task-set difficulty, weaker with\nincreasing task-set size and weaker with increasing perceptual similarity\nwithin a task set.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 09:10:24 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:30:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Smith", "Freddie Bickford", ""], ["Luo", "Xiaoliang", ""], ["Roads", "Brett D.", ""], ["Love", "Bradley C.", ""]]}, {"id": "2003.00883", "submitter": "Camilo Pestana", "authors": "Camilo Pestana, Naveed Akhtar, Wei Liu, David Glance, Ajmal Mian", "title": "Adversarial Perturbations Prevail in the Y-Channel of the YCbCr Color\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning offers state of the art solutions for image recognition.\nHowever, deep models are vulnerable to adversarial perturbations in images that\nare subtle but significantly change the model's prediction. In a white-box\nattack, these perturbations are generally learned for deep models that operate\non RGB images and, hence, the perturbations are equally distributed in the RGB\ncolor space. In this paper, we show that the adversarial perturbations prevail\nin the Y-channel of the YCbCr space. Our finding is motivated from the fact\nthat the human vision and deep models are more responsive to shape and texture\nrather than color. Based on our finding, we propose a defense against\nadversarial images. Our defence, coined ResUpNet, removes perturbations only\nfrom the Y-channel by exploiting ResNet features in an upsampling framework\nwithout the need for a bottleneck. At the final stage, the untouched\nCbCr-channels are combined with the refined Y-channel to restore the clean\nimage. Note that ResUpNet is model agnostic as it does not modify the DNN\nstructure. ResUpNet is trained end-to-end in Pytorch and the results are\ncompared to existing defence techniques in the input transformation category.\nOur results show that our approach achieves the best balance between defence\nagainst adversarial attacks such as FGSM, PGD and DDN and maintaining the\noriginal accuracies of VGG-16, ResNet50 and DenseNet121 on clean images. We\nperform another experiment to show that learning adversarial perturbations only\nfor the Y-channel results in higher fooling rates for the same perturbation\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 02:41:42 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Pestana", "Camilo", ""], ["Akhtar", "Naveed", ""], ["Liu", "Wei", ""], ["Glance", "David", ""], ["Mian", "Ajmal", ""]]}, {"id": "2003.00891", "submitter": "Steffen Wolf", "authors": "Steffen Wolf, Fred A. Hamprecht, Jan Funke", "title": "Instance Separation Emerges from Inpainting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained to inpaint partially occluded images show a deep\nunderstanding of image composition and have even been shown to remove objects\nfrom images convincingly. In this work, we investigate how this implicit\nknowledge of image composition can be leveraged for fully self-supervised\ninstance separation. We propose a measure for the independence of two image\nregions given a fully self-supervised inpainting network and separate objects\nby maximizing this independence. We evaluate our method on two microscopy image\ndatasets and show that it reaches similar segmentation performance to fully\nsupervised methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:05:39 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wolf", "Steffen", ""], ["Hamprecht", "Fred A.", ""], ["Funke", "Jan", ""]]}, {"id": "2003.00894", "submitter": "Vladimir Pestov", "authors": "Beno\\^it Collins, Sushma Kumari, and Vladimir G. Pestov", "title": "Universal consistency of the $k$-NN rule in metric spaces and Nagata\n  dimension", "comments": "21 pp., 2 figures, latex with ESAIM: Probability and Statistics\n  macros, a version with the two anonymous referees comments taken into account", "journal-ref": "ESAIM: Probability and Statistics 24 (2020), 914--934", "doi": "10.1051/ps/2020018", "report-no": null, "categories": "math.MG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$ nearest neighbour learning rule (under the uniform distance tie\nbreaking) is universally consistent in every metric space $X$ that is\nsigma-finite dimensional in the sense of Nagata. This was pointed out by\nC\\'erou and Guyader (2006) as a consequence of the main result by those\nauthors, combined with a theorem in real analysis sketched by D. Preiss (1971)\n(and elaborated in detail by Assouad and Quentin de Gromard (2006)). We show\nthat it is possible to give a direct proof along the same lines as the original\ntheorem of Charles J. Stone (1977) about the universal consistency of the\n$k$-NN classifier in the finite dimensional Euclidean space. The generalization\nis non-trivial because of the distance ties being more prevalent in the\nnon-euclidean setting, and on the way we investigate the relevant geometric\nproperties of the metrics and the limitations of the Stone argument, by\nconstructing various examples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:59:47 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 17:57:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Collins", "Beno\u00eet", ""], ["Kumari", "Sushma", ""], ["Pestov", "Vladimir G.", ""]]}, {"id": "2003.00911", "submitter": "Fuzhen Zhuang", "authors": "Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong\n  and Qing He", "title": "A Survey on Knowledge Graph-Based Recommender Systems", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the information explosion problem and enhance user experience in\nvarious online applications, recommender systems have been developed to model\nusers preferences. Although numerous efforts have been made toward more\npersonalized recommendations, recommender systems still suffer from several\nchallenges, such as data sparsity and cold start. In recent years, generating\nrecommendations with the knowledge graph as side information has attracted\nconsiderable interest. Such an approach can not only alleviate the\nabovementioned issues for a more accurate recommendation, but also provide\nexplanations for recommended items. In this paper, we conduct a systematical\nsurvey of knowledge graph-based recommender systems. We collect recently\npublished papers in this field and summarize them from two perspectives. On the\none hand, we investigate the proposed algorithms by focusing on how the papers\nutilize the knowledge graph for accurate and explainable recommendation. On the\nother hand, we introduce datasets used in these works. Finally, we propose\nseveral potential research directions in this field.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 02:26:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Guo", "Qingyu", ""], ["Zhuang", "Fuzhen", ""], ["Qin", "Chuan", ""], ["Zhu", "Hengshu", ""], ["Xie", "Xing", ""], ["Xiong", "Hui", ""], ["He", "Qing", ""]]}, {"id": "2003.00920", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes, Alessandro Rudi, Francis Bach", "title": "Structured Prediction with Partial Labelling through the Infimum Loss", "comments": "8 pages for main paper, 27 with main paper, 13 figures, 3 tables", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:1230-1239, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating datasets is one of the main costs in nowadays supervised learning.\nThe goal of weak supervision is to enable models to learn using only forms of\nlabelling which are cheaper to collect, as partial labelling. This is a type of\nincomplete annotation where, for each datapoint, supervision is cast as a set\nof labels containing the real one. The problem of supervised learning with\npartial labelling has been studied for specific instances such as\nclassification, multi-label, ranking or segmentation, but a general framework\nis still missing. This paper provides a unified framework based on structured\nprediction and on the concept of infimum loss to deal with partial labelling\nover a wide family of learning problems and loss functions. The framework leads\nnaturally to explicit algorithms that can be easily implemented and for which\nproved statistical consistency and learning rates. Experiments confirm the\nsuperiority of the proposed approach over commonly used baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:59:41 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:34:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cabannes", "Vivien", ""], ["Rudi", "Alessandro", ""], ["Bach", "Francis", ""]]}, {"id": "2003.00937", "submitter": "Yi-Rui Yang", "authors": "Yi-Rui Yang, Wu-Jun Li", "title": "BASGD: Buffered Asynchronous SGD for Byzantine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning has become a hot research topic, due to its wide\napplication in cluster-based large-scale learning, federated learning, edge\ncomputing and so on. Most distributed learning methods assume no error and\nattack on the workers. However, many unexpected cases, such as communication\nerror and even malicious attack, may happen in real applications. Hence,\nByzantine learning (BL), which refers to distributed learning with attack or\nerror, has recently attracted much attention. Most existing BL methods are\nsynchronous, which will result in slow convergence when there exist\nheterogeneous workers. Furthermore, in some applications like federated\nlearning and edge computing, synchronization cannot even be performed most of\nthe time due to the online workers (clients or edge servers). Hence,\nasynchronous BL (ABL) is more general and practical than synchronous BL (SBL).\nTo the best of our knowledge, there exist only two ABL methods. One of them\ncannot resist malicious attack. The other needs to store some training\ninstances on the server, which has the privacy leak problem. In this paper, we\npropose a novel method, called buffered asynchronous stochastic gradient\ndescent (BASGD), for BL. BASGD is an asynchronous method. Furthermore, BASGD\nhas no need to store any training instances on the server, and hence can\npreserve privacy in ABL. BASGD is theoretically proved to have the ability of\nresisting against error and malicious attack. Moreover, BASGD has a similar\ntheoretical convergence rate to that of vanilla asynchronous SGD (ASGD), with\nan extra constant variance. Empirical results show that BASGD can significantly\noutperform vanilla ASGD and other ABL baselines, when there exists error or\nattack on workers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:34:28 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 09:06:33 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 09:06:17 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yang", "Yi-Rui", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2003.00952", "submitter": "Jary Pomponi", "authors": "Jary Pomponi, Simone Scardapane, and Aurelio Uncini", "title": "Bayesian Neural Networks With Maximum Mean Discrepancy Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNNs) are trained to optimize an entire\ndistribution over their weights instead of a single set, having significant\nadvantages in terms of, e.g., interpretability, multi-task learning, and\ncalibration. Because of the intractability of the resulting optimization\nproblem, most BNNs are either sampled through Monte Carlo methods, or trained\nby minimizing a suitable Evidence Lower BOund (ELBO) on a variational\napproximation. In this paper, we propose a variant of the latter, wherein we\nreplace the Kullback-Leibler divergence in the ELBO term with a Maximum Mean\nDiscrepancy (MMD) estimator, inspired by recent work in variational inference.\nAfter motivating our proposal based on the properties of the MMD term, we\nproceed to show a number of empirical advantages of the proposed formulation\nover the state-of-the-art. In particular, our BNNs achieve higher accuracy on\nmultiple benchmarks, including several image classification tasks. In addition,\nthey are more robust to the selection of a prior over the weights, and they are\nbetter calibrated. As a second contribution, we provide a new formulation for\nestimating the uncertainty on a given prediction, showing it performs in a more\nrobust fashion against adversarial attacks and the injection of noise over\ntheir inputs, compared to more classical criteria such as the differential\nentropy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:54:48 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:56:44 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pomponi", "Jary", ""], ["Scardapane", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2003.00973", "submitter": "Debabrota Basu", "authors": "Ashish Dandekar, Debabrota Basu, Stephane Bressan", "title": "Differential Privacy at Risk: Bridging Randomness and Privacy Budget", "comments": "Presented in Workshop on Privacy Preserving AI (PPAI) at AAAI, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The calibration of noise for a privacy-preserving mechanism depends on the\nsensitivity of the query and the prescribed privacy level. A data steward must\nmake the non-trivial choice of a privacy level that balances the requirements\nof users and the monetary constraints of the business entity. We analyse roles\nof the sources of randomness, namely the explicit randomness induced by the\nnoise distribution and the implicit randomness induced by the data-generation\ndistribution, that are involved in the design of a privacy-preserving\nmechanism. The finer analysis enables us to provide stronger privacy guarantees\nwith quantifiable risks. Thus, we propose privacy at risk that is a\nprobabilistic calibration of privacy-preserving mechanisms. We provide a\ncomposition theorem that leverages privacy at risk. We instantiate the\nprobabilistic calibration for the Laplace mechanism by providing analytical\nresults. We also propose a cost model that bridges the gap between the privacy\nlevel and the compensation budget estimated by a GDPR compliant business\nentity. The convexity of the proposed cost model leads to a unique fine-tuning\nof privacy level that minimises the compensation budget. We show its\neffectiveness by illustrating a realistic scenario that avoids overestimation\nof the compensation budget by using privacy at risk for the Laplace mechanism.\nWe quantitatively show that composition using the cost optimal privacy at risk\nprovides stronger privacy guarantee than the classical advanced composition.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:44:14 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 23:14:27 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Dandekar", "Ashish", ""], ["Basu", "Debabrota", ""], ["Bressan", "Stephane", ""]]}, {"id": "2003.00982", "submitter": "Vijay Prakash Dwivedi", "authors": "Vijay Prakash Dwivedi, Chaitanya K. Joshi, Thomas Laurent, Yoshua\n  Bengio, Xavier Bresson", "title": "Benchmarking Graph Neural Networks", "comments": "Benchmarking framework on GitHub at\n  https://github.com/graphdeeplearning/benchmarking-gnns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have become the standard toolkit for analyzing\nand learning from data on graphs. As the field grows, it becomes critical to\nidentify key architectures and validate new ideas that generalize to larger,\nmore complex datasets. Unfortunately, it has been increasingly difficult to\ngauge the effectiveness of new models in the absence of a standardized\nbenchmark with consistent experimental settings. In this paper, we introduce a\nreproducible GNN benchmarking framework, with the facility for researchers to\nadd new models conveniently for arbitrary datasets. We demonstrate the\nusefulness of our framework by presenting a principled investigation into the\nrecent Weisfeiler-Lehman GNNs (WL-GNNs) compared to message passing-based graph\nconvolutional networks (GCNs) for a variety of graph tasks, i.e. graph\nregression/classification and node/link prediction, with medium-scale datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:58:46 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 16:45:15 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 16:38:28 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Dwivedi", "Vijay Prakash", ""], ["Joshi", "Chaitanya K.", ""], ["Laurent", "Thomas", ""], ["Bengio", "Yoshua", ""], ["Bresson", "Xavier", ""]]}, {"id": "2003.00992", "submitter": "Edric Tam", "authors": "Edric Tam and David Dunson", "title": "Fiedler Regularization: Learning Neural Networks with Graph Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel regularization approach for deep learning that\nincorporates and respects the underlying graphical structure of the neural\nnetwork. Existing regularization methods often focus on dropping/penalizing\nweights in a global manner that ignores the connectivity structure of the\nneural network. We propose to use the Fiedler value of the neural network's\nunderlying graph as a tool for regularization. We provide theoretical support\nfor this approach via spectral graph theory. We list several useful properties\nof the Fiedler value that makes it suitable in regularization. We provide an\napproximate, variational approach for fast computation in practical training of\nneural networks. We provide bounds on such approximations. We provide an\nalternative but equivalent formulation of this framework in the form of a\nstructurally weighted L1 penalty, thus linking our approach to sparsity\ninduction. We performed experiments on datasets that compare Fiedler\nregularization with traditional regularization methods such as dropout and\nweight decay. Results demonstrate the efficacy of Fiedler regularization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:19:33 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 19:11:43 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 08:39:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tam", "Edric", ""], ["Dunson", "David", ""]]}, {"id": "2003.00997", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Generating Higher-Fidelity Synthetic Datasets with Privacy Guarantees", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of enhancing user privacy in common machine\nlearning development tasks, such as data annotation and inspection, by\nsubstituting the real data with samples form a generative adversarial network.\nWe propose employing Bayesian differential privacy as the means to achieve a\nrigorous theoretical guarantee while providing a better privacy-utility\ntrade-off. We demonstrate experimentally that our approach produces\nhigher-fidelity samples, compared to prior work, allowing to (1) detect more\nsubtle data errors and biases, and (2) reduce the need for real data labelling\nby achieving high accuracy when training directly on artificial samples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:23:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "2003.01000", "submitter": "Javier Garcia-Barcos", "authors": "Javier Garcia-Barcos, Ruben Martinez-Cantin", "title": "Robust Policy Search for Robot Navigation with Stochastic Meta-Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is an efficient nonlinear optimization method where the\nqueries are carefully selected to gather information about the optimum\nlocation. Thus, in the context of policy search, it has been called active\npolicy search. The main ingredients of Bayesian optimization for sample\nefficiency are the probabilistic surrogate model and the optimal decision\nheuristics. In this work, we exploit those to provide robustness to different\nissues for policy search algorithms. We combine several methods and show how\ntheir interaction works better than the sum of the parts. First, to deal with\ninput noise and provide a safe and repeatable policy we use an improved version\nof unscented Bayesian optimization. Then, to deal with mismodeling errors and\nimprove exploration we use stochastic meta-policies for query selection and an\nadaptive kernel. We compare the proposed algorithm with previous results in\nseveral optimization benchmarks and robot tasks, such as pushing objects with a\nrobot arm, or path finding with a rover.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:30:59 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Garcia-Barcos", "Javier", ""], ["Martinez-Cantin", "Ruben", ""]]}, {"id": "2003.01013", "submitter": "Yuwei Luo", "authors": "Sen Na, Yuwei Luo, Zhuoran Yang, Zhaoran Wang, Mladen Kolar", "title": "Semiparametric Nonlinear Bipartite Graph Representation Learning with\n  Provable Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is a ubiquitous task in machine learning where\nthe goal is to embed each vertex into a low-dimensional vector space. We\nconsider the bipartite graph and formalize its representation learning problem\nas a statistical estimation problem of parameters in a semiparametric\nexponential family distribution. The bipartite graph is assumed to be generated\nby a semiparametric exponential family distribution, whose parametric component\nis given by the proximity of outputs of two one-layer neural networks, while\nnonparametric (nuisance) component is the base measure. Neural networks take\nhigh-dimensional features as inputs and output embedding vectors. In this\nsetting, the representation learning problem is equivalent to recovering the\nweight matrices. The main challenges of estimation arise from the nonlinearity\nof activation functions and the nonparametric nuisance component of the\ndistribution. To overcome these challenges, we propose a pseudo-likelihood\nobjective based on the rank-order decomposition technique and focus on its\nlocal geometry. We show that the proposed objective is strongly convex in a\nneighborhood around the ground truth, so that a gradient descent-based method\nachieves linear convergence rate. Moreover, we prove that the sample complexity\nof the problem is linear in dimensions (up to logarithmic factors), which is\nconsistent with parametric Gaussian models. However, our estimator is robust to\nany model misspecification within the exponential family, which is validated in\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:40:36 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Na", "Sen", ""], ["Luo", "Yuwei", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Kolar", "Mladen", ""]]}, {"id": "2003.01039", "submitter": "Jacob Miller", "authors": "Jacob Miller, Guillaume Rabusseau, John Terilla", "title": "Tensor Networks for Probabilistic Sequence Modeling", "comments": "18 pages, 2 figures; v4 conference version; v3 link to code for\n  experiments; v2 major revision with new main result on regular expression\n  sampling. International Conference on Artificial Intelligence and Statistics.\n  PMLR, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor networks are a powerful modeling framework developed for computational\nmany-body physics, which have only recently been applied within machine\nlearning. In this work we utilize a uniform matrix product state (u-MPS) model\nfor probabilistic modeling of sequence data. We first show that u-MPS enable\nsequence-level parallelism, with length-n sequences able to be evaluated in\ndepth O(log n). We then introduce a novel generative algorithm giving trained\nu-MPS the ability to efficiently sample from a wide variety of conditional\ndistributions, each one defined by a regular expression. Special cases of this\nalgorithm correspond to autoregressive and fill-in-the-blank sampling, but more\ncomplex regular expressions permit the generation of richly structured data in\na manner that has no direct analogue in neural generative models. Experiments\non sequence modeling with synthetic and real text data show u-MPS outperforming\na variety of baselines and effectively generalizing their predictions in the\npresence of limited data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:16:05 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 16:45:55 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 14:00:57 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 16:52:06 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Miller", "Jacob", ""], ["Rabusseau", "Guillaume", ""], ["Terilla", "John", ""]]}, {"id": "2003.01043", "submitter": "Ayush Kumar", "authors": "Ayush Kumar, Jithendra Vepa", "title": "Gated Mechanism for Attention Based Multimodal Sentiment Analysis", "comments": "Accepted to appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sentiment analysis has recently gained popularity because of its\nrelevance to social media posts, customer service calls and video blogs. In\nthis paper, we address three aspects of multimodal sentiment analysis; 1. Cross\nmodal interaction learning, i.e. how multiple modalities contribute to the\nsentiment, 2. Learning long-term dependencies in multimodal interactions and 3.\nFusion of unimodal and cross modal cues. Out of these three, we find that\nlearning cross modal interactions is beneficial for this problem. We perform\nexperiments on two benchmark datasets, CMU Multimodal Opinion level Sentiment\nIntensity (CMU-MOSI) and CMU Multimodal Opinion Sentiment and Emotion Intensity\n(CMU-MOSEI) corpus. Our approach on both these tasks yields accuracies of 83.9%\nand 81.1% respectively, which is 1.6% and 1.34% absolute improvement over\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 06:58:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kumar", "Ayush", ""], ["Vepa", "Jithendra", ""]]}, {"id": "2003.01054", "submitter": "St\\'ephane d'Ascoli", "authors": "St\\'ephane d'Ascoli, Maria Refinetti, Giulio Biroli, Florent Krzakala", "title": "Double Trouble in Double Descent : Bias and Variance(s) in the Lazy\n  Regime", "comments": "29 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can achieve remarkable generalization performances while\ninterpolating the training data perfectly. Rather than the U-curve emblematic\nof the bias-variance trade-off, their test error often follows a \"double\ndescent\" - a mark of the beneficial role of overparametrization. In this work,\nwe develop a quantitative theory for this phenomenon in the so-called lazy\nlearning regime of neural networks, by considering the problem of learning a\nhigh-dimensional function with random features regression. We obtain a precise\nasymptotic expression for the bias-variance decomposition of the test error,\nand show that the bias displays a phase transition at the interpolation\nthreshold, beyond which it remains constant. We disentangle the variances\nstemming from the sampling of the dataset, from the additive noise corrupting\nthe labels, and from the initialization of the weights. Following up on Geiger\net al. 2019, we first show that the latter two contributions are the crux of\nthe double descent: they lead to the overfitting peak at the interpolation\nthreshold and to the decay of the test error upon overparametrization. We then\nquantify how they are suppressed by ensemble averaging the outputs of K\nindependently initialized estimators. When K is sent to infinity, the test\nerror remains constant beyond the interpolation threshold. We further compare\nthe effects of overparametrizing, ensembling and regularizing. Finally, we\npresent numerical experiments on classic deep learning setups to show that our\nresults hold qualitatively in realistic lazy learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:39:31 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 07:42:38 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Refinetti", "Maria", ""], ["Biroli", "Giulio", ""], ["Krzakala", "Florent", ""]]}, {"id": "2003.01063", "submitter": "Marija Jegorova", "authors": "Marija Jegorova, Antti Ilari Karjalainen, Jose Vazquez, Timothy M.\n  Hospedales", "title": "Unlimited Resolution Image Generation with R2D2-GANs", "comments": "Accepted to 2020 IEEE OCEANS (Singapore)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel simulation technique for generating high\nquality images of any predefined resolution. This method can be used to\nsynthesize sonar scans of size equivalent to those collected during a\nfull-length mission, with across track resolutions of any chosen magnitude. In\nessence, our model extends Generative Adversarial Networks (GANs) based\narchitecture into a conditional recursive setting, that facilitates the\ncontinuity of the generated images. The data produced is continuous,\nrealistically-looking, and can also be generated at least two times faster than\nthe real speed of acquisition for the sonars with higher resolutions, such as\nEdgeTech. The seabed topography can be fully controlled by the user. The visual\nassessment tests demonstrate that humans cannot distinguish the simulated\nimages from real. Moreover, experimental results suggest that in the absence of\nreal data the autonomous recognition systems can benefit greatly from training\nwith the synthetic data, produced by the R2D2-GANs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:49:32 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Jegorova", "Marija", ""], ["Karjalainen", "Antti Ilari", ""], ["Vazquez", "Jose", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "2003.01067", "submitter": "Naji Shajarisales", "authors": "Naji Shajarisales, Peter Spirtes, Kun Zhang", "title": "Learning from Positive and Unlabeled Data by Identifying the Annotation\n  Process", "comments": "Submitted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In binary classification, Learning from Positive and Unlabeled data (LePU) is\nsemi-supervised learning but with labeled elements from only one class. Most of\nthe research on LePU relies on some form of independence between the selection\nprocess of annotated examples and the features of the annotated class, known as\nthe Selected Completely At Random (SCAR) assumption. Yet the annotation process\nis an important part of the data collection, and in many cases it naturally\ndepends on certain features of the data (e.g., the intensity of an image and\nthe size of the object to be detected in the image). Without any constraints on\nthe model for the annotation process, classification results in the LePU\nproblem will be highly non-unique. So proper, flexible constraints are needed.\nIn this work we incorporate more flexible and realistic models for the\nannotation process than SCAR, and more importantly, offer a solution for the\nchallenging LePU problem. On the theory side, we establish the identifiability\nof the properties of the annotation process and the classification function, in\nlight of the considered constraints on the data-generating process. We also\npropose an inference algorithm to learn the parameters of the model, with\nsuccessful experimental results on both simulated and real data. We also\npropose a novel real-world dataset forLePU, as a benchmark dataset for future\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:57:12 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Shajarisales", "Naji", ""], ["Spirtes", "Peter", ""], ["Zhang", "Kun", ""]]}, {"id": "2003.01074", "submitter": "Ashish Rao", "authors": "Ashish Rao, Bidipta Sarkar, and Tejas Narayanan", "title": "Gaussian Process Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel actor-critic, model-free reinforcement learning algorithm\nwhich employs a Bayesian method of parameter space exploration to solve\nenvironments. A Gaussian process is used to learn the expected return of a\npolicy given the policy's parameters. The system is trained by updating the\nparameters using gradient descent on a new surrogate loss function consisting\nof the Proximal Policy Optimization 'Clipped' loss function and a bonus term\nrepresenting the expected improvement acquisition function given by the\nGaussian process. This new method is shown to be comparable to and at times\nempirically outperform current algorithms on environments that simulate robotic\nlocomotion using the MuJoCo physics engine.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:06:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Rao", "Ashish", ""], ["Sarkar", "Bidipta", ""], ["Narayanan", "Tejas", ""]]}, {"id": "2003.01086", "submitter": "Rui Shu", "authors": "Rui Shu, Tung Nguyen, Yinlam Chow, Tuan Pham, Khoat Than, Mohammad\n  Ghavamzadeh, Stefano Ermon, Hung H. Bui", "title": "Predictive Coding for Locally-Linear Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional observations and unknown dynamics are major challenges when\napplying optimal control to many real-world decision making tasks. The Learning\nControllable Embedding (LCE) framework addresses these challenges by embedding\nthe observations into a lower dimensional latent space, estimating the latent\ndynamics, and then performing control directly in the latent space. To ensure\nthe learned latent dynamics are predictive of next-observations, all existing\nLCE approaches decode back into the observation space and explicitly perform\nnext-observation prediction---a challenging high-dimensional task that\nfurthermore introduces a large number of nuisance parameters (i.e., the\ndecoder) which are discarded during control. In this paper, we propose a novel\ninformation-theoretic LCE approach and show theoretically that explicit\nnext-observation prediction can be replaced with predictive coding. We then use\npredictive coding to develop a decoder-free LCE model whose latent dynamics are\namenable to locally-linear control. Extensive experiments on benchmark tasks\nshow that our model reliably learns a controllable latent space that leads to\nsuperior performance when compared with state-of-the-art LCE baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:20:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Shu", "Rui", ""], ["Nguyen", "Tung", ""], ["Chow", "Yinlam", ""], ["Pham", "Tuan", ""], ["Than", "Khoat", ""], ["Ghavamzadeh", "Mohammad", ""], ["Ermon", "Stefano", ""], ["Bui", "Hung H.", ""]]}, {"id": "2003.01094", "submitter": "Quanquan Gu", "authors": "Difan Zou and Philip M. Long and Quanquan Gu", "title": "On the Global Convergence of Training Deep Linear ResNets", "comments": "26 pages, 1 figure. In ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of gradient descent (GD) and stochastic gradient\ndescent (SGD) for training $L$-hidden-layer linear residual networks (ResNets).\nWe prove that for training deep residual networks with certain linear\ntransformations at input and output layers, which are fixed throughout\ntraining, both GD and SGD with zero initialization on all hidden weights can\nconverge to the global minimum of the training loss. Moreover, when\nspecializing to appropriate Gaussian random linear transformations, GD and SGD\nprovably optimize wide enough deep linear ResNets. Compared with the global\nconvergence result of GD for training standard deep linear networks (Du & Hu\n2019), our condition on the neural network width is sharper by a factor of\n$O(\\kappa L)$, where $\\kappa$ denotes the condition number of the covariance\nmatrix of the training data. We further propose a modified identity input and\noutput transformations, and show that a $(d+k)$-wide neural network is\nsufficient to guarantee the global convergence of GD/SGD, where $d,k$ are the\ninput and output dimensions respectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:34:49 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zou", "Difan", ""], ["Long", "Philip M.", ""], ["Gu", "Quanquan", ""]]}, {"id": "2003.01115", "submitter": "S.T. John", "authors": "Mark van der Wilk, Vincent Dutordoir, ST John, Artem Artemev, Vincent\n  Adam, and James Hensman", "title": "A Framework for Interdomain and Multioutput Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One obstacle to the use of Gaussian processes (GPs) in large-scale problems,\nand as a component in deep learning system, is the need for bespoke derivations\nand implementations for small variations in the model or inference. In order to\nimprove the utility of GPs we need a modular system that allows rapid\nimplementation and testing, as seen in the neural network community. We present\na mathematical and software framework for scalable approximate inference in\nGPs, which combines interdomain approximations and multiple outputs. Our\nframework, implemented in GPflow, provides a unified interface for many\nexisting multioutput models, as well as more recent convolutional structures.\nThis simplifies the creation of deep models with GPs, and we hope that this\nwork will encourage more interest in this approach.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:24:59 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["van der Wilk", "Mark", ""], ["Dutordoir", "Vincent", ""], ["John", "ST", ""], ["Artemev", "Artem", ""], ["Adam", "Vincent", ""], ["Hensman", "James", ""]]}, {"id": "2003.01150", "submitter": "Nataly Brukhim", "authors": "Nataly Brukhim, Xinyi Chen, Elad Hazan, Shay Moran", "title": "Online Agnostic Boosting via Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a widely used machine learning approach based on the idea of\naggregating weak learning rules. While in statistical learning numerous\nboosting methods exist both in the realizable and agnostic settings, in online\nlearning they exist only in the realizable case. In this work we provide the\nfirst agnostic online boosting algorithm; that is, given a weak learner with\nonly marginally-better-than-trivial regret guarantees, our algorithm boosts it\nto a strong learner with sublinear regret.\n  Our algorithm is based on an abstract (and simple) reduction to online convex\noptimization, which efficiently converts an arbitrary online convex optimizer\nto an online booster.\n  Moreover, this reduction extends to the statistical as well as the online\nrealizable settings, thus unifying the 4 cases of statistical/online and\nagnostic/realizable boosting.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 19:21:25 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Brukhim", "Nataly", ""], ["Chen", "Xinyi", ""], ["Hazan", "Elad", ""], ["Moran", "Shay", ""]]}, {"id": "2003.01169", "submitter": "Alexander Moreno", "authors": "Alexander Moreno, Zhenke Wu, Jamie Yap, David Wetter, Cho Lam, Inbal\n  Nahum-Shani, Walter Dempsey, James M. Rehg", "title": "A Robust Functional EM Algorithm for Incomplete Panel Count Data", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Panel count data describes aggregated counts of recurrent events observed at\ndiscrete time points. To understand dynamics of health behaviors, the field of\nquantitative behavioral research has evolved to increasingly rely upon panel\ncount data collected via multiple self reports, for example, about frequencies\nof smoking using in-the-moment surveys on mobile devices. However, missing\nreports are common and present a major barrier to downstream statistical\nlearning. As a first step, under a missing completely at random assumption\n(MCAR), we propose a simple yet widely applicable functional EM algorithm to\nestimate the counting process mean function, which is of central interest to\nbehavioral scientists. The proposed approach wraps several popular panel count\ninference methods, seamlessly deals with incomplete counts and is robust to\nmisspecification of the Poisson process assumption. Theoretical analysis of the\nproposed algorithm provides finite-sample guarantees by expanding parametric EM\ntheory to our general non-parametric setting. We illustrate the utility of the\nproposed algorithm through numerical experiments and an analysis of smoking\ncessation data. We also discuss useful extensions to address deviations from\nthe MCAR assumption and covariate effects.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 20:04:38 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 16:56:30 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 02:34:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Moreno", "Alexander", ""], ["Wu", "Zhenke", ""], ["Yap", "Jamie", ""], ["Wetter", "David", ""], ["Lam", "Cho", ""], ["Nahum-Shani", "Inbal", ""], ["Dempsey", "Walter", ""], ["Rehg", "James M.", ""]]}, {"id": "2003.01171", "submitter": "Xxx Lin Lin", "authors": "Daixin Wang and Jianbin Lin and Peng Cui and Quanhui Jia and Zhen Wang\n  and Yanming Fang and Quan Yu and Jun Zhou and Shuang Yang and Yuan Qi", "title": "A Semi-supervised Graph Attentive Network for Financial Fraud Detection", "comments": "icdm", "journal-ref": null, "doi": "10.1109/ICDM.2019.00070", "report-no": null, "categories": "cs.SI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of financial services, fraud detection has been a very\nimportant problem to guarantee a healthy environment for both users and\nproviders. Conventional solutions for fraud detection mainly use some\nrule-based methods or distract some features manually to perform prediction.\nHowever, in financial services, users have rich interactions and they\nthemselves always show multifaceted information. These data form a large\nmultiview network, which is not fully exploited by conventional methods.\nAdditionally, among the network, only very few of the users are labelled, which\nalso poses a great challenge for only utilizing labeled data to achieve a\nsatisfied performance on fraud detection.\n  To address the problem, we expand the labeled data through their social\nrelations to get the unlabeled data and propose a semi-supervised attentive\ngraph neural network, namedSemiGNN to utilize the multi-view labeled and\nunlabeled data for fraud detection. Moreover, we propose a hierarchical\nattention mechanism to better correlate different neighbors and different\nviews. Simultaneously, the attention mechanism can make the model interpretable\nand tell what are the important factors for the fraud and why the users are\npredicted as fraud. Experimentally, we conduct the prediction task on the users\nof Alipay, one of the largest third-party online and offline cashless payment\nplatform serving more than 4 hundreds of million users in China. By utilizing\nthe social relations and the user attributes, our method can achieve a better\naccuracy compared with the state-of-the-art methods on two tasks. Moreover, the\ninterpretable results also give interesting intuitions regarding the tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:35:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Wang", "Daixin", ""], ["Lin", "Jianbin", ""], ["Cui", "Peng", ""], ["Jia", "Quanhui", ""], ["Wang", "Zhen", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.01176", "submitter": "Chirag Nagpal", "authors": "Chirag Nagpal, Xinyu Rachel Li and Artur Dubrawski", "title": "Deep Survival Machines: Fully Parametric Survival Regression and\n  Representation Learning for Censored Data with Competing Risks", "comments": "Also appeared in NeurIPS 2019 Workshop on Machine Learning for\n  Healthcare (ML4H)", "journal-ref": "IEEE Journal of Biomedical and Health Informatics, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new approach to estimating relative risks in time-to-event\nprediction problems with censored data in a fully parametric manner. Our\napproach does not require making strong assumptions of constant proportional\nhazard of the underlying survival distribution, as required by the\nCox-proportional hazard model. By jointly learning deep nonlinear\nrepresentations of the input covariates, we demonstrate the benefits of our\napproach when used to estimate survival risks through extensive experimentation\non multiple real world datasets with different levels of censoring. We further\ndemonstrate advantages of our model in the competing risks scenario. To the\nbest of our knowledge, this is the first work involving fully parametric\nestimation of survival times with competing risks in the presence of censoring.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 20:21:59 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 22:18:44 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 12:09:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Nagpal", "Chirag", ""], ["Li", "Xinyu Rachel", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2003.01181", "submitter": "Shenyang Huang", "authors": "Stefano Alletto, Shenyang Huang, Vincent Francois-Lavet, Yohei Nakata\n  and Guillaume Rabusseau", "title": "RandomNet: Towards Fully Automatic Neural Architecture Design for\n  Multimodal Learning", "comments": "6 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all neural architecture search methods are evaluated in terms of\nperformance (i.e. test accuracy) of the model structures that it finds. Should\nit be the only metric for a good autoML approach? To examine aspects beyond\nperformance, we propose a set of criteria aimed at evaluating the core of\nautoML problem: the amount of human intervention required to deploy these\nmethods into real world scenarios. Based on our proposed evaluation checklist,\nwe study the effectiveness of a random search strategy for fully automated\nmultimodal neural architecture search. Compared to traditional methods that\nrely on manually crafted feature extractors, our method selects each modality\nfrom a large search space with minimal human supervision. We show that our\nproposed random search strategy performs close to the state of the art on the\nAV-MNIST dataset while meeting the desirable characteristics for a fully\nautomated design process.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 20:41:57 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Alletto", "Stefano", ""], ["Huang", "Shenyang", ""], ["Francois-Lavet", "Vincent", ""], ["Nakata", "Yohei", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2003.01219", "submitter": "Matt Jordan", "authors": "Matt Jordan, Alexandros G. Dimakis", "title": "Exactly Computing the Local Lipschitz Constant of ReLU Networks", "comments": "Accepted into NeurIPS 2020. Code: https://github.com/revbucket/lipMIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local Lipschitz constant of a neural network is a useful metric with\napplications in robustness, generalization, and fairness evaluation. We provide\nnovel analytic results relating the local Lipschitz constant of nonsmooth\nvector-valued functions to a maximization over the norm of the generalized\nJacobian. We present a sufficient condition for which backpropagation always\nreturns an element of the generalized Jacobian, and reframe the problem over\nthis broad class of functions. We show strong inapproximability results for\nestimating Lipschitz constants of ReLU networks, and then formulate an\nalgorithm to compute these quantities exactly. We leverage this algorithm to\nevaluate the tightness of competing Lipschitz estimators and the effects of\nregularized training on the Lipschitz constant.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:15:54 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 01:46:26 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Jordan", "Matt", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "2003.01227", "submitter": "Marius Hobbhahn", "authors": "Marius Hobbhahn, Agustinus Kristiadi, Philipp Hennig", "title": "Fast Predictive Uncertainty for Classification with Bayesian Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian Deep Learning, distributions over the output of classification\nneural networks are approximated by first constructing a Gaussian distribution\nover the weights, then sampling from it to receive a distribution over the\ncategorical output distribution. This is costly. We reconsider old work to\nconstruct a Dirichlet approximation of this output distribution, which yields\nan analytic map between Gaussian distributions in logit space and Dirichlet\ndistributions (the conjugate prior to the categorical) in the output space. We\nargue that the resulting Dirichlet distribution has theoretical and practical\nadvantages, in particular more efficient computation of the uncertainty\nestimate, scaling to large datasets and networks like ImageNet and DenseNet. We\ndemonstrate the use of this Dirichlet approximation by using it to construct a\nlightweight uncertainty-aware output ranking for the ImageNet setup.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:29:03 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 09:19:59 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hobbhahn", "Marius", ""], ["Kristiadi", "Agustinus", ""], ["Hennig", "Philipp", ""]]}, {"id": "2003.01247", "submitter": "Diego Granziol", "authors": "Diego Granziol, Xingchen Wan, Samuel Albanie, Stephen Roberts", "title": "Iterative Averaging in the Quest for Best Test Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse and explain the increased generalisation performance\n\\latestEdits{of} Iterate Averaging using a Gaussian Process perturbation model\nbetween the true and batch risk surface on the high dimensional quadratic. %\nBased on our theoretical results We derive three phenomena \\latestEdits{from\nour theoretical results:} (1) The importance of combining iterate averaging\nwith large learning rates and regularisation for improved regularisation (2)\nJustification for less frequent averaging. (3) That we expect adaptive gradient\nmethods to work equally well or better with iterate averaging than their non\nadaptive counterparts. Inspired by these results\\latestEdits{, together with}\nempirical investigations of the importance of appropriate regularisation for\nthe solution diversity of the iterates, we propose two adaptive algorithms with\niterate averaging. \\latestEdits{These} give significantly better results than\nSGD, require less tuning and do not require early stopping or validation set\nmonitoring. We showcase the efficacy of our approach on the CIFAR-10/100,\nImageNet and Penn Treebank datasets on a variety of modern and classical\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 23:27:29 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:35:28 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 21:31:32 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 10:43:42 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Granziol", "Diego", ""], ["Wan", "Xingchen", ""], ["Albanie", "Samuel", ""], ["Roberts", "Stephen", ""]]}, {"id": "2003.01249", "submitter": "Jeet Mohapatra", "authors": "Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei (Lily) Weng, Sijia Liu, Pin-Yu\n  Chen, Luca Daniel", "title": "Hidden Cost of Randomized Smoothing", "comments": "Jeet Mohapatra and Ching-Yun Ko contributed equally. To appear in\n  AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fragility of modern machine learning models has drawn a considerable\namount of attention from both academia and the public. While immense interests\nwere in either crafting adversarial attacks as a way to measure the robustness\nof neural networks or devising worst-case analytical robustness verification\nwith guarantees, few methods could enjoy both scalability and robustness\nguarantees at the same time. As an alternative to these attempts, randomized\nsmoothing adopts a different prediction rule that enables statistical\nrobustness arguments which easily scale to large networks. However, in this\npaper, we point out the side effects of current randomized smoothing workflows.\nSpecifically, we articulate and prove two major points: 1) the decision\nboundaries of smoothed classifiers will shrink, resulting in disparity in\nclass-wise accuracy; 2) applying noise augmentation in the training process\ndoes not necessarily resolve the shrinking issue due to the inconsistent\nlearning objectives.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 23:37:42 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 22:03:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Mohapatra", "Jeet", "", "Lily"], ["Ko", "Ching-Yun", "", "Lily"], ["Tsui-Wei", "", "", "Lily"], ["Weng", "", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Daniel", "Luca", ""]]}, {"id": "2003.01262", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt and Ari Morcos", "title": "Selectivity considered harmful: evaluating the causal impact of class\n  selectivity in DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The properties of individual neurons are often analyzed in order to\nunderstand the biological and artificial neural networks in which they're\nembedded. Class selectivity-typically defined as how different a neuron's\nresponses are across different classes of stimuli or data samples-is commonly\nused for this purpose. However, it remains an open question whether it is\nnecessary and/or sufficient for deep neural networks (DNNs) to learn class\nselectivity in individual units. We investigated the causal impact of class\nselectivity on network function by directly regularizing for or against class\nselectivity. Using this regularizer to reduce class selectivity across units in\nconvolutional neural networks increased test accuracy by over 2% for ResNet18\ntrained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class\nselectivity by a factor of 2.5 with no impact on test accuracy, and reduce it\nnearly to zero with only a small ($\\sim$2%) drop in test accuracy. In contrast,\nregularizing to increase class selectivity significantly decreased test\naccuracy across all models and datasets. These results indicate that class\nselectivity in individual units is neither sufficient nor strictly necessary,\nand can even impair DNN performance. They also encourage caution when focusing\non the properties of single units as representative of the mechanisms by which\nDNNs function.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:22:37 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 00:20:47 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 17:31:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2003.01283", "submitter": "Hongkai Chen", "authors": "Hongkai Chen, Nicola Paoletti, Scott A. Smolka, Shan Lin", "title": "MPC-guided Imitation Learning of Neural Network Policies for the\n  Artificial Pancreas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though model predictive control (MPC) is currently the main algorithm\nfor insulin control in the artificial pancreas (AP), it usually requires\ncomplex online optimizations, which are infeasible for resource-constrained\nmedical devices. MPC also typically relies on state estimation, an error-prone\nprocess. In this paper, we introduce a novel approach to AP control that uses\nImitation Learning to synthesize neural-network insulin policies from\nMPC-computed demonstrations. Such policies are computationally efficient and,\nby instrumenting MPC at training time with full state information, they can\ndirectly map measurements into optimal therapy decisions, thus bypassing state\nestimation. We apply Bayesian inference via Monte Carlo Dropout to learn\npolicies, which allows us to quantify prediction uncertainty and thereby derive\nsafer therapy decisions. We show that our control policies trained under a\nspecific patient model readily generalize (in terms of model parameters and\ndisturbance distributions) to patient cohorts, consistently outperforming\ntraditional MPC with state estimation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 01:25:45 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chen", "Hongkai", ""], ["Paoletti", "Nicola", ""], ["Smolka", "Scott A.", ""], ["Lin", "Shan", ""]]}, {"id": "2003.01291", "submitter": "Timo Welti", "authors": "Arnulf Jentzen and Timo Welti", "title": "Overall error analysis for the training of deep neural networks via\n  stochastic gradient descent with random initialisation", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the accomplishments of deep learning based algorithms in numerous\napplications and very broad corresponding research interest, at the moment\nthere is still no rigorous understanding of the reasons why such algorithms\nproduce useful results in certain situations. A thorough mathematical analysis\nof deep learning based algorithms seems to be crucial in order to improve our\nunderstanding and to make their implementation more effective and efficient. In\nthis article we provide a mathematically rigorous full error analysis of deep\nlearning based empirical risk minimisation with quadratic loss function in the\nprobabilistically strong sense, where the underlying deep neural networks are\ntrained using stochastic gradient descent with random initialisation. The\nconvergence speed we obtain is presumably far from optimal and suffers under\nthe curse of dimensionality. To the best of our knowledge, we establish,\nhowever, the first full error analysis in the scientific literature for a deep\nlearning based algorithm in the probabilistically strong sense and, moreover,\nthe first full error analysis in the scientific literature for a deep learning\nbased algorithm where stochastic gradient descent with random initialisation is\nthe employed optimisation method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 01:41:17 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Jentzen", "Arnulf", ""], ["Welti", "Timo", ""]]}, {"id": "2003.01296", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and Khoa Doan and Pranjul Yadav and S. Sathiya\n  Keerthi", "title": "Regression via Implicit Models and Optimal Transport Cost Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the classic problem of regression, which involves the\ninductive learning of a map, $y=f(x,z)$, $z$ denoting noise,\n$f:\\mathbb{R}^n\\times \\mathbb{R}^k \\rightarrow \\mathbb{R}^m$. Recently,\nConditional GAN (CGAN) has been applied for regression and has shown to be\nadvantageous over the other standard approaches like Gaussian Process\nRegression, given its ability to implicitly model complex noise forms. However,\nthe current CGAN implementation for regression uses the classical\ngenerator-discriminator architecture with the minimax optimization approach,\nwhich is notorious for being difficult to train due to issues like training\ninstability or failure to converge. In this paper, we take another step towards\nregression models that implicitly model the noise, and propose a solution which\ndirectly optimizes the optimal transport cost between the true probability\ndistribution $p(y|x)$ and the estimated distribution $\\hat{p}(y|x)$ and does\nnot suffer from the issues associated with the minimax approach. On a variety\nof synthetic and real-world datasets, our proposed solution achieves\nstate-of-the-art results. The code accompanying this paper is available at\n\"https://github.com/gurdaspuriya/ot_regression\".\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 02:26:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Manchanda", "Saurav", ""], ["Doan", "Khoa", ""], ["Yadav", "Pranjul", ""], ["Keerthi", "S. Sathiya", ""]]}, {"id": "2003.01303", "submitter": "Lu Wen", "authors": "Lu Wen, Jingliang Duan, Shengbo Eben Li, Shaobing Xu, Huei Peng", "title": "Safe Reinforcement Learning for Autonomous Vehicles through Parallel\n  Constrained Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is attracting increasing interests in autonomous\ndriving due to its potential to solve complex classification and control\nproblems. However, existing RL algorithms are rarely applied to real vehicles\nfor two predominant problems: behaviours are unexplainable, and they cannot\nguarantee safety under new scenarios. This paper presents a safe RL algorithm,\ncalled Parallel Constrained Policy Optimization (PCPO), for two autonomous\ndriving tasks. PCPO extends today's common actor-critic architecture to a\nthree-component learning framework, in which three neural networks are used to\napproximate the policy function, value function and a newly added risk\nfunction, respectively. Meanwhile, a trust region constraint is added to allow\nlarge update steps without breaking the monotonic improvement condition. To\nensure the feasibility of safety constrained problems, synchronized parallel\nlearners are employed to explore different state spaces, which accelerates\nlearning and policy-update. The simulations of two scenarios for autonomous\nvehicles confirm we can ensure safety while achieving fast learning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 02:53:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wen", "Lu", ""], ["Duan", "Jingliang", ""], ["Li", "Shengbo Eben", ""], ["Xu", "Shaobing", ""], ["Peng", "Huei", ""]]}, {"id": "2003.01312", "submitter": "Vaibhav Srivastava", "authors": "Peter Landgren, Vaibhav Srivastava, and Naomi Ehrich Leonard", "title": "Distributed Cooperative Decision Making in Multi-agent Multi-armed\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a distributed decision-making problem in which multiple agents face\nthe same multi-armed bandit (MAB), and each agent makes sequential choices\namong arms to maximize its own individual reward. The agents cooperate by\nsharing their estimates over a fixed communication graph. We consider an\nunconstrained reward model in which two or more agents can choose the same arm\nand collect independent rewards. And we consider a constrained reward model in\nwhich agents that choose the same arm at the same time receive no reward. We\ndesign a dynamic, consensus-based, distributed estimation algorithm for\ncooperative estimation of mean rewards at each arm. We leverage the estimates\nfrom this algorithm to develop two distributed algorithms: coop-UCB2 and\ncoop-UCB2-selective-learning, for the unconstrained and constrained reward\nmodels, respectively. We show that both algorithms achieve group performance\nclose to the performance of a centralized fusion center. Further, we\ninvestigate the influence of the communication graph structure on performance.\nWe propose a novel graph explore-exploit index that predicts the relative\nperformance of groups in terms of the communication graph, and we propose a\nnovel nodal explore-exploit centrality index that predicts the relative\nperformance of agents in terms of the agent locations in the communication\ngraph.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 03:20:44 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 19:54:20 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Landgren", "Peter", ""], ["Srivastava", "Vaibhav", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2003.01322", "submitter": "Quoc Tran-Dinh", "authors": "Quoc Tran-Dinh and Deyi Liu", "title": "Faster Randomized Primal-Dual Algorithms For Nonsmooth Composite Convex\n  Minimization", "comments": "33, 6 figures", "journal-ref": null, "doi": null, "report-no": "UNC-STOR 03.2020.W4 (Second version)", "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two novel randomized primal-dual algorithms to solve nonsmooth\ncomposite convex optimization problems. The first algorithm is fully\nrandomized, i.e., it has parallel randomized updates on both primal and dual\nvariables, while the second one is a semi-randomized scheme, which only has one\nrandomized update on the primal (or dual) variable while using the full update\nfor the other. Both algorithms achieve the best-known $\\mathcal{O}(1/k)$ or\n$\\mathcal{O}(1/k^2)$ convergence rates in expectation under either only\nconvexity or strong convexity, respectively, where $k$ is the iteration\ncounter. These rates can be obtained for both the primal and dual problems.\nWith new parameter update rules, our algorithms can be boosted up to\n$\\underline{o}(1/(k\\sqrt{\\log{k}}))$ or\n$\\underline{o}(1/(k^2\\sqrt{\\log{k}}))$-rates in expectation, respectively (see\ndefinitions below). To the best of our knowledge, this is the first time such\nfaster convergence rates are shown for randomized primal-dual methods. Finally,\nwe verify our theoretical results via two numerical examples and compare them\nwith state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 03:59:26 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:42:31 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Tran-Dinh", "Quoc", ""], ["Liu", "Deyi", ""]]}, {"id": "2003.01328", "submitter": "Kishan Panaganti Badrinath", "authors": "Kishan Panaganti and Dileep Kalathil", "title": "Bounded Regret for Finitely Parameterized Multi-Armed Bandits", "comments": "15 pages, 7 figures, Reinforcement Learning, Multi-armed Bandits,\n  Sequential Decision Making", "journal-ref": null, "doi": "10.1109/LCSYS.2020.3008798", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finitely parameterized multi-armed bandits where\nthe model of the underlying stochastic environment can be characterized based\non a common unknown parameter. The true parameter is unknown to the learning\nagent. However, the set of possible parameters, which is finite, is known a\npriori. We propose an algorithm that is simple and easy to implement, which we\ncall Finitely Parameterized Upper Confidence Bound (FP-UCB) algorithm, which\nuses the information about the underlying parameter set for faster learning. In\nparticular, we show that the FP-UCB algorithm achieves a bounded regret under\nsome structural condition on the underlying parameter set. We also show that,\nif the underlying parameter set does not satisfy the necessary structural\ncondition, the FP-UCB algorithm achieves a logarithmic regret, but with a\nsmaller preceding constant compared to the standard UCB algorithm. We also\nvalidate the superior performance of the FP-UCB algorithm through extensive\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 04:37:07 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 05:09:23 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2020 07:46:01 GMT"}, {"version": "v4", "created": "Sat, 18 Jul 2020 22:31:07 GMT"}, {"version": "v5", "created": "Sat, 7 Nov 2020 20:28:14 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Panaganti", "Kishan", ""], ["Kalathil", "Dileep", ""]]}, {"id": "2003.01332", "submitter": "Ziniu Hu", "authors": "Ziniu Hu, Yuxiao Dong, Kuansan Wang, Yizhou Sun", "title": "Heterogeneous Graph Transformer", "comments": "Published on WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emerging success of graph neural networks\n(GNNs) for modeling structured data. However, most GNNs are designed for\nhomogeneous graphs, in which all nodes and edges belong to the same types,\nmaking them infeasible to represent heterogeneous structures. In this paper, we\npresent the Heterogeneous Graph Transformer (HGT) architecture for modeling\nWeb-scale heterogeneous graphs. To model heterogeneity, we design node- and\nedge-type dependent parameters to characterize the heterogeneous attention over\neach edge, empowering HGT to maintain dedicated representations for different\ntypes of nodes and edges. To handle dynamic heterogeneous graphs, we introduce\nthe relative temporal encoding technique into HGT, which is able to capture the\ndynamic structural dependency with arbitrary durations. To handle Web-scale\ngraph data, we design the heterogeneous mini-batch graph sampling\nalgorithm---HGSampling---for efficient and scalable training. Extensive\nexperiments on the Open Academic Graph of 179 million nodes and 2 billion edges\nshow that the proposed HGT model consistently outperforms all the\nstate-of-the-art GNN baselines by 9%--21% on various downstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 04:49:21 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hu", "Ziniu", ""], ["Dong", "Yuxiao", ""], ["Wang", "Kuansan", ""], ["Sun", "Yizhou", ""]]}, {"id": "2003.01351", "submitter": "Mingxuan Yue", "authors": "Mingxuan Yue, Yaguang Li, Haoze Yang, Ritesh Ahuja, Yao-Yi Chiang,\n  Cyrus Shahabi", "title": "DETECT: Deep Trajectory Clustering for Mobility-Behavior Analysis", "comments": "Published as a conference paper at BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying mobility behaviors in rich trajectory data is of great economic\nand social interest to various applications including urban planning, marketing\nand intelligence. Existing work on trajectory clustering often relies on\nsimilarity measurements that utilize raw spatial and/or temporal information of\ntrajectories. These measures are incapable of identifying similar moving\nbehaviors that exhibit varying spatio-temporal scales of movement. In addition,\nthe expense of labeling massive trajectory data is a barrier to supervised\nlearning models. To address these challenges, we propose an unsupervised neural\napproach for mobility behavior clustering, called the Deep Embedded TrajEctory\nClusTering network (DETECT). DETECT operates in three parts: first it\ntransforms the trajectories by summarizing their critical parts and augmenting\nthem with context derived from their geographical locality (e.g., using POIs\nfrom gazetteers). In the second part, it learns a powerful representation of\ntrajectories in the latent space of behaviors, thus enabling a clustering\nfunction (such as $k$-means) to be applied. Finally, a clustering oriented loss\nis directly built on the embedded features to jointly perform feature\nrefinement and cluster assignment, thus improving separability between mobility\nbehaviors. Exhaustive quantitative and qualitative experiments on two\nreal-world datasets demonstrate the effectiveness of our approach for mobility\nbehavior analyses.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 06:09:15 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yue", "Mingxuan", ""], ["Li", "Yaguang", ""], ["Yang", "Haoze", ""], ["Ahuja", "Ritesh", ""], ["Chiang", "Yao-Yi", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "2003.01367", "submitter": "Samarth Sinha", "authors": "Samarth Sinha, Animesh Garg, Hugo Larochelle", "title": "Curriculum By Smoothing", "comments": "NeurIPS 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have shown impressive performance in\ncomputer vision tasks such as image classification, detection, and\nsegmentation. Moreover, recent work in Generative Adversarial Networks (GANs)\nhas highlighted the importance of learning by progressively increasing the\ndifficulty of a learning task [26]. When learning a network from scratch, the\ninformation propagated within the network during the earlier stages of training\ncan contain distortion artifacts due to noise which can be detrimental to\ntraining. In this paper, we propose an elegant curriculum based scheme that\nsmoothes the feature embedding of a CNN using anti-aliasing or low-pass\nfilters. We propose to augment the train-ing of CNNs by controlling the amount\nof high frequency information propagated within the CNNs as training\nprogresses, by convolving the output of a CNN feature map of each layer with a\nGaussian kernel. By decreasing the variance of the Gaussian kernel, we\ngradually increase the amount of high-frequency information available within\nthe network for inference. As the amount of information in the feature maps\nincreases during training, the network is able to progressively learn better\nrepresentations of the data. Our proposed augmented training scheme\nsignificantly improves the performance of CNNs on various vision tasks without\neither adding additional trainable parameters or an auxiliary regularization\nobjective. The generality of our method is demonstrated through empirical\nperformance gains in CNN architectures across four different tasks: transfer\nlearning, cross-task transfer learning, and generative models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 07:27:44 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 23:07:54 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 18:24:41 GMT"}, {"version": "v4", "created": "Sun, 6 Dec 2020 23:18:04 GMT"}, {"version": "v5", "created": "Tue, 5 Jan 2021 04:53:44 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Sinha", "Samarth", ""], ["Garg", "Animesh", ""], ["Larochelle", "Hugo", ""]]}, {"id": "2003.01373", "submitter": "Haozhe Wang", "authors": "Haozhe Wang, Jiale Zhou, Xuming He", "title": "Learning Context-aware Task Reasoning for Efficient Meta-reinforcement\n  Learning", "comments": "accepted to AAMAS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent success of deep network-based Reinforcement Learning (RL), it\nremains elusive to achieve human-level efficiency in learning novel tasks.\nWhile previous efforts attempt to address this challenge using meta-learning\nstrategies, they typically suffer from sampling inefficiency with on-policy RL\nalgorithms or meta-overfitting with off-policy learning. In this work, we\npropose a novel meta-RL strategy to address those limitations. In particular,\nwe decompose the meta-RL problem into three sub-tasks, task-exploration,\ntask-inference and task-fulfillment, instantiated with two deep network agents\nand a task encoder. During meta-training, our method learns a task-conditioned\nactor network for task-fulfillment, an explorer network with a self-supervised\nreward shaping that encourages task-informative experiences in\ntask-exploration, and a context-aware graph-based task encoder for task\ninference. We validate our approach with extensive experiments on several\npublic benchmarks and the results show that our algorithm effectively performs\nexploration for task inference, improves sample efficiency during both training\nand testing, and mitigates the meta-overfitting problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 07:38:53 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wang", "Haozhe", ""], ["Zhou", "Jiale", ""], ["He", "Xuming", ""]]}, {"id": "2003.01384", "submitter": "William Agnew", "authors": "William Agnew and Pedro Domingos", "title": "Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep reinforcement learning (RL) approaches incorporate minimal prior\nknowledge about the environment, limiting computational and sample efficiency.\n\\textit{Objects} provide a succinct and causal description of the world, and\nmany recent works have proposed unsupervised object representation learning\nusing priors and losses over static object properties like visual consistency.\nHowever, object dynamics and interactions are also critical cues for\nobjectness. In this paper we propose a framework for reasoning about object\ndynamics and behavior to rapidly determine minimal and task-specific object\nrepresentations. To demonstrate the need to reason over object behavior and\ndynamics, we introduce a suite of RGBD MuJoCo object collection and avoidance\ntasks that, while intuitive and visually simple, confound state-of-the-art\nunsupervised object representation learning algorithms. We also highlight the\npotential of this framework on several Atari games, using our object\nrepresentation and standard RL and planning algorithms to learn dramatically\nfaster than existing deep RL algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 08:18:49 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 05:55:55 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 19:38:32 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Agnew", "William", ""], ["Domingos", "Pedro", ""]]}, {"id": "2003.01412", "submitter": "Ziling Wu", "authors": "Ziling Wu, Ping Liu, Zheng Hu, Bocheng Li and Jun Wang", "title": "CRATOS: Cognition of Reliable Algorithm for Time-series Optimal Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection of time series plays an important role in reliability\nsystems engineering. However, in practical application, there is no precisely\ndefined boundary between normal and anomalous behaviors in different\napplication scenarios. Therefore, different anomaly detection algorithms and\nprocesses ought to be adopted for time series in different situation. Although\nsuch strategy improve the accuracy of anomaly detection, it takes a lot of time\nfor practitioners to configure various algorithms to millions of series, which\ngreatly increases the development and maintenance cost of anomaly detection\nprocesses. In this paper, we propose CRATOS which is a self-adapt algorithms\nthat extract features from time series, and then cluster series with similar\nfeatures into one group. For each group we utilize evolutionary algorithm to\nsearch the best anomaly detection methods and processes. Our methods can\nsignificantly reduce the cost of development and maintenance of anomaly\ndetection. According to experiments, our clustering methods achieves the\nstate-of-art results. The accuracy of the anomaly detection algorithms in this\npaper is 85.1%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 09:49:30 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:17:59 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 13:12:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wu", "Ziling", ""], ["Liu", "Ping", ""], ["Hu", "Zheng", ""], ["Li", "Bocheng", ""], ["Wang", "Jun", ""]]}, {"id": "2003.01415", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (DMA), Gabriel Peyr\\'e (DMA)", "title": "Online Sinkhorn: Optimal Transport distances from sample streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Transport (OT) distances are now routinely used as loss functions in\nML tasks. Yet, computing OT distances between arbitrary (i.e. not necessarily\ndiscrete) probability distributions remains an open problem. This paper\nintroduces a new online estimator of entropy-regularized OT distances between\ntwo such arbitrary distributions. It uses streams of samples from both\ndistributions to iteratively enrich a non-parametric representation of the\ntransportation plan. Compared to the classic Sinkhorn algorithm, our method\nleverages new samples at each iteration, which enables a consistent estimation\nof the true regularized OT distance. We provide a theoretical analysis of the\nconvergence of the online Sinkhorn algorithm, showing a nearly-O(1/n)\nasymptotic sample complexity for the iterate sequence. We validate our method\non synthetic 1D to 10D data and on real 3D shape data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 09:58:01 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 11:32:26 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Mensch", "Arthur", "", "DMA"], ["Peyr\u00e9", "Gabriel", "", "DMA"]]}, {"id": "2003.01416", "submitter": "Morteza Haghir Chehreghani", "authors": "Niklas {\\AA}kerblom and Yuxin Chen and Morteza Haghir Chehreghani", "title": "An Online Learning Framework for Energy-Efficient Navigation of Electric\n  Vehicles", "comments": "Accepted at IJCAI 2020 Main Track. Sole copyright holder is IJCAI\n  (International Joint Conferences on Artificial Intelligence), all rights\n  reserved. Available at https://www.ijcai.org/Proceedings/2020/284", "journal-ref": "IJCAI 2020, Pages 2051-2057", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-efficient navigation constitutes an important challenge in electric\nvehicles, due to their limited battery capacity. We employ a Bayesian approach\nto model the energy consumption at road segments for efficient navigation. In\norder to learn the model parameters, we develop an online learning framework\nand investigate several exploration strategies such as Thompson Sampling and\nUpper Confidence Bound. We then extend our online learning framework to\nmulti-agent setting, where multiple vehicles adaptively navigate and learn the\nparameters of the energy model. We analyze Thompson Sampling and establish\nrigorous regret bounds on its performance. Finally, we demonstrate the\nperformance of our methods via several real-world experiments on Luxembourg\nSUMO Traffic dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:05:45 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 16:34:59 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["\u00c5kerblom", "Niklas", ""], ["Chen", "Yuxin", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2003.01432", "submitter": "Dimitri Bouche", "authors": "Dimitri Bouche, Marianne Clausel, Fran\\c{c}ois Roueff and Florence\n  d'Alch\\'e-Buc", "title": "Nonlinear Functional Output Regression: a Dictionary Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address functional-output regression, we introduce projection learning\n(PL), a novel dictionary-based approach that learns to predict a function that\nis expanded on a dictionary while minimizing an empirical risk based on a\nfunctional loss. PL makes it possible to use non orthogonal dictionaries and\ncan then be combined with dictionary learning; it is thus much more flexible\nthan expansion-based approaches relying on vectorial losses. This general\nmethod is instantiated with reproducing kernel Hilbert spaces of vector-valued\nfunctions as kernel-based projection learning (KPL). For the functional square\nloss, two closed-form estimators are proposed, one for fully observed output\nfunctions and the other for partially observed ones. Both are backed\ntheoretically by an excess risk analysis. Then, in the more general setting of\nintegral losses based on differentiable ground losses, KPL is implemented using\nfirst-order optimization for both fully and partially observed output\nfunctions. Eventually, several robustness aspects of the proposed algorithms\nare highlighted on a toy dataset; and a study on two real datasets shows that\nthey are competitive compared to other nonlinear approaches. Notably, using the\nsquare loss and a learnt dictionary, KPL enjoys a particularily attractive\ntrade-off between computational cost and performances.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:31:17 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:49:31 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 16:36:51 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 15:13:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Bouche", "Dimitri", ""], ["Clausel", "Marianne", ""], ["Roueff", "Fran\u00e7ois", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "2003.01436", "submitter": "Shanchao Yang", "authors": "Shanchao Yang, Jing Liu, Kai Wu and Mingming Li", "title": "Learn to Generate Time Series Conditioned Graphs with Generative\n  Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based approaches have been utilized to model and generate\ngraphs subjected to different distributions recently. However, they are\ntypically unsupervised learning based and unconditioned generative models or\nsimply conditioned on the graph-level contexts, which are not associated with\nrich semantic node-level contexts. Differently, in this paper, we are\ninterested in a novel problem named Time Series Conditioned Graph Generation:\ngiven an input multivariate time series, we aim to infer a target relation\ngraph modeling the underlying interrelationships between time series with each\nnode corresponding to each time series. For example, we can study the\ninterrelationships between genes in a gene regulatory network of a certain\ndisease conditioned on their gene expression data recorded as time series. To\nachieve this, we propose a novel Time Series conditioned Graph\nGeneration-Generative Adversarial Networks (TSGG-GAN) to handle challenges of\nrich node-level context structures conditioning and measuring similarities\ndirectly between graphs and time series. Extensive experiments on synthetic and\nreal-word gene regulatory networks datasets demonstrate the effectiveness and\ngeneralizability of the proposed TSGG-GAN.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:41:56 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Shanchao", ""], ["Liu", "Jing", ""], ["Wu", "Kai", ""], ["Li", "Mingming", ""]]}, {"id": "2003.01452", "submitter": "Francesco Trov\\'o Dr.", "authors": "Alessandro Nuara, Francesco Trov\\`o, Nicola Gatti and Marcello\n  Restelli", "title": "Online Joint Bid/Daily Budget Optimization of Internet Advertising\n  Campaigns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pay-per-click advertising includes various formats (\\emph{e.g.}, search,\ncontextual, social) with a total investment of more than 200 billion USD per\nyear worldwide. An advertiser is given a daily budget to allocate over several,\neven thousands, campaigns, mainly distinguishing for the ad, target, or\nchannel. Furthermore, publishers choose the ads to display and how to allocate\nthem employing auctioning mechanisms, in which every day the advertisers set\nfor each campaign a bid corresponding to the maximum amount of money per click\nthey are willing to pay and the fraction of the daily budget to invest. In this\npaper, we study the problem of automating the online joint bid/daily budget\noptimization of pay-per-click advertising campaigns over multiple channels. We\nformulate our problem as a combinatorial semi-bandit problem, which requires\nsolving a special case of the Multiple-Choice Knapsack problem every day.\nFurthermore, for every campaign, we capture the dependency of the number of\nclicks on the bid and daily budget by Gaussian Processes, thus requiring mild\nassumptions on the regularity of these functions. We design four algorithms and\nshow that they suffer from a regret that is upper bounded with high probability\nas O(sqrt{T}), where T is the time horizon of the learning process. We\nexperimentally evaluate our algorithms with synthetic settings generated from\nreal data from Yahoo!, and we present the results of the adoption of our\nalgorithms in a real-world application with a daily average spent of 1,000\nEuros for more than one year.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 11:07:38 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Nuara", "Alessandro", ""], ["Trov\u00f2", "Francesco", ""], ["Gatti", "Nicola", ""], ["Restelli", "Marcello", ""]]}, {"id": "2003.01461", "submitter": "Limor Gultchin", "authors": "Limor Gultchin, Matt J. Kusner, Varun Kanade, Ricardo Silva", "title": "Differentiable Causal Backdoor Discovery", "comments": "Published in the Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2020, Palermo, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the causal effect of a decision is critical to nearly all forms\nof decision-making. In particular, it is a key quantity in drug development, in\ncrafting government policy, and when implementing a real-world machine learning\nsystem. Given only observational data, confounders often obscure the true\ncausal effect. Luckily, in some cases, it is possible to recover the causal\neffect by using certain observed variables to adjust for the effects of\nconfounders. However, without access to the true causal model, finding this\nadjustment requires brute-force search. In this work, we present an algorithm\nthat exploits auxiliary variables, similar to instruments, in order to find an\nappropriate adjustment by a gradient-based optimization method. We demonstrate\nthat it outperforms practical alternatives in estimating the true causal\neffect, without knowledge of the full causal graph.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 11:32:43 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Gultchin", "Limor", ""], ["Kusner", "Matt J.", ""], ["Kanade", "Varun", ""], ["Silva", "Ricardo", ""]]}, {"id": "2003.01475", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek, Pawe{\\l} Pe{\\l}ka", "title": "Pattern Similarity-based Machine Learning Methods for Mid-term Load\n  Forecasting: A Comparative Study", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern similarity-based methods are widely used in classification and\nregression problems. Repeated, similar-shaped cycles observed in seasonal time\nseries encourage to apply these methods for forecasting. In this paper we use\nthe pattern similarity-based methods for forecasting monthly electricity demand\nexpressing annual seasonality. An integral part of the models is the time\nseries representation using patterns of time series sequences. Pattern\nrepresentation ensures the input and output data unification through trend\nfiltering and variance equalization. Consequently, pattern representation\nsimplifies the forecasting problem and allows us to use models based on pattern\nsimilarity. We consider four such models: nearest neighbor model, fuzzy\nneighborhood model, kernel regression model and general regression neural\nnetwork. A regression function is constructed by aggregation output patterns\nwith weights dependent on the similarity between input patterns. The advantages\nof the proposed models are: clear principle of operation, small number of\nparameters to adjust, fast optimization procedure, good generalization ability,\nworking on the newest data without retraining, robustness to missing input\nvariables, and generating a vector as an output. In the experimental part of\nthe work the proposed models were used to forecasting the monthly demand for 35\nEuropean countries. The model performances were compared with the performances\nof the classical models such as ARIMA and exponential smoothing as well as\nstate-of-the-art models such as multilayer perceptron, neuro-fuzzy system and\nlong short-term memory model. The results show high performance of the proposed\nmodels which outperform the comparative models in accuracy, simplicity and ease\nof optimization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 12:14:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Dudek", "Grzegorz", ""], ["Pe\u0142ka", "Pawe\u0142", ""]]}, {"id": "2003.01497", "submitter": "Jad Rahme", "authors": "Jad Rahme, Samy Jelassi, Joan Bruna, S. Matthew Weinberg", "title": "A Permutation-Equivariant Neural Network Architecture For Auction Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing an incentive compatible auction that maximizes expected revenue is\na central problem in Auction Design. Theoretical approaches to the problem have\nhit some limits in the past decades and analytical solutions are known for only\na few simple settings. Computational approaches to the problem through the use\nof LPs have their own set of limitations. Building on the success of deep\nlearning, a new approach was recently proposed by Duetting et al. (2019) in\nwhich the auction is modeled by a feed-forward neural network and the design\nproblem is framed as a learning problem. The neural architectures used in that\nwork are general purpose and do not take advantage of any of the symmetries the\nproblem could present, such as permutation equivariance. In this work, we\nconsider auction design problems that have permutation-equivariant symmetry and\nconstruct a neural architecture that is capable of perfectly recovering the\npermutation-equivariant optimal mechanism, which we show is not possible with\nthe previous architecture. We demonstrate that permutation-equivariant\narchitectures are not only capable of recovering previous results, they also\nhave better generalization properties.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 00:37:36 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 08:17:47 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Rahme", "Jad", ""], ["Jelassi", "Samy", ""], ["Bruna", "Joan", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "2003.01513", "submitter": "Javier Sagastuy-Brena", "authors": "Daniel Kunin, Aran Nayebi, Javier Sagastuy-Brena, Surya Ganguli,\n  Jonathan M. Bloom, Daniel L. K. Yamins", "title": "Two Routes to Scalable Credit Assignment without Weight Symmetry", "comments": "ICML 2020 Camera Ready Version, 19 pages including supplementary\n  information, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural plausibility of backpropagation has long been disputed, primarily\nfor its use of non-local weight transport $-$ the biologically dubious\nrequirement that one neuron instantaneously measure the synaptic weights of\nanother. Until recently, attempts to create local learning rules that avoid\nweight transport have typically failed in the large-scale learning scenarios\nwhere backpropagation shines, e.g. ImageNet categorization with deep\nconvolutional networks. Here, we investigate a recently proposed local learning\nrule that yields competitive performance with backpropagation and find that it\nis highly sensitive to metaparameter choices, requiring laborious tuning that\ndoes not transfer across network architecture. Our analysis indicates the\nunderlying mathematical reason for this instability, allowing us to identify a\nmore robust local learning rule that better transfers without metaparameter\ntuning. Nonetheless, we find a performance and stability gap between this local\nrule and backpropagation that widens with increasing model depth. We then\ninvestigate several non-local learning rules that relax the need for\ninstantaneous weight transport into a more biologically-plausible \"weight\nestimation\" process, showing that these rules match state-of-the-art\nperformance on deep networks and operate effectively in the presence of noisy\nupdates. Taken together, our results suggest two routes towards the discovery\nof neural implementations for credit assignment without weight symmetry:\nfurther improvement of local rules so that they perform consistently across\narchitectures and the identification of biological implementations for\nnon-local learning mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:39:16 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 03:55:29 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Kunin", "Daniel", ""], ["Nayebi", "Aran", ""], ["Sagastuy-Brena", "Javier", ""], ["Ganguli", "Surya", ""], ["Bloom", "Jonathan M.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2003.01515", "submitter": "Ziqi Liu", "authors": "Ziqi Liu, Dong Wang, Qianyu Yu, Zhiqiang Zhang, Yue Shen, Jian Ma,\n  Wenliang Zhong, Jinjie Gu, Jun Zhou, Shuang Yang, Yuan Qi", "title": "Graph Representation Learning for Merchant Incentive Optimization in\n  Mobile Payment Marketing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile payment such as Alipay has been widely used in our daily lives. To\nfurther promote the mobile payment activities, it is important to run marketing\ncampaigns under a limited budget by providing incentives such as coupons,\ncommissions to merchants. As a result, incentive optimization is the key to\nmaximizing the commercial objective of the marketing campaign. With the\nanalyses of online experiments, we found that the transaction network can\nsubtly describe the similarity of merchants' responses to different incentives,\nwhich is of great use in the incentive optimization problem. In this paper, we\npresent a graph representation learning method atop of transaction networks for\nmerchant incentive optimization in mobile payment marketing. With limited\nsamples collected from online experiments, our end-to-end method first learns\nmerchant representations based on an attributed transaction networks, then\neffectively models the correlations between the commercial objectives each\nmerchant may achieve and the incentives under varying treatments. Thus we are\nable to model the sensitivity to incentive for each merchant, and spend the\nmost budgets on those merchants that show strong sensitivities in the marketing\ncampaign. Extensive offline and online experimental results at Alipay\ndemonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:48:55 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Liu", "Ziqi", ""], ["Wang", "Dong", ""], ["Yu", "Qianyu", ""], ["Zhang", "Zhiqiang", ""], ["Shen", "Yue", ""], ["Ma", "Jian", ""], ["Zhong", "Wenliang", ""], ["Gu", "Jinjie", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.01519", "submitter": "Muhammad Bilal", "authors": "Zahoor Uddin, Muhammad Altaf, Muhammad Bilal, Lewis Nkenyereye, Ali\n  Kashif Bashir", "title": "Amateur Drones Detection: A machine learning approach utilizing the\n  acoustic signals in the presence of strong interference", "comments": "25 pages, 10 figures, accepted for the publication in future issue of\n  \"Computer Communications (2020)\"", "journal-ref": null, "doi": "10.1016/j.comcom.2020.02.065", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to small size, sensing capabilities and autonomous nature, the Unmanned\nAir Vehicles (UAVs) have enormous applications in various areas, e.g., remote\nsensing, navigation, archaeology, journalism, environmental science, and\nagriculture. However, the unmonitored deployment of UAVs called the amateur\ndrones (AmDr) can lead to serious security threats and risk to human life and\ninfrastructure. Therefore, timely detection of the AmDr is essential for the\nprotection and security of sensitive organizations, human life and other vital\ninfrastructure. AmDrs can be detected using different techniques based on\nsound, video, thermal, and radio frequencies. However, the performance of these\ntechniques is limited in sever atmospheric conditions. In this paper, we\npropose an efficient unsupervise machine learning approach of independent\ncomponent analysis (ICA) to detect various acoustic signals i.e., sounds of\nbird, airplanes, thunderstorm, rain, wind and the UAVs in practical scenario.\nAfter unmixing the signals, the features like Mel Frequency Cepstral\nCoefficients (MFCC), the power spectral density (PSD) and the Root Mean Square\nValue (RMS) of the PSD are extracted by using ICA. The PSD and the RMS of PSD\nsignals are extracted by first passing the signals from octave band filter\nbanks. Based on the above features the signals are classified using Support\nVector Machines (SVM) and K Nearest Neighbor (KNN) to detect the presence or\nabsence of AmDr. Unique feature of the proposed technique is the detection of a\nsingle or multiple AmDrs at a time in the presence of multiple acoustic\ninterfering signals. The proposed technique is verified through extensive\nsimulations and it is observed that the RMS values of PSD with KNN performs\nbetter than the MFCC with KNN and SVM.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:28:17 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Uddin", "Zahoor", ""], ["Altaf", "Muhammad", ""], ["Bilal", "Muhammad", ""], ["Nkenyereye", "Lewis", ""], ["Bashir", "Ali Kashif", ""]]}, {"id": "2003.01526", "submitter": "Adam Krzyzak", "authors": "M. Kohler, A. Krzyzak and B. Walter", "title": "On the rate of convergence of image classifiers based on convolutional\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classifiers based on convolutional neural networks are defined, and the\nrate of convergence of the misclassification risk of the estimates towards the\noptimal misclassification risk is analyzed. Under suitable assumptions on the\nsmoothness and structure of the aposteriori probability a rate of convergence\nis shown which is independent of the dimension of the image. This proves that\nin image classification it is possible to circumvent the curse of\ndimensionality by convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 14:24:24 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 19:02:44 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 18:20:55 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kohler", "M.", ""], ["Krzyzak", "A.", ""], ["Walter", "B.", ""]]}, {"id": "2003.01531", "submitter": "Yossi Adi", "authors": "Eliya Nachmani, Yossi Adi, Lior Wolf", "title": "Voice Separation with an Unknown Number of Multiple Speakers", "comments": "Accepted to ICML 2020. For associated audio samples, see\n  http://enk100.github.io/speaker_separation", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for separating a mixed audio sequence, in which\nmultiple voices speak simultaneously. The new method employs gated neural\nnetworks that are trained to separate the voices at multiple processing steps,\nwhile maintaining the speaker in each output channel fixed. A different model\nis trained for every number of possible speakers, and the model with the\nlargest number of speakers is employed to select the actual number of speakers\nin a given sample. Our method greatly outperforms the current state of the art,\nwhich, as we show, is not competitive for more than two speakers.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 20:02:54 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 12:36:52 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 08:38:44 GMT"}, {"version": "v4", "created": "Tue, 1 Sep 2020 14:12:16 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Nachmani", "Eliya", ""], ["Adi", "Yossi", ""], ["Wolf", "Lior", ""]]}, {"id": "2003.01538", "submitter": "M. G. Sarwar Murshed", "authors": "Edward Verenich, Alvaro Velasquez, M.G. Sarwar Murshed, Faraz Hussain", "title": "FlexServe: Deployment of PyTorch Models as Flexible REST Endpoints", "comments": "3 pages, 1 figure, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of artificial intelligence capabilities into modern software\nsystems is increasingly being simplified through the use of cloud-based machine\nlearning services and representational state transfer architecture design.\nHowever, insufficient information regarding underlying model provenance and the\nlack of control over model evolution serve as an impediment to the more\nwidespread adoption of these services in many operational environments which\nhave strict security requirements. Furthermore, tools such as TensorFlow\nServing allow models to be deployed as RESTful endpoints, but require\nerror-prone transformations for PyTorch models as these dynamic computational\ngraphs. This is in contrast to the static computational graphs of TensorFlow.\nTo enable rapid deployments of PyTorch models without intermediate\ntransformations we have developed FlexServe, a simple library to deploy\nmulti-model ensembles with flexible batching.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:51:09 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Verenich", "Edward", ""], ["Velasquez", "Alvaro", ""], ["Murshed", "M. G. Sarwar", ""], ["Hussain", "Faraz", ""]]}, {"id": "2003.01541", "submitter": "Taban Eslami", "authors": "Taban Eslami, Joseph S. Raiker and Fahad Saeed", "title": "Explainable and Scalable Machine-Learning Algorithms for Detection of\n  Autism Spectrum Disorder using fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing Autism Spectrum Disorder (ASD) is a challenging problem, and is\nbased purely on behavioral descriptions of symptomology (DSM-5/ICD-10), and\nrequires informants to observe children with disorder across different settings\n(e.g. home, school). Numerous limitations (e.g., informant discrepancies, lack\nof adherence to assessment guidelines, informant biases) to current diagnostic\npractices have the potential to result in over-, under-, or misdiagnosis of the\ndisorder. Advances in neuroimaging technologies are providing a critical step\ntowards a more objective assessment of the disorder. Prior research provides\nstrong evidence that structural and functional magnetic resonance imaging (MRI)\ndata collected from individuals with ASD exhibit distinguishing characteristics\nthat differ in local and global spatial, and temporal neural-patterns of the\nbrain. Our proposed deep-learning model ASD-DiagNet exhibits consistently high\naccuracy for classification of ASD brain scans from neurotypical scans. We have\nfor the first time integrated traditional machine-learning and deep-learning\ntechniques that allows us to isolate ASD biomarkers from MRI data sets. Our\nmethod, called Auto-ASD-Network, uses a combination of deep-learning and\nSupport Vector Machines (SVM) to classify ASD scans from neurotypical scans.\nSuch interpretable models would help explain the decisions made by\ndeep-learning techniques leading to knowledge discovery for neuroscientists,\nand transparent analysis for clinicians.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:20:44 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Eslami", "Taban", ""], ["Raiker", "Joseph S.", ""], ["Saeed", "Fahad", ""]]}, {"id": "2003.01575", "submitter": "Lifeng Liu", "authors": "Lifeng Liu, Fengda Zhang, Jun Xiao, and Chao Wu", "title": "Evaluation Framework For Large-scale Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is proposed as a machine learning setting to enable\ndistributed edge devices, such as mobile phones, to collaboratively learn a\nshared prediction model while keeping all the training data on device, which\ncan not only take full advantage of data distributed across millions of nodes\nto train a good model but also protect data privacy. However, learning in\nscenario above poses new challenges. In fact, data across a massive number of\nunreliable devices is likely to be non-IID (identically and independently\ndistributed), which may make the performance of models trained by federated\nlearning unstable. In this paper, we introduce a framework designed for\nlarge-scale federated learning which consists of approaches to generating\ndataset and modular evaluation framework. Firstly, we construct a suite of\nopen-source non-IID datasets by providing three respects including covariate\nshift, prior probability shift, and concept shift, which are grounded in\nreal-world assumptions. In addition, we design several rigorous evaluation\nmetrics including the number of network nodes, the size of datasets, the number\nof communication rounds and communication resources etc. Finally, we present an\nopen-source benchmark for large-scale federated learning research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:12:13 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 02:14:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Liu", "Lifeng", ""], ["Zhang", "Fengda", ""], ["Xiao", "Jun", ""], ["Wu", "Chao", ""]]}, {"id": "2003.01580", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "Are You an Introvert or Extrovert? Accurate Classification With Only Ten\n  Predictors", "comments": "To be published in IEEE conference proceedings: 2nd International\n  Conference on Artificial Intelligence in Information and Communication,\n  ICAIIC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how accurately the prediction of being an introvert\nvs. extrovert can be made with less than ten predictors. The study is based on\na previous data collection of 7161 respondents of a survey on 91 personality\nand 3 demographic items. The results show that it is possible to effectively\nreduce the size of this measurement instrument from 94 to 10 features with a\nperformance loss of only 1%, achieving an accuracy of 73.81% on unseen data.\nClass imbalance correction methods like SMOTE or ADASYN showed considerable\nimprovement on the validation set but only minor performance improvement on the\ntesting set.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 04:30:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.01595", "submitter": "Harrison Rosenberg", "authors": "Yue Gao, Harrison Rosenberg, Kassem Fawaz, Somesh Jha, Justin Hsu", "title": "Analyzing Accuracy Loss in Randomized Smoothing Defenses", "comments": "19 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning (ML) algorithms, especially deep neural\nnetworks (DNNs), have demonstrated remarkable success (sometimes exceeding\nhuman-level performance) on several tasks, including face and speech\nrecognition. However, ML algorithms are vulnerable to \\emph{adversarial\nattacks}, such test-time, training-time, and backdoor attacks. In test-time\nattacks an adversary crafts adversarial examples, which are specially crafted\nperturbations imperceptible to humans which, when added to an input example,\nforce a machine learning model to misclassify the given input example.\nAdversarial examples are a concern when deploying ML algorithms in critical\ncontexts, such as information security and autonomous driving. Researchers have\nresponded with a plethora of defenses. One promising defense is\n\\emph{randomized smoothing} in which a classifier's prediction is smoothed by\nadding random noise to the input example we wish to classify. In this paper, we\ntheoretically and empirically explore randomized smoothing. We investigate the\neffect of randomized smoothing on the feasible hypotheses space, and show that\nfor some noise levels the set of hypotheses which are feasible shrinks due to\nsmoothing, giving one reason why the natural accuracy drops after smoothing. To\nperform our analysis, we introduce a model for randomized smoothing which\nabstracts away specifics, such as the exact distribution of the noise. We\ncomplement our theoretical results with extensive experiments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:27:53 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Gao", "Yue", ""], ["Rosenberg", "Harrison", ""], ["Fawaz", "Kassem", ""], ["Jha", "Somesh", ""], ["Hsu", "Justin", ""]]}, {"id": "2003.01599", "submitter": "Alex Nichol", "authors": "Alex Nichol", "title": "VQ-DRAW: A Sequential Discrete VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I present VQ-DRAW, an algorithm for learning compact discrete\nrepresentations of data. VQ-DRAW leverages a vector quantization effect to\nadapt the sequential generation scheme of DRAW to discrete latent variables. I\nshow that VQ-DRAW can effectively learn to compress images from a variety of\ncommon datasets, as well as generate realistic samples from these datasets with\nno help from an autoregressive prior.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:34:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Nichol", "Alex", ""]]}, {"id": "2003.01604", "submitter": "Zhen Peng", "authors": "Zhen Peng, Yixiang Dong, Minnan Luo, Xiao-Ming Wu, Qinghua Zheng", "title": "Self-Supervised Graph Representation Learning via Global Context\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To take full advantage of fast-growing unlabeled networked data, this paper\nintroduces a novel self-supervised strategy for graph representation learning\nby exploiting natural supervision provided by the data itself. Inspired by\nhuman social behavior, we assume that the global context of each node is\ncomposed of all nodes in the graph since two arbitrary entities in a connected\nnetwork could interact with each other via paths of varying length. Based on\nthis, we investigate whether the global context can be a source of free and\neffective supervisory signals for learning useful node representations.\nSpecifically, we randomly select pairs of nodes in a graph and train a\nwell-designed neural net to predict the contextual position of one node\nrelative to the other. Our underlying hypothesis is that the representations\nlearned from such within-graph context would capture the global topology of the\ngraph and finely characterize the similarity and differentiation between nodes,\nwhich is conducive to various downstream learning tasks. Extensive benchmark\nexperiments including node classification, clustering, and link prediction\ndemonstrate that our approach outperforms many state-of-the-art unsupervised\nmethods and sometimes even exceeds the performance of supervised counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:46:01 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Peng", "Zhen", ""], ["Dong", "Yixiang", ""], ["Luo", "Minnan", ""], ["Wu", "Xiao-Ming", ""], ["Zheng", "Qinghua", ""]]}, {"id": "2003.01609", "submitter": "Karim Guirguis", "authors": "Karim Guirguis, Christoph Schorn, Andre Guntoro, Sherif Abdulatif, Bin\n  Yang", "title": "SELD-TCN: Sound Event Localization & Detection via Temporal\n  Convolutional Networks", "comments": "5 pages, 3 tables, 2 figures. Submitted to EUSIPCO 2020", "journal-ref": null, "doi": "10.23919/Eusipco47968.2020.9287716", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of the surrounding environment plays a critical role in\nautonomous robotic systems, such as self-driving cars. Extensive research has\nbeen carried out concerning visual perception. Yet, to obtain a more complete\nperception of the environment, autonomous systems of the future should also\ntake acoustic information into account. Recent sound event localization and\ndetection (SELD) frameworks utilize convolutional recurrent neural networks\n(CRNNs). However, considering the recurrent nature of CRNNs, it becomes\nchallenging to implement them efficiently on embedded hardware. Not only are\ntheir computations strenuous to parallelize, but they also require high memory\nbandwidth and large memory buffers. In this work, we develop a more robust and\nhardware-friendly novel architecture based on a temporal convolutional\nnetwork(TCN). The proposed framework (SELD-TCN) outperforms the\nstate-of-the-art SELDnet performance on four different datasets. Moreover,\nSELD-TCN achieves 4x faster training time per epoch and 40x faster inference\ntime on an ordinary graphics processing unit (GPU).\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:48:57 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Guirguis", "Karim", ""], ["Schorn", "Christoph", ""], ["Guntoro", "Andre", ""], ["Abdulatif", "Sherif", ""], ["Yang", "Bin", ""]]}, {"id": "2003.01629", "submitter": "Kei Ota", "authors": "Kei Ota, Tomoaki Oiki, Devesh K. Jha, Toshisada Mariyama, Daniel\n  Nikovski", "title": "Can Increasing Input Dimensionality Improve Deep Reinforcement Learning?", "comments": "11 pages, 10 figures. Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms have recently achieved remarkable\nsuccesses in various sequential decision making tasks, leveraging advances in\nmethods for training large deep networks. However, these methods usually\nrequire large amounts of training data, which is often a big problem for\nreal-world applications. One natural question to ask is whether learning good\nrepresentations for states and using larger networks helps in learning better\npolicies. In this paper, we try to study if increasing input dimensionality\nhelps improve performance and sample efficiency of model-free deep RL\nalgorithms. To do so, we propose an online feature extractor network (OFENet)\nthat uses neural nets to produce good representations to be used as inputs to\ndeep RL algorithms. Even though the high dimensionality of input is usually\nsupposed to make learning of RL agents more difficult, we show that the RL\nagents in fact learn more efficiently with the high-dimensional representation\nthan with the lower-dimensional state observations. We believe that stronger\nfeature propagation together with larger networks (and thus larger search\nspace) allows RL agents to learn more complex functions of states and thus\nimproves the sample efficiency. Through numerical experiments, we show that the\nproposed method outperforms several other state-of-the-art algorithms in terms\nof both sample efficiency and performance. Codes for the proposed method are\navailable at http://www.merl.com/research/license/OFENet .\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 16:52:05 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 03:29:14 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ota", "Kei", ""], ["Oiki", "Tomoaki", ""], ["Jha", "Devesh K.", ""], ["Mariyama", "Toshisada", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2003.01640", "submitter": "Gregory Plumb", "authors": "Gregory Plumb, Jonathan Terhorst, Sriram Sankararaman, Ameet Talwalkar", "title": "Explaining Groups of Points in Low-Dimensional Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common workflow in data exploration is to learn a low-dimensional\nrepresentation of the data, identify groups of points in that representation,\nand examine the differences between the groups to determine what they\nrepresent. We treat this workflow as an interpretable machine learning problem\nby leveraging the model that learned the low-dimensional representation to help\nidentify the key differences between the groups. To solve this problem, we\nintroduce a new type of explanation, a Global Counterfactual Explanation (GCE),\nand our algorithm, Transitive Global Translations (TGT), for computing GCEs.\nTGT identifies the differences between each pair of groups using compressed\nsensing but constrains those pairwise differences to be consistent among all of\nthe groups. Empirically, we demonstrate that TGT is able to identify\nexplanations that accurately explain the model while being relatively sparse,\nand that these explanations match real patterns in the data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:06:55 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:34:34 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 15:54:13 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Plumb", "Gregory", ""], ["Terhorst", "Jonathan", ""], ["Sankararaman", "Sriram", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2003.01641", "submitter": "Kei Ota", "authors": "Kei Ota, Yoko Sasaki, Devesh K. Jha, Yusuke Yoshiyasu, and Asako\n  Kanezaki", "title": "Efficient Exploration in Constrained Environments with Goal-Oriented\n  Reference Path", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of building learning agents that can\nefficiently learn to navigate in constrained environments. The main goal is to\ndesign agents that can efficiently learn to understand and generalize to\ndifferent environments using high-dimensional inputs (a 2D map), while\nfollowing feasible paths that avoid obstacles in obstacle-cluttered\nenvironment. To achieve this, we make use of traditional path planning\nalgorithms, supervised learning, and reinforcement learning algorithms in a\nsynergistic way. The key idea is to decouple the navigation problem into\nplanning and control, the former of which is achieved by supervised learning\nwhereas the latter is done by reinforcement learning. Specifically, we train a\ndeep convolutional network that can predict collision-free paths based on a map\nof the environment-- this is then used by a reinforcement learning algorithm to\nlearn to closely follow the path. This allows the trained agent to achieve good\ngeneralization while learning faster. We test our proposed method in the\nrecently proposed Safety Gym suite that allows testing of safety-constraints\nduring training of learning agents. We compare our proposed method with\nexisting work and show that our method consistently improves the sample\nefficiency and generalization capability to novel environments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:07:47 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ota", "Kei", ""], ["Sasaki", "Yoko", ""], ["Jha", "Devesh K.", ""], ["Yoshiyasu", "Yusuke", ""], ["Kanezaki", "Asako", ""]]}, {"id": "2003.01652", "submitter": "Hadi Daneshmand", "authors": "Hadi Daneshmand, Jonas Kohler, Francis Bach, Thomas Hofmann, Aurelien\n  Lucchi", "title": "Batch Normalization Provably Avoids Rank Collapse for Randomly\n  Initialised Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomly initialized neural networks are known to become harder to train with\nincreasing depth, unless architectural enhancements like residual connections\nand batch normalization are used. We here investigate this phenomenon by\nrevisiting the connection between random initialization in deep networks and\nspectral instabilities in products of random matrices. Given the rich\nliterature on random matrices, it is not surprising to find that the rank of\nthe intermediate representations in unnormalized networks collapses quickly\nwith depth. In this work we highlight the fact that batch normalization is an\neffective strategy to avoid rank collapse for both linear and ReLU networks.\nLeveraging tools from Markov chain theory, we derive a meaningful lower rank\nbound in deep linear networks. Empirically, we also demonstrate that this rank\nrobustness generalizes to ReLU nets. Finally, we conduct an extensive set of\nexperiments on real-world data sets, which confirm that rank stability is\nindeed a crucial condition for training modern-day deep neural architectures.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:21:07 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 11:46:50 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:14:09 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Daneshmand", "Hadi", ""], ["Kohler", "Jonas", ""], ["Bach", "Francis", ""], ["Hofmann", "Thomas", ""], ["Lucchi", "Aurelien", ""]]}, {"id": "2003.01665", "submitter": "Jaewoo Park", "authors": "Jaewoo Park, Yoon Gyo Jung, Andrew Beng Jin Teoh", "title": "Discriminative Multi-level Reconstruction under Compact Latent Space for\n  One-Class Novelty Detection", "comments": "Accepted to ICPR 2020 Oral (acceptance rate 4.4%)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In one-class novelty detection, a model learns solely on the in-class data to\nsingle out out-class instances. Autoencoder (AE) variants aim to compactly\nmodel the in-class data to reconstruct it exclusively, thus differentiating the\nin-class from out-class by the reconstruction error. However, compact modeling\nin an improper way might collapse the latent representations of the in-class\ndata and thus their reconstruction, which would lead to performance\ndeterioration. Moreover, to properly measure the reconstruction error of\nhigh-dimensional data, a metric is required that captures high-level semantics\nof the data. To this end, we propose Discriminative Compact AE (DCAE) that\nlearns both compact and collapse-free latent representations of the in-class\ndata, thereby reconstructing them both finely and exclusively. In DCAE, (a) we\nforce a compact latent space to bijectively represent the in-class data by\nreconstructing them through internal discriminative layers of generative\nadversarial nets. (b) Based on the deep encoder's vulnerability to open set\nrisk, out-class instances are encoded into the same compact latent space and\nreconstructed poorly without sacrificing the quality of in-class data\nreconstruction. (c) In inference, the reconstruction error is measured by a\nnovel metric that computes the dissimilarity between a query and its\nreconstruction based on the class semantics captured by the internal\ndiscriminator. Extensive experiments on public image datasets validate the\neffectiveness of our proposed model on both novelty and adversarial example\ndetection, delivering state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 17:45:54 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:27:12 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 14:00:42 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Park", "Jaewoo", ""], ["Jung", "Yoon Gyo", ""], ["Teoh", "Andrew Beng Jin", ""]]}, {"id": "2003.01687", "submitter": "Warren Morningstar", "authors": "Warren R. Morningstar, Sharad M. Vikram, Cusuh Ham, Andrew Gallagher,\n  Joshua V. Dillon", "title": "Automatic Differentiation Variational Inference with Mixtures", "comments": "Submitted to NeurIPS 2020, Corrected footnote from: \"34th Conference\n  on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada\"\n  to \"Preprint. Under review.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Differentiation Variational Inference (ADVI) is a useful tool for\nefficiently learning probabilistic models in machine learning. Generally\napproximate posteriors learned by ADVI are forced to be unimodal in order to\nfacilitate use of the reparameterization trick. In this paper, we show how\nstratified sampling may be used to enable mixture distributions as the\napproximate posterior, and derive a new lower bound on the evidence analogous\nto the importance weighted autoencoder (IWAE). We show that this \"SIWAE\" is a\ntighter bound than both IWAE and the traditional ELBO, both of which are\nspecial instances of this bound. We verify empirically that the traditional\nELBO objective disfavors the presence of multimodal posterior distributions and\nmay therefore not be able to fully capture structure in the latent space. Our\nexperiments show that using the SIWAE objective allows the encoder to learn\nmore complex distributions which regularly contain multimodality, resulting in\nhigher accuracy and better calibration in the presence of incomplete, limited,\nor corrupted data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:12:42 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 16:51:02 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 22:05:39 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2020 17:35:38 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Morningstar", "Warren R.", ""], ["Vikram", "Sharad M.", ""], ["Ham", "Cusuh", ""], ["Gallagher", "Andrew", ""], ["Dillon", "Joshua V.", ""]]}, {"id": "2003.01690", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Reliable evaluation of adversarial robustness with an ensemble of\n  diverse parameter-free attacks", "comments": "In ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of defense strategies against adversarial attacks has significantly\ngrown over the last years, but progress is hampered as the evaluation of\nadversarial defenses is often insufficient and thus gives a wrong impression of\nrobustness. Many promising defenses could be broken later on, making it\ndifficult to identify the state-of-the-art. Frequent pitfalls in the evaluation\nare improper tuning of hyperparameters of the attacks, gradient obfuscation or\nmasking. In this paper we first propose two extensions of the PGD-attack\novercoming failures due to suboptimal step size and problems of the objective\nfunction. We then combine our novel attacks with two complementary existing\nones to form a parameter-free, computationally affordable and user-independent\nensemble of attacks to test adversarial robustness. We apply our ensemble to\nover 50 models from papers published at recent top machine learning and\ncomputer vision venues. In all except one of the cases we achieve lower robust\ntest accuracy than reported in these papers, often by more than $10\\%$,\nidentifying several broken defenses.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:15:55 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 18:31:08 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "2003.01704", "submitter": "Aldo Pacchiano", "authors": "Aldo Pacchiano, My Phan, Yasin Abbasi-Yadkori, Anup Rao, Julian\n  Zimmert, Tor Lattimore, Csaba Szepesvari", "title": "Model Selection in Contextual Stochastic Bandit Problems", "comments": "12 main pages, 2 figures, 14 appendix pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model selection in stochastic bandit problems. Our approach relies\non a master algorithm that selects its actions among candidate base algorithms.\nWhile this problem is studied for specific classes of stochastic base\nalgorithms, our objective is to provide a method that can work with more\ngeneral classes of stochastic base algorithms. We propose a master algorithm\ninspired by CORRAL \\cite{DBLP:conf/colt/AgarwalLNS17} and introduce a novel and\ngeneric smoothing transformation for stochastic bandit algorithms that permits\nus to obtain $O(\\sqrt{T})$ regret guarantees for a wide class of base\nalgorithms when working along with our master. We exhibit a lower bound showing\nthat even when one of the base algorithms has $O(\\log T)$ regret, in general it\nis impossible to get better than $\\Omega(\\sqrt{T})$ regret in model selection,\neven asymptotically. We apply our algorithm to choose among different values of\n$\\epsilon$ for the $\\epsilon$-greedy algorithm, and to choose between the\n$k$-armed UCB and linear UCB algorithms. Our empirical studies further confirm\nthe effectiveness of our model-selection method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:46:34 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:39:06 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Pacchiano", "Aldo", ""], ["Phan", "My", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Rao", "Anup", ""], ["Zimmert", "Julian", ""], ["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "2003.01709", "submitter": "Donald J. Hejna Iii", "authors": "Donald J. Hejna III, Pieter Abbeel, Lerrel Pinto", "title": "Hierarchically Decoupled Imitation for Morphological Transfer", "comments": "International Conference on Machine Learning (ICML) 2020 camera ready\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-range behaviors on complex high-dimensional agents is a\nfundamental problem in robot learning. For such tasks, we argue that\ntransferring learned information from a morphologically simpler agent can\nmassively improve the sample efficiency of a more complex one. To this end, we\npropose a hierarchical decoupling of policies into two parts: an independently\nlearned low-level policy and a transferable high-level policy. To remedy poor\ntransfer performance due to mismatch in morphologies, we contribute two key\nideas. First, we show that incentivizing a complex agent's low-level to imitate\na simpler agent's low-level significantly improves zero-shot high-level\ntransfer. Second, we show that KL-regularized training of the high level\nstabilizes learning and prevents mode-collapse. Finally, on a suite of publicly\nreleased navigation and manipulation environments, we demonstrate the\napplicability of hierarchical transfer on long-range tasks across morphologies.\nOur code and videos can be found at\nhttps://sites.google.com/berkeley.edu/morphology-transfer.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:56:49 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 07:26:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hejna", "Donald J.", "III"], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2003.01747", "submitter": "Victor Veitch", "authors": "Victor Veitch and Anisha Zaveri", "title": "Sense and Sensitivity Analysis: Simple Post-Hoc Analysis of Bias Due to\n  Unobserved Confounding", "comments": "\"Austen\" is Jane Austen, in service of the pun in the title. Paper\n  published at NeurIPS 2020. Arxiv version has identical content but nicer\n  formating. NeurIPS spotlight talk here:\n  https://nips.cc/virtual/2020/public/poster_7d265aa7147bd3913fb84c7963a209d1.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a truth universally acknowledged that an observed association without\nknown mechanism must be in want of a causal estimate. However, causal\nestimation from observational data often relies on the (untestable) assumption\nof `no unobserved confounding'. Violations of this assumption can induce bias\nin effect estimates. In principle, such bias could invalidate or reverse the\nconclusions of a study. However, in some cases, we might hope that the\ninfluence of unobserved confounders is weak relative to a `large' estimated\neffect, so the qualitative conclusions are robust to bias from unobserved\nconfounding. The purpose of this paper is to develop \\emph{Austen plots}, a\nsensitivity analysis tool to aid such judgments by making it easier to reason\nabout potential bias induced by unobserved confounding. We formalize\nconfounding strength in terms of how strongly the confounder influences\ntreatment assignment and outcome. For a target level of bias, an Austen plot\nshows the minimum values of treatment and outcome influence required to induce\nthat level of bias. Domain experts can then make subjective judgments about\nwhether such strong confounders are plausible. To aid this judgment, the Austen\nplot additionally displays the estimated influence strength of (groups of) the\nobserved covariates. Austen plots generalize the classic sensitivity analysis\napproach of Imbens [Imb03]. Critically, Austen plots allow any approach for\nmodeling the observed data and producing the initial estimate. We illustrate\nthe tool by assessing biases for several real causal inference problems, using\na variety of machine learning approaches for the initial data analysis. Code is\navailable at https://github.com/anishazaveri/austen_plots\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 19:18:24 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 01:11:49 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Veitch", "Victor", ""], ["Zaveri", "Anisha", ""]]}, {"id": "2003.01751", "submitter": "Bozhou Chen", "authors": "Bozhou Chen, Kaixin Zhang, Longshen Ou, Chenmin Ba, Hongzhi Wang and\n  Chunnan Wang (Habin Institute of Technology)", "title": "Automatic Hyper-Parameter Optimization Based on Mapping Discovery from\n  Data to Hyper-Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have made remarkable achievements in the field of\nartificial intelligence. However, most machine learning algorithms are\nsensitive to the hyper-parameters. Manually optimizing the hyper-parameters is\na common method of hyper-parameter tuning. However, it is costly and\nempirically dependent. Automatic hyper-parameter optimization (autoHPO) is\nfavored due to its effectiveness. However, current autoHPO methods are usually\nonly effective for a certain type of problems, and the time cost is high. In\nthis paper, we propose an efficient automatic parameter optimization approach,\nwhich is based on the mapping from data to the corresponding hyper-parameters.\nTo describe such mapping, we propose a sophisticated network structure. To\nobtain such mapping, we develop effective network constrution algorithms. We\nalso design strategy to optimize the result futher during the application of\nthe mapping. Extensive experimental results demonstrate that the proposed\napproaches outperform the state-of-the-art apporaches significantly.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 19:26:23 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Chen", "Bozhou", "", "Habin Institute of Technology"], ["Zhang", "Kaixin", "", "Habin Institute of Technology"], ["Ou", "Longshen", "", "Habin Institute of Technology"], ["Ba", "Chenmin", "", "Habin Institute of Technology"], ["Wang", "Hongzhi", "", "Habin Institute of Technology"], ["Wang", "Chunnan", "", "Habin Institute of Technology"]]}, {"id": "2003.01753", "submitter": "Zepeng Huo", "authors": "Zepeng Huo, Arash PakBin, Xiaohan Chen, Nathan Hurley, Ye Yuan,\n  Xiaoning Qian, Zhangyang Wang, Shuai Huang, Bobak Mortazavi", "title": "Uncertainty Quantification for Deep Context-Aware Mobile Activity\n  Recognition and Unknown Context Discovery", "comments": "10 pages, 5 figures, accepted by AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activity recognition in wearable computing faces two key challenges: i)\nactivity characteristics may be context-dependent and change under different\ncontexts or situations; ii) unknown contexts and activities may occur from time\nto time, requiring flexibility and adaptability of the algorithm. We develop a\ncontext-aware mixture of deep models termed the {\\alpha}-\\b{eta} network\ncoupled with uncertainty quantification (UQ) based upon maximum entropy to\nenhance human activity recognition performance. We improve accuracy and F score\nby 10% by identifying high-level contexts in a data-driven way to guide model\ndevelopment. In order to ensure training stability, we have used a\nclustering-based pre-training in both public and in-house datasets,\ndemonstrating improved accuracy through unknown context discovery.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 19:35:34 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Huo", "Zepeng", ""], ["PakBin", "Arash", ""], ["Chen", "Xiaohan", ""], ["Hurley", "Nathan", ""], ["Yuan", "Ye", ""], ["Qian", "Xiaoning", ""], ["Wang", "Zhangyang", ""], ["Huang", "Shuai", ""], ["Mortazavi", "Bobak", ""]]}, {"id": "2003.01762", "submitter": "Jiawen Liu", "authors": "Jie Liu, Jiawen Liu, Zhen Xie, Dong Li", "title": "FLAME: A Self-Adaptive Auto-labeling System for Heterogeneous Mobile\n  Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to accurately and efficiently label data on a mobile device is critical\nfor the success of training machine learning models on mobile devices.\nAuto-labeling data on mobile devices is challenging, because data is usually\nincrementally generated and there is possibility of having unknown labels.\nFurthermore, the rich hardware heterogeneity on mobile devices creates\nchallenges on efficiently executing auto-labeling workloads. In this paper, we\nintroduce Flame, an auto-labeling system that can label non-stationary data\nwith unknown labels. Flame includes a runtime system that efficiently schedules\nand executes auto-labeling workloads on heterogeneous mobile processors.\nEvaluating Flame with eight datasets on a smartphone, we demonstrate that Flame\nenables auto-labeling with high labeling accuracy and high performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 19:54:32 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Liu", "Jie", ""], ["Liu", "Jiawen", ""], ["Xie", "Zhen", ""], ["Li", "Dong", ""]]}, {"id": "2003.01770", "submitter": "Kamiar Rahnama Rad", "authors": "Kamiar Rahnama Rad and Wenda Zhou and Arian Maleki", "title": "Error bounds in estimating the out-of-sample prediction error using\n  leave-one-out cross validation in high-dimensions", "comments": null, "journal-ref": "AISTATS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of out-of-sample risk estimation in the high dimensional\nregime where both the sample size $n$ and number of features $p$ are large, and\n$n/p$ can be less than one. Extensive empirical evidence confirms the accuracy\nof leave-one-out cross validation (LO) for out-of-sample risk estimation. Yet,\na unifying theoretical evaluation of the accuracy of LO in high-dimensional\nproblems has remained an open problem. This paper aims to fill this gap for\npenalized regression in the generalized linear family. With minor assumptions\nabout the data generating process, and without any sparsity assumptions on the\nregression coefficients, our theoretical analysis obtains finite sample upper\nbounds on the expected squared error of LO in estimating the out-of-sample\nerror. Our bounds show that the error goes to zero as $n,p \\rightarrow \\infty$,\neven when the dimension $p$ of the feature vectors is comparable with or\ngreater than the sample size $n$. One technical advantage of the theory is that\nit can be used to clarify and connect some results from the recent literature\non scalable approximate LO.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:07:07 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Rad", "Kamiar Rahnama", ""], ["Zhou", "Wenda", ""], ["Maleki", "Arian", ""]]}, {"id": "2003.01792", "submitter": "Yaotian Wang", "authors": "Yaotian Wang, Xiaohang Sun and Jason W. Fleischer", "title": "When deep denoising meets iterative phase retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a signal from its Fourier intensity underlies many important\napplications, including lensless imaging and imaging through scattering media.\nConventional algorithms for retrieving the phase suffer when noise is present\nbut display global convergence when given clean data. Neural networks have been\nused to improve algorithm robustness, but efforts to date are sensitive to\ninitial conditions and give inconsistent performance. Here, we combine\niterative methods from phase retrieval with image statistics from deep\ndenoisers, via regularization-by-denoising. The resulting methods inherit the\nadvantages of each approach and outperform other noise-robust phase retrieval\nalgorithms. Our work paves the way for hybrid imaging methods that integrate\nmachine-learned constraints in conventional algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:00:45 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Wang", "Yaotian", ""], ["Sun", "Xiaohang", ""], ["Fleischer", "Jason W.", ""]]}, {"id": "2003.01794", "submitter": "Mao Ye", "authors": "Mao Ye, Chengyue Gong, Lizhen Nie, Denny Zhou, Adam Klivans, and Qiang\n  Liu", "title": "Good Subnetworks Provably Exist: Pruning via Greedy Forward Selection", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent empirical works show that large deep neural networks are often highly\nredundant and one can find much smaller subnetworks without a significant drop\nof accuracy. However, most existing methods of network pruning are empirical\nand heuristic, leaving it open whether good subnetworks provably exist, how to\nfind them efficiently, and if network pruning can be provably better than\ndirect training using gradient descent. We answer these problems positively by\nproposing a simple greedy selection approach for finding good subnetworks,\nwhich starts from an empty network and greedily adds important neurons from the\nlarge network. This differs from the existing methods based on backward\nelimination, which remove redundant neurons from the large network.\nTheoretically, applying the greedy selection strategy on sufficiently large\n{pre-trained} networks guarantees to find small subnetworks with lower loss\nthan networks directly trained with gradient descent. Our results also apply to\npruning randomly weighted networks. Practically, we improve prior arts of\nnetwork pruning on learning compact neural architectures on ImageNet, including\nResNet, MobilenetV2/V3, and ProxylessNet. Our theory and empirical results on\nMobileNet suggest that we should fine-tune the pruned subnetworks to leverage\nthe information from the large model, instead of re-training from new random\ninitialization as suggested in \\citet{liu2018rethinking}.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:03:11 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 23:05:34 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 05:35:07 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ye", "Mao", ""], ["Gong", "Chengyue", ""], ["Nie", "Lizhen", ""], ["Zhou", "Denny", ""], ["Klivans", "Adam", ""], ["Liu", "Qiang", ""]]}, {"id": "2003.01795", "submitter": "Alejandro Parada-Mayorga", "authors": "Alejandro Parada-Mayorga, Luana Ruiz and Alejandro Ribeiro", "title": "Graphon Pooling in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been used effectively in different\napplications involving the processing of signals on irregular structures\nmodeled by graphs. Relying on the use of shift-invariant graph filters, GNNs\nextend the operation of convolution to graphs. However, the operations of\npooling and sampling are still not clearly defined and the approaches proposed\nin the literature either modify the graph structure in a way that does not\npreserve its spectral properties, or require defining a policy for selecting\nwhich nodes to keep. In this work, we propose a new strategy for pooling and\nsampling on GNNs using graphons which preserves the spectral properties of the\ngraph. To do so, we consider the graph layers in a GNN as elements of a\nsequence of graphs that converge to a graphon. In this way we have no ambiguity\nin the node labeling when mapping signals from one layer to the other and a\nspectral representation that is consistent throughout the layers. We evaluate\nthis strategy in a synthetic and a real-world numerical experiment where we\nshow that graphon pooling GNNs are less prone to overfitting and improve upon\nother pooling techniques, especially when the dimensionality reduction ratios\nbetween layers is large.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:04:20 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Parada-Mayorga", "Alejandro", ""], ["Ruiz", "Luana", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2003.01803", "submitter": "Quanquan Gu", "authors": "Tianyuan Jin, Pan Xu, Jieming Shi, Xiaokui Xiao, and Quanquan Gu", "title": "MOTS: Minimax Optimal Thompson Sampling", "comments": "27 pages, 1 table, 2 figures. This version improves the presentation\n  in V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling is one of the most widely used algorithms for many online\ndecision problems, due to its simplicity in implementation and superior\nempirical performance over other state-of-the-art methods. Despite its\npopularity and empirical success, it has remained an open problem whether\nThompson sampling can match the minimax lower bound $\\Omega(\\sqrt{KT})$ for\n$K$-armed bandit problems, where $T$ is the total time horizon. In this paper,\nwe solve this long open problem by proposing a variant of Thompson sampling\ncalled MOTS that adaptively clips the sampling instance of the chosen arm at\neach time step. We prove that this simple variant of Thompson sampling achieves\nthe minimax optimal regret bound $O(\\sqrt{KT})$ for finite time horizon $T$, as\nwell as the asymptotic optimal regret bound for Gaussian rewards when $T$\napproaches infinity. To our knowledge, MOTS is the first Thompson sampling type\nalgorithm that achieves the minimax optimality for multi-armed bandit problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:24:39 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 03:42:26 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 06:12:11 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Jin", "Tianyuan", ""], ["Xu", "Pan", ""], ["Shi", "Jieming", ""], ["Xiao", "Xiaokui", ""], ["Gu", "Quanquan", ""]]}, {"id": "2003.01820", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, Rahul Savani", "title": "Robust Market Making via Adversarial Reinforcement Learning", "comments": "7 pages, 3 figures; IJCAI-PRICAI '20 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that adversarial reinforcement learning (ARL) can be used to produce\nmarket marking agents that are robust to adversarial and adaptively-chosen\nmarket conditions. To apply ARL, we turn the well-studied single-agent model of\nAvellaneda and Stoikov [2008] into a discrete-time zero-sum game between a\nmarket maker and adversary. The adversary acts as a proxy for other market\nparticipants that would like to profit at the market maker's expense. We\nempirically compare two conventional single-agent RL agents with ARL, and show\nthat our ARL approach leads to: 1) the emergence of risk-averse behaviour\nwithout constraints or domain-specific penalties; 2) significant improvements\nin performance across a set of standard metrics, evaluated with or without an\nadversary in the test environment, and; 3) improved robustness to model\nuncertainty. We empirically demonstrate that our ARL method consistently\nconverges, and we prove for several special cases that the profiles that we\nconverge to correspond to Nash equilibria in a simplified single-stage game.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 22:40:57 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 15:15:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Spooner", "Thomas", ""], ["Savani", "Rahul", ""]]}, {"id": "2003.01847", "submitter": "Weonyoung Joo", "authors": "Weonyoung Joo, Dongjun Kim, Seungjae Shin, Il-Chul Moon", "title": "Generalized Gumbel-Softmax Gradient Estimator for Various Discrete\n  Random Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the gradients of stochastic nodes is one of the crucial research\nquestions in the deep generative modeling community, which enables the gradient\ndescent optimization on neural network parameters. This estimation problem\nbecomes further complex when we regard the stochastic nodes to be discrete\nbecause pathwise derivative techniques cannot be applied. Hence, the stochastic\ngradient estimation of discrete distributions requires either a score function\nmethod or continuous relaxation of the discrete random variables. This paper\nproposes a general version of the Gumbel-Softmax estimator with continuous\nrelaxation, and this estimator is able to relax the discreteness of probability\ndistributions including more diverse types, other than categorical and\nBernoulli. In detail, we utilize the truncation of discrete random variables\nand the Gumbel-Softmax trick with a linear transformation for the relaxed\nreparameterization. The proposed approach enables the relaxed discrete random\nvariable to be reparameterized and to backpropagated through a large scale\nstochastic computational graph. Our experiments consist of (1) synthetic data\nanalyses, which show the efficacy of our methods; and (2) applications on VAE\nand topic model, which demonstrate the value of the proposed estimation in\npractices.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 01:13:15 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 10:38:58 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Joo", "Weonyoung", ""], ["Kim", "Dongjun", ""], ["Shin", "Seungjae", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2003.01852", "submitter": "Taisuke Kobayashi", "authors": "Taisuke Kobayashi", "title": "q-VAE for Disentangled Representation Learning and Latent Dynamical\n  Systems", "comments": "8 pages, 8 figures", "journal-ref": "IEEE Robotics and Automation Letters, 2020", "doi": "10.1109/LRA.2020.3010206", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variational autoencoder (VAE) derived from Tsallis statistics called q-VAE\nis proposed. In the proposed method, a standard VAE is employed to\nstatistically extract latent space hidden in sampled data, and this latent\nspace helps make robots controllable in feasible computational time and cost.\nTo improve the usefulness of the latent space, this paper focuses on\ndisentangled representation learning, e.g., $\\beta$-VAE, which is the baseline\nfor it. Starting from a Tsallis statistics perspective, a new lower bound for\nthe proposed q-VAE is derived to maximize the likelihood of the sampled data,\nwhich can be considered an adaptive $\\beta$-VAE with deformed Kullback-Leibler\ndivergence. To verify the benefits of the proposed q-VAE, a benchmark task to\nextract the latent space from the MNIST dataset was performed. The results\ndemonstrate that the proposed q-VAE improved disentangled representation while\nmaintaining the reconstruction accuracy of the data. In addition, it relaxes\nthe independency condition between data, which is demonstrated by learning the\nlatent dynamics of nonlinear dynamical systems. By combining disentangled\nrepresentation, the proposed q-VAE achieves stable and accurate long-term state\nprediction from the initial state and the action sequence.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 01:38:39 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:39:40 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Kobayashi", "Taisuke", ""]]}, {"id": "2003.01873", "submitter": "Bowen Gang", "authors": "Bowen Gang, Gourab Mukherjee and Wenguang Sun", "title": "Large-Scale Shrinkage Estimation under Markovian Dependence", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneous estimation of a sequence of dependent\nparameters that are generated from a hidden Markov model. Based on observing a\nnoise contaminated vector of observations from such a sequence model, we\nconsider simultaneous estimation of all the parameters irrespective of their\nhidden states under square error loss. We study the roles of statistical\nshrinkage for improved estimation of these dependent parameters. Being\ncompletely agnostic on the distributional properties of the unknown underlying\nHidden Markov model, we develop a novel non-parametric shrinkage algorithm. Our\nproposed method elegantly combines \\textit{Tweedie}-based non-parametric\nshrinkage ideas with efficient estimation of the hidden states under Markovian\ndependence. Based on extensive numerical experiments, we establish superior\nperformance our our proposed algorithm compared to non-shrinkage based\nstate-of-the-art parametric as well as non-parametric algorithms used in hidden\nMarkov models. We provide decision theoretic properties of our methodology and\nexhibit its enhanced efficacy over popular shrinkage methods built under\nindependence. We demonstrate the application of our methodology on real-world\ndatasets for analyzing of temporally dependent social and economic indicators\nsuch as search trends and unemployment rates as well as estimating spatially\ndependent Copy Number Variations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 03:29:40 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 23:25:16 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Gang", "Bowen", ""], ["Mukherjee", "Gourab", ""], ["Sun", "Wenguang", ""]]}, {"id": "2003.01876", "submitter": "Yangsibo Huang", "authors": "Yangsibo Huang, Yushan Su, Sachin Ravi, Zhao Song, Sanjeev Arora, Kai\n  Li", "title": "Privacy-preserving Learning via Deep Net Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper attempts to answer the question whether neural network pruning can\nbe used as a tool to achieve differential privacy without losing much data\nutility. As a first step towards understanding the relationship between neural\nnetwork pruning and differential privacy, this paper proves that pruning a\ngiven layer of the neural network is equivalent to adding a certain amount of\ndifferentially private noise to its hidden-layer activations. The paper also\npresents experimental results to show the practical implications of the\ntheoretical finding and the key parameter values in a simple practical setting.\nThese results show that neural network pruning can be a more effective\nalternative to adding differentially private noise for neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 03:42:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Huang", "Yangsibo", ""], ["Su", "Yushan", ""], ["Ravi", "Sachin", ""], ["Song", "Zhao", ""], ["Arora", "Sanjeev", ""], ["Li", "Kai", ""]]}, {"id": "2003.01878", "submitter": "Sen Liu", "authors": "Sen Liu (1), Branden B. Kappes (1), Behnam Amin-ahmadi (1), Othmane\n  Benafan (2), Xiaoli Zhang (1), Aaron P. Stebner (1,3) ((1) Mechanical\n  Engineering, Colorado School of Mines, Golden (2) Materials and Structures\n  Division, NASA Glenn Research Center (3) Mechanical Engineering and Materials\n  Science and Engineering, Georgia Institute of Technology)", "title": "Physics-informed machine learning for composition-process-property alloy\n  design: shape memory alloy demonstration", "comments": "Submitted to Journal, 34 pages, 6 main figures/tables, and 9\n  supplementary figures/tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is shown to predict new alloys and their performances\nin a high dimensional, multiple-target-property design space that considers\nchemistry, multi-step processing routes, and characterization methodology\nvariations. A physics-informed featured engineering approach is shown to enable\notherwise poorly performing ML models to perform well with the same data.\nSpecifically, previously engineered elemental features based on alloy\nchemistries are combined with newly engineered heat treatment process features.\nThe new features result from first transforming the heat treatment parameter\ndata as it was previously recorded using nonlinear mathematical relationships\nknown to describe the thermodynamics and kinetics of phase transformations in\nalloys. The ability of the ML model to be used for predictive design is\nvalidated using blind predictions. Composition - process - property\nrelationships for thermal hysteresis of shape memory alloys (SMAs) with complex\nmicrostructures created via multiple\nmelting-homogenization-solutionization-precipitation processing stage\nvariations are captured, in addition to the mean transformation temperatures of\nthe SMAs. The quantitative models of hysteresis exhibited by such highly\nprocessed alloys demonstrate the ability for ML models to design for physical\ncomplexities that have challenged physics-based modeling approaches for\ndecades.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 03:53:55 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 22:53:06 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 22:42:06 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Liu", "Sen", ""], ["Kappes", "Branden B.", ""], ["Amin-ahmadi", "Behnam", ""], ["Benafan", "Othmane", ""], ["Zhang", "Xiaoli", ""], ["Stebner", "Aaron P.", ""]]}, {"id": "2003.01887", "submitter": "Hayato Ushijima-Mwesigwa", "authors": "Eldan Cohen, Avradip Mandal, Hayato Ushijima-Mwesigwa, and Arnab Roy", "title": "Ising-based Consensus Clustering on Specialized Hardware", "comments": "Accepted in Symposium on Intelligent Data Analysis 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of specialized optimization hardware such as CMOS annealers and\nadiabatic quantum computers carries the promise of solving hard combinatorial\noptimization problems more efficiently in hardware. Recent work has focused on\nformulating different combinatorial optimization problems as Ising models, the\ncore mathematical abstraction used by a large number of these hardware\nplatforms, and evaluating the performance of these models when solved on\nspecialized hardware. An interesting area of application is data mining, where\ncombinatorial optimization problems underlie many core tasks. In this work, we\nfocus on consensus clustering (clustering aggregation), an important\ncombinatorial problem that has received much attention over the last two\ndecades. We present two Ising models for consensus clustering and evaluate them\nusing the Fujitsu Digital Annealer, a quantum-inspired CMOS annealer. Our\nempirical evaluation shows that our approach outperforms existing techniques\nand is a promising direction for future research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 04:37:59 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Cohen", "Eldan", ""], ["Mandal", "Avradip", ""], ["Ushijima-Mwesigwa", "Hayato", ""], ["Roy", "Arnab", ""]]}, {"id": "2003.01889", "submitter": "Yusuke Hayashi", "authors": "Yusuke Hayashi and Taiji Suzuki", "title": "Meta Cyclical Annealing Schedule: A Simple Approach to Avoiding\n  Meta-Amortization Error", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn new concepts with small amounts of data is a crucial\naspect of intelligence that has proven challenging for deep learning methods.\nMeta-learning for few-shot learning offers a potential solution to this\nproblem: by learning to learn across data from many previous tasks, few-shot\nlearning algorithms can discover the structure among tasks to enable fast\nlearning of new tasks. However, a critical challenge in few-shot learning is\ntask ambiguity: even when a powerful prior can be meta-learned from a large\nnumber of prior tasks, a small dataset for a new task can simply be very\nambiguous to acquire a single model for that task. The Bayesian meta-learning\nmodels can naturally resolve this problem by putting a sophisticated prior\ndistribution and let the posterior well regularized through Bayesian decision\ntheory. However, currently known Bayesian meta-learning procedures such as\nVERSA suffer from the so-called {\\it information preference problem}, that is,\nthe posterior distribution is degenerated to one point and is far from the\nexact one. To address this challenge, we design a novel meta-regularization\nobjective using {\\it cyclical annealing schedule} and {\\it maximum mean\ndiscrepancy} (MMD) criterion. The cyclical annealing schedule is quite\neffective at avoiding such degenerate solutions. This procedure includes a\ndifficult KL-divergence estimation, but we resolve the issue by employing MMD\ninstead of KL-divergence. The experimental results show that our approach\nsubstantially outperforms standard meta-learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 04:43:16 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Hayashi", "Yusuke", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2003.01892", "submitter": "Jiawei Chen", "authors": "Jiawei Chen, Can Wang, Sheng Zhou, Qihao Shi, Jingbang Chen, Yan Feng,\n  Chun Chen", "title": "Fast Adaptively Weighted Matrix Factorization for Recommendation with\n  Implicit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation from implicit feedback is a highly challenging task due to the\nlack of the reliable observed negative data. A popular and effective approach\nfor implicit recommendation is to treat unobserved data as negative but\ndownweight their confidence. Naturally, how to assign confidence weights and\nhow to handle the large number of the unobserved data are two key problems for\nimplicit recommendation models. However, existing methods either pursuit fast\nlearning by manually assigning simple confidence weights, which lacks\nflexibility and may create empirical bias in evaluating user's preference; or\nadaptively infer personalized confidence weights but suffer from low\nefficiency. To achieve both adaptive weights assignment and efficient model\nlearning, we propose a fast adaptively weighted matrix factorization (FAWMF)\nbased on variational auto-encoder. The personalized data confidence weights are\nadaptively assigned with a parameterized neural network (function) and the\nnetwork can be inferred from the data. Further, to support fast and stable\nlearning of FAWMF, a new specific batch-based learning algorithm fBGD has been\ndeveloped, which trains on all feedback data but its complexity is linear to\nthe number of observed data. Extensive experiments on real-world datasets\ndemonstrate the superiority of the proposed FAWMF and its learning algorithm\nfBGD.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 04:50:44 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Chen", "Jiawei", ""], ["Wang", "Can", ""], ["Zhou", "Sheng", ""], ["Shi", "Qihao", ""], ["Chen", "Jingbang", ""], ["Feng", "Yan", ""], ["Chen", "Chun", ""]]}, {"id": "2003.01897", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Prayaag Venkat, Sham Kakade, Tengyu Ma", "title": "Optimal Regularization Can Mitigate Double Descent", "comments": "v2: Accepted to ICLR 2021. Minor edits to Intro and Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent empirical and theoretical studies have shown that many learning\nalgorithms -- from linear regression to neural networks -- can have test\nperformance that is non-monotonic in quantities such the sample size and model\nsize. This striking phenomenon, often referred to as \"double descent\", has\nraised questions of if we need to re-think our current understanding of\ngeneralization. In this work, we study whether the double-descent phenomenon\ncan be avoided by using optimal regularization. Theoretically, we prove that\nfor certain linear regression models with isotropic data distribution,\noptimally-tuned $\\ell_2$ regularization achieves monotonic test performance as\nwe grow either the sample size or the model size. We also demonstrate\nempirically that optimally-tuned $\\ell_2$ regularization can mitigate double\ndescent for more general models, including neural networks. Our results suggest\nthat it may also be informative to study the test risk scalings of various\nalgorithms in the context of appropriately tuned regularization.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 05:19:09 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 04:45:47 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Venkat", "Prayaag", ""], ["Kakade", "Sham", ""], ["Ma", "Tengyu", ""]]}, {"id": "2003.01905", "submitter": "Sulgi Kim", "authors": "Sulgi Kim and Kyungmin Kim", "title": "Odds-Ratio Thompson Sampling to Control for Time-Varying Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandit methods have been used for dynamic experiments\nparticularly in online services. Among the methods, thompson sampling is widely\nused because it is simple but shows desirable performance. Many thompson\nsampling methods for binary rewards use logistic model that is written in a\nspecific parameterization. In this study, we reparameterize logistic model with\nodds ratio parameters. This shows that thompson sampling can be used with\nsubset of parameters. Based on this finding, we propose a novel method,\n\"Odds-ratio thompson sampling\", which is expected to work robust to\ntime-varying effect. Use of the proposed method in continuous experiment is\ndescribed with discussing a desirable property of the method. In simulation\nstudies, the novel method works robust to temporal background effect, while the\nloss of performance was only marginal in case with no such effect. Finally,\nusing dataset from real service, we showed that the novel method would gain\ngreater rewards in practical environment.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 05:48:21 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Kim", "Sulgi", ""], ["Kim", "Kyungmin", ""]]}, {"id": "2003.01908", "submitter": "Hadi Salman", "authors": "Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor and J. Zico Kolter", "title": "Denoised Smoothing: A Provable Defense for Pretrained Classifiers", "comments": "10 pages main text; 29 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for provably defending any pretrained image classifier\nagainst $\\ell_p$ adversarial attacks. This method, for instance, allows public\nvision API providers and users to seamlessly convert pretrained non-robust\nclassification services into provably robust ones. By prepending a\ncustom-trained denoiser to any off-the-shelf image classifier and using\nrandomized smoothing, we effectively create a new classifier that is guaranteed\nto be $\\ell_p$-robust to adversarial examples, without modifying the pretrained\nclassifier. Our approach applies to both the white-box and the black-box\nsettings of the pretrained classifier. We refer to this defense as denoised\nsmoothing, and we demonstrate its effectiveness through extensive\nexperimentation on ImageNet and CIFAR-10. Finally, we use our approach to\nprovably defend the Azure, Google, AWS, and ClarifAI image classification APIs.\nOur code replicating all the experiments in the paper can be found at:\nhttps://github.com/microsoft/denoised-smoothing.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:15:55 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 02:20:16 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Salman", "Hadi", ""], ["Sun", "Mingjie", ""], ["Yang", "Greg", ""], ["Kapoor", "Ashish", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2003.01912", "submitter": "Ethan Fetaya", "authors": "Ethan Fetaya, Yonatan Lifshitz, Elad Aaron and Shai Gordin", "title": "Restoration of Fragmentary Babylonian Texts Using Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main source of information regarding ancient Mesopotamian history and\nculture are clay cuneiform tablets. Despite being an invaluable resource, many\ntablets are fragmented leading to missing information. Currently these missing\nparts are manually completed by experts. In this work we investigate the\npossibility of assisting scholars and even automatically completing the breaks\nin ancient Akkadian texts from Achaemenid period Babylonia by modelling the\nlanguage using recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:36:50 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fetaya", "Ethan", ""], ["Lifshitz", "Yonatan", ""], ["Aaron", "Elad", ""], ["Gordin", "Shai", ""]]}, {"id": "2003.01922", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Haipeng Luo, Alekh Agarwal", "title": "Taking a hint: How to leverage loss predictors in contextual bandits?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of learning in contextual bandits with the help of loss\npredictors. The main question we address is whether one can improve over the\nminimax regret $\\mathcal{O}(\\sqrt{T})$ for learning over $T$ rounds, when the\ntotal error of the predictor $\\mathcal{E} \\leq T$ is relatively small. We\nprovide a complete answer to this question, including upper and lower bounds\nfor various settings: adversarial versus stochastic environments, known versus\nunknown $\\mathcal{E}$, and single versus multiple predictors. We show several\nsurprising results, such as 1) the optimal regret is\n$\\mathcal{O}(\\min\\{\\sqrt{T}, \\sqrt{\\mathcal{E}}T^\\frac{1}{4}\\})$ when\n$\\mathcal{E}$ is known, a sharp contrast to the standard and better bound\n$\\mathcal{O}(\\sqrt{\\mathcal{E}})$ for non-contextual problems (such as\nmulti-armed bandits); 2) the same bound cannot be achieved if $\\mathcal{E}$ is\nunknown, but as a remedy, $\\mathcal{O}(\\sqrt{\\mathcal{E}}T^\\frac{1}{3})$ is\nachievable; 3) with $M$ predictors, a linear dependence on $M$ is necessary,\neven if logarithmic dependence is possible for non-contextual problems.\n  We also develop several novel algorithmic techniques to achieve matching\nupper bounds, including 1) a key action remapping technique for optimal regret\nwith known $\\mathcal{E}$, 2) implementing Catoni's robust mean estimator\nefficiently via an ERM oracle leading to an efficient algorithm in the\nstochastic setting with optimal regret, 3) constructing an underestimator for\n$\\mathcal{E}$ via estimating the histogram with bins of exponentially\nincreasing size for the stochastic setting with unknown $\\mathcal{E}$, and 4) a\nself-referential scheme for learning with multiple predictors, all of which\nmight be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 07:36:38 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:31:50 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Luo", "Haipeng", ""], ["Agarwal", "Alekh", ""]]}, {"id": "2003.01926", "submitter": "Chandan Singh", "authors": "Chandan Singh, Wooseok Ha, Francois Lanusse, Vanessa Boehm, Jia Liu,\n  Bin Yu", "title": "Transformation Importance with Applications to Cosmology", "comments": "Published in ICLR 2020 Workshop on Fundamental Science in the era of\n  AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning lies at the heart of new possibilities for scientific\ndiscovery, knowledge generation, and artificial intelligence. Its potential\nbenefits to these fields requires going beyond predictive accuracy and focusing\non interpretability. In particular, many scientific problems require\ninterpretations in a domain-specific interpretable feature space (e.g. the\nfrequency domain) whereas attributions to the raw features (e.g. the pixel\nspace) may be unintelligible or even misleading. To address this challenge, we\npropose TRIM (TRansformation IMportance), a novel approach which attributes\nimportances to features in a transformed space and can be applied post-hoc to a\nfully trained model. TRIM is motivated by a cosmological parameter estimation\nproblem using deep neural networks (DNNs) on simulated data, but it is\ngenerally applicable across domains/models and can be combined with any local\ninterpretation method. In our cosmology example, combining TRIM with contextual\ndecomposition shows promising results for identifying which frequencies a DNN\nuses, helping cosmologists to understand and validate that the model learns\nappropriate physical features rather than simulation artifacts.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 07:50:49 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 17:28:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Singh", "Chandan", ""], ["Ha", "Wooseok", ""], ["Lanusse", "Francois", ""], ["Boehm", "Vanessa", ""], ["Liu", "Jia", ""], ["Yu", "Bin", ""]]}, {"id": "2003.01927", "submitter": "Yonghyun Jeong Mr", "authors": "Yonghyun Jeong, Hyunjin Choi, Byoungjip Kim, Youngjune Gwon", "title": "DefogGAN: Predicting Hidden Information in the StarCraft Fog of War with\n  Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DefogGAN, a generative approach to the problem of inferring state\ninformation hidden in the fog of war for real-time strategy (RTS) games. Given\na partially observed state, DefogGAN generates defogged images of a game as\npredictive information. Such information can lead to create a strategic agent\nfor the game. DefogGAN is a conditional GAN variant featuring pyramidal\nreconstruction loss to optimize on multiple feature resolution scales.We have\nvalidated DefogGAN empirically using a large dataset of professional StarCraft\nreplays. Our results indicate that DefogGAN can predict the enemy buildings and\ncombat units as accurately as professional players do and achieves a superior\nperformance among state-of-the-art defoggers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 07:52:11 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 04:24:40 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Jeong", "Yonghyun", ""], ["Choi", "Hyunjin", ""], ["Kim", "Byoungjip", ""], ["Gwon", "Youngjune", ""]]}, {"id": "2003.01941", "submitter": "Chenlin Meng", "authors": "Chenlin Meng, Yang Song, Jiaming Song and Stefano Ermon", "title": "Gaussianization Flows", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative Gaussianization is a fixed-point iteration procedure that can\ntransform any continuous random vector into a Gaussian one. Based on iterative\nGaussianization, we propose a new type of normalizing flow model that enables\nboth efficient computation of likelihoods and efficient inversion for sample\ngeneration. We demonstrate that these models, named Gaussianization flows, are\nuniversal approximators for continuous probability distributions under some\nregularity conditions. Because of this guaranteed expressivity, they can\ncapture multimodal target distributions without compromising the efficiency of\nsample generation. Experimentally, we show that Gaussianization flows achieve\nbetter or comparable performance on several tabular datasets compared to other\nefficiently invertible flow models such as Real NVP, Glow and FFJORD. In\nparticular, Gaussianization flows are easier to initialize, demonstrate better\nrobustness with respect to different transformations of the training data, and\ngeneralize better on small training sets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 08:15:06 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Meng", "Chenlin", ""], ["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "2003.01951", "submitter": "Felix Abramovich", "authors": "Felix Abramovich, Vadim Grinshtein and Tomer Levy", "title": "Multiclass classification by sparse multinomial logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider high-dimensional multiclass classification by\nsparse multinomial logistic regression. We propose first a feature selection\nprocedure based on penalized maximum likelihood with a complexity penalty on\nthe model size and derive the nonasymptotic bounds for misclassification excess\nrisk of the resulting classifier. We establish also their tightness by deriving\nthe corresponding minimax lower bounds. In particular, we show that there exist\ntwo regimes corresponding to small and large number of classes. The bounds can\nbe reduced under the additional low noise condition. To find a penalized\nmaximum likelihood solution with a complexity penalty requires, however, a\ncombinatorial search over all possible models. To design a feature selection\nprocedure computationally feasible for high-dimensional data, we propose\nmultinomial logistic group Lasso and Slope classifiers and show that they also\nachieve the minimax order.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 08:44:48 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 09:53:00 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 11:35:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Abramovich", "Felix", ""], ["Grinshtein", "Vadim", ""], ["Levy", "Tomer", ""]]}, {"id": "2003.01971", "submitter": "Ilija Bogunovic", "authors": "Ilija Bogunovic, Andreas Krause, Jonathan Scarlett", "title": "Corruption-Tolerant Gaussian Process Bandit Optimization", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing an unknown (typically non-convex)\nfunction with a bounded norm in some Reproducing Kernel Hilbert Space (RKHS),\nbased on noisy bandit feedback. We consider a novel variant of this problem in\nwhich the point evaluations are not only corrupted by random noise, but also\nadversarial corruptions. We introduce an algorithm Fast-Slow GP-UCB based on\nGaussian process methods, randomized selection between two instances labeled\n\"fast\" (but non-robust) and \"slow\" (but robust), enlarged confidence bounds,\nand the principle of optimism under uncertainty. We present a novel theoretical\nanalysis upper bounding the cumulative regret in terms of the corruption level,\nthe time horizon, and the underlying kernel, and we argue that certain\ndependencies cannot be improved. We observe that distinct algorithmic ideas are\nrequired depending on whether one is required to perform well in both the\ncorrupted and non-corrupted settings, and whether the corruption level is known\nor not.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 09:46:58 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Bogunovic", "Ilija", ""], ["Krause", "Andreas", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2003.01972", "submitter": "Victor Berger", "authors": "Michele Sebag (LRI), Victor Berger (TAU), Mich\\`ele Sebag (LRI)", "title": "Variational Auto-Encoder: not all failures are equal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We claim that a source of severe failures for Variational Auto-Encoders is\nthe choice of the distribution class used for the observation model.A first\ntheoretical and experimental contribution of the paper is to establish that\neven in the large sample limit with arbitrarily powerful neural architectures\nand latent space, the VAE failsif the sharpness of the distribution class does\nnot match the scale of the data.Our second claim is that the distribution\nsharpness must preferably be learned by the VAE (as opposed to, fixed and\noptimized offline): Autonomously adjusting this sharpness allows the VAE to\ndynamically control the trade-off between the optimization of the\nreconstruction loss and the latent compression. A second empirical contribution\nis to show how the control of this trade-off is instrumental in escaping poor\nlocal optima, akin a simulated annealing schedule.Both claims are backed upon\nexperiments on artificial data, MNIST and CelebA, showing how sharpness\nlearning addresses the notorious VAE blurriness issue.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 09:48:02 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Sebag", "Michele", "", "LRI"], ["Berger", "Victor", "", "TAU"], ["Sebag", "Mich\u00e8le", "", "LRI"]]}, {"id": "2003.01993", "submitter": "Igor Buzhinsky", "authors": "Igor Buzhinsky, Arseny Nerinovsky, Stavros Tripakis", "title": "Metrics and methods for robustness evaluation of neural networks with\n  generative models", "comments": "24 pages, 9 figures; data in Table 3 and Fig. 3 corrected (results\n  unchanged), several typos fixed, references updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that modern deep neural network classifiers are\neasy to fool, assuming that an adversary is able to slightly modify their\ninputs. Many papers have proposed adversarial attacks, defenses and methods to\nmeasure robustness to such adversarial perturbations. However, most commonly\nconsidered adversarial examples are based on $\\ell_p$-bounded perturbations in\nthe input space of the neural network, which are unlikely to arise naturally.\nRecently, especially in computer vision, researchers discovered \"natural\" or\n\"semantic\" perturbations, such as rotations, changes of brightness, or more\nhigh-level changes, but these perturbations have not yet been systematically\nutilized to measure the performance of classifiers. In this paper, we propose\nseveral metrics to measure robustness of classifiers to natural adversarial\nexamples, and methods to evaluate them. These metrics, called latent space\nperformance metrics, are based on the ability of generative models to capture\nprobability distributions, and are defined in their latent spaces. On three\nimage classification case studies, we evaluate the proposed metrics for several\nclassifiers, including ones trained in conventional and robust ways. We find\nthat the latent counterparts of adversarial robustness are associated with the\naccuracy of the classifier rather than its conventional adversarial robustness,\nbut the latter is still reflected on the properties of found latent\nperturbations. In addition, our novel method of finding latent adversarial\nperturbations demonstrates that these perturbations are often perceptually\nsmall.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 10:58:59 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 15:55:23 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Buzhinsky", "Igor", ""], ["Nerinovsky", "Arseny", ""], ["Tripakis", "Stavros", ""]]}, {"id": "2003.01998", "submitter": "Victor Garcia Satorras", "authors": "Victor Garcia Satorras, Max Welling", "title": "Neural Enhanced Belief Propagation on Factor Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graphical model is a structured representation of locally dependent random\nvariables. A traditional method to reason over these random variables is to\nperform inference using belief propagation. When provided with the true data\ngenerating process, belief propagation can infer the optimal posterior\nprobability estimates in tree structured factor graphs. However, in many cases\nwe may only have access to a poor approximation of the data generating process,\nor we may face loops in the factor graph, leading to suboptimal estimates. In\nthis work we first extend graph neural networks to factor graphs (FG-GNN). We\nthen propose a new hybrid model that runs conjointly a FG-GNN with belief\npropagation. The FG-GNN receives as input messages from belief propagation at\nevery inference iteration and outputs a corrected version of them. As a result,\nwe obtain a more accurate algorithm that combines the benefits of both belief\npropagation and graph neural networks. We apply our ideas to error correction\ndecoding tasks, and we show that our algorithm can outperform belief\npropagation for LDPC codes on bursty channels.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 11:03:07 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 09:09:48 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 11:20:00 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2020 10:18:41 GMT"}, {"version": "v5", "created": "Tue, 16 Mar 2021 14:51:58 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Satorras", "Victor Garcia", ""], ["Welling", "Max", ""]]}, {"id": "2003.02035", "submitter": "Yuri F. Saporito", "authors": "Yuri F. Saporito and Zhaoyu Zhang", "title": "PDGM: a Neural Network Approach to Solve Path-Dependent Partial\n  Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel numerical method for Path-Dependent Partial\nDifferential Equations (PPDEs). These equations firstly appeared in the seminal\nwork of Dupire [2009], where the functional It\\^o calculus was developed to\ndeal with path-dependent financial derivatives contracts. More specificaly, we\ngeneralize the Deep Galerking Method (DGM) of Sirignano and Spiliopoulos [2018]\nto deal with these equations. The method, which we call Path-Dependent DGM\n(PDGM), consists of using a combination of feed-forward and Long Short-Term\nMemory architectures to model the solution of the PPDE. We then analyze several\nnumerical examples, many from the Financial Mathematics literature, that show\nthe capabilities of the method under very different situations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 12:26:54 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 19:18:44 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Saporito", "Yuri F.", ""], ["Zhang", "Zhaoyu", ""]]}, {"id": "2003.02037", "submitter": "Joost van Amersfoort", "authors": "Joost van Amersfoort, Lewis Smith, Yee Whye Teh, Yarin Gal", "title": "Uncertainty Estimation Using a Single Deep Deterministic Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for training a deterministic deep model that can find and\nreject out of distribution data points at test time with a single forward pass.\nOur approach, deterministic uncertainty quantification (DUQ), builds upon ideas\nof RBF networks. We scale training in these with a novel loss function and\ncentroid updating scheme and match the accuracy of softmax models. By enforcing\ndetectability of changes in the input using a gradient penalty, we are able to\nreliably detect out of distribution data. Our uncertainty quantification scales\nwell to large datasets, and using a single model, we improve upon or match Deep\nEnsembles in out of distribution detection on notable difficult dataset pairs\nsuch as FashionMNIST vs. MNIST, and CIFAR-10 vs. SVHN.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 12:27:36 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 16:04:35 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["van Amersfoort", "Joost", ""], ["Smith", "Lewis", ""], ["Teh", "Yee Whye", ""], ["Gal", "Yarin", ""]]}, {"id": "2003.02038", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Jianyong Sun and Zongben Xu", "title": "On Hyper-parameter Tuning for Stochastic Optimization Algorithms", "comments": "Our explanation of reinforcement learning for adjustment algorithm is\n  far fetched in Section ?B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first-ever algorithmic framework for tuning\nhyper-parameters of stochastic optimization algorithm based on reinforcement\nlearning. Hyper-parameters impose significant influences on the performance of\nstochastic optimization algorithms, such as evolutionary algorithms (EAs) and\nmeta-heuristics. Yet, it is very time-consuming to determine optimal\nhyper-parameters due to the stochastic nature of these algorithms. We propose\nto model the tuning procedure as a Markov decision process, and resort the\npolicy gradient algorithm to tune the hyper-parameters. Experiments on tuning\nstochastic algorithms with different kinds of hyper-parameters (continuous and\ndiscrete) for different optimization problems (continuous and discrete) show\nthat the proposed hyper-parameter tuning algorithms do not require much less\nrunning times of the stochastic algorithms than bayesian optimization method.\nThe proposed framework can be used as a standard tool for hyper-parameter\ntuning in stochastic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 12:29:12 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:32:23 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Haotian", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2003.02106", "submitter": "Markus Loecher", "authors": "Markus Loecher", "title": "Unbiased variable importance for random forests", "comments": null, "journal-ref": null, "doi": "10.1080/03610926.2020.1764042", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The default variable-importance measure in random Forests, Gini importance,\nhas been shown to suffer from the bias of the underlying Gini-gain splitting\ncriterion. While the alternative permutation importance is generally accepted\nas a reliable measure of variable importance, it is also computationally\ndemanding and suffers from other shortcomings. We propose a simple solution to\nthe misleading/untrustworthy Gini importance which can be viewed as an\noverfitting problem: we compute the loss reduction on the out-of-bag instead of\nthe in-bag training samples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 14:40:31 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 07:47:01 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Loecher", "Markus", ""]]}, {"id": "2003.02122", "submitter": "Liudmila Ostroumova Prokhorenkova", "authors": "Aleksei Ustimenko, Liudmila Prokhorenkova", "title": "StochasticRank: Global Optimization of Scale-Free Discrete Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a powerful and efficient framework for direct\noptimization of ranking metrics. The problem is ill-posed due to the discrete\nstructure of the loss, and to deal with that, we introduce two important\ntechniques: stochastic smoothing and novel gradient estimate based on partial\nintegration. We show that classic smoothing approaches may introduce bias and\npresent a universal solution for a proper debiasing. Importantly, we can\nguarantee global convergence of our method by adopting a recently proposed\nStochastic Gradient Langevin Boosting algorithm. Our algorithm is implemented\nas a part of the CatBoost gradient boosting library and outperforms the\nexisting approaches on several learning-to-rank datasets. In addition to\nranking metrics, our framework applies to any scale-free discrete loss\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:27:11 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 08:32:24 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Ustimenko", "Aleksei", ""], ["Prokhorenkova", "Liudmila", ""]]}, {"id": "2003.02133", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Han Yu, Qiang Yang", "title": "Threats to Federated Learning: A Survey", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of data silos and popular privacy awareness, the\ntraditional centralized approach of training artificial intelligence (AI)\nmodels is facing strong challenges. Federated learning (FL) has recently\nemerged as a promising solution under this new reality. Existing FL protocol\ndesign has been shown to exhibit vulnerabilities which can be exploited by\nadversaries both within and without the system to compromise data privacy. It\nis thus of paramount importance to make FL system designers to be aware of the\nimplications of future FL algorithm design on privacy-preservation. Currently,\nthere is no survey on this topic. In this paper, we bridge this important gap\nin FL literature. By providing a concise introduction to the concept of FL, and\na unique taxonomy covering threat models and two major attacks on FL: 1)\npoisoning attacks and 2) inference attacks, this paper provides an accessible\nreview of this important topic. We highlight the intuitions, key techniques as\nwell as fundamental assumptions adopted by various attacks, and discuss\npromising future research directions towards more robust privacy preservation\nin FL.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:30:10 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Han", ""], ["Yang", "Qiang", ""]]}, {"id": "2003.02139", "submitter": "Andrew Wilson", "authors": "Wesley J. Maddox, Gregory Benton, Andrew Gordon Wilson", "title": "Rethinking Parameter Counting in Deep Models: Effective Dimensionality\n  Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks appear to have mysterious generalization properties when\nusing parameter counting as a proxy for complexity. Indeed, neural networks\noften have many more parameters than there are data points, yet still provide\ngood generalization performance. Moreover, when we measure generalization as a\nfunction of parameters, we see double descent behaviour, where the test error\ndecreases, increases, and then again decreases. We show that many of these\nproperties become understandable when viewed through the lens of effective\ndimensionality, which measures the dimensionality of the parameter space\ndetermined by the data. We relate effective dimensionality to posterior\ncontraction in Bayesian deep learning, model selection, width-depth tradeoffs,\ndouble descent, and functional diversity in loss surfaces, leading to a richer\nunderstanding of the interplay between parameters and functions in deep models.\nWe also show that effective dimensionality compares favourably to alternative\nnorm- and flatness- based generalization measures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:39:27 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:43:35 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Maddox", "Wesley J.", ""], ["Benton", "Gregory", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2003.02149", "submitter": "Jarek Duda Dr", "authors": "Jarek Duda", "title": "Adaptive exponential power distribution with moving estimator for\n  nonstationary time series", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While standard estimation assumes that all datapoints are from probability\ndistribution of the same fixed parameters $\\theta$, we will focus on maximum\nlikelihood (ML) adaptive estimation for nonstationary time series: separately\nestimating parameters $\\theta_T$ for each time $T$ based on the earlier values\n$(x_t)_{t<T}$ using (exponential) moving ML estimator $\\theta_T=\\arg\\max_\\theta\nl_T$ for $l_T=\\sum_{t<T} \\eta^{T-t} \\ln(\\rho_\\theta (x_t))$ and some\n$\\eta\\in(0,1]$. Computational cost of such moving estimator is generally much\nhigher as we need to optimize log-likelihood multiple times, however, in many\ncases it can be made inexpensive thanks to dependencies. We focus on such\nexample: $\\rho(x)\\propto \\exp(-|(x-\\mu)/\\sigma|^\\kappa/\\kappa)$ exponential\npower distribution (EPD) family, which covers wide range of tail behavior like\nGaussian ($\\kappa=2$) or Laplace ($\\kappa=1$) distribution. It is also\nconvenient for such adaptive estimation of scale parameter $\\sigma$ as its\nstandard ML estimation is $\\sigma^\\kappa$ being average $\\|x-\\mu\\|^\\kappa$. By\njust replacing average with exponential moving average:\n$(\\sigma_{T+1})^\\kappa=\\eta(\\sigma_T)^\\kappa +(1-\\eta)|x_T-\\mu|^\\kappa$ we can\ninexpensively make it adaptive. It is tested on daily log-return series for\nDJIA companies, leading to essentially better log-likelihoods than standard\n(static) estimation, with optimal $\\kappa$ tails types varying between\ncompanies. Presented general alternative estimation philosophy provides tools\nwhich might be useful for building better models for analysis of nonstationary\ntime-series.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:56:44 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 16:26:16 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "2003.02157", "submitter": "Md. Shirajum Munir", "authors": "Md. Shirajum Munir, Sarder Fakhrul Abedin, Nguyen H. Tran, Zhu Han,\n  Eui-Nam Huh, Choong Seon Hong", "title": "Risk-Aware Energy Scheduling for Edge Computing with Microgrid: A\n  Multi-Agent Deep Reinforcement Learning Approach", "comments": "Accepted Article BY IEEE Transactions on Network and Service\n  Management, DOI: 10.1109/TNSM.2021.3049381", "journal-ref": null, "doi": "10.1109/TNSM.2021.3049381", "report-no": null, "categories": "physics.soc-ph cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, multi-access edge computing (MEC) is a key enabler for\nhandling the massive expansion of Internet of Things (IoT) applications and\nservices. However, energy consumption of a MEC network depends on volatile\ntasks that induces risk for energy demand estimations. As an energy supplier, a\nmicrogrid can facilitate seamless energy supply. However, the risk associated\nwith energy supply is also increased due to unpredictable energy generation\nfrom renewable and non-renewable sources. Especially, the risk of energy\nshortfall is involved with uncertainties in both energy consumption and\ngeneration. In this paper, we study a risk-aware energy scheduling problem for\na microgrid-powered MEC network. First, we formulate an optimization problem\nconsidering the conditional value-at-risk (CVaR) measurement for both energy\nconsumption and generation, where the objective is to minimize the expected\nresidual of scheduled energy for the MEC networks and we show this problem is\nan NP-hard problem. Second, we analyze our formulated problem using a\nmulti-agent stochastic game that ensures the joint policy Nash equilibrium, and\nshow the convergence of the proposed model. Third, we derive the solution by\napplying a multi-agent deep reinforcement learning (MADRL)-based asynchronous\nadvantage actor-critic (A3C) algorithm with shared neural networks. This method\nmitigates the curse of dimensionality of the state space and chooses the best\npolicy among the agents for the proposed problem. Finally, the experimental\nresults establish a significant performance gain by considering CVaR for high\naccuracy energy scheduling of the proposed model than both the single and\nrandom agent models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:14:38 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 04:17:04 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 02:51:28 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Munir", "Md. Shirajum", ""], ["Abedin", "Sarder Fakhrul", ""], ["Tran", "Nguyen H.", ""], ["Han", "Zhu", ""], ["Huh", "Eui-Nam", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.02174", "submitter": "Daniil Polykovskiy", "authors": "Daniil Polykovskiy and Dmitry Vetrov", "title": "Deterministic Decoding for Discrete Data in Variational Autoencoders", "comments": "AISTATS 2020; GitHub: https://github.com/insilicomedicine/DD-VAE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders are prominent generative models for modeling\ndiscrete data. However, with flexible decoders, they tend to ignore the latent\ncodes. In this paper, we study a VAE model with a deterministic decoder\n(DD-VAE) for sequential data that selects the highest-scoring tokens instead of\nsampling. Deterministic decoding solely relies on latent codes as the only way\nto produce diverse objects, which improves the structure of the learned\nmanifold. To implement DD-VAE, we propose a new class of bounded support\nproposal distributions and derive Kullback-Leibler divergence for Gaussian and\nuniform priors. We also study a continuous relaxation of deterministic decoding\nobjective function and analyze the relation of reconstruction accuracy and\nrelaxation parameters. We demonstrate the performance of DD-VAE on multiple\ndatasets, including molecular generation and optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 16:36:52 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Polykovskiy", "Daniil", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2003.02188", "submitter": "Evgenii Zheltonozhskii", "authors": "Evgenii Zheltonozhskii, Chaim Baskin, Yaniv Nemcovsky, Brian Chmiel,\n  Avi Mendelson, Alex M. Bronstein", "title": "Colored Noise Injection for Training Adversarially Robust Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Even though deep learning has shown unmatched performance on various tasks,\nneural networks have been shown to be vulnerable to small adversarial\nperturbations of the input that lead to significant performance degradation. In\nthis work we extend the idea of adding white Gaussian noise to the network\nweights and activations during adversarial training (PNI) to the injection of\ncolored noise for defense against common white-box and black-box attacks. We\nshow that our approach outperforms PNI and various previous approaches in terms\nof adversarial accuracy on CIFAR-10 and CIFAR-100 datasets. In addition, we\nprovide an extensive ablation study of the proposed method justifying the\nchosen configurations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:01:54 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 12:21:56 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zheltonozhskii", "Evgenii", ""], ["Baskin", "Chaim", ""], ["Nemcovsky", "Yaniv", ""], ["Chmiel", "Brian", ""], ["Mendelson", "Avi", ""], ["Bronstein", "Alex M.", ""]]}, {"id": "2003.02189", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni and Shie Mannor and Matteo Pirotta", "title": "Exploration-Exploitation in Constrained MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequential decision-making problems, the goal is to optimize a\nutility function while satisfying a set of constraints on different utilities.\nThis learning problem is formalized through Constrained Markov Decision\nProcesses (CMDPs). In this paper, we investigate the exploration-exploitation\ndilemma in CMDPs. While learning in an unknown CMDP, an agent should trade-off\nexploration to discover new information about the MDP, and exploitation of the\ncurrent knowledge to maximize the reward while satisfying the constraints.\nWhile the agent will eventually learn a good or optimal policy, we do not want\nthe agent to violate the constraints too often during the learning process. In\nthis work, we analyze two approaches for learning in CMDPs. The first approach\nleverages the linear formulation of CMDP to perform optimistic planning at each\nepisode. The second approach leverages the dual formulation (or saddle-point\nformulation) of CMDP to perform incremental, optimistic updates of the primal\nand dual variables. We show that both achieves sublinear regret w.r.t.\\ the\nmain utility while having a sublinear regret on the constraint violations. That\nbeing said, we highlight a crucial difference between the two approaches; the\nlinear programming approach results in stronger guarantees than in the dual\nformulation based approach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:03:56 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Efroni", "Yonathan", ""], ["Mannor", "Shie", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2003.02205", "submitter": "Marco Broccardo", "authors": "Ziqi Wang, Marco Broccardo, Junho Song", "title": "Probabilistic Performance-Pattern Decomposition (PPPD): analysis\n  framework and applications to stochastic mechanical systems", "comments": "Autoencoder, clustering, diffusion map, manifold learning, Monte\n  Carlo simulation, pattern recognition, stochastic dynamics, uncertainty\n  quantification. 44 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the early 1900s, numerous research efforts have been devoted to\ndeveloping quantitative solutions to stochastic mechanical systems. In general,\nthe problem is perceived as solved when a complete or partial probabilistic\ndescription on the quantity of interest (QoI) is determined. However, in the\npresence of complex system behavior, there is a critical need to go beyond mere\nprobabilistic descriptions. In fact, to gain a full understanding of the\nsystem, it is crucial to extract physical characterizations from the\nprobabilistic structure of the QoI, especially when the QoI solution is\nobtained in a data-driven fashion. Motivated by this perspective, the paper\nproposes a framework to obtain structuralized characterizations on behaviors of\nstochastic systems. The framework is named Probabilistic Performance-Pattern\nDecomposition (PPPD). PPPD analysis aims to decompose complex response\nbehaviors, conditional to a prescribed performance state, into meaningful\npatterns in the space of system responses, and to investigate how the patterns\nare triggered in the space of basic random variables. To illustrate the\napplication of PPPD, the paper studies three numerical examples: 1) an\nillustrative example with hypothetical stochastic processes input and output;\n2) a stochastic Lorenz system with periodic as well as chaotic behaviors; and\n3) a simplified shear-building model subjected to a stochastic ground motion\nexcitation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:18:43 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Wang", "Ziqi", ""], ["Broccardo", "Marco", ""], ["Song", "Junho", ""]]}, {"id": "2003.02214", "submitter": "Hamid Mousavi", "authors": "S. Hamid Mousavi, Jakob Drefs, Florian Hirschberger, J\\\"org L\\\"ucke", "title": "Maximal Causes for Exponential Family Observables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models represent observed variables as parameterized\nfunctions of a set of latent variables. Examples are factor analysis or\nprobabilistic sparse coding which assume weighted linear summations to\ndetermine the mean of Gaussian distribution for the observables. However, in\nmany cases observables do not follow a normal distribution, and a linear\nsummation of latents is often at odds with non-Gaussian observables (e.g.,\nmeans of the Bernoulli distribution have to lie in the unit interval).\nFurthermore, the assumption of a linear summation model may (for many types of\ndata) not be closely aligned with the true data generation process even for\nGaussian observables. Alternative superposition models (i.e., alternative links\nbetween latents and observables) have therefore been investigated repeatedly.\nHere we show that using the maximization instead of summation to link latents\nto observables allows for the derivation of a very general and concise set of\nparameter update equations. Concretely, we derive a set of update equations\nthat has the same functional form for all distributions of the exponential\nfamily. Our results consequently provide directly applicable learning equations\nfor commonly as well as for unusually distributed data. We numerically verify\nour analytical results assuming standard Gaussian, Gamma, Poisson, Bernoulli\nand Exponential distributions. We point to some potential applications by\nproviding different experiments on the learning of variance structure, noise\ntype estimation, and denoising.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:36:00 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 14:39:57 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mousavi", "S. Hamid", ""], ["Drefs", "Jakob", ""], ["Hirschberger", "Florian", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "2003.02218", "submitter": "Aitor Lewkowycz", "authors": "Aitor Lewkowycz, Yasaman Bahri, Ethan Dyer, Jascha Sohl-Dickstein, Guy\n  Gur-Ari", "title": "The large learning rate phase of deep learning: the catapult mechanism", "comments": "25 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of initial learning rate can have a profound effect on the\nperformance of deep networks. We present a class of neural networks with\nsolvable training dynamics, and confirm their predictions empirically in\npractical deep learning settings. The networks exhibit sharply distinct\nbehaviors at small and large learning rates. The two regimes are separated by a\nphase transition. In the small learning rate phase, training can be understood\nusing the existing theory of infinitely wide neural networks. At large learning\nrates the model captures qualitatively distinct phenomena, including the\nconvergence of gradient descent dynamics to flatter minima. One key prediction\nof our model is a narrow range of large, stable learning rates. We find good\nagreement between our model's predictions and training dynamics in realistic\ndeep learning settings. Furthermore, we find that the optimal performance in\nsuch settings is often found in the large learning rate phase. We believe our\nresults shed light on characteristics of models trained at different learning\nrates. In particular, they fill a gap between existing wide neural network\ntheory, and the nonlinear, large learning rate, training dynamics relevant to\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:52:48 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Lewkowycz", "Aitor", ""], ["Bahri", "Yasaman", ""], ["Dyer", "Ethan", ""], ["Sohl-Dickstein", "Jascha", ""], ["Gur-Ari", "Guy", ""]]}, {"id": "2003.02228", "submitter": "Julian Busch", "authors": "Julian Busch, Jiaxing Pi, Thomas Seidl", "title": "PushNet: Efficient and Adaptive Neural Message Passing", "comments": null, "journal-ref": "24th European Conference on Artificial Intelligence (ECAI 2020)", "doi": "10.3233/FAIA200199", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing neural networks have recently evolved into a state-of-the-art\napproach to representation learning on graphs. Existing methods perform\nsynchronous message passing along all edges in multiple subsequent rounds and\nconsequently suffer from various shortcomings: Propagation schemes are\ninflexible since they are restricted to $k$-hop neighborhoods and insensitive\nto actual demands of information propagation. Further, long-range dependencies\ncannot be modeled adequately and learned representations are based on\ncorrelations of fixed locality. These issues prevent existing methods from\nreaching their full potential in terms of prediction performance. Instead, we\nconsider a novel asynchronous message passing approach where information is\npushed only along the most relevant edges until convergence. Our proposed\nalgorithm can equivalently be formulated as a single synchronous message\npassing iteration using a suitable neighborhood function, thus sharing the\nadvantages of existing methods while addressing their central issues. The\nresulting neural network utilizes a node-adaptive receptive field derived from\nmeaningful sparse node neighborhoods. In addition, by learning and combining\nnode representations over differently sized neighborhoods, our model is able to\ncapture correlations on multiple scales. We further propose variants of our\nbase model with different inductive bias. Empirical results are provided for\nsemi-supervised node classification on five real-world datasets following a\nrigorous evaluation protocol. We find that our models outperform competitors on\nall datasets in terms of accuracy with statistical significance. In some cases,\nour models additionally provide faster runtime.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:15:30 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 05:36:52 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 17:13:07 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 00:20:05 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Busch", "Julian", ""], ["Pi", "Jiaxing", ""], ["Seidl", "Thomas", ""]]}, {"id": "2003.02234", "submitter": "Christopher Tosh", "authors": "Christopher Tosh and Akshay Krishnamurthy and Daniel Hsu", "title": "Contrastive estimation reveals topic posterior information to linear\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning is an approach to representation learning that utilizes\nnaturally occurring similar and dissimilar pairs of data points to find useful\nembeddings of data. In the context of document classification under topic\nmodeling assumptions, we prove that contrastive learning is capable of\nrecovering a representation of documents that reveals their underlying topic\nposterior information to linear models. We apply this procedure in a\nsemi-supervised setup and demonstrate empirically that linear classifiers with\nthese representations perform well in document classification tasks with very\nfew training examples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:20:55 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Tosh", "Christopher", ""], ["Krishnamurthy", "Akshay", ""], ["Hsu", "Daniel", ""]]}, {"id": "2003.02237", "submitter": "Vaishaal Shankar", "authors": "Vaishaal Shankar, Alex Fang, Wenshuo Guo, Sara Fridovich-Keil, Ludwig\n  Schmidt, Jonathan Ragan-Kelley, Benjamin Recht", "title": "Neural Kernels Without Tangents", "comments": "code used to produce our results can be found at:\n  https://github.com/modestyachts/neural_kernels_code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the connections between neural networks and simple building\nblocks in kernel space. In particular, using well established feature space\ntools such as direct sum, averaging, and moment lifting, we present an algebra\nfor creating \"compositional\" kernels from bags of features. We show that these\noperations correspond to many of the building blocks of \"neural tangent kernels\n(NTK)\". Experimentally, we show that there is a correlation in test error\nbetween neural network architectures and the associated kernels. We construct a\nsimple neural network architecture using only 3x3 convolutions, 2x2 average\npooling, ReLU, and optimized with SGD and MSE loss that achieves 96% accuracy\non CIFAR10, and whose corresponding compositional kernel achieves 90% accuracy.\nWe also use our constructions to investigate the relative performance of neural\nnetworks, NTKs, and compositional kernels in the small dataset regime. In\nparticular, we find that compositional kernels outperform NTKs and neural\nnetworks outperform both kernel methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:25:41 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 18:46:30 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Shankar", "Vaishaal", ""], ["Fang", "Alex", ""], ["Guo", "Wenshuo", ""], ["Fridovich-Keil", "Sara", ""], ["Schmidt", "Ludwig", ""], ["Ragan-Kelley", "Jonathan", ""], ["Recht", "Benjamin", ""]]}, {"id": "2003.02261", "submitter": "Borys Tymchenko", "authors": "Borys Tymchenko, Philip Marchenko and Dmitry Spodarets", "title": "Deep Learning Approach to Diabetic Retinopathy Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Diabetic retinopathy is one of the most threatening complications of diabetes\nthat leads to permanent blindness if left untreated. One of the essential\nchallenges is early detection, which is very important for treatment success.\nUnfortunately, the exact identification of the diabetic retinopathy stage is\nnotoriously tricky and requires expert human interpretation of fundus images.\nSimplification of the detection step is crucial and can help millions of\npeople. Convolutional neural networks (CNN) have been successfully applied in\nmany adjacent subjects, and for diagnosis of diabetic retinopathy itself.\nHowever, the high cost of big labeled datasets, as well as inconsistency\nbetween different doctors, impede the performance of these methods. In this\npaper, we propose an automatic deep-learning-based method for stage detection\nof diabetic retinopathy by single photography of the human fundus.\nAdditionally, we propose the multistage approach to transfer learning, which\nmakes use of similar datasets with different labeling. The presented method can\nbe used as a screening method for early detection of diabetic retinopathy with\nsensitivity and specificity of 0.99 and is ranked 54 of 2943 competing methods\n(quadratic weighted kappa score of 0.925466) on APTOS 2019 Blindness Detection\nDataset (13000 images).\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:17:46 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Tymchenko", "Borys", ""], ["Marchenko", "Philip", ""], ["Spodarets", "Dmitry", ""]]}, {"id": "2003.02287", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Vahab Mirrokni, Renato Paes Leme", "title": "Bandits with adversarial scaling", "comments": "Appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study \"adversarial scaling\", a multi-armed bandit model where rewards have\na stochastic and an adversarial component. Our model captures display\nadvertising where the \"click-through-rate\" can be decomposed to a (fixed across\ntime) arm-quality component and a non-stochastic user-relevance component\n(fixed across arms). Despite the relative stochasticity of our model, we\ndemonstrate two settings where most bandit algorithms suffer. On the positive\nside, we show that two algorithms, one from the action elimination and one from\nthe mirror descent family are adaptive enough to be robust to adversarial\nscaling. Our results shed light on the robustness of adaptive parameter\nselection in stochastic bandits, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 19:03:23 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 03:07:22 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Mirrokni", "Vahab", ""], ["Leme", "Renato Paes", ""]]}, {"id": "2003.02306", "submitter": "Marcos Eduardo Valle", "authors": "Marcos Eduardo Valle", "title": "Reduced Dilation-Erosion Perceptron for Binary Classification", "comments": null, "journal-ref": "Mathematics 2020, 8, 512", "doi": "10.3390/math8040512", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dilation and erosion are two elementary operations from mathematical\nmorphology, a non-linear lattice computing methodology widely used for image\nprocessing and analysis. The dilation-erosion perceptron (DEP) is a\nmorphological neural network obtained by a convex combination of a dilation and\nan erosion followed by the application of a hard-limiter function for binary\nclassification tasks. A DEP classifier can be trained using a convex-concave\nprocedure along with the minimization of the hinge loss function. As a lattice\ncomputing model, the DEP classifier assumes the feature and class spaces are\npartially ordered sets. In many practical situations, however, there is no\nnatural ordering for the feature patterns. Using concepts from multi-valued\nmathematical morphology, this paper introduces the reduced dilation-erosion\n(r-DEP) classifier. An r-DEP classifier is obtained by endowing the feature\nspace with an appropriate reduced ordering. Such reduced ordering can be\ndetermined using two approaches: One based on an ensemble of support vector\nclassifiers (SVCs) with different kernels and the other based on a bagging of\nsimilar SVCs trained using different samples of the training set. Using several\nbinary classification datasets from the OpenML repository, the ensemble and\nbagging r-DEP classifiers yielded in mean higher balanced accuracy scores than\nthe linear, polynomial, and radial basis function (RBF) SVCs as well as their\nensemble and a bagging of RBF SVCs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 19:50:35 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 18:07:40 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Valle", "Marcos Eduardo", ""]]}, {"id": "2003.02309", "submitter": "Xiangrui Li", "authors": "Xiangrui Li, Xin Li, Deng Pan and Dongxiao Zhu", "title": "On the Learning Property of Logistic and Softmax Losses for Deep Neural\n  Networks", "comments": "AAAI2020. Previously this appeared as arXiv:1906.04026v2, which was\n  submitted as a replacement by accident", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) trained with logistic and softmax\nlosses have made significant advancement in visual recognition tasks in\ncomputer vision. When training data exhibit class imbalances, the class-wise\nreweighted version of logistic and softmax losses are often used to boost\nperformance of the unweighted version. In this paper, motivated to explain the\nreweighting mechanism, we explicate the learning property of those two loss\nfunctions by analyzing the necessary condition (e.g., gradient equals to zero)\nafter training CNNs to converge to a local minimum. The analysis immediately\nprovides us explanations for understanding (1) quantitative effects of the\nclass-wise reweighting mechanism: deterministic effectiveness for binary\nclassification using logistic loss yet indeterministic for multi-class\nclassification using softmax loss; (2) disadvantage of logistic loss for\nsingle-label multi-class classification via one-vs.-all approach, which is due\nto the averaging effect on predicted probabilities for the negative class\n(e.g., non-target classes) in the learning process. With the disadvantage and\nadvantage of logistic loss disentangled, we thereafter propose a novel\nreweighted logistic loss for multi-class classification. Our simple yet\neffective formulation improves ordinary logistic loss by focusing on learning\nhard non-target classes (target vs. non-target class in one-vs.-all) and turned\nout to be competitive with softmax loss. We evaluate our method on several\nbenchmark datasets to demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 19:58:02 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Li", "Xiangrui", ""], ["Li", "Xin", ""], ["Pan", "Deng", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "2003.02334", "submitter": "Dan Wang", "authors": "Parisa Golbayani, Dan Wang, Ionut Florescu", "title": "Application of Deep Neural Networks to assess corporate Credit Rating", "comments": "19 pages, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature implements machine learning techniques to assess corporate\ncredit rating based on financial statement reports. In this work, we analyze\nthe performance of four neural network architectures (MLP, CNN, CNN2D, LSTM) in\npredicting corporate credit rating as issued by Standard and Poor's. We analyze\ncompanies from the energy, financial and healthcare sectors in US. The goal of\nthe analysis is to improve application of machine learning algorithms to credit\nassessment. To this end, we focus on three questions. First, we investigate if\nthe algorithms perform better when using a selected subset of features, or if\nit is better to allow the algorithms to select features themselves. Second, is\nthe temporal aspect inherent in financial data important for the results\nobtained by a machine learning algorithm? Third, is there a particular neural\nnetwork architecture that consistently outperforms others with respect to input\nfeatures, sectors and holdout set? We create several case studies to answer\nthese questions and analyze the results using ANOVA and multiple comparison\ntesting procedure.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 21:29:22 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Golbayani", "Parisa", ""], ["Wang", "Dan", ""], ["Florescu", "Ionut", ""]]}, {"id": "2003.02353", "submitter": "Paul Parker", "authors": "Paul A. Parker, Scott H. Holan, Nalini Ravishanker", "title": "Nonlinear Time Series Classification Using Bispectrum-based Deep\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification using novel techniques has experienced a recent\nresurgence and growing interest from statisticians, subject-domain scientists,\nand decision makers in business and industry. This is primarily due to the ever\nincreasing amount of big and complex data produced as a result of technological\nadvances. A motivating example is that of Google trends data, which exhibit\nhighly nonlinear behavior. Although a rich literature exists for addressing\nthis problem, existing approaches mostly rely on first and second order\nproperties of the time series, since they typically assume linearity of the\nunderlying process. Often, these are inadequate for effective classification of\nnonlinear time series data such as Google Trends data. Given these\nmethodological deficiencies and the abundance of nonlinear time series that\npersist among real-world phenomena, we introduce an approach that merges higher\norder spectral analysis (HOSA) with deep convolutional neural networks (CNNs)\nfor classifying time series. The effectiveness of our approach is illustrated\nusing simulated data and two motivating industry examples that involve Google\ntrends data and electronic device energy consumption data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 22:27:52 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Parker", "Paul A.", ""], ["Holan", "Scott H.", ""], ["Ravishanker", "Nalini", ""]]}, {"id": "2003.02359", "submitter": "Nicholas Galioto", "authors": "Nicholas Galioto and Alex Gorodetsky", "title": "Bayesian System ID: Optimal management of parameter, model, and\n  measurement uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the robustness of a probabilistic formulation of system\nidentification (ID) to sparse, noisy, and indirect data. Specifically, we\ncompare estimators of future system behavior derived from the Bayesian\nposterior of a learning problem to several commonly used least squares-based\noptimization objectives used in system ID. Our comparisons indicate that the\nlog posterior has improved geometric properties compared with the objective\nfunction surfaces of traditional methods that include differentially\nconstrained least squares and least squares reconstructions of discrete time\nsteppers like dynamic mode decomposition (DMD). These properties allow it to be\nboth more sensitive to new data and less affected by multiple minima ---\noverall yielding a more robust approach. Our theoretical results indicate that\nleast squares and regularized least squares methods like dynamic mode\ndecomposition and sparse identification of nonlinear dynamics (SINDy) can be\nderived from the probabilistic formulation by assuming noiseless measurements.\nWe also analyze the computational complexity of a Gaussian filter-based\napproximate marginal Markov Chain Monte Carlo scheme that we use to obtain the\nBayesian posterior for both linear and nonlinear problems. We then empirically\ndemonstrate that obtaining the marginal posterior of the parameter dynamics and\nmaking predictions by extracting optimal estimators (e.g., mean, median, mode)\nyields orders of magnitude improvement over the aforementioned approaches. We\nattribute this performance to the fact that the Bayesian approach captures\nparameter, model, and measurement uncertainties, whereas the other methods\ntypically neglect at least one type of uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 22:48:30 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Galioto", "Nicholas", ""], ["Gorodetsky", "Alex", ""]]}, {"id": "2003.02365", "submitter": "David Berthelot", "authors": "David Berthelot, Peyman Milanfar, Ian Goodfellow", "title": "Creating High Resolution Images with a Latent Adversarial Generator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating realistic images is difficult, and many formulations for this task\nhave been proposed recently. If we restrict the task to that of generating a\nparticular class of images, however, the task becomes more tractable. That is\nto say, instead of generating an arbitrary image as a sample from the manifold\nof natural images, we propose to sample images from a particular \"subspace\" of\nnatural images, directed by a low-resolution image from the same subspace. The\nproblem we address, while close to the formulation of the single-image\nsuper-resolution problem, is in fact rather different. Single image\nsuper-resolution is the task of predicting the image closest to the ground\ntruth from a relatively low resolution image. We propose to produce samples of\nhigh resolution images given extremely small inputs with a new method called\nLatent Adversarial Generator (LAG). In our generative sampling framework, we\nonly use the input (possibly of very low-resolution) to direct what class of\nsamples the network should produce. As such, the output of our algorithm is not\na unique image that relates to the input, but rather a possible se} of related\nimages sampled from the manifold of natural images. Our method learns\nexclusively in the latent space of the adversary using perceptual loss -- it\ndoes not have a pixel loss.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 23:23:08 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Berthelot", "David", ""], ["Milanfar", "Peyman", ""], ["Goodfellow", "Ian", ""]]}, {"id": "2003.02367", "submitter": "Nick James", "authors": "Nick James and Max Menzies", "title": "Optimally adaptive Bayesian spectral density estimation for stationary\n  and nonstationary processes", "comments": "Equal contribution. Expression and structure edits relative to v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article improves on existing methods to estimate the spectral density of\nstationary and nonstationary time series assuming a Gaussian process prior. By\noptimising an appropriate eigendecomposition using a smoothing spline\ncovariance structure, our method more appropriately models both smooth and\nrough data. We further justify the utility of this optimal eigendecomposition\nby investigating the performance of alternative covariance functions other than\nsmoothing splines. We show that the optimal eigendecomposition provides a\nmaterial improvement, while the other covariance functions under examination do\nnot, all performing comparatively well as the smoothing spline. During our\ncomputational investigation, we introduce new validation metrics for the\nspectral density estimate, inspired from the physical sciences. We validate our\nmodels in an extensive simulation study and demonstrate superior performance\nwith real data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 23:35:57 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 10:00:46 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["James", "Nick", ""], ["Menzies", "Max", ""]]}, {"id": "2003.02369", "submitter": "Byung Hoon Ahn", "authors": "Byung Hoon Ahn, Jinwon Lee, Jamie Menjay Lin, Hsin-Pai Cheng, Jilei\n  Hou, Hadi Esmaeilzadeh", "title": "Ordering Chaos: Memory-Aware Scheduling of Irregularly Wired Neural\n  Networks for Edge Devices", "comments": "Published as a conference paper at MLSys 2020 (Oral Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances demonstrate that irregularly wired neural networks from\nNeural Architecture Search (NAS) and Random Wiring can not only automate the\ndesign of deep neural networks but also emit models that outperform previous\nmanual designs. These designs are especially effective while designing neural\narchitectures under hard resource constraints (memory, MACs, . . . ) which\nhighlights the importance of this class of designing neural networks. However,\nsuch a move creates complication in the previously streamlined pattern of\nexecution. In fact one of the main challenges is that the order of such nodes\nin the neural network significantly effects the memory footprint of the\nintermediate activations. Current compilers do not schedule with regard to\nactivation memory footprint that it significantly increases its peak compared\nto the optimum, rendering it not applicable for edge devices. To address this\nstanding issue, we present a memory-aware compiler, dubbed SERENITY, that\nutilizes dynamic programming to find a sequence that finds a schedule with\noptimal memory footprint. Our solution also comprises of graph rewriting\ntechnique that allows further reduction beyond the optimum. As such, SERENITY\nachieves optimal peak memory, and the graph rewriting technique further\nimproves this resulting in 1.68x improvement with dynamic programming-based\nscheduler and 1.86x with graph rewriting, against TensorFlow Lite with less\nthan one minute overhead.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 23:38:54 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ahn", "Byung Hoon", ""], ["Lee", "Jinwon", ""], ["Lin", "Jamie Menjay", ""], ["Cheng", "Hsin-Pai", ""], ["Hou", "Jilei", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2003.02386", "submitter": "Feng Jin", "authors": "Feng Jin, Arindam Sengupta, and Siyang Cao", "title": "mmFall: Fall Detection using 4D MmWave Radar and a Hybrid Variational\n  RNN AutoEncoder", "comments": "Preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose mmFall - a novel fall detection system, which\ncomprises of (i) the emerging millimeter-wave (mmWave) radar sensor to collect\nthe human body's point cloud along with the body centroid, and (ii) a\nvariational recurrent autoencoder (VRAE) to compute the anomaly level of the\nbody motion based on the acquired point cloud. A fall is claimed to have\noccurred when the spike in anomaly level and the drop in centroid height occur\nsimultaneously. The mmWave radar sensor provides several advantages, such as\nprivacycompliance and high-sensitivity to motion, over the traditional sensing\nmodalities. However, (i) randomness in radar point cloud data and (ii)\ndifficulties in fall collection/labeling in the traditional supervised fall\ndetection approaches are the two main challenges. To overcome the randomness in\nradar data, the proposed VRAE uses variational inference, a probabilistic\napproach rather than the traditional deterministic approach, to infer the\nposterior probability of the body's latent motion state at each frame, followed\nby a recurrent neural network (RNN) to learn the temporal features of the\nmotion over multiple frames. Moreover, to circumvent the difficulties in fall\ndata collection/labeling, the VRAE is built upon an autoencoder architecture in\na semi-supervised approach, and trained on only normal activities of daily\nliving (ADL) such that in the inference stage the VRAE will generate a spike in\nthe anomaly level once an abnormal motion, such as fall, occurs. During the\nexperiment, we implemented the VRAE along with two other baselines, and tested\non the dataset collected in an apartment. The receiver operating characteristic\n(ROC) curve indicates that our proposed model outperforms the other two\nbaselines, and achieves 98% detection out of 50 falls at the expense of just 2\nfalse alarms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 00:37:21 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:14:35 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2020 22:56:58 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 17:33:46 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Jin", "Feng", ""], ["Sengupta", "Arindam", ""], ["Cao", "Siyang", ""]]}, {"id": "2003.02387", "submitter": "Kailiang Wu", "authors": "Zhen Chen, Kailiang Wu, Dongbin Xiu", "title": "Methods to Recover Unknown Processes in Partial Differential Equations\n  Using Data", "comments": "21 pages, 11 figures", "journal-ref": "Journal of Scientific Computing 85, 23 (2020)", "doi": "10.1007/s10915-020-01324-8", "report-no": null, "categories": "math.NA cs.NA math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying unknown processes embedded in\ntime-dependent partial differential equation (PDE) using observational data,\nwith an application to advection-diffusion type PDE. We first conduct\ntheoretical analysis and derive conditions to ensure the solvability of the\nproblem. We then present a set of numerical approaches, including Galerkin type\nalgorithm and collocation type algorithm. Analysis of the algorithms are\npresented, along with their implementation detail. The Galerkin algorithm is\nmore suitable for practical situations, particularly those with noisy data, as\nit avoids using derivative/gradient data. Various numerical examples are then\npresented to demonstrate the performance and properties of the numerical\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 00:50:08 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chen", "Zhen", ""], ["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "2003.02389", "submitter": "Alex Renda", "authors": "Alex Renda, Jonathan Frankle, Michael Carbin", "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural network pruning algorithms proceed in three steps: train the\nnetwork to completion, remove unwanted structure to compress the network, and\nretrain the remaining structure to recover lost accuracy. The standard\nretraining technique, fine-tuning, trains the unpruned weights from their final\ntrained values using a small fixed learning rate. In this paper, we compare\nfine-tuning to alternative retraining techniques. Weight rewinding (as proposed\nby Frankle et al., (2019)), rewinds unpruned weights to their values from\nearlier in training and retrains them from there using the original training\nschedule. Learning rate rewinding (which we propose) trains the unpruned\nweights from their final values using the same learning rate schedule as weight\nrewinding. Both rewinding techniques outperform fine-tuning, forming the basis\nof a network-agnostic pruning algorithm that matches the accuracy and\ncompression ratios of several more network-specific state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 00:53:18 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Renda", "Alex", ""], ["Frankle", "Jonathan", ""], ["Carbin", "Michael", ""]]}, {"id": "2003.02395", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez, L\\'eon Bottou, Francis Bach, Nicolas Usunier", "title": "A Simple Convergence Proof of Adam and Adagrad", "comments": "24 pages, 1 figures, preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a simple proof of convergence covering both the Adam and Adagrad\nadaptive optimization algorithms when applied to smooth (possibly non-convex)\nobjective functions with bounded gradients. We show that in expectation, the\nsquared norm of the objective gradient averaged over the trajectory has an\nupper-bound which is explicit in the constants of the problem, parameters of\nthe optimizer and the total number of iterations $N$. This bound can be made\narbitrarily small: Adam with a learning rate $\\alpha=1/\\sqrt{N}$ and a momentum\nparameter on squared gradients $\\beta_2=1-1/N$ achieves the same rate of\nconvergence $O(\\ln(N)/\\sqrt{N})$ as Adagrad. Finally, we obtain the tightest\ndependency on the heavy ball momentum among all previous convergence bounds for\nnon-convex Adam and Adagrad, improving from $O((1-\\beta_1)^{-3})$ to\n$O((1-\\beta_1)^{-1})$. Our technique also improves the best known dependency\nfor standard SGD by a factor $1 - \\beta_1$.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 01:56:17 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 12:08:29 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["D\u00e9fossez", "Alexandre", ""], ["Bottou", "L\u00e9on", ""], ["Bach", "Francis", ""], ["Usunier", "Nicolas", ""]]}, {"id": "2003.02426", "submitter": "Gurpreet Singh", "authors": "Gurpreet Singh, Soumyajit Gupta, Matt Lease, Clint N. Dawson", "title": "TIME: A Transparent, Interpretable, Model-Adaptive and Explainable\n  Neural Network for Dynamic Physical Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Differential Equations are infinite dimensional encoded\nrepresentations of physical processes. However, imbibing multiple observation\ndata towards a coupled representation presents significant challenges. We\npresent a fully convolutional architecture that captures the invariant\nstructure of the domain to reconstruct the observable system. The proposed\narchitecture is significantly low-weight compared to other networks for such\nproblems. Our intent is to learn coupled dynamic processes interpreted as\ndeviations from true kernels representing isolated processes for\nmodel-adaptivity. Experimental analysis shows that our architecture is robust\nand transparent in capturing process kernels and system anomalies. We also show\nthat high weights representation is not only redundant but also impacts network\ninterpretability. Our design is guided by domain knowledge, with isolated\nprocess representations serving as ground truths for verification. These allow\nus to identify redundant kernels and their manifestations in activation maps to\nguide better designs that are both interpretable and explainable unlike\ntraditional deep-nets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 04:19:59 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 04:45:20 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Singh", "Gurpreet", ""], ["Gupta", "Soumyajit", ""], ["Lease", "Matt", ""], ["Dawson", "Clint N.", ""]]}, {"id": "2003.02436", "submitter": "Noam Shazeer", "authors": "Noam Shazeer, Zhenzhong Lan, Youlong Cheng, Nan Ding, Le Hou", "title": "Talking-Heads Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"talking-heads attention\" - a variation on multi-head attention\nwhich includes linearprojections across the attention-heads dimension,\nimmediately before and after the softmax operation.While inserting only a small\nnumber of additional parameters and a moderate amount of additionalcomputation,\ntalking-heads attention leads to better perplexities on masked language\nmodeling tasks, aswell as better quality when transfer-learning to language\ncomprehension and question answering tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 05:17:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Shazeer", "Noam", ""], ["Lan", "Zhenzhong", ""], ["Cheng", "Youlong", ""], ["Ding", "Nan", ""], ["Hou", "Le", ""]]}, {"id": "2003.02452", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Kevin C. Chang, Qibing Li, Xiaolin Zheng", "title": "Semi-supervised Learning Meets Factorization: Learning to Recommend with\n  Chain Graph Model", "comments": "Accepted by TKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently latent factor model (LFM) has been drawing much attention in\nrecommender systems due to its good performance and scalability. However,\nexisting LFMs predict missing values in a user-item rating matrix only based on\nthe known ones, and thus the sparsity of the rating matrix always limits their\nperformance. Meanwhile, semi-supervised learning (SSL) provides an effective\nway to alleviate the label (i.e., rating) sparsity problem by performing label\npropagation, which is mainly based on the smoothness insight on affinity\ngraphs. However, graph-based SSL suffers serious scalability and graph\nunreliable problems when directly being applied to do recommendation. In this\npaper, we propose a novel probabilistic chain graph model (CGM) to marry SSL\nwith LFM. The proposed CGM is a combination of Bayesian network and Markov\nrandom field. The Bayesian network is used to model the rating generation and\nregression procedures, and the Markov random field is used to model the\nconfidence-aware smoothness constraint between the generated ratings.\nExperimental results show that our proposed CGM significantly outperforms the\nstate-of-the-art approaches in terms of four evaluation metrics, and with a\nlarger performance margin when data sparsity increases.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 06:34:53 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Chen", "Chaochao", ""], ["Chang", "Kevin C.", ""], ["Li", "Qibing", ""], ["Zheng", "Xiaolin", ""]]}, {"id": "2003.02455", "submitter": "Cuong Nguyen", "authors": "Cuong Nguyen, Thanh-Toan Do, Gustavo Carneiro", "title": "PAC-Bayesian Meta-learning with Implicit Prior and Posterior", "comments": "Correct the proof for PAC-Bayes meta-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new and rigorously-formulated PAC-Bayes few-shot meta-learning\nalgorithm that implicitly learns a prior distribution of the model of interest.\nOur proposed method extends the PAC-Bayes framework from a single task setting\nto the few-shot learning setting to upper-bound generalisation errors on unseen\ntasks and samples. We also propose a generative-based approach to model the\nshared prior and the posterior of task-specific model parameters more\nexpressively compared to the usual diagonal Gaussian assumption. We show that\nthe models trained with our proposed meta-learning algorithm are well\ncalibrated and accurate, with state-of-the-art calibration and classification\nresults on few-shot classification (mini-ImageNet and tiered-ImageNet) and\nregression (multi-modal task-distribution regression) benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 06:56:19 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 01:33:37 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Nguyen", "Cuong", ""], ["Do", "Thanh-Toan", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "2003.02460", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Ruslan Salakhutdinov,\n  Kamalika Chaudhuri", "title": "A Closer Look at Accuracy vs. Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for training robust networks lead to a drop in test accuracy,\nwhich has led prior works to posit that a robustness-accuracy tradeoff may be\ninevitable in deep learning. We take a closer look at this phenomenon and first\nshow that real image datasets are actually separated. With this property in\nmind, we then prove that robustness and accuracy should both be achievable for\nbenchmark datasets through locally Lipschitz functions, and hence, there should\nbe no inherent tradeoff between robustness and accuracy. Through extensive\nexperiments with robustness methods, we argue that the gap between theory and\npractice arises from two limitations of current methods: either they fail to\nimpose local Lipschitzness or they are insufficiently generalized. We explore\ncombining dropout with robust training methods and obtain better\ngeneralization. We conclude that achieving robustness and accuracy in practice\nmay require using methods that impose local Lipschitzness and augmenting them\nwith deep learning generalization techniques. Code available at\nhttps://github.com/yangarbiter/robust-local-lipschitz\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 07:09:32 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 04:15:33 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 19:59:39 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Zhang", "Hongyang", ""], ["Salakhutdinov", "Ruslan", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2003.02471", "submitter": "Fabio Muratore", "authors": "Fabio Muratore and Christian Eilers and Michael Gienger and Jan Peters", "title": "Data-efficient Domain Randomization with Bayesian Optimization", "comments": "Accepted at RA-L / ICRA", "journal-ref": null, "doi": "10.1109/LRA.2021.3052391", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning policies for robot control, the required real-world data is\ntypically prohibitively expensive to acquire, so learning in simulation is a\npopular strategy. Unfortunately, such polices are often not transferable to the\nreal world due to a mismatch between the simulation and reality, called\n'reality gap'. Domain randomization methods tackle this problem by randomizing\nthe physics simulator (source domain) during training according to a\ndistribution over domain parameters in order to obtain more robust policies\nthat are able to overcome the reality gap. Most domain randomization approaches\nsample the domain parameters from a fixed distribution. This solution is\nsuboptimal in the context of sim-to-real transferability, since it yields\npolicies that have been trained without explicitly optimizing for the reward on\nthe real system (target domain). Additionally, a fixed distribution assumes\nthere is prior knowledge about the uncertainty over the domain parameters. In\nthis paper, we propose Bayesian Domain Randomization (BayRn), a black-box\nsim-to-real algorithm that solves tasks efficiently by adapting the domain\nparameter distribution during learning given sparse data from the real-world\ntarget domain. BayRn uses Bayesian optimization to search the space of source\ndomain distribution parameters such that this leads to a policy which maximizes\nthe real-word objective, allowing for adaptive distributions during policy\noptimization. We experimentally validate the proposed approach in sim-to-sim as\nwell as in sim-to-real experiments, comparing against three baseline methods on\ntwo robotic tasks. Our results show that BayRn is able to perform sim-to-real\ntransfer, while significantly reducing the required prior knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 07:48:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:39:04 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 11:04:19 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 17:06:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Muratore", "Fabio", ""], ["Eilers", "Christian", ""], ["Gienger", "Michael", ""], ["Peters", "Jan", ""]]}, {"id": "2003.02544", "submitter": "Pedro Lara-Ben\\'itez", "authors": "Pedro Lara-Ben\\'itez, Manuel Carranza-Garc\\'ia, Francisco\n  Mart\\'inez-\\'Alvarez and Jos\\'e C. Riquelme", "title": "On the performance of deep learning models for time series\n  classification in streaming", "comments": "Paper submitted to the 15th International Conference on Soft\n  Computing Models in Industrial and Environmental Applications (SOCO 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing data streams arriving at high speed requires the development of\nmodels that can provide fast and accurate predictions. Although deep neural\nnetworks are the state-of-the-art for many machine learning tasks, their\nperformance in real-time data streaming scenarios is a research area that has\nnot yet been fully addressed. Nevertheless, there have been recent efforts to\nadapt complex deep learning models for streaming tasks by reducing their\nprocessing rate. The design of the asynchronous dual-pipeline deep learning\nframework allows to predict over incoming instances and update the model\nsimultaneously using two separate layers. The aim of this work is to assess the\nperformance of different types of deep architectures for data streaming\nclassification using this framework. We evaluate models such as multi-layer\nperceptrons, recurrent, convolutional and temporal convolutional neural\nnetworks over several time-series datasets that are simulated as streams. The\nobtained results indicate that convolutional architectures achieve a higher\nperformance in terms of accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 11:41:29 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 09:55:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lara-Ben\u00edtez", "Pedro", ""], ["Carranza-Garc\u00eda", "Manuel", ""], ["Mart\u00ednez-\u00c1lvarez", "Francisco", ""], ["Riquelme", "Jos\u00e9 C.", ""]]}, {"id": "2003.02554", "submitter": "Jacob Deasy", "authors": "Jacob Deasy, Ari Ercole and Pietro Li\\`o", "title": "Adaptive Prediction Timing for Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In realistic scenarios, multivariate timeseries evolve over case-by-case\ntime-scales. This is particularly clear in medicine, where the rate of clinical\nevents varies by ward, patient, and application. Increasingly complex models\nhave been shown to effectively predict patient outcomes, but have failed to\nadapt granularity to these inherent temporal resolutions. As such, we introduce\na novel, more realistic, approach to generating patient outcome predictions at\nan adaptive rate based on uncertainty accumulation in Bayesian recurrent\nmodels. We use a Recurrent Neural Network (RNN) and a Bayesian embedding layer\nwith a new aggregation method to demonstrate adaptive prediction timing. Our\nmodel predicts more frequently when events are dense or the model is certain of\nevent latent representations, and less frequently when readings are sparse or\nthe model is uncertain. At 48 hours after patient admission, our model achieves\nequal performance compared to its static-windowed counterparts, while\ngenerating patient- and event-specific prediction timings that lead to improved\npredictive performance over the crucial first 12 hours of the patient stay.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:02:44 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Deasy", "Jacob", ""], ["Ercole", "Ari", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2003.02556", "submitter": "Longfei Li", "authors": "Qitao Shi, Ya-Lin Zhang, Longfei Li, Xinxing Yang, Meng Li, Jun Zhou", "title": "SAFE: Scalable Automatic Feature Engineering Framework for Industrial\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been widely applied in Internet companies\nfor various tasks, acting as an essential driving force, and feature\nengineering has been generally recognized as a crucial tache when constructing\nmachine learning systems. Recently, a growing effort has been made to the\ndevelopment of automatic feature engineering methods, so that the substantial\nand tedious manual effort can be liberated. However, for industrial tasks, the\nefficiency and scalability of these methods are still far from satisfactory. In\nthis paper, we proposed a staged method named SAFE (Scalable Automatic Feature\nEngineering), which can provide excellent efficiency and scalability, along\nwith requisite interpretability and promising performance. Extensive\nexperiments are conducted and the results show that the proposed method can\nprovide prominent efficiency and competitive effectiveness when comparing with\nother methods. What's more, the adequate scalability of the proposed method\nensures it to be deployed in large scale industrial tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:07:36 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 03:03:55 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 04:47:36 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Shi", "Qitao", ""], ["Zhang", "Ya-Lin", ""], ["Li", "Longfei", ""], ["Yang", "Xinxing", ""], ["Li", "Meng", ""], ["Zhou", "Jun", ""]]}, {"id": "2003.02570", "submitter": "Yushi Qiu", "authors": "Yushi Qiu, Reiji Suda", "title": "Train-by-Reconnect: Decoupling Locations of Weights from their Values", "comments": "34th Annual Conference on Neural Information Processing Systems\n  (NeurIPS 2020). 18 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes untrained deep neural networks (DNNs) different from the trained\nperformant ones? By zooming into the weights in well-trained DNNs, we found it\nis the location of weights that hold most of the information encoded by the\ntraining. Motivated by this observation, we hypothesize that weights in\nstochastic gradient-based method trained DNNs can be separated into two\ndimensions: the locations of weights and their exact values. To assess our\nhypothesis, we propose a novel method named Lookahead Permutation (LaPerm) to\ntrain DNNs by reconnecting the weights. We empirically demonstrate the\nversatility of LaPerm while producing extensive evidence to support our\nhypothesis: when the initial weights are random and dense, our method\ndemonstrates speed and performance similar to or better than that of regular\noptimizers, e.g., Adam; when the initial weights are random and sparse (many\nzeros), our method changes the way neurons connect and reach accuracy\ncomparable to that of a well-trained fully initialized network; when the\ninitial weights share a single value, our method finds weight agnostic neural\nnetwork with far better-than-chance accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:40:46 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 10:05:12 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 10:01:32 GMT"}, {"version": "v4", "created": "Wed, 15 Apr 2020 05:32:32 GMT"}, {"version": "v5", "created": "Thu, 9 Jul 2020 07:07:03 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 06:26:35 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Qiu", "Yushi", ""], ["Suda", "Reiji", ""]]}, {"id": "2003.02578", "submitter": "Hee-Seok Oh", "authors": "Jang-Hyun Kim, Jongmin Lee, Hee-Seok Oh", "title": "Spherical Principal Curves", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  43, 2165-2171 (2021)", "doi": "10.1109/TPAMI.2020.3025327", "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for dimension reduction of data observed\nin a sphere. Several dimension reduction techniques have recently developed for\nthe analysis of non-Euclidean data. As a pioneer work, Hauberg (2016) attempted\nto implement principal curves on Riemannian manifolds. However, this approach\nuses approximations to deal with data on Riemannian manifolds, which causes\ndistorted results. In this study, we propose a new approach to construct\nprincipal curves on a sphere by a projection of the data onto a continuous\ncurve. Our approach lies in the same line of Hastie and Stuetzle (1989) that\nproposed principal curves for Euclidean space data. We further investigate the\nstationarity of the proposed principal curves that satisfy the self-consistency\non a sphere. Results from real data analysis with earthquake data and\nsimulation examples demonstrate the promising empirical properties of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:50:51 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 13:13:26 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 07:11:41 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Kim", "Jang-Hyun", ""], ["Lee", "Jongmin", ""], ["Oh", "Hee-Seok", ""]]}, {"id": "2003.02587", "submitter": "Fuli Feng", "authors": "Fuli Feng, Xiangnan He, Hanwang Zhang, and Tat-Seng Chua", "title": "Cross-GCN: Enhancing Graph Convolutional Network with $k$-Order Feature\n  Interactions", "comments": "Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) is an emerging technique that performs\nlearning and reasoning on graph data. It operates feature learning on the graph\nstructure, through aggregating the features of the neighbor nodes to obtain the\nembedding of each target node. Owing to the strong representation power, recent\nresearch shows that GCN achieves state-of-the-art performance on several tasks\nsuch as recommendation and linked document classification.\n  Despite its effectiveness, we argue that existing designs of GCN forgo\nmodeling cross features, making GCN less effective for tasks or data where\ncross features are important. Although neural network can approximate any\ncontinuous function, including the multiplication operator for modeling feature\ncrosses, it can be rather inefficient to do so (i.e., wasting many parameters\nat the risk of overfitting) if there is no explicit design.\n  To this end, we design a new operator named Cross-feature Graph Convolution,\nwhich explicitly models the arbitrary-order cross features with complexity\nlinear to feature dimension and order size. We term our proposed architecture\nas Cross-GCN, and conduct experiments on three graphs to validate its\neffectiveness. Extensive analysis validates the utility of explicitly modeling\ncross features in GCN, especially for feature learning at lower layers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 13:05:27 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Zhang", "Hanwang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2003.02601", "submitter": "Sergio Gonz\\'alez V\\'azquez", "authors": "Sergio Gonz\\'alez, Salvador Garc\\'ia, Sheng-Tun Li, Robert John,\n  Francisco Herrera", "title": "Fuzzy k-Nearest Neighbors with monotonicity constraints: Moving towards\n  the robustness of monotonic noise", "comments": "Accepted in Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model based on Fuzzy k-Nearest Neighbors for\nclassification with monotonic constraints, Monotonic Fuzzy k-NN (MonFkNN).\nReal-life data-sets often do not comply with monotonic constraints due to class\nnoise. MonFkNN incorporates a new calculation of fuzzy memberships, which\nincreases robustness against monotonic noise without the need for relabeling.\nOur proposal has been designed to be adaptable to the different needs of the\nproblem being tackled. In several experimental studies, we show significant\nimprovements in accuracy while matching the best degree of monotonicity\nobtained by comparable methods. We also show that MonFkNN empirically achieves\nimproved performance compared with Monotonic k-NN in the presence of large\namounts of class noise.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 13:27:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Gonz\u00e1lez", "Sergio", ""], ["Garc\u00eda", "Salvador", ""], ["Li", "Sheng-Tun", ""], ["John", "Robert", ""], ["Herrera", "Francisco", ""]]}, {"id": "2003.02623", "submitter": "Tae-Eon Park", "authors": "Tae-Eon Park and Taesup Moon", "title": "Unsupervised Neural Universal Denoiser for Finite-Input General-Output\n  Noisy Channel", "comments": "17 pages, 7 figures, Proceedings of the 23rdInternational Conference\n  on Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a novel neural network-based universal denoiser for the\nfinite-input, general-output (FIGO) channel. Based on the assumption of known\nnoisy channel densities, which is realistic in many practical scenarios, we\ntrain the network such that it can denoise as well as the best sliding window\ndenoiser for any given underlying clean source data. Our algorithm, dubbed as\nGeneralized CUDE (Gen-CUDE), enjoys several desirable properties; it can be\ntrained in an unsupervised manner (solely based on the noisy observation data),\nhas much smaller computational complexity compared to the previously developed\nuniversal denoiser for the same setting, and has much tighter upper bound on\nthe denoising performance, which is obtained by a theoretical analysis. In our\nexperiments, we show such tighter upper bound is also realized in practice by\nshowing that Gen-CUDE achieves much better denoising results compared to other\nstrong baselines for both synthetic and real underlying clean sequences.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 17:11:56 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Park", "Tae-Eon", ""], ["Moon", "Taesup", ""]]}, {"id": "2003.02631", "submitter": "Zhaohui Yang", "authors": "Linyan Lu and Zhaohui Yang and Mingzhe Chen and Zelin Zang and\n  Mohammad Shikh-Bahaei", "title": "Machine Learning for Predictive Deployment of UAVs with Multiple Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a machine learning based deployment framework of unmanned\naerial vehicles (UAVs) is studied. In the considered model, UAVs are deployed\nas flying base stations (BS) to offload heavy traffic from ground BSs. Due to\ntime-varying traffic distribution, a long short-term memory (LSTM) based\nprediction algorithm is introduced to predict the future cellular traffic. To\npredict the user service distribution, a KEG algorithm, which is a joint\nK-means and expectation maximization (EM) algorithm based on Gaussian mixture\nmodel (GMM), is proposed for determining the service area of each UAV. Based on\nthe predicted traffic, the optimal UAV positions are derived and three\nmulti-access techniques are compared so as to minimize the total transmit\npower. Simulation results show that the proposed method can reduce up to 24\\%\nof the total power consumption compared to the conventional method without\ntraffic prediction. Besides, rate splitting multiple access (RSMA) has the\nlower required transmit power compared to frequency domain multiple access\n(FDMA) and time domain multiple access (TDMA).\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 00:15:09 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 13:21:21 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Lu", "Linyan", ""], ["Yang", "Zhaohui", ""], ["Chen", "Mingzhe", ""], ["Zang", "Zelin", ""], ["Shikh-Bahaei", "Mohammad", ""]]}, {"id": "2003.02634", "submitter": "Samuele Tosatto", "authors": "Samuele Tosatto, Jonas Stadtmueller, Jan Peters", "title": "Dimensionality Reduction of Movement Primitives in Parameter Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Movement primitives are an important policy class for real-world robotics.\nHowever, the high dimensionality of their parametrization makes the policy\noptimization expensive both in terms of samples and computation. Enabling an\nefficient representation of movement primitives facilitates the application of\nmachine learning techniques such as reinforcement on robotics. Motions,\nespecially in highly redundant kinematic structures, exhibit high correlation\nin the configuration space. For these reasons, prior work has mainly focused on\nthe application of dimensionality reduction techniques in the configuration\nspace. In this paper, we investigate the application of dimensionality\nreduction in the parameter space, identifying principal movements. The\nresulting approach is enriched with a probabilistic treatment of the\nparameters, inheriting all the properties of the Probabilistic Movement\nPrimitives. We test the proposed technique both on a real robotic task and on a\ndatabase of complex human movements. The empirical analysis shows that the\ndimensionality reduction in parameter space is more effective than in\nconfiguration space, as it enables the representation of the movements with a\nsignificant reduction of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:38:39 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Tosatto", "Samuele", ""], ["Stadtmueller", "Jonas", ""], ["Peters", "Jan", ""]]}, {"id": "2003.02636", "submitter": "Avi Singh", "authors": "Avi Singh, Eric Jang, Alexander Irpan, Daniel Kappler, Murtaza Dalal,\n  Sergey Levine, Mohi Khansari, Chelsea Finn", "title": "Scalable Multi-Task Imitation Learning with Autonomous Improvement", "comments": "Accepted to ICRA 2020. Supplementary material at\n  https://sites.google.com/view/scalable-mili", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While robot learning has demonstrated promising results for enabling robots\nto automatically acquire new skills, a critical challenge in deploying\nlearning-based systems is scale: acquiring enough data for the robot to\neffectively generalize broadly. Imitation learning, in particular, has remained\na stable and powerful approach for robot learning, but critically relies on\nexpert operators for data collection. In this work, we target this challenge,\naiming to build an imitation learning system that can continuously improve\nthrough autonomous data collection, while simultaneously avoiding the explicit\nuse of reinforcement learning, to maintain the stability, simplicity, and\nscalability of supervised imitation. To accomplish this, we cast the problem of\nimitation with autonomous improvement into a multi-task setting. We utilize the\ninsight that, in a multi-task setting, a failed attempt at one task might\nrepresent a successful attempt at another task. This allows us to leverage the\nrobot's own trials as demonstrations for tasks other than the one that the\nrobot actually attempted. Using an initial dataset of multi-task demonstration\ndata, the robot autonomously collects trials which are only sparsely labeled\nwith a binary indication of whether the trial accomplished any useful task or\nnot. We then embed the trials into a learned latent space of tasks, trained\nusing only the initial demonstration dataset, to draw similarities between\nvarious trials, enabling the robot to achieve one-shot generalization to new\ntasks. In contrast to prior imitation learning approaches, our method can\nautonomously collect data with sparse supervision for continuous improvement,\nand in contrast to reinforcement learning algorithms, our method can\neffectively improve from sparse, task-agnostic reward signals.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:56:42 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Singh", "Avi", ""], ["Jang", "Eric", ""], ["Irpan", "Alexander", ""], ["Kappler", "Daniel", ""], ["Dalal", "Murtaza", ""], ["Levine", "Sergey", ""], ["Khansari", "Mohi", ""], ["Finn", "Chelsea", ""]]}, {"id": "2003.02638", "submitter": "Marcus Ebner Von Eschenbach", "authors": "Marcus Ebner von Eschenbach, Binyamin Manela, Jan Peters, Armin Biess", "title": "Metric-Based Imitation Learning Between Two Dissimilar Anthropomorphic\n  Robotic Arms", "comments": "8 pages, 5 figures, submitted to IEEE Robotics and Automation\n  Letters/IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of autonomous robotic systems that can learn from human\ndemonstrations to imitate a desired behavior - rather than being manually\nprogrammed - has huge technological potential. One major challenge in imitation\nlearning is the correspondence problem: how to establish corresponding states\nand actions between expert and learner, when the embodiments of the agents are\ndifferent (morphology, dynamics, degrees of freedom, etc.). Many existing\napproaches in imitation learning circumvent the correspondence problem, for\nexample, kinesthetic teaching or teleoperation, which are performed on the\nrobot. In this work we explicitly address the correspondence problem by\nintroducing a distance measure between dissimilar embodiments. This measure is\nthen used as a loss function for static pose imitation and as a feedback signal\nwithin a model-free deep reinforcement learning framework for dynamic movement\nimitation between two anthropomorphic robotic arms in simulation. We find that\nthe measure is well suited for describing the similarity between embodiments\nand for learning imitation policies by distance minimization.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:47:19 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["von Eschenbach", "Marcus Ebner", ""], ["Manela", "Binyamin", ""], ["Peters", "Jan", ""], ["Biess", "Armin", ""]]}, {"id": "2003.02641", "submitter": "Yuri Gloumakov", "authors": "Yuri Gloumakov, Adam J. Spiers, Aaron M. Dollar", "title": "Dimensionality Reduction and Motion Clustering during Activities of\n  Daily Living: 3, 4, and 7 Degree-of-Freedom Arm Movements", "comments": "11 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide variety of motions performed by the human arm during daily tasks\nmakes it desirable to find representative subsets to reduce the dimensionality\nof these movements for a variety of applications, including the design and\ncontrol of robotic and prosthetic devices. This paper presents a novel method\nand the results of an extensive human subjects study to obtain representative\narm joint angle trajectories that span naturalistic motions during Activities\nof Daily Living (ADLs). In particular, we seek to identify sets of useful\nmotion trajectories of the upper limb that are functions of a single variable,\nallowing, for instance, an entire prosthetic or robotic arm to be controlled\nwith a single input from a user, along with a means to select between motions\nfor different tasks. Data driven approaches are used to obtain clusters as well\nas representative motion averages for the full-arm 7 degree of freedom (DOF),\nelbow-wrist 4 DOF, and wrist-only 3 DOF motions. The proposed method makes use\nof well-known techniques such as dynamic time warping (DTW) to obtain a\ndivergence measure between motion segments, DTW barycenter averaging (DBA) to\nobtain averages, Ward's distance criterion to build hierarchical trees,\nbatch-DTW to simultaneously align multiple motion data, and functional\nprincipal component analysis (fPCA) to evaluate cluster variability. The\nclusters that emerge associate various recorded motions into primarily hand\nstart and end location for the full-arm system, motion direction for the\nwrist-only system, and an intermediate between the two qualities for the\nelbow-wrist system. The proposed clustering methodology is justified by\ncomparing results against alternative approaches.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:32:36 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Gloumakov", "Yuri", ""], ["Spiers", "Adam J.", ""], ["Dollar", "Aaron M.", ""]]}, {"id": "2003.02643", "submitter": "Victor Farias Monteiro", "authors": "Juno V. Saraiva, Iran M. Braga Jr., Victor F. Monteiro, F. Rafael M.\n  Lima, Tarcisio F. Maciel, Walter C. Freitas Jr. and F. Rodrigo P. Cavalcanti", "title": "Deep Reinforcement Learning for QoS-Constrained Resource Allocation in\n  Multiservice Networks", "comments": "Submitted to \"Journal of Communication and Information System\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study a Radio Resource Allocation (RRA) that was\nformulated as a non-convex optimization problem whose main aim is to maximize\nthe spectral efficiency subject to satisfaction guarantees in multiservice\nwireless systems. This problem has already been previously investigated in the\nliterature and efficient heuristics have been proposed. However, in order to\nassess the performance of Machine Learning (ML) algorithms when solving\noptimization problems in the context of RRA, we revisit that problem and\npropose a solution based on a Reinforcement Learning (RL) framework.\nSpecifically, a distributed optimization method based on multi-agent deep RL is\ndeveloped, where each agent makes its decisions to find a policy by interacting\nwith the local environment, until reaching convergence. Thus, this article\nfocuses on an application of RL and our main proposal consists in a new deep RL\nbased approach to jointly deal with RRA, satisfaction guarantees and Quality of\nService (QoS) constraints in multiservice celular networks. Lastly, through\ncomputational simulations we compare the state-of-art solutions of the\nliterature with our proposal and we show a near optimal performance of the\nlatter in terms of throughput and outage rate.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 19:32:15 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Saraiva", "Juno V.", ""], ["Braga", "Iran M.", "Jr."], ["Monteiro", "Victor F.", ""], ["Lima", "F. Rafael M.", ""], ["Maciel", "Tarcisio F.", ""], ["Freitas", "Walter C.", "Jr."], ["Cavalcanti", "F. Rodrigo P.", ""]]}, {"id": "2003.02645", "submitter": "Micha Livne", "authors": "Micha Livne, Kevin Swersky, David J. Fleet", "title": "SentenceMIM: A Latent Variable Language Model", "comments": "Preprint. Demo: https://github.com/seraphlabs-ca/SentenceMIM-demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SentenceMIM is a probabilistic auto-encoder for language data, trained with\nMutual Information Machine (MIM) learning to provide a fixed length\nrepresentation of variable length language observations (i.e., similar to VAE).\nPrevious attempts to learn VAEs for language data faced challenges due to\nposterior collapse. MIM learning encourages high mutual information between\nobservations and latent variables, and is robust against posterior collapse. As\nsuch, it learns informative representations whose dimension can be an order of\nmagnitude higher than existing language VAEs. Importantly, the SentenceMIM loss\nhas no hyper-parameters, simplifying optimization. We compare sentenceMIM with\nVAE, and AE on multiple datasets. SentenceMIM yields excellent reconstruction,\ncomparable to AEs, with a rich structured latent space, comparable to VAEs. The\nstructured latent representation is demonstrated with interpolation between\nsentences of different lengths. We demonstrate the versatility of sentenceMIM\nby utilizing a trained model for question-answering and transfer learning,\nwithout fine-tuning, outperforming VAE and AE with similar architectures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:34:29 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 02:41:29 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 15:20:13 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 11:24:11 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 20:02:00 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Livne", "Micha", ""], ["Swersky", "Kevin", ""], ["Fleet", "David J.", ""]]}, {"id": "2003.02650", "submitter": "Mahdi Azari", "authors": "Atefeh Hajijamali Arani, M. Mahdi Azari, William Melek, and Safieddin\n  Safavi-Naeini", "title": "Learning in the Sky: An Efficient 3D Placement of UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of unmanned aerial vehicles (UAVs) as aerial base stations can\ndeliver a fast and flexible solution for serving varying traffic demand. In\norder to adequately benefit of UAVs deployment, their efficient placement is of\nutmost importance, and requires to intelligently adapt to the environment\nchanges. In this paper, we propose a learning-based mechanism for the\nthree-dimensional deployment of UAVs assisting terrestrial cellular networks in\nthe downlink. The problem is modeled as a non-cooperative game among UAVs in\nsatisfaction form. To solve the game, we utilize a low complexity algorithm, in\nwhich unsatisfied UAVs update their locations based on a learning algorithm.\nSimulation results reveal that the proposed UAV placement algorithm yields\nsignificant performance gains up to about 52% and 74% in terms of throughput\nand the number of dropped users, respectively, compared to an optimized\nbaseline algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:16:00 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Arani", "Atefeh Hajijamali", ""], ["Azari", "M. Mahdi", ""], ["Melek", "William", ""], ["Safavi-Naeini", "Safieddin", ""]]}, {"id": "2003.02651", "submitter": "Cristian Tatino", "authors": "Cristian Tatino, Nikolaos Pappas, Ilaria Malanchini, Lutz Ewe, and Di\n  Yuan", "title": "Learning-Based Link Scheduling in Millimeter-wave Multi-connectivity\n  Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-connectivity is emerging as a promising solution to provide reliable\ncommunications and seamless connectivity for the millimeter-wave frequency\nrange. Due to the blockage sensitivity at such high frequencies, connectivity\nwith multiple cells can drastically increase the network performance in terms\nof throughput and reliability. However, an inefficient link scheduling, i.e.,\nover and under-provisioning of connections, can lead either to high\ninterference and energy consumption or to unsatisfied user's quality of service\n(QoS) requirements. In this work, we present a learning-based solution that is\nable to learn and then to predict the optimal link scheduling to satisfy users'\nQoS requirements while avoiding communication interruptions. Moreover, we\ncompare the proposed approach with two base line methods and the genie-aided\nlink scheduling that assumes perfect channel knowledge. We show that the\nlearning-based solution approaches the optimum and outperforms the base line\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:42:21 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Tatino", "Cristian", ""], ["Pappas", "Nikolaos", ""], ["Malanchini", "Ilaria", ""], ["Ewe", "Lutz", ""], ["Yuan", "Di", ""]]}, {"id": "2003.02655", "submitter": "Tamir Blum", "authors": "Tamir Blum and Kazuya Yoshida", "title": "PPMC RL Training Algorithm: Rough Terrain Intelligent Robots through\n  Reinforcement Learning", "comments": "6 pages, 7 figures, 4 wheeled rover in a rough environment resembling\n  lunar surface", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots can now learn how to make decisions and control themselves,\ngeneralizing learned behaviors to unseen scenarios. In particular, AI powered\nrobots show promise in rough environments like the lunar surface, due to the\nenvironmental uncertainties. We address this critical generalization aspect for\nrobot locomotion in rough terrain through a training algorithm we have created\ncalled the Path Planning and Motion Control (PPMC) Training Algorithm. This\nalgorithm is coupled with any generic reinforcement learning algorithm to teach\nrobots how to respond to user commands and to travel to designated locations on\na single neural network. In this paper, we show that the algorithm works\nindependent of the robot structure, demonstrating that it works on a wheeled\nrover in addition the past results on a quadruped walking robot. Further, we\ntake several big steps towards real world practicality by introducing a rough\nhighly uneven terrain. Critically, we show through experiments that the robot\nlearns to generalize to new rough terrain maps, retaining a 100% success rate.\nTo the best of our knowledge, this is the first paper to introduce a generic\ntraining algorithm teaching generalized PPMC in rough environments to any\nrobot, with just the use of reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:14:52 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 08:26:45 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Blum", "Tamir", ""], ["Yoshida", "Kazuya", ""]]}, {"id": "2003.02657", "submitter": "Wonjun Ko", "authors": "Wonjun Ko, Eunjin Jeon, Seungwoo Jeong, and Heung-Il Suk", "title": "Multi-Scale Neural network for EEG Representation Learning in BCI", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have had a methodological and practical\nimpact on brain-computer interface research. Among the various deep network\narchitectures, convolutional neural networks have been well suited for\nspatio-spectral-temporal electroencephalogram signal representation learning.\nMost of the existing CNN-based methods described in the literature extract\nfeatures at a sequential level of abstraction with repetitive nonlinear\noperations and involve densely connected layers for classification. However,\nstudies in neurophysiology have revealed that EEG signals carry information in\ndifferent ranges of frequency components. To better reflect these\nmulti-frequency properties in EEGs, we propose a novel deep multi-scale neural\nnetwork that discovers feature representations in multiple frequency/time\nranges and extracts relationships among electrodes, i.e., spatial\nrepresentations, for subject intention/condition identification. Furthermore,\nby completely representing EEG signals with spatio-spectral-temporal\ninformation, the proposed method can be utilized for diverse paradigms in both\nactive and passive BCIs, contrary to existing methods that are primarily\nfocused on single-paradigm BCIs. To demonstrate the validity of our proposed\nmethod, we conducted experiments on various paradigms of active/passive BCI\ndatasets. Our experimental results demonstrated that the proposed method\nachieved performance improvements when judged against comparable\nstate-of-the-art methods. Additionally, we analyzed the proposed method using\ndifferent techniques, such as PSD curves and relevance score inspection to\nvalidate the multi-scale EEG signal information capturing ability, activation\npattern maps for investigating the learned spatial filters, and t-SNE plotting\nfor visualizing represented features. Finally, we also demonstrated our\nmethod's application to real-world problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:06:47 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ko", "Wonjun", ""], ["Jeon", "Eunjin", ""], ["Jeong", "Seungwoo", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2003.02658", "submitter": "Philippe Wenk", "authors": "Emmanouil Angelis, Philippe Wenk, Bernhard Sch\\\"olkopf, Stefan Bauer\n  and Andreas Krause", "title": "SLEIPNIR: Deterministic and Provably Accurate Feature Expansion for\n  Gaussian Process Regression with Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are an important regression tool with excellent analytic\nproperties which allow for direct integration of derivative observations.\nHowever, vanilla GP methods scale cubically in the amount of observations. In\nthis work, we propose a novel approach for scaling GP regression with\nderivatives based on quadrature Fourier features. We then prove deterministic,\nnon-asymptotic and exponentially fast decaying error bounds which apply for\nboth the approximated kernel as well as the approximated posterior. To\nfurthermore illustrate the practical applicability of our method, we then apply\nit to ODIN, a recently developed algorithm for ODE parameter inference. In an\nextensive experiments section, all results are empirically validated,\ndemonstrating the speed, accuracy, and practical applicability of this\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 14:33:20 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Angelis", "Emmanouil", ""], ["Wenk", "Philippe", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""], ["Krause", "Andreas", ""]]}, {"id": "2003.02671", "submitter": "Ion Matei Dr.", "authors": "Ion Matei, Johan de Kleer, Alexander Feldman, Rahul Rai, Souma\n  Chowdhury", "title": "Hybrid modeling: Applications in real-time diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced-order models that accurately abstract high fidelity models and enable\nfaster simulation is vital for real-time, model-based diagnosis applications.\nIn this paper, we outline a novel hybrid modeling approach that combines\nmachine learning inspired models and physics-based models to generate\nreduced-order models from high fidelity models. We are using such models for\nreal-time diagnosis applications. Specifically, we have developed machine\nlearning inspired representations to generate reduced order component models\nthat preserve, in part, the physical interpretation of the original high\nfidelity component models. To ensure the accuracy, scalability and numerical\nstability of the learning algorithms when training the reduced-order models we\nuse optimization platforms featuring automatic differentiation. Training data\nis generated by simulating the high-fidelity model. We showcase our approach in\nthe context of fault diagnosis of a rail switch system. Three new model\nabstractions whose complexities are two orders of magnitude smaller than the\ncomplexity of the high fidelity model, both in the number of equations and\nsimulation time are shown. The numerical experiments and results demonstrate\nthe efficacy of the proposed hybrid modeling approach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 00:44:57 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Matei", "Ion", ""], ["de Kleer", "Johan", ""], ["Feldman", "Alexander", ""], ["Rai", "Rahul", ""], ["Chowdhury", "Souma", ""]]}, {"id": "2003.02681", "submitter": "Jing Yang", "authors": "Weiqiang Wu, Jing Yang, and Cong Shen", "title": "Stochastic Linear Contextual Bandits with Diverse Contexts", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the impact of context diversity on stochastic\nlinear contextual bandits. As opposed to the previous view that contexts lead\nto more difficult bandit learning, we show that when the contexts are\nsufficiently diverse, the learner is able to utilize the information obtained\nduring exploitation to shorten the exploration process, thus achieving reduced\nregret. We design the LinUCB-d algorithm, and propose a novel approach to\nanalyze its regret performance. The main theoretical result is that under the\ndiverse context assumption, the cumulative expected regret of LinUCB-d is\nbounded by a constant. As a by-product, our results improve the previous\nunderstanding of LinUCB and strengthen its performance guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 14:51:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Wu", "Weiqiang", ""], ["Yang", "Jing", ""], ["Shen", "Cong", ""]]}, {"id": "2003.02685", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir, Pier Luigi Dragotti and Deniz Gunduz", "title": "Privacy-Aware Time-Series Data Sharing with Deep Reinforcement Learning", "comments": "13 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1907.07606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of things (IoT) devices are becoming increasingly popular thanks to\nmany new services and applications they offer. However, in addition to their\nmany benefits, they raise privacy concerns since they share fine-grained\ntime-series user data with untrusted third parties. In this work, we study the\nprivacy-utility trade-off (PUT) in time-series data sharing. Existing\napproaches to PUT mainly focus on a single data point; however, temporal\ncorrelations in time-series data introduce new challenges. Methods that\npreserve the privacy for the current time may leak significant amount of\ninformation at the trace level as the adversary can exploit temporal\ncorrelations in a trace. We consider sharing the distorted version of a user's\ntrue data sequence with an untrusted third party. We measure the privacy\nleakage by the mutual information between the user's true data sequence and\nshared version. We consider both the instantaneous and average distortion\nbetween the two sequences, under a given distortion measure, as the utility\nloss metric. To tackle the history-dependent mutual information minimization,\nwe reformulate the problem as a Markov decision process (MDP), and solve it\nusing asynchronous actor-critic deep reinforcement learning (RL). We evaluate\nthe performance of the proposed solution in location trace privacy on both\nsynthetic and GeoLife GPS trajectory datasets. For the latter, we show the\nvalidity of our solution by testing the privacy of the released location\ntrajectory against an adversary network.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:47:25 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 11:52:41 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Dragotti", "Pier Luigi", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2003.02689", "submitter": "Luoyi Zhang", "authors": "Luoyi Zhang, Ming Xu", "title": "EPINE: Enhanced Proximity Information Network Embedding", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised homogeneous network embedding (NE) represents every vertex of\nnetworks into a low-dimensional vector and meanwhile preserves the network\ninformation. Adjacency matrices retain most of the network information, and\ndirectly charactrize the first-order proximity. In this work, we devote to\nmining valuable information in adjacency matrices at a deeper level. Under the\nsame objective, many NE methods calculate high-order proximity by the powers of\nadjacency matrices, which is not accurate and well-designed enough. Instead, we\npropose to redefine high-order proximity in a more intuitive manner. Besides,\nwe design a novel algorithm for calculation, which alleviates the scalability\nproblem in the field of accurate calculation for high-order proximity.\nComprehensive experiments on real-world network datasets demonstrate the\neffectiveness of our method in downstream machine learning tasks such as\nnetwork reconstruction, link prediction and node classification.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:57:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Zhang", "Luoyi", ""], ["Xu", "Ming", ""]]}, {"id": "2003.02729", "submitter": "Nathaniel Garton", "authors": "Nathaniel Garton and Jarad Niemi and Alicia Carriquiry", "title": "Knot Selection in Sparse Gaussian Processes with a Variational Objective\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse, knot-based Gaussian processes have enjoyed considerable success as\nscalable approximations to full Gaussian processes. Certain sparse models can\nbe derived through specific variational approximations to the true posterior,\nand knots can be selected to minimize the Kullback-Leibler divergence between\nthe approximate and true posterior. While this has been a successful approach,\nsimultaneous optimization of knots can be slow due to the number of parameters\nbeing optimized. Furthermore, there have been few proposed methods for\nselecting the number of knots, and no experimental results exist in the\nliterature. We propose using a one-at-a-time knot selection algorithm based on\nBayesian optimization to select the number and locations of knots. We showcase\nthe competitive performance of this method relative to simultaneous\noptimization of knots on three benchmark data sets, but at a fraction of the\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 15:56:41 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 23:26:43 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Garton", "Nathaniel", ""], ["Niemi", "Jarad", ""], ["Carriquiry", "Alicia", ""]]}, {"id": "2003.02735", "submitter": "Casey Cole", "authors": "Casey A. Cole, Bethany Janos, Dien Anshari, James F. Thrasher, Scott\n  Strayer, and Homayoun Valafar", "title": "Recognition of Smoking Gesture Using Smart Watch Technology", "comments": "7 pages, Published originally at HIMS in 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diseases resulting from prolonged smoking are the most common preventable\ncauses of death in the world today. In this report we investigate the success\nof utilizing accelerometer sensors in smart watches to identify smoking\ngestures. Early identification of smoking gestures can help to initiate the\nappropriate intervention method and prevent relapses in smoking. Our\nexperiments indicate 85%-95% success rates in identification of smoking gesture\namong other similar gestures using Artificial Neural Networks (ANNs). Our\ninvestigations concluded that information obtained from the x-dimension of\naccelerometers is the best means of identifying the smoking gesture, while y\nand z dimensions are helpful in eliminating other gestures such as: eating,\ndrinking, and scratch of nose. We utilized sensor data from the Apple Watch\nduring the training of the ANN. Using sensor data from another participant\ncollected on Pebble Steel, we obtained a smoking identification accuracy of\ngreater than 90% when using an ANN trained on data previously collected from\nthe Apple Watch. Finally, we have demonstrated the possibility of using smart\nwatches to perform continuous monitoring of daily activities.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:05:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cole", "Casey A.", ""], ["Janos", "Bethany", ""], ["Anshari", "Dien", ""], ["Thrasher", "James F.", ""], ["Strayer", "Scott", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2003.02738", "submitter": "Florian Schmidt", "authors": "Florian Schmidt and Thomas Hofmann", "title": "BERT as a Teacher: Contextual Embeddings for Sequence-Level Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the quality of a generated sequence against a set of references is\na central problem in many learning frameworks, be it to compute a score, to\nassign a reward, or to perform discrimination. Despite great advances in model\narchitectures, metrics that scale independently of the number of references are\nstill based on n-gram estimates. We show that the underlying operations,\ncounting words and comparing counts, can be lifted to embedding words and\ncomparing embeddings. An in-depth analysis of BERT embeddings shows empirically\nthat contextual embeddings can be employed to capture the required dependencies\nwhile maintaining the necessary scalability through appropriate pruning and\nsmoothing techniques. We cast unconditional generation as a reinforcement\nlearning problem and show that our reward function indeed provides a more\neffective learning signal than n-gram reward in this challenging setting.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:06:37 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Schmidt", "Florian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "2003.02740", "submitter": "Yongle Luo", "authors": "Yongle Luo, Kun Dong, Lili Zhao, Zhiyong Sun, Chao Zhou, Bo Song", "title": "Balance Between Efficient and Effective Learning: Dense2Sparse Reward\n  Shaping for Robot Manipulation with Environment Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and effective learning is one of the ultimate goals of the deep\nreinforcement learning (DRL), although the compromise has been made in most of\nthe time, especially for the application of robot manipulations. Learning is\nalways expensive for robot manipulation tasks and the learning effectiveness\ncould be affected by the system uncertainty. In order to solve above\nchallenges, in this study, we proposed a simple but powerful reward shaping\nmethod, namely Dense2Sparse. It combines the advantage of fast convergence of\ndense reward and the noise isolation of the sparse reward, to achieve a balance\nbetween learning efficiency and effectiveness, which makes it suitable for\nrobot manipulation tasks. We evaluated our Dense2Sparse method with a series of\nablation experiments using the state representation model with system\nuncertainty. The experiment results show that the Dense2Sparse method obtained\nhigher expected reward compared with the ones using standalone dense reward or\nsparse reward, and it also has a superior tolerance of system uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:10:15 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Luo", "Yongle", ""], ["Dong", "Kun", ""], ["Zhao", "Lili", ""], ["Sun", "Zhiyong", ""], ["Zhou", "Chao", ""], ["Song", "Bo", ""]]}, {"id": "2003.02751", "submitter": "Ehsan Haghighat", "authors": "Ehsan Haghighat, Maziar Raissi, Adrian Moure, Hector Gomez, Ruben\n  Juanes", "title": "A deep learning framework for solution and discovery in solid mechanics", "comments": "19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the application of a class of deep learning, known as Physics\nInformed Neural Networks (PINN), to learning and discovery in solid mechanics.\nWe explain how to incorporate the momentum balance and constitutive relations\ninto PINN, and explore in detail the application to linear elasticity, and\nillustrate its extension to nonlinear problems through an example that\nshowcases von~Mises elastoplasticity. While common PINN algorithms are based on\ntraining one deep neural network (DNN), we propose a multi-network model that\nresults in more accurate representation of the field variables. To validate the\nmodel, we test the framework on synthetic data generated from analytical and\nnumerical reference solutions. We study convergence of the PINN model, and show\nthat Isogeometric Analysis (IGA) results in superior accuracy and convergence\ncharacteristics compared with classic low-order Finite Element Method (FEM). We\nalso show the applicability of the framework for transfer learning, and find\nvastly accelerated convergence during network re-training. Finally, we find\nthat honoring the physics leads to improved robustness: when trained only on a\nfew parameters, we find that the PINN model can accurately predict the solution\nfor a wide range of parameters new to the network---thus pointing to an\nimportant application of this framework to sensitivity analysis and surrogate\nmodeling.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:24:53 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 20:42:15 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Haghighat", "Ehsan", ""], ["Raissi", "Maziar", ""], ["Moure", "Adrian", ""], ["Gomez", "Hector", ""], ["Juanes", "Ruben", ""]]}, {"id": "2003.02752", "submitter": "Hongxin Wei", "authors": "Hongxin Wei, Lei Feng, Xiangyu Chen, Bo An", "title": "Combating noisy labels by agreement: A joint training method with\n  co-regularization", "comments": "Accepted by CVPR 2020; Code is available at:\n  https://github.com/hongxin001/JoCoR. arXiv admin note: text overlap with\n  arXiv:1901.04215 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning with noisy labels is a practically challenging problem in\nweakly supervised learning. The state-of-the-art approaches \"Decoupling\" and\n\"Co-teaching+\" claim that the \"disagreement\" strategy is crucial for\nalleviating the problem of learning with noisy labels. In this paper, we start\nfrom a different perspective and propose a robust learning paradigm called\nJoCoR, which aims to reduce the diversity of two networks during training.\nSpecifically, we first use two networks to make predictions on the same\nmini-batch data and calculate a joint loss with Co-Regularization for each\ntraining example. Then we select small-loss examples to update the parameters\nof both two networks simultaneously. Trained by the joint loss, these two\nnetworks would be more and more similar due to the effect of Co-Regularization.\nExtensive experimental results on corrupted data from benchmark datasets\nincluding MNIST, CIFAR-10, CIFAR-100 and Clothing1M demonstrate that JoCoR is\nsuperior to many state-of-the-art approaches for learning with noisy labels.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:42:41 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 07:40:58 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 17:06:32 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Wei", "Hongxin", ""], ["Feng", "Lei", ""], ["Chen", "Xiangyu", ""], ["An", "Bo", ""]]}, {"id": "2003.02774", "submitter": "Francesco Palmieri A. N.", "authors": "Francesco A. N. Palmieri and Krishna R. Pattipati and Giovanni\n  Fioretti and Giovanni Di Gennaro and Amedeo Buonanno", "title": "Path Planning Using Probability Tensor Flows", "comments": "Submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability models have been proposed in the literature to account for\n\"intelligent\" behavior in many contexts. In this paper, probability propagation\nis applied to model agent's motion in potentially complex scenarios that\ninclude goals and obstacles. The backward flow provides precious background\ninformation to the agent's behavior, viz., inferences coming from the future\ndetermine the agent's actions. Probability tensors are layered in time in both\ndirections in a manner similar to convolutional neural networks. The discussion\nis carried out with reference to a set of simulated grids where, despite the\napparent task complexity, a solution, if feasible, is always found. The\noriginal model proposed by Attias has been extended to include non-absorbing\nobstacles, multiple goals and multiple agents. The emerging behaviors are very\nrealistic and demonstrate great potentials of the application of this framework\nto real environments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 17:14:52 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Palmieri", "Francesco A. N.", ""], ["Pattipati", "Krishna R.", ""], ["Fioretti", "Giovanni", ""], ["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""]]}, {"id": "2003.02793", "submitter": "Hangyu Zhu", "authors": "Hangyu Zhu and Yaochu Jin", "title": "Real-time Federated Evolutionary Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed machine learning approach to privacy\npreservation and two major technical challenges prevent a wider application of\nfederated learning. One is that federated learning raises high demands on\ncommunication, since a large number of model parameters must be transmitted\nbetween the server and the clients. The other challenge is that training large\nmachine learning models such as deep neural networks in federated learning\nrequires a large amount of computational resources, which may be unrealistic\nfor edge devices such as mobile phones. The problem becomes worse when deep\nneural architecture search is to be carried out in federated learning. To\naddress the above challenges, we propose an evolutionary approach to real-time\nfederated neural architecture search that not only optimize the model\nperformance but also reduces the local payload. During the search, a\ndouble-sampling technique is introduced, in which for each individual, a\nrandomly sampled sub-model of a master model is transmitted to a number of\nrandomly sampled clients for training without reinitialization. This way, we\neffectively reduce computational and communication costs required for\nevolutionary optimization and avoid big performance fluctuations of the local\nmodels, making the proposed framework well suited for real-time federated\nneural architecture search.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:03:28 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Zhu", "Hangyu", ""], ["Jin", "Yaochu", ""]]}, {"id": "2003.02800", "submitter": "Sourjya Roy", "authors": "Sourjya Roy, Priyadarshini Panda, Gopalakrishnan Srinivasan, and Anand\n  Raghunathan", "title": "Pruning Filters while Training for Efficiently Optimizing Deep Learning\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep networks have millions to billions of parameters, which leads to\nhigh memory and energy requirements during training as well as during inference\non resource-constrained edge devices. Consequently, pruning techniques have\nbeen proposed that remove less significant weights in deep networks, thereby\nreducing their memory and computational requirements. Pruning is usually\nperformed after training the original network, and is followed by further\nretraining to compensate for the accuracy loss incurred during pruning. The\nprune-and-retrain procedure is repeated iteratively until an optimum tradeoff\nbetween accuracy and efficiency is reached. However, such iterative retraining\nadds to the overall training complexity of the network. In this work, we\npropose a dynamic pruning-while-training procedure, wherein we prune filters of\nthe convolutional layers of a deep network during training itself, thereby\nprecluding the need for separate retraining. We evaluate our dynamic\npruning-while-training approach with three different pre-existing pruning\nstrategies, viz. mean activation-based pruning, random pruning, and L1\nnormalization-based pruning. Our results for VGG-16 trained on CIFAR10 shows\nthat L1 normalization provides the best performance among all the techniques\nexplored in this work with less than 1% drop in accuracy after pruning 80% of\nthe filters compared to the original network. We further evaluated the L1\nnormalization based pruning mechanism on CIFAR100. Results indicate that\npruning while training yields a compressed network with almost no accuracy loss\nafter pruning 50% of the filters compared to the original network and ~5% loss\nfor high pruning rates (>80%). The proposed pruning methodology yields 41%\nreduction in the number of computations and memory accesses during training for\nCIFAR10, CIFAR100 and ImageNet compared to training with retraining for 10\nepochs .\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:05:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Roy", "Sourjya", ""], ["Panda", "Priyadarshini", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2003.02804", "submitter": "Pavel Karpov Dr", "authors": "Igor V. Tetko, Pavel Karpov, Ruud Van Deursen, Guillaume Godin", "title": "State-of-the-Art Augmented NLP Transformer models for direct and\n  single-step retrosynthesis", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-19266-y", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We investigated the effect of different training scenarios on predicting the\n(retro)synthesis of chemical compounds using a text-like representation of\nchemical reactions (SMILES) and Natural Language Processing neural network\nTransformer architecture. We showed that data augmentation, which is a powerful\nmethod used in image processing, eliminated the effect of data memorization by\nneural networks, and improved their performance for the prediction of new\nsequences. This effect was observed when augmentation was used simultaneously\nfor input and the target data simultaneously. The top-5 accuracy was 84.8% for\nthe prediction of the largest fragment (thus identifying principal\ntransformation for classical retro-synthesis) for the USPTO-50k test dataset\nand was achieved by a combination of SMILES augmentation and a beam search\nalgorithm. The same approach provided significantly better results for the\nprediction of direct reactions from the single-step USPTO-MIT test set. Our\nmodel achieved 90.6% top-1 and 96.1% top-5 accuracy for its challenging mixed\nset and 97% top-5 accuracy for the USPTO-MIT separated set. It also\nsignificantly improved results for USPTO-full set single-step retrosynthesis\nfor both top-1 and top-10 accuracies. The appearance frequency of the most\nabundantly generated SMILES was well correlated with the prediction outcome and\ncan be used as a measure of the quality of reaction prediction.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:11:11 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 14:23:59 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Tetko", "Igor V.", ""], ["Karpov", "Pavel", ""], ["Van Deursen", "Ruud", ""], ["Godin", "Guillaume", ""]]}, {"id": "2003.02808", "submitter": "Joseph Vargovich", "authors": "Toby Hocking, Joseph Vargovich", "title": "Linear time dynamic programming for the exact path of optimal models\n  selected from a finite set", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning algorithms are formulated in terms of finding model parameters\nwhich minimize a data-fitting loss function plus a regularizer. When the\nregularizer involves the l0 pseudo-norm, the resulting regularization path\nconsists of a finite set of models. The fastest existing algorithm for\ncomputing the breakpoints in the regularization path is quadratic in the number\nof models, so it scales poorly to high dimensional problems. We provide new\nformal proofs that a dynamic programming algorithm can be used to compute the\nbreakpoints in linear time. Empirical results on changepoint detection problems\ndemonstrate the improved accuracy and speed relative to grid search and the\nprevious quadratic time algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:16:58 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Hocking", "Toby", ""], ["Vargovich", "Joseph", ""]]}, {"id": "2003.02817", "submitter": "Lucas Nunes Sequeira", "authors": "Lucas Nunes Sequeira, Bruno Moreschi, Fabio Gagliardi Cozman and\n  Bernardo Fontes", "title": "An Empirical Accuracy Law for Sequential Machine Translation: the Case\n  of Google Translate", "comments": "11 pages, 8 figures (mostly graphs), a few mathematical functions and\n  samples of the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we have established, through empirical testing, a law that\nrelates the number of translating hops to translation accuracy in sequential\nmachine translation in Google Translate. Both accuracy and size decrease with\nthe number of hops; the former displays a decrease closely following a power\nlaw. Such a law allows one to predict the behavior of translation chains that\nmay be built as society increasingly depends on automated devices.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:40:44 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 18:22:36 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Sequeira", "Lucas Nunes", ""], ["Moreschi", "Bruno", ""], ["Cozman", "Fabio Gagliardi", ""], ["Fontes", "Bernardo", ""]]}, {"id": "2003.02819", "submitter": "Aditya Menon", "authors": "Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, Sanjiv\n  Kumar", "title": "Does label smoothing mitigate label noise?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Label smoothing is commonly used in training deep learning models, wherein\none-hot training labels are mixed with uniform label vectors. Empirically,\nsmoothing has been shown to improve both predictive performance and model\ncalibration. In this paper, we study whether label smoothing is also effective\nas a means of coping with label noise. While label smoothing apparently\namplifies this problem --- being equivalent to injecting symmetric noise to the\nlabels --- we show how it relates to a general family of loss-correction\ntechniques from the label noise literature. Building on this connection, we\nshow that label smoothing is competitive with loss-correction under label\nnoise. Further, we show that when distilling models from noisy data, label\nsmoothing of the teacher is beneficial; this is in contrast to recent findings\nfor noise-free problems, and sheds further light on settings where label\nsmoothing is beneficial.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:43:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Lukasik", "Michal", ""], ["Bhojanapalli", "Srinadh", ""], ["Menon", "Aditya Krishna", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2003.02821", "submitter": "Sana Tonekaboni", "authors": "Sana Tonekaboni, Shalmali Joshi, Kieran Campbell, David Duvenaud, Anna\n  Goldenberg", "title": "What went wrong and when? Instance-wise Feature Importance for\n  Time-series Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations of time series models are useful for high stakes applications\nlike healthcare but have received little attention in machine learning\nliterature. We propose FIT, a framework that evaluates the importance of\nobservations for a multivariate time-series black-box model by quantifying the\nshift in the predictive distribution over time. FIT defines the importance of\nan observation based on its contribution to the distributional shift under a\nKL-divergence that contrasts the predictive distribution against a\ncounterfactual where the rest of the features are unobserved. We also\ndemonstrate the need to control for time-dependent distribution shifts. We\ncompare with state-of-the-art baselines on simulated and real-world clinical\ndata and demonstrate that our approach is superior in identifying important\ntime points and observations throughout the time series.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:45:05 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 20:55:38 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 17:23:35 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Tonekaboni", "Sana", ""], ["Joshi", "Shalmali", ""], ["Campbell", "Kieran", ""], ["Duvenaud", "David", ""], ["Goldenberg", "Anna", ""]]}, {"id": "2003.02829", "submitter": "Wolfgang Gatterbauer", "authors": "Krishna Kumar P. and Paul Langton and Wolfgang Gatterbauer", "title": "Factorized Graph Representations for Semi-Supervised Learning from\n  Sparse Data", "comments": "SIGMOD 2020 (Extended version)", "journal-ref": null, "doi": "10.1145/3318464.3380577", "report-no": null, "categories": "cs.LG cs.DB cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node classification is an important problem in graph data management. It is\ncommonly solved by various label propagation methods that work iteratively\nstarting from a few labeled seed nodes. For graphs with arbitrary\ncompatibilities between classes, these methods crucially depend on knowing the\ncompatibility matrix that must be provided by either domain experts or\nheuristics. Can we instead directly estimate the correct compatibilities from a\nsparsely labeled graph in a principled and scalable way? We answer this\nquestion affirmatively and suggest a method called distant compatibility\nestimation that works even on extremely sparsely labeled graphs (e.g., 1 in\n10,000 nodes is labeled) in a fraction of the time it later takes to label the\nremaining nodes. Our approach first creates multiple factorized graph\nrepresentations (with size independent of the graph) and then performs\nestimation on these smaller graph sketches. We define algebraic amplification\nas the more general idea of leveraging algebraic properties of an algorithm's\nupdate equations to amplify sparse signals. We show that our estimator is by\norders of magnitude faster than an alternative approach and that the end-to-end\nclassification accuracy is comparable to using gold standard compatibilities.\nThis makes it a cheap preprocessing step for any existing label propagation\nmethod and removes the current dependence on heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:57:45 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["P.", "Krishna Kumar", ""], ["Langton", "Paul", ""], ["Gatterbauer", "Wolfgang", ""]]}, {"id": "2003.02833", "submitter": "Cen Chen", "authors": "Cen Chen, Chen Liang, Jianbin Lin, Li Wang, Ziqi Liu, Xinxing Yang,\n  Xiukun Wang, Jun Zhou, Yang Shuang, Yuan Qi", "title": "InfDetect: a Large Scale Graph-based Fraud Detection System for\n  E-Commerce Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The insurance industry has been creating innovative products around the\nemerging online shopping activities. Such e-commerce insurance is designed to\nprotect buyers from potential risks such as impulse purchases and counterfeits.\nFraudulent claims towards online insurance typically involve multiple parties\nsuch as buyers, sellers, and express companies, and they could lead to heavy\nfinancial losses. In order to uncover the relations behind organized fraudsters\nand detect fraudulent claims, we developed a large-scale insurance fraud\ndetection system, i.e., InfDetect, which provides interfaces for commonly used\ngraphs, standard data processing procedures, and a uniform graph learning\nplatform. InfDetect is able to process big graphs containing up to 100 millions\nof nodes and billions of edges. In this paper, we investigate different graphs\nto facilitate fraudster mining, such as a device-sharing graph, a transaction\ngraph, a friendship graph, and a buyer-seller graph. These graphs are fed to a\nuniform graph learning platform containing supervised and unsupervised graph\nlearning algorithms. Cases on widely applied e-commerce insurance are described\nto demonstrate the usage and capability of our system. InfDetect has\nsuccessfully detected thousands of fraudulent claims and saved over tens of\nthousands of dollars daily.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 05:43:49 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 03:51:14 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 09:24:50 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Chen", "Cen", ""], ["Liang", "Chen", ""], ["Lin", "Jianbin", ""], ["Wang", "Li", ""], ["Liu", "Ziqi", ""], ["Yang", "Xinxing", ""], ["Wang", "Xiukun", ""], ["Zhou", "Jun", ""], ["Shuang", "Yang", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.02834", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jun Zhou, Bingzhe Wu, Wenjin Fang, Li Wang, Yuan Qi,\n  Xiaolin Zheng", "title": "Practical Privacy Preserving POI Recommendation", "comments": "Accepted by ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-of-Interest (POI) recommendation has been extensively studied and\nsuccessfully applied in industry recently. However, most existing approaches\nbuild centralized models on the basis of collecting users' data. Both private\ndata and models are held by the recommender, which causes serious privacy\nconcerns. In this paper, we propose a novel Privacy preserving POI\nRecommendation (PriRec) framework. First, to protect data privacy, users'\nprivate data (features and actions) are kept on their own side, e.g., Cellphone\nor Pad. Meanwhile, the public data need to be accessed by all the users are\nkept by the recommender to reduce the storage costs of users' devices. Those\npublic data include: (1) static data only related to the status of POI, such as\nPOI categories, and (2) dynamic data depend on user-POI actions such as visited\ncounts. The dynamic data could be sensitive, and we develop local differential\nprivacy techniques to release such data to public with privacy guarantees.\nSecond, PriRec follows the representations of Factorization Machine (FM) that\nconsists of linear model and the feature interaction model. To protect the\nmodel privacy, the linear models are saved on users' side, and we propose a\nsecure decentralized gradient descent protocol for users to learn it\ncollaboratively. The feature interaction model is kept by the recommender since\nthere is no privacy risk, and we adopt secure aggregation strategy in federated\nlearning paradigm to learn it. To this end, PriRec keeps users' private raw\ndata and models in users' own hands, and protects user privacy to a large\nextent. We apply PriRec in real-world datasets, and comprehensive experiments\ndemonstrate that, compared with FM, PriRec achieves comparable or even better\nrecommendation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 06:06:40 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 06:11:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chen", "Chaochao", ""], ["Zhou", "Jun", ""], ["Wu", "Bingzhe", ""], ["Fang", "Wenjin", ""], ["Wang", "Li", ""], ["Qi", "Yuan", ""], ["Zheng", "Xiaolin", ""]]}, {"id": "2003.02836", "submitter": "Kazi Nazmul Haque", "authors": "Kazi Nazmul Haque, Rajib Rana, John H. L. Hansen, Bj\\\"orn Schuller", "title": "Guided Generative Adversarial Neural Network for Representation Learning\n  and High Fidelity Audio Generation using Fewer Labelled Audio Data", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent improvements in Generative Adversarial Neural Networks (GANs) have\nshown their ability to generate higher quality samples as well as to learn good\nrepresentations for transfer learning. Most of the representation learning\nmethods based on GANs learn representations ignoring their post-use scenario,\nwhich can lead to increased generalisation ability. However, the model can\nbecome redundant if it is intended for a specific task. For example, assume we\nhave a vast unlabelled audio dataset, and we want to learn a representation\nfrom this dataset so that it can be used to improve the emotion recognition\nperformance of a small labelled audio dataset. During the representation\nlearning training, if the model does not know the post emotion recognition\ntask, it can completely ignore emotion-related characteristics in the learnt\nrepresentation. This is a fundamental challenge for any unsupervised\nrepresentation learning model. In this paper, we aim to address this challenge\nby proposing a novel GAN framework: Guided Generative Neural Network (GGAN),\nwhich guides a GAN to focus on learning desired representations and generating\nsuperior quality samples for audio data leveraging fewer labelled samples.\nExperimental results show that using a very small amount of labelled data as\nguidance, a GGAN learns significantly better representations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 11:01:33 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 12:05:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Haque", "Kazi Nazmul", ""], ["Rana", "Rajib", ""], ["Hansen", "John H. L.", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "2003.02837", "submitter": "Claudio Zito", "authors": "Claudio Zito, Fabio Tesser, Mauro Nicolao, Piero Cosi", "title": "Statistical Context-Dependent Units Boundary Correction for Corpus-based\n  Unit-Selection Text-to-Speech", "comments": "isbn:978-88-7870-619-4", "journal-ref": "In Proc. of 7th Conference of Associazione Italiana di Scienze\n  della Voce, pp. 392:403, 2011", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, we present an innovative technique for speaker adaptation in\norder to improve the accuracy of segmentation with application to\nunit-selection Text-To-Speech (TTS) systems. Unlike conventional techniques for\nspeaker adaptation, which attempt to improve the accuracy of the segmentation\nusing acoustic models that are more robust in the face of the speaker's\ncharacteristics, we aim to use only context dependent characteristics\nextrapolated with linguistic analysis techniques. In simple terms, we use the\nintuitive idea that context dependent information is tightly correlated with\nthe related acoustic waveform. We propose a statistical model, which predicts\ncorrecting values to reduce the systematic error produced by a state-of-the-art\nHidden Markov Model (HMM) based speech segmentation. Our approach consists of\ntwo phases: (1) identifying context-dependent phonetic unit classes (for\ninstance, the class which identifies vowels as being the nucleus of\nmonosyllabic words); and (2) building a regression model that associates the\nmean error value made by the ASR during the segmentation of a single speaker\ncorpus to each class. The success of the approach is evaluated by comparing the\ncorrected boundaries of units and the state-of-the-art HHM segmentation against\na reference alignment, which is supposed to be the optimal solution. In\nconclusion, our work supplies a first analysis of a model sensitive to\nspeaker-dependent characteristics, robust to defective and noisy information,\nand a very simple implementation which could be utilized as an alternative to\neither more expensive speaker-adaptation systems or of numerous manual\ncorrection sessions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:42:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 15:52:05 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zito", "Claudio", ""], ["Tesser", "Fabio", ""], ["Nicolao", "Mauro", ""], ["Cosi", "Piero", ""]]}, {"id": "2003.02838", "submitter": "Suyog Gupta", "authors": "Suyog Gupta, Berkin Akin", "title": "Accelerator-aware Neural Network Design using AutoML", "comments": "Accepted paper at the On-device Intelligence Workshop at MLSys\n  Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural network hardware accelerators provide a substantial amount of\nraw compute throughput, the models deployed on them must be co-designed for the\nunderlying hardware architecture to obtain the optimal system performance. We\npresent a class of computer vision models designed using hardware-aware neural\narchitecture search and customized to run on the Edge TPU, Google's neural\nnetwork hardware accelerator for low-power, edge devices. For the Edge TPU in\nCoral devices, these models enable real-time image classification performance\nwhile achieving accuracy typically seen only with larger, compute-heavy models\nrunning in data centers. On Pixel 4's Edge TPU, these models improve the\naccuracy-latency tradeoff over existing SoTA mobile models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 21:34:22 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Gupta", "Suyog", ""], ["Akin", "Berkin", ""]]}, {"id": "2003.02870", "submitter": "Mihaela Dimovska", "authors": "Mihaela Dimovska, Donatello Materassi", "title": "An algorithm for reconstruction of triangle-free linear dynamic networks\n  with verification of correctness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing a network of dynamic systems from observational data is an\nactive area of research. Many approaches guarantee a consistent reconstruction\nunder the relatively strong assumption that the network dynamics is governed by\nstrictly causal transfer functions. However, in many practical scenarios,\nstrictly causal models are not adequate to describe the system and it is\nnecessary to consider models with dynamics that include direct feedthrough\nterms. In presence of direct feedthroughs, guaranteeing a consistent\nreconstruction is a more challenging task. Indeed, under no additional\nassumptions on the network, we prove that, even in the limit of infinite data,\nany reconstruction method is susceptible to inferring edges that do not exist\nin the true network (false positives) or not detecting edges that are present\nin the network (false negative). However, for a class of triangle-free networks\nintroduced in this article, some consistency guarantees can be provided. We\npresent a method that either exactly recovers the topology of a triangle-free\nnetwork certifying its correctness or outputs a graph that is sparser than the\ntopology of the actual network, specifying that such a graph has no false\npositives, but there are false negatives.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:10:29 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 19:10:29 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Dimovska", "Mihaela", ""], ["Materassi", "Donatello", ""]]}, {"id": "2003.02873", "submitter": "Aur\\'elien Bibaut", "authors": "Aur\\'elien F. Bibaut, Antoine Chambaz, Mark J. van der Laan", "title": "Generalized Policy Elimination: an efficient algorithm for Nonparametric\n  Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Generalized Policy Elimination (GPE) algorithm, an\noracle-efficient contextual bandit (CB) algorithm inspired by the Policy\nElimination algorithm of \\cite{dudik2011}. We prove the first regret optimality\nguarantee theorem for an oracle-efficient CB algorithm competing against a\nnonparametric class with infinite VC-dimension. Specifically, we show that GPE\nis regret-optimal (up to logarithmic factors) for policy classes with\nintegrable entropy. For classes with larger entropy, we show that the core\ntechniques used to analyze GPE can be used to design an $\\varepsilon$-greedy\nalgorithm with regret bound matching that of the best algorithms to date. We\nillustrate the applicability of our algorithms and theorems with examples of\nlarge nonparametric policy classes, for which the relevant optimization oracles\ncan be efficiently implemented.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:11:29 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Bibaut", "Aur\u00e9lien F.", ""], ["Chambaz", "Antoine", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "2003.02894", "submitter": "Esther Derman", "authors": "Esther Derman and Shie Mannor", "title": "Distributional Robustness and Regularization in Reinforcement Learning", "comments": "Accepted at the \"Theoretical Foundations of Reinforcement Learning\"\n  Workshop - ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributionally Robust Optimization (DRO) has enabled to prove the\nequivalence between robustness and regularization in classification and\nregression, thus providing an analytical reason why regularization generalizes\nwell in statistical learning. Although DRO's extension to sequential\ndecision-making overcomes $\\textit{external uncertainty}$ through the robust\nMarkov Decision Process (MDP) setting, the resulting formulation is hard to\nsolve, especially on large domains. On the other hand, existing regularization\nmethods in reinforcement learning only address $\\textit{internal uncertainty}$\ndue to stochasticity. Our study aims to facilitate robust reinforcement\nlearning by establishing a dual relation between robust MDPs and\nregularization. We introduce Wasserstein distributionally robust MDPs and prove\nthat they hold out-of-sample performance guarantees. Then, we introduce a new\nregularizer for empirical value functions and show that it lower bounds the\nWasserstein distributionally robust value function. We extend the result to\nlinear value function approximation for large state spaces. Our approach\nprovides an alternative formulation of robustness with guaranteed finite-sample\nperformance. Moreover, it suggests using regularization as a practical tool for\ndealing with $\\textit{external uncertainty}$ in reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:56:23 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 06:01:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Derman", "Esther", ""], ["Mannor", "Shie", ""]]}, {"id": "2003.02911", "submitter": "Juan Ignacio Perotti", "authors": "Juan I. Perotti, Nahuel Almeira, Fabio Saracco", "title": "Towards a generalization of information theory for hierarchical\n  partitions", "comments": "6 figures", "journal-ref": "Phys. Rev. E 101, 062148 (2020)", "doi": "10.1103/PhysRevE.101.062148", "report-no": null, "categories": "cs.IT cond-mat.stat-mech cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems often exhibit multiple levels of organization covering a wide\nrange of physical scales, so the study of the hierarchical decomposition of\ntheir structure and function is frequently convenient. To better understand\nthis phenomenon, we introduce a generalization of information theory that works\nwith hierarchical partitions. We begin revisiting the recently introduced\nHierarchical Mutual Information (HMI), and show that it can be written as a\nlevel by level summation of classical conditional mutual information terms.\nThen, we prove that the HMI is bounded from above by the corresponding\nhierarchical joint entropy. In this way, in analogy to the classical case, we\nderive hierarchical generalizations of many other classical\ninformation-theoretic quantities. In particular, we prove that, as opposed to\nits classical counterpart, the hierarchical generalization of the Variation of\nInformation is not a metric distance, but it admits a transformation into one.\nMoreover, focusing on potential applications of the existing developments of\nthe theory, we show how to adjust by chance the HMI. We also corroborate and\nanalyze all the presented theoretical results with exhaustive numerical\ncomputations, and include an illustrative application example of the introduced\nformalism. Finally, we mention some open problems that should be eventually\naddressed for the proposed generalization of information theory to reach\nmaturity.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 11:47:45 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 22:11:19 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Perotti", "Juan I.", ""], ["Almeira", "Nahuel", ""], ["Saracco", "Fabio", ""]]}, {"id": "2003.02920", "submitter": "Ding Xia", "authors": "Xi Yang, Ding Xia, Taichi Kin, Takeo Igarashi", "title": "IntrA: 3D Intracranial Aneurysm Dataset for Deep Learning", "comments": "Accepted by cvpr2020, camera-ready version will be uploaded later", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medicine is an important application area for deep learning models. Research\nin this field is a combination of medical expertise and data science knowledge.\nIn this paper, instead of 2D medical images, we introduce an open-access 3D\nintracranial aneurysm dataset, IntrA, that makes the application of\npoints-based and mesh-based classification and segmentation models available.\nOur dataset can be used to diagnose intracranial aneurysms and to extract the\nneck for a clipping operation in medicine and other areas of deep learning,\nsuch as normal estimation and surface reconstruction. We provide a large-scale\nbenchmark of classification and part segmentation by testing state-of-the-art\nnetworks. We also discuss the performance of each method and demonstrate the\nchallenges of our dataset. The published dataset can be accessed here:\nhttps://github.com/intra3d2019/IntrA.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 05:21:53 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 08:09:59 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yang", "Xi", ""], ["Xia", "Ding", ""], ["Kin", "Taichi", ""], ["Igarashi", "Takeo", ""]]}, {"id": "2003.02929", "submitter": "Aliaksandr Hubin", "authors": "Aliaksandr Hubin, Geir Storvik, Florian Frommlet", "title": "Flexible Bayesian Nonlinear Model Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression models are used in a wide range of applications providing a\npowerful scientific tool for researchers from different fields. Linear models\nare often not sufficient to describe the complex relationship between input\nvariables and a response. This relationship can be better described by\nnon-linearities and complex functional interactions. Deep learning models have\nbeen extremely successful in terms of prediction although they are often\ndifficult to specify and potentially suffer from overfitting. In this paper, we\nintroduce a class of Bayesian generalized nonlinear regression models with a\ncomprehensive non-linear feature space. Non-linear features are generated\nhierarchically, similarly to deep learning, but have additional flexibility on\nthe possible types of features to be considered. This flexibility, combined\nwith variable selection, allows us to find a small set of important features\nand thereby more interpretable models. A genetically modified Markov chain\nMonte Carlo algorithm is developed to make inference. Model averaging is also\npossible within our framework. In various applications, we illustrate how our\napproach is used to obtain meaningful non-linear models. Additionally, we\ncompare its predictive performance with a number of machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 21:20:55 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Hubin", "Aliaksandr", ""], ["Storvik", "Geir", ""], ["Frommlet", "Florian", ""]]}, {"id": "2003.02932", "submitter": "Aldo Pacchiano", "authors": "Aldo Pacchiano, Heinrich Jiang, Michael I. Jordan", "title": "Robustness Guarantees for Mode Estimation with an Application to Bandits", "comments": "12 pages, 7 figures, 14 appendix pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode estimation is a classical problem in statistics with a wide range of\napplications in machine learning. Despite this, there is little understanding\nin its robustness properties under possibly adversarial data contamination. In\nthis paper, we give precise robustness guarantees as well as privacy guarantees\nunder simple randomization. We then introduce a theory for multi-armed bandits\nwhere the values are the modes of the reward distributions instead of the mean.\nWe prove regret guarantees for the problems of top arm identification, top\nm-arms identification, contextual modal bandits, and infinite continuous arms\ntop arm recovery. We show in simulations that our algorithms are robust to\nperturbation of the arms by adversarial noise sequences, thus rendering modal\nbandits an attractive choice in situations where the rewards may have outliers\nor adversarial corruptions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 21:29:27 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Pacchiano", "Aldo", ""], ["Jiang", "Heinrich", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2003.02944", "submitter": "Haowen Fang", "authors": "Haowen Fang, Amar Shrestha, Ziyi Zhao, Qinru Qiu", "title": "Exploiting Neuron and Synapse Filter Dynamics in Spatial Temporal\n  Learning of Deep Spiking Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent discovered spatial-temporal information processing capability of\nbio-inspired Spiking neural networks (SNN) has enabled some interesting models\nand applications. However designing large-scale and high-performance model is\nyet a challenge due to the lack of robust training algorithms. A bio-plausible\nSNN model with spatial-temporal property is a complex dynamic system. Each\nsynapse and neuron behave as filters capable of preserving temporal\ninformation. As such neuron dynamics and filter effects are ignored in existing\ntraining algorithms, the SNN downgrades into a memoryless system and loses the\nability of temporal signal processing. Furthermore, spike timing plays an\nimportant role in information representation, but conventional rate-based spike\ncoding models only consider spike trains statistically, and discard information\ncarried by its temporal structures. To address the above issues, and exploit\nthe temporal dynamics of SNNs, we formulate SNN as a network of infinite\nimpulse response (IIR) filters with neuron nonlinearity. We proposed a training\nalgorithm that is capable to learn spatial-temporal patterns by searching for\nthe optimal synapse filter kernels and weights. The proposed model and training\nalgorithm are applied to construct associative memories and classifiers for\nsynthetic and public datasets including MNIST, NMNIST, DVS 128 etc.; and their\naccuracy outperforms state-of-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:27:39 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 03:39:24 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fang", "Haowen", ""], ["Shrestha", "Amar", ""], ["Zhao", "Ziyi", ""], ["Qiu", "Qinru", ""]]}, {"id": "2003.02960", "submitter": "Aditya Golatkar", "authors": "Aditya Golatkar, Alessandro Achille, Stefano Soatto", "title": "Forgetting Outside the Box: Scrubbing Deep Networks of Information\n  Accessible from Input-Output Observations", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a procedure for removing dependency on a cohort of training data\nfrom a trained deep network that improves upon and generalizes previous methods\nto different readout functions and can be extended to ensure forgetting in the\nactivations of the network. We introduce a new bound on how much information\ncan be extracted per query about the forgotten cohort from a black-box network\nfor which only the input-output behavior is observed. The proposed forgetting\nprocedure has a deterministic part derived from the differential equations of a\nlinearized version of the model, and a stochastic part that ensures information\ndestruction by adding noise tailored to the geometry of the loss landscape. We\nexploit the connections between the activation and weight dynamics of a DNN\ninspired by Neural Tangent Kernels to compute the information in the\nactivations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 23:17:35 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 06:52:59 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 02:23:28 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Golatkar", "Aditya", ""], ["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "2003.02977", "submitter": "Zhisheng Xiao", "authors": "Zhisheng Xiao, Qing Yan, Yali Amit", "title": "Likelihood Regret: An Out-of-Distribution Detection Score For\n  Variational Auto-encoder", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep probabilistic generative models enable modeling the likelihoods of very\nhigh dimensional data. An important application of generative modeling should\nbe the ability to detect out-of-distribution (OOD) samples by setting a\nthreshold on the likelihood. However, some recent studies show that\nprobabilistic generative models can, in some cases, assign higher likelihoods\non certain types of OOD samples, making the OOD detection rules based on\nlikelihood threshold problematic. To address this issue, several OOD detection\nmethods have been proposed for deep generative models. In this paper, we make\nthe observation that many of these methods fail when applied to generative\nmodels based on Variational Auto-encoders (VAE). As an alternative, we propose\nLikelihood Regret, an efficient OOD score for VAEs. We benchmark our proposed\nmethod over existing approaches, and empirical results suggest that our method\nobtains the best overall OOD detection performances when applied to VAEs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 00:30:38 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 03:03:08 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 21:58:14 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xiao", "Zhisheng", ""], ["Yan", "Qing", ""], ["Amit", "Yali", ""]]}, {"id": "2003.02981", "submitter": "Chen Dan", "authors": "Avrim Blum, Chen Dan, Saeed Seddighin", "title": "Learning Complexity of Simulated Annealing", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulated annealing is an effective and general means of optimization. It is\nin fact inspired by metallurgy, where the temperature of a material determines\nits behavior in thermodynamics. Likewise, in simulated annealing, the actions\nthat the algorithm takes depend entirely on the value of a variable which\ncaptures the notion of temperature. Typically, simulated annealing starts with\na high temperature, which makes the algorithm pretty unpredictable, and\ngradually cools the temperature down to become more stable.\n  A key component that plays a crucial role in the performance of simulated\nannealing is the criteria under which the temperature changes namely, the\ncooling schedule. Motivated by this, we study the following question in this\nwork: \"Given enough samples to the instances of a specific class of\noptimization problems, can we design optimal (or approximately optimal) cooling\nschedules that minimize the runtime or maximize the success rate of the\nalgorithm on average when the underlying problem is drawn uniformly at random\nfrom the same class?\"\n  We provide positive results both in terms of sample complexity and simulation\ncomplexity. For sample complexity, we show that $\\tilde O(\\sqrt{m})$ samples\nsuffice to find an approximately optimal cooling schedule of length $m$. We\ncomplement this result by giving a lower bound of $\\tilde \\Omega(m^{1/3})$ on\nthe sample complexity of any learning algorithm that provides an almost optimal\ncooling schedule. These results are general and rely on no assumption. For\nsimulation complexity, however, we make additional assumptions to measure the\nsuccess rate of an algorithm. To this end, we introduce the monotone stationary\ngraph that models the performance of simulated annealing. Based on this model,\nwe present polynomial time algorithms with provable guarantees for the learning\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 00:49:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 21:17:37 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Blum", "Avrim", ""], ["Dan", "Chen", ""], ["Seddighin", "Saeed", ""]]}, {"id": "2003.03021", "submitter": "Kai Jia", "authors": "Kai Jia, Martin Rinard", "title": "Exploiting Verified Neural Networks via Floating Point Numerical Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to reliably characterize the robustness of deep neural\nnetworks, researchers have developed verification algorithms for deep neural\nnetworks. Given a neural network, the verifiers aim to answer whether certain\nproperties are guaranteed with respect to all inputs in a space. However,\nlittle attention has been paid to floating point numerical error in neural\nnetwork verification.\n  We show that the negligence of floating point error is easily exploitable in\npractice. For a pretrained neural network, we present a method that efficiently\nsearches inputs regarding which a complete verifier incorrectly claims the\nnetwork is robust. We also present a method to construct neural network\narchitectures and weights that induce wrong results of an incomplete verifier.\nOur results highlight that, to achieve practically reliable verification of\nneural networks, any verification system must accurately (or conservatively)\nmodel the effects of any floating point computations in the network inference\nor verification system.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 03:58:26 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 08:24:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jia", "Kai", ""], ["Rinard", "Martin", ""]]}, {"id": "2003.03028", "submitter": "Stephen Wu", "authors": "Yong Huang, Haoyu Zhang, Hui Li, Stephen Wu", "title": "Recovering compressed images for automatic crack segmentation using\n  generative models", "comments": "34 pages, 15 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.ymssp.2020.107061", "report-no": null, "categories": "eess.IV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a structural health monitoring (SHM) system that uses digital cameras to\nmonitor cracks of structural surfaces, techniques for reliable and effective\ndata compression are essential to ensure a stable and energy efficient crack\nimages transmission in wireless devices, e.g., drones and robots with high\ndefinition cameras installed. Compressive sensing (CS) is a signal processing\ntechnique that allows accurate recovery of a signal from a sampling rate much\nsmaller than the limitation of the Nyquist sampling theorem. The conventional\nCS method is based on the principle that, through a regularized optimization,\nthe sparsity property of the original signals in some domain can be exploited\nto get the exact reconstruction with a high probability. However, the strong\nassumption of the signals being highly sparse in an invertible space is\nrelatively hard for real crack images. In this paper, we present a new approach\nof CS that replaces the sparsity regularization with a generative model that is\nable to effectively capture a low dimension representation of targeted images.\nWe develop a recovery framework for automatic crack segmentation of compressed\ncrack images based on this new CS method and demonstrate the remarkable\nperformance of the method taking advantage of the strong capability of\ngenerative models to capture the necessary features required in the crack\nsegmentation task even the backgrounds of the generated images are not well\nreconstructed. The superior performance of our recovery framework is\nillustrated by comparing with three existing CS algorithms. Furthermore, we\nshow that our framework is extensible to other common problems in automatic\ncrack segmentation, such as defect recovery from motion blurring and occlusion.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 04:48:05 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Huang", "Yong", ""], ["Zhang", "Haoyu", ""], ["Li", "Hui", ""], ["Wu", "Stephen", ""]]}, {"id": "2003.03033", "submitter": "Davis Blalock", "authors": "Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, John\n  Guttag", "title": "What is the State of Neural Network Pruning?", "comments": "Published in Proceedings of Machine Learning and Systems 2020 (MLSys\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning---the task of reducing the size of a network by\nremoving parameters---has been the subject of a great deal of work in recent\nyears. We provide a meta-analysis of the literature, including an overview of\napproaches to pruning and consistent findings in the literature. After\naggregating results across 81 papers and pruning hundreds of models in\ncontrolled conditions, our clearest finding is that the community suffers from\na lack of standardized benchmarks and metrics. This deficiency is substantial\nenough that it is hard to compare pruning techniques to one another or\ndetermine how much progress the field has made over the past three decades. To\naddress this situation, we identify issues with current practices, suggest\nconcrete remedies, and introduce ShrinkBench, an open-source framework to\nfacilitate standardized evaluations of pruning methods. We use ShrinkBench to\ncompare various pruning techniques and show that its comprehensive evaluation\ncan prevent common pitfalls when comparing pruning methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:06:12 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Blalock", "Davis", ""], ["Ortiz", "Jose Javier Gonzalez", ""], ["Frankle", "Jonathan", ""], ["Guttag", "John", ""]]}, {"id": "2003.03042", "submitter": "Jiabei Yang", "authors": "Jiabei Yang, Issa J. Dahabreh and Jon A. Steingrimsson", "title": "Causal Interaction Trees: Tree-Based Subgroup Identification for\n  Observational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Causal Interaction Trees for identifying subgroups of participants\nthat have enhanced treatment effects using observational data. We extend the\nClassification and Regression Tree algorithm by using splitting criteria that\nfocus on maximizing between-group treatment effect heterogeneity based on\nsubgroup-specific treatment effect estimators to dictate decision-making in the\nalgorithm. We derive properties of three subgroup-specific treatment effect\nestimators that account for the observational nature of the data -- inverse\nprobability weighting, g-formula and doubly robust estimators. We study the\nperformance of the proposed algorithms using simulations and implement the\nalgorithms in an observational study that evaluates the effectiveness of right\nheart catheterization on critically ill patients.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:51:27 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Yang", "Jiabei", ""], ["Dahabreh", "Issa J.", ""], ["Steingrimsson", "Jon A.", ""]]}, {"id": "2003.03051", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Peilin Zhao, Qingyao Wu, Bin Li, Junzhou Huang, and\n  Mingkui Tan", "title": "Cost-Sensitive Portfolio Selection via Deep Reinforcement Learning", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio Selection is an important real-world financial task and has\nattracted extensive attention in artificial intelligence communities. This\ntask, however, has two main difficulties: (i) the non-stationary price series\nand complex asset correlations make the learning of feature representation very\nhard; (ii) the practicality principle in financial markets requires controlling\nboth transaction and risk costs. Most existing methods adopt handcraft features\nand/or consider no constraints for the costs, which may make them perform\nunsatisfactorily and fail to control both costs in practice. In this paper, we\npropose a cost-sensitive portfolio selection method with deep reinforcement\nlearning. Specifically, a novel two-stream portfolio policy network is devised\nto extract both price series patterns and asset correlations, while a new\ncost-sensitive reward function is developed to maximize the accumulated return\nand constrain both costs via reinforcement learning. We theoretically analyze\nthe near-optimality of the proposed reward, which shows that the growth rate of\nthe policy regarding this reward function can approach the theoretical optimum.\nWe also empirically evaluate the proposed method on real-world datasets.\nPromising results demonstrate the effectiveness and superiority of the proposed\nmethod in terms of profitability, cost-sensitivity and representation\nabilities.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 06:28:17 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Zhang", "Yifan", ""], ["Zhao", "Peilin", ""], ["Wu", "Qingyao", ""], ["Li", "Bin", ""], ["Huang", "Junzhou", ""], ["Tan", "Mingkui", ""]]}, {"id": "2003.03076", "submitter": "Arthur Denouveaux", "authors": "Rachid Guennouni Hassani (X), Alexis Gilles, Emmanuel Lassalle, Arthur\n  D\\'enouveaux", "title": "Predicting Stock Returns with Batched AROW", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the AROW regression algorithm developed by Vaits and Crammer in\n[VC11] to handle synchronous mini-batch updates and apply it to stock return\nprediction. By design, the model should be more robust to noise and adapt\nbetter to non-stationarity compared to a simple rolling regression. We\nempirically show that the new model outperforms more classical approaches by\nbacktesting a strategy on S\\&P500 stocks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 08:42:12 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 07:55:19 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Hassani", "Rachid Guennouni", "", "X"], ["Gilles", "Alexis", ""], ["Lassalle", "Emmanuel", ""], ["D\u00e9nouveaux", "Arthur", ""]]}, {"id": "2003.03080", "submitter": "Simone Rossi", "authors": "Simone Rossi and Markus Heinonen and Edwin V. Bonilla and Zheyang Shen\n  and Maurizio Filippone", "title": "Sparse Gaussian Processes Revisited: Bayesian Approaches to\n  Inducing-Variable Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference techniques based on inducing variables provide an\nelegant framework for scalable posterior estimation in Gaussian process (GP)\nmodels. Besides enabling scalability, one of their main advantages over sparse\napproximations using direct marginal likelihood maximization is that they\nprovide a robust alternative for point estimation of the inducing inputs, i.e.\nthe location of the inducing variables. In this work we challenge the common\nwisdom that optimizing the inducing inputs in the variational framework yields\noptimal performance. We show that, by revisiting old model approximations such\nas the fully-independent training conditionals endowed with powerful\nsampling-based inference methods, treating both inducing locations and GP\nhyper-parameters in a Bayesian way can improve performance significantly. Based\non stochastic gradient Hamiltonian Monte Carlo, we develop a fully Bayesian\napproach to scalable GP and deep GP models, and demonstrate its\nstate-of-the-art performance through an extensive experimental campaign across\nseveral regression and classification problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 08:53:18 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 21:59:27 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 08:50:07 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 13:22:25 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rossi", "Simone", ""], ["Heinonen", "Markus", ""], ["Bonilla", "Edwin V.", ""], ["Shen", "Zheyang", ""], ["Filippone", "Maurizio", ""]]}, {"id": "2003.03123", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Janek Gro{\\ss}, Stephan G\\\"unnemann", "title": "Directional Message Passing for Molecular Graphs", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have recently achieved great successes in predicting\nquantum mechanical properties of molecules. These models represent a molecule\nas a graph using only the distance between atoms (nodes). They do not, however,\nconsider the spatial direction from one atom to another, despite directional\ninformation playing a central role in empirical potentials for molecules, e.g.\nin angular potentials. To alleviate this limitation we propose directional\nmessage passing, in which we embed the messages passed between atoms instead of\nthe atoms themselves. Each message is associated with a direction in coordinate\nspace. These directional message embeddings are rotationally equivariant since\nthe associated directions rotate with the molecule. We propose a message\npassing scheme analogous to belief propagation, which uses the directional\ninformation by transforming messages based on the angle between them.\nAdditionally, we use spherical Bessel functions and spherical harmonics to\nconstruct theoretically well-founded, orthogonal representations that achieve\nbetter performance than the currently prevalent Gaussian radial basis\nrepresentations while using fewer than 1/4 of the parameters. We leverage these\ninnovations to construct the directional message passing neural network\n(DimeNet). DimeNet outperforms previous GNNs on average by 76% on MD17 and by\n31% on QM9. Our implementation is available online.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 10:30:17 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Klicpera", "Johannes", ""], ["Gro\u00df", "Janek", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2003.03124", "submitter": "Karol Gregor", "authors": "Karol Gregor", "title": "Finding online neural update rules by learning to remember", "comments": "11 Pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate learning of the online local update rules for neural\nactivations (bodies) and weights (synapses) from scratch. We represent the\nstates of each weight and activation by small vectors, and parameterize their\nupdates using (meta-) neural networks. Different neuron types are represented\nby different embedding vectors which allows the same two functions to be used\nfor all neurons. Instead of training directly for the objective using evolution\nor long term back-propagation, as is commonly done in similar systems, we\nmotivate and study a different objective: That of remembering past snippets of\nexperience. We explain how this objective relates to standard back-propagation\ntraining and other forms of learning. We train for this objective using short\nterm back-propagation and analyze the performance as a function of both the\ndifferent network types and the difficulty of the problem. We find that this\nanalysis gives interesting insights onto what constitutes a learning rule. We\nalso discuss how such system could form a natural substrate for addressing\ntopics such as episodic memories, meta-learning and auxiliary objectives.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 10:31:30 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Gregor", "Karol", ""]]}, {"id": "2003.03125", "submitter": "Radha Kopparti", "authors": "Radha Kopparti, Tillman Weyde", "title": "Weight Priors for Learning Identity Relations", "comments": "Proceedings of KR2ML @ NeurIPS 2019, Vancouver, Canada", "journal-ref": "Proceedings of KR2ML @ NeurIPS 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning abstract and systematic relations has been an open issue in neural\nnetwork learning for over 30 years. It has been shown recently that neural\nnetworks do not learn relations based on identity and are unable to generalize\nwell to unseen data. The Relation Based Pattern (RBP) approach has been\nproposed as a solution for this problem. In this work, we extend RBP by\nrealizing it as a Bayesian prior on network weights to model the identity\nrelations. This weight prior leads to a modified regularization term in\notherwise standard network learning. In our experiments, we show that the\nBayesian weight priors lead to perfect generalization when learning identity\nbased relations and do not impede general neural network learning. We believe\nthat the approach of creating an inductive bias with weight priors can be\nextended easily to other forms of relations and will be beneficial for many\nother learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 10:32:03 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 20:13:52 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Kopparti", "Radha", ""], ["Weyde", "Tillman", ""]]}, {"id": "2003.03143", "submitter": "Liyuan Wang", "authors": "Liyuan Wang, Bo Lei, Qian Li, Hang Su, Jun Zhu, Yi Zhong", "title": "Triple Memory Networks: a Brain-Inspired Method for Continual Learning", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual acquisition of novel experience without interfering previously\nlearned knowledge, i.e. continual learning, is critical for artificial neural\nnetworks, but limited by catastrophic forgetting. A neural network adjusts its\nparameters when learning a new task, but then fails to conduct the old tasks\nwell. By contrast, the brain has a powerful ability to continually learn new\nexperience without catastrophic interference. The underlying neural mechanisms\npossibly attribute to the interplay of hippocampus-dependent memory system and\nneocortex-dependent memory system, mediated by prefrontal cortex. Specifically,\nthe two memory systems develop specialized mechanisms to consolidate\ninformation as more specific forms and more generalized forms, respectively,\nand complement the two forms of information in the interplay. Inspired by such\nbrain strategy, we propose a novel approach named triple memory networks (TMNs)\nfor continual learning. TMNs model the interplay of hippocampus, prefrontal\ncortex and sensory cortex (a neocortex region) as a triple-network architecture\nof generative adversarial networks (GAN). The input information is encoded as\nspecific representation of the data distributions in a generator, or\ngeneralized knowledge of solving tasks in a discriminator and a classifier,\nwith implementing appropriate brain-inspired algorithms to alleviate\ncatastrophic forgetting in each module. Particularly, the generator replays\ngenerated data of the learned tasks to the discriminator and the classifier,\nboth of which are implemented with a weight consolidation regularizer to\ncomplement the lost information in generation process. TMNs achieve new\nstate-of-the-art performance on a variety of class-incremental learning\nbenchmarks on MNIST, SVHN, CIFAR-10 and ImageNet-50, comparing with strong\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 11:35:24 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Wang", "Liyuan", ""], ["Lei", "Bo", ""], ["Li", "Qian", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""], ["Zhong", "Yi", ""]]}, {"id": "2003.03172", "submitter": "Tapajit Dey", "authors": "Tapajit Dey, Sara Mousavi, Eduardo Ponce, Tanner Fry, Bogdan\n  Vasilescu, Anna Filippova, Audris Mockus", "title": "Detecting and Characterizing Bots that Commit Code", "comments": "Preprint of the paper accepted in MSR, 2020 conference", "journal-ref": null, "doi": "10.1145/3379597.3387478", "report-no": null, "categories": "cs.SE cs.CR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Some developer activity traditionally performed manually, such as\nmaking code commits, opening, managing, or closing issues is increasingly\nsubject to automation in many OSS projects. Specifically, such activity is\noften performed by tools that react to events or run at specific times. We\nrefer to such automation tools as bots and, in many software mining scenarios\nrelated to developer productivity or code quality it is desirable to identify\nbots in order to separate their actions from actions of individuals. Aim: Find\nan automated way of identifying bots and code committed by these bots, and to\ncharacterize the types of bots based on their activity patterns. Method and\nResult: We propose BIMAN, a systematic approach to detect bots using author\nnames, commit messages, files modified by the commit, and projects associated\nwith the ommits. For our test data, the value for AUC-ROC was 0.9. We also\ncharacterized these bots based on the time patterns of their code commits and\nthe types of files modified, and found that they primarily work with\ndocumentation files and web pages, and these files are most prevalent in HTML\nand JavaScript ecosystems. We have compiled a shareable dataset containing\ndetailed information about 461 bots we found (all of whom have more than 1000\ncommits) and 13,762,430 commits they created.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:54:07 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 01:28:42 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 20:47:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dey", "Tapajit", ""], ["Mousavi", "Sara", ""], ["Ponce", "Eduardo", ""], ["Fry", "Tanner", ""], ["Vasilescu", "Bogdan", ""], ["Filippova", "Anna", ""], ["Mockus", "Audris", ""]]}, {"id": "2003.03179", "submitter": "Heon Song", "authors": "H. Song, N. Mitsuo, S. Uchida, D. Suehiro", "title": "No Regret Sample Selection with Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) suffer from noisy-labeled data because of the\nrisk of overfitting. To avoid the risk, in this paper, we propose a novel DNN\ntraining method with sample selection based on adaptive k-set selection, which\nselects k (< n) clean sample candidates from the whole n noisy training samples\nat each epoch. It has a strong advantage of guaranteeing the performance of the\nselection theoretically. Roughly speaking, a regret, which is defined by the\ndifference between the actual selection and the best selection, of the proposed\nmethod is theoretically bounded, even though the best selection is unknown\nuntil the end of all epochs. The experimental results on multiple noisy-labeled\ndatasets demonstrate that our sample selection strategy works effectively in\nthe DNN training; in fact, the proposed method achieved the best or the\nsecond-best performance among state-of-the-art methods, while requiring a\nsignificantly lower computational cost. The code is available at\nhttps://github.com/songheony/TAkS.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 13:17:35 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 00:59:45 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 04:27:26 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 01:49:39 GMT"}, {"version": "v5", "created": "Sun, 4 Apr 2021 15:12:40 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Song", "H.", ""], ["Mitsuo", "N.", ""], ["Uchida", "S.", ""], ["Suehiro", "D.", ""]]}, {"id": "2003.03182", "submitter": "Konstantin Kobs", "authors": "Konstantin Kobs, Michael Steininger, Albin Zehe, Florian\n  Lautenschlager, Andreas Hotho", "title": "SimLoss: Class Similarities in Cross Entropy", "comments": "This paper is going to be published in the proceedings of the 25th\n  International Symposium on Methodologies for Intelligent Systems (ISMIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One common loss function in neural network classification tasks is\nCategorical Cross Entropy (CCE), which punishes all misclassifications equally.\nHowever, classes often have an inherent structure. For instance, classifying an\nimage of a rose as \"violet\" is better than as \"truck\". We introduce SimLoss, a\ndrop-in replacement for CCE that incorporates class similarities along with two\ntechniques to construct such matrices from task-specific knowledge. We test\nSimLoss on Age Estimation and Image Classification and find that it brings\nsignificant improvements over CCE on several metrics. SimLoss therefore allows\nfor explicit modeling of background knowledge by simply exchanging the loss\nfunction, while keeping the neural network architecture the same. Code and\nadditional resources can be found at https://github.com/konstantinkobs/SimLoss.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 13:21:37 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Kobs", "Konstantin", ""], ["Steininger", "Michael", ""], ["Zehe", "Albin", ""], ["Lautenschlager", "Florian", ""], ["Hotho", "Andreas", ""]]}, {"id": "2003.03190", "submitter": "Zhongliang Guo", "authors": "Zhongliang Guo and Stephen Wu and Mitsuru Ohno and Ryo Yoshida", "title": "A Bayesian algorithm for retrosynthesis", "comments": null, "journal-ref": "J. Chem. Inf. Model. 60 (2020) 4474-4486", "doi": "10.1021/acs.jcim.0c00320", "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of synthetic routes that end with a desired product has\nbeen an inherently time-consuming process that is largely dependent on expert\nknowledge regarding a limited fraction of the entire reaction space. At\npresent, emerging machine-learning technologies are overturning the process of\nretrosynthetic planning. The objective of this study is to discover synthetic\nroutes backwardly from a given desired molecule to commercially available\ncompounds. The problem is reduced to a combinatorial optimization task with the\nsolution space subject to the combinatorial complexity of all possible pairs of\npurchasable reactants. We address this issue within the framework of Bayesian\ninference and computation. The workflow consists of two steps: a deep neural\nnetwork is trained that forwardly predicts a product of the given reactants\nwith a high level of accuracy, following which this forward model is inverted\ninto the backward one via Bayes' law of conditional probability. Using the\nbackward model, a diverse set of highly probable reaction sequences ending with\na given synthetic target is exhaustively explored using a Monte Carlo search\nalgorithm. The Bayesian retrosynthesis algorithm could successfully rediscover\n80.3% and 50.0% of known synthetic routes of single-step and two-step reactions\nwithin top-10 accuracy, respectively, thereby outperforming state-of-the-art\nalgorithms in terms of the overall accuracy. Remarkably, the Monte Carlo\nmethod, which was specifically designed for the presence of diverse multiple\nroutes, often revealed a ranked list of hundreds of reaction routes to the same\nsynthetic target. We investigated the potential applicability of such diverse\ncandidates based on expert knowledge from synthetic organic chemistry.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 13:30:30 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Guo", "Zhongliang", ""], ["Wu", "Stephen", ""], ["Ohno", "Mitsuru", ""], ["Yoshida", "Ryo", ""]]}, {"id": "2003.03196", "submitter": "Wonyong Jeong", "authors": "Jaehong Yoon, Wonyong Jeong, Giwoong Lee, Eunho Yang, Sung Ju Hwang", "title": "Federated Continual Learning with Weighted Inter-client Transfer", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of interest in continual learning and federated\nlearning, both of which are important in deep neural networks in real-world\nscenarios. Yet little research has been done regarding the scenario where each\nclient learns on a sequence of tasks from a private local data stream. This\nproblem of federated continual learning poses new challenges to continual\nlearning, such as utilizing knowledge from other clients, while preventing\ninterference from irrelevant knowledge. To resolve these issues, we propose a\nnovel federated continual learning framework, Federated Weighted Inter-client\nTransfer (FedWeIT), which decomposes the network weights into global federated\nparameters and sparse task-specific parameters, and each client receives\nselective knowledge from other clients by taking a weighted combination of\ntheir task-specific parameters. FedWeIT minimizes interference between\nincompatible tasks, and also allows positive knowledge transfer across clients\nduring learning. We validate our FedWeIT against existing federated learning\nand continual learning methods under varying degrees of task similarity across\nclients, and our model significantly outperforms them with a large reduction in\nthe communication cost. Code is available at https://github.com/wyjeong/FedWeIT\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 13:33:48 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 14:47:52 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 05:18:59 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 02:36:10 GMT"}, {"version": "v5", "created": "Mon, 14 Jun 2021 07:57:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yoon", "Jaehong", ""], ["Jeong", "Wonyong", ""], ["Lee", "Giwoong", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2003.03229", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Nicolae-Catalin Ristea,\n  Nicu Sebe", "title": "Non-linear Neurons with Human-like Apical Dendrite Activations", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to classify linearly non-separable data, neurons are typically\norganized into multi-layer neural networks that are equipped with at least one\nhidden layer. Inspired by some recent discoveries in neuroscience, we propose a\nnew neuron model along with a novel activation function enabling learning of\nnon-linear decision boundaries using a single neuron. We show that a standard\nneuron followed by the novel apical dendrite activation (ADA) can learn the XOR\nlogical function with 100% accuracy. Furthermore, we conduct experiments on\nthree benchmark data sets from computer vision and natural language processing,\ni.e. Fashion-MNIST, UTKFace and MOROCO, showing that the ADA and the leaky ADA\nfunctions provide superior results to Rectified Liner Units (ReLU) and leaky\nReLU, for various neural network architectures, e.g. 1-hidden layer or 2-hidden\nlayers multi-layer perceptrons (MLPs) and convolutional neural networks (CNNs)\nsuch as LeNet, VGG, ResNet and Character-level CNN. We also obtain further\nimprovements when we change the standard model of the neuron with our pyramidal\nneuron with apical dendrite activations (PyNADA).\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:09:39 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 06:51:38 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Ionescu", "Radu Tudor", ""], ["Ristea", "Nicolae-Catalin", ""], ["Sebe", "Nicu", ""]]}, {"id": "2003.03241", "submitter": "Theodore Papamarkou", "authors": "Theodore Papamarkou, Hayley Guy, Bryce Kroencke, Jordan Miller,\n  Preston Robinette, Daniel Schultz, Jacob Hinkle, Laura Pullum, Catherine\n  Schuman, Jeremy Renshaw, Stylianos Chatzidakis", "title": "Automated detection of corrosion in used nuclear fuel dry storage\n  canisters using residual neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nondestructive evaluation methods play an important role in ensuring\ncomponent integrity and safety in many industries. Operator fatigue can play a\ncritical role in the reliability of such methods. This is important for\ninspecting high value assets or assets with a high consequence of failure, such\nas aerospace and nuclear components. Recent advances in convolution neural\nnetworks can support and automate these inspection efforts. This paper proposes\nusing residual neural networks (ResNets) for real-time detection of corrosion,\nincluding iron oxide discoloration, pitting and stress corrosion cracking, in\ndry storage stainless steel canisters housing used nuclear fuel. The proposed\napproach crops nuclear canister images into smaller tiles, trains a ResNet on\nthese tiles, and classifies images as corroded or intact using the per-image\ncount of tiles predicted as corroded by the ResNet. The results demonstrate\nthat such a deep learning approach allows to detect the locus of corrosion via\nsmaller tiles, and at the same time to infer with high accuracy whether an\nimage comes from a corroded canister. Thereby, the proposed approach holds\npromise to automate and speed up nuclear fuel canister inspections, to minimize\ninspection costs, and to partially replace human-conducted onsite inspections,\nthus reducing radiation doses to personnel.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:42:07 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 17:24:21 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 16:06:36 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Papamarkou", "Theodore", ""], ["Guy", "Hayley", ""], ["Kroencke", "Bryce", ""], ["Miller", "Jordan", ""], ["Robinette", "Preston", ""], ["Schultz", "Daniel", ""], ["Hinkle", "Jacob", ""], ["Pullum", "Laura", ""], ["Schuman", "Catherine", ""], ["Renshaw", "Jeremy", ""], ["Chatzidakis", "Stylianos", ""]]}, {"id": "2003.03274", "submitter": "Evgenii Tsymbalov", "authors": "Evgenii Tsymbalov, Kirill Fedyanin, Maxim Panov", "title": "Dropout Strikes Back: Improved Uncertainty Estimation via Diversity\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation for machine learning models is of high importance in\nmany scenarios such as constructing the confidence intervals for model\npredictions and detection of out-of-distribution or adversarially generated\npoints. In this work, we show that modifying the sampling distributions for\ndropout layers in neural networks improves the quality of uncertainty\nestimation. Our main idea consists of two main steps: computing data-driven\ncorrelations between neurons and generating samples, which include maximally\ndiverse neurons. In a series of experiments on simulated and real-world data,\nwe demonstrate that the diversification via determinantal point processes-based\nsampling achieves state-of-the-art results in uncertainty estimation for\nregression and classification tasks. An important feature of our approach is\nthat it does not require any modification to the models or training procedures,\nallowing straightforward application to any deep learning model with dropout\nlayers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:20:04 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 07:25:58 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Tsymbalov", "Evgenii", ""], ["Fedyanin", "Kirill", ""], ["Panov", "Maxim", ""]]}, {"id": "2003.03284", "submitter": "John Bronskill", "authors": "John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin,\n  Richard E. Turner", "title": "TaskNorm: Rethinking Batch Normalization for Meta-Learning", "comments": null, "journal-ref": "Proceedings of Machine Learning and Systems 2020, 4683-4694", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern meta-learning approaches for image classification rely on increasingly\ndeep networks to achieve state-of-the-art performance, making batch\nnormalization an essential component of meta-learning pipelines. However, the\nhierarchical nature of the meta-learning setting presents several challenges\nthat can render conventional batch normalization ineffective, giving rise to\nthe need to rethink normalization in this setting. We evaluate a range of\napproaches to batch normalization for meta-learning scenarios, and develop a\nnovel approach that we call TaskNorm. Experiments on fourteen datasets\ndemonstrate that the choice of batch normalization has a dramatic effect on\nboth classification accuracy and training time for both gradient based and\ngradient-free meta-learning approaches. Importantly, TaskNorm is found to\nconsistently improve performance. Finally, we provide a set of best practices\nfor normalization that will allow fair comparison of meta-learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:43:27 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 14:09:28 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bronskill", "John", ""], ["Gordon", "Jonathan", ""], ["Requeima", "James", ""], ["Nowozin", "Sebastian", ""], ["Turner", "Richard E.", ""]]}, {"id": "2003.03290", "submitter": "Tiago Azevedo", "authors": "Tiago Azevedo, Luca Passamonti, Pietro Li\\`o, Nicola Toschi", "title": "Towards a predictive spatio-temporal representation of brain data", "comments": "To appear in the Workshop on AI for Affordable Healthcare (AI4AH) at\n  ICLR 2020. 8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterisation of the brain as a \"connectome\", in which the connections\nare represented by correlational values across timeseries and as summary\nmeasures derived from graph theory analyses, has been very popular in the last\nyears. However, although this representation has advanced our understanding of\nthe brain function, it may represent an oversimplified model. This is because\nthe typical fMRI datasets are constituted by complex and highly heterogeneous\ntimeseries that vary across space (i.e., location of brain regions). We compare\nvarious modelling techniques from deep learning and geometric deep learning to\npave the way for future research in effectively leveraging the rich spatial and\ntemporal domains of typical fMRI datasets, as well as of other similar\ndatasets. As a proof-of-concept, we compare our approaches in the homogeneous\nand publicly available Human Connectome Project (HCP) dataset on a supervised\nbinary classification task. We hope that our methodological advances relative\nto previous \"connectomic\" measures can ultimately be clinically and\ncomputationally relevant by leading to a more nuanced understanding of the\nbrain dynamics in health and disease. Such understanding of the brain can\nfundamentally reduce the constant specialised clinical expertise in order to\naccurately understand brain variability.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:49:45 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Azevedo", "Tiago", ""], ["Passamonti", "Luca", ""], ["Li\u00f2", "Pietro", ""], ["Toschi", "Nicola", ""]]}, {"id": "2003.03297", "submitter": "Jean Tarbouriech", "authors": "Jean Tarbouriech, Shubhanshu Shekhar, Matteo Pirotta, Mohammad\n  Ghavamzadeh, Alessandro Lazaric", "title": "Active Model Estimation in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficient exploration in order to learn an accurate\nmodel of an environment, modeled as a Markov decision process (MDP). Efficient\nexploration in this problem requires the agent to identify the regions in which\nestimating the model is more difficult and then exploit this knowledge to\ncollect more samples there. In this paper, we formalize this problem, introduce\nthe first algorithm to learn an $\\epsilon$-accurate estimate of the dynamics,\nand provide its sample complexity analysis. While this algorithm enjoys strong\nguarantees in the large-sample regime, it tends to have a poor performance in\nearly stages of exploration. To address this issue, we propose an algorithm\nthat is based on maximum weighted entropy, a heuristic that stems from common\nsense and our theoretical analysis. The main idea here is to cover the entire\nstate-action space with the weight proportional to the noise in the\ntransitions. Using a number of simple domains with heterogeneous noise in their\ntransitions, we show that our heuristic-based algorithm outperforms both our\noriginal algorithm and the maximum entropy algorithm in the small sample\nregime, while achieving similar asymptotic performance as that of the original\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 16:17:24 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:39:45 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tarbouriech", "Jean", ""], ["Shekhar", "Shubhanshu", ""], ["Pirotta", "Matteo", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2003.03300", "submitter": "Julien Pelamatti", "authors": "Julien Pelamatti, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi,\n  Yannick Guerin", "title": "Bayesian optimization of variable-size design space problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the framework of complex system design, it is often necessary to solve\nmixed variable optimization problems, in which the objective and constraint\nfunctions can depend simultaneously on continuous and discrete variables.\nAdditionally, complex system design problems occasionally present a\nvariable-size design space. This results in an optimization problem for which\nthe search space varies dynamically (with respect to both number and type of\nvariables) along the optimization process as a function of the values of\nspecific discrete decision variables. Similarly, the number and type of\nconstraints can vary as well. In this paper, two alternative Bayesian\nOptimization-based approaches are proposed in order to solve this type of\noptimization problems. The first one consists in a budget allocation strategy\nallowing to focus the computational budget on the most promising design\nsub-spaces. The second approach, instead, is based on the definition of a\nkernel function allowing to compute the covariance between samples\ncharacterized by partially different sets of variables. The results obtained on\nanalytical and engineering related test-cases show a faster and more consistent\nconvergence of both proposed methods with respect to the standard approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 16:30:44 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Pelamatti", "Julien", ""], ["Brevault", "Loic", ""], ["Balesdent", "Mathieu", ""], ["Talbi", "El-Ghazali", ""], ["Guerin", "Yannick", ""]]}, {"id": "2003.03320", "submitter": "Felix Sattler", "authors": "Felix Sattler, Thomas Wiegand, Wojciech Samek", "title": "Trends and Advancements in Deep Neural Network Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MM cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their great performance and scalability properties neural networks\nhave become ubiquitous building blocks of many applications. With the rise of\nmobile and IoT, these models now are also being increasingly applied in\ndistributed settings, where the owners of the data are separated by limited\ncommunication channels and privacy constraints. To address the challenges of\nthese distributed environments, a wide range of training and evaluation schemes\nhave been developed, which require the communication of neural network\nparametrizations. These novel approaches, which bring the \"intelligence to the\ndata\" have many advantages over traditional cloud solutions such as\nprivacy-preservation, increased security and device autonomy, communication\nefficiency and high training speed. This paper gives an overview over the\nrecent advancements and challenges in this new field of research at the\nintersection of machine learning and communications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 17:34:15 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Sattler", "Felix", ""], ["Wiegand", "Thomas", ""], ["Samek", "Wojciech", ""]]}, {"id": "2003.03351", "submitter": "Kaichen Zhou", "authors": "Kaichen Zhou, Shiji Song, Gao Huang, Wu Cheng, Quan Zhou", "title": "Tighter Bound Estimation of Sensitivity Analysis for Incremental and\n  Decremental Data Modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale classification problems, the data set always be faced with\nfrequent updates when a part of the data is added to or removed from the\noriginal data set. In this case, conventional incremental learning, which\nupdates an existing classifier by explicitly modeling the data modification, is\nmore efficient than retraining a new classifier from scratch. However,\nsometimes, we are more interested in determining whether we should update the\nclassifier or performing some sensitivity analysis tasks. To deal with these\nsuch tasks, we propose an algorithm to make rational inferences about the\nupdated linear classifier without exactly updating the classifier.\nSpecifically, the proposed algorithm can be used to estimate the upper and\nlower bounds of the updated classifier's coefficient matrix with a low\ncomputational complexity related to the size of the updated dataset. Both\ntheoretical analysis and experiment results show that the proposed approach is\nsuperior to existing methods in terms of tightness of coefficients' bounds and\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 18:28:26 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 12:40:29 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 05:39:39 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2021 23:26:18 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Zhou", "Kaichen", ""], ["Song", "Shiji", ""], ["Huang", "Gao", ""], ["Cheng", "Wu", ""], ["Zhou", "Quan", ""]]}, {"id": "2003.03375", "submitter": "Eric Guizzo", "authors": "Eric Guizzo, Tillman Weyde, Jack Barnett Leveson", "title": "Multi-Time-Scale Convolution for Emotion Recognition from Speech Audio\n  Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Robustness against temporal variations is important for emotion recognition\nfrom speech audio, since emotion is ex-pressed through complex spectral\npatterns that can exhibit significant local dilation and compression on the\ntime axis depending on speaker and context. To address this and potentially\nother tasks, we introduce the multi-time-scale (MTS) method to create\nflexibility towards temporal variations when analyzing time-frequency\nrepresentations of audio data. MTS extends convolutional neural networks with\nconvolution kernels that are scaled and re-sampled along the time axis, to\nincrease temporal flexibility without increasing the number of trainable\nparameters compared to standard convolutional layers. We evaluate MTS and\nstandard convolutional layers in different architectures for emotion\nrecognition from speech audio, using 4 datasets of different sizes. The results\nshow that the use of MTS layers consistently improves the generalization of\nnetworks of different capacity and depth, compared to standard convolution,\nespecially on smaller datasets\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 12:28:04 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Guizzo", "Eric", ""], ["Weyde", "Tillman", ""], ["Leveson", "Jack Barnett", ""]]}, {"id": "2003.03384", "submitter": "Esteban Real", "authors": "Esteban Real, Chen Liang, David R. So, and Quoc V. Le", "title": "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch", "comments": "Accepted for publication at the 37th International Conference on\n  Machine Learning (ICML 2020). Near camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning research has advanced in multiple aspects, including model\nstructures and learning methods. The effort to automate such research, known as\nAutoML, has also made significant progress. However, this progress has largely\nfocused on the architecture of neural networks, where it has relied on\nsophisticated expert-designed layers as building blocks---or similarly\nrestrictive search spaces. Our goal is to show that AutoML can go further: it\nis possible today to automatically discover complete machine learning\nalgorithms just using basic mathematical operations as building blocks. We\ndemonstrate this by introducing a novel framework that significantly reduces\nhuman bias through a generic search space. Despite the vastness of this space,\nevolutionary search can still discover two-layer neural networks trained by\nbackpropagation. These simple neural networks can then be surpassed by evolving\ndirectly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques\nemerge in the top algorithms, such as bilinear interactions, normalized\ngradients, and weight averaging. Moreover, evolution adapts algorithms to\ndifferent task types: e.g., dropout-like techniques appear when little data is\navailable. We believe these preliminary successes in discovering machine\nlearning algorithms from scratch indicate a promising new direction for the\nfield.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 19:00:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 04:32:44 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Real", "Esteban", ""], ["Liang", "Chen", ""], ["So", "David R.", ""], ["Le", "Quoc V.", ""]]}, {"id": "2003.03397", "submitter": "Raman Arora", "authors": "Raman Arora, Peter Bartlett, Poorya Mianjy, Nathan Srebro", "title": "Dropout: Explicit Forms and Capacity Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the capacity control provided by dropout in various machine\nlearning problems. First, we study dropout for matrix completion, where it\ninduces a data-dependent regularizer that, in expectation, equals the weighted\ntrace-norm of the product of the factors. In deep learning, we show that the\ndata-dependent regularizer due to dropout directly controls the Rademacher\ncomplexity of the underlying class of deep neural networks. These developments\nenable us to give concrete generalization error bounds for the dropout\nalgorithm in both matrix completion as well as training deep neural networks.\nWe evaluate our theoretical findings on real-world datasets, including\nMovieLens, MNIST, and Fashion-MNIST.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 19:10:15 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Arora", "Raman", ""], ["Bartlett", "Peter", ""], ["Mianjy", "Poorya", ""], ["Srebro", "Nathan", ""]]}, {"id": "2003.03426", "submitter": "Orestis Papadigenopoulos", "authors": "Soumya Basu, Orestis Papadigenopoulos, Constantine Caramanis, Sanjay\n  Shakkottai", "title": "Contextual Blocking Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a novel variant of the multi-armed bandit problem, where at each\ntime step, the player observes an independently sampled context that determines\nthe arms' mean rewards. However, playing an arm blocks it (across all contexts)\nfor a fixed and known number of future time steps. The above contextual\nsetting, which captures important scenarios such as recommendation systems or\nad placement with diverse users, invalidates greedy solution techniques that\nare effective for its non-contextual counterpart (Basu et al., NeurIPS19).\nAssuming knowledge of the context distribution and the mean reward of each\narm-context pair, we cast the problem as an online bipartite matching problem,\nwhere the right-vertices (contexts) arrive stochastically and the left-vertices\n(arms) are blocked for a finite number of rounds each time they are matched.\nThis problem has been recently studied in the full-information case, where\ncompetitive ratio bounds have been derived. We focus on the bandit setting,\nwhere the reward distributions are initially unknown; we propose a UCB-based\nvariant of the full-information algorithm that guarantees a $\\mathcal{O}(\\log\nT)$-regret w.r.t. an $\\alpha$-optimal strategy in $T$ time steps, matching the\n$\\Omega(\\log(T))$ regret lower bound in this setting. Due to the time\ncorrelations caused by blocking, existing techniques for upper bounding regret\nfail. For proving our regret bounds, we introduce the novel concepts of delayed\nexploitation and opportunistic subsampling and combine them with ideas from\ncombinatorial bandits and non-stationary Markov chains coupling.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 20:34:42 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 11:36:37 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Basu", "Soumya", ""], ["Papadigenopoulos", "Orestis", ""], ["Caramanis", "Constantine", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2003.03456", "submitter": "P Sharoff", "authors": "P Sharoff, Nishant A. Mehta, Ravi Ganti", "title": "A Farewell to Arms: Sequential Reward Maximization on a Budget with a\n  Giving Up Option", "comments": "16 pages, AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential decision-making problem where an agent can take one\naction at a time and each action has a stochastic temporal extent, i.e., a new\naction cannot be taken until the previous one is finished. Upon completion, the\nchosen action yields a stochastic reward. The agent seeks to maximize its\ncumulative reward over a finite time budget, with the option of \"giving up\" on\na current action -- hence forfeiting any reward -- in order to choose another\naction. We cast this problem as a variant of the stochastic multi-armed bandits\nproblem with stochastic consumption of resource. For this problem, we first\nestablish that the optimal arm is the one that maximizes the ratio of the\nexpected reward of the arm to the expected waiting time before the agent sees\nthe reward due to pulling that arm. Using a novel upper confidence bound on\nthis ratio, we then introduce an upper confidence based-algorithm, WAIT-UCB,\nfor which we establish logarithmic, problem-dependent regret bound which has an\nimproved dependence on problem parameters compared to previous works.\nSimulations on various problem configurations comparing WAIT-UCB against the\nstate-of-the-art algorithms are also presented.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 22:16:20 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sharoff", "P", ""], ["Mehta", "Nishant A.", ""], ["Ganti", "Ravi", ""]]}, {"id": "2003.03462", "submitter": "Kaspar M\\\"artens", "authors": "Kaspar M\\\"artens and Christopher Yau", "title": "BasisVAE: Translation-invariant feature-level clustering with\n  Variational Autoencoders", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) provide a flexible and scalable framework for\nnon-linear dimensionality reduction. However, in application domains such as\ngenomics where data sets are typically tabular and high-dimensional, a\nblack-box approach to dimensionality reduction does not provide sufficient\ninsights. Common data analysis workflows additionally use clustering techniques\nto identify groups of similar features. This usually leads to a two-stage\nprocess, however, it would be desirable to construct a joint modelling\nframework for simultaneous dimensionality reduction and clustering of features.\nIn this paper, we propose to achieve this through the BasisVAE: a combination\nof the VAE and a probabilistic clustering prior, which lets us learn a one-hot\nbasis function representation as part of the decoder network. Furthermore, for\nscenarios where not all features are aligned, we develop an extension to handle\ntranslation-invariant basis functions. We show how a collapsed variational\ninference scheme leads to scalable and efficient inference for BasisVAE,\ndemonstrated on various toy examples as well as on single-cell gene expression\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 23:10:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["M\u00e4rtens", "Kaspar", ""], ["Yau", "Christopher", ""]]}, {"id": "2003.03463", "submitter": "Lantao Yu", "authors": "Lantao Yu, Yang Song, Jiaming Song, Stefano Ermon", "title": "Training Deep Energy-Based Models with f-Divergence Minimization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep energy-based models (EBMs) are very flexible in distribution\nparametrization but computationally challenging because of the intractable\npartition function. They are typically trained via maximum likelihood, using\ncontrastive divergence to approximate the gradient of the KL divergence between\ndata and model distribution. While KL divergence has many desirable properties,\nother f-divergences have shown advantages in training implicit density\ngenerative models such as generative adversarial networks. In this paper, we\npropose a general variational framework termed f-EBM to train EBMs using any\ndesired f-divergence. We introduce a corresponding optimization algorithm and\nprove its local convergence property with non-linear dynamical systems theory.\nExperimental results demonstrate the superiority of f-EBM over contrastive\ndivergence, as well as the benefits of training EBMs using f-divergences other\nthan KL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 23:11:13 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:21:03 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Yu", "Lantao", ""], ["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "2003.03466", "submitter": "Philipp Drewe-Boss", "authors": "Philipp Drewe-Boss, Dirk Enders, Jochen Walker, Uwe Ohler", "title": "Deep learning for prediction of population health costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of healthcare costs is important for optimally managing\nhealth costs. However, methods leveraging the medical richness from data such\nas health insurance claims or electronic health records are missing. Here, we\ndeveloped a deep neural network to predict future cost from health insurance\nclaims records. We applied the deep network and a ridge regression model to a\nsample of 1.4 million German insurants to predict total one-year health care\ncosts. Both methods were compared to Morbi-RSA models with various performance\nmeasures and were also used to predict patients with a change in costs and to\nidentify relevant codes for this prediction. We showed that the neural network\noutperformed the ridge regression as well as all Morbi-RSA models for cost\nprediction. Further, the neural network was superior to ridge regression in\npredicting patients with cost change and identified more specific codes. In\nsummary, we showed that our deep neural network can leverage the full\ncomplexity of the patient records and outperforms standard approaches. We\nsuggest that the better performance is due to the ability to incorporate\ncomplex interactions in the model and that the model might also be used for\npredicting other health phenotypes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 23:33:39 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Drewe-Boss", "Philipp", ""], ["Enders", "Dirk", ""], ["Walker", "Jochen", ""], ["Ohler", "Uwe", ""]]}, {"id": "2003.03470", "submitter": "Roman Vainshtein", "authors": "Asnat Greenstein-Messica, Roman Vainshtein, Gilad Katz, Bracha\n  Shapira, Lior Rokach", "title": "Automatic Machine Learning Derived from Scholarly Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenging aspects of applying machine learning is the need to\nidentify the algorithms that will perform best for a given dataset. This\nprocess can be difficult, time consuming and often requires a great deal of\ndomain knowledge. We present Sommelier, an expert system for recommending the\nmachine learning algorithms that should be applied on a previously unseen\ndataset. Sommelier is based on word embedding representations of the domain\nknowledge extracted from a large corpus of academic publications. When\npresented with a new dataset and its problem description, Sommelier leverages a\nrecommendation model trained on the word embedding representation to provide a\nranked list of the most relevant algorithms to be used on the dataset. We\ndemonstrate Sommelier's effectiveness by conducting an extensive evaluation on\n121 publicly available datasets and 53 classification algorithms. The top\nalgorithms recommended for each dataset by Sommelier were able to achieve on\naverage 97.7% of the optimal accuracy of all surveyed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 23:49:00 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Greenstein-Messica", "Asnat", ""], ["Vainshtein", "Roman", ""], ["Katz", "Gilad", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "2003.03474", "submitter": "Jordan Lam", "authors": "Jordan Lam, Robert Abbas", "title": "Machine Learning based Anomaly Detection for 5G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting the networks of tomorrow is set to be a challenging domain due to\nincreasing cyber security threats and widening attack surfaces created by the\nInternet of Things (IoT), increased network heterogeneity, increased use of\nvirtualisation technologies and distributed architectures. This paper proposes\nSDS (Software Defined Security) as a means to provide an automated, flexible\nand scalable network defence system. SDS will harness current advances in\nmachine learning to design a CNN (Convolutional Neural Network) using NAS\n(Neural Architecture Search) to detect anomalous network traffic. SDS can be\napplied to an intrusion detection system to create a more proactive and\nend-to-end defence for a 5G network. To test this assumption, normal and\nanomalous network flows from a simulated environment have been collected and\nanalyzed with a CNN. The results from this method are promising as the model\nhas identified benign traffic with a 100% accuracy rate and anomalous traffic\nwith a 96.4% detection rate. This demonstrates the effectiveness of network\nflow analysis for a variety of common malicious attacks and also provides a\nviable option for detection of encrypted malicious network traffic.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 00:17:08 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lam", "Jordan", ""], ["Abbas", "Robert", ""]]}, {"id": "2003.03477", "submitter": "Qinqing Zheng", "authors": "Qinqing Zheng, Bor-Yiing Su, Jiyan Yang, Alisson Azzolini, Qiang Wu,\n  Ou Jin, Shri Karandikar, Hagay Lupesko, Liang Xiong, Eric Zhou", "title": "ShadowSync: Performing Synchronization in the Background for Highly\n  Scalable Distributed Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are often trained with a tremendous amount of data,\nand distributed training is the workhorse to shorten the training time. While\nthe training throughput can be increased by simply adding more workers, it is\nalso increasingly challenging to preserve the model quality. In this paper, we\npresent \\shadowsync, a distributed framework specifically tailored to modern\nscale recommendation system training. In contrast to previous works where\nsynchronization happens as part of the training process, \\shadowsync separates\nthe synchronization from training and runs it in the background. Such isolation\nsignificantly reduces the synchronization overhead and increases the\nsynchronization frequency, so that we are able to obtain both high throughput\nand excellent model quality when training at scale. The superiority of our\nprocedure is confirmed by experiments on training deep neural networks for\nclick-through-rate prediction tasks. Our framework is capable to express data\nparallelism and/or model parallelism, generic to host various types of\nsynchronization algorithms, and readily applicable to large scale problems in\nother areas.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 00:26:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 18:29:21 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 18:23:31 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zheng", "Qinqing", ""], ["Su", "Bor-Yiing", ""], ["Yang", "Jiyan", ""], ["Azzolini", "Alisson", ""], ["Wu", "Qiang", ""], ["Jin", "Ou", ""], ["Karandikar", "Shri", ""], ["Lupesko", "Hagay", ""], ["Xiong", "Liang", ""], ["Zhou", "Eric", ""]]}, {"id": "2003.03485", "submitter": "Zongyi Li", "authors": "Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu,\n  Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar", "title": "Neural Operator: Graph Kernel Network for Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical development of neural networks has been primarily for mappings\nbetween a finite-dimensional Euclidean space and a set of classes, or between\ntwo finite-dimensional Euclidean spaces. The purpose of this work is to\ngeneralize neural networks so that they can learn mappings between\ninfinite-dimensional spaces (operators). The key innovation in our work is that\na single set of network parameters, within a carefully designed network\narchitecture, may be used to describe mappings between infinite-dimensional\nspaces and between different finite-dimensional approximations of those spaces.\nWe formulate approximation of the infinite-dimensional mapping by composing\nnonlinear activation functions and a class of integral operators. The kernel\nintegration is computed by message passing on graph networks. This approach has\nsubstantial practical consequences which we will illustrate in the context of\nmappings between input data to partial differential equations (PDEs) and their\nsolutions. In this context, such learned networks can generalize among\ndifferent approximation methods for the PDE (such as finite difference or\nfinite element methods) and among approximations corresponding to different\nunderlying levels of resolution and discretization. Experiments confirm that\nthe proposed graph kernel network does have the desired properties and show\ncompetitive performance compared to the state of the art solvers.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 01:56:20 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Li", "Zongyi", ""], ["Kovachki", "Nikola", ""], ["Azizzadenesheli", "Kamyar", ""], ["Liu", "Burigede", ""], ["Bhattacharya", "Kaushik", ""], ["Stuart", "Andrew", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2003.03490", "submitter": "Chen-Yu Wei", "authors": "Ehsan Emamjomeh-Zadeh, Chen-Yu Wei, Haipeng Luo, David Kempe", "title": "Adversarial Online Learning with Changing Action Sets: Efficient\n  Algorithms with Approximate Regret Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of online learning with sleeping experts/bandits: in\neach time step, only a subset of the actions are available for the algorithm to\nchoose from (and learn about). The work of Kleinberg et al. (2010) showed that\nthere exist no-regret algorithms which perform no worse than the best ranking\nof actions asymptotically. Unfortunately, achieving this regret bound appears\ncomputationally hard: Kanade and Steinke (2014) showed that achieving this\nno-regret performance is at least as hard as PAC-learning DNFs, a notoriously\ndifficult problem. In the present work, we relax the original problem and study\ncomputationally efficient no-approximate-regret algorithms: such algorithms may\nexceed the optimal cost by a multiplicative constant in addition to the\nadditive regret. We give an algorithm that provides a no-approximate-regret\nguarantee for the general sleeping expert/bandit problems. For several\ncanonical special cases of the problem, we give algorithms with significantly\nbetter approximation ratios; these algorithms also illustrate different\ntechniques for achieving no-approximate-regret guarantees.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 02:13:21 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 09:17:56 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Emamjomeh-Zadeh", "Ehsan", ""], ["Wei", "Chen-Yu", ""], ["Luo", "Haipeng", ""], ["Kempe", "David", ""]]}, {"id": "2003.03506", "submitter": "Thirunavukarasu Balasubramaniam", "authors": "Thirunavukarasu Balasubramaniam, Richi Nayak, Chau Yuen", "title": "Columnwise Element Selection for Computationally Efficient Nonnegative\n  Coupled Matrix Tensor Factorization", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": "10.1109/TKDE.2020.2967045", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupled Matrix Tensor Factorization (CMTF) facilitates the integration and\nanalysis of multiple data sources and helps discover meaningful information.\nNonnegative CMTF (N-CMTF) has been employed in many applications for\nidentifying latent patterns, prediction, and recommendation. However, due to\nthe added complexity with coupling between tensor and matrix data, existing\nN-CMTF algorithms exhibit poor computation efficiency. In this paper, a\ncomputationally efficient N-CMTF factorization algorithm is presented based on\nthe column-wise element selection, preventing frequent gradient updates.\nTheoretical and empirical analyses show that the proposed N-CMTF factorization\nalgorithm is not only more accurate but also more computationally efficient\nthan existing algorithms in approximating the tensor as well as in identifying\nthe underlying nature of factors.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 03:34:53 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Balasubramaniam", "Thirunavukarasu", ""], ["Nayak", "Richi", ""], ["Yuen", "Chau", ""]]}, {"id": "2003.03515", "submitter": "Jun Han Mr", "authors": "Jun Han", "title": "Scalable Approximate Inference and Some Applications", "comments": "PhD thesis, Dartmouth College (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate inference in probability models is a fundamental task in machine\nlearning. Approximate inference provides powerful tools to Bayesian reasoning,\ndecision making, and Bayesian deep learning. The main goal is to estimate the\nexpectation of interested functions w.r.t. a target distribution. When it comes\nto high dimensional probability models and large datasets, efficient\napproximate inference becomes critically important. In this thesis, we propose\na new framework for approximate inference, which combines the advantages of\nthese three frameworks and overcomes their limitations. Our proposed four\nalgorithms are motivated by the recent computational progress of Stein's\nmethod. Our proposed algorithms are applied to continuous and discrete\ndistributions under the setting when the gradient information of the target\ndistribution is available or unavailable. Theoretical analysis is provided to\nprove the convergence of our proposed algorithms. Our adaptive IS algorithm\niteratively improves the importance proposal by functionally decreasing the KL\ndivergence between the updated proposal and the target. When the gradient of\nthe target is unavailable, our proposed sampling algorithm leverages the\ngradient of a surrogate model and corrects induced bias with importance\nweights, which significantly outperforms other gradient-free sampling\nalgorithms. In addition, our theoretical results enable us to perform the\ngoodness-of-fit test on discrete distributions. At the end of the thesis, we\npropose an importance-weighted method to efficiently aggregate local models in\ndistributed learning with one-shot communication. Results on simulated and real\ndatasets indicate the statistical efficiency and wide applicability of our\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 04:33:27 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Han", "Jun", ""]]}, {"id": "2003.03517", "submitter": "Shravan Veerapaneni", "authors": "Gary R. Marple, David Gorsich, Paramsothy Jayakumar, Shravan\n  Veerapaneni", "title": "An Active Learning Framework for Constructing High-fidelity Mobility\n  Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mobility map, which provides maximum achievable speed on a given terrain,\nis essential for path planning of autonomous ground vehicles in off-road\nsettings. While physics-based simulations play a central role in creating\nnext-generation, high-fidelity mobility maps, they are cumbersome and\nexpensive. For instance, a typical simulation can take weeks to run on a\nsupercomputer and each map requires thousands of such simulations. Recent work\nat the U.S. Army CCDC Ground Vehicle Systems Center has shown that trained\nmachine learning classifiers can greatly improve the efficiency of this\nprocess. However, deciding which simulations to run in order to train the\nclassifier efficiently is still an open problem. According to PAC learning\ntheory, data that can be separated by a classifier is expected to require\n$\\mathcal{O}(1/\\epsilon)$ randomly selected points (simulations) to train the\nclassifier with error less than $\\epsilon$. In this paper, building on existing\nalgorithms, we introduce an active learning paradigm that substantially reduces\nthe number of simulations needed to train a machine learning classifier without\nsacrificing accuracy. Experimental results suggest that our sampling algorithm\ncan train a neural network, with higher accuracy, using less than half the\nnumber of simulations when compared to random sampling.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 04:50:58 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Marple", "Gary R.", ""], ["Gorsich", "David", ""], ["Jayakumar", "Paramsothy", ""], ["Veerapaneni", "Shravan", ""]]}, {"id": "2003.03519", "submitter": "Hanting Chen", "authors": "Hanting Chen, Yunhe Wang, Han Shu, Changyuan Wen, Chunjing Xu, Boxin\n  Shi, Chao Xu, Chang Xu", "title": "Distilling portable Generative Adversarial Networks for Image\n  Translation", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite Generative Adversarial Networks (GANs) have been widely used in\nvarious image-to-image translation tasks, they can be hardly applied on mobile\ndevices due to their heavy computation and storage cost. Traditional network\ncompression methods focus on visually recognition tasks, but never deal with\ngeneration tasks. Inspired by knowledge distillation, a student generator of\nfewer parameters is trained by inheriting the low-level and high-level\ninformation from the original heavy teacher generator. To promote the\ncapability of student generator, we include a student discriminator to measure\nthe distances between real images, and images generated by student and teacher\ngenerators. An adversarial learning process is therefore established to\noptimize student generator and student discriminator. Qualitative and\nquantitative analysis by conducting experiments on benchmark datasets\ndemonstrate that the proposed method can learn portable generative models with\nstrong performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 05:53:01 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Chen", "Hanting", ""], ["Wang", "Yunhe", ""], ["Shu", "Han", ""], ["Wen", "Changyuan", ""], ["Xu", "Chunjing", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Xu", "Chang", ""]]}, {"id": "2003.03524", "submitter": "Vincenzo Crescimanna", "authors": "Vincenzo Crescimanna, Bruce Graham", "title": "The Variational InfoMax Learning Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Inference and Information Bottleneck are the two most popular\nobjectives for neural networks, but they can be optimised only via a\nvariational lower bound: the Variational Information Bottleneck (VIB). In this\nmanuscript we show that the two objectives are actually equivalent to the\nInfoMax: maximise the information between the data and the labels. The InfoMax\nrepresentation of the two objectives is not relevant only per se, since it\nhelps to understand the role of the network capacity, but also because it\nallows us to derive a variational objective, the Variational InfoMax (VIM),\nthat maximises them directly without resorting to any lower bound. The\ntheoretical improvement of VIM over VIB is highlighted by the computational\nexperiments, where the model trained by VIM improves the VIB model in three\ndifferent tasks: accuracy, robustness to noise and representation quality.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 07:14:35 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Crescimanna", "Vincenzo", ""], ["Graham", "Bruce", ""]]}, {"id": "2003.03526", "submitter": "Konatsu Miyamoto", "authors": "Konatsu Miyamoto, Masaya Suzuki, Yuma Kigami, Kodai Satake", "title": "Convergence of Q-value in case of Gaussian rewards", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, as a study of reinforcement learning, we converge the Q\nfunction to unbounded rewards such as Gaussian distribution. From the central\nlimit theorem, in some real-world applications it is natural to assume that\nrewards follow a Gaussian distribution , but existing proofs cannot guarantee\nconvergence of the Q-function. Furthermore, in the distribution-type\nreinforcement learning and Bayesian reinforcement learning that have become\npopular in recent years, it is better to allow the reward to have a Gaussian\ndistribution. Therefore, in this paper, we prove the convergence of the\nQ-function under the condition of $E[r(s,a)^2]<\\infty$, which is much more\nrelaxed than the existing research. Finally, as a bonus, a proof of the policy\ngradient theorem for distributed reinforcement learning is also posted.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 07:29:07 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Miyamoto", "Konatsu", ""], ["Suzuki", "Masaya", ""], ["Kigami", "Yuma", ""], ["Satake", "Kodai", ""]]}, {"id": "2003.03532", "submitter": "Xiang Zhou", "authors": "Xiang Zhou, Huizhuo Yuan, Chris Junchi Li, Qingyun Sun", "title": "Stochastic Modified Equations for Continuous Limit of Stochastic ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic version of alternating direction method of multiplier (ADMM) and\nits variants (linearized ADMM, gradient-based ADMM) plays a key role for modern\nlarge scale machine learning problems. One example is the regularized empirical\nrisk minimization problem. In this work, we put different variants of\nstochastic ADMM into a unified form, which includes standard, linearized and\ngradient-based ADMM with relaxation, and study their dynamics via a\ncontinuous-time model approach. We adapt the mathematical framework of\nstochastic modified equation (SME), and show that the dynamics of stochastic\nADMM is approximated by a class of stochastic differential equations with small\nnoise parameters in the sense of weak approximation. The continuous-time\nanalysis would uncover important analytical insights into the behaviors of the\ndiscrete-time algorithm, which are non-trivial to gain otherwise. For example,\nwe could characterize the fluctuation of the solution paths precisely, and\ndecide optimal stopping time to minimize the variance of solution paths.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 08:01:50 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhou", "Xiang", ""], ["Yuan", "Huizhuo", ""], ["Li", "Chris Junchi", ""], ["Sun", "Qingyun", ""]]}, {"id": "2003.03533", "submitter": "Damien Querlioz", "authors": "Axel Laborieux, Maxence Ernoult, Tifenn Hirtzlin and Damien Querlioz", "title": "Synaptic Metaplasticity in Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have surpassed human performance in multiple\nsituations, they are prone to catastrophic forgetting: upon training a new\ntask, they rapidly forget previously learned ones. Neuroscience studies, based\non idealized tasks, suggest that in the brain, synapses overcome this issue by\nadjusting their plasticity depending on their past history. However, such\n\"metaplastic\" behaviours do not transfer directly to mitigate catastrophic\nforgetting in deep neural networks. In this work, we interpret the hidden\nweights used by binarized neural networks, a low-precision version of deep\nneural networks, as metaplastic variables, and modify their training technique\nto alleviate forgetting. Building on this idea, we propose and demonstrate\nexperimentally, in situations of multitask and stream learning, a training\ntechnique that reduces catastrophic forgetting without needing previously\npresented data, nor formal boundaries between datasets and with performance\napproaching more mainstream techniques with task boundaries. We support our\napproach with a theoretical analysis on a tractable task. This work bridges\ncomputational neuroscience and deep learning, and presents significant assets\nfor future embedded and neuromorphic systems, especially when using novel\nnanodevices featuring physics analogous to metaplasticity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 08:09:34 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 14:56:46 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Laborieux", "Axel", ""], ["Ernoult", "Maxence", ""], ["Hirtzlin", "Tifenn", ""], ["Querlioz", "Damien", ""]]}, {"id": "2003.03546", "submitter": "Victor Gallego", "authors": "David Rios Insua, Roi Naveiro, Victor Gallego, Jason Poulos", "title": "Adversarial Machine Learning: Perspectives from Adversarial Risk\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Machine Learning (AML) is emerging as a major field aimed at the\nprotection of automated ML systems against security threats. The majority of\nwork in this area has built upon a game-theoretic framework by modelling a\nconflict between an attacker and a defender. After reviewing game-theoretic\napproaches to AML, we discuss the benefits that a Bayesian Adversarial Risk\nAnalysis perspective brings when defending ML based systems. A research agenda\nis included.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 10:30:43 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Insua", "David Rios", ""], ["Naveiro", "Roi", ""], ["Gallego", "Victor", ""], ["Poulos", "Jason", ""]]}, {"id": "2003.03564", "submitter": "Jinjin Xu", "authors": "Jinjin Xu, Wenli Du, Ran Cheng, Wangli He, Yaochu Jin", "title": "Ternary Compression for Communication-Efficient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning over massive data stored in different locations is essential in many\nreal-world applications. However, sharing data is full of challenges due to the\nincreasing demands of privacy and security with the growing use of smart mobile\ndevices and IoT devices. Federated learning provides a potential solution to\nprivacy-preserving and secure machine learning, by means of jointly training a\nglobal model without uploading data distributed on multiple devices to a\ncentral server. However, most existing work on federated learning adopts\nmachine learning models with full-precision weights, and almost all these\nmodels contain a large number of redundant parameters that do not need to be\ntransmitted to the server, consuming an excessive amount of communication\ncosts. To address this issue, we propose a federated trained ternary\nquantization (FTTQ) algorithm, which optimizes the quantized networks on the\nclients through a self-learning quantization factor. A convergence proof of the\nquantization factor and the unbiasedness of FTTQ is given. In addition, we\npropose a ternary federated averaging protocol (T-FedAvg) to reduce the\nupstream and downstream communication of federated learning systems. Empirical\nexperiments are conducted to train widely used deep learning models on publicly\navailable datasets, and our results demonstrate the effectiveness of FTTQ and\nT-FedAvg compared with the canonical federated learning algorithms in reducing\ncommunication costs and maintaining the learning performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 11:55:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Xu", "Jinjin", ""], ["Du", "Wenli", ""], ["Cheng", "Ran", ""], ["He", "Wangli", ""], ["Jin", "Yaochu", ""]]}, {"id": "2003.03572", "submitter": "Thirunavukarasu Balasubramaniam", "authors": "Thirunavukarasu Balasubramaniam, Richi Nayak, Chau Yuen", "title": "Efficient Nonnegative Tensor Factorization via Saturating Coordinate\n  Descent", "comments": "Accepted for publication in ACM Transactions on Knowledge Discovery\n  from Data", "journal-ref": null, "doi": "10.1145/3385654", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancements in computing technology and web-based applications,\ndata is increasingly generated in multi-dimensional form. This data is usually\nsparse due to the presence of a large number of users and fewer user\ninteractions. To deal with this, the Nonnegative Tensor Factorization (NTF)\nbased methods have been widely used. However existing factorization algorithms\nare not suitable to process in all three conditions of size, density, and rank\nof the tensor. Consequently, their applicability becomes limited. In this\npaper, we propose a novel fast and efficient NTF algorithm using the element\nselection approach. We calculate the element importance using Lipschitz\ncontinuity and propose a saturation point based element selection method that\nchooses a set of elements column-wise for updating to solve the optimization\nproblem. Empirical analysis reveals that the proposed algorithm is scalable in\nterms of tensor size, density, and rank in comparison to the relevant\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 12:51:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Balasubramaniam", "Thirunavukarasu", ""], ["Nayak", "Richi", ""], ["Yuen", "Chau", ""]]}, {"id": "2003.03576", "submitter": "Jussi Hanhirova", "authors": "Jussi Hanhirova, Anton Debner, Matias Hyypp\\\"a, Vesa Hirvisalo", "title": "A machine learning environment for evaluating autonomous driving\n  software", "comments": "8 pages, 13 figures", "journal-ref": "Embedded World Conference 2019 Proceedings", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles need safe development and testing environments. Many\ntraffic scenarios are such that they cannot be tested in the real world. We see\nhybrid photorealistic simulation as a viable tool for developing AI (artificial\nintelligence) software for autonomous driving. We present a machine learning\nenvironment for detecting autonomous vehicle corner case behavior. Our\nenvironment is based on connecting the CARLA simulation software to TensorFlow\nmachine learning framework and custom AI client software. The AI client\nsoftware receives data from a simulated world via virtual sensors and\ntransforms the data into information using machine learning models. The AI\nclients control vehicles in the simulated world. Our environment monitors the\nstate assumed by the vehicle AIs to the ground truth state derived from the\nsimulation model. Our system can search for corner cases where the vehicle AI\nis unable to correctly understand the situation. In our paper, we present the\noverall hybrid simulator architecture and compare different configurations. We\npresent performance measurements from real setups, and outline the main\nparameters affecting the hybrid simulator performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 13:05:03 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Hanhirova", "Jussi", ""], ["Debner", "Anton", ""], ["Hyypp\u00e4", "Matias", ""], ["Hirvisalo", "Vesa", ""]]}, {"id": "2003.03600", "submitter": "Nina Mazyavkina", "authors": "Nina Mazyavkina and Sergey Sviridov and Sergei Ivanov and Evgeny\n  Burnaev", "title": "Reinforcement Learning for Combinatorial Optimization: A Survey", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many traditional algorithms for solving combinatorial optimization problems\ninvolve using hand-crafted heuristics that sequentially construct a solution.\nSuch heuristics are designed by domain experts and may often be suboptimal due\nto the hard nature of the problems. Reinforcement learning (RL) proposes a good\nalternative to automate the search of these heuristics by training an agent in\na supervised or self-supervised manner. In this survey, we explore the recent\nadvancements of applying RL frameworks to hard combinatorial problems. Our\nsurvey provides the necessary background for operations research and machine\nlearning communities and showcases the works that are moving the field forward.\nWe juxtapose recently proposed RL methods, laying out the timeline of the\nimprovements for each problem, as well as we make a comparison with traditional\nalgorithms, indicating that RL models can become a promising direction for\nsolving combinatorial problems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 16:19:45 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 17:35:46 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 12:57:36 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Mazyavkina", "Nina", ""], ["Sviridov", "Sergey", ""], ["Ivanov", "Sergei", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2003.03601", "submitter": "Nuri Mert Vural", "authors": "N. Mert Vural, Selim F. Yilmaz, Fatih Ilhan and Suleyman S. Kozat", "title": "RNN-based Online Learning: An Efficient First-Order Optimization\n  Algorithm with a Convergence Guarantee", "comments": "This paper was an early draft of the presented results. We have\n  written and published another paper (arXiv:2005.08948) where we have improved\n  the material in this paper. The published paper covers most of the material\n  presented in this paper as well. Therefore, we remove this paper from Arxiv\n  and kindly refer the interested readers to arXiv:2005.08948", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate online nonlinear regression with continually running recurrent\nneural network networks (RNNs), i.e., RNN-based online learning. For RNN-based\nonline learning, we introduce an efficient first-order training algorithm that\ntheoretically guarantees to converge to the optimum network parameters. Our\nalgorithm is truly online such that it does not make any assumption on the\nlearning environment to guarantee convergence. Through numerical simulations,\nwe verify our theoretical results and illustrate significant performance\nimprovements achieved by our algorithm with respect to the state-of-the-art RNN\ntraining methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 16:31:22 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:30:41 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vural", "N. Mert", ""], ["Yilmaz", "Selim F.", ""], ["Ilhan", "Fatih", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2003.03609", "submitter": "Zhe Li", "authors": "Zhe Li, Chunhua Sun, Chunli Liu, Xiayu Chen, Meng Wang, Yezheng Liu", "title": "RCC-Dual-GAN: An Efficient Approach for Outlier Detection with Few\n  Identified Anomalies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is an important task in data mining and many technologies\nhave been explored in various applications. However, due to the default\nassumption that outliers are non-concentrated, unsupervised outlier detection\nmay not correctly detect group anomalies with higher density levels. As for the\nsupervised outlier detection, although high detection rates and optimal\nparameters can usually be achieved, obtaining sufficient and correct labels is\na time-consuming task. To address these issues, we focus on semi-supervised\noutlier detection with few identified anomalies, in the hope of using limited\nlabels to achieve high detection accuracy. First, we propose a novel detection\nmodel Dual-GAN, which can directly utilize the potential information in\nidentified anomalies to detect discrete outliers and partially identified group\nanomalies simultaneously. And then, considering the instances with similar\noutput values may not all be similar in a complex data structure, we replace\nthe two MO-GAN components in Dual-GAN with the combination of RCC and M-GAN\n(RCC-Dual-GAN). In addition, to deal with the evaluation of Nash equilibrium\nand the selection of optimal model, two evaluation indicators are created and\nintroduced into the two models to make the detection process more intelligent.\nExtensive experiments on both benchmark datasets and two practical tasks\ndemonstrate that our proposed approaches (i.e., Dual-GAN and RCC-Dual-GAN) can\nsignificantly improve the accuracy of outlier detection even with only a few\nidentified anomalies. Moreover, compared with the two MO-GAN components in\nDual-GAN, the network structure combining RCC and M-GAN has greater stability\nin various situations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 17:13:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Li", "Zhe", ""], ["Sun", "Chunhua", ""], ["Liu", "Chunli", ""], ["Chen", "Xiayu", ""], ["Wang", "Meng", ""], ["Liu", "Yezheng", ""]]}, {"id": "2003.03616", "submitter": "James Murphy", "authors": "Lenore Cowen, Kapil Devkota, Xiaozhe Hu, James M. Murphy, and Kaiyi Wu", "title": "Diffusion State Distances: Multitemporal Analysis, Fast Algorithms, and\n  Applications to Biological Networks", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-dependent metrics are powerful tools for learning the underlying\nstructure of high-dimensional data. This article develops and analyzes a\ndata-dependent metric known as diffusion state distance (DSD), which compares\npoints using a data-driven diffusion process. Unlike related diffusion methods,\nDSDs incorporate information across time scales, which allows for the intrinsic\ndata structure to be inferred in a parameter-free manner. This article develops\na theory for DSD based on the multitemporal emergence of mesoscopic equilibria\nin the underlying diffusion process. New algorithms for denoising and dimension\nreduction with DSD are also proposed and analyzed. These approaches are based\non a weighted spectral decomposition of the underlying diffusion process, and\nexperiments on synthetic datasets and real biological networks illustrate the\nefficacy of the proposed algorithms in terms of both speed and accuracy.\nThroughout, comparisons with related methods are made, in order to illustrate\nthe distinct advantages of DSD for datasets exhibiting multiscale structure.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 17:43:34 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Cowen", "Lenore", ""], ["Devkota", "Kapil", ""], ["Hu", "Xiaozhe", ""], ["Murphy", "James M.", ""], ["Wu", "Kaiyi", ""]]}, {"id": "2003.03621", "submitter": "Moritz Herrmann", "authors": "Moritz Herrmann, Philipp Probst, Roman Hornung, Vindi Jurinovic,\n  Anne-Laure Boulesteix", "title": "Large-scale benchmark study of survival prediction methods using\n  multi-omics data", "comments": "23 pages, 6 tables, 3 figures", "journal-ref": "Briefings in Bioinformatics (2020) bbaa167", "doi": "10.1093/bib/bbaa167", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-omics data, that is, datasets containing different types of\nhigh-dimensional molecular variables (often in addition to classical clinical\nvariables), are increasingly generated for the investigation of various\ndiseases. Nevertheless, questions remain regarding the usefulness of\nmulti-omics data for the prediction of disease outcomes such as survival time.\nIt is also unclear which methods are most appropriate to derive such prediction\nmodels. We aim to give some answers to these questions by means of a\nlarge-scale benchmark study using real data. Different prediction methods from\nmachine learning and statistics were applied on 18 multi-omics cancer datasets\nfrom the database \"The Cancer Genome Atlas\", containing from 35 to 1,000\nobservations and from 60,000 to 100,000 variables. The considered outcome was\nthe (censored) survival time. Twelve methods based on boosting, penalized\nregression and random forest were compared, comprising both methods that do and\nthat do not take the group structure of the omics variables into account. The\nKaplan-Meier estimate and a Cox model using only clinical variables were used\nas reference methods. The methods were compared using several repetitions of\n5-fold cross-validation. Uno's C-index and the integrated Brier-score served as\nperformance metrics. The results show that, although multi-omics data can\nimprove the prediction performance, this is not generally the case. Only the\nmethod block forest slightly outperformed the Cox model on average over all\ndatasets. Taking into account the multi-omics structure improves the predictive\nperformance and protects variables in low-dimensional groups - especially\nclinical variables - from not being included in the model. All analyses are\nreproducible using freely available R code.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:03:17 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Herrmann", "Moritz", ""], ["Probst", "Philipp", ""], ["Hornung", "Roman", ""], ["Jurinovic", "Vindi", ""], ["Boulesteix", "Anne-Laure", ""]]}, {"id": "2003.03622", "submitter": "Quanshi Zhang", "authors": "Xu Cheng, Zhefan Rao, Yilan Chen, Quanshi Zhang", "title": "Explaining Knowledge Distillation by Quantifying the Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method to interpret the success of knowledge\ndistillation by quantifying and analyzing task-relevant and task-irrelevant\nvisual concepts that are encoded in intermediate layers of a deep neural\nnetwork (DNN). More specifically, three hypotheses are proposed as follows. 1.\nKnowledge distillation makes the DNN learn more visual concepts than learning\nfrom raw data. 2. Knowledge distillation ensures that the DNN is prone to\nlearning various visual concepts simultaneously. Whereas, in the scenario of\nlearning from raw data, the DNN learns visual concepts sequentially. 3.\nKnowledge distillation yields more stable optimization directions than learning\nfrom raw data. Accordingly, we design three types of mathematical metrics to\nevaluate feature representations of the DNN. In experiments, we diagnosed\nvarious DNNs, and above hypotheses were verified.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:09:17 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Cheng", "Xu", ""], ["Rao", "Zhefan", ""], ["Chen", "Yilan", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2003.03629", "submitter": "Lucas Mentch", "authors": "Lucas Mentch and Siyu Zhou", "title": "Getting Better from Worse: Augmented Bagging and a Cautionary Tale of\n  Variable Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size, complexity, and availability of data continues to grow,\nscientists are increasingly relying upon black-box learning algorithms that can\noften provide accurate predictions with minimal a priori model specifications.\nTools like random forests have an established track record of off-the-shelf\nsuccess and even offer various strategies for analyzing the underlying\nrelationships among variables. Here, motivated by recent insights into random\nforest behavior, we introduce the simple idea of augmented bagging (AugBagg), a\nprocedure that operates in an identical fashion to classical bagging and random\nforests, but which operates on a larger, augmented space containing additional\nrandomly generated noise features. Surprisingly, we demonstrate that this\nsimple act of including extra noise variables in the model can lead to dramatic\nimprovements in out-of-sample predictive accuracy, sometimes outperforming even\nan optimally tuned traditional random forest. As a result, intuitive notions of\nvariable importance based on improved model accuracy may be deeply flawed, as\neven purely random noise can routinely register as statistically significant.\nNumerous demonstrations on both real and synthetic data are provided along with\na proposed solution.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:35:10 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 16:34:57 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Mentch", "Lucas", ""], ["Zhou", "Siyu", ""]]}, {"id": "2003.03633", "submitter": "Majed El Helou", "authors": "Majed El Helou, Frederike D\\\"umbgen, Sabine S\\\"usstrunk", "title": "AL2: Progressive Activation Loss for Learning General Representations in\n  Classification Neural Networks", "comments": null, "journal-ref": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large capacity of neural networks enables them to learn complex\nfunctions. To avoid overfitting, networks however require a lot of training\ndata that can be expensive and time-consuming to collect. A common practical\napproach to attenuate overfitting is the use of network regularization\ntechniques. We propose a novel regularization method that progressively\npenalizes the magnitude of activations during training. The combined activation\nsignals produced by all neurons in a given layer form the representation of the\ninput image in that feature space. We propose to regularize this representation\nin the last feature layer before classification layers. Our method's effect on\ngeneralization is analyzed with label randomization tests and cumulative\nablations. Experimental results show the advantages of our approach in\ncomparison with commonly-used regularizers on standard benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:38:46 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Helou", "Majed El", ""], ["D\u00fcmbgen", "Frederike", ""], ["S\u00fcsstrunk", "Sabine", ""]]}, {"id": "2003.03657", "submitter": "O\\u{g}uzhan Karaahmeto\\u{g}lu", "authors": "Oguzhan Karaahmetoglu (1 and 2) and Suleyman Serdar Kozat (1 and 2)\n  ((1) Bilkent University, (2) DataBoss A.S.)", "title": "Prediction with Spatio-temporal Point Processes with Self Organizing\n  Decision Trees", "comments": "The article contains grammar errors and incorrect mathematical\n  formulations. Also, figures and references are inappropriate. Another work,\n  with corrected notations and references, has been accepted and published as\n  arXiv:2006.14426. There is no need for this source anymore", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the spatio-temporal prediction problem, which has attracted the\nattention of many researchers due to its critical real-life applications. In\nparticular, we introduce a novel approach to this problem. Our approach is\nbased on the Hawkes process, which is a non-stationary and self-exciting point\nprocess. We extend the formulations of a standard point process model that can\nrepresent time-series data to represent a spatio-temporal data. We model the\ndata as nonstationary in time and space. Furthermore, we partition the spatial\nregion we are working on into subregions via an adaptive decision tree and\nmodel the source statistics in each subregion with individual but mutually\ninteracting point processes. We also provide a gradient based joint\noptimization algorithm for the point process and decision tree parameters.\nThus, we introduce a model that can jointly infer the source statistics and an\nadaptive partitioning of the spatial region. Finally, we provide experimental\nresults on real-life data, which provides significant improvement due to space\nadaptation and joint optimization compared to standard well-known methods in\nthe literature.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 20:39:31 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 08:38:42 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 06:15:37 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Karaahmetoglu", "Oguzhan", "", "1 and 2"], ["Kozat", "Suleyman Serdar", "", "1 and 2"]]}, {"id": "2003.03668", "submitter": "Richard Samworth", "authors": "Yudong Chen, Tengyao Wang and Richard J. Samworth", "title": "High-dimensional, multiscale online changepoint detection", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for high-dimensional, online changepoint detection\nin settings where a $p$-variate Gaussian data stream may undergo a change in\nmean. The procedure works by performing likelihood ratio tests against simple\nalternatives of different scales in each coordinate, and then aggregating test\nstatistics across scales and coordinates. The algorithm is online in the sense\nthat both its storage requirements and worst-case computational complexity per\nnew observation are independent of the number of previous observations; in\npractice, it may even be significantly faster than this. We prove that the\npatience, or average run length under the null, of our procedure is at least at\nthe desired nominal level, and provide guarantees on its response delay under\nthe alternative that depend on the sparsity of the vector of mean change.\nSimulations confirm the practical effectiveness of our proposal, which is\nimplemented in the R package 'ocd', and we also demonstrate its utility on a\nseismology data set.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 21:54:09 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 15:46:08 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Yudong", ""], ["Wang", "Tengyao", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2003.03671", "submitter": "Fatih \\.Ilhan", "authors": "Fatih Ilhan, Suleyman Serdar Kozat", "title": "Modeling of Spatio-Temporal Hawkes Processes with Randomized Kernels", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3019329", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate spatio-temporal event analysis using point processes.\nInferring the dynamics of event sequences spatiotemporally has many practical\napplications including crime prediction, social media analysis, and traffic\nforecasting. In particular, we focus on spatio-temporal Hawkes processes that\nare commonly used due to their capability to capture excitations between event\noccurrences. We introduce a novel inference framework based on randomized\ntransformations and gradient descent to learn the process. We replace the\nspatial kernel calculations by randomized Fourier feature-based\ntransformations. The introduced randomization by this representation provides\nflexibility while modeling the spatial excitation between events. Moreover, the\nsystem described by the process is expressed within closed-form in terms of\nscalable matrix operations. During the optimization, we use maximum likelihood\nestimation approach and gradient descent while properly handling positivity and\northonormality constraints. The experiment results show the improvements\nachieved by the introduced method in terms of fitting capability in synthetic\nand real datasets with respect to the conventional inference methods in the\nspatio-temporal Hawkes process literature. We also analyze the triggering\ninteractions between event types and how their dynamics change in space and\ntime through the interpretation of learned parameters.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:21:06 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 19:04:45 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ilhan", "Fatih", ""], ["Kozat", "Suleyman Serdar", ""]]}, {"id": "2003.03672", "submitter": "Huan Lei", "authors": "Huan Lei, Lei Wu and Weinan E", "title": "Machine learning based non-Newtonian fluid model with molecular fidelity", "comments": null, "journal-ref": "Phys. Rev. E 102, 043309 (2020)", "doi": "10.1103/PhysRevE.102.043309", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a machine-learning-based framework for constructing continuum\nnon-Newtonian fluid dynamics model directly from a micro-scale description.\nDumbbell polymer solutions are used as examples to demonstrate the essential\nideas. To faithfully retain molecular fidelity, we establish a micro-macro\ncorrespondence via a set of encoders for the micro-scale polymer configurations\nand their macro-scale counterparts, a set of nonlinear conformation tensors.\nThe dynamics of these conformation tensors can be derived from the micro-scale\nmodel and the relevant terms can be parametrized using machine learning. The\nfinal model named the deep non-Newtonian model (DeePN$^2$), takes the form of\nconventional non-Newtonian fluid dynamics models, with a new form of the\nobjective tensor derivative. Both the formulation of the dynamic equation and\nthe neural network representation rigorously preserve the rotational\ninvariance, which ensures the admissibility of the constructed model. Numerical\nresults demonstrate the accuracy of DeePN$^2$, where models based on empirical\nclosures show limitations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:24:34 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 21:38:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lei", "Huan", ""], ["Wu", "Lei", ""], ["E", "Weinan", ""]]}, {"id": "2003.03675", "submitter": "Yang Zhang", "authors": "Ahmed Salem and Rui Wen and Michael Backes and Shiqing Ma and Yang\n  Zhang", "title": "Dynamic Backdoor Attacks Against Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has made tremendous progress during the past decade and\nis being adopted in various critical real-world applications. However, recent\nresearch has shown that ML models are vulnerable to multiple security and\nprivacy attacks. In particular, backdoor attacks against ML models that have\nrecently raised a lot of awareness. A successful backdoor attack can cause\nsevere consequences, such as allowing an adversary to bypass critical\nauthentication systems.\n  Current backdooring techniques rely on adding static triggers (with fixed\npatterns and locations) on ML model inputs. In this paper, we propose the first\nclass of dynamic backdooring techniques: Random Backdoor, Backdoor Generating\nNetwork (BaN), and conditional Backdoor Generating Network (c-BaN). Triggers\ngenerated by our techniques can have random patterns and locations, which\nreduce the efficacy of the current backdoor detection mechanisms. In\nparticular, BaN and c-BaN are the first two schemes that algorithmically\ngenerate triggers, which rely on a novel generative network. Moreover, c-BaN is\nthe first conditional backdooring technique, that given a target label, it can\ngenerate a target-specific trigger. Both BaN and c-BaN are essentially a\ngeneral framework which renders the adversary the flexibility for further\ncustomizing backdoor attacks.\n  We extensively evaluate our techniques on three benchmark datasets: MNIST,\nCelebA, and CIFAR-10. Our techniques achieve almost perfect attack performance\non backdoored data with a negligible utility loss. We further show that our\ntechniques can bypass current state-of-the-art defense mechanisms against\nbackdoor attacks, including Neural Cleanse, ABS, and STRIP.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:46:51 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Salem", "Ahmed", ""], ["Wen", "Rui", ""], ["Backes", "Michael", ""], ["Ma", "Shiqing", ""], ["Zhang", "Yang", ""]]}, {"id": "2003.03685", "submitter": "Jakob Runge", "authors": "Jakob Runge", "title": "Discovering contemporaneous and lagged causal relations in\n  autocorrelated nonlinear time series datasets", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider causal discovery from time series using conditional independence\n(CI) based network learning algorithms such as the PC algorithm. The PC\nalgorithm is divided into a skeleton phase where adjacencies are determined\nbased on efficiently selected CI tests and subsequent phases where links are\noriented utilizing the Markov and Faithfulness assumptions. Here we show that\nautocorrelation makes the PC algorithm much less reliable with very low\nadjacency and orientation detection rates and inflated false positives. We\npropose a new algorithm, called PCMCI$^+$ that extends the PCMCI method from\n[Runge et al., 2019b] to also include discovery of contemporaneous links. It\nseparates the skeleton phase for lagged and contemporaneous conditioning sets\nand modifies the conditioning sets for the individual CI tests. We show that\nthis algorithm now benefits from increasing autocorrelation and yields much\nmore adjacency detection power and especially more orientation recall for\ncontemporaneous links while controlling false positives and having much shorter\nruntimes. Numerical experiments indicate that the algorithm can be of\nconsiderable use in many application scenarios for dozens of variables and\nlarge time delays.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 23:33:34 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Runge", "Jakob", ""]]}, {"id": "2003.03687", "submitter": "Bo Liu", "authors": "Bo Liu, Mengya Shen", "title": "Some Geometrical and Topological Properties of DNNs' Decision Boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Geometry and topology of decision regions are closely related with\nclassification performance and robustness against adversarial attacks. In this\npaper, we use differential geometry to theoretically explore the geometrical\nand topological properties of decision regions produced by deep neural networks\n(DNNs). The goal is to obtain some geometrical and topological properties of\ndecision boundaries for given DNN models, and provide some principled guidance\nto design and regularization of DNNs. First, we present the curvatures of\ndecision boundaries in terms of network parameters, and give sufficient\nconditions on network parameters for producing flat or developable decision\nboundaries. Based on the Gauss-Bonnet-Chern theorem in differential geometry,\nwe then propose a method to compute the Euler characteristics of compact\ndecision boundaries, and verify it with experiments.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 23:46:30 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 00:33:53 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Liu", "Bo", ""], ["Shen", "Mengya", ""]]}, {"id": "2003.03689", "submitter": "Behzad Ghazanfari", "authors": "Behzad Ghazanfari, Fatemeh Afghah, MohammadTaghi Hajiaghayi", "title": "Inverse Feature Learning: Feature learning based on Representation\n  Learning of Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes inverse feature learning as a novel supervised feature\nlearning technique that learns a set of high-level features for classification\nbased on an error representation approach. The key contribution of this method\nis to learn the representation of error as high-level features, while current\nrepresentation learning methods interpret error by loss functions which are\nobtained as a function of differences between the true labels and the predicted\nones. One advantage of such learning method is that the learned features for\neach class are independent of learned features for other classes; therefore,\nthis method can learn simultaneously meaning that it can learn new classes\nwithout retraining. Error representation learning can also help with\ngeneralization and reduce the chance of over-fitting by adding a set of\nimpactful features to the original data set which capture the relationships\nbetween each instance and different classes through an error generation and\nanalysis process. This method can be particularly effective in data sets, where\nthe instances of each class have diverse feature representations or the ones\nwith imbalanced classes. The experimental results show that the proposed method\nresults in significantly better performance compared to the state-of-the-art\nclassification techniques for several popular data sets. We hope this paper can\nopen a new path to utilize the proposed perspective of error representation\nlearning in different feature learning domains.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 00:22:26 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ghazanfari", "Behzad", ""], ["Afghah", "Fatemeh", ""], ["Hajiaghayi", "MohammadTaghi", ""]]}, {"id": "2003.03691", "submitter": "Yi Yang", "authors": "Yi Yang, Yuxuan Guo and Xiangyu Chang", "title": "Angle-Based Cost-Sensitive Multicategory Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world classification problems come with costs which can vary for\ndifferent types of misclassification. It is thus important to develop\ncost-sensitive classifiers which minimize the total misclassification cost.\nAlthough binary cost-sensitive classifiers have been well-studied, solving\nmulticategory classification problems is still challenging. A popular approach\nto address this issue is to construct K classification functions for a K-class\nproblem and remove the redundancy by imposing a sum-to-zero constraint.\nHowever, such method usually results in higher computational complexity and\ninefficient algorithms. In this paper, we propose a novel angle-based\ncost-sensitive classification framework for multicategory classification\nwithout the sum-to-zero constraint. Loss functions that included in the\nangle-based cost-sensitive classification framework are further justified to be\nFisher consistent. To show the usefulness of the framework, two cost-sensitive\nmulticategory boosting algorithms are derived as concrete instances. Numerical\nexperiments demonstrate that proposed boosting algorithms yield competitive\nclassification performances against other existing boosting approaches.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 00:42:15 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yang", "Yi", ""], ["Guo", "Yuxuan", ""], ["Chang", "Xiangyu", ""]]}, {"id": "2003.03692", "submitter": "Benyamin Ghojogh", "authors": "Haoran Ma, Benyamin Ghojogh, Maria N. Samad, Dongyu Zheng, Mark\n  Crowley", "title": "Isolation Mondrian Forest for Batch and Online Anomaly Detection", "comments": "Accepted for presentation at the IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC) 2020. The first three authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method, named isolation Mondrian forest (iMondrian forest),\nfor batch and online anomaly detection. The proposed method is a novel hybrid\nof isolation forest and Mondrian forest which are existing methods for batch\nanomaly detection and online random forest, respectively. iMondrian forest\ntakes the idea of isolation, using the depth of a node in a tree, and\nimplements it in the Mondrian forest structure. The result is a new data\nstructure which can accept streaming data in an online manner while being used\nfor anomaly detection. Our experiments show that iMondrian forest mostly\nperforms better than isolation forest in batch settings and has better or\ncomparable performance against other batch and online anomaly detection\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 00:42:23 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 00:11:30 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Ma", "Haoran", ""], ["Ghojogh", "Benyamin", ""], ["Samad", "Maria N.", ""], ["Zheng", "Dongyu", ""], ["Crowley", "Mark", ""]]}, {"id": "2003.03695", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi, Yi Yao and Ajay Divakaran", "title": "Progressive Growing of Neural ODEs", "comments": null, "journal-ref": "ICLR Workshop on Neural Networks and Differential Equations, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equations (NODEs) have proven to be a powerful\nmodeling tool for approximating (interpolation) and forecasting (extrapolation)\nirregularly sampled time series data. However, their performance degrades\nsubstantially when applied to real-world data, especially long-term data with\ncomplex behaviors (e.g., long-term trend across years, mid-term seasonality\nacross months, and short-term local variation across days). To address the\nmodeling of such complex data with different behaviors at different frequencies\n(time spans), we propose a novel progressive learning paradigm of NODEs for\nlong-term time series forecasting. Specifically, following the principle of\ncurriculum learning, we gradually increase the complexity of data and network\ncapacity as training progresses. Our experiments with both synthetic data and\nreal traffic data (PeMS Bay Area traffic data) show that our training\nmethodology consistently improves the performance of vanilla NODEs by over 64%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 01:15:01 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ayyubi", "Hammad A.", ""], ["Yao", "Yi", ""], ["Divakaran", "Ajay", ""]]}, {"id": "2003.03699", "submitter": "Depeng Xu", "authors": "Depeng Xu, Wei Du and Xintao Wu", "title": "Removing Disparate Impact of Differentially Private Stochastic Gradient\n  Descent on Model Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we enforce differential privacy in machine learning, the utility-privacy\ntrade-off is different w.r.t. each group. Gradient clipping and random noise\naddition disproportionately affect underrepresented and complex classes and\nsubgroups, which results in inequality in utility loss. In this work, we\nanalyze the inequality in utility loss by differential privacy and propose a\nmodified differentially private stochastic gradient descent (DPSGD), called\nDPSGD-F, to remove the potential disparate impact of differential privacy on\nthe protected group. DPSGD-F adjusts the contribution of samples in a group\ndepending on the group clipping bias such that differential privacy has no\ndisparate impact on group utility. Our experimental evaluation shows how group\nsample size and group clipping bias affect the impact of differential privacy\nin DPSGD, and how adaptive clipping for each group helps to mitigate the\ndisparate impact caused by differential privacy in DPSGD-F.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 02:06:15 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 21:04:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Depeng", ""], ["Du", "Wei", ""], ["Wu", "Xintao", ""]]}, {"id": "2003.03709", "submitter": "Yufeng Zhang", "authors": "Yufeng Zhang, Qi Cai, Zhuoran Yang, Zhaoran Wang", "title": "Generative Adversarial Imitation Learning with Neural Networks: Global\n  Optimality and Convergence Rate", "comments": "42 pages; accepted to ICML; initial draft submitted in Feb, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial imitation learning (GAIL) demonstrates tremendous\nsuccess in practice, especially when combined with neural networks. Different\nfrom reinforcement learning, GAIL learns both policy and reward function from\nexpert (human) demonstration. Despite its empirical success, it remains unclear\nwhether GAIL with neural networks converges to the globally optimal solution.\nThe major difficulty comes from the nonconvex-nonconcave minimax optimization\nstructure. To bridge the gap between practice and theory, we analyze a\ngradient-based algorithm with alternating updates and establish its sublinear\nconvergence to the globally optimal solution. To the best of our knowledge, our\nanalysis establishes the global optimality and convergence rate of GAIL with\nneural networks for the first time.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 03:39:36 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 03:33:18 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Zhang", "Yufeng", ""], ["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2003.03722", "submitter": "Jieyu Lin", "authors": "Jieyu Lin, Kristina Dzeparoska, Sai Qian Zhang, Alberto Leon-Garcia,\n  Nicolas Papernot", "title": "On the Robustness of Cooperative Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multi-agent reinforcement learning (c-MARL), agents learn to\ncooperatively take actions as a team to maximize a total team reward. We\nanalyze the robustness of c-MARL to adversaries capable of attacking one of the\nagents on a team. Through the ability to manipulate this agent's observations,\nthe adversary seeks to decrease the total team reward.\n  Attacking c-MARL is challenging for three reasons: first, it is difficult to\nestimate team rewards or how they are impacted by an agent mispredicting;\nsecond, models are non-differentiable; and third, the feature space is\nlow-dimensional. Thus, we introduce a novel attack. The attacker first trains a\npolicy network with reinforcement learning to find a wrong action it should\nencourage the victim agent to take. Then, the adversary uses targeted\nadversarial examples to force the victim to take this action.\n  Our results on the StartCraft II multi-agent benchmark demonstrate that\nc-MARL teams are highly vulnerable to perturbations applied to one of their\nagent's observations. By attacking a single agent, our attack method has highly\nnegative impact on the overall team reward, reducing it from 20 to 9.4. This\nresults in the team's winning rate to go down from 98.9% to 0%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 05:12:13 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lin", "Jieyu", ""], ["Dzeparoska", "Kristina", ""], ["Zhang", "Sai Qian", ""], ["Leon-Garcia", "Alberto", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2003.03777", "submitter": "Fernando Gama", "authors": "Fernando Gama, Elvin Isufi, Geert Leus, Alejandro Ribeiro", "title": "Graphs, Convolutions, and Neural Networks: From Graph Filters to Graph\n  Neural Networks", "comments": "Submitted to IEEE SPM Special Issue on Graph Signal Processing:\n  Foundations and Emerging Directions", "journal-ref": null, "doi": "10.1109/MSP.2020.3016143", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network data can be conveniently modeled as a graph signal, where data values\nare assigned to nodes of a graph that describes the underlying network\ntopology. Successful learning from network data is built upon methods that\neffectively exploit this graph structure. In this work, we leverage graph\nsignal processing to characterize the representation space of graph neural\nnetworks (GNNs). We discuss the role of graph convolutional filters in GNNs and\nshow that any architecture built with such filters has the fundamental\nproperties of permutation equivariance and stability to changes in the\ntopology. These two properties offer insight about the workings of GNNs and\nhelp explain their scalability and transferability properties which, coupled\nwith their local and distributed nature, make GNNs powerful tools for learning\nin physical networks. We also introduce GNN extensions using edge-varying and\nautoregressive moving average graph filters and discuss their properties.\nFinally, we study the use of GNNs in recommender systems and learning\ndecentralized controllers for robot swarms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 13:02:15 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 22:54:12 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 05:43:39 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 18:41:19 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 13:35:21 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gama", "Fernando", ""], ["Isufi", "Elvin", ""], ["Leus", "Geert", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2003.03778", "submitter": "Rapha\\\"el Dang-Nhu", "authors": "Rapha\\\"el Dang-Nhu, Gagandeep Singh, Pavol Bielik, Martin Vechev", "title": "Adversarial Attacks on Probabilistic Autoregressive Forecasting Models", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an effective generation of adversarial attacks on neural models\nthat output a sequence of probability distributions rather than a sequence of\nsingle values. This setting includes the recently proposed deep probabilistic\nautoregressive forecasting models that estimate the probability distribution of\na time series given its past and achieve state-of-the-art results in a diverse\nset of application domains. The key technical challenge we address is\neffectively differentiating through the Monte-Carlo estimation of statistics of\nthe joint distribution of the output sequence. Additionally, we extend prior\nwork on probabilistic forecasting to the Bayesian setting which allows\nconditioning on future observations, instead of only on past observations. We\ndemonstrate that our approach can successfully generate attacks with small\ninput perturbations in two challenging tasks where robust decision making is\ncrucial: stock market trading and prediction of electricity consumption.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 13:08:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Dang-Nhu", "Rapha\u00ebl", ""], ["Singh", "Gagandeep", ""], ["Bielik", "Pavol", ""], ["Vechev", "Martin", ""]]}, {"id": "2003.03813", "submitter": "Petar Milin", "authors": "Petar Milin, Harish Tayyar Madabushi, Michael Croucher, Dagmar Divjak", "title": "Keeping it simple: Implementation and performance of the proto-principle\n  of adaptation and learning in the language sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Widrow-Hoff rule and its applications to\nlanguage data. After contextualizing the rule historically and placing it in\nthe chain of neurally inspired artificial learning models, we explain its\nrationale and implementational considerations. Using a number of case studies\nwe illustrate how the Widrow-Hoff rule offers unexpected opportunities for the\ncomputational simulation of a range of language phenomena that make it possible\nto approach old problems from a novel perspective.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 17:07:08 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Milin", "Petar", ""], ["Madabushi", "Harish Tayyar", ""], ["Croucher", "Michael", ""], ["Divjak", "Dagmar", ""]]}, {"id": "2003.03828", "submitter": "Grigorios Chrysos", "authors": "Grigorios G. Chrysos, Stylianos Moschoglou, Giorgos Bouritsas, Yannis\n  Panagakis, Jiankang Deng, Stefanos Zafeiriou", "title": "$\\Pi-$nets: Deep Polynomial Neural Networks", "comments": "Accepted in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (DCNNs) is currently the method of choice\nboth for generative, as well as for discriminative learning in computer vision\nand machine learning. The success of DCNNs can be attributed to the careful\nselection of their building blocks (e.g., residual blocks, rectifiers,\nsophisticated normalization schemes, to mention but a few). In this paper, we\npropose $\\Pi$-Nets, a new class of DCNNs. $\\Pi$-Nets are polynomial neural\nnetworks, i.e., the output is a high-order polynomial of the input. $\\Pi$-Nets\ncan be implemented using special kind of skip connections and their parameters\ncan be represented via high-order tensors. We empirically demonstrate that\n$\\Pi$-Nets have better representation power than standard DCNNs and they even\nproduce good results without the use of non-linear activation functions in a\nlarge battery of tasks and signals, i.e., images, graphs, and audio. When used\nin conjunction with activation functions, $\\Pi$-Nets produce state-of-the-art\nresults in challenging tasks, such as image generation. Lastly, our framework\nelucidates why recent generative models, such as StyleGAN, improve upon their\npredecessors, e.g., ProGAN.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 18:48:43 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 17:25:40 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Chrysos", "Grigorios G.", ""], ["Moschoglou", "Stylianos", ""], ["Bouritsas", "Giorgos", ""], ["Panagakis", "Yannis", ""], ["Deng", "Jiankang", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2003.03835", "submitter": "Lorenzo Nespoli", "authors": "Lorenzo Nespoli, Vasco Medici", "title": "Multivariate Boosted Trees and Applications to Forecasting and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted trees are competition-winning, general-purpose,\nnon-parametric regressors, which exploit sequential model fitting and gradient\ndescent to minimize a specific loss function. The most popular implementations\nare tailored to univariate regression and classification tasks, precluding the\npossibility of capturing multivariate target cross-correlations and applying\nconditional penalties to the predictions. In this paper, we present a\ncomputationally efficient algorithm for fitting multivariate boosted trees. We\nshow that multivariate trees can outperform their univariate counterpart when\nthe predictions are correlated. Furthermore, the algorithm allows to\narbitrarily regularize the predictions, so that properties like smoothness,\nconsistency and functional relations can be enforced. We present applications\nand numerical results related to forecasting and control.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 19:26:59 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Nespoli", "Lorenzo", ""], ["Medici", "Vasco", ""]]}, {"id": "2003.03862", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Improving Training on Noisy Stuctured Labels", "comments": "8 pages main text, 13 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained annotations---e.g. dense image labels, image segmentation and\ntext tagging---are useful in many ML applications but they are labor-intensive\nto generate. Moreover there are often systematic, structured errors in these\nfine-grained annotations. For example, a car might be entirely unannotated in\nthe image, or the boundary between a car and street might only be coarsely\nannotated. Standard ML training on data with such structured errors produces\nmodels with biases and poor performance. In this work, we propose a novel\nframework of Error-Correcting Networks (ECN) to address the challenge of\nlearning in the presence structured error in fine-grained annotations. Given a\nlarge noisy dataset with commonly occurring structured errors, and a much\nsmaller dataset with more accurate annotations, ECN is able to substantially\nimprove the prediction of fine-grained annotations compared to standard\napproaches for training on noisy data. It does so by learning to leverage the\nstructures in the annotations and in the noisy labels. Systematic experiments\non image segmentation and text tagging demonstrate the strong performance of\nECN in improving training on noisy structured labels.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 22:55:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "2003.03882", "submitter": "Yong Liu", "authors": "Yong Liu and Lizhong Ding and Weiping Wang", "title": "Theoretical Analysis of Divide-and-Conquer ERM: Beyond Square Loss and\n  RKHS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical analysis of the divide-and-conquer based distributed learning\nwith least square loss in the reproducing kernel Hilbert space (RKHS) have\nrecently been explored within the framework of learning theory. However, the\nstudies on learning theory for general loss functions and hypothesis spaces\nremain limited. To fill the gap, we study the risk performance of distributed\nempirical risk minimization (ERM) for general loss functions and hypothesis\nspaces. The main contributions are two-fold. First, we derive two tight risk\nbounds under certain basic assumptions on the hypothesis space, as well as the\nsmoothness, Lipschitz continuity, strong convexity of the loss function.\nSecond, we further develop a more general risk bound for distributed ERM\nwithout the restriction of strong convexity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 01:50:19 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 01:34:05 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 07:59:08 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Liu", "Yong", ""], ["Ding", "Lizhong", ""], ["Wang", "Weiping", ""]]}, {"id": "2003.03888", "submitter": "Yong Liu", "authors": "Yong Liu and Lizhong Ding and Weiping Wang", "title": "Nearly Optimal Clustering Risk Bounds for Kernel K-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the statistical properties of kernel $k$-means and\nobtain a nearly optimal excess clustering risk bound, substantially improving\nthe state-of-art bounds in the existing clustering risk analyses. We further\nanalyze the statistical effect of computational approximations of the\nNystr\\\"{o}m kernel $k$-means, and prove that it achieves the same statistical\naccuracy as the exact kernel $k$-means considering only $\\Omega(\\sqrt{nk})$\nNystr\\\"{o}m landmark points. To the best of our knowledge, such sharp excess\nclustering risk bounds for kernel (or approximate kernel) $k$-means have never\nbeen proposed before.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 02:13:32 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 01:40:12 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Liu", "Yong", ""], ["Ding", "Lizhong", ""], ["Wang", "Weiping", ""]]}, {"id": "2003.03892", "submitter": "Yihe Dong", "authors": "Yihe Dong, Will Sawin", "title": "COPT: Coordinated Optimal Transport for Graph Sketching", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce COPT, a novel distance metric between graphs defined via an\noptimization routine, computing a coordinated pair of optimal transport maps\nsimultaneously. This gives an unsupervised way to learn general-purpose graph\nrepresentation, applicable to both graph sketching and graph comparison. COPT\ninvolves simultaneously optimizing dual transport plans, one between the\nvertices of two graphs, and another between graph signal probability\ndistributions. We show theoretically that our method preserves important global\nstructural information on graphs, in particular spectral information, and\nanalyze connections to existing studies. Empirically, COPT outperforms state of\nthe art methods in graph classification on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 02:30:23 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 18:21:17 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Dong", "Yihe", ""], ["Sawin", "Will", ""]]}, {"id": "2003.03893", "submitter": "You-Gan Wang", "authors": "Jinran Wu and You-Gan Wang", "title": "A working likelihood approach to support vector regression with a\n  data-driven insensitivity parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The insensitive parameter in support vector regression determines the set of\nsupport vectors that greatly impacts the prediction. A data-driven approach is\nproposed to determine an approximate value for this insensitive parameter by\nminimizing a generalized loss function originating from the likelihood\nprinciple. This data-driven support vector regression also statistically\nstandardizes samples using the scale of noises. Nonlinear and linear numerical\nsimulations with three types of noises ($\\epsilon$-Laplacian distribution,\nnormal distribution, and uniform distribution), and in addition, five real\nbenchmark data sets, are used to test the capacity of the proposed method.\nBased on all of the simulations and the five case studies, the proposed support\nvector regression using a working likelihood, data-driven insensitive parameter\nis superior and has lower computational costs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 02:32:32 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wu", "Jinran", ""], ["Wang", "You-Gan", ""]]}, {"id": "2003.03900", "submitter": "Aman Sinha", "authors": "Aman Sinha, Matthew O'Kelly, Hongrui Zheng, Rahul Mangharam, John\n  Duchi, Russ Tedrake", "title": "FormulaZero: Distributionally Robust Online Adaptation via Offline\n  Population Synthesis", "comments": "ICML 2020: https://icml.cc/virtual/2020/poster/6277", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing performance and safety is crucial to deploying autonomous vehicles\nin multi-agent environments. In particular, autonomous racing is a domain that\npenalizes safe but conservative policies, highlighting the need for robust,\nadaptive strategies. Current approaches either make simplifying assumptions\nabout other agents or lack robust mechanisms for online adaptation. This work\nmakes algorithmic contributions to both challenges. First, to generate a\nrealistic, diverse set of opponents, we develop a novel method for self-play\nbased on replica-exchange Markov chain Monte Carlo. Second, we propose a\ndistributionally robust bandit optimization procedure that adaptively adjusts\nrisk aversion relative to uncertainty in beliefs about opponents' behaviors. We\nrigorously quantify the tradeoffs in performance and robustness when\napproximating these computations in real-time motion-planning, and we\ndemonstrate our methods experimentally on autonomous vehicles that achieve\nscaled speeds comparable to Formula One racecars.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 03:07:57 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 17:00:39 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Sinha", "Aman", ""], ["O'Kelly", "Matthew", ""], ["Zheng", "Hongrui", ""], ["Mangharam", "Rahul", ""], ["Duchi", "John", ""], ["Tedrake", "Russ", ""]]}, {"id": "2003.03919", "submitter": "Sankalp Garg", "authors": "Sankalp Garg, Navodita Sharma, Woojeong Jin, Xiang Ren", "title": "Temporal Attribute Prediction via Joint Modeling of Multi-Relational\n  Structure Evolution", "comments": "In Proceedings of IJCAI 2020. Code can be found at\n  https://github.com/INK-USC/DArtNet . The sole copyright holder is IJCAI\n  (International Joint Conferences on Artificial Intelligence), all rights\n  reserved. Original Publication available at\n  https://www.ijcai.org/Proceedings/2020/386", "journal-ref": null, "doi": "10.24963/ijcai.2020/386", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction is an important problem in machine learning. Previous\nmethods for time series prediction did not involve additional information. With\na lot of dynamic knowledge graphs available, we can use this additional\ninformation to predict the time series better. Recently, there has been a focus\non the application of deep representation learning on dynamic graphs. These\nmethods predict the structure of the graph by reasoning over the interactions\nin the graph at previous time steps. In this paper, we propose a new framework\nto incorporate the information from dynamic knowledge graphs for time series\nprediction. We show that if the information contained in the graph and the time\nseries data are closely related, then this inter-dependence can be used to\npredict the time series with improved accuracy. Our framework, DArtNet, learns\na static embedding for every node in the graph as well as a dynamic embedding\nwhich is dependent on the dynamic attribute value (time-series). Then it\ncaptures the information from the neighborhood by taking a relation specific\nmean and encodes the history information using RNN. We jointly train the model\nlink prediction and attribute prediction. We evaluate our method on five\nspecially curated datasets for this problem and show a consistent improvement\nin time series prediction results. We release the data and code of model\nDArtNet for future research at https://github.com/INK-USC/DArtNet .\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 04:16:43 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 09:43:10 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Garg", "Sankalp", ""], ["Sharma", "Navodita", ""], ["Jin", "Woojeong", ""], ["Ren", "Xiang", ""]]}, {"id": "2003.03924", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Nan Jiang", "title": "Q* Approximation Schemes for Batch Reinforcement Learning: A Theoretical\n  Comparison", "comments": "Published in UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove performance guarantees of two algorithms for approximating $Q^\\star$\nin batch reinforcement learning. Compared to classical iterative methods such\nas Fitted Q-Iteration---whose performance loss incurs quadratic dependence on\nhorizon---these methods estimate (some forms of) the Bellman error and enjoy\nlinear-in-horizon error propagation, a property established for the first time\nfor algorithms that rely solely on batch data and output stationary policies.\nOne of the algorithms uses a novel and explicit importance-weighting correction\nto overcome the infamous \"double sampling\" difficulty in Bellman error\nestimation, and does not use any squared losses. Our analyses reveal its\ndistinct characteristics and potential advantages compared to classical\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 05:12:39 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:32:46 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 21:37:37 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 04:09:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Xie", "Tengyang", ""], ["Jiang", "Nan", ""]]}, {"id": "2003.03934", "submitter": "Raha Moraffah", "authors": "Raha Moraffah, Mansooreh Karami, Ruocheng Guo, Adrienne Raglin, Huan\n  Liu", "title": "Causal Interpretability for Machine Learning -- Problems, Methods and\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have had discernible achievements in a myriad of\napplications. However, most of these models are black-boxes, and it is obscure\nhow the decisions are made by them. This makes the models unreliable and\nuntrustworthy. To provide insights into the decision making processes of these\nmodels, a variety of traditional interpretable models have been proposed.\nMoreover, to generate more human-friendly explanations, recent work on\ninterpretability tries to answer questions related to causality such as \"Why\ndoes this model makes such decisions?\" or \"Was it a specific feature that\ncaused the decision made by the model?\". In this work, models that aim to\nanswer causal questions are referred to as causal interpretable models. The\nexisting surveys have covered concepts and methodologies of traditional\ninterpretability. In this work, we present a comprehensive survey on causal\ninterpretable models from the aspects of the problems and methods. In addition,\nthis survey provides in-depth insights into the existing evaluation metrics for\nmeasuring interpretability, which can help practitioners understand for what\nscenarios each evaluation metric is suitable.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 06:16:00 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 17:17:56 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:23:46 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Moraffah", "Raha", ""], ["Karami", "Mansooreh", ""], ["Guo", "Ruocheng", ""], ["Raglin", "Adrienne", ""], ["Liu", "Huan", ""]]}, {"id": "2003.03946", "submitter": "Sivan Sabato", "authors": "Sanjoy Dasgupta and Sivan Sabato", "title": "Robust Learning from Discriminative Feature Feedback", "comments": "To appear in AISTATS 2020", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics (AISTATS), 973--982, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced the model of learning from discriminative feature\nfeedback, in which a human annotator not only provides labels of instances, but\nalso identifies discriminative features that highlight important differences\nbetween pairs of instances. It was shown that such feedback can be conducive to\nlearning, and makes it possible to efficiently learn some concept classes that\nwould otherwise be intractable. However, these results all relied upon perfect\nannotator feedback. In this paper, we introduce a more realistic, robust\nversion of the framework, in which the annotator is allowed to make mistakes.\nWe show how such errors can be handled algorithmically, in both an adversarial\nand a stochastic setting. In particular, we derive regret bounds in both\nsettings that, as in the case of a perfect annotator, are independent of the\nnumber of features. We show that this result cannot be obtained by a naive\nreduction from the robust setting to the non-robust setting.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 06:45:52 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Sabato", "Sivan", ""]]}, {"id": "2003.03960", "submitter": "Hikaru Shindo", "authors": "Hikaru Shindo, Masaaki Nishino, Yasuaki Kobayashi, Akihiro Yamamoto", "title": "Metric Learning for Ordered Labeled Trees with pq-grams", "comments": "Accepted at ECAI 2020 (full paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the similarity between two data points plays a vital role in many\nmachine learning algorithms. Metric learning has the aim of learning a good\nmetric automatically from data. Most existing studies on metric learning for\ntree-structured data have adopted the approach of learning the tree edit\ndistance. However, the edit distance is not amenable for big data analysis\nbecause it incurs high computation cost. In this paper, we propose a new metric\nlearning approach for tree-structured data with pq-grams. The pq-gram distance\nis a distance for ordered labeled trees, and has much lower computation cost\nthan the tree edit distance. In order to perform metric learning based on\npq-grams, we propose a new differentiable parameterized distance, weighted\npq-gram distance. We also propose a way to learn the proposed distance based on\nLarge Margin Nearest Neighbors (LMNN), which is a well-studied and practical\nmetric learning scheme. We formulate the metric learning problem as an\noptimization problem and use the gradient descent technique to perform metric\nlearning. We empirically show that the proposed approach not only achieves\ncompetitive results with the state-of-the-art edit distance-based methods in\nvarious classification problems, but also solves the classification problems\nmuch more rapidly than the edit distance-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 08:04:47 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Shindo", "Hikaru", ""], ["Nishino", "Masaaki", ""], ["Kobayashi", "Yasuaki", ""], ["Yamamoto", "Akihiro", ""]]}, {"id": "2003.03977", "submitter": "Nikhil Iyer", "authors": "Nikhil Iyer, V Thejas, Nipun Kwatra, Ramachandran Ramjee, Muthian\n  Sivathanu", "title": "Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate\n  Schedule", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several papers argue that wide minima generalize better than narrow minima.\nIn this paper, through detailed experiments that not only corroborate the\ngeneralization properties of wide minima, we also provide empirical evidence\nfor a new hypothesis that the density of wide minima is likely lower than the\ndensity of narrow minima. Further, motivated by this hypothesis, we design a\nnovel explore-exploit learning rate schedule. On a variety of image and natural\nlanguage datasets, compared to their original hand-tuned learning rate\nbaselines, we show that our explore-exploit schedule can result in either up to\n0.84% higher absolute accuracy using the original training budget or up to 57%\nreduced training time while achieving the original reported accuracy. For\nexample, we achieve state-of-the-art (SOTA) accuracy for IWSLT'14 (DE-EN)\ndataset by just modifying the learning rate schedule of a high performing\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 09:01:53 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 15:31:50 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 05:47:56 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 06:58:28 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 05:48:04 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Iyer", "Nikhil", ""], ["Thejas", "V", ""], ["Kwatra", "Nipun", ""], ["Ramjee", "Ramachandran", ""], ["Sivathanu", "Muthian", ""]]}, {"id": "2003.04033", "submitter": "Zehao Dou", "authors": "Yuanzhi Li, Zehao Dou", "title": "Making Method of Moments Great Again? -- How can GANs learn\n  distributions", "comments": "50+ pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are widely used models to learn\ncomplex real-world distributions. In GANs, the training of the generator\nusually stops when the discriminator can no longer distinguish the generator's\noutput from the set of training examples. A central question of GANs is that\nwhen the training stops, whether the generated distribution is actually close\nto the target distribution, and how the training process reaches to such\nconfigurations efficiently? In this paper, we established a theoretical results\ntowards understanding this generator-discriminator training process. We\nempirically observe that during the earlier stage of the GANs training, the\ndiscriminator is trying to force the generator to match the low degree moments\nbetween the generator's output and the target distribution. Moreover, only by\nmatching these empirical moments over polynomially many training examples, we\nprove that the generator can already learn notable class of distributions,\nincluding those that can be generated by two-layer neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 10:50:35 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 16:26:49 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 20:56:37 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Yuanzhi", ""], ["Dou", "Zehao", ""]]}, {"id": "2003.04046", "submitter": "Shengchao Yan", "authors": "Shengchao Yan, Jingwei Zhang, Daniel B\\\"uscher, Wolfram Burgard", "title": "Efficiency and Equity are Both Essential: A Generalized Traffic Signal\n  Controller with Deep Reinforcement Learning", "comments": "Published as a conference paper at IROS 2020", "journal-ref": null, "doi": "10.1109/IROS45743.2020.9340784", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal controllers play an essential role in today's traffic system.\nHowever, the majority of them currently is not sufficiently flexible or\nadaptive to generate optimal traffic schedules. In this paper we present an\napproach to learning policies for signal controllers using deep reinforcement\nlearning aiming for optimized traffic flow. Our method uses a novel formulation\nof the reward function that simultaneously considers efficiency and equity. We\nfurthermore present a general approach to find the bound for the proposed\nequity factor and we introduce the adaptive discounting approach that greatly\nstabilizes learning and helps to maintain a high flexibility of green light\nduration. The experimental evaluations on both simulated and real-world data\ndemonstrate that our proposed algorithm achieves state-of-the-art performance\n(previously held by traditional non-learning methods) on a wide range of\ntraffic situations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 11:34:52 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 16:22:44 GMT"}, {"version": "v3", "created": "Sun, 27 Dec 2020 12:26:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Yan", "Shengchao", ""], ["Zhang", "Jingwei", ""], ["B\u00fcscher", "Daniel", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2003.04063", "submitter": "Lukas Hedegaard Morsing", "authors": "Lukas Hedegaard Morsing, Omar Ali Sheikh-Omar and Alexandros Iosifidis", "title": "Supervised Domain Adaptation using Graph Embedding", "comments": "7 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting deep convolutional neural networks to perform well requires a large\namount of training data. When the available labelled data is small, it is often\nbeneficial to use transfer learning to leverage a related larger dataset\n(source) in order to improve the performance on the small dataset (target).\nAmong the transfer learning approaches, domain adaptation methods assume that\ndistributions between the two domains are shifted and attempt to realign them.\nIn this paper, we consider the domain adaptation problem from the perspective\nof dimensionality reduction and propose a generic framework based on graph\nembedding. Instead of solving the generalised eigenvalue problem, we formulate\nthe graph-preserving criterion as a loss in the neural network and learn a\ndomain-invariant feature transformation in an end-to-end fashion. We show that\nthe proposed approach leads to a powerful Domain Adaptation framework; a simple\nLDA-inspired instantiation of the framework leads to state-of-the-art\nperformance on two of the most widely used Domain Adaptation benchmarks,\nOffice31 and MNIST to USPS datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:25:13 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 09:35:19 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Morsing", "Lukas Hedegaard", ""], ["Sheikh-Omar", "Omar Ali", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2003.04069", "submitter": "Ahmed Touati", "authors": "Ahmed Touati, Adrien Ali Taiga, Marc G. Bellemare", "title": "Zooming for Efficient Model-Free Reinforcement Learning in Metric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wealth of research into provably efficient reinforcement learning\nalgorithms, most works focus on tabular representation and thus struggle to\nhandle exponentially or infinitely large state-action spaces. In this paper, we\nconsider episodic reinforcement learning with a continuous state-action space\nwhich is assumed to be equipped with a natural metric that characterizes the\nproximity between different states and actions. We propose ZoomRL, an online\nalgorithm that leverages ideas from continuous bandits to learn an adaptive\ndiscretization of the joint space by zooming in more promising and frequently\nvisited regions while carefully balancing the exploitation-exploration\ntrade-off. We show that ZoomRL achieves a worst-case regret\n$\\tilde{O}(H^{\\frac{5}{2}} K^{\\frac{d+1}{d+2}})$ where $H$ is the planning\nhorizon, $K$ is the number of episodes and $d$ is the covering dimension of the\nspace with respect to the metric. Moreover, our algorithm enjoys improved\nmetric-dependent guarantees that reflect the geometry of the underlying space.\nFinally, we show that our algorithm is robust to small misspecification errors.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:32:02 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Touati", "Ahmed", ""], ["Taiga", "Adrien Ali", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2003.04078", "submitter": "Ryoma Sato", "authors": "Ryoma Sato", "title": "A Survey on The Expressive Power of Graph Neural Networks", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are effective machine learning models for\nvarious graph learning problems. Despite their empirical successes, the\ntheoretical limitations of GNNs have been revealed recently. Consequently, many\nGNN models have been proposed to overcome these limitations. In this survey, we\nprovide a comprehensive overview of the expressive power of GNNs and provably\npowerful variants of GNNs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:37:40 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 00:43:36 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 13:04:56 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 05:22:01 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Sato", "Ryoma", ""]]}, {"id": "2003.04108", "submitter": "Ahmed Touati", "authors": "Ahmed Touati, Amy Zhang, Joelle Pineau, Pascal Vincent", "title": "Stable Policy Optimization via Off-Policy Divergence Regularization", "comments": null, "journal-ref": "Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI), PMLR volume 124, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization\n(PPO) are among the most successful policy gradient approaches in deep\nreinforcement learning (RL). While these methods achieve state-of-the-art\nperformance across a wide range of challenging tasks, there is room for\nimprovement in the stabilization of the policy learning and how the off-policy\ndata are used. In this paper we revisit the theoretical foundations of these\nalgorithms and propose a new algorithm which stabilizes the policy improvement\nthrough a proximity term that constrains the discounted state-action visitation\ndistribution induced by consecutive policies to be close to one another. This\nproximity term, expressed in terms of the divergence between the visitation\ndistributions, is learned in an off-policy and adversarial manner. We\nempirically show that our proposed method can have a beneficial effect on\nstability and improve final performance in benchmark high-dimensional control\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:05:47 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:04:22 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Touati", "Ahmed", ""], ["Zhang", "Amy", ""], ["Pineau", "Joelle", ""], ["Vincent", "Pascal", ""]]}, {"id": "2003.04109", "submitter": "Inon Peled", "authors": "Inon Peled, Raghuveer Kamalakar, Carlos Lima Azevedo, Francisco C.\n  Pereira", "title": "QTIP: Quick simulation-based adaptation of Traffic model per Incident\n  Parameters", "comments": "18 pages, 13 figures, 4 tables", "journal-ref": null, "doi": "10.1080/17477778.2020.1756702", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current data-driven traffic prediction models are usually trained with large\ndatasets, e.g. several months of speeds and flows. Such models provide very\ngood fit for ordinary road conditions, but often fail just when they are most\nneeded: when traffic suffers a sudden and significant disruption, such as a\nroad incident. In this work, we describe QTIP: a simulation-based framework for\nquasi-instantaneous adaptation of prediction models upon traffic disruption. In\na nutshell, QTIP performs real-time simulations of the affected road for\nmultiple scenarios, analyzes the results, and suggests a change to an ordinary\nprediction model accordingly. QTIP constructs the simulated scenarios per\nproperties of the incident, as conveyed by immediate distress signals from\naffected vehicles. Such real-time signals are provided by In-Vehicle Monitor\nSystems, which are becoming increasingly prevalent world-wide. We experiment\nQTIP in a case study of a Danish motorway, and the results show that QTIP can\nimprove traffic prediction in the first critical minutes of road incidents.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:07:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Peled", "Inon", ""], ["Kamalakar", "Raghuveer", ""], ["Azevedo", "Carlos Lima", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2003.04116", "submitter": "M. G. Sarwar Murshed", "authors": "M. G. Sarwar Murshed, Edward Verenich, James J. Carroll, Nazar Khan,\n  Faraz Hussain", "title": "Hazard Detection in Supermarkets using Deep Learning on the Edge", "comments": "6 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supermarkets need to ensure clean and safe environments for both shoppers and\nemployees. Slips, trips, and falls can result in injuries that have a physical\nas well as financial cost. Timely detection of hazardous conditions such as\nspilled liquids or fallen items on supermarket floors can reduce the chances of\nserious injuries. This paper presents EdgeLite, a novel, lightweight deep\nlearning model for easy deployment and inference on resource-constrained\ndevices. We describe the use of EdgeLite on two edge devices for detecting\nsupermarket floor hazards. On a hazard detection dataset that we developed,\nEdgeLite, when deployed on edge devices, outperformed six state-of-the-art\nobject detection models in terms of accuracy while having comparable memory\nusage and inference time.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:43:55 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Murshed", "M. G. Sarwar", ""], ["Verenich", "Edward", ""], ["Carroll", "James J.", ""], ["Khan", "Nazar", ""], ["Hussain", "Faraz", ""]]}, {"id": "2003.04117", "submitter": "M. G. Sarwar Murshed", "authors": "Edward Verenich, Alvaro Velasquez, M.G. Sarwar Murshed, Faraz Hussain", "title": "The Utility of Feature Reuse: Transfer Learning in Data-Starved Regimes", "comments": "3 pages, 1 figure, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of transfer learning with deep neural networks has increasingly\nbecome widespread for deploying well-tested computer vision systems to newer\ndomains, especially those with limited datasets. We describe a transfer\nlearning use case for a domain with a data-starved regime, having fewer than\n100 labeled target samples. We evaluate the effectiveness of convolutional\nfeature extraction and fine-tuning of overparameterized models with respect to\nthe size of target training data, as well as their generalization performance\non data with covariate shift, or out-of-distribution (OOD) data. Our\nexperiments show that both overparameterization and feature reuse contribute to\nsuccessful application of transfer learning in training image classifiers in\ndata-starved regimes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:48:58 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Verenich", "Edward", ""], ["Velasquez", "Alvaro", ""], ["Murshed", "M. G. Sarwar", ""], ["Hussain", "Faraz", ""]]}, {"id": "2003.04125", "submitter": "Ayman Boustati", "authors": "Ayman Boustati, Sattar Vakili, James Hensman, ST John", "title": "Amortized variance reduction for doubly stochastic objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate inference in complex probabilistic models such as deep Gaussian\nprocesses requires the optimisation of doubly stochastic objective functions.\nThese objectives incorporate randomness both from mini-batch subsampling of the\ndata and from Monte Carlo estimation of expectations. If the gradient variance\nis high, the stochastic optimisation problem becomes difficult with a slow rate\nof convergence. Control variates can be used to reduce the variance, but past\napproaches do not take into account how mini-batch stochasticity affects\nsampling stochasticity, resulting in sub-optimal variance reduction. We propose\na new approach in which we use a recognition network to cheaply approximate the\noptimal control variate for each mini-batch, with no additional model gradient\ncomputations. We illustrate the properties of this proposal and test its\nperformance on logistic regression and deep Gaussian processes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:23:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Boustati", "Ayman", ""], ["Vakili", "Sattar", ""], ["Hensman", "James", ""], ["John", "ST", ""]]}, {"id": "2003.04135", "submitter": "Ibrahim Jubran", "authors": "Ibrahim Jubran and Murad Tukan and Alaa Maalouf and Dan Feldman", "title": "Sets Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input to the \\emph{sets-$k$-means} problem is an integer $k\\geq 1$ and a\nset $\\mathcal{P}=\\{P_1,\\cdots,P_n\\}$ of sets in $\\mathbb{R}^d$. The goal is to\ncompute a set $C$ of $k$ centers (points) in $\\mathbb{R}^d$ that minimizes the\nsum $\\sum_{P\\in \\mathcal{P}} \\min_{p\\in P, c\\in C}\\left\\| p-c \\right\\|^2$ of\nsquared distances to these sets. An \\emph{$\\varepsilon$-core-set} for this\nproblem is a weighted subset of $\\mathcal{P}$ that approximates this sum up to\n$1\\pm\\varepsilon$ factor, for \\emph{every} set $C$ of $k$ centers in\n$\\mathbb{R}^d$. We prove that such a core-set of $O(\\log^2{n})$ sets always\nexists, and can be computed in $O(n\\log{n})$ time, for every input\n$\\mathcal{P}$ and every fixed $d,k\\geq 1$ and $\\varepsilon \\in (0,1)$. The\nresult easily generalized for any metric space, distances to the power of\n$z>0$, and M-estimators that handle outliers. Applying an inefficient but\noptimal algorithm on this coreset allows us to obtain the first PTAS\n($1+\\varepsilon$ approximation) for the sets-$k$-means problem that takes time\nnear linear in $n$. This is the first result even for sets-mean on the plane\n($k=1$, $d=2$). Open source code and experimental results for document\nclassification and facility locations are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:30:30 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Jubran", "Ibrahim", ""], ["Tukan", "Murad", ""], ["Maalouf", "Alaa", ""], ["Feldman", "Dan", ""]]}, {"id": "2003.04166", "submitter": "Hawoong Jeong", "authors": "Dong-Kyum Kim, Youngkyoung Bae, Sangyun Lee, and Hawoong Jeong", "title": "Learning entropy production via neural networks", "comments": "6+8 pages, 4+8 figures", "journal-ref": "Phys. Rev. Lett. 125, 140604 (2020)", "doi": "10.1103/PhysRevLett.125.140604", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Letter presents a neural estimator for entropy production, or NEEP, that\nestimates entropy production (EP) from trajectories of relevant variables\nwithout detailed information on the system dynamics. For steady state, we\nrigorously prove that the estimator, which can be built up from different\nchoices of deep neural networks, provides stochastic EP by optimizing the\nobjective function proposed here. We verify the NEEP with the stochastic\nprocesses of the bead-spring and discrete flashing ratchet models, and also\ndemonstrate that our method is applicable to high-dimensional data and can\nprovide coarse-grained EP for Markov systems with unobservable states.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:23:36 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 14:56:13 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 06:58:51 GMT"}, {"version": "v4", "created": "Sat, 12 Sep 2020 02:59:17 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Kim", "Dong-Kyum", ""], ["Bae", "Youngkyoung", ""], ["Lee", "Sangyun", ""], ["Jeong", "Hawoong", ""]]}, {"id": "2003.04173", "submitter": "Alexey Zaytsev", "authors": "Ivan Fursov, Alexey Zaytsev, Nikita Kluchnikov, Andrey Kravchenko,\n  Evgeny Burnaev", "title": "Gradient-based adversarial attacks on categorical sequence models via\n  traversing an embedded world", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models suffer from a phenomenon called adversarial attacks: we\ncan apply minor changes to the model input to fool a classifier for a\nparticular example. The literature mostly considers adversarial attacks on\nmodels with images and other structured inputs. However, the adversarial\nattacks for categorical sequences can also be harmful. Successful attacks for\ninputs in the form of categorical sequences should address the following\nchallenges: (1) non-differentiability of the target function, (2) constraints\non transformations of initial sequences, and (3) diversity of possible\nproblems. We handle these challenges using two black-box adversarial attacks.\nThe first approach adopts a Monte-Carlo method and allows usage in any\nscenario, the second approach uses a continuous relaxation of models and target\nmetrics, and thus allows usage of state-of-the-art methods for adversarial\nattacks with little additional effort. Results for money transactions, medical\nfraud, and NLP datasets suggest that proposed methods generate reasonable\nadversarial sequences that are close to original ones but fool machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:31:36 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 06:16:28 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 17:31:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Fursov", "Ivan", ""], ["Zaytsev", "Alexey", ""], ["Kluchnikov", "Nikita", ""], ["Kravchenko", "Andrey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2003.04180", "submitter": "Pritish Kamath", "authors": "Pritish Kamath, Omar Montasser, Nathan Srebro", "title": "Approximate is Good Enough: Probabilistic Variants of Dimensional and\n  Margin Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and study approximate notions of dimensional and margin\ncomplexity, which correspond to the minimal dimension or norm of an embedding\nrequired to approximate, rather then exactly represent, a given hypothesis\nclass. We show that such notions are not only sufficient for learning using\nlinear predictors or a kernel, but unlike the exact variants, are also\nnecessary. Thus they are better suited for discussing limitations of linear or\nkernel methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:57:41 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kamath", "Pritish", ""], ["Montasser", "Omar", ""], ["Srebro", "Nathan", ""]]}, {"id": "2003.04203", "submitter": "Neda Navidi", "authors": "Neda Navidi", "title": "Human AI interaction loop training: New approach for interactive\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) in various decision-making tasks of machine\nlearning provides effective results with an agent learning from a stand-alone\nreward function. However, it presents unique challenges with large amounts of\nenvironment states and action spaces, as well as in the determination of\nrewards. This complexity, coming from high dimensionality and continuousness of\nthe environments considered herein, calls for a large number of learning trials\nto learn about the environment through Reinforcement Learning. Imitation\nLearning (IL) offers a promising solution for those challenges using a teacher.\nIn IL, the learning process can take advantage of human-sourced assistance\nand/or control over the agent and environment. A human teacher and an agent\nlearner are considered in this study. The teacher takes part in the agent\ntraining towards dealing with the environment, tackling a specific objective,\nand achieving a predefined goal. Within that paradigm, however, existing IL\napproaches have the drawback of expecting extensive demonstration information\nin long-horizon problems. This paper proposes a novel approach combining IL\nwith different types of RL methods, namely state action reward state action\n(SARSA) and asynchronous advantage actor-critic (A3C) agents, to overcome the\nproblems of both stand-alone systems. It is addressed how to effectively\nleverage the teacher feedback, be it direct binary or indirect detailed for the\nagent learner to learn sequential decision-making policies. The results of this\nstudy on various OpenAI Gym environments show that this algorithmic method can\nbe incorporated with different combinations, significantly decreases both human\nendeavor and tedious exploration process.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:27:48 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Navidi", "Neda", ""]]}, {"id": "2003.04207", "submitter": "Antonio Candelieri", "authors": "Antonio Candelieri, Ilaria Giordani, Riccardo Perego, Francesco\n  Archetti", "title": "Composition of kernel and acquisition functions for High Dimensional\n  Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization has become the reference method for the global\noptimization of black box, expensive and possibly noisy functions. Bayesian\nOp-timization learns a probabilistic model about the objective function,\nusually a Gaussian Process, and builds, depending on its mean and variance, an\nacquisition function whose optimizer yields the new evaluation point, leading\nto update the probabilistic surrogate model. Despite its sample efficiency,\nBayesian Optimiza-tion does not scale well with the dimensions of the problem.\nThe optimization of the acquisition function has received less attention\nbecause its computational cost is usually considered negligible compared to\nthat of the evaluation of the objec-tive function. Its efficient optimization\nis often inhibited, particularly in high di-mensional problems, by multiple\nextrema. In this paper we leverage the addition-ality of the objective function\ninto mapping both the kernel and the acquisition function of the Bayesian\nOptimization in lower dimensional subspaces. This ap-proach makes more\nefficient the learning/updating of the probabilistic surrogate model and allows\nan efficient optimization of the acquisition function. Experi-mental results\nare presented for real-life application, that is the control of pumps in urban\nwater distribution systems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:45:57 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Candelieri", "Antonio", ""], ["Giordani", "Ilaria", ""], ["Perego", "Riccardo", ""], ["Archetti", "Francesco", ""]]}, {"id": "2003.04216", "submitter": "Mehmet Emre Ozfatura", "authors": "Emre Ozfatura, Stefano Rini, Deniz Gunduz", "title": "Decentralized SGD with Over-the-Air Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of decentralized stochastic gradient descent (DSGD)\nin a wireless network, where the nodes collaboratively optimize an objective\nfunction using their local datasets. Unlike the conventional setting, where the\nnodes communicate over error-free orthogonal communication links, we assume\nthat transmissions are prone to additive noise and interference.We first\nconsider a point-to-point (P2P) transmission strategy, termed the OAC-P2P\nscheme, in which the node pairs are scheduled in an orthogonal fashion to\nminimize interference. Since in the DSGD framework, each node requires a linear\ncombination of the neighboring models at the consensus step, we then propose\nthe OAC-MAC scheme, which utilizes the signal superposition property of the\nwireless medium to achieve over-the-air computation (OAC). For both schemes, we\ncast the scheduling problem as a graph coloring problem. We numerically\nevaluate the performance of these two schemes for the MNIST image\nclassification task under various network conditions. We show that the OAC-MAC\nscheme attains better convergence performance with a fewer communication\nrounds.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:33:59 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ozfatura", "Emre", ""], ["Rini", "Stefano", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2003.04218", "submitter": "Christopher Hahn", "authors": "Christopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus N. Rabe,\n  Bernd Finkbeiner", "title": "Teaching Temporal Logics to Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two fundamental questions in neuro-symbolic computing: can deep\nlearning tackle challenging problems in logics end-to-end, and can neural\nnetworks learn the semantics of logics. In this work we focus on linear-time\ntemporal logic (LTL), as it is widely used in verification. We train a\nTransformer on the problem to directly predict a solution, i.e. a trace, to a\ngiven LTL formula. The training data is generated with classical solvers,\nwhich, however, only provide one of many possible solutions to each formula. We\ndemonstrate that it is sufficient to train on those particular solutions to\nformulas, and that Transformers can predict solutions even to formulas from\nbenchmarks from the literature on which the classical solver timed out.\nTransformers also generalize to the semantics of the logics: while they often\ndeviate from the solutions found by the classical solvers, they still predict\ncorrect solutions to most formulas.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:46:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:02:34 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 12:41:20 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hahn", "Christopher", ""], ["Schmitt", "Frederik", ""], ["Kreber", "Jens U.", ""], ["Rabe", "Markus N.", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2003.04241", "submitter": "Vincent Roger", "authors": "Vincent Roger, J\\'er\\^ome Farinas and Julien Pinquier", "title": "Deep Neural Networks for Automatic Speech Processing: A Survey from\n  Large Corpora to Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art speech systems are using Deep Neural Networks (DNNs).\nThose systems require a large amount of data to be learned. Hence, learning\nstate-of-the-art frameworks on under-resourced speech languages/problems is a\ndifficult task. Problems could be the limited amount of data for impaired\nspeech. Furthermore, acquiring more data and/or expertise is time-consuming and\nexpensive. In this paper we position ourselves for the following speech\nprocessing tasks: Automatic Speech Recognition, speaker identification and\nemotion recognition. To assess the problem of limited data, we firstly\ninvestigate state-of-the-art Automatic Speech Recognition systems as it\nrepresents the hardest tasks (due to the large variability in each language).\nNext, we provide an overview of techniques and tasks requiring fewer data. In\nthe last section we investigate few-shot techniques as we interpret\nunder-resourced speech as a few-shot problem. In that sense we propose an\noverview of few-shot techniques and perspectives of using such techniques for\nthe focused speech problems in this survey. It occurs that the reviewed\ntechniques are not well adapted for large datasets. Nevertheless, some\npromising results from the literature encourage the usage of such techniques\nfor speech processing.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:26:30 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Roger", "Vincent", ""], ["Farinas", "J\u00e9r\u00f4me", ""], ["Pinquier", "Julien", ""]]}, {"id": "2003.04247", "submitter": "David Sommer", "authors": "David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal", "title": "Towards Probabilistic Verification of Machine Unlearning", "comments": "code is available at\n  https://github.com/inspire-group/unlearning-verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to be forgotten, also known as the right to erasure, is the right\nof individuals to have their data erased from an entity storing it. The status\nof this long held notion was legally solidified recently by the General Data\nProtection Regulation (GDPR) in the European Union. Consequently, there is a\nneed for mechanisms whereby users can verify if service providers comply with\ntheir deletion requests. In this work, we take the first step in proposing a\nformal framework to study the design of such verification mechanisms for data\ndeletion requests -- also known as machine unlearning -- in the context of\nsystems that provide machine learning as a service (MLaaS). Our framework\nallows the rigorous quantification of any verification mechanism based on\nstandard hypothesis testing. Furthermore, we propose a novel backdoor-based\nverification mechanism and demonstrate its effectiveness in certifying data\ndeletion with high confidence, thus providing a basis for quantitatively\ninferring machine unlearning.\n  We evaluate our approach over a range of network architectures such as\nmulti-layer perceptrons (MLP), convolutional neural networks (CNN), residual\nnetworks (ResNet), and long short-term memory (LSTM), as well as over 5\ndifferent datasets. We demonstrate that our approach has minimal effect on the\nML service's accuracy but provides high confidence verification of unlearning.\nOur proposed mechanism works even if only a handful of users employ our system\nto ascertain compliance with data deletion requests. In particular, with just\n5% of users participating, modifying half their data with a backdoor, and with\nmerely 30 test queries, our verification mechanism has both false positive and\nfalse negative ratios below $10^{-3}$. We also show the effectiveness of our\napproach by testing it against an adaptive adversary that uses a\nstate-of-the-art backdoor defense method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:39:46 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 16:01:10 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sommer", "David Marco", ""], ["Song", "Liwei", ""], ["Wagh", "Sameer", ""], ["Mittal", "Prateek", ""]]}, {"id": "2003.04261", "submitter": "Sara Mousavi", "authors": "Sara Mousavi, Dylan Lee, Tatianna Griffin, Dawnie Steadman, and Audris\n  Mockus", "title": "Collaborative Learning of Semi-Supervised Clustering and Classification\n  for Labeling Uncurated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific image collections present potential value in various areas of\nscience and business but are often not curated nor have any way to readily\nextract relevant content. To employ contemporary supervised image analysis\nmethods on such image data, they must first be cleaned and organized, and then\nmanually labeled for the nomenclature employed in the specific domain, which is\na time consuming and expensive endeavor. To address this issue, we designed and\nimplemented the Plud system. Plud provides an iterative semi-supervised\nworkflow to minimize the effort spent by an expert and handles realistic large\ncollections of images. We believe it can support labeling datasets regardless\nof their size and type. Plud is an iterative sequence of unsupervised\nclustering, human assistance, and supervised classification. With each\niteration 1) the labeled dataset grows, 2) the generality of the classification\nmethod and its accuracy increases, and 3) manual effort is reduced. We\nevaluated the effectiveness of our system, by applying it on over a million\nimages documenting human decomposition. In our experiment comparing manual\nlabeling with labeling conducted with the support of Plud, we found that it\nreduces the time needed to label data and produces highly accurate models for\nthis new domain.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:03:05 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mousavi", "Sara", ""], ["Lee", "Dylan", ""], ["Griffin", "Tatianna", ""], ["Steadman", "Dawnie", ""], ["Mockus", "Audris", ""]]}, {"id": "2003.04273", "submitter": "Saket Dingliwal", "authors": "Saket Dingliwal, Divyansh Pareek, Jatin Arora", "title": "Finding Input Characterizations for Output Properties in ReLU Neural\n  Networks", "comments": "5 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have emerged as a powerful mechanism and are\nbeing increasingly deployed in real-world safety-critical domains. Despite the\nwidespread success, their complex architecture makes proving any formal\nguarantees about them difficult. Identifying how logical notions of high-level\ncorrectness relate to the complex low-level network architecture is a\nsignificant challenge. In this project, we extend the ideas presented in and\nintroduce a way to bridge the gap between the architecture and the high-level\nspecifications. Our key insight is that instead of directly proving the safety\nproperties that are required, we first prove properties that relate closely to\nthe structure of the neural net and use them to reason about the safety\nproperties. We build theoretical foundations for our approach, and empirically\nevaluate the performance through various experiments, achieving promising\nresults than the existing approach by identifying a larger region of input\nspace that guarantees a certain property on the output.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:29:39 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Dingliwal", "Saket", ""], ["Pareek", "Divyansh", ""], ["Arora", "Jatin", ""]]}, {"id": "2003.04276", "submitter": "Kaicheng Yu", "authors": "Kaicheng Yu and Rene Ranftl and Mathieu Salzmann", "title": "How to Train Your Super-Net: An Analysis of Training Heuristics in\n  Weight-Sharing NAS", "comments": "Updated with latest results on NASBench-101, now we achieve 0.48\n  sparse Kendall-Tau on this space", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weight sharing promises to make neural architecture search (NAS) tractable\neven on commodity hardware. Existing methods in this space rely on a diverse\nset of heuristics to design and train the shared-weight backbone network,\na.k.a. the super-net. Since heuristics and hyperparameters substantially vary\nacross different methods, a fair comparison between them can only be achieved\nby systematically analyzing the influence of these factors. In this paper, we\ntherefore provide a systematic evaluation of the heuristics and hyperparameters\nthat are frequently employed by weight-sharing NAS algorithms. Our analysis\nuncovers that some commonly-used heuristics for super-net training negatively\nimpact the correlation between super-net and stand-alone performance, and\nevidences the strong influence of certain hyperparameters and architectural\nchoices. Our code and experiments set a strong and reproducible baseline that\nfuture works can build on.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:34:32 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 13:42:15 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Yu", "Kaicheng", ""], ["Ranftl", "Rene", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "2003.04285", "submitter": "Behzad Ghazanfari", "authors": "Behzad Ghazanfari, Fatemeh Afghah", "title": "Deep Inverse Feature Learning: A Representation Learning of Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel perspective about error in machine learning and\nproposes inverse feature learning (IFL) as a representation learning approach\nthat learns a set of high-level features based on the representation of error\nfor classification or clustering purposes. The proposed perspective about error\nrepresentation is fundamentally different from current learning methods, where\nin classification approaches they interpret the error as a function of the\ndifferences between the true labels and the predicted ones or in clustering\napproaches, in which the clustering objective functions such as compactness are\nused. Inverse feature learning method operates based on a deep clustering\napproach to obtain a qualitative form of the representation of error as\nfeatures. The performance of the proposed IFL method is evaluated by applying\nthe learned features along with the original features, or just using the\nlearned features in different classification and clustering techniques for\nseveral data sets. The experimental results show that the proposed method leads\nto promising results in classification and especially in clustering. In\nclassification, the proposed features along with the primary features improve\nthe results of most of the classification methods on several popular data sets.\nIn clustering, the performance of different clustering methods is considerably\nimproved on different data sets. There are interesting results that show some\nfew features of the representation of error capture highly informative aspects\nof primary features. We hope this paper helps to utilize the error\nrepresentation learning in different feature learning domains.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:45:44 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ghazanfari", "Behzad", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "2003.04286", "submitter": "Charles Jin", "authors": "Charles Jin, Martin Rinard", "title": "Manifold Regularization for Locally Stable Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply concepts from manifold regularization to develop new regularization\ntechniques for training locally stable deep neural networks. Our regularizers\nare based on a sparsification of the graph Laplacian which holds with high\nprobability when the data is sparse in high dimensions, as is common in deep\nlearning. Empirically, our networks exhibit stability in a diverse set of\nperturbation models, including $\\ell_2$, $\\ell_\\infty$, and Wasserstein-based\nperturbations; in particular, we achieve 40% adversarial accuracy on CIFAR-10\nagainst an adaptive PGD attack using $\\ell_\\infty$ perturbations of size\n$\\epsilon = 8/255$, and state-of-the-art verified accuracy of 21% in the same\nperturbation model. Furthermore, our techniques are efficient, incurring\noverhead on par with two additional parallel forward passes through the\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:45:44 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:53:45 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jin", "Charles", ""], ["Rinard", "Martin", ""]]}, {"id": "2003.04292", "submitter": "Mahdi Karami", "authors": "Mahdi Karami, Dale Schuurmans", "title": "Variational Inference for Deep Probabilistic Canonical Correlation\n  Analysis", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep probabilistic multi-view model that is\ncomposed of a linear multi-view layer based on probabilistic canonical\ncorrelation analysis (CCA) description in the latent space together with deep\ngenerative networks as observation models. The network is designed to decompose\nthe variations of all views into a shared latent representation and a set of\nview-specific components where the shared latent representation is intended to\ndescribe the common underlying sources of variation among the views. An\nefficient variational inference procedure is developed that approximates the\nposterior distributions of the latent probabilistic multi-view layer while\ntaking into account the solution of probabilistic CCA. A generalization to\nmodels with arbitrary number of views is also proposed. The empirical studies\nconfirm that the proposed deep generative multi-view model can successfully\nextend deep variational inference to multi-view learning while it efficiently\nintegrates the relationship between multiple views to alleviate the difficulty\nof learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:51:15 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Karami", "Mahdi", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2003.04300", "submitter": "Ondrej Biza", "authors": "Ondrej Biza, Robert Platt, Jan-Willem van de Meent and Lawson L. S.\n  Wong", "title": "Learning Discrete State Abstractions With Deep Variational Inference", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is crucial for effective sequential decision making in domains\nwith large state spaces. In this work, we propose an information bottleneck\nmethod for learning approximate bisimulations, a type of state abstraction. We\nuse a deep neural encoder to map states onto continuous embeddings. We map\nthese embeddings onto a discrete representation using an action-conditioned\nhidden Markov model, which is trained end-to-end with the neural network. Our\nmethod is suited for environments with high-dimensional states and learns from\na stream of experience collected by an agent acting in a Markov decision\nprocess. Through this learned discrete abstract model, we can efficiently plan\nfor unseen goals in a multi-goal Reinforcement Learning setting. We test our\nmethod in simplified robotic manipulation domains with image states. We also\ncompare it against previous model-based approaches to finding bisimulations in\ndiscrete grid-world-like environments. Source code is available at\nhttps://github.com/ondrejba/discrete_abstractions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:58:27 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 21:02:40 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 18:06:21 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Biza", "Ondrej", ""], ["Platt", "Robert", ""], ["van de Meent", "Jan-Willem", ""], ["Wong", "Lawson L. S.", ""]]}, {"id": "2003.04302", "submitter": "Huizhuo Yuan", "authors": "Huizhuo Yuan, Xiangru Lian, Ji Liu, Yuren Zhou", "title": "Stochastic Recursive Momentum for Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel algorithm named STOchastic Recursive\nMomentum for Policy Gradient (STORM-PG), which operates a SARAH-type stochastic\nrecursive variance-reduced policy gradient in an exponential moving average\nfashion. STORM-PG enjoys a provably sharp $O(1/\\epsilon^3)$ sample complexity\nbound for STORM-PG, matching the best-known convergence rate for policy\ngradient algorithm. In the mean time, STORM-PG avoids the alternations between\nlarge batches and small batches which persists in comparable variance-reduced\npolicy gradient methods, allowing considerably simpler parameter tuning.\nNumerical experiments depicts the superiority of our algorithm over comparative\npolicy gradient algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:59:03 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yuan", "Huizhuo", ""], ["Lian", "Xiangru", ""], ["Liu", "Ji", ""], ["Zhou", "Yuren", ""]]}, {"id": "2003.04310", "submitter": "Filip Tolovski", "authors": "Filip Tolovski", "title": "Advancing Renewable Electricity Consumption With Reinforcement Learning", "comments": "To be presented at the Workshop on Tackling Climate Change with\n  Machine Learning at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the share of renewable energy sources in the present electric energy mix\nrises, their intermittence proves to be the biggest challenge to carbon free\nelectricity generation. To address this challenge, we propose an electricity\npricing agent, which sends price signals to the customers and contributes to\nshifting the customer demand to periods of high renewable energy generation. We\npropose an implementation of a pricing agent with a reinforcement learning\napproach where the environment is represented by the customers, the electricity\ngeneration utilities and the weather conditions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:57:58 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Tolovski", "Filip", ""]]}, {"id": "2003.04315", "submitter": "Benjamin Lee", "authors": "Benjamin Charles Germain Lee, Kyle Lo, Doug Downey, Daniel S. Weld", "title": "Explanation-Based Tuning of Opaque Machine Learners with Application to\n  Paper Recommendation", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in human-centered AI has shown the benefits of machine-learning\nsystems that can explain their predictions. Methods that allow users to tune a\nmodel in response to the explanations are similarly useful. While both\ncapabilities are well-developed for transparent learning models (e.g., linear\nmodels and GA2Ms), and recent techniques (e.g., LIME and SHAP) can generate\nexplanations for opaque models, no method currently exists for tuning of opaque\nmodels in response to explanations. This paper introduces LIMEADE, a general\nframework for tuning an arbitrary machine learning model based on an\nexplanation of the model's prediction. We apply our framework to Semantic\nSanity, a neural recommender system for scientific papers, and report on a\ndetailed user study, showing that our framework leads to significantly higher\nperceived user control, trust, and satisfaction.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 18:00:00 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Lee", "Benjamin Charles Germain", ""], ["Lo", "Kyle", ""], ["Downey", "Doug", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2003.04339", "submitter": "Zhishuai Guo", "authors": "Zhishuai Guo, Yan Yan and Tianbao Yang", "title": "Revisiting SGD with Increasingly Weighted Averaging: Optimization and\n  Generalization Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been widely studied in the literature\nfrom different angles, and is commonly employed for solving many big data\nmachine learning problems. However, the averaging technique, which combines all\niterative solutions into a single solution, is still under-explored. While some\nincreasingly weighted averaging schemes have been considered in the literature,\nexisting works are mostly restricted to strongly convex objective functions and\nthe convergence of optimization error. It remains unclear how these averaging\nschemes affect the convergence of {\\it both optimization error and\ngeneralization error} (two equally important components of testing error) for\n{\\bf non-strongly convex objectives, including non-convex problems}. In this\npaper, we {\\it fill the gap} by comprehensively analyzing the increasingly\nweighted averaging on convex, strongly convex and non-convex objective\nfunctions in terms of both optimization error and generalization error. In\nparticular, we analyze a family of increasingly weighted averaging, where the\nweight for the solution at iteration $t$ is proportional to $t^{\\alpha}$\n($\\alpha > 0$). We show how $\\alpha$ affects the optimization error and the\ngeneralization error, and exhibit the trade-off caused by $\\alpha$. Experiments\nhave demonstrated this trade-off and the effectiveness of polynomially\nincreased weighted averaging compared with other averaging schemes for a wide\nrange of problems including deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 18:14:00 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 03:07:15 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 01:21:16 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Guo", "Zhishuai", ""], ["Yan", "Yan", ""], ["Yang", "Tianbao", ""]]}, {"id": "2003.04382", "submitter": "Qicheng Lao", "authors": "Qicheng Lao, Xiang Jiang, Mohammad Havaei, Yoshua Bengio", "title": "Continuous Domain Adaptation with Variational Domain-Agnostic Feature\n  Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in non-stationary environments is one of the biggest challenges in\nmachine learning. Non-stationarity can be caused by either task drift, i.e.,\nthe drift in the conditional distribution of labels given the input data, or\nthe domain drift, i.e., the drift in the marginal distribution of the input\ndata. This paper aims to tackle this challenge in the context of continuous\ndomain adaptation, where the model is required to learn new tasks adapted to\nnew domains in a non-stationary environment while maintaining previously\nlearned knowledge. To deal with both drifts, we propose variational\ndomain-agnostic feature replay, an approach that is composed of three\ncomponents: an inference module that filters the input data into\ndomain-agnostic representations, a generative module that facilitates knowledge\ntransfer, and a solver module that applies the filtered and transferable\nknowledge to solve the queries. We address the two fundamental scenarios in\ncontinuous domain adaptation, demonstrating the effectiveness of our proposed\napproach for practical usage.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 19:50:24 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Lao", "Qicheng", ""], ["Jiang", "Xiang", ""], ["Havaei", "Mohammad", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2003.04396", "submitter": "Naveed Naimipour", "authors": "Naveed Naimipour, Shahin Khobahi, Mojtaba Soltanalian", "title": "UPR: A Model-Driven Architecture for Deep Phase Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of phase retrieval has been intriguing researchers for decades\ndue to its appearance in a wide range of applications. The task of a phase\nretrieval algorithm is typically to recover a signal from linear phase-less\nmeasurements. In this paper, we approach the problem by proposing a hybrid\nmodel-based data-driven deep architecture, referred to as the Unfolded Phase\nRetrieval (UPR), that shows potential in improving the performance of the\nstate-of-the-art phase retrieval algorithms. Specifically, the proposed method\nbenefits from versatility and interpretability of well established model-based\nalgorithms, while simultaneously benefiting from the expressive power of deep\nneural networks. Our numerical results illustrate the effectiveness of such\nhybrid deep architectures and showcase the untapped potential of data-aided\nmethodologies to enhance the existing phase retrieval algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:22:40 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Naimipour", "Naveed", ""], ["Khobahi", "Shahin", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "2003.04422", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Correlated Initialization for Correlated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial data exhibits the property that nearby points are correlated. This\nholds also for learnt representations across layers, but not for commonly used\nweight initialization methods. Our theoretical analysis reveals for\nuncorrelated initialization that (i) flow through layers suffers from much more\nrapid decrease and (ii) training of individual parameters is subject to more\n``zig-zagging''. We propose multiple methods for correlated initialization. For\nCNNs, they yield accuracy gains of several per cent in the absence of\nregularization. Even for properly tuned L2-regularization gains are often\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 21:37:59 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "2003.04427", "submitter": "Yan Zhang", "authors": "Yan Zhang and Michael M. Zavlanos", "title": "Transfer Reinforcement Learning under Unobserved Contextual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a transfer reinforcement learning problem where the\nstate transitions and rewards are affected by the environmental context.\nSpecifically, we consider a demonstrator agent that has access to a\ncontext-aware policy and can generate transition and reward data based on that\npolicy. These data constitute the experience of the demonstrator. Then, the\ngoal is to transfer this experience, excluding the underlying contextual\ninformation, to a learner agent that does not have access to the environmental\ncontext, so that they can learn a control policy using fewer samples. It is\nwell known that, disregarding the causal effect of the contextual information,\ncan introduce bias in the transition and reward models estimated by the\nlearner, resulting in a learned suboptimal policy. To address this challenge,\nin this paper, we develop a method to obtain causal bounds on the transition\nand reward functions using the demonstrator's data, which we then use to obtain\ncausal bounds on the value functions. Using these value function bounds, we\npropose new Q learning and UCB-Q learning algorithms that converge to the true\nvalue function without bias. We provide numerical experiments for robot motion\nplanning problems that validate the proposed value function bounds and\ndemonstrate that the proposed algorithms can effectively make use of the data\nfrom the demonstrator to accelerate the learning process of the learner.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:00:04 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Yan", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "2003.04430", "submitter": "Zidi Xiu", "authors": "Zidi Xiu, Chenyang Tao, Benjamin A. Goldstein, Ricardo Henao", "title": "Variational Learning of Individual Survival Distributions", "comments": null, "journal-ref": null, "doi": "10.1145/3368555.3384454", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of modern health data provides many opportunities for the use\nof machine learning techniques to build better statistical models to improve\nclinical decision making. Predicting time-to-event distributions, also known as\nsurvival analysis, plays a key role in many clinical applications. We introduce\na variational time-to-event prediction model, named Variational Survival\nInference (VSI), which builds upon recent advances in distribution learning\ntechniques and deep neural networks. VSI addresses the challenges of\nnon-parametric distribution estimation by ($i$) relaxing the restrictive\nmodeling assumptions made in classical models, and ($ii$) efficiently handling\nthe censored observations, {\\it i.e.}, events that occur outside the\nobservation window, all within the variational framework. To validate the\neffectiveness of our approach, an extensive set of experiments on both\nsynthetic and real-world datasets is carried out, showing improved performance\nrelative to competing solutions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:09:51 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 05:01:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Xiu", "Zidi", ""], ["Tao", "Chenyang", ""], ["Goldstein", "Benjamin A.", ""], ["Henao", "Ricardo", ""]]}, {"id": "2003.04448", "submitter": "Qian Huang", "authors": "Qian Huang, Horace He, Abhay Singh, Yan Zhang, Ser-Nam Lim, Austin\n  Benson", "title": "Better Set Representations For Relational Reasoning", "comments": "Preprint, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating relational reasoning into neural networks has greatly expanded\ntheir capabilities and scope. One defining trait of relational reasoning is\nthat it operates on a set of entities, as opposed to standard vector\nrepresentations. Existing end-to-end approaches typically extract entities from\ninputs by directly interpreting the latent feature representations as a set. We\nshow that these approaches do not respect set permutational invariance and thus\nhave fundamental representational limitations. To resolve this limitation, we\npropose a simple and general network module called a Set Refiner Network (SRN).\nWe first use synthetic image experiments to demonstrate how our approach\neffectively decomposes objects without explicit supervision. Then, we insert\nour module into existing relational reasoning models and show that respecting\nset invariance leads to substantial gains in prediction performance and\nrobustness on several relational reasoning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 23:07:27 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 06:40:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Huang", "Qian", ""], ["He", "Horace", ""], ["Singh", "Abhay", ""], ["Zhang", "Yan", ""], ["Lim", "Ser-Nam", ""], ["Benson", "Austin", ""]]}, {"id": "2003.04475", "submitter": "Remi Tachet Des Combes", "authors": "Remi Tachet, Han Zhao, Yu-Xiang Wang and Geoff Gordon", "title": "Domain Adaptation with Conditional Distribution Matching and Generalized\n  Label Shift", "comments": "Appeared in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning has demonstrated good performance in the unsupervised\ndomain adaptation setting, by learning domain-invariant representations.\nHowever, recent work has shown limitations of this approach when label\ndistributions differ between the source and target domains. In this paper, we\npropose a new assumption, generalized label shift ($GLS$), to improve\nrobustness against mismatched label distributions. $GLS$ states that,\nconditioned on the label, there exists a representation of the input that is\ninvariant between the source and target domains. Under $GLS$, we provide\ntheoretical guarantees on the transfer performance of any classifier. We also\ndevise necessary and sufficient conditions for $GLS$ to hold, by using an\nestimation of the relative class weights between domains and an appropriate\nreweighting of samples. Our weight estimation method could be straightforwardly\nand generically applied in existing domain adaptation (DA) algorithms that\nlearn domain-invariant representations, with small computational overhead. In\nparticular, we modify three DA algorithms, JAN, DANN and CDAN, and evaluate\ntheir performance on standard and artificial DA tasks. Our algorithms\noutperform the base versions, with vast improvements for large label\ndistribution mismatches. Our code is available at https://tinyurl.com/y585xt6j.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 00:35:23 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 04:01:17 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 21:59:58 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tachet", "Remi", ""], ["Zhao", "Han", ""], ["Wang", "Yu-Xiang", ""], ["Gordon", "Geoff", ""]]}, {"id": "2003.04493", "submitter": "Qinqing Zheng", "authors": "Qinqing Zheng, Jinshuo Dong, Qi Long, Weijie J. Su", "title": "Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth\n  Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets containing sensitive information are often sequentially analyzed by\nmany algorithms. This raises a fundamental question in differential privacy\nregarding how the overall privacy bound degrades under composition. To address\nthis question, we introduce a family of analytical and sharp privacy bounds\nunder composition using the Edgeworth expansion in the framework of the\nrecently proposed f-differential privacy. In contrast to the existing\ncomposition theorems using the central limit theorem, our new privacy bounds\nunder composition gain improved tightness by leveraging the refined\napproximation accuracy of the Edgeworth expansion. Our approach is easy to\nimplement and computationally efficient for any number of compositions. The\nsuperiority of these new bounds is confirmed by an asymptotic error analysis\nand an application to quantifying the overall privacy guarantees of noisy\nstochastic gradient descent used in training private deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 01:54:15 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 15:18:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zheng", "Qinqing", ""], ["Dong", "Jinshuo", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2003.04497", "submitter": "Ali Anaissi", "authors": "Ali Anaissi, Basem Suleiman, Seid Miad Zandavi", "title": "Online Tensor-Based Learning for Multi-Way Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online analysis of multi-way data stored in a tensor $\\mathcal{X} \\in\n\\mathbb{R} ^{I_1 \\times \\dots \\times I_N} $ has become an essential tool for\ncapturing the underlying structures and extracting the sensitive features which\ncan be used to learn a predictive model. However, data distributions often\nevolve with time and a current predictive model may not be sufficiently\nrepresentative in the future. Therefore, incrementally updating the\ntensor-based features and model coefficients are required in such situations. A\nnew efficient tensor-based feature extraction, named NeSGD, is proposed for\nonline $CANDECOMP/PARAFAC$ (CP) decomposition. According to the new features\nobtained from the resultant matrices of NeSGD, a new criteria is triggered for\nthe updated process of the online predictive model. Experimental evaluation in\nthe field of structural health monitoring using laboratory-based and real-life\nstructural datasets show that our methods provide more accurate results\ncompared with existing online tensor analysis and model learning. The results\nshowed that the proposed methods significantly improved the classification\nerror rates, were able to assimilate the changes in the positive data\ndistribution over time, and maintained a high predictive accuracy in all case\nstudies.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 02:04:08 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Anaissi", "Ali", ""], ["Suleiman", "Basem", ""], ["Zandavi", "Seid Miad", ""]]}, {"id": "2003.04508", "submitter": "Yunxing Zhang", "authors": "Rui Zhang, Yunxing Zhang, Xuelong Li", "title": "Unsupervised Graph Embedding via Adaptive Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph autoencoders (GAEs) are powerful tools in representation learning for\ngraph embedding. However, the performance of GAEs is very dependent on the\nquality of the graph structure, i.e., of the adjacency matrix. In other words,\nGAEs would perform poorly when the adjacency matrix is incomplete or be\ndisturbed. In this paper, two novel unsupervised graph embedding methods,\nunsupervised graph embedding via adaptive graph learning (BAGE) and\nunsupervised graph embedding via variational adaptive graph learning (VBAGE)\nare proposed. The proposed methods expand the application range of GAEs on\ngraph embedding, i.e, on the general datasets without graph structure.\nMeanwhile, the adaptive learning mechanism can initialize the adjacency matrix\nwithout be affected by the parameter. Besides that, the latent representations\nare embedded in the laplacian graph structure to preserve the topology\nstructure of the graph in the vector space. Moreover, the adjacency matrix can\nbe self-learned for better embedding performance when the original graph\nstructure is incomplete. With adaptive learning, the proposed method is much\nmore robust to the graph structure. Experimental studies on several datasets\nvalidate our design and demonstrate that our methods outperform baselines by a\nwide margin in node clustering, node classification, and graph visualization\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 02:33:14 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 07:16:19 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 11:26:59 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Zhang", "Rui", ""], ["Zhang", "Yunxing", ""], ["Li", "Xuelong", ""]]}, {"id": "2003.04509", "submitter": "Shay Moran", "authors": "Noga Alon, Amos Beimel, Shay Moran, and Uri Stemmer", "title": "Closure Properties for Private Classification and Online Prediction", "comments": "Improved some of the upper bounds w.r.t the Littlestone dimension.\n  Most significantly, we removed two exponents from the bound w.r.t general\n  composition (now it has a single exponent rather than triple exponents). Add\n  a figure. Other", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let~$\\cH$ be a class of boolean functions and consider a {\\it composed class}\n$\\cH'$ that is derived from~$\\cH$ using some arbitrary aggregation rule (for\nexample, $\\cH'$ may be the class of all 3-wise majority-votes of functions in\n$\\cH$). We upper bound the Littlestone dimension of~$\\cH'$ in terms of that\nof~$\\cH$. As a corollary, we derive closure properties for online learning and\nprivate PAC learning.\n  The derived bounds on the Littlestone dimension exhibit an undesirable\nexponential dependence. For private learning, we prove close to optimal bounds\nthat circumvents this suboptimal dependency. The improved bounds on the sample\ncomplexity of private learning are derived algorithmically via transforming a\nprivate learner for the original class $\\cH$ to a private learner for the\ncomposed class~$\\cH'$. Using the same ideas we show that any ({\\em proper or\nimproper}) private algorithm that learns a class of functions $\\cH$ in the\nrealizable case (i.e., when the examples are labeled by some function in the\nclass) can be transformed to a private algorithm that learns the class $\\cH$ in\nthe agnostic case.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 02:34:16 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 15:40:29 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 03:50:06 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Alon", "Noga", ""], ["Beimel", "Amos", ""], ["Moran", "Shay", ""], ["Stemmer", "Uri", ""]]}, {"id": "2003.04514", "submitter": "Homanga Bharadhwaj", "authors": "Samarth Sinha, Homanga Bharadhwaj, Anirudh Goyal, Hugo Larochelle,\n  Animesh Garg, Florian Shkurti", "title": "Diversity inducing Information Bottleneck in Model Ensembles", "comments": "AAAI 2021. Samarth Sinha* and Homanga Bharadhwaj* contributed equally\n  to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have achieved state-of-the-art performance on a\nnumber of vision tasks, generalization over high dimensional multi-modal data,\nand reliable predictive uncertainty estimation are still active areas of\nresearch. Bayesian approaches including Bayesian Neural Nets (BNNs) do not\nscale well to modern computer vision tasks, as they are difficult to train, and\nhave poor generalization under dataset-shift. This motivates the need for\neffective ensembles which can generalize and give reliable uncertainty\nestimates. In this paper, we target the problem of generating effective\nensembles of neural networks by encouraging diversity in prediction. We\nexplicitly optimize a diversity inducing adversarial loss for learning the\nstochastic latent variables and thereby obtain diversity in the output\npredictions necessary for modeling multi-modal data. We evaluate our method on\nbenchmark datasets: MNIST, CIFAR100, TinyImageNet and MIT Places 2, and\ncompared to the most competitive baselines show significant improvements in\nclassification accuracy, under a shift in the data distribution and in\nout-of-distribution detection. Code will be released in this url\nhttps://github.com/rvl-lab-utoronto/dibs\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:10:41 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 22:57:12 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 20:14:08 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sinha", "Samarth", ""], ["Bharadhwaj", "Homanga", ""], ["Goyal", "Anirudh", ""], ["Larochelle", "Hugo", ""], ["Garg", "Animesh", ""], ["Shkurti", "Florian", ""]]}, {"id": "2003.04521", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Jianyong Sun and Zongben Xu", "title": "Learning to be Global Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of artificial intelligence has cast a new light on the\ndevelopment of optimization algorithm. This paper proposes to learn a two-phase\n(including a minimization phase and an escaping phase) global optimization\nalgorithm for smooth non-convex functions. For the minimization phase, a\nmodel-driven deep learning method is developed to learn the update rule of\ndescent direction, which is formalized as a nonlinear combination of historical\ninformation, for convex functions. We prove that the resultant algorithm with\nthe proposed adaptive direction guarantees convergence for convex functions.\nEmpirical study shows that the learned algorithm significantly outperforms some\nwell-known classical optimization algorithms, such as gradient descent,\nconjugate descent and BFGS, and performs well on ill-posed functions. The\nescaping phase from local optimum is modeled as a Markov decision process with\na fixed escaping policy. We further propose to learn an optimal escaping policy\nby reinforcement learning. The effectiveness of the escaping policies is\nverified by optimizing synthesized functions and training a deep neural network\nfor CIFAR image classification. The learned two-phase global optimization\nalgorithm demonstrates a promising global search capability on some benchmark\nfunctions and machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:46:25 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Haotian", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2003.04549", "submitter": "Kihyun Tae", "authors": "Ki Hyun Tae, Steven Euijong Whang", "title": "Slice Tuner: A Selective Data Acquisition Framework for Accurate and\n  Fair Machine Learning Models", "comments": "15 pages, 11 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes democratized in the era of Software 2.0, a\nserious bottleneck is acquiring enough data to ensure accurate and fair models.\nRecent techniques including crowdsourcing provide cost-effective ways to gather\nsuch data. However, simply acquiring data as much as possible is not\nnecessarily an effective strategy for optimizing accuracy and fairness. For\nexample, if an online app store has enough training data for certain slices of\ndata (say American customers), but not for others, obtaining more American\ncustomer data will only bias the model training. Instead, we contend that one\nneeds to selectively acquire data and propose Slice Tuner, which acquires\npossibly-different amounts of data per slice such that the model accuracy and\nfairness on all slices are optimized. This problem is different than labeling\nexisting data (as in active learning or weak supervision) because the goal is\nobtaining the right amounts of new data. At its core, Slice Tuner maintains\nlearning curves of slices that estimate the model accuracies given more data\nand uses convex optimization to find the best data acquisition strategy. The\nkey challenges of estimating learning curves are that they may be inaccurate if\nthere is not enough data, and there may be dependencies among slices where\nacquiring data for one slice influences the learning curves of others. We solve\nthese issues by iteratively and efficiently updating the learning curves as\nmore data is acquired. We evaluate Slice Tuner on real datasets using\ncrowdsourcing for data acquisition and show that Slice Tuner significantly\noutperforms baselines in terms of model accuracy and fairness, even when the\nlearning curves cannot be reliably estimated.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 06:34:21 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 01:26:22 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tae", "Ki Hyun", ""], ["Whang", "Steven Euijong", ""]]}, {"id": "2003.04560", "submitter": "Yoni Kasten", "authors": "Ronen Basri, Meirav Galun, Amnon Geifman, David Jacobs, Yoni Kasten,\n  Shira Kritchman", "title": "Frequency Bias in Neural Networks for Input of Non-Uniform Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have partly attributed the generalization ability of\nover-parameterized neural networks to frequency bias -- networks trained with\ngradient descent on data drawn from a uniform distribution find a low frequency\nfit before high frequency ones. As realistic training sets are not drawn from a\nuniform distribution, we here use the Neural Tangent Kernel (NTK) model to\nexplore the effect of variable density on training dynamics. Our results, which\ncombine analytic and empirical observations, show that when learning a pure\nharmonic function of frequency $\\kappa$, convergence at a point $\\x \\in\n\\Sphere^{d-1}$ occurs in time $O(\\kappa^d/p(\\x))$ where $p(\\x)$ denotes the\nlocal density at $\\x$. Specifically, for data in $\\Sphere^1$ we analytically\nderive the eigenfunctions of the kernel associated with the NTK for two-layer\nnetworks. We further prove convergence results for deep, fully connected\nnetworks with respect to the spectral decomposition of the NTK. Our empirical\nstudy highlights similarities and differences between deep and shallow networks\nin this model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 07:20:14 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Basri", "Ronen", ""], ["Galun", "Meirav", ""], ["Geifman", "Amnon", ""], ["Jacobs", "David", ""], ["Kasten", "Yoni", ""], ["Kritchman", "Shira", ""]]}, {"id": "2003.04575", "submitter": "Jiyang Xie", "authors": "Jiyang Xie, Dongliang Chang, Zhanyu Ma, Guoqiang Zhang and Jun Guo", "title": "Channel Attention with Embedding Gaussian Process: A Probabilistic\n  Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel attention mechanisms, as the key components of some modern\nconvolutional neural networks (CNNs) architectures, have been commonly used in\nmany visual tasks for effective performance improvement. It is able to\nreinforce the informative channels and to suppress useless channels of feature\nmaps obtained by CNNs. Recently, different attention modules have been\nproposed, which are implemented in various ways. However, they are mainly based\non convolution and pooling operations, which are lack of intuitive and\nreasonable insights about the principles that they are based on. Moreover, the\nways that they improve the performance of the CNNs is not clear either. In this\npaper, we propose a Gaussian process embedded channel attention (GPCA) module\nand interpret the channel attention intuitively and reasonably in a\nprobabilistic way. The GPCA module is able to model the correlations from\nchannels which are assumed as beta distributed variables with Gaussian process\nprior. As the beta distribution is intractably integrated into the end-to-end\ntraining of the CNNs, we utilize an appropriate approximation of the beta\ndistribution to make the distribution assumption implemented easily. In this\ncase, the proposed GPCA module can be integrated into the end-to-end training\nof the CNNs. Experimental results demonstrate that the proposed GPCA module can\nimprove the accuracies of image classification on four widely used datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 08:38:49 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Xie", "Jiyang", ""], ["Chang", "Dongliang", ""], ["Ma", "Zhanyu", ""], ["Zhang", "Guoqiang", ""], ["Guo", "Jun", ""]]}, {"id": "2003.04576", "submitter": "Padraig Davidson", "authors": "Padraig Davidson, Michael Steininger, Florian Lautenschlager,\n  Konstantin Kobs, Anna Krause and Andreas Hotho", "title": "Anomaly Detection in Beehives using Deep Recurrent Autoencoders", "comments": null, "journal-ref": "Proceedings of the 9th International Conference on Sensor Networks\n  (SENSORNETS 2020), 2020, 142-149", "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision beekeeping allows to monitor bees' living conditions by equipping\nbeehives with sensors. The data recorded by these hives can be analyzed by\nmachine learning models to learn behavioral patterns of or search for unusual\nevents in bee colonies. One typical target is the early detection of bee\nswarming as apiarists want to avoid this due to economical reasons. Advanced\nmethods should be able to detect any other unusual or abnormal behavior arising\nfrom illness of bees or from technical reasons, e.g. sensor failure.\n  In this position paper we present an autoencoder, a deep learning model,\nwhich detects any type of anomaly in data independent of its origin. Our model\nis able to reveal the same swarms as a simple rule-based swarm detection\nalgorithm but is also triggered by any other anomaly. We evaluated our model on\nreal world data sets that were collected on different hives and with different\nsensor setups.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 08:39:37 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Davidson", "Padraig", ""], ["Steininger", "Michael", ""], ["Lautenschlager", "Florian", ""], ["Kobs", "Konstantin", ""], ["Krause", "Anna", ""], ["Hotho", "Andreas", ""]]}, {"id": "2003.04630", "submitter": "Miles Cranmer", "authors": "Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David\n  Spergel, Shirley Ho", "title": "Lagrangian Neural Networks", "comments": "7 pages (+2 appendix). Published in ICLR 2020 Deep Differential\n  Equations Workshop. Code at github.com/MilesCranmer/lagrangian_nns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate models of the world are built upon notions of its underlying\nsymmetries. In physics, these symmetries correspond to conservation laws, such\nas for energy and momentum. Yet even though neural network models see\nincreasing use in the physical sciences, they struggle to learn these\nsymmetries. In this paper, we propose Lagrangian Neural Networks (LNNs), which\ncan parameterize arbitrary Lagrangians using neural networks. In contrast to\nmodels that learn Hamiltonians, LNNs do not require canonical coordinates, and\nthus perform well in situations where canonical momenta are unknown or\ndifficult to compute. Unlike previous approaches, our method does not restrict\nthe functional form of learned energies and will produce energy-conserving\nmodels for a variety of tasks. We test our approach on a double pendulum and a\nrelativistic particle, demonstrating energy conservation where a baseline\napproach incurs dissipation and modeling relativity without canonical\ncoordinates where a Hamiltonian approach fails. Finally, we show how this model\ncan be applied to graphs and continuous systems using a Lagrangian Graph\nNetwork, and demonstrate it on the 1D wave equation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 10:55:25 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 05:22:58 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Cranmer", "Miles", ""], ["Greydanus", "Sam", ""], ["Hoyer", "Stephan", ""], ["Battaglia", "Peter", ""], ["Spergel", "David", ""], ["Ho", "Shirley", ""]]}, {"id": "2003.04664", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas, C\\'edric Colas, Lilian Weng, Katja Hofmann and\n  Pierre-Yves Oudeyer", "title": "Automatic Curriculum Learning For Deep RL: A Short Survey", "comments": "Accepted at IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Curriculum Learning (ACL) has become a cornerstone of recent\nsuccesses in Deep Reinforcement Learning (DRL).These methods shape the learning\ntrajectories of agents by challenging them with tasks adapted to their\ncapacities. In recent years, they have been used to improve sample efficiency\nand asymptotic performance, to organize exploration, to encourage\ngeneralization or to solve sparse reward problems, among others. The ambition\nof this work is dual: 1) to present a compact and accessible introduction to\nthe Automatic Curriculum Learning literature and 2) to draw a bigger picture of\nthe current state of the art in ACL to encourage the cross-breeding of existing\nconcepts and the emergence of new ideas.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:38:31 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 20:51:40 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Colas", "C\u00e9dric", ""], ["Weng", "Lilian", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2003.04675", "submitter": "Tung Nguyen", "authors": "Duy T. Nguyen, Kathryn E. Kasmarik, Hussein A. Abbass", "title": "Towards Interpretable Neural Networks: An Exact Transformation to\n  Multi-Class Multivariate Decision Trees", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) are commonly labelled as black-boxes,\nlacking interpretability. This hinders human understanding of ANNs' behaviors.\nA need exists to generate a meaningful sequential logic for the production of a\nspecific output. Decision trees exhibit better interpretability and expressive\npower due to their representation language and the existence of efficient\nalgorithms to generate rules. Growing a decision tree based on the available\ndata could produce larger than necessary trees or trees that do not generalise\nwell. In this paper, we introduce two novel multivariate decision tree (MDT)\nalgorithms for rule extraction from an ANN: an Exact-Convertible Decision Tree\n(EC-DT) and an Extended C-Net algorithm to transform a neural network with\nRectified Linear Unit activation functions into a representative tree which can\nbe used to extract multivariate rules for reasoning. While the EC-DT translates\nthe ANN in a layer-wise manner to represent exactly the decision boundaries\nimplicitlylearned by the hidden layers of the network, the Extended C-Net\ninherits the decompositional approach from EC-DT and combines with a C5 tree\nlearning algorithm to construct the decision rules. The results suggest that\nwhile EC-DT is superior in preserving the structure and the accuracy of ANN,\nExtended C-Net generates the most compact and highly effective trees from ANN.\nBoth proposed MDT algorithms generate rules including combinations of multiple\nattributes for precise interpretation of decision-making processes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:04:08 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 05:55:26 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 14:52:56 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Nguyen", "Duy T.", ""], ["Kasmarik", "Kathryn E.", ""], ["Abbass", "Hussein A.", ""]]}, {"id": "2003.04684", "submitter": "Mahdi Boloursaz Mashhadi", "authors": "Mahdi Boloursaz Mashhadi, Qianqian Yang, and Deniz Gunduz", "title": "Distributed Deep Convolutional Compression for Massive MIMO CSI Feedback", "comments": "arXiv admin note: text overlap with arXiv:1907.02942", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (MIMO) systems require downlink\nchannel state information (CSI) at the base station (BS) to achieve spatial\ndiversity and multiplexing gains. In a frequency division duplex (FDD)\nmultiuser massive MIMO network, each user needs to compress and feedback its\ndownlink CSI to the BS. The CSI overhead scales with the number of antennas,\nusers and subcarriers, and becomes a major bottleneck for the overall spectral\nefficiency. In this paper, we propose a deep learning (DL)-based CSI\ncompression scheme, called DeepCMC, composed of convolutional layers followed\nby quantization and entropy coding blocks. In comparison with previous DL-based\nCSI reduction structures, DeepCMC proposes a novel fully-convolutional neural\nnetwork (NN) architecture, with residual layers at the decoder, and\nincorporates quantization and entropy coding blocks into its design. DeepCMC is\ntrained to minimize a weighted rate-distortion cost, which enables a trade-off\nbetween the CSI quality and its feedback overhead. Simulation results\ndemonstrate that DeepCMC outperforms the state of the art CSI compression\nschemes in terms of the reconstruction quality of CSI for the same compression\nrate. We also propose a distributed version of DeepCMC for a multi-user MIMO\nscenario to encode and reconstruct the CSI from multiple users in a distributed\nmanner. Distributed DeepCMC not only utilizes the inherent CSI structures of a\nsingle MIMO user for compression, but also benefits from the correlations among\nthe channel matrices of nearby users to further improve the performance in\ncomparison with DeepCMC. We also propose a reduced-complexity training method\nfor distributed DeepCMC, allowing to scale it to multiple users, and suggest a\ncluster-based distributed DeepCMC approach for practical implementation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 12:33:31 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 11:31:03 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Mashhadi", "Mahdi Boloursaz", ""], ["Yang", "Qianqian", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2003.04691", "submitter": "Hideaki Imamura", "authors": "Hideaki Imamura, Nontawat Charoenphakdee, Futoshi Futami, Issei Sato,\n  Junya Honda, Masashi Sugiyama", "title": "Time-varying Gaussian Process Bandit Optimization with Non-constant\n  Evaluation Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process bandit is a problem in which we want to find a maximizer\nof a black-box function with the minimum number of function evaluations. If the\nblack-box function varies with time, then time-varying Bayesian optimization is\na promising framework. However, a drawback with current methods is in the\nassumption that the evaluation time for every observation is constant, which\ncan be unrealistic for many practical applications, e.g., recommender systems\nand environmental monitoring. As a result, the performance of current methods\ncan be degraded when this assumption is violated. To cope with this problem, we\npropose a novel time-varying Bayesian optimization algorithm that can\neffectively handle the non-constant evaluation time. Furthermore, we\ntheoretically establish a regret bound of our algorithm. Our bound elucidates\nthat a pattern of the evaluation time sequence can hugely affect the difficulty\nof the problem. We also provide experimental results to validate the practical\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:28:33 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 00:38:08 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Imamura", "Hideaki", ""], ["Charoenphakdee", "Nontawat", ""], ["Futami", "Futoshi", ""], ["Sato", "Issei", ""], ["Honda", "Junya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2003.04696", "submitter": "Fernando P\\'erez-Garc\\'ia", "authors": "Fernando P\\'erez-Garc\\'ia, Rachel Sparks and S\\'ebastien Ourselin", "title": "TorchIO: a Python library for efficient loading, preprocessing,\n  augmentation and patch-based sampling of medical images in deep learning", "comments": "Submitted to Computer Methods and Programs in Biomedicine. 27 pages,\n  7 figures. Documentation for TorchIO can be found at http://torchio.rtfd.io/", "journal-ref": "Computer Methods and Programs in Biomedicine (June 2021), p.\n  106236. ISSN: 0169-2607", "doi": "10.1016/j.cmpb.2021.106236", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Processing of medical images such as MRI or CT presents unique challenges\ncompared to RGB images typically used in computer vision. These include a lack\nof labels for large datasets, high computational costs, and metadata to\ndescribe the physical properties of voxels. Data augmentation is used to\nartificially increase the size of the training datasets. Training with image\npatches decreases the need for computational power. Spatial metadata needs to\nbe carefully taken into account in order to ensure a correct alignment of\nvolumes.\n  We present TorchIO, an open-source Python library to enable efficient\nloading, preprocessing, augmentation and patch-based sampling of medical images\nfor deep learning. TorchIO follows the style of PyTorch and integrates standard\nmedical image processing libraries to efficiently process images during\ntraining of neural networks. TorchIO transforms can be composed, reproduced,\ntraced and extended. We provide multiple generic preprocessing and augmentation\noperations as well as simulation of MRI-specific artifacts.\n  Source code, comprehensive tutorials and extensive documentation for TorchIO\ncan be found at https://github.com/fepegar/torchio. The package can be\ninstalled from the Python Package Index running 'pip install torchio'. It\nincludes a command-line interface which allows users to apply transforms to\nimage files without using Python. Additionally, we provide a graphical\ninterface within a TorchIO extension in 3D Slicer to visualize the effects of\ntransforms.\n  TorchIO was developed to help researchers standardize medical image\nprocessing pipelines and allow them to focus on the deep learning experiments.\nIt encourages open science, as it supports reproducibility and is version\ncontrolled so that the software can be cited precisely. Due to its modularity,\nthe library is compatible with other frameworks for deep learning with medical\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:36:16 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 20:43:32 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 09:09:03 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 10:05:29 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["P\u00e9rez-Garc\u00eda", "Fernando", ""], ["Sparks", "Rachel", ""], ["Ourselin", "S\u00e9bastien", ""]]}, {"id": "2003.04726", "submitter": "Rosana Veroneze", "authors": "Rosana Veroneze and Fernando J. Von Zuben", "title": "New advances in enumerative biclustering algorithms with online\n  partitioning", "comments": "This report unifies the proposals of two previous reports ('Efficient\n  mining of maximal biclusters in mixed-attribute datasets' and\n  'RIn-Close_CVC2: an even more efficient enumerative algorithm for\n  biclustering of numerical datasets') and brings some new novelties too. arXiv\n  admin note: substantial text overlap with arXiv:1810.07725", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper further extends RIn-Close_CVC, a biclustering algorithm capable of\nperforming an efficient, complete, correct and non-redundant enumeration of\nmaximal biclusters with constant values on columns in numerical datasets. By\navoiding a priori partitioning and itemization of the dataset, RIn-Close_CVC\nimplements an online partitioning, which is demonstrated here to guide to more\ninformative biclustering results. The improved algorithm is called\nRIn-Close_CVC3, keeps those attractive properties of RIn-Close_CVC, as formally\nproved here, and is characterized by: a drastic reduction in memory usage; a\nconsistent gain in runtime; additional ability to handle datasets with missing\nvalues; and additional ability to operate with attributes characterized by\ndistinct distributions or even mixed data types. The experimental results\ninclude synthetic and real-world datasets used to perform scalability and\nsensitivity analyses. As a practical case study, a parsimonious set of relevant\nand interpretable mixed-attribute-type rules is obtained in the context of\nsupervised descriptive pattern mining.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 14:54:26 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Veroneze", "Rosana", ""], ["Von Zuben", "Fernando J.", ""]]}, {"id": "2003.04733", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed Tewfik", "title": "Speaker Identification using EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore speaker identification using electroencephalography\n(EEG) signals. The performance of speaker identification systems degrades in\npresence of background noise, this paper demonstrates that EEG features can be\nused to enhance the performance of speaker identification systems operating in\npresence and absence of background noise. The paper further demonstrates that\nin presence of high background noise, speaker identification system using only\nEEG features as input demonstrates better performance than the system using\nonly acoustic features as input.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 04:04:19 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed", ""]]}, {"id": "2003.04735", "submitter": "Rui Zhang", "authors": "Rui Zhang, Quanyan Zhu", "title": "Security of Distributed Machine Learning: A Game-Theoretic Approach to\n  Design Secure DSVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning algorithms play a significant role in processing\nmassive data sets over large networks. However, the increasing reliance on\nmachine learning on information and communication technologies (ICTs) makes it\ninherently vulnerable to cyber threats. This work aims to develop secure\ndistributed algorithms to protect the learning from data poisoning and network\nattacks. We establish a game-theoretic framework to capture the conflicting\ngoals of a learner who uses distributed support vector machines (SVMs) and an\nattacker who is capable of modifying training data and labels. We develop a\nfully distributed and iterative algorithm to capture real-time reactions of the\nlearner at each node to adversarial behaviors. The numerical results show that\ndistributed SVM is prone to fail in different types of attacks, and their\nimpact has a strong dependence on the network structure and attack\ncapabilities.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 18:54:17 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 21:50:35 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Rui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2003.04763", "submitter": "Hatoon AlSagri", "authors": "Hatoon S. AlSagri, Mourad Ykhlef", "title": "Machine Learning-based Approach for Depression Detection in Twitter\n  Using Content and Activity Features", "comments": "16 pages, 7 figures, journal article", "journal-ref": null, "doi": "10.1587/transinf.2020EDP7023", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media channels, such as Facebook, Twitter, and Instagram, have altered\nour world forever. People are now increasingly connected than ever and reveal a\nsort of digital persona. Although social media certainly has several remarkable\nfeatures, the demerits are undeniable as well. Recent studies have indicated a\ncorrelation between high usage of social media sites and increased depression.\nThe present study aims to exploit machine learning techniques for detecting a\nprobable depressed Twitter user based on both, his/her network behavior and\ntweets. For this purpose, we trained and tested classifiers to distinguish\nwhether a user is depressed or not using features extracted from his/ her\nactivities in the network and tweets. The results showed that the more features\nare used, the higher are the accuracy and F-measure scores in detecting\ndepressed users. This method is a data-driven, predictive approach for early\ndetection of depression or other mental illnesses. This study's main\ncontribution is the exploration part of the features and its impact on\ndetecting the depression level.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 11:27:39 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["AlSagri", "Hatoon S.", ""], ["Ykhlef", "Mourad", ""]]}, {"id": "2003.04774", "submitter": "Alexander Thebelt", "authors": "Alexander Thebelt, Jan Kronqvist, Miten Mistry, Robert M. Lee, Nathan\n  Sudermann-Merx, Ruth Misener", "title": "ENTMOOT: A Framework for Optimization over Ensemble Tree Models", "comments": "33 pages, 10 figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.compchemeng.2021.107343", "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted trees and other regression tree models perform well in a\nwide range of real-world, industrial applications. These tree models (i) offer\ninsight into important prediction features, (ii) effectively manage sparse\ndata, and (iii) have excellent prediction capabilities. Despite their\nadvantages, they are generally unpopular for decision-making tasks and\nblack-box optimization, which is due to their difficult-to optimize structure\nand the lack of a reliable uncertainty measure. ENTMOOT is our new framework\nfor integrating (already trained) tree models into larger optimization\nproblems. The contributions of ENTMOOT include: (i) explicitly introducing a\nreliable uncertainty measure that is compatible with tree models, (ii) solving\nthe larger optimization problems that incorporate these uncertainty aware tree\nmodels, (iii) proving that the solutions are globally optimal, i.e. no better\nsolution exists. In particular, we show how the ENTMOOT approach allows a\nsimple integration of tree models into decision-making and black-box\noptimization, where it proves as a strong competitor to commonly-used\nframeworks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 14:34:07 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 00:16:58 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 15:10:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thebelt", "Alexander", ""], ["Kronqvist", "Jan", ""], ["Mistry", "Miten", ""], ["Lee", "Robert M.", ""], ["Sudermann-Merx", "Nathan", ""], ["Misener", "Ruth", ""]]}, {"id": "2003.04786", "submitter": "Kun Chen", "authors": "Xiaokang Liu, Shujie Ma, Kun Chen", "title": "Multivariate Functional Regression via Nested Reduced-Rank\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nested reduced-rank regression (NRRR) approach in fitting\nregression model with multivariate functional responses and predictors, to\nachieve tailored dimension reduction and facilitate\ninterpretation/visualization of the resulting functional model. Our approach is\nbased on a two-level low-rank structure imposed on the functional regression\nsurfaces. A global low-rank structure identifies a small set of latent\nprincipal functional responses and predictors that drives the underlying\nregression association. A local low-rank structure then controls the complexity\nand smoothness of the association between the principal functional responses\nand predictors. Through a basis expansion approach, the functional problem\nboils down to an interesting integrated matrix approximation task, where the\nblocks or submatrices of an integrated low-rank matrix share some common row\nspace and/or column space. An iterative algorithm with convergence guarantee is\ndeveloped. We establish the consistency of NRRR and also show through\nnon-asymptotic analysis that it can achieve at least a comparable error rate to\nthat of the reduced-rank regression. Simulation studies demonstrate the\neffectiveness of NRRR. We apply NRRR in an electricity demand problem, to\nrelate the trajectories of the daily electricity consumption with those of the\ndaily temperatures.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 14:58:54 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Liu", "Xiaokang", ""], ["Ma", "Shujie", ""], ["Chen", "Kun", ""]]}, {"id": "2003.04793", "submitter": "Benjamin Paassen", "authors": "Benjamin Paassen and Alexander Schulz", "title": "Reservoir memory machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Neural Turing Machines have gathered attention by joining\nthe flexibility of neural networks with the computational capabilities of\nTuring machines. However, Neural Turing Machines are notoriously hard to train,\nwhich limits their applicability. We propose reservoir memory machines, which\nare still able to solve some of the benchmark tests for Neural Turing Machines,\nbut are much faster to train, requiring only an alignment algorithm and linear\nregression. Our model can also be seen as an extension of echo state networks\nwith an external memory, enabling arbitrarily long storage without\ninterference.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:45:00 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Paassen", "Benjamin", ""], ["Schulz", "Alexander", ""]]}, {"id": "2003.04794", "submitter": "Marius Miron", "authors": "Marius Miron, Song\\\"ul Tolan, Emilia G\\'omez, Carlos Castillo", "title": "Addressing multiple metrics of group fairness in data-driven decision\n  making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Fairness, Accountability, and Transparency in Machine Learning (FAT-ML)\nliterature proposes a varied set of group fairness metrics to measure\ndiscrimination against socio-demographic groups that are characterized by a\nprotected feature, such as gender or race.Such a system can be deemed as either\nfair or unfair depending on the choice of the metric. Several metrics have been\nproposed, some of them incompatible with each other.We do so empirically, by\nobserving that several of these metrics cluster together in two or three main\nclusters for the same groups and machine learning methods. In addition, we\npropose a robust way to visualize multidimensional fairness in two dimensions\nthrough a Principal Component Analysis (PCA) of the group fairness metrics.\nExperimental results on multiple datasets show that the PCA decomposition\nexplains the variance between the metrics with one to three components.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:13:05 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Miron", "Marius", ""], ["Tolan", "Song\u00fcl", ""], ["G\u00f3mez", "Emilia", ""], ["Castillo", "Carlos", ""]]}, {"id": "2003.04808", "submitter": "Johannes Welbl", "authors": "Johannes Welbl, Pasquale Minervini, Max Bartolo, Pontus Stenetorp,\n  Sebastian Riedel", "title": "Undersensitivity in Neural Reading Comprehension", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current reading comprehension models generalise well to in-distribution test\nsets, yet perform poorly on adversarially selected inputs. Most prior work on\nadversarial inputs studies oversensitivity: semantically invariant text\nperturbations that cause a model's prediction to change when it should not. In\nthis work we focus on the complementary problem: excessive prediction\nundersensitivity, where input text is meaningfully changed but the model's\nprediction does not, even though it should. We formulate a noisy adversarial\nattack which searches among semantic variations of the question for which a\nmodel erroneously predicts the same answer, and with even higher probability.\nDespite comprising unanswerable questions, both SQuAD2.0 and NewsQA models are\nvulnerable to this attack. This indicates that although accurate, models tend\nto rely on spurious patterns and do not fully consider the information\nspecified in a question. We experiment with data augmentation and adversarial\ntraining as defences, and find that both substantially decrease vulnerability\nto attacks on held out data, as well as held out attack spaces. Addressing\nundersensitivity also improves results on AddSent and AddOneSent, and models\nfurthermore generalise better when facing train/evaluation distribution\nmismatch: they are less prone to overly rely on predictive cues present only in\nthe training set, and outperform a conventional model by as much as 10.9% F1.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 19:03:36 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Welbl", "Johannes", ""], ["Minervini", "Pasquale", ""], ["Bartolo", "Max", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2003.04811", "submitter": "Junchao Zhang", "authors": "Junchao Zhang", "title": "Weighted Encoding Based Image Interpolation With Nonlocal Linear\n  Regression Model", "comments": null, "journal-ref": null, "doi": "10.1364/AO.397652", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image interpolation is a special case of image super-resolution, where the\nlow-resolution image is directly down-sampled from its high-resolution\ncounterpart without blurring and noise. Therefore, assumptions adopted in\nsuper-resolution models are not valid for image interpolation. To address this\nproblem, we propose a novel image interpolation model based on sparse\nrepresentation. Two widely used priors including sparsity and nonlocal\nself-similarity are used as the regularization terms to enhance the stability\nof interpolation model. Meanwhile, we incorporate the nonlocal linear\nregression into this model since nonlocal similar patches could provide a\nbetter approximation to a given patch. Moreover, we propose a new approach to\nlearn adaptive sub-dictionary online instead of clustering. For each patch,\nsimilar patches are grouped to learn adaptive sub-dictionary, generating a more\nsparse and accurate representation. Finally, the weighted encoding is\nintroduced to suppress tailing of fitting residuals in data fidelity. Abundant\nexperimental results demonstrate that our proposed method outperforms several\nstate-of-the-art methods in terms of quantitative measures and visual quality.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 03:20:21 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhang", "Junchao", ""]]}, {"id": "2003.04816", "submitter": "Sarder Fakhrul Abedin", "authors": "Sarder Fakhrul Abedin, Md. Shirajum Munir, Nguyen H. Tran, Zhu Han,\n  Choong Seon Hong", "title": "Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep\n  Reinforcement Learning Approach", "comments": "Submitted to IEEE Transactions on Intelligent Transportation Systems,\n  Special Issue on Unmanned Aircraft System Traffic Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design a navigation policy for multiple unmanned aerial\nvehicles (UAVs) where mobile base stations (BSs) are deployed to improve the\ndata freshness and connectivity to the Internet of Things (IoT) devices. First,\nwe formulate an energy-efficient trajectory optimization problem in which the\nobjective is to maximize the energy efficiency by optimizing the UAV-BS\ntrajectory policy. We also incorporate different contextual information such as\nenergy and age of information (AoI) constraints to ensure the data freshness at\nthe ground BS. Second, we propose an agile deep reinforcement learning with\nexperience replay model to solve the formulated problem concerning the\ncontextual constraints for the UAV-BS navigation. Moreover, the proposed\napproach is well-suited for solving the problem, since the state space of the\nproblem is extremely large and finding the best trajectory policy with useful\ncontextual features is too complex for the UAV-BSs. By applying the proposed\ntrained model, an effective real-time trajectory policy for the UAV-BSs\ncaptures the observable network states over time. Finally, the simulation\nresults illustrate the proposed approach is 3.6% and 3.13% more energy\nefficient than those of the greedy and baseline deep Q Network (DQN)\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:29:15 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Abedin", "Sarder Fakhrul", ""], ["Munir", "Md. Shirajum", ""], ["Tran", "Nguyen H.", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.04819", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki, Oliver Kiss, Rik Sarkar", "title": "Karate Club: An API Oriented Open-source Python Framework for\n  Unsupervised Learning on Graphs", "comments": "The frameworks is available at:\n  https://github.com/benedekrozemberczki/karateclub", "journal-ref": "Published in CIKM 2020 as a resource track paper", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Karate Club a Python framework combining more than 30\nstate-of-the-art graph mining algorithms which can solve unsupervised machine\nlearning tasks. The primary goal of the package is to make community detection,\nnode and whole graph embedding available to a wide audience of machine learning\nresearchers and practitioners. We designed Karate Club with an emphasis on a\nconsistent application interface, scalability, ease of use, sensible out of the\nbox model behaviour, standardized dataset ingestion, and output generation.\nThis paper discusses the design principles behind this framework with practical\nexamples. We show Karate Club's efficiency with respect to learning performance\non a wide range of real world clustering problems, classification tasks and\nsupport evidence with regards to its competitive speed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:54:53 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 16:33:04 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 10:21:01 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Kiss", "Oliver", ""], ["Sarkar", "Rik", ""]]}, {"id": "2003.04873", "submitter": "Haoyun Ying", "authors": "Haoyun Ying, Keheng Mao, Klaus Mosegaard", "title": "Moving Target Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Markov Chain Monte Carlo (MCMC) methods are popular when considering\nsampling from a high-dimensional random variable $\\mathbf{x}$ with possibly\nunnormalised probability density $p$ and observed data $\\mathbf{d}$. However,\nMCMC requires evaluating the posterior distribution $p(\\mathbf{x}|\\mathbf{d})$\nof the proposed candidate $\\mathbf{x}$ at each iteration when constructing the\nacceptance rate. This is costly when such evaluations are intractable. In this\npaper, we introduce a new non-Markovian sampling algorithm called Moving Target\nMonte Carlo (MTMC). The acceptance rate at $n$-th iteration is constructed\nusing an iteratively updated approximation of the posterior distribution\n$a_n(\\mathbf{x})$ instead of $p(\\mathbf{x}|\\mathbf{d})$. The true value of the\nposterior $p(\\mathbf{x}|\\mathbf{d})$ is only calculated if the candidate\n$\\mathbf{x}$ is accepted. The approximation $a_n$ utilises these evaluations\nand converges to $p$ as $n \\rightarrow \\infty$. A proof of convergence and\nestimation of convergence rate in different situations are given.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:38:36 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Ying", "Haoyun", ""], ["Mao", "Keheng", ""], ["Mosegaard", "Klaus", ""]]}, {"id": "2003.04887", "submitter": "Huanru Henry Mao", "authors": "Thomas Bachlechner, Bodhisattwa Prasad Majumder, Huanru Henry Mao,\n  Garrison W. Cottrell, Julian McAuley", "title": "ReZero is All You Need: Fast Convergence at Large Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks often suffer from vanishing or exploding gradients due to\ninefficient signal propagation, leading to long training times or convergence\ndifficulties. Various architecture designs, sophisticated residual-style\nnetworks, and initialization schemes have been shown to improve deep signal\npropagation. Recently, Pennington et al. used free probability theory to show\nthat dynamical isometry plays an integral role in efficient deep learning. We\nshow that the simplest architecture change of gating each residual connection\nusing a single zero-initialized parameter satisfies initial dynamical isometry\nand outperforms more complex approaches. Although much simpler than its\npredecessors, this gate enables training thousands of fully connected layers\nwith fast convergence and better test performance for ResNets trained on\nCIFAR-10. We apply this technique to language modeling and find that we can\neasily train 120-layer Transformers. When applied to 12 layer Transformers, it\nconverges 56% faster on enwiki8.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:58:01 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 00:09:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Bachlechner", "Thomas", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["Mao", "Huanru Henry", ""], ["Cottrell", "Garrison W.", ""], ["McAuley", "Julian", ""]]}, {"id": "2003.04919", "submitter": "Jared Willard", "authors": "Jared Willard, Xiaowei Jia, Shaoming Xu, Michael Steinbach, Vipin\n  Kumar", "title": "Integrating Scientific Knowledge with Machine Learning for Engineering\n  and Environmental Systems", "comments": "35 pages, 4 figures, submitted to ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing consensus that solutions to complex science and\nengineering problems require novel methodologies that are able to integrate\ntraditional physics-based modeling approaches with state-of-the-art machine\nlearning (ML) techniques. This paper provides a structured overview of such\ntechniques. Application-centric objective areas for which these approaches have\nbeen applied are summarized, and then classes of methodologies used to\nconstruct physics-guided ML models and hybrid physics-ML frameworks are\ndescribed. We then provide a taxonomy of these existing techniques, which\nuncovers knowledge gaps and potential crossovers of methods between disciplines\nthat can serve as ideas for future research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 18:24:41 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 19:22:46 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 22:25:56 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 01:20:15 GMT"}, {"version": "v5", "created": "Fri, 23 Jul 2021 17:10:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Willard", "Jared", ""], ["Jia", "Xiaowei", ""], ["Xu", "Shaoming", ""], ["Steinbach", "Michael", ""], ["Kumar", "Vipin", ""]]}, {"id": "2003.04937", "submitter": "N. Benjamin Erichson", "authors": "Miles E. Lopes and N. Benjamin Erichson and Michael W. Mahoney", "title": "Error Estimation for Sketched SVD via the Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to compute fast approximations to the singular value decompositions\n(SVD) of very large matrices, randomized sketching algorithms have become a\nleading approach. However, a key practical difficulty of sketching an SVD is\nthat the user does not know how far the sketched singular vectors/values are\nfrom the exact ones. Indeed, the user may be forced to rely on analytical\nworst-case error bounds, which do not account for the unique structure of a\ngiven problem. As a result, the lack of tools for error estimation often leads\nto much more computation than is really necessary. To overcome these\nchallenges, this paper develops a fully data-driven bootstrap method that\nnumerically estimates the actual error of sketched singular vectors/values. In\nparticular, this allows the user to inspect the quality of a rough initial\nsketched SVD, and then adaptively predict how much extra work is needed to\nreach a given error tolerance. Furthermore, the method is computationally\ninexpensive, because it operates only on sketched objects, and it requires no\npasses over the full matrix being factored. Lastly, the method is supported by\ntheoretical guarantees and a very encouraging set of experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 19:14:08 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Lopes", "Miles E.", ""], ["Erichson", "N. Benjamin", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2003.04948", "submitter": "David Blei", "authors": "Yixin Wang, David M. Blei", "title": "Towards Clarifying the Theory of the Deconfounder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wang and Blei (2019) studies multiple causal inference and proposes the\ndeconfounder algorithm. The paper discusses theoretical requirements and\npresents empirical studies. Several refinements have been suggested around the\ntheory of the deconfounder. Among these, Imai and Jiang clarified the\nassumption of \"no unobserved single-cause confounders.\" Using their assumption,\nthis paper clarifies the theory. Furthermore, Ogburn et al. (2020) proposes\ncounterexamples to the theory. But the proposed counterexamples do not satisfy\nthe required assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 19:59:03 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "2003.04960", "submitter": "Sanmit Narvekar", "authors": "Sanmit Narvekar and Bei Peng and Matteo Leonetti and Jivko Sinapov and\n  Matthew E. Taylor and Peter Stone", "title": "Curriculum Learning for Reinforcement Learning Domains: A Framework and\n  Survey", "comments": null, "journal-ref": "Journal of Machine Learning Research 21(181):1-50, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) is a popular paradigm for addressing sequential\ndecision tasks in which the agent has only limited environmental feedback.\nDespite many advances over the past three decades, learning in many domains\nstill requires a large amount of interaction with the environment, which can be\nprohibitively expensive in realistic scenarios. To address this problem,\ntransfer learning has been applied to reinforcement learning such that\nexperience gained in one task can be leveraged when starting to learn the next,\nharder task. More recently, several lines of research have explored how tasks,\nor data samples themselves, can be sequenced into a curriculum for the purpose\nof learning a problem that may otherwise be too difficult to learn from\nscratch. In this article, we present a framework for curriculum learning (CL)\nin reinforcement learning, and use it to survey and classify existing CL\nmethods in terms of their assumptions, capabilities, and goals. Finally, we use\nour framework to find open problems and suggest directions for future RL\ncurriculum learning research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 20:41:24 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 22:31:51 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Narvekar", "Sanmit", ""], ["Peng", "Bei", ""], ["Leonetti", "Matteo", ""], ["Sinapov", "Jivko", ""], ["Taylor", "Matthew E.", ""], ["Stone", "Peter", ""]]}, {"id": "2003.04968", "submitter": "Tanvir Ahmad", "authors": "Gunjan Ansari, Chandni Saxena, Tanvir Ahmad and M.N.Doja", "title": "Aspect Term Extraction using Graph-based Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based Sentiment Analysis is a major subarea of sentiment analysis.\nMany supervised and unsupervised approaches have been proposed in the past for\ndetecting and analyzing the sentiment of aspect terms. In this paper, a\ngraph-based semi-supervised learning approach for aspect term extraction is\nproposed. In this approach, every identified token in the review document is\nclassified as aspect or non-aspect term from a small set of labeled tokens\nusing label spreading algorithm. The k-Nearest Neighbor (kNN) for graph\nsparsification is employed in the proposed approach to make it more time and\nmemory efficient. The proposed work is further extended to determine the\npolarity of the opinion words associated with the identified aspect terms in\nreview sentence to generate visual aspect-based summary of review documents.\nThe experimental study is conducted on benchmark and crawled datasets of\nrestaurant and laptop domains with varying value of labeled instances. The\nresults depict that the proposed approach could achieve good result in terms of\nPrecision, Recall and Accuracy with limited availability of labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:11:02 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Ansari", "Gunjan", ""], ["Saxena", "Chandni", ""], ["Ahmad", "Tanvir", ""], ["Doja", "M. N.", ""]]}, {"id": "2003.04972", "submitter": "Zachary Lindner", "authors": "Zachary Lindner", "title": "A Comparative Study of Sequence Classification Models for Privacy Policy\n  Coverage Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy policies are legal documents that describe how a website will\ncollect, use, and distribute a user's data. Unfortunately, such documents are\noften overly complicated and filled with legal jargon; making it difficult for\nusers to fully grasp what exactly is being collected and why. Our solution to\nthis problem is to provide users with a coverage analysis of a given website's\nprivacy policy using a wide range of classical machine learning and deep\nlearning techniques. Given a website's privacy policy, the classifier\nidentifies the associated data practice for each logical segment. These data\npractices/labels are taken directly from the OPP-115 corpus. For example, the\ndata practice \"Data Retention\" refers to how long a website stores a user's\ninformation. The coverage analysis allows users to determine how many of the\nten possible data practices are covered, along with identifying the sections\nthat correspond to the data practices of particular interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:46:22 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Lindner", "Zachary", ""]]}, {"id": "2003.04974", "submitter": "Prakhar Thapak", "authors": "Prakhar Thapak and Prodip Hore", "title": "Transformer++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in attention mechanisms have replaced recurrent neural\nnetworks and its variants for machine translation tasks. Transformer using\nattention mechanism solely achieved state-of-the-art results in sequence\nmodeling. Neural machine translation based on the attention mechanism is\nparallelizable and addresses the problem of handling long-range dependencies\namong words in sentences more effectively than recurrent neural networks. One\nof the key concepts in attention is to learn three matrices, query, key, and\nvalue, where global dependencies among words are learned through linearly\nprojecting word embeddings through these matrices. Multiple query, key, value\nmatrices can be learned simultaneously focusing on a different subspace of the\nembedded dimension, which is called multi-head in Transformer. We argue that\ncertain dependencies among words could be learned better through an\nintermediate context than directly modeling word-word dependencies. This could\nhappen due to the nature of certain dependencies or lack of patterns that lend\nthem difficult to be modeled globally using multi-head self-attention. In this\nwork, we propose a new way of learning dependencies through a context in\nmulti-head using convolution. This new form of multi-head attention along with\nthe traditional form achieves better results than Transformer on the WMT 2014\nEnglish-to-German and English-to-French translation tasks. We also introduce a\nframework to learn POS tagging and NER information during the training of\nencoder which further improves results achieving a new state-of-the-art of 32.1\nBLEU, better than existing best by 1.4 BLEU, on the WMT 2014 English-to-German\nand 44.6 BLEU, better than existing best by 1.1 BLEU, on the WMT 2014\nEnglish-to-French translation tasks. We call this Transformer++.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:00:16 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Thapak", "Prakhar", ""], ["Hore", "Prodip", ""]]}, {"id": "2003.04978", "submitter": "Sairamvinay Vijayaraghavan", "authors": "Sairamvinay Vijayaraghavan, Ye Wang, Zhiyuan Guo, John Voong, Wenda\n  Xu, Armand Nasseri, Jiaru Cai, Linda Li, Kevin Vuong, and Eshan Wadhwa", "title": "Fake News Detection with Different Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is a paper for exploring various different models aiming at developing\nfake news detection models and we had used certain machine learning algorithms\nand we had used pretrained algorithms such as TFIDF and CV and W2V as features\nfor processing textual data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 06:15:17 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Vijayaraghavan", "Sairamvinay", ""], ["Wang", "Ye", ""], ["Guo", "Zhiyuan", ""], ["Voong", "John", ""], ["Xu", "Wenda", ""], ["Nasseri", "Armand", ""], ["Cai", "Jiaru", ""], ["Li", "Linda", ""], ["Vuong", "Kevin", ""], ["Wadhwa", "Eshan", ""]]}, {"id": "2003.04980", "submitter": "Jonas Rieger", "authors": "Jonas Rieger, Lars Koppers, Carsten Jentsch, and J\\\"org Rahnenf\\\"uhrer", "title": "Improving Reliability of Latent Dirichlet Allocation by Assessing Its\n  Stability Using Clustering Techniques on Replicated Runs", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For organizing large text corpora topic modeling provides useful tools. A\nwidely used method is Latent Dirichlet Allocation (LDA), a generative\nprobabilistic model which models single texts in a collection of texts as\nmixtures of latent topics. The assignments of words to topics rely on initial\nvalues such that generally the outcome of LDA is not fully reproducible. In\naddition, the reassignment via Gibbs Sampling is based on conditional\ndistributions, leading to different results in replicated runs on the same text\ndata. This fact is often neglected in everyday practice. We aim to improve the\nreliability of LDA results. Therefore, we study the stability of LDA by\ncomparing assignments from replicated runs. We propose to quantify the\nsimilarity of two generated topics by a modified Jaccard coefficient. Using\nsuch similarities, topics can be clustered. A new pruning algorithm for\nhierarchical clustering results based on the idea that two LDA runs create\npairs of similar topics is proposed. This approach leads to the new measure\nS-CLOP ({\\bf S}imilarity of multiple sets by {\\bf C}lustering with {\\bf LO}cal\n{\\bf P}runing) for quantifying the stability of LDA models. We discuss some\ncharacteristics of this measure and illustrate it with an application to real\ndata consisting of newspaper articles from \\textit{USA Today}. Our results show\nthat the measure S-CLOP is useful for assessing the stability of LDA models or\nany other topic modeling procedure that characterize its topics by word\ndistributions. Based on the newly proposed measure for LDA stability, we\npropose a method to increase the reliability and hence to improve the\nreproducibility of empirical findings based on topic modeling. This increase in\nreliability is obtained by running the LDA several times and taking as\nprototype the most representative run, that is the LDA run with highest average\nsimilarity to all other runs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 07:10:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Rieger", "Jonas", ""], ["Koppers", "Lars", ""], ["Jentsch", "Carsten", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2003.04981", "submitter": "Xinyi Zhou", "authors": "Xinyi Zhou, Jindi Wu, Reza Zafarani", "title": "SAFE: Similarity-Aware Multi-Modal Fake News Detection", "comments": "To be published in The 24th Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective detection of fake news has recently attracted significant\nattention. Current studies have made significant contributions to predicting\nfake news with less focus on exploiting the relationship (similarity) between\nthe textual and visual information in news articles. Attaching importance to\nsuch similarity helps identify fake news stories that, for example, attempt to\nuse irrelevant images to attract readers' attention. In this work, we propose a\n$\\mathsf{S}$imilarity-$\\mathsf{A}$ware $\\mathsf{F}$ak$\\mathsf{E}$ news\ndetection method ($\\mathsf{SAFE}$) which investigates multi-modal (textual and\nvisual) information of news articles. First, neural networks are adopted to\nseparately extract textual and visual features for news representation. We\nfurther investigate the relationship between the extracted features across\nmodalities. Such representations of news textual and visual information along\nwith their relationship are jointly learned and used to predict fake news. The\nproposed method facilitates recognizing the falsity of news articles based on\ntheir text, images, or their \"mismatches.\" We conduct extensive experiments on\nlarge-scale real-world data, which demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:51:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zhou", "Xinyi", ""], ["Wu", "Jindi", ""], ["Zafarani", "Reza", ""]]}, {"id": "2003.04983", "submitter": "Megan Leszczynski", "authors": "Megan Leszczynski, Avner May, Jian Zhang, Sen Wu, Christopher R.\n  Aberger, Christopher R\\'e", "title": "Understanding the Downstream Instability of Word Embeddings", "comments": "In Proceedings of the 3rd MLSys Conference, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many industrial machine learning (ML) systems require frequent retraining to\nkeep up-to-date with constantly changing data. This retraining exacerbates a\nlarge challenge facing ML systems today: model training is unstable, i.e.,\nsmall changes in training data can cause significant changes in the model's\npredictions. In this paper, we work on developing a deeper understanding of\nthis instability, with a focus on how a core building block of modern natural\nlanguage processing (NLP) pipelines---pre-trained word embeddings---affects the\ninstability of downstream NLP models. We first empirically reveal a tradeoff\nbetween stability and memory: increasing the embedding memory 2x can reduce the\ndisagreement in predictions due to small changes in training data by 5% to 37%\n(relative). To theoretically explain this tradeoff, we introduce a new measure\nof embedding instability---the eigenspace instability measure---which we prove\nbounds the disagreement in downstream predictions introduced by the change in\nword embeddings. Practically, we show that the eigenspace instability measure\ncan be a cost-effective way to choose embedding parameters to minimize\ninstability without training downstream models, outperforming other embedding\ndistance measures and performing competitively with a nearest neighbor-based\nmeasure. Finally, we demonstrate that the observed stability-memory tradeoffs\nextend to other types of embeddings as well, including knowledge graph and\ncontextual word embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 00:39:12 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Leszczynski", "Megan", ""], ["May", "Avner", ""], ["Zhang", "Jian", ""], ["Wu", "Sen", ""], ["Aberger", "Christopher R.", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2003.04986", "submitter": "Vukosi Marivate", "authors": "Vukosi Marivate, Tshephisho Sefara, Vongani Chabalala, Keamogetswe\n  Makhaya, Tumisho Mokgonyane, Rethabile Mokoena, Abiodun Modupe", "title": "Investigating an approach for low resource language dataset creation,\n  curation and classification: Setswana and Sepedi", "comments": "Submitted to Resources for African Indigenous Languages (RAIL) at\n  LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The recent advances in Natural Language Processing have been a boon for\nwell-represented languages in terms of available curated data and research\nresources. One of the challenges for low-resourced languages is clear\nguidelines on the collection, curation and preparation of datasets for\ndifferent use-cases. In this work, we take on the task of creation of two\ndatasets that are focused on news headlines (i.e short text) for Setswana and\nSepedi and creation of a news topic classification task. We document our work\nand also present baselines for classification. We investigate an approach on\ndata augmentation, better suited to low resource languages, to improve the\nperformance of the classifiers\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:58:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Marivate", "Vukosi", ""], ["Sefara", "Tshephisho", ""], ["Chabalala", "Vongani", ""], ["Makhaya", "Keamogetswe", ""], ["Mokgonyane", "Tumisho", ""], ["Mokoena", "Rethabile", ""], ["Modupe", "Abiodun", ""]]}, {"id": "2003.04987", "submitter": "Shi Yu", "authors": "Shi Yu, Yuxin Chen, Hussain Zaidi", "title": "A Financial Service Chatbot based on Deep Bidirectional Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a chatbot using Deep Bidirectional Transformer models (BERT) to\nhandle client questions in financial investment customer service. The bot can\nrecognize 381 intents, and decides when to say \"I don't know\" and escalates\nirrelevant/uncertain questions to human operators. Our main novel contribution\nis the discussion about uncertainty measure for BERT, where three different\napproaches are systematically compared on real problems. We investigated two\nuncertainty metrics, information entropy and variance of dropout sampling in\nBERT, followed by mixed-integer programming to optimize decision thresholds.\nAnother novel contribution is the usage of BERT as a language model in\nautomatic spelling correction. Inputs with accidental spelling errors can\nsignificantly decrease intent classification performance. The proposed approach\ncombines probabilities from masked language model and word edit distances to\nfind the best corrections for misspelled words. The chatbot and the entire\nconversational AI system are developed using open-source tools, and deployed\nwithin our company's intranet. The proposed approach can be useful for\nindustries seeking similar in-house solutions in their specific business\ndomains. We share all our code and a sample chatbot built on a public dataset\non Github.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:48:55 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Yu", "Shi", ""], ["Chen", "Yuxin", ""], ["Zaidi", "Hussain", ""]]}, {"id": "2003.04988", "submitter": "Barun Patra", "authors": "Vishwas Suryanarayanan, Barun Patra, Pamela Bhattacharya, Chala Fufa,\n  Charles Lee", "title": "ScopeIt: Scoping Task Relevant Sentences in Documents", "comments": "Accepted in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent assistants like Cortana, Siri, Alexa, and Google Assistant are\ntrained to parse information when the conversation is synchronous and short;\nhowever, for email-based conversational agents, the communication is\nasynchronous, and often contains information irrelevant to the assistant. This\nmakes it harder for the system to accurately detect intents, extract entities\nrelevant to those intents and thereby perform the desired action. We present a\nneural model for scoping relevant information for the agent from a large query.\nWe show that when used as a preprocessing step, the model improves performance\nof both intent detection and entity extraction tasks. We demonstrate the\nmodel's impact on Scheduler (Cortana is the persona of the agent, while\nScheduler is the name of the service. We use them interchangeably in the\ncontext of this paper.) - a virtual conversational meeting scheduling assistant\nthat interacts asynchronously with users through email. The model helps the\nentity extraction and intent detection tasks requisite by Scheduler achieve an\naverage gain of 35% in precision without any drop in recall. Additionally, we\ndemonstrate that the same approach can be used for component level analysis in\nlarge documents, such as signature block identification.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 02:33:10 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 09:44:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Suryanarayanan", "Vishwas", ""], ["Patra", "Barun", ""], ["Bhattacharya", "Pamela", ""], ["Fufa", "Chala", ""], ["Lee", "Charles", ""]]}, {"id": "2003.04989", "submitter": "Daniel Otero Baguer", "authors": "Daniel Otero Baguer, Johannes Leuschner, Maximilian Schmidt", "title": "Computed Tomography Reconstruction Using Deep Image Prior and Learned\n  Reconstruction Methods", "comments": null, "journal-ref": "Inverse Problems, Volume 36, Number 9 (2020)", "doi": "10.1088/1361-6420/aba415", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the application of deep learning methods for\ncomputed tomography in the context of having a low-data regime. As motivation,\nwe review some of the existing approaches and obtain quantitative results after\ntraining them with different amounts of data. We find that the learned\nprimal-dual has an outstanding performance in terms of reconstruction quality\nand data efficiency. However, in general, end-to-end learned methods have two\nissues: a) lack of classical guarantees in inverse problems and b) lack of\ngeneralization when not trained with enough data. To overcome these issues, we\nbring in the deep image prior approach in combination with classical\nregularization. The proposed methods improve the state-of-the-art results in\nthe low data-regime.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:03:34 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 12:09:52 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Baguer", "Daniel Otero", ""], ["Leuschner", "Johannes", ""], ["Schmidt", "Maximilian", ""]]}, {"id": "2003.04991", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Hemant Purohit and Huzefa Rangwala", "title": "Unsupervised and Interpretable Domain Adaptation to Rapidly Filter\n  Tweets for Emergency Services", "comments": "8 pages, 4 Figures, 6 Tables, Source Code Available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the onset of a disaster event, filtering relevant information from the\nsocial web data is challenging due to its sparse availability and practical\nlimitations in labeling datasets of an ongoing crisis. In this paper, we\nhypothesize that unsupervised domain adaptation through multi-task learning can\nbe a useful framework to leverage data from past crisis events for training\nefficient information filtering models during the sudden onset of a new crisis.\nWe present a novel method to classify relevant tweets during an ongoing crisis\nwithout seeing any new examples, using the publicly available dataset of TREC\nincident streams. Specifically, we construct a customized multi-task\narchitecture with a multi-domain discriminator for crisis analytics: multi-task\ndomain adversarial attention network. This model consists of dedicated\nattention layers for each task to provide model interpretability; critical for\nreal-word applications. As deep networks struggle with sparse datasets, we show\nthat this can be improved by sharing a base layer for multi-task learning and\ndomain adversarial training. Evaluation of domain adaptation for crisis events\nis performed by choosing a target event as the test set and training on the\nrest. Our results show that the multi-task model outperformed its single task\ncounterpart. For the qualitative evaluation of interpretability, we show that\nthe attention layer can be used as a guide to explain the model predictions and\nempower emergency services for exploring accountability of the model, by\nshowcasing the words in a tweet that are deemed important in the classification\nprocess. Finally, we show a practical implication of our work by providing a\nuse-case for the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:40:14 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 18:01:19 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Krishnan", "Jitin", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2003.04994", "submitter": "Yating Zhang", "authors": "Tianyi Wang, Yating Zhang, Xiaozhong Liu, Changlong Sun, Qiong Zhang", "title": "Masking Orchestration: Multi-task Pretraining for Multi-role Dialogue\n  Representation Learning", "comments": "8 pages, 4 figures, AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-role dialogue understanding comprises a wide range of diverse tasks\nsuch as question answering, act classification, dialogue summarization etc.\nWhile dialogue corpora are abundantly available, labeled data, for specific\nlearning tasks, can be highly scarce and expensive. In this work, we\ninvestigate dialogue context representation learning with various types\nunsupervised pretraining tasks where the training objectives are given\nnaturally according to the nature of the utterance and the structure of the\nmulti-role conversation. Meanwhile, in order to locate essential information\nfor dialogue summarization/extraction, the pretraining process enables external\nknowledge integration. The proposed fine-tuned pretraining mechanism is\ncomprehensively evaluated via three different dialogue datasets along with a\nnumber of downstream dialogue-mining tasks. Result shows that the proposed\npretraining mechanism significantly contributes to all the downstream tasks\nwithout discrimination to different encoders.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:36:52 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Wang", "Tianyi", ""], ["Zhang", "Yating", ""], ["Liu", "Xiaozhong", ""], ["Sun", "Changlong", ""], ["Zhang", "Qiong", ""]]}, {"id": "2003.04998", "submitter": "Yitong Li", "authors": "Yitong Li, Dianqi Li, Sushant Prakash and Peng Wang", "title": "Toward Interpretability of Dual-Encoder Models for Dialogue Response\n  Suggestions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows how to improve and interpret the commonly used dual encoder\nmodel for response suggestion in dialogue. We present an attentive dual encoder\nmodel that includes an attention mechanism on top of the extracted word-level\nfeatures from two encoders, one for context and one for label respectively. To\nimprove the interpretability in the dual encoder models, we design a novel\nregularization loss to minimize the mutual information between unimportant\nwords and desired labels, in addition to the original attention method, so that\nimportant words are emphasized while unimportant words are de-emphasized. This\ncan help not only with model interpretability, but can also further improve\nmodel accuracy. We propose an approximation method that uses a neural network\nto calculate the mutual information. Furthermore, by adding a residual layer\nbetween raw word embeddings and the final encoded context feature, word-level\ninterpretability is preserved at the final prediction of the model. We compare\nthe proposed model with existing methods for the dialogue response task on two\npublic datasets (Persona and Ubuntu). The experiments demonstrate the\neffectiveness of the proposed model in terms of better Recall@1 accuracy and\nvisualized interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:26:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Li", "Yitong", ""], ["Li", "Dianqi", ""], ["Prakash", "Sushant", ""], ["Wang", "Peng", ""]]}, {"id": "2003.05012", "submitter": "Stephanie Milani", "authors": "Stephanie Milani, Nicholay Topin, Brandon Houghton, William H. Guss,\n  Sharada P. Mohanty, Keisuke Nakata, Oriol Vinyals, Noboru Sean Kuno", "title": "Retrospective Analysis of the 2019 MineRL Competition on Sample\n  Efficient Reinforcement Learning", "comments": "To appear in Proceedings of Machine Learning Research: NeurIPS 2019\n  Competition & Demonstration Track Postproceedings. 12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate research in the direction of sample efficient reinforcement\nlearning, we held the MineRL Competition on Sample Efficient Reinforcement\nLearning Using Human Priors at the Thirty-third Conference on Neural\nInformation Processing Systems (NeurIPS 2019). The primary goal of this\ncompetition was to promote the development of algorithms that use human\ndemonstrations alongside reinforcement learning to reduce the number of samples\nneeded to solve complex, hierarchical, and sparse environments. We describe the\ncompetition, outlining the primary challenge, the competition design, and the\nresources that we provided to the participants. We provide an overview of the\ntop solutions, each of which use deep reinforcement learning and/or imitation\nlearning. We also discuss the impact of our organizational decisions on the\ncompetition and future directions for improvement.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:39:52 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 03:03:17 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 17:06:17 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 16:54:23 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Houghton", "Brandon", ""], ["Guss", "William H.", ""], ["Mohanty", "Sharada P.", ""], ["Nakata", "Keisuke", ""], ["Vinyals", "Oriol", ""], ["Kuno", "Noboru Sean", ""]]}, {"id": "2003.05024", "submitter": "Sam Ganzfried", "authors": "Max Chiswick and Sam Ganzfried", "title": "Prediction of Bayesian Intervals for Tropical Storms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on recent research for prediction of hurricane trajectories using\nrecurrent neural networks (RNNs), we have developed improved methods and\ngeneralized the approach to predict Bayesian intervals in addition to simple\npoint estimates. Tropical storms are capable of causing severe damage, so\naccurately predicting their trajectories can bring significant benefits to\ncities and lives, especially as they grow more intense due to climate change\neffects. By implementing the Bayesian interval using dropout in an RNN, we\nimprove the actionability of the predictions, for example by estimating the\nareas to evacuate in the landfall region. We used an RNN to predict the\ntrajectory of the storms at 6-hour intervals. We used latitude, longitude,\nwindspeed, and pressure features from a Statistical Hurricane Intensity\nPrediction Scheme (SHIPS) dataset of about 500 tropical storms in the Atlantic\nOcean. Our results show how neural network dropout values affect predictions\nand intervals.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 22:31:58 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Chiswick", "Max", ""], ["Ganzfried", "Sam", ""]]}, {"id": "2003.05033", "submitter": "Michael Arbel", "authors": "Michael Arbel and Liang Zhou and Arthur Gretton", "title": "Generalized Energy Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Generalized Energy Based Model (GEBM) for generative\nmodelling. These models combine two trained components: a base distribution\n(generally an implicit model), which can learn the support of data with low\nintrinsic dimension in a high dimensional space; and an energy function, to\nrefine the probability mass on the learned support. Both the energy function\nand base jointly constitute the final model, unlike GANs, which retain only the\nbase distribution (the \"generator\"). GEBMs are trained by alternating between\nlearning the energy and the base. We show that both training stages are\nwell-defined: the energy is learned by maximising a generalized likelihood, and\nthe resulting energy-based loss provides informative gradients for learning the\nbase. Samples from the posterior on the latent space of the trained model can\nbe obtained via MCMC, thus finding regions in this space that produce better\nquality samples. Empirically, the GEBM samples on image-generation tasks are of\nmuch better quality than those from the learned generator alone, indicating\nthat all else being equal, the GEBM will outperform a GAN of the same\ncomplexity. When using normalizing flows as base measures, GEBMs succeed on\ndensity modelling tasks, returning comparable performance to direct maximum\nlikelihood of the same networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 23:22:09 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:12:48 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 15:08:00 GMT"}, {"version": "v4", "created": "Fri, 9 Oct 2020 20:57:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Arbel", "Michael", ""], ["Zhou", "Liang", ""], ["Gretton", "Arthur", ""]]}, {"id": "2003.05048", "submitter": "Songkai Xue", "authors": "Songkai Xue, Mikhail Yurochkin and Yuekai Sun", "title": "Auditing ML Models for Individual Bias and Unfairness", "comments": "In Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of auditing ML models for individual bias/unfairness. We\nformalize the task in an optimization problem and develop a suite of\ninferential tools for the optimal value. Our tools permit us to obtain\nasymptotic confidence intervals and hypothesis tests that cover the\ntarget/control the Type I error rate exactly. To demonstrate the utility of our\ntools, we use them to reveal the gender and racial biases in Northpointe's\nCOMPAS recidivism prediction instrument.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 00:35:57 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Xue", "Songkai", ""], ["Yurochkin", "Mikhail", ""], ["Sun", "Yuekai", ""]]}, {"id": "2003.05063", "submitter": "Sara Morsy", "authors": "Sara Morsy and George Karypis", "title": "Context-aware Non-linear and Neural Attentive Knowledge-based Models for\n  Grade Prediction", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.11858", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grade prediction for future courses not yet taken by students is important as\nit can help them and their advisers during the process of course selection as\nwell as for designing personalized degree plans and modifying them based on\ntheir performance. One of the successful approaches for accurately predicting a\nstudent's grades in future courses is Cumulative Knowledge-based Regression\nModels (CKRM). CKRM learns shallow linear models that predict a student's\ngrades as the similarity between his/her knowledge state and the target course.\nHowever, prior courses taken by a student can have \\black{different\ncontributions when estimating a student's knowledge state and towards each\ntarget course, which} cannot be captured by linear models. Moreover, CKRM and\nother grade prediction methods ignore the effect of concurrently-taken courses\non a student's performance in a target course. In this paper, we propose\ncontext-aware non-linear and neural attentive models that can potentially\nbetter estimate a student's knowledge state from his/her prior course\ninformation, as well as model the interactions between a target course and\nconcurrent courses. Compared to the competing methods, our experiments on a\nlarge real-world dataset consisting of more than $1.5$M grades show the\neffectiveness of the proposed models in accurately predicting students' grades.\nMoreover, the attention weights learned by the neural attentive model can be\nhelpful in better designing their degree plans.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:20:48 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Morsy", "Sara", ""], ["Karypis", "George", ""]]}, {"id": "2003.05070", "submitter": "Ali Anaissi", "authors": "Ali Anaissi, Seid Miad Zandavi", "title": "Multi-Objective Variational Autoencoder: an Application for Smart\n  Infrastructure Maintenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-way data analysis has become an essential tool for capturing underlying\nstructures in higher-order data sets where standard two-way analysis techniques\noften fail to discover the hidden correlations between variables in multi-way\ndata. We propose a multi-objective variational autoencoder (MVA) method for\nsmart infrastructure damage detection and diagnosis in multi-way sensing data\nbased on the reconstruction probability of autoencoder deep neural network\n(ADNN). Our method fuses data from multiple sensors in one ADNN at which\ninformative features are being extracted and utilized for damage\nidentification. It generates probabilistic anomaly scores to detect damage,\nasses its severity and further localize it via a new localization layer\nintroduced in the ADNN.\n  We evaluated our method on multi-way datasets in the area of structural\nhealth monitoring for damage diagnosis purposes. The data was collected from\nour deployed data acquisition system on a cable-stayed bridge in Western Sydney\nand from a laboratory based building structure obtained from Los Alamos\nNational Laboratory (LANL). Experimental results show that the proposed method\ncan accurately detect structural damage. It was also able to estimate the\ndifferent levels of damage severity, and capture damage locations in an\nunsupervised aspect. Compared to the state-of-the-art approaches, our proposed\nmethod shows better performance in terms of damage detection and localization.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 01:30:08 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Anaissi", "Ali", ""], ["Zandavi", "Seid Miad", ""]]}, {"id": "2003.05101", "submitter": "Beheshteh Toloueirakhshan", "authors": "Beheshteh T. Rakhshan and Guillaume Rabusseau", "title": "Tensorized Random Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel random projection technique for efficiently reducing the\ndimension of very high-dimensional tensors. Building upon classical results on\nGaussian random projections and Johnson-Lindenstrauss transforms~(JLT), we\npropose two tensorized random projection maps relying on the tensor train~(TT)\nand CP decomposition format, respectively. The two maps offer very low memory\nrequirements and can be applied efficiently when the inputs are low rank\ntensors given in the CP or TT format. Our theoretical analysis shows that the\ndense Gaussian matrix in JLT can be replaced by a low-rank tensor implicitly\nrepresented in compressed form with random factors, while still approximately\npreserving the Euclidean distance of the projected inputs. In addition, our\nresults reveal that the TT format is substantially superior to CP in terms of\nthe size of the random projection needed to achieve the same distortion ratio.\nExperiments on synthetic data validate our theoretical analysis and demonstrate\nthe superiority of the TT decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 03:56:44 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Rakhshan", "Beheshteh T.", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2003.05103", "submitter": "Enrico Camporeale", "authors": "Enrico Camporeale and Algo Car\\`e", "title": "Estimation of Accurate and Calibrated Uncertainties in Deterministic\n  models", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.04475", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of assigning uncertainties to\nsingle-point predictions generated by a deterministic model that outputs a\ncontinuous variable. This problem applies to any state-of-the-art physics or\nengineering models that have a computational cost that does not readily allow\nto run ensembles and to estimate the uncertainty associated to single-point\npredictions. Essentially, we devise a method to easily transform a\ndeterministic prediction into a probabilistic one. We show that for doing so,\none has to compromise between the accuracy and the reliability (calibration) of\nsuch a probabilistic model. Hence, we introduce a cost function that encodes\ntheir trade-off. We use the Continuous Rank Probability Score to measure\naccuracy and we derive an analytic formula for the reliability, in the case of\nforecasts of continuous scalar variables expressed in terms of Gaussian\ndistributions. The new Accuracy-Reliability cost function is then used to\nestimate the input-dependent variance, given a black-box mean function, by\nsolving a two-objective optimization problem. The simple philosophy behind this\nstrategy is that predictions based on the estimated variances should not only\nbe accurate, but also reliable (i.e. statistical consistent with observations).\nConversely, early works based on the minimization of classical cost functions,\nsuch as the negative log probability density, cannot simultaneously enforce\nboth accuracy and reliability. We show several examples both with synthetic\ndata, where the underlying hidden noise can accurately be recovered, and with\nlarge real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 04:02:56 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Camporeale", "Enrico", ""], ["Car\u00e8", "Algo", ""]]}, {"id": "2003.05107", "submitter": "Dimitrios Boursinos", "authors": "Dimitrios Boursinos and Xenofon Koutsoukos", "title": "Trusted Confidence Bounds for Learning Enabled Cyber-Physical Systems", "comments": "Accepted at the Workshop on Assured Autonomous Systems at the IEEE\n  Symposium on Security and Privacy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) can benefit by the use of learning enabled\ncomponents (LECs) such as deep neural networks (DNNs) for perception and\ndecision making tasks. However, DNNs are typically non-transparent making\nreasoning about their predictions very difficult, and hence their application\nto safety-critical systems is very challenging. LECs could be integrated easier\ninto CPS if their predictions could be complemented with a confidence measure\nthat quantifies how much we trust their output. The paper presents an approach\nfor computing confidence bounds based on Inductive Conformal Prediction (ICP).\nWe train a Triplet Network architecture to learn representations of the input\ndata that can be used to estimate the similarity between test examples and\nexamples in the training data set. Then, these representations are used to\nestimate the confidence of set predictions from a classifier that is based on\nthe neural network architecture used in the triplet. The approach is evaluated\nusing a robotic navigation benchmark and the results show that we can computed\ntrusted confidence bounds efficiently in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 04:31:10 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 05:55:12 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Boursinos", "Dimitrios", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2003.05148", "submitter": "Zhongzhi Yu", "authors": "Zhongzhi Yu, Yemin Shi, Tiejun Huang, Yizhou Yu", "title": "Kernel Quantization for Efficient Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel network compression framework Kernel Quantization\n(KQ), targeting to efficiently convert any pre-trained full-precision\nconvolutional neural network (CNN) model into a low-precision version without\nsignificant performance loss. Unlike existing methods struggling with weight\nbit-length, KQ has the potential in improving the compression ratio by\nconsidering the convolution kernel as the quantization unit. Inspired by the\nevolution from weight pruning to filter pruning, we propose to quantize in both\nkernel and weight level. Instead of representing each weight parameter with a\nlow-bit index, we learn a kernel codebook and replace all kernels in the\nconvolution layer with corresponding low-bit indexes. Thus, KQ can represent\nthe weight tensor in the convolution layer with low-bit indexes and a kernel\ncodebook with limited size, which enables KQ to achieve significant compression\nratio. Then, we conduct a 6-bit parameter quantization on the kernel codebook\nto further reduce redundancy. Extensive experiments on the ImageNet\nclassification task prove that KQ needs 1.05 and 1.62 bits on average in VGG\nand ResNet18, respectively, to represent each parameter in the convolution\nlayer and achieves the state-of-the-art compression ratio with little accuracy\nloss.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:00:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Yu", "Zhongzhi", ""], ["Shi", "Yemin", ""], ["Huang", "Tiejun", ""], ["Yu", "Yizhou", ""]]}, {"id": "2003.05155", "submitter": "Thanh Binh Bui", "authors": "Stefan Studer, Thanh Binh Bui, Christian Drescher, Alexander\n  Hanuschkin, Ludwig Winkler, Steven Peters, Klaus-Robert Mueller", "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality\n  Assurance Methodology", "comments": "Machine Learning Applications, Quality Assurance Methodology, Process\n  Model, Best Practices for Machine Learning Applications, Automotive Industry\n  and Academia, Best Practices, Guidelines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is an established and frequently used technique in industry\nand academia but a standard process model to improve success and efficiency of\nmachine learning applications is still missing. Project organizations and\nmachine learning practitioners have a need for guidance throughout the life\ncycle of a machine learning application to meet business expectations. We\ntherefore propose a process model for the development of machine learning\napplications, that covers six phases from defining the scope to maintaining the\ndeployed machine learning application. The first phase combines business and\ndata understanding as data availability oftentimes affects the feasibility of\nthe project. The sixth phase covers state-of-the-art approaches for monitoring\nand maintenance of a machine learning applications, as the risk of model\ndegradation in a changing environment is eminent. With each task of the\nprocess, we propose quality assurance methodology that is suitable to adress\nchallenges in machine learning development that we identify in form of risks.\nThe methodology is drawn from practical experience and scientific literature\nand has proven to be general and stable. The process model expands on CRISP-DM,\na data mining process model that enjoys strong industry support but lacks to\naddress machine learning specific tasks. Our work proposes an industry and\napplication neutral process model tailored for machine learning applications\nwith focus on technical tasks for quality assurance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:25:49 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 14:33:24 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Studer", "Stefan", ""], ["Bui", "Thanh Binh", ""], ["Drescher", "Christian", ""], ["Hanuschkin", "Alexander", ""], ["Winkler", "Ludwig", ""], ["Peters", "Steven", ""], ["Mueller", "Klaus-Robert", ""]]}, {"id": "2003.05164", "submitter": "Naeem Paeedeh", "authors": "Naeem Paeedeh, Kamaledin Ghiasi-Shirazi", "title": "Improving the Backpropagation Algorithm with Consequentialism Weight\n  Updates over Mini-Batches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many attempts took place to improve the adaptive filters that can also be\nuseful to improve backpropagation (BP). Normalized least mean squares (NLMS) is\none of the most successful algorithms derived from Least mean squares (LMS).\nHowever, its extension to multi-layer neural networks has not happened before.\nHere, we first show that it is possible to consider a multi-layer neural\nnetwork as a stack of adaptive filters. Additionally, we introduce more\ncomprehensible interpretations of NLMS than the complicated geometric\ninterpretation in affine projection algorithm (APA) for a single\nfully-connected (FC) layer that can easily be generalized to, for instance,\nconvolutional neural networks and also works better with mini-batch training.\nWith this new viewpoint, we introduce a better algorithm by predicting then\nemending the adverse consequences of the actions that take place in BP even\nbefore they happen. Finally, the proposed method is compatible with stochastic\ngradient descent (SGD) and applicable to momentum-based derivatives such as\nRMSProp, Adam, and NAG. Our experiments show the usefulness of our algorithm in\nthe training of deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:45:36 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 03:41:00 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Paeedeh", "Naeem", ""], ["Ghiasi-Shirazi", "Kamaledin", ""]]}, {"id": "2003.05169", "submitter": "Thomas Lartigue", "authors": "Thomas Lartigue (ARAMIS, CMAP), Simona Bottani (ARAMIS), Stephanie\n  Baron (HEGP), Olivier Colliot (ARAMIS), Stanley Durrleman (ARAMIS),\n  St\\'ephanie Allassonni\\`ere (CRC (UMR\\_S\\_1138 / U1138))", "title": "Gaussian Graphical Model exploration and selection in high dimension low\n  sample size setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Graphical Models (GGM) are often used to describe the conditional\ncorrelations between the components of a random vector. In this article, we\ncompare two families of GGM inference methods: nodewise edge selection and\npenalised likelihood maximisation. We demonstrate on synthetic data that, when\nthe sample size is small, the two methods produce graphs with either too few or\ntoo many edges when compared to the real one. As a result, we propose a\ncomposite procedure that explores a family of graphs with an nodewise numerical\nscheme and selects a candidate among them with an overall likelihood criterion.\nWe demonstrate that, when the number of observations is small, this selection\nmethod yields graphs closer to the truth and corresponding to distributions\nwith better KL divergence with regards to the real distribution than the other\ntwo. Finally, we show the interest of our algorithm on two concrete cases:\nfirst on brain imaging data, then on biological nephrology data. In both cases\nour results are more in line with current knowledge in each field.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:00:52 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Lartigue", "Thomas", "", "ARAMIS, CMAP"], ["Bottani", "Simona", "", "ARAMIS"], ["Baron", "Stephanie", "", "HEGP"], ["Colliot", "Olivier", "", "ARAMIS"], ["Durrleman", "Stanley", "", "ARAMIS"], ["Allassonni\u00e8re", "St\u00e9phanie", "", "CRC"]]}, {"id": "2003.05174", "submitter": "Renyuan Xu", "authors": "Jose Blanchet, Renyuan Xu and Zhengyuan Zhou", "title": "Delay-Adaptive Learning in Generalized Linear Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we consider online learning in generalized linear contextual\nbandits where rewards are not immediately observed. Instead, rewards are\navailable to the decision-maker only after some delay, which is unknown and\nstochastic. We study the performance of two well-known algorithms adapted to\nthis delayed setting: one based on upper confidence bounds, and the other based\non Thompson sampling. We describe modifications on how these two algorithms\nshould be adapted to handle delays and give regret characterizations for both\nalgorithms. Our results contribute to the broad landscape of contextual bandits\nliterature by establishing that both algorithms can be made to be robust to\ndelays, thereby helping clarify and reaffirm the empirical success of these two\nalgorithms, which are widely deployed in modern recommendation engines.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:12:44 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Blanchet", "Jose", ""], ["Xu", "Renyuan", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2003.05189", "submitter": "Dexiong Chen", "authors": "Dexiong Chen, Laurent Jacob, Julien Mairal", "title": "Convolutional Kernel Networks for Graph-Structured Data", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML), Jul 2020", "doi": null, "report-no": "hal-02151135", "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a family of multilayer graph kernels and establish new links\nbetween graph convolutional neural networks and kernel methods. Our approach\ngeneralizes convolutional kernel networks to graph-structured data, by\nrepresenting graphs as a sequence of kernel feature maps, where each node\ncarries information about local graph substructures. On the one hand, the\nkernel point of view offers an unsupervised, expressive, and easy-to-regularize\ndata representation, which is useful when limited samples are available. On the\nother hand, our model can also be trained end-to-end on large-scale data,\nleading to new types of graph convolutional neural networks. We show that our\nmethod achieves competitive performance on several graph classification\nbenchmarks, while offering simple model interpretation. Our code is freely\navailable at https://github.com/claying/GCKN.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:44:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 08:46:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chen", "Dexiong", ""], ["Jacob", "Laurent", ""], ["Mairal", "Julien", ""]]}, {"id": "2003.05198", "submitter": "Chaochao Chen", "authors": "Longfei Zheng, Chaochao Chen, Yingting Liu, Bingzhe Wu, Xibin Wu, Li\n  Wang, Lei Wang, Jun Zhou, Shuang Yang", "title": "Industrial Scale Privacy Preserving Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) has been showing great potential in kinds of\nreal-world applications such as fraud detection and distress prediction.\nMeanwhile, data isolation has become a serious problem currently, i.e.,\ndifferent parties cannot share data with each other. To solve this issue, most\nresearch leverages cryptographic techniques to train secure DNN models for\nmulti-parties without compromising their private data. Although such methods\nhave strong security guarantee, they are difficult to scale to deep networks\nand large datasets due to its high communication and computation complexities.\nTo solve the scalability of the existing secure Deep Neural Network (DNN) in\ndata isolation scenarios, in this paper, we propose an industrial scale privacy\npreserving neural network learning paradigm, which is secure against\nsemi-honest adversaries. Our main idea is to split the computation graph of DNN\ninto two parts, i.e., the computations related to private data are performed by\neach party using cryptographic techniques, and the rest computations are done\nby a neutral server with high computation ability. We also present a defender\nmechanism for further privacy protection. We conduct experiments on real-world\nfraud detection dataset and financial distress prediction dataset, the\nencouraging results demonstrate the practicalness of our proposal.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:15:37 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 05:42:35 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zheng", "Longfei", ""], ["Chen", "Chaochao", ""], ["Liu", "Yingting", ""], ["Wu", "Bingzhe", ""], ["Wu", "Xibin", ""], ["Wang", "Li", ""], ["Wang", "Lei", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""]]}, {"id": "2003.05252", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Coordinate-wise Armijo's condition: General case", "comments": "6 pages. Preprint arXiv:1911.07820 is incorporated as a very special\n  case", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $z=(x,y)$ be coordinates for the product space $\\mathbb{R}^{m_1}\\times\n\\mathbb{R}^{m_2}$. Let $f:\\mathbb{R}^{m_1}\\times \\mathbb{R}^{m_2}\\rightarrow\n\\mathbb{R}$ be a $C^1$ function, and $\\nabla f=(\\partial _xf,\\partial _yf)$ its\ngradient. Fix $0<\\alpha <1$. For a point $(x,y) \\in \\mathbb{R}^{m_1}\\times\n\\mathbb{R}^{m_2}$, a number $\\delta >0$ satisfies Armijo's condition at $(x,y)$\nif the following inequality holds: \\begin{eqnarray*} f(x-\\delta \\partial\n_xf,y-\\delta \\partial _yf)-f(x,y)\\leq -\\alpha \\delta (||\\partial\n_xf||^2+||\\partial _yf||^2). \\end{eqnarray*}\n  In one previous paper, we proposed the following {\\bf coordinate-wise}\nArmijo's condition. Fix again $0<\\alpha <1$. A pair of positive numbers $\\delta\n_1,\\delta _2>0$ satisfies the coordinate-wise variant of Armijo's condition at\n$(x,y)$ if the following inequality holds: \\begin{eqnarray*} [f(x-\\delta\n_1\\partial _xf(x,y), y-\\delta _2\\partial _y f(x,y))]-[f(x,y)]\\leq -\\alpha\n(\\delta _1||\\partial _xf(x,y)||^2+\\delta _2||\\partial _yf(x,y)||^2).\n\\end{eqnarray*} Previously we applied this condition for functions of the form\n$f(x,y)=f(x)+g(y)$, and proved various convergent results for them. For a\ngeneral function, it is crucial - for being able to do real computations - to\nhave a systematic algorithm for obtaining $\\delta _1$ and $\\delta _2$\nsatisfying the coordinate-wise version of Armijo's condition, much like\nBacktracking for the usual Armijo's condition. In this paper we propose such an\nalgorithm, and prove according convergent results.\n  We then analyse and present experimental results for some functions such as\n$f(x,y)=a|x|+y$ (given by Asl and Overton in connection to Wolfe's method),\n$f(x,y)=x^3 sin (1/x) + y^3 sin(1/y)$ and Rosenbrock's function.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:17:05 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2003.05271", "submitter": "Talgat Daulbaev", "authors": "Talgat Daulbaev and Alexandr Katrutsa and Larisa Markeeva and Julia\n  Gusak and Andrzej Cichocki and Ivan Oseledets", "title": "Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple interpolation-based method for the efficient\napproximation of gradients in neural ODE models. We compare it with the reverse\ndynamic method (known in the literature as \"adjoint method\") to train neural\nODEs on classification, density estimation, and inference approximation tasks.\nWe also propose a theoretical justification of our approach using logarithmic\nnorm formalism. As a result, our method allows faster model training than the\nreverse dynamic method that was confirmed and validated by extensive numerical\nexperiments for several standard benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 13:15:57 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 21:44:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Daulbaev", "Talgat", ""], ["Katrutsa", "Alexandr", ""], ["Markeeva", "Larisa", ""], ["Gusak", "Julia", ""], ["Cichocki", "Andrzej", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2003.05285", "submitter": "Nadav Shalit", "authors": "Nadav Shalit, Michael Fire and Eran Ben Elia", "title": "Imputing Missing Boarding Stations With Machine Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in population densities and environmental awareness, public\ntransport has become an important aspect of urban life. Consequently, large\nquantities of transportation data are generated, and mining data from smart\ncard use has become a standardized method to understand the travel habits of\npassengers. Public transport datasets, however, often may lack data integrity;\nboarding stop information may be missing due to either imperfect acquirement\nprocesses or inadequate reporting. As a result, large quantities of\nobservations and even complete sections of cities might be absent from the\nsmart card database. We have developed a machine (supervised) learning method\nto impute missing boarding stops based on ordinal classification. In addition,\nwe present a new metric, Pareto Accuracy, to evaluate algorithms where classes\nhave an ordinal nature. Results are based on a case study in the Israeli city\nof Beer Sheva for one month of data. We show that our proposed method\nsignificantly notably outperforms current imputation methods and can improve\nthe accuracy and usefulness of large-scale transportation data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:07:39 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shalit", "Nadav", ""], ["Fire", "Michael", ""], ["Elia", "Eran Ben", ""]]}, {"id": "2003.05303", "submitter": "Lucia Cavallaro", "authors": "Lucia Cavallaro, Annamaria Ficara, Pasquale De Meo, Giacomo Fiumara,\n  Salvatore Catanese, Ovidiu Bagdasar and Antonio Liotta", "title": "Disrupting Resilient Criminal Networks through Data Analysis: The case\n  of Sicilian Mafia", "comments": "12 pages, 4 figures, paper submitted to PLOS ONE Journal", "journal-ref": "PLoS ONE 15(8): e0236476 (2020)", "doi": "10.1371/journal.pone.0236476", "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to other types of social networks, criminal networks present hard\nchallenges, due to their strong resilience to disruption, which poses severe\nhurdles to law-enforcement agencies. Herein, we borrow methods and tools from\nSocial Network Analysis to (i) unveil the structure of Sicilian Mafia gangs,\nbased on two real-world datasets, and (ii) gain insights as to how to\nefficiently disrupt them. Mafia networks have peculiar features, due to the\nlinks distribution and strength, which makes them very different from other\nsocial networks, and extremely robust to exogenous perturbations. Analysts are\nalso faced with the difficulty in collecting reliable datasets that accurately\ndescribe the gangs' internal structure and their relationships with the\nexternal world, which is why earlier studies are largely qualitative, elusive\nand incomplete. An added value of our work is the generation of two real-world\ndatasets, based on raw data derived from juridical acts, relating to a Mafia\norganization that operated in Sicily during the first decade of 2000s. We\ncreated two different networks, capturing phone calls and physical meetings,\nrespectively. Our network disruption analysis simulated different intervention\nprocedures: (i) arresting one criminal at a time (sequential node removal); and\n(ii) police raids (node block removal). We measured the effectiveness of each\napproach through a number of network centrality metrics. We found Betweeness\nCentrality to be the most effective metric, showing how, by neutralizing only\nthe 5% of the affiliates, network connectivity dropped by 70%. We also\nidentified that, due the peculiar type of interactions in criminal networks\n(namely, the distribution of the interactions frequency) no significant\ndifferences exist between weighted and unweighted network analysis. Our work\nhas significant practical applications for tackling criminal and terrorist\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:42:59 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Cavallaro", "Lucia", ""], ["Ficara", "Annamaria", ""], ["De Meo", "Pasquale", ""], ["Fiumara", "Giacomo", ""], ["Catanese", "Salvatore", ""], ["Bagdasar", "Ovidiu", ""], ["Liotta", "Antonio", ""]]}, {"id": "2003.05325", "submitter": "Ferran Alet", "authors": "Ferran Alet, Martin F. Schneider, Tomas Lozano-Perez, Leslie Pack\n  Kaelbling", "title": "Meta-learning curiosity algorithms", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We hypothesize that curiosity is a mechanism found by evolution that\nencourages meaningful exploration early in an agent's life in order to expose\nit to experiences that enable it to obtain high rewards over the course of its\nlifetime. We formulate the problem of generating curious behavior as one of\nmeta-learning: an outer loop will search over a space of curiosity mechanisms\nthat dynamically adapt the agent's reward signal, and an inner loop will\nperform standard reinforcement learning using the adapted reward signal.\nHowever, current meta-RL methods based on transferring neural network weights\nhave only generalized between very similar tasks. To broaden the\ngeneralization, we instead propose to meta-learn algorithms: pieces of code\nsimilar to those designed by humans in ML papers. Our rich language of programs\ncombines neural networks with other building blocks such as buffers,\nnearest-neighbor modules and custom loss functions. We demonstrate the\neffectiveness of the approach empirically, finding two novel curiosity\nalgorithms that perform on par or better than human-designed published\ncuriosity algorithms in domains as disparate as grid navigation with image\ninputs, acrobot, lunar lander, ant and hopper.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:25:43 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Alet", "Ferran", ""], ["Schneider", "Martin F.", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "2003.05330", "submitter": "James Hickey", "authors": "James M. Hickey, Pietro G. Di Stefano and Vlasios Vasileiou", "title": "Fairness by Explicability and Adversarial SHAP Learning", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to understand and trust the fairness of model predictions,\nparticularly when considering the outcomes of unprivileged groups, is critical\nto the deployment and adoption of machine learning systems. SHAP values provide\na unified framework for interpreting model predictions and feature attribution\nbut do not address the problem of fairness directly. In this work, we propose a\nnew definition of fairness that emphasises the role of an external auditor and\nmodel explicability. To satisfy this definition, we develop a framework for\nmitigating model bias using regularizations constructed from the SHAP values of\nan adversarial surrogate model. We focus on the binary classification task with\na single unprivileged group and link our fairness explicability constraints to\nclassical statistical fairness metrics. We demonstrate our approaches using\ngradient and adaptive boosting on: a synthetic dataset, the UCI Adult (Census)\ndataset and a real-world credit scoring dataset. The models produced were\nfairer and performant.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:36:34 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 13:36:06 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 08:28:06 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Hickey", "James M.", ""], ["Di Stefano", "Pietro G.", ""], ["Vasileiou", "Vlasios", ""]]}, {"id": "2003.05334", "submitter": "Wei Zhou", "authors": "Wei Zhou, Yiying Li, Yongxin Yang, Huaimin Wang, Timothy M. Hospedales", "title": "Online Meta-Critic Learning for Off-Policy Actor-Critic Methods", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-Policy Actor-Critic (Off-PAC) methods have proven successful in a variety\nof continuous control tasks. Normally, the critic's action-value function is\nupdated using temporal-difference, and the critic in turn provides a loss for\nthe actor that trains it to take actions with higher expected return. In this\npaper, we introduce a novel and flexible meta-critic that observes the learning\nprocess and meta-learns an additional loss for the actor that accelerates and\nimproves actor-critic learning. Compared to the vanilla critic, the meta-critic\nnetwork is explicitly trained to accelerate the learning process; and compared\nto existing meta-learning algorithms, meta-critic is rapidly learned online for\na single task, rather than slowly over a family of tasks. Crucially, our\nmeta-critic framework is designed for off-policy based learners, which\ncurrently provide state-of-the-art reinforcement learning sample efficiency. We\ndemonstrate that online meta-critic learning leads to improvements in avariety\nof continuous control environments when combined with contemporary Off-PAC\nmethods DDPG, TD3 and the state-of-the-art SAC.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:39:49 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 04:53:38 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Wei", ""], ["Li", "Yiying", ""], ["Yang", "Yongxin", ""], ["Wang", "Huaimin", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "2003.05377", "submitter": "Raul Lima", "authors": "Raul de Ara\\'ujo Lima, R\\^omulo C\\'esar Costa de Sousa, Simone Diniz\n  Junqueira Barbosa, H\\'elio Cort\\^es Vieira Lopes", "title": "Brazilian Lyrics-Based Music Genre Classification Using a BLSTM Network", "comments": "7 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organize songs, albums, and artists in groups with shared similarity could be\ndone with the help of genre labels. In this paper, we present a novel approach\nfor automatic classifying musical genre in Brazilian music using only the song\nlyrics. This kind of classification remains a challenge in the field of Natural\nLanguage Processing. We construct a dataset of 138,368 Brazilian song lyrics\ndistributed in 14 genres. We apply SVM, Random Forest and a Bidirectional Long\nShort-Term Memory (BLSTM) network combined with different word embeddings\ntechniques to address this classification task. Our experiments show that the\nBLSTM method outperforms the other models with an F1-score average of $0.48$.\nSome genres like \"gospel\", \"funk-carioca\" and \"sertanejo\", which obtained 0.89,\n0.70 and 0.69 of F1-score, respectively, can be defined as the most distinct\nand easy to classify in the Brazilian musical genres context.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:39:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lima", "Raul de Ara\u00fajo", ""], ["de Sousa", "R\u00f4mulo C\u00e9sar Costa", ""], ["Barbosa", "Simone Diniz Junqueira", ""], ["Lopes", "H\u00e9lio Cort\u00eas Vieira", ""]]}, {"id": "2003.05402", "submitter": "Boxin Zhao", "authors": "Boxin Zhao, Y. Samuel Wang, Mladen Kolar", "title": "FuDGE: Functional Differential Graph Estimation with fully and\n  discretely observed curves", "comments": "84 pages, 5 figures, submitted to JMLR. arXiv admin note: text\n  overlap with arXiv:1910.09701", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the difference between two functional\nundirected graphical models with shared structures. In many applications, data\nare naturally regarded as high-dimensional random function vectors rather than\nmultivariate scalars. For example, electroencephalography (EEG) data are more\nappropriately treated as functions of time. In these problems, not only can the\nnumber of functions measured per sample be large, but each function is itself\nan infinite dimensional object, making estimation of model parameters\nchallenging. In practice, curves are usually discretely observed, which makes\ngraph structure recovery even more challenging. We formally characterize when\ntwo functional graphical models are comparable and propose a method that\ndirectly estimates the functional differential graph, which we term FuDGE.\nFuDGE avoids separate estimation of each graph, which allows for estimation in\nproblems where individual graphs are dense, but their difference is sparse. We\nshow that FuDGE consistently estimates the functional differential graph in a\nhigh-dimensional setting for both discretely observed and fully observed\nfunction paths. We illustrate finite sample properties of our method through\nsimulation studies. In order to demonstrate the benefits of our method, we\npropose Joint Functional Graphical Lasso as a competitor, which is a\ngeneralization of the Joint Graphical Lasso. Finally, we apply our method to\nEEG data to uncover differences in functional brain connectivity between\nalcoholics and control subjects.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 16:47:22 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 02:43:27 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Zhao", "Boxin", ""], ["Wang", "Y. Samuel", ""], ["Kolar", "Mladen", ""]]}, {"id": "2003.05405", "submitter": "Arthur Mensch", "authors": "Kamalaker Dadi (PARIETAL), Ga\\\"el Varoquaux (PARIETAL), Antonia\n  Machlouzarides-Shalit (PARIETAL), Krzysztof J. Gorgolewski, Demian Wassermann\n  (PARIETAL), Bertrand Thirion (PARIETAL), Arthur Mensch (DMA, PARIETAL)", "title": "Fine-grain atlases of functional modes for fMRI analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population imaging markedly increased the size of functional-imaging\ndatasets, shedding new light on the neural basis of inter-individual\ndifferences. Analyzing these large data entails new scalability challenges,\ncomputational and statistical. For this reason, brain images are typically\nsummarized in a few signals, for instance reducing voxel-level measures with\nbrain atlases or functional modes. A good choice of the corresponding brain\nnetworks is important, as most data analyses start from these reduced signals.\nWe contribute finely-resolved atlases of functional modes, comprising from 64\nto 1024 networks. These dictionaries of functional modes (DiFuMo) are trained\non millions of fMRI functional brain volumes of total size 2.4TB, spanned over\n27 studies and many research groups. We demonstrate the benefits of extracting\nreduced signals on our fine-grain atlases for many classic functional data\nanalysis pipelines: stimuli decoding from 12,334 brain responses, standard GLM\nanalysis of fMRI across sessions and individuals, extraction of resting-state\nfunctional-connectomes biomarkers for 2,500 individuals, data compression and\nmeta-analysis over more than 15,000 statistical maps. In each of these analysis\nscenarii, we compare the performance of our functional atlases with that of\nother popular references, and to a simple voxel-level analysis. Results\nhighlight the importance of using high-dimensional \"soft\" functional atlases,\nto represent and analyse brain activity while capturing its functional\ngradients. Analyses on high-dimensional modes achieve similar statistical\nperformance as at the voxel level, but with much reduced computational cost and\nhigher interpretability. In addition to making them available, we provide\nmeaningful names for these modes, based on their anatomical location. It will\nfacilitate reporting of results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:04:12 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Dadi", "Kamalaker", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"], ["Machlouzarides-Shalit", "Antonia", "", "PARIETAL"], ["Gorgolewski", "Krzysztof J.", "", "PARIETAL"], ["Wassermann", "Demian", "", "PARIETAL"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Mensch", "Arthur", "", "DMA, PARIETAL"]]}, {"id": "2003.05417", "submitter": "Jenny Zukerman", "authors": "Jenny Zukerman, Tom Tirer, Raja Giryes", "title": "BP-DIP: A Backprojection based Deep Image Prior", "comments": "Accepted to EUSIPCO 2020. Link to code:\n  https://github.com/jennyzu/BP-DIP-deblurring. 5 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are a very powerful tool for many computer vision tasks,\nincluding image restoration, exhibiting state-of-the-art results. However, the\nperformance of deep learning methods tends to drop once the observation model\nused in training mismatches the one in test time. In addition, most deep\nlearning methods require vast amounts of training data, which are not\naccessible in many applications. To mitigate these disadvantages, we propose to\ncombine two image restoration approaches: (i) Deep Image Prior (DIP), which\ntrains a convolutional neural network (CNN) from scratch in test time using the\ngiven degraded image. It does not require any training data and builds on the\nimplicit prior imposed by the CNN architecture; and (ii) a backprojection (BP)\nfidelity term, which is an alternative to the standard least squares loss that\nis usually used in previous DIP works. We demonstrate the performance of the\nproposed method, termed BP-DIP, on the deblurring task and show its advantages\nover the plain DIP, with both higher PSNR values and better inference run-time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 17:09:12 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:01:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zukerman", "Jenny", ""], ["Tirer", "Tom", ""], ["Giryes", "Raja", ""]]}, {"id": "2003.05425", "submitter": "Pim de Haan", "authors": "Pim de Haan, Maurice Weiler, Taco Cohen and Max Welling", "title": "Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric\n  graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common approach to define convolutions on meshes is to interpret them as a\ngraph and apply graph convolutional networks (GCNs). Such GCNs utilize\nisotropic kernels and are therefore insensitive to the relative orientation of\nvertices and thus to the geometry of the mesh as a whole. We propose Gauge\nEquivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge\nequivariant kernels. Since the resulting features carry orientation\ninformation, we introduce a geometric message passing scheme defined by\nparallel transporting features over mesh edges. Our experiments validate the\nsignificantly improved expressivity of the proposed model over conventional\nGCNs and other methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 17:21:15 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["de Haan", "Pim", ""], ["Weiler", "Maurice", ""], ["Cohen", "Taco", ""], ["Welling", "Max", ""]]}, {"id": "2003.05431", "submitter": "Gr\\'egoire Montavon", "authors": "Oliver Eberle, Jochen B\\\"uttner, Florian Kr\\\"autli, Klaus-Robert\n  M\\\"uller, Matteo Valleriani, Gr\\'egoire Montavon", "title": "Building and Interpreting Deep Similarity Models", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3020738", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning algorithms such as kernel machines, nearest neighbors,\nclustering, or anomaly detection, are based on the concept of 'distance' or\n'similarity'. Before similarities are used for training an actual machine\nlearning model, we would like to verify that they are bound to meaningful\npatterns in the data. In this paper, we propose to make similarities\ninterpretable by augmenting them with an explanation in terms of input\nfeatures. We develop BiLRP, a scalable and theoretically founded method to\nsystematically decompose similarity scores on pairs of input features. Our\nmethod can be expressed as a composition of LRP explanations, which were shown\nin previous works to scale to highly nonlinear functions. Through an extensive\nset of experiments, we demonstrate that BiLRP robustly explains complex\nsimilarity models, e.g. built on VGG-16 deep neural network features.\nAdditionally, we apply our method to an open problem in digital humanities:\ndetailed assessment of similarity between historical documents such as\nastronomical tables. Here again, BiLRP provides insight and brings\nverifiability into a highly engineered and problem-specific similarity model.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 17:46:55 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Eberle", "Oliver", ""], ["B\u00fcttner", "Jochen", ""], ["Kr\u00e4utli", "Florian", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Valleriani", "Matteo", ""], ["Montavon", "Gr\u00e9goire", ""]]}, {"id": "2003.05436", "submitter": "Wilson Yan", "authors": "Wilson Yan, Ashwin Vangipuram, Pieter Abbeel, Lerrel Pinto", "title": "Learning Predictive Representations for Deformable Objects Using\n  Contrastive Estimation", "comments": "Project website:\n  https://sites.google.com/view/contrastive-predictive-model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using visual model-based learning for deformable object manipulation is\nchallenging due to difficulties in learning plannable visual representations\nalong with complex dynamic models. In this work, we propose a new learning\nframework that jointly optimizes both the visual representation model and the\ndynamics model using contrastive estimation. Using simulation data collected by\nrandomly perturbing deformable objects on a table, we learn latent dynamics\nmodels for these objects in an offline fashion. Then, using the learned models,\nwe use simple model-based planning to solve challenging deformable object\nmanipulation tasks such as spreading ropes and cloths. Experimentally, we show\nsubstantial improvements in performance over standard model-based learning\ntechniques across our rope and cloth manipulation suite. Finally, we transfer\nour visual manipulation policies trained on data purely collected in simulation\nto a real PR2 robot through domain randomization.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 17:55:15 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Yan", "Wilson", ""], ["Vangipuram", "Ashwin", ""], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2003.05482", "submitter": "Sudeep Salgia", "authors": "Sudeep Salgia, Qing Zhao, Sattar Vakili", "title": "Stochastic Coordinate Minimization with Progressive Precision for\n  Stochastic Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework based on iterative coordinate minimization (CM) is developed for\nstochastic convex optimization. Given that exact coordinate minimization is\nimpossible due to the unknown stochastic nature of the objective function, the\ncrux of the proposed optimization algorithm is an optimal control of the\nminimization precision in each iteration. We establish the optimal precision\ncontrol and the resulting order-optimal regret performance for strongly convex\nand separably nonsmooth functions. An interesting finding is that the optimal\nprogression of precision across iterations is independent of the\nlow-dimensional CM routine employed, suggesting a general framework for\nextending low-dimensional optimization routines to high-dimensional problems.\nThe proposed algorithm is amenable to online implementation and inherits the\nscalability and parallelizability properties of CM for large-scale\noptimization. Requiring only a sublinear order of message exchanges, it also\nlends itself well to distributed computing as compared with the alternative\napproach of coordinate gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 18:42:40 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Salgia", "Sudeep", ""], ["Zhao", "Qing", ""], ["Vakili", "Sattar", ""]]}, {"id": "2003.05508", "submitter": "Yiping Lu", "authors": "Yiping Lu, Chao Ma, Yulong Lu, Jianfeng Lu, Lexing Ying", "title": "A Mean-field Analysis of Deep ResNet and Beyond: Towards Provable\n  Optimization Via Overparameterization From Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks with stochastic gradient descent (SGD) can\noften achieve zero training loss on real-world tasks although the optimization\nlandscape is known to be highly non-convex. To understand the success of SGD\nfor training deep neural networks, this work presents a mean-field analysis of\ndeep residual networks, based on a line of works that interpret the continuum\nlimit of the deep residual network as an ordinary differential equation when\nthe network capacity tends to infinity. Specifically, we propose a new\ncontinuum limit of deep residual networks, which enjoys a good landscape in the\nsense that every local minimizer is global. This characterization enables us to\nderive the first global convergence result for multilayer neural networks in\nthe mean-field regime. Furthermore, without assuming the convexity of the loss\nlandscape, our proof relies on a zero-loss assumption at the global minimizer\nthat can be achieved when the model shares a universal approximation property.\nKey to our result is the observation that a deep residual network resembles a\nshallow network ensemble, i.e. a two-layer network. We bound the difference\nbetween the shallow network and our ResNet model via the adjoint sensitivity\nmethod, which enables us to apply existing mean-field analyses of two-layer\nnetworks to deep networks. Furthermore, we propose several novel training\nschemes based on the new continuous model, including one training procedure\nthat switches the order of the residual blocks and results in strong empirical\nperformance on the benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 20:14:47 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 19:10:15 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Lu", "Yiping", ""], ["Ma", "Chao", ""], ["Lu", "Yulong", ""], ["Lu", "Jianfeng", ""], ["Ying", "Lexing", ""]]}, {"id": "2003.05551", "submitter": "Michael Kellman", "authors": "Michael Kellman, Kevin Zhang, Jon Tamir, Emrah Bostan, Michael Lustig,\n  Laura Waller", "title": "Memory-efficient Learning for Large-scale Computational Imaging", "comments": "9 pages, 8 figures. See also relate NeurIPS 2019 presentation\n  arXiv:1912.05098", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical aspects of computational imaging systems, such as experimental\ndesign and image priors, can be optimized through deep networks formed by the\nunrolled iterations of classical model-based reconstructions (termed\nphysics-based networks). However, for real-world large-scale inverse problems,\ncomputing gradients via backpropagation is infeasible due to memory limitations\nof graphics processing units. In this work, we propose a memory-efficient\nlearning procedure that exploits the reversibility of the network's layers to\nenable data-driven design for large-scale computational imaging systems. We\ndemonstrate our method on a small-scale compressed sensing example, as well as\ntwo large-scale real-world systems: multi-channel magnetic resonance imaging\nand super-resolution optical microscopy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:08:04 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kellman", "Michael", ""], ["Zhang", "Kevin", ""], ["Tamir", "Jon", ""], ["Bostan", "Emrah", ""], ["Lustig", "Michael", ""], ["Waller", "Laura", ""]]}, {"id": "2003.05554", "submitter": "Jackson Loper", "authors": "Jackson Loper, David Blei, John P. Cunningham, and Liam Paninski", "title": "Linear-time inference for Gaussian Processes on one dimension", "comments": "New experiments about importance of rank, Q", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) provide powerful probabilistic frameworks for\ninterpolation, forecasting, and smoothing, but have been hampered by\ncomputational scaling issues. Here we investigate data sampled on one dimension\n(e.g., a scalar or vector time series sampled at arbitrarily-spaced intervals),\nfor which state-space models are popular due to their linearly-scaling\ncomputational costs. It has long been conjectured that state-space models are\ngeneral, able to approximate any one-dimensional GP. We provide the first\ngeneral proof of this conjecture, showing that any stationary GP on one\ndimension with vector-valued observations governed by a Lebesgue-integrable\ncontinuous kernel can be approximated to any desired precision using a\nspecifically-chosen state-space model: the Latent Exponentially Generated (LEG)\nfamily. This new family offers several advantages compared to the general\nstate-space model: it is always stable (no unbounded growth), the covariance\ncan be computed in closed form, and its parameter space is unconstrained\n(allowing straightforward estimation via gradient descent). The theorem's proof\nalso draws connections to Spectral Mixture Kernels, providing insight about\nthis popular family of kernels. We develop parallelized algorithms for\nperforming inference and learning in the LEG model, test the algorithm on real\nand synthetic data, and demonstrate scaling to datasets with billions of\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:20:13 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 17:37:20 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 19:37:58 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 14:13:49 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Loper", "Jackson", ""], ["Blei", "David", ""], ["Cunningham", "John P.", ""], ["Paninski", "Liam", ""]]}, {"id": "2003.05555", "submitter": "Vaneet Aggarwal", "authors": "Qinbo Bai and Vaneet Aggarwal and Ather Gattami", "title": "Provably Efficient Model-Free Algorithm for MDPs with Peak Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the optimization of dynamic systems, the variables typically have\nconstraints. Such problems can be modeled as a Constrained Markov Decision\nProcess (CMDP). This paper considers the peak constraints, where the agent\nchooses the policy to maximize the long-term average reward as well as\nsatisfies the constraints at each time. We propose a model-free algorithm that\nconverts CMDP problem to an unconstrained problem and a Q-learning based\napproach is used. We extend the concept of probably approximately correct (PAC)\nto define a criterion of $\\epsilon$-optimal policy. The proposed algorithm is\nproved to achieve an $\\epsilon$-optimal policy with probability at least $1-p$\nwhen the episode $K\\geq\\Omega(\\frac{I^2H^6SA\\ell}{\\epsilon^2})$, where $S$ and\n$A$ is the number of states and actions, respectively, $H$ is the number of\nsteps per episode, $I$ is the number of constraint functions, and\n$\\ell=\\log(\\frac{SAT}{p})$. We note that this is the first result on PAC kind\nof analysis for CMDP with peak constraints, where the transition probabilities\nare not known apriori. We demonstrate the proposed algorithm on an energy\nharvesting problem where it outperforms state-of-the-art and performs close to\nthe theoretical upper bound of the studied optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:23:29 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 20:33:30 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 22:30:59 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 01:58:47 GMT"}, {"version": "v5", "created": "Sat, 30 Jan 2021 21:05:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bai", "Qinbo", ""], ["Aggarwal", "Vaneet", ""], ["Gattami", "Ather", ""]]}, {"id": "2003.05602", "submitter": "Yuening Li", "authors": "Yuening Li, Daochen Zha, Praveen Kumar Venugopal, Na Zou, and Xia Hu", "title": "PyODDS: An End-to-end Outlier Detection System with Automated Machine\n  Learning", "comments": "In Companion Proceedings of the Web Conference 2020 (WWW 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is an important task for various data mining applications.\nCurrent outlier detection techniques are often manually designed for specific\ndomains, requiring large human efforts of database setup, algorithm selection,\nand hyper-parameter tuning. To fill this gap, we present PyODDS, an automated\nend-to-end Python system for Outlier Detection with Database Support, which\nautomatically optimizes an outlier detection pipeline for a new data source at\nhand. Specifically, we define the search space in the outlier detection\npipeline, and produce a search strategy within the given search space. PyODDS\nenables end-to-end executions based on an Apache Spark backend server and a\nlight-weight database. It also provides unified interfaces and visualizations\nfor users with or without data science or machine learning background. In\nparticular, we demonstrate PyODDS on several real-world datasets, with\nquantification analysis and visualization results.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 03:30:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Li", "Yuening", ""], ["Zha", "Daochen", ""], ["Venugopal", "Praveen Kumar", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "2003.05610", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Ziqi Liu, Peilin Zhao, Jun Zhou, Xiaolong Li", "title": "Privacy Preserving Point-of-interest Recommendation Using Decentralized\n  Matrix Factorization", "comments": "Accepted by AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Points of interest (POI) recommendation has been drawn much attention\nrecently due to the increasing popularity of location-based networks, e.g.,\nFoursquare and Yelp. Among the existing approaches to POI recommendation,\nMatrix Factorization (MF) based techniques have proven to be effective.\nHowever, existing MF approaches suffer from two major problems: (1) Expensive\ncomputations and storages due to the centralized model training mechanism: the\ncentralized learners have to maintain the whole user-item rating matrix, and\npotentially huge low rank matrices. (2) Privacy issues: the users' preferences\nare at risk of leaking to malicious attackers via the centralized learner. To\nsolve these, we present a Decentralized MF (DMF) framework for POI\nrecommendation. Specifically, instead of maintaining all the low rank matrices\nand sensitive rating data for training, we propose a random walk based\ndecentralized training technique to train MF models on each user's end, e.g.,\ncell phone and Pad. By doing so, the ratings of each user are still kept on\none's own hand, and moreover, decentralized learning can be taken as\ndistributed learning with multi-learners (users), and thus alleviates the\ncomputation and storage issue. Experimental results on two real-world datasets\ndemonstrate that, comparing with the classic and state-of-the-art latent factor\nmodels, DMF significantly improvements the recommendation performance in terms\nof precision and recall.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 04:08:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Chen", "Chaochao", ""], ["Liu", "Ziqi", ""], ["Zhao", "Peilin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "2003.05622", "submitter": "Ping Li", "authors": "Weijie Zhao, Deping Xie, Ronglai Jia, Yulei Qian, Ruiquan Ding,\n  Mingming Sun, Ping Li", "title": "Distributed Hierarchical GPU Parameter Server for Massive Scale Deep\n  Learning Ads Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks of ads systems usually take input from multiple resources,\ne.g., query-ad relevance, ad features and user portraits. These inputs are\nencoded into one-hot or multi-hot binary features, with typically only a tiny\nfraction of nonzero feature values per example. Deep learning models in online\nadvertising industries can have terabyte-scale parameters that do not fit in\nthe GPU memory nor the CPU main memory on a computing node. For example, a\nsponsored online advertising system can contain more than $10^{11}$ sparse\nfeatures, making the neural network a massive model with around 10 TB\nparameters. In this paper, we introduce a distributed GPU hierarchical\nparameter server for massive scale deep learning ads systems. We propose a\nhierarchical workflow that utilizes GPU High-Bandwidth Memory, CPU main memory\nand SSD as 3-layer hierarchical storage. All the neural network training\ncomputations are contained in GPUs. Extensive experiments on real-world data\nconfirm the effectiveness and the scalability of the proposed system. A 4-node\nhierarchical GPU parameter server can train a model more than 2X faster than a\n150-node in-memory distributed parameter server in an MPI cluster. In addition,\nthe price-performance ratio of our proposed system is 4-9 times better than an\nMPI-cluster solution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 05:15:48 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zhao", "Weijie", ""], ["Xie", "Deping", ""], ["Jia", "Ronglai", ""], ["Qian", "Yulei", ""], ["Ding", "Ruiquan", ""], ["Sun", "Mingming", ""], ["Li", "Ping", ""]]}, {"id": "2003.05623", "submitter": "Hongseok Namkoong", "authors": "Hongseok Namkoong, Ramtin Keramati, Steve Yadlowsky, Emma Brunskill", "title": "Off-policy Policy Evaluation For Sequential Decisions Under Unobserved\n  Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observed decisions depend only on observed features, off-policy policy\nevaluation (OPE) methods for sequential decision making problems can estimate\nthe performance of evaluation policies before deploying them. This assumption\nis frequently violated due to unobserved confounders, unrecorded variables that\nimpact both the decisions and their outcomes. We assess robustness of OPE\nmethods under unobserved confounding by developing worst-case bounds on the\nperformance of an evaluation policy. When unobserved confounders can affect\nevery decision in an episode, we demonstrate that even small amounts of\nper-decision confounding can heavily bias OPE methods. Fortunately, in a number\nof important settings found in healthcare, policy-making, operations, and\ntechnology, unobserved confounders may primarily affect only one of the many\ndecisions made. Under this less pessimistic model of one-decision confounding,\nwe propose an efficient loss-minimization-based procedure for computing\nworst-case bounds, and prove its statistical consistency. On two simulated\nhealthcare examples---management of sepsis patients and developmental\ninterventions for autistic children---where this is a reasonable model of\nconfounding, we demonstrate that our method invalidates non-robust results and\nprovides meaningful certificates of robustness, allowing reliable selection of\npolicies even under unobserved confounding.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 05:20:37 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Namkoong", "Hongseok", ""], ["Keramati", "Ramtin", ""], ["Yadlowsky", "Steve", ""], ["Brunskill", "Emma", ""]]}, {"id": "2003.05636", "submitter": "Yinghua Zhang", "authors": "Yinghua Zhang, Yu Zhang, Ying Wei, Kun Bai, Yangqiu Song, Qiang Yang", "title": "Fisher Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep domain adaptation models learn a neural network in an unlabeled target\ndomain by leveraging the knowledge from a labeled source domain. This can be\nachieved by learning a domain-invariant feature space. Though the learned\nrepresentations are separable in the source domain, they usually have a large\nvariance and samples with different class labels tend to overlap in the target\ndomain, which yields suboptimal adaptation performance. To fill the gap, a\nFisher loss is proposed to learn discriminative representations which are\nwithin-class compact and between-class separable. Experimental results on two\nbenchmark datasets show that the Fisher loss is a general and effective loss\nfor deep domain adaptation. Noticeable improvements are brought when it is used\ntogether with widely adopted transfer criteria, including MMD, CORAL and domain\nadversarial loss. For example, an absolute improvement of 6.67% in terms of the\nmean accuracy is attained when the Fisher loss is used together with the domain\nadversarial loss on the Office-Home dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 06:17:48 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zhang", "Yinghua", ""], ["Zhang", "Yu", ""], ["Wei", "Ying", ""], ["Bai", "Kun", ""], ["Song", "Yangqiu", ""], ["Yang", "Qiang", ""]]}, {"id": "2003.05649", "submitter": "Xiaoxi Zhang", "authors": "Xiaoxi Zhang, Jianyu Wang, Gauri Joshi, and Carlee Joe-Wong", "title": "Machine Learning on Volatile Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the massive size of the neural network models and training datasets\nused in machine learning today, it is imperative to distribute stochastic\ngradient descent (SGD) by splitting up tasks such as gradient evaluation across\nmultiple worker nodes. However, running distributed SGD can be prohibitively\nexpensive because it may require specialized computing resources such as GPUs\nfor extended periods of time. We propose cost-effective strategies to exploit\nvolatile cloud instances that are cheaper than standard instances, but may be\ninterrupted by higher priority workloads. To the best of our knowledge, this\nwork is the first to quantify how variations in the number of active worker\nnodes (as a result of preemption) affects SGD convergence and the time to train\nthe model. By understanding these trade-offs between preemption probability of\nthe instances, accuracy, and training time, we are able to derive practical\nstrategies for configuring distributed SGD jobs on volatile instances such as\nAmazon EC2 spot instances and other preemptible cloud instances. Experimental\nresults show that our strategies achieve good training performance at\nsubstantially lower cost.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 07:47:34 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zhang", "Xiaoxi", ""], ["Wang", "Jianyu", ""], ["Joshi", "Gauri", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "2003.05672", "submitter": "Steven Elsworth", "authors": "Steven Elsworth and Stefan G\\\"uttel", "title": "Time Series Forecasting Using LSTM Networks: A Symbolic Approach", "comments": "12 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods trained on raw numerical time series data exhibit\nfundamental limitations such as a high sensitivity to the hyper parameters and\neven to the initialization of random weights. A combination of a recurrent\nneural network with a dimension-reducing symbolic representation is proposed\nand applied for the purpose of time series forecasting. It is shown that the\nsymbolic representation can help to alleviate some of the aforementioned\nproblems and, in addition, might allow for faster training without sacrificing\nthe forecast performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 09:18:22 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Elsworth", "Steven", ""], ["G\u00fcttel", "Stefan", ""]]}, {"id": "2003.05689", "submitter": "Tong Yu", "authors": "Tong Yu and Hong Zhu", "title": "Hyper-Parameter Optimization: A Review of Algorithms and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since deep neural networks were developed, they have made huge contributions\nto everyday lives. Machine learning provides more rational advice than humans\nare capable of in almost every aspect of daily life. However, despite this\nachievement, the design and training of neural networks are still challenging\nand unpredictable procedures. To lower the technical thresholds for common\nusers, automated hyper-parameter optimization (HPO) has become a popular topic\nin both academic and industrial areas. This paper provides a review of the most\nessential topics on HPO. The first section introduces the key hyper-parameters\nrelated to model training and structure, and discusses their importance and\nmethods to define the value range. Then, the research focuses on major\noptimization algorithms and their applicability, covering their efficiency and\naccuracy especially for deep learning networks. This study next reviews major\nservices and toolkits for HPO, comparing their support for state-of-the-art\nsearching algorithms, feasibility with major deep learning frameworks, and\nextensibility for new modules designed by users. The paper concludes with\nproblems that exist when HPO is applied to deep learning, a comparison between\noptimization algorithms, and prominent approaches for model evaluation with\nlimited computational resources.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 10:12:22 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Yu", "Tong", ""], ["Zhu", "Hong", ""]]}, {"id": "2003.05703", "submitter": "Jonathan Peck", "authors": "Raaghavi Sivaguru, Jonathan Peck, Femi Olumofin, Anderson Nascimento\n  and Martine De Cock", "title": "Inline Detection of DGA Domains Using Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware applications typically use a command and control (C&C) server to\nmanage bots to perform malicious activities. Domain Generation Algorithms\n(DGAs) are popular methods for generating pseudo-random domain names that can\nbe used to establish a communication between an infected bot and the C&C\nserver. In recent years, machine learning based systems have been widely used\nto detect DGAs. There are several well known state-of-the-art classifiers in\nthe literature that can detect DGA domain names in real-time applications with\nhigh predictive performance. However, these DGA classifiers are highly\nvulnerable to adversarial attacks in which adversaries purposely craft domain\nnames to evade DGA detection classifiers. In our work, we focus on hardening\nDGA classifiers against adversarial attacks. To this end, we train and evaluate\nstate-of-the-art deep learning and random forest (RF) classifiers for DGA\ndetection using side information that is harder for adversaries to manipulate\nthan the domain name itself. Additionally, the side information features are\nselected such that they are easily obtainable in practice to perform inline DGA\ndetection. The performance and robustness of these models is assessed by\nexposing them to one day of real-traffic data as well as domains generated by\nadversarial attack algorithms. We found that the DGA classifiers that rely on\nboth the domain name and side information have high performance and are more\nrobust against adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 11:00:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Sivaguru", "Raaghavi", ""], ["Peck", "Jonathan", ""], ["Olumofin", "Femi", ""], ["Nascimento", "Anderson", ""], ["De Cock", "Martine", ""]]}, {"id": "2003.05729", "submitter": "Thiernithi Variddhisa\\\"i", "authors": "Thiernithi Variddhisai, Danilo Mandic", "title": "Methods of Adaptive Signal Processing on Graphs Using Vertex-Time\n  Autoregressive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of a random process has been recently extended to graph signals,\nwhereby random graph processes are a class of multivariate stochastic processes\nwhose coefficients are matrices with a \\textit{graph-topological} structure.\nThe system identification problem of a random graph process therefore revolves\naround determining its underlying topology, or mathematically, the graph shift\noperators (GSOs) i.e. an adjacency matrix or a Laplacian matrix. In the same\nwork that introduced random graph processes, a \\textit{batch} optimization\nmethod to solve for the GSO was also proposed for the random graph process\nbased on a \\textit{causal} vertex-time autoregressive model. To this end, the\nonline version of this optimization problem was proposed via the framework of\nadaptive filtering. The modified stochastic gradient projection method was\nemployed on the regularized least squares objective to create the filter. The\nrecursion is divided into 3 regularized sub-problems to address issues like\nmulti-convexity, sparsity, commutativity and bias. A discussion on convergence\nanalysis is also included. Finally, experiments are conducted to illustrate the\nperformance of the proposed algorithm, from traditional MSE measure to\nsuccessful recovery rate regardless correct values, all of which to shed light\non the potential, the limit and the possible research attempt of this work.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:42:27 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Variddhisai", "Thiernithi", ""], ["Mandic", "Danilo", ""]]}, {"id": "2003.05730", "submitter": "Jintang Li", "authors": "Liang Chen, Jintang Li, Jiaying Peng, Tao Xie, Zengxu Cao, Kun Xu,\n  Xiangnan He, Zibin Zheng", "title": "A Survey of Adversarial Learning on Graphs", "comments": "TKDD under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models on graphs have achieved remarkable performance in\nvarious graph analysis tasks, e.g., node classification, link prediction and\ngraph clustering. However, they expose uncertainty and unreliability against\nthe well-designed inputs, i.e., adversarial examples. Accordingly, a line of\nstudies have emerged for both attack and defense addressed in different graph\nanalysis tasks, leading to the arms race in graph adversarial learning.\n  Despite the booming works, there still lacks a unified problem definition and\na comprehensive review. To bridge this gap, we investigate and summarize the\nexisting works on graph adversarial learning tasks systemically. Specifically,\nwe survey and unify the existing works w.r.t. attack and defense in graph\nanalysis tasks, and give appropriate definitions and taxonomies at the same\ntime. Besides, we emphasize the importance of related evaluation metrics,\ninvestigate and summarize them comprehensively. Hopefully, our works can\nprovide a comprehensive overview and offer insights for the relevant\nresearchers. More details of our works are available at\nhttps://github.com/gitgiter/Graph-Adversarial-Learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 12:48:00 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 13:43:57 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Chen", "Liang", ""], ["Li", "Jintang", ""], ["Peng", "Jiaying", ""], ["Xie", "Tao", ""], ["Cao", "Zengxu", ""], ["Xu", "Kun", ""], ["He", "Xiangnan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2003.05731", "submitter": "Yue Zhao", "authors": "Yue Zhao, Xiyang Hu, Cheng Cheng, Cong Wang, Changlin Wan, Wen Wang,\n  Jianing Yang, Haoping Bai, Zheng Li, Cao Xiao, Yunlong Wang, Zhi Qiao, Jimeng\n  Sun, Leman Akoglu", "title": "SUOD: Accelerating Large-Scale Unsupervised Heterogeneous Outlier\n  Detection", "comments": "Proceedings of the 4th Conference on Machine Learning and Systems\n  (MLSys). The code is available at see http://github.com/yzhao062/SUOD. arXiv\n  admin note: text overlap with arXiv:2002.03222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection (OD) is a key machine learning (ML) task for identifying\nabnormal objects from general samples with numerous high-stake applications\nincluding fraud detection and intrusion detection. Due to the lack of ground\ntruth labels, practitioners often have to build a large number of unsupervised,\nheterogeneous models (i.e., different algorithms with varying hyperparameters)\nfor further combination and analysis, rather than relying on a single model.\nHow to accelerate the training and scoring on new-coming samples by\noutlyingness (referred as prediction throughout the paper) with a large number\nof unsupervised, heterogeneous OD models? In this study, we propose a modular\nacceleration system, called SUOD, to address it. The proposed system focuses on\nthree complementary acceleration aspects (data reduction for high-dimensional\ndata, approximation for costly models, and taskload imbalance optimization for\ndistributed environment), while maintaining performance accuracy. Extensive\nexperiments on more than 20 benchmark datasets demonstrate SUOD's effectiveness\nin heterogeneous OD acceleration, along with a real-world deployment case on\nfraudulent claim analysis at IQVIA, a leading healthcare firm. We open-source\nSUOD for reproducibility and accessibility.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 00:22:50 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 21:57:38 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 14:38:38 GMT"}, {"version": "v4", "created": "Fri, 5 Mar 2021 01:55:27 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhao", "Yue", ""], ["Hu", "Xiyang", ""], ["Cheng", "Cheng", ""], ["Wang", "Cong", ""], ["Wan", "Changlin", ""], ["Wang", "Wen", ""], ["Yang", "Jianing", ""], ["Bai", "Haoping", ""], ["Li", "Zheng", ""], ["Xiao", "Cao", ""], ["Wang", "Yunlong", ""], ["Qiao", "Zhi", ""], ["Sun", "Jimeng", ""], ["Akoglu", "Leman", ""]]}, {"id": "2003.05733", "submitter": "Bai Li", "authors": "Bai Li, Shiqi Wang, Yunhan Jia, Yantao Lu, Zhenyu Zhong, Lawrence\n  Carin, Suman Jana", "title": "Towards Practical Lottery Ticket Hypothesis for Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has proposed the lottery ticket hypothesis, suggesting that\nfor a deep neural network, there exist trainable sub-networks performing\nequally or better than the original model with commensurate training steps.\nWhile this discovery is insightful, finding proper sub-networks requires\niterative training and pruning. The high cost incurred limits the applications\nof the lottery ticket hypothesis. We show there exists a subset of the\naforementioned sub-networks that converge significantly faster during the\ntraining process and thus can mitigate the cost issue. We conduct extensive\nexperiments to show such sub-networks consistently exist across various model\nstructures for a restrictive setting of hyperparameters ($e.g.$, carefully\nselected learning rate, pruning ratio, and model capacity). As a practical\napplication of our findings, we demonstrate that such sub-networks can help in\ncutting down the total time of adversarial training, a standard approach to\nimprove robustness, by up to 49\\% on CIFAR-10 to achieve the state-of-the-art\nrobustness.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 03:11:52 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Li", "Bai", ""], ["Wang", "Shiqi", ""], ["Jia", "Yunhan", ""], ["Lu", "Yantao", ""], ["Zhong", "Zhenyu", ""], ["Carin", "Lawrence", ""], ["Jana", "Suman", ""]]}, {"id": "2003.05738", "submitter": "Fran\\c{c}ois-Xavier Devailly", "authors": "Fran\\c{c}ois-Xavier Devailly, Denis Larocque, Laurent Charlin", "title": "IG-RL: Inductive Graph Reinforcement Learning for Massive-Scale Traffic\n  Signal Control", "comments": "11 pages, 10 figures, 1 table. IEEE Transactions on Intelligent\n  Transportation Systems (2021)", "journal-ref": null, "doi": "10.1109/TITS.2021.3070835", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling adaptive traffic-signal control involves dealing with combinatorial\nstate and action spaces. Multi-agent reinforcement learning attempts to address\nthis challenge by distributing control to specialized agents. However,\nspecialization hinders generalization and transferability, and the\ncomputational graphs underlying neural-networks architectures -- dominating in\nthe multi-agent setting -- do not offer the flexibility to handle an arbitrary\nnumber of entities which changes both between road networks, and over time as\nvehicles traverse the network. We introduce Inductive Graph Reinforcement\nLearning (IG-RL) based on graph-convolutional networks which adapts to the\nstructure of any road network, to learn detailed representations of\ntraffic-controllers and their surroundings. Our decentralized approach enables\nlearning of a transferable-adaptive-traffic-signal-control policy. After being\ntrained on an arbitrary set of road networks, our model can generalize to new\nroad networks, traffic distributions, and traffic regimes, with no additional\ntraining and a constant number of parameters, enabling greater scalability\ncompared to prior methods. Furthermore, our approach can exploit the\ngranularity of available data by capturing the (dynamic) demand at both the\nlane and the vehicle levels. The proposed method is tested on both road\nnetworks and traffic settings never experienced during training. We compare\nIG-RL to multi-agent reinforcement learning and domain-specific baselines. In\nboth synthetic road networks and in a larger experiment involving the control\nof the 3,971 traffic signals of Manhattan, we show that different\ninstantiations of IG-RL outperform baselines.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 17:17:59 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 05:18:29 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 21:46:26 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 19:02:33 GMT"}, {"version": "v5", "created": "Mon, 21 Jun 2021 17:32:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Devailly", "Fran\u00e7ois-Xavier", ""], ["Larocque", "Denis", ""], ["Charlin", "Laurent", ""]]}, {"id": "2003.05740", "submitter": "Kenneth Leerbeck", "authors": "Kenneth Leerbeck and Peder Bacher and Rune Junker and Goran\n  Goranovi\\'c and Olivier Corradi and Razgar Ebrahimy and Anna Tveit and Henrik\n  Madsen", "title": "Short-Term Forecasting of CO2 Emission Intensity in Power Grids by\n  Machine Learning", "comments": "15 pages and 11 figures including appendix. Submitted to Applied\n  Energy (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning algorithm is developed to forecast the CO2 emission\nintensities in electrical power grids in the Danish bidding zone DK2,\ndistinguishing between average and marginal emissions. The analysis was done on\ndata set comprised of a large number (473) of explanatory variables such as\npower production, demand, import, weather conditions etc. collected from\nselected neighboring zones. The number was reduced to less than 50 using both\nLASSO (a penalized linear regression analysis) and a forward feature selection\nalgorithm. Three linear regression models that capture different aspects of the\ndata (non-linearities and coupling of variables etc.) were created and combined\ninto a final model using Softmax weighted average. Cross-validation is\nperformed for debiasing and autoregressive moving average model (ARIMA)\nimplemented to correct the residuals, making the final model the variant with\nexogenous inputs (ARIMAX). The forecasts with the corresponding uncertainties\nare given for two time horizons, below and above six hours. Marginal emissions\ncame up independent of any conditions in the DK2 zone, suggesting that the\nmarginal generators are located in the neighbouring zones.\n  The developed methodology can be applied to any bidding zone in the European\nelectricity network without requiring detailed knowledge about the zone.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 16:34:28 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Leerbeck", "Kenneth", ""], ["Bacher", "Peder", ""], ["Junker", "Rune", ""], ["Goranovi\u0107", "Goran", ""], ["Corradi", "Olivier", ""], ["Ebrahimy", "Razgar", ""], ["Tveit", "Anna", ""], ["Madsen", "Henrik", ""]]}, {"id": "2003.05744", "submitter": "Ilay Luz", "authors": "Ilay Luz, Meirav Galun, Haggai Maron, Ronen Basri, Irad Yavneh", "title": "Learning Algebraic Multigrid Using Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient numerical solvers for sparse linear systems are crucial in science\nand engineering. One of the fastest methods for solving large-scale sparse\nlinear systems is algebraic multigrid (AMG). The main challenge in the\nconstruction of AMG algorithms is the selection of the prolongation operator --\na problem-dependent sparse matrix which governs the multiscale hierarchy of the\nsolver and is critical to its efficiency. Over many years, numerous methods\nhave been developed for this task, and yet there is no known single right\nanswer except in very special cases. Here we propose a framework for learning\nAMG prolongation operators for linear systems with sparse symmetric positive\n(semi-) definite matrices. We train a single graph neural network to learn a\nmapping from an entire class of such matrices to prolongation operators, using\nan efficient unsupervised loss function. Experiments on a broad class of\nproblems demonstrate improved convergence rates compared to classical AMG,\ndemonstrating the potential utility of neural networks for developing sparse\nsystem solvers.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 12:36:48 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 09:23:34 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Luz", "Ilay", ""], ["Galun", "Meirav", ""], ["Maron", "Haggai", ""], ["Basri", "Ronen", ""], ["Yavneh", "Irad", ""]]}, {"id": "2003.05747", "submitter": "Mathis Petrovich", "authors": "Mathis Petrovich and Makoto Yamada", "title": "Fast local linear regression with anchor regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression is an important task in machine learning and data mining. It has\nseveral applications in various domains, including finance, biomedical, and\ncomputer vision. Recently, network Lasso, which estimates local models by\nmaking clusters using the network information, was proposed and its superior\nperformance was demonstrated. In this study, we propose a simple yet effective\nlocal model training algorithm called the fast anchor regularized local linear\nmethod (FALL). More specifically, we train a local model for each sample by\nregularizing it with precomputed anchor models. The key advantage of the\nproposed algorithm is that we can obtain a closed-form solution with only\nmatrix multiplication; additionally, the proposed algorithm is easily\ninterpretable, fast to compute and parallelizable. Through experiments on\nsynthetic and real-world datasets, we demonstrate that FALL compares favorably\nin terms of accuracy with the state-of-the-art network Lasso algorithm with\nsignificantly smaller training time (two orders of magnitude).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:03:33 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Petrovich", "Mathis", ""], ["Yamada", "Makoto", ""]]}, {"id": "2003.05748", "submitter": "Sean Saito", "authors": "Sean Saito, Jin Wang", "title": "Explaining Away Attacks Against Neural Networks", "comments": "2 pages, 2 figures; Accepted at MLSys 2020 First Workshop on Secure\n  and Resilient Autonomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of identifying adversarial attacks on image-based\nneural networks. We present intriguing experimental results showing significant\ndiscrepancies between the explanations generated for the predictions of a model\non clean and adversarial data. Utilizing this intuition, we propose a framework\nwhich can identify whether a given input is adversarial based on the\nexplanations given by the model. Code for our experiments can be found here:\nhttps://github.com/seansaito/Explaining-Away-Attacks-Against-Neural-Networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:32:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Saito", "Sean", ""], ["Wang", "Jin", ""]]}, {"id": "2003.05776", "submitter": "Huitong Ding", "authors": "Ning An, Liuqi Jin, Huitong Ding, Jiaoyun Yang, Jing Yuan", "title": "A deep belief network-based method to identify proteomic risk markers\n  for Alzheimer disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a large body of research has formally identified apolipoprotein E\n(APOE) as a major genetic risk marker for Alzheimer disease, accumulating\nevidence supports the notion that other risk markers may exist. The traditional\nAlzheimer-specific signature analysis methods, however, have not been able to\nmake full use of rich protein expression data, especially the interaction\nbetween attributes. This paper develops a novel feature selection method to\nidentify pathogenic factors of Alzheimer disease using the proteomic and\nclinical data. This approach has taken the weights of network nodes as the\nimportance order of signaling protein expression values. After generating and\nevaluating the candidate subset, the method helps to select an optimal subset\nof proteins that achieved an accuracy greater than 90%, which is superior to\ntraditional machine learning methods for clinical Alzheimer disease diagnosis.\nBesides identifying a proteomic risk marker and further reinforce the link\nbetween metabolic risk factors and Alzheimer disease, this paper also suggests\nthat apidonectin-linked pathways are a possible therapeutic drug target.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:37:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["An", "Ning", ""], ["Jin", "Liuqi", ""], ["Ding", "Huitong", ""], ["Yang", "Jiaoyun", ""], ["Yuan", "Jing", ""]]}, {"id": "2003.05777", "submitter": "Ranjan Maitra", "authors": "Souradeep Chattopadhyay and Steven D. Kawaler and Ranjan Maitra", "title": "Multi-layered Characterisation of hot stellar systems with confidence", "comments": "10 pages; 7 figures; 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.GA astro-ph.SR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the physical and evolutionary properties of Hot Stellar Systems\n(HSS) is a major challenge in astronomy. We studied the dataset on 13456 HSS of\nMisgeld and Hilker (2011) that includes 12763 candidate globular clusters and\nfound multi-layered homogeneous grouping among these stellar systems. Our\nmethods elicited eight homogeneous ellipsoidal groups at the finest sub-group\nlevel. Some of these groups have high overlap and were merged through a\nmulti-phased syncytial algorithm motivated from Almod\\'ovar-Rivera and Maitra\n(2020). Five groups were merged in the first phase, resulting in three\ncomplex-structured groups. Our algorithm determined further complex structure\nand permitted one more merging phase, revealing two complex-structured groups\nat the highest level. A nonparametric bootstrap procedure found our group\nassignments to generally have high confidences in classification, indicating\nstability of our HSS assignments. The physical and kinematic properties of the\ntwo highest-level groups were assessed in terms of mass, effective radius,\nsurface density and mass-luminosity ratio. The first group consisted of older,\nsmaller and less bright HSS while the second group consisted of the brighter\nand younger HSS. Our analysis provides novel insight into the physical and\nevolutionary properties of HSS and specifically of %also helps to understand\nphysical and evolutionary properties of candidate globular clusters. Further,\nthe candidate globular clusters are seen to have very high probability of being\nglobular clusters rather than dwarfs or dwarf ellipticals that are also\nindicated to be quite distinct from each other.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 13:12:14 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 05:23:42 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2020 08:30:15 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Chattopadhyay", "Souradeep", ""], ["Kawaler", "Steven D.", ""], ["Maitra", "Ranjan", ""]]}, {"id": "2003.05783", "submitter": "Kimia Nadjahi", "authors": "Kimia Nadjahi, Alain Durmus, L\\'ena\\\"ic Chizat, Soheil Kolouri, Shahin\n  Shahrampour, Umut \\c{S}im\\c{s}ekli", "title": "Statistical and Topological Properties of Sliced Probability Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of slicing divergences has been proven to be successful when\ncomparing two probability measures in various machine learning applications\nincluding generative modeling, and consists in computing the expected value of\na `base divergence' between one-dimensional random projections of the two\nmeasures. However, the computational and statistical consequences of such a\ntechnique have not yet been well-established. In this paper, we aim at bridging\nthis gap and derive some properties of sliced divergence functions. First, we\nshow that slicing preserves the metric axioms and the weak continuity of the\ndivergence, implying that the sliced divergence will share similar topological\nproperties. We then precise the results in the case where the base divergence\nbelongs to the class of integral probability metrics. On the other hand, we\nestablish that, under mild conditions, the sample complexity of the sliced\ndivergence does not depend on the dimension, even when the base divergence\nsuffers from the curse of dimensionality. We finally apply our general results\nto the Wasserstein distance and Sinkhorn divergences, and illustrate our theory\non both synthetic and real data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 13:15:17 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Nadjahi", "Kimia", ""], ["Durmus", "Alain", ""], ["Chizat", "L\u00e9na\u00efc", ""], ["Kolouri", "Soheil", ""], ["Shahrampour", "Shahin", ""], ["\u015eim\u015fekli", "Umut", ""]]}, {"id": "2003.05822", "submitter": "Benjamin Miller", "authors": "Benjamin A. Miller and Mustafa \\c{C}amurcu and Alexander J. Gomez and\n  Kevin Chan and Tina Eliassi-Rad", "title": "Topological Effects on Attacks Against Vertex Classification", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex classification is vulnerable to perturbations of both graph topology\nand vertex attributes, as shown in recent research. As in other machine\nlearning domains, concerns about robustness to adversarial manipulation can\nprevent potential users from adopting proposed methods when the consequence of\naction is very high. This paper considers two topological characteristics of\ngraphs and explores the way these features affect the amount the adversary must\nperturb the graph in order to be successful. We show that, if certain vertices\nare included in the training set, it is possible to substantially an\nadversary's required perturbation budget. On four citation datasets, we\ndemonstrate that if the training set includes high degree vertices or vertices\nthat ensure all unlabeled nodes have neighbors in the training set, we show\nthat the adversary's budget often increases by a substantial factor---often a\nfactor of 2 or more---over random training for the Nettack poisoning attack.\nEven for especially easy targets (those that are misclassified after just one\nor two perturbations), the degradation of performance is much slower, assigning\nmuch lower probabilities to the incorrect classes. In addition, we demonstrate\nthat this robustness either persists when recently proposed defenses are\napplied, or is competitive with the resulting performance improvement for the\ndefender.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:37:57 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Miller", "Benjamin A.", ""], ["\u00c7amurcu", "Mustafa", ""], ["Gomez", "Alexander J.", ""], ["Chan", "Kevin", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "2003.05838", "submitter": "Geoffrey Chinot", "authors": "Geoffrey Chinot, Matthieu Lerasle", "title": "On the robustness of the minimum $\\ell_2$ interpolator", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the interpolator with minimal $\\ell_2$-norm $\\hat{\\beta}$ in a\ngeneral high dimensional linear regression framework where $\\mathbb Y=\\mathbb\nX\\beta^*+\\xi$ where $\\mathbb X$ is a random $n\\times p$ matrix with independent\n$\\mathcal N(0,\\Sigma)$ rows and without assumption on the noise vector $\\xi\\in\n\\mathbb R^n$. We prove that, with high probability, the prediction loss of this\nestimator is bounded from above by $(\\|\\beta^*\\|^2_2r_{cn}(\\Sigma)\\vee\n\\|\\xi\\|^2)/n$, where $r_{k}(\\Sigma)=\\sum_{i\\geq k}\\lambda_i(\\Sigma)$ are the\nrests of the sum of eigenvalues of $\\Sigma$. These bounds show a transition in\nthe rates. For high signal to noise ratios, the rates\n$\\|\\beta^*\\|^2_2r_{cn}(\\Sigma)/n$ broadly improve the existing ones. For low\nsignal to noise ratio, we also provide lower bound holding with large\nprobability. Under assumptions on the sprectrum of $\\Sigma$, this lower bound\nis of order $\\| \\xi\\|_2^2/n$, matching the upper bound. Consequently, in the\nlarge noise regime, we are able to precisely track the prediction error with\nlarge probability. This results give new insight when the interpolation can be\nharmless in high dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:12:28 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 13:48:18 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Chinot", "Geoffrey", ""], ["Lerasle", "Matthieu", ""]]}, {"id": "2003.05884", "submitter": "Evgeniy Golikov", "authors": "Eugene A. Golikov", "title": "Towards a General Theory of Infinite-Width Limits of Neural Classifiers", "comments": "27 pages, 7 figures, accepted to ICML'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining theoretical guarantees for neural networks training appears to be a\nhard problem in a general case. Recent research has been focused on studying\nthis problem in the limit of infinite width and two different theories have\nbeen developed: a mean-field (MF) and a constant kernel (NTK) limit theories.\nWe propose a general framework that provides a link between these seemingly\ndistinct theories. Our framework out of the box gives rise to a discrete-time\nMF limit which was not previously explored in the literature. We prove a\nconvergence theorem for it and show that it provides a more reasonable\napproximation for finite-width nets compared to the NTK limit if learning rates\nare not very small. Also, our framework suggests a limit model that coincides\nneither with the MF limit nor with the NTK one. We show that for networks with\nmore than two hidden layers RMSProp training has a non-trivial discrete-time MF\nlimit but GD training does not have one. Overall, our framework demonstrates\nthat both MF and NTK limits have considerable limitations in approximating\nfinite-sized neural nets, indicating the need for designing more accurate\ninfinite-width approximations for them.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 16:27:00 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 09:06:29 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 20:02:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Golikov", "Eugene A.", ""]]}, {"id": "2003.05926", "submitter": "Paul Scherer", "authors": "Paul Scherer, Pietro Lio", "title": "Learning distributed representations of graphs with Geo2DR", "comments": "9 Pages, Revised version accepted at ICML 2020 GRL+ Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Geo2DR (Geometric to Distributed Representations), a GPU ready\nPython library for unsupervised learning on graph-structured data using\ndiscrete substructure patterns and neural language models. It contains\nefficient implementations of popular graph decomposition algorithms and neural\nlanguage models in PyTorch which can be combined to learn representations of\ngraphs using the distributive hypothesis. Furthermore, Geo2DR comes with\ngeneral data processing and loading methods to bring substantial speed-up in\nthe training of the neural language models. Through this we provide a modular\nset of tools and methods to quickly construct systems capable of learning\ndistributed representations of graphs. This is useful for replication of\nexisting methods, modification, or development of completely new methods. This\npaper serves to present the Geo2DR library and perform a comprehensive\ncomparative analysis of existing methods re-implemented using Geo2DR across\nwidely used graph classification benchmarks. Geo2DR displays a high\nreproducibility of results in published methods and interoperability with other\nlibraries useful for distributive language modelling.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:49:15 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 21:12:50 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 15:37:59 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Scherer", "Paul", ""], ["Lio", "Pietro", ""]]}, {"id": "2003.05928", "submitter": "Sungho Shin", "authors": "Sungho Shin, Alex D. Smith, S. Joe Qin, Victor M. Zavala", "title": "On the Convergence of the Dynamic Inner PCA Algorithm", "comments": null, "journal-ref": "In Proceedings of Foundations of Process Analytics and Machine\n  Learning, 2019", "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic inner principal component analysis (DiPCA) is a powerful method for\nthe analysis of time-dependent multivariate data. DiPCA extracts dynamic latent\nvariables that capture the most dominant temporal trends by solving a\nlarge-scale, dense, and nonconvex nonlinear program (NLP). A scalable\ndecomposition algorithm has been recently proposed in the literature to solve\nthese challenging NLPs. The decomposition algorithm performs well in practice\nbut its convergence properties are not well understood. In this work, we show\nthat this algorithm is a specialized variant of a coordinate maximization\nalgorithm. This observation allows us to explain why the decomposition\nalgorithm might work (or not) in practice and can guide improvements. We\ncompare the performance of the decomposition strategies with that of the\noff-the-shelf solver Ipopt. The results show that decomposition is more\nscalable and, surprisingly, delivers higher quality solutions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:50:34 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Shin", "Sungho", ""], ["Smith", "Alex D.", ""], ["Qin", "S. Joe", ""], ["Zavala", "Victor M.", ""]]}, {"id": "2003.05955", "submitter": "Esther Rolf", "authors": "Esther Rolf, Michael I. Jordan, Benjamin Recht", "title": "Post-Estimation Smoothing: A Simple Baseline for Learning with Side\n  Information", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational data are often accompanied by natural structural indices, such\nas time stamps or geographic locations, which are meaningful to prediction\ntasks but are often discarded. We leverage semantically meaningful indexing\ndata while ensuring robustness to potentially uninformative or misleading\nindices. We propose a post-estimation smoothing operator as a fast and\neffective method for incorporating structural index data into prediction.\nBecause the smoothing step is separate from the original predictor, it applies\nto a broad class of machine learning tasks, with no need to retrain models. Our\ntheoretical analysis details simple conditions under which post-estimation\nsmoothing will improve accuracy over that of the original predictor. Our\nexperiments on large scale spatial and temporal datasets highlight the speed\nand accuracy of post-estimation smoothing in practice. Together, these results\nilluminate a novel way to consider and incorporate the natural structure of\nindex variables in machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 18:04:20 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Rolf", "Esther", ""], ["Jordan", "Michael I.", ""], ["Recht", "Benjamin", ""]]}, {"id": "2003.05989", "submitter": "Mahlagha Sedghi", "authors": "Mahlagha Sedghi, George Atia, Michael Georgiopoulos", "title": "A Multi-criteria Approach for Fast and Outlier-aware Representative\n  Selection from Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of representative selection amounts to sampling few informative\nexemplars from large datasets. This paper presents MOSAIC, a novel\nrepresentative selection approach from high-dimensional data that may exhibit\nnon-linear structures. Resting upon a novel quadratic formulation, Our method\nadvances a multi-criteria selection approach that maximizes the global\nrepresentation power of the sampled subset, ensures diversity, and rejects\ndisruptive information by effectively detecting outliers. Through theoretical\nanalyses we characterize the obtained sketch and reveal that the sampled\nrepresentatives maximize a well-defined notion of data coverage in a\ntransformed space. In addition, we present a highly scalable randomized\nimplementation of the proposed algorithm shown to bring about substantial\nspeedups. MOSAIC's superiority in achieving the desired characteristics of a\nrepresentative subset all at once while exhibiting remarkable robustness to\nvarious outlier types is demonstrated via extensive experiments conducted on\nboth real and synthetic data with comparisons to state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:31:10 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Sedghi", "Mahlagha", ""], ["Atia", "George", ""], ["Georgiopoulos", "Michael", ""]]}, {"id": "2003.05990", "submitter": "Ranjan Maitra", "authors": "Karl T. Pazdernik and Ranjan Maitra", "title": "Estimating Basis Functions in Massive Fields under the Spatial Mixed\n  Effects Model", "comments": "21 pages, 18 figures, 7 tables", "journal-ref": null, "doi": "10.1002/SAM.11537", "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial prediction is commonly achieved under the assumption of a Gaussian\nrandom field (GRF) by obtaining maximum likelihood estimates of parameters, and\nthen using the kriging equations to arrive at predicted values. For massive\ndatasets, fixed rank kriging using the Expectation-Maximization (EM) algorithm\nfor estimation has been proposed as an alternative to the usual but\ncomputationally prohibitive kriging method. The method reduces computation cost\nof estimation by redefining the spatial process as a linear combination of\nbasis functions and spatial random effects. A disadvantage of this method is\nthat it imposes constraints on the relationship between the observed locations\nand the knots. We develop an alternative method that utilizes the Spatial Mixed\nEffects (SME) model, but allows for additional flexibility by estimating the\nrange of the spatial dependence between the observations and the knots via an\nAlternating Expectation Conditional Maximization (AECM) algorithm. Experiments\nshow that our methodology improves estimation without sacrificing prediction\naccuracy while also minimizing the additional computational burden of extra\nparameter estimation. The methodology is applied to a temperature data set\narchived by the United States National Climate Data Center, with improved\nresults over previous methodology.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:36:40 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pazdernik", "Karl T.", ""], ["Maitra", "Ranjan", ""]]}, {"id": "2003.05991", "submitter": "Dor Bank", "authors": "Dor Bank, Noam Koenigstein, Raja Giryes", "title": "Autoencoders", "comments": "Book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autoencoder is a specific type of a neural network, which is mainly\ndesigned to encode the input into a compressed and meaningful representation,\nand then decode it back such that the reconstructed input is similar as\npossible to the original one. This chapter surveys the different types of\nautoencoders that are mainly used today. It also describes various applications\nand use-cases of autoencoders.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:38:47 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 11:18:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Bank", "Dor", ""], ["Koenigstein", "Noam", ""], ["Giryes", "Raja", ""]]}, {"id": "2003.05996", "submitter": "Cuong Nguyen", "authors": "Cuong Q. Nguyen, Constantine Kreatsoulas, and Kim M. Branson", "title": "Meta-Learning GNN Initializations for Low-Resource Molecular Property\n  Prediction", "comments": "ICML 2020 Workshop on Graph Representation Learning and Beyond (GRL+)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Building in silico models to predict chemical properties and activities is a\ncrucial step in drug discovery. However, limited labeled data often hinders the\napplication of deep learning in this setting. Meanwhile advances in\nmeta-learning have enabled state-of-the-art performances in few-shot learning\nbenchmarks, naturally prompting the question: Can meta-learning improve deep\nlearning performance in low-resource drug discovery projects? In this work, we\nassess the transferability of graph neural networks initializations learned by\nthe Model-Agnostic Meta-Learning (MAML) algorithm - and its variants FO-MAML\nand ANIL - for chemical properties and activities tasks. Using the ChEMBL20\ndataset to emulate low-resource settings, our benchmark shows that\nmeta-initializations perform comparably to or outperform multi-task\npre-training baselines on 16 out of 20 in-distribution tasks and on all\nout-of-distribution tasks, providing an average improvement in AUPRC of 11.2%\nand 26.9% respectively. Finally, we observe that meta-initializations\nconsistently result in the best performing models across fine-tuning sets with\n$k \\in \\{16, 32, 64, 128, 256\\}$ instances.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:49:57 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:53:26 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Nguyen", "Cuong Q.", ""], ["Kreatsoulas", "Constantine", ""], ["Branson", "Kim M.", ""]]}, {"id": "2003.05997", "submitter": "Aurko Roy", "authors": "Aurko Roy, Mohammad Saffar, Ashish Vaswani and David Grangier", "title": "Efficient Content-Based Sparse Attention with Routing Transformers", "comments": "TACL 2020; pre-MIT Press publication version; v5 has a random\n  attention baseline", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention has recently been adopted for a wide range of sequence\nmodeling problems. Despite its effectiveness, self-attention suffers from\nquadratic compute and memory requirements with respect to sequence length.\nSuccessful approaches to reduce this complexity focused on attending to local\nsliding windows or a small set of locations independent of content. Our work\nproposes to learn dynamic sparse attention patterns that avoid allocating\ncomputation and memory to attend to content unrelated to the query of interest.\nThis work builds upon two lines of research: it combines the modeling\nflexibility of prior work on content-based sparse attention with the efficiency\ngains from approaches based on local, temporal sparse attention. Our model, the\nRouting Transformer, endows self-attention with a sparse routing module based\non online k-means while reducing the overall complexity of attention to\n$O\\left(n^{1.5}d\\right)$ from $O\\left(n^2d\\right)$ for sequence length $n$ and\nhidden dimension $d$. We show that our model outperforms comparable sparse\nattention models on language modeling on Wikitext-103 (15.8 vs 18.3 perplexity)\nas well as on image generation on ImageNet-64 (3.43 vs 3.44 bits/dim) while\nusing fewer self-attention layers. Additionally, we set a new state-of-the-art\non the newly released PG-19 data-set, obtaining a test perplexity of 33.2 with\na 22 layer Routing Transformer model trained on sequences of length 8192.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:50:14 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 19:22:32 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 17:29:51 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 02:42:17 GMT"}, {"version": "v5", "created": "Sat, 24 Oct 2020 19:41:17 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Roy", "Aurko", ""], ["Saffar", "Mohammad", ""], ["Vaswani", "Ashish", ""], ["Grangier", "David", ""]]}, {"id": "2003.05999", "submitter": "Sahin Lale", "authors": "Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, Anima Anandkumar", "title": "Adaptive Control and Regret Minimization in Linear Quadratic Gaussian\n  (LQG) Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of adaptive control in partially observable linear\nquadratic Gaussian control systems, where the model dynamics are unknown a\npriori. We propose LqgOpt, a novel reinforcement learning algorithm based on\nthe principle of optimism in the face of uncertainty, to effectively minimize\nthe overall control cost. We employ the predictor state evolution\nrepresentation of the system dynamics and deploy a recently proposed\nclosed-loop system identification method, estimation, and confidence bound\nconstruction. LqgOpt efficiently explores the system dynamics, estimates the\nmodel parameters up to their confidence interval, and deploys the controller of\nthe most optimistic model for further exploration and exploitation. We provide\nstability guarantees for LqgOpt and prove the regret upper bound of\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ for adaptive control of linear quadratic\nGaussian (LQG) systems, where $T$ is the time horizon of the problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:56:38 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 02:33:00 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Lale", "Sahin", ""], ["Azizzadenesheli", "Kamyar", ""], ["Hassibi", "Babak", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2003.06005", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Karthikeyan Natesan Ramamurthy, Bhanukiran Vinzamuri, Yunfeng Zhang,\n  Amit Dhurandhar", "title": "Model Agnostic Multilevel Explanations", "comments": "21 pages, 9 figures, 1 table", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, post-hoc local instance-level and global dataset-level\nexplainability of black-box models has received a lot of attention. Much less\nattention has been given to obtaining insights at intermediate or group levels,\nwhich is a need outlined in recent works that study the challenges in realizing\nthe guidelines in the General Data Protection Regulation (GDPR). In this paper,\nwe propose a meta-method that, given a typical local explainability method, can\nbuild a multilevel explanation tree. The leaves of this tree correspond to the\nlocal explanations, the root corresponds to the global explanation, and\nintermediate levels correspond to explanations for groups of data points that\nit automatically clusters. The method can also leverage side information, where\nusers can specify points for which they may want the explanations to be\nsimilar. We argue that such a multilevel structure can also be an effective\nform of communication, where one could obtain few explanations that\ncharacterize the entire dataset by considering an appropriate level in our\nexplanation tree. Explanations for novel test points can be cost-efficiently\nobtained by associating them with the closest training points. When the local\nexplainability technique is generalized additive (viz. LIME, GAMs), we develop\na fast approximate algorithm for building the multilevel tree and study its\nconvergence behavior. We validate the effectiveness of the proposed technique\nbased on two human studies -- one with experts and the other with non-expert\nusers -- on real world datasets, and show that we produce high fidelity sparse\nexplanations on several other public datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 20:18:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ramamurthy", "Karthikeyan Natesan", ""], ["Vinzamuri", "Bhanukiran", ""], ["Zhang", "Yunfeng", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2003.06016", "submitter": "Amy Zhang", "authors": "Amy Zhang, Clare Lyle, Shagun Sodhani, Angelos Filos, Marta\n  Kwiatkowska, Joelle Pineau, Yarin Gal, Doina Precup", "title": "Invariant Causal Prediction for Block MDPs", "comments": "Accepted to ICML 2020. 16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization across environments is critical to the successful application\nof reinforcement learning algorithms to real-world challenges. In this paper,\nwe consider the problem of learning abstractions that generalize in block MDPs,\nfamilies of environments with a shared latent state space and dynamics\nstructure over that latent space, but varying observations. We leverage tools\nfrom causal inference to propose a method of invariant prediction to learn\nmodel-irrelevance state abstractions (MISA) that generalize to novel\nobservations in the multi-environment setting. We prove that for certain\nclasses of environments, this approach outputs with high probability a state\nabstraction corresponding to the causal feature set with respect to the return.\nWe further provide more general bounds on model error and generalization error\nin the multi-environment setting, in the process showing a connection between\ncausal variable selection and the state abstraction framework for MDPs. We give\nempirical evidence that our methods work in both linear and nonlinear settings,\nattaining improved generalization over single- and multi-task baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 21:03:01 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 18:01:02 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Zhang", "Amy", ""], ["Lyle", "Clare", ""], ["Sodhani", "Shagun", ""], ["Filos", "Angelos", ""], ["Kwiatkowska", "Marta", ""], ["Pineau", "Joelle", ""], ["Gal", "Yarin", ""], ["Precup", "Doina", ""]]}, {"id": "2003.06048", "submitter": "Hermina Petric Maretic", "authors": "Hermina Petric Maretic, Mireille El Gheche, Matthias Minder, Giovanni\n  Chierchia, Pascal Frossard", "title": "Wasserstein-based Graph Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for comparing non-aligned graphs of different\nsizes, based on the Wasserstein distance between graph signal distributions\ninduced by the respective graph Laplacian matrices. Specifically, we cast a new\nformulation for the one-to-many graph alignment problem, which aims at matching\na node in the smaller graph with one or more nodes in the larger graph. By\nintegrating optimal transport in our graph comparison framework, we generate\nboth a structurally-meaningful graph distance, and a signal transportation plan\nthat models the structure of graph data. The resulting alignment problem is\nsolved with stochastic gradient descent, where we use a novel Dykstra operator\nto ensure that the solution is a one-to-many (soft) assignment matrix. We\ndemonstrate the performance of our novel framework on graph alignment and graph\nclassification, and we show that our method leads to significant improvements\nwith respect to the state-of-the-art algorithms for each of these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 22:31:59 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Maretic", "Hermina Petric", ""], ["Gheche", "Mireille El", ""], ["Minder", "Matthias", ""], ["Chierchia", "Giovanni", ""], ["Frossard", "Pascal", ""]]}, {"id": "2003.06050", "submitter": "Mandana Saebi", "authors": "Mandana Saebi, Steven Krieg, Chuxu Zhang, Meng Jiang, and Nitesh\n  Chawla", "title": "Heterogeneous Relational Reasoning in Knowledge Graphs with\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Path-based relational reasoning over knowledge graphs has become increasingly\npopular due to a variety of downstream applications such as question answering\nin dialogue systems, fact prediction, and recommender systems. In recent years,\nreinforcement learning (RL) has provided solutions that are more interpretable\nand explainable than other deep learning models. However, these solutions still\nface several challenges, including large action space for the RL agent and\naccurate representation of entity neighborhood structure. We address these\nproblems by introducing a type-enhanced RL agent that uses the local\nneighborhood information for efficient path-based reasoning over knowledge\ngraphs. Our solution uses graph neural network (GNN) for encoding the\nneighborhood information and utilizes entity types to prune the action space.\nExperiments on real-world dataset show that our method outperforms\nstate-of-the-art RL methods and discovers more novel paths during the training\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 22:39:58 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Saebi", "Mandana", ""], ["Krieg", "Steven", ""], ["Zhang", "Chuxu", ""], ["Jiang", "Meng", ""], ["Chawla", "Nitesh", ""]]}, {"id": "2003.06060", "submitter": "Ruixiang Zhang", "authors": "Tong Che, Ruixiang Zhang, Jascha Sohl-Dickstein, Hugo Larochelle, Liam\n  Paull, Yuan Cao, Yoshua Bengio", "title": "Your GAN is Secretly an Energy-based Model and You Should use\n  Discriminator Driven Latent Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the sum of the implicit generator log-density $\\log p_g$ of a\nGAN with the logit score of the discriminator defines an energy function which\nyields the true data density when the generator is imperfect but the\ndiscriminator is optimal, thus making it possible to improve on the typical\ngenerator (with implicit density $p_g$). To make that practical, we show that\nsampling from this modified density can be achieved by sampling in latent space\naccording to an energy-based model induced by the sum of the latent prior\nlog-density and the discriminator output score. This can be achieved by running\na Langevin MCMC in latent space and then applying the generator function, which\nwe call Discriminator Driven Latent Sampling~(DDLS). We show that DDLS is\nhighly efficient compared to previous methods which work in the\nhigh-dimensional pixel space and can be applied to improve on previously\ntrained GANs of many types. We evaluate DDLS on both synthetic and real-world\ndatasets qualitatively and quantitatively. On CIFAR-10, DDLS substantially\nimproves the Inception Score of an off-the-shelf pre-trained\nSN-GAN~\\citep{sngan} from $8.22$ to $9.09$ which is even comparable to the\nclass-conditional BigGAN~\\citep{biggan} model. This achieves a new\nstate-of-the-art in unconditional image synthesis setting without introducing\nextra parameters or additional training.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 23:33:50 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 03:31:07 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 17:57:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Che", "Tong", ""], ["Zhang", "Ruixiang", ""], ["Sohl-Dickstein", "Jascha", ""], ["Larochelle", "Hugo", ""], ["Paull", "Liam", ""], ["Cao", "Yuan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2003.06066", "submitter": "Christian Scheller", "authors": "Christian Scheller, Yanick Schraner and Manfred Vogel", "title": "Sample Efficient Reinforcement Learning through Learning from\n  Demonstrations in Minecraft", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample inefficiency of deep reinforcement learning methods is a major\nobstacle for their use in real-world applications. In this work, we show how\nhuman demonstrations can improve final performance of agents on the Minecraft\nminigame ObtainDiamond with only 8M frames of environment interaction. We\npropose a training procedure where policy networks are first trained on human\ndata and later fine-tuned by reinforcement learning. Using a policy\nexploitation mechanism, experience replay and an additional loss against\ncatastrophic forgetting, our best agent was able to achieve a mean score of 48.\nOur proposed solution placed 3rd in the NeurIPS MineRL Competition for\nSample-Efficient Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 23:46:16 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Scheller", "Christian", ""], ["Schraner", "Yanick", ""], ["Vogel", "Manfred", ""]]}, {"id": "2003.06069", "submitter": "Renyuan Xu", "authors": "Xin Guo, Anran Hu, Renyuan Xu and Junzi Zhang", "title": "A General Framework for Learning Mean-Field Games", "comments": "9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a general mean-field game (GMFG) framework for\nsimultaneous learning and decision-making in stochastic games with a large\npopulation. It first establishes the existence of a unique Nash Equilibrium to\nthis GMFG, and demonstrates that naively combining Q-learning with the\nfixed-point approach in classical MFGs yields unstable algorithms. It then\nproposes value-based and policy-based reinforcement learning algorithms (GMF-P\nand GMF-P respectively) with smoothed policies, with analysis of convergence\nproperty and computational complexity. The experiments on repeated Ad auction\nproblems demonstrate that GMF-V-Q, a specific GMF-V algorithm based on\nQ-learning, is efficient and robust in terms of convergence and learning\naccuracy. Moreover, its performance is superior in convergence, stability, and\nlearning ability, when compared with existing algorithms for multi-agent\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:27:57 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Guo", "Xin", ""], ["Hu", "Anran", ""], ["Xu", "Renyuan", ""], ["Zhang", "Junzi", ""]]}, {"id": "2003.06080", "submitter": "Barry Doyle", "authors": "Arjun Balaji, Lachlan Kelsey, Kamran Majeed, Carl Schultz, Barry Doyle", "title": "Coronary Artery Segmentation from Intravascular Optical Coherence\n  Tomography Using Deep Capsules", "comments": "This version has been accepted in Artificial Intelligence in\n  Medicine. Main paper: 28 pages, 9 figures, 4 tables. Supplementary Material:\n  3 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.artmed.2021.102072", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The segmentation and analysis of coronary arteries from intravascular optical\ncoherence tomography (IVOCT) is an important aspect of diagnosing and managing\ncoronary artery disease. Current image processing methods are hindered by the\ntime needed to generate expert-labelled datasets and the potential for bias\nduring the analysis. Therefore, automated, robust, unbiased and timely geometry\nextraction from IVOCT, using image processing, would be beneficial to\nclinicians. With clinical application in mind, we aim to develop a model with a\nsmall memory footprint that is fast at inference time without sacrificing\nsegmentation quality. Using a large IVOCT dataset of 12,011 expert-labelled\nimages from 22 patients, we construct a new deep learning method based on\ncapsules which automatically produces lumen segmentations. Our dataset contains\nimages with both blood and light artefacts (22.8%), as well as metallic (23.1%)\nand bioresorbable stents (2.5%). We split the dataset into a training (70%),\nvalidation (20%) and test (10%) set and rigorously investigate design\nvariations with respect to upsampling regimes and input selection. We show that\nour developments lead to a model, DeepCap, that is on par with state-of-the-art\nmachine learning methods in terms of segmentation quality and robustness, while\nusing as little as 12% of the parameters. This enables DeepCap to have per\nimage inference times up to 70% faster on GPU and up to 95% faster on CPU\ncompared to other state-of-the-art models. DeepCap is a robust automated\nsegmentation tool that can aid clinicians to extract unbiased geometrical data\nfrom IVOCT.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 01:37:45 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 01:49:52 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 05:33:35 GMT"}, {"version": "v4", "created": "Thu, 8 Apr 2021 03:02:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Balaji", "Arjun", ""], ["Kelsey", "Lachlan", ""], ["Majeed", "Kamran", ""], ["Schultz", "Carl", ""], ["Doyle", "Barry", ""]]}, {"id": "2003.06097", "submitter": "Liu Yang", "authors": "Liu Yang, Xuhui Meng, George Em Karniadakis", "title": "B-PINNs: Bayesian Physics-Informed Neural Networks for Forward and\n  Inverse PDE Problems with Noisy Data", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109913", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian physics-informed neural network (B-PINN) to solve both\nforward and inverse nonlinear problems described by partial differential\nequations (PDEs) and noisy data. In this Bayesian framework, the Bayesian\nneural network (BNN) combined with a PINN for PDEs serves as the prior while\nthe Hamiltonian Monte Carlo (HMC) or the variational inference (VI) could serve\nas an estimator of the posterior. B-PINNs make use of both physical laws and\nscattered noisy measurements to provide predictions and quantify the aleatoric\nuncertainty arising from the noisy data in the Bayesian framework. Compared\nwith PINNs, in addition to uncertainty quantification, B-PINNs obtain more\naccurate predictions in scenarios with large noise due to their capability of\navoiding overfitting. We conduct a systematic comparison between the two\ndifferent approaches for the B-PINN posterior estimation (i.e., HMC or VI),\nalong with dropout used for quantifying uncertainty in deep neural networks.\nOur experiments show that HMC is more suitable than VI for the B-PINNs\nposterior estimation, while dropout employed in PINNs can hardly provide\naccurate predictions with reasonable uncertainty. Finally, we replace the BNN\nin the prior with a truncated Karhunen-Lo\\`eve (KL) expansion combined with HMC\nor a deep normalizing flow (DNF) model as posterior estimators. The KL is as\naccurate as BNN and much faster but this framework cannot be easily extended to\nhigh-dimensional problems unlike the BNN based framework.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 04:00:42 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Yang", "Liu", ""], ["Meng", "Xuhui", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2003.06100", "submitter": "Xiaoming Liu", "authors": "Xiaoming Liu, Qirui Li, Chao Shen, Xi Peng, Yadong Zhou, Xiaohong Guan", "title": "Learning by Sampling and Compressing: Efficient Graph Representation\n  Learning with Extremely Limited Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution network (GCN) attracts intensive research interest with\nbroad applications. While existing work mainly focused on designing novel GCN\narchitectures for better performance, few of them studied a practical yet\nchallenging problem: How to learn GCNs from data with extremely limited\nannotation? In this paper, we propose a new learning method by sampling\nstrategy and model compression to overcome this challenge. Our approach has\nmultifold advantages: 1) the adaptive sampling strategy largely suppresses the\nGCN training deviation over uniform sampling; 2) compressed GCN-based methods\nwith a smaller scale of parameters need fewer labeled data to train; 3) the\nsmaller scale of training data is beneficial to reduce the human resource cost\nto label them. We choose six popular GCN baselines and conduct extensive\nexperiments on three real-world datasets. The results show that by applying our\nmethod, all GCN baselines cut down the annotation requirement by as much as\n90$\\%$ and compress the scale of parameters more than 6$\\times$ without\nsacrificing their strong performance. It verifies that the training method\ncould extend the existing semi-supervised GCN-based methods to the scenarios\nwith the extremely small scale of labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 04:11:41 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 09:34:57 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Liu", "Xiaoming", ""], ["Li", "Qirui", ""], ["Shen", "Chao", ""], ["Peng", "Xi", ""], ["Zhou", "Yadong", ""], ["Guan", "Xiaohong", ""]]}, {"id": "2003.06112", "submitter": "Linh Ngo", "authors": "Ngo Van Linh, Tran Xuan Bach and Khoat Than", "title": "A Graph Convolutional Topic Model for Short and Noisy Text Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning hidden topics from data streams has become absolutely necessary but\nposed challenging problems such as concept drift as well as short and noisy\ndata. Using prior knowledge to enrich a topic model is one of potential\nsolutions to cope with these challenges. Prior knowledge that is derived from\nhuman knowledge (e.g. Wordnet) or a pre-trained model (e.g. Word2vec) is very\nvaluable and useful to help topic models work better. However, in a streaming\nenvironment where data arrives continually and infinitely, existing studies are\nlimited to exploiting these resources effectively. Especially, a knowledge\ngraph, that contains meaningful word relations, is ignored. In this paper, to\naim at exploiting a knowledge graph effectively, we propose a novel graph\nconvolutional topic model (GCTM) which integrates graph convolutional networks\n(GCN) into a topic model and a learning method which learns the networks and\nthe topic model simultaneously for data streams. In each minibatch, our method\nnot only can exploit an external knowledge graph but also can balance the\nexternal and old knowledge to perform well on new data. We conduct extensive\nexperiments to evaluate our method with both a human knowledge graph (Wordnet)\nand a graph built from pre-trained word embeddings (Word2vec). The experimental\nresults show that our method achieves significantly better performances than\nstate-of-the-art baselines in terms of probabilistic predictive measure and\ntopic coherence. In particular, our method can work well when dealing with\nshort texts as well as concept drift. The implementation of GCTM is available\nat \\url{https://github.com/bachtranxuan/GCTM.git}.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 05:09:00 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 06:43:33 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 03:51:01 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Van Linh", "Ngo", ""], ["Bach", "Tran Xuan", ""], ["Than", "Khoat", ""]]}, {"id": "2003.06113", "submitter": "Tiehang Duan", "authors": "Tiehang Duan, Mihir Chauhan, Mohammad Abuzar Shaikh, Jun Chu, Sargur\n  Srihari", "title": "Ultra Efficient Transfer Learning with Meta Update for Cross Subject EEG\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The pattern of Electroencephalogram (EEG) signal differs significantly across\ndifferent subjects, and poses challenge for EEG classifiers in terms of 1)\neffectively adapting a learned classifier onto a new subject, 2) retaining\nknowledge of known subjects after the adaptation. We propose an efficient\ntransfer learning method, named Meta UPdate Strategy (MUPS-EEG), for continuous\nEEG classification across different subjects. The model learns effective\nrepresentations with meta update which accelerates adaptation on new subject\nand mitigate forgetting of knowledge on previous subjects at the same time. The\nproposed mechanism originates from meta learning and works to 1) find feature\nrepresentation that is broadly suitable for different subjects, 2) maximizes\nsensitivity of loss function for fast adaptation on new subject. The method can\nbe applied to all deep learning oriented models. Extensive experiments on two\npublic datasets demonstrate the effectiveness of the proposed model,\noutperforming current state of the arts by a large margin in terms of both\nadapting on new subject and retain knowledge of learned subjects.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 05:10:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 15:32:39 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 08:43:37 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Duan", "Tiehang", ""], ["Chauhan", "Mihir", ""], ["Shaikh", "Mohammad Abuzar", ""], ["Chu", "Jun", ""], ["Srihari", "Sargur", ""]]}, {"id": "2003.06121", "submitter": "Robi Bhattacharjee", "authors": "Robi Bhattacharjee and Kamalika Chaudhuri", "title": "When are Non-Parametric Methods Robust?", "comments": "accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A growing body of research has shown that many classifiers are susceptible to\n{\\em{adversarial examples}} -- small strategic modifications to test inputs\nthat lead to misclassification. In this work, we study general non-parametric\nmethods, with a view towards understanding when they are robust to these\nmodifications. We establish general conditions under which non-parametric\nmethods are r-consistent -- in the sense that they converge to optimally robust\nand accurate classifiers in the large sample limit.\n  Concretely, our results show that when data is well-separated, nearest\nneighbors and kernel classifiers are r-consistent, while histograms are not.\nFor general data distributions, we prove that preprocessing by Adversarial\nPruning (Yang et. al., 2019) -- that makes data well-separated -- followed by\nnearest neighbors or kernel classifiers also leads to r-consistency.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 05:23:53 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 22:18:08 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Bhattacharjee", "Robi", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2003.06123", "submitter": "Linh Ngo", "authors": "Tran Xuan Bach, Nguyen Duc Anh, Ngo Van Linh and Khoat Than", "title": "Dynamic transformation of prior knowledge into Bayesian models for data\n  streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider how to effectively use prior knowledge when learning a Bayesian\nmodel from streaming environments where the data come infinitely and\nsequentially. This problem is highly important in the era of data explosion and\nrich sources of precious external knowledge such as pre-trained models,\nontologies, Wikipedia, etc. We show that some existing approaches can forget\nany knowledge very fast. We then propose a novel framework that enables to\nincorporate the prior knowledge of different forms into a base Bayesian model\nfor data streams. Our framework subsumes some existing popular models for\ntime-series/dynamic data. Extensive experiments show that our framework\noutperforms existing methods with a large margin. In particular, our framework\ncan help Bayesian models generalize well on extremely short text while other\nmethods overfit. The implementation of our framework is available at\nhttps://github.com/bachtranxuan/TPS.git.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 05:39:01 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 03:48:32 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 06:38:09 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Bach", "Tran Xuan", ""], ["Anh", "Nguyen Duc", ""], ["Van Linh", "Ngo", ""], ["Than", "Khoat", ""]]}, {"id": "2003.06152", "submitter": "Roi Livni", "authors": "Assaf Dauber and Meir Feder and Tomer Koren and Roi Livni", "title": "Can Implicit Bias Explain Generalization? Stochastic Convex Optimization\n  as a Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of implicit bias, or implicit regularization, has been suggested\nas a means to explain the surprising generalization ability of modern-days\noverparameterized learning algorithms. This notion refers to the tendency of\nthe optimization algorithm towards a certain structured solution that often\ngeneralizes well. Recently, several papers have studied implicit regularization\nand were able to identify this phenomenon in various scenarios. We revisit this\nparadigm in arguably the simplest non-trivial setup, and study the implicit\nbias of Stochastic Gradient Descent (SGD) in the context of Stochastic Convex\nOptimization. As a first step, we provide a simple construction that rules out\nthe existence of a \\emph{distribution-independent} implicit regularizer that\ngoverns the generalization ability of SGD. We then demonstrate a learning\nproblem that rules out a very general class of \\emph{distribution-dependent}\nimplicit regularizers from explaining generalization, which includes strongly\nconvex regularizers as well as non-degenerate norm-based regularizations.\nCertain aspects of our constructions point out to significant difficulties in\nproviding a comprehensive explanation of an algorithm's generalization\nperformance by solely arguing about its implicit regularization properties.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 08:40:33 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 09:54:15 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 08:16:38 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Dauber", "Assaf", ""], ["Feder", "Meir", ""], ["Koren", "Tomer", ""], ["Livni", "Roi", ""]]}, {"id": "2003.06205", "submitter": "Eva Blanco", "authors": "E. Blanco-Mallo, B. Remeseiro, V. Bol\\'on-Canedo, A. Alonso-Betanzos", "title": "On the effectiveness of convolutional autoencoders on image-based\n  personalized recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RS) are increasingly present in our daily lives,\nespecially since the advent of Big Data, which allows for storing all kinds of\ninformation about users' preferences. Personalized RS are successfully applied\nin platforms such as Netflix, Amazon or YouTube. However, they are missing in\ngastronomic platforms such as TripAdvisor, where moreover we can find millions\nof images tagged with users' tastes. This paper explores the potential of using\nthose images as sources of information for modeling users' tastes and proposes\nan image-based classification system to obtain personalized recommendations,\nusing a convolutional autoencoder as feature extractor. The proposed\narchitecture will be applied to TripAdvisor data, using users' reviews that can\nbe defined as a triad composed by a user, a restaurant, and an image of it\ntaken by the user. Since the dataset is highly unbalanced, the use of data\naugmentation on the minority class is also considered in the experimentation.\nResults on data from three cities of different sizes (Santiago de Compostela,\nBarcelona and New York) demonstrate the effectiveness of using a convolutional\nautoencoder as feature extractor, instead of the standard deep features\ncomputed with convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:19:02 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Blanco-Mallo", "E.", ""], ["Remeseiro", "B.", ""], ["Bol\u00f3n-Canedo", "V.", ""], ["Alonso-Betanzos", "A.", ""]]}, {"id": "2003.06210", "submitter": "Emanuele Fabbiani", "authors": "Emanuele Fabbiani, Pulkit Nahata, Giuseppe De Nicolao, Giancarlo\n  Ferrari-Trecate", "title": "Identification of AC Networks via Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing integration of intermittent renewable generation in power\nnetworks calls for novel planning and control methodologies, which hinge on\ndetailed knowledge of the grid. However, reliable information concerning the\nsystem topology and parameters may be missing or outdated for temporally\nvarying AC networks. This paper proposes an online learning procedure to\nestimate the admittance matrix of an AC network capturing topological\ninformation and line parameters. We start off by providing a recursive\nidentification algorithm that exploits phasor measurements of voltages and\ncurrents. With the goal of accelerating convergence, we subsequently complement\nour base algorithm with a design-of-experiment procedure, which maximizes the\ninformation content of data at each step by computing optimal voltage\nexcitations. Our approach improves on existing techniques and its effectiveness\nis substantiated by numerical studies on a 6-bus AC network.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:40:53 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 15:44:23 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Fabbiani", "Emanuele", ""], ["Nahata", "Pulkit", ""], ["De Nicolao", "Giuseppe", ""], ["Ferrari-Trecate", "Giancarlo", ""]]}, {"id": "2003.06213", "submitter": "Manjesh Kumar Hanawal", "authors": "Debamita Ghosh, Arun Verma and Manjesh K. Hanawal", "title": "Learning and Fairness in Energy Harvesting: A Maximin Multi-Armed\n  Bandits Approach", "comments": "To be presented at SPCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in wireless radio frequency (RF) energy harvesting allows\nsensor nodes to increase their lifespan by remotely charging their batteries.\nThe amount of energy harvested by the nodes varies depending on their ambient\nenvironment, and proximity to the source. The lifespan of the sensor network\ndepends on the minimum amount of energy a node can harvest in the network. It\nis thus important to learn the least amount of energy harvested by nodes so\nthat the source can transmit on a frequency band that maximizes this amount. We\nmodel this learning problem as a novel stochastic Maximin Multi-Armed Bandits\n(Maximin MAB) problem and propose an Upper Confidence Bound (UCB) based\nalgorithm named Maximin UCB. Maximin MAB is a generalization of standard MAB\nand enjoys the same performance guarantee as that of the UCB1 algorithm.\nExperimental results validate the performance guarantees of our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:58:36 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 02:58:18 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 10:01:56 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ghosh", "Debamita", ""], ["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2003.06222", "submitter": "Gerrit van den Burg", "authors": "Gerrit J.J. van den Burg and Christopher K.I. Williams", "title": "An Evaluation of Change Point Detection Algorithms", "comments": "For code and data, see\n  https://github.com/alan-turing-institute/TCPDBench ; Changelog in pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change point detection is an important part of time series analysis, as the\npresence of a change point indicates an abrupt and significant change in the\ndata generating process. While many algorithms for change point detection\nexist, little attention has been paid to evaluating their performance on\nreal-world time series. Algorithms are typically evaluated on simulated data\nand a small number of commonly-used series with unreliable ground truth.\nClearly this does not provide sufficient insight into the comparative\nperformance of these algorithms. Therefore, instead of developing yet another\nchange point detection method, we consider it vastly more important to properly\nevaluate existing algorithms on real-world data. To achieve this, we present\nthe first data set specifically designed for the evaluation of change point\ndetection algorithms, consisting of 37 time series from various domains. Each\ntime series was annotated by five expert human annotators to provide ground\ntruth on the presence and location of change points. We analyze the consistency\nof the human annotators, and describe evaluation metrics that can be used to\nmeasure algorithm performance in the presence of multiple ground truth\nannotations. Subsequently, we present a benchmark study where 14 existing\nalgorithms are evaluated on each of the time series in the data set. This study\nshows that binary segmentation (Scott and Knott, 1974) and Bayesian online\nchange point detection (Adams and MacKay, 2007) are among the best performing\nmethods. Our aim is that this data set will serve as a proving ground in the\ndevelopment of novel change point detection algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 12:23:41 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 12:28:45 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Burg", "Gerrit J. J. van den", ""], ["Williams", "Christopher K. I.", ""]]}, {"id": "2003.06254", "submitter": "Luke Darlow", "authors": "Luke Nicholas Darlow, Amos Storkey", "title": "What Information Does a ResNet Compress?", "comments": "10 pages + appendices; submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The information bottleneck principle (Shwartz-Ziv & Tishby, 2017) suggests\nthat SGD-based training of deep neural networks results in optimally compressed\nhidden layers, from an information theoretic perspective. However, this claim\nwas established on toy data. The goal of the work we present here is to test\nwhether the information bottleneck principle is applicable to a realistic\nsetting using a larger and deeper convolutional architecture, a ResNet model.\nWe trained PixelCNN++ models as inverse representation decoders to measure the\nmutual information between hidden layers of a ResNet and input image data, when\ntrained for (1) classification and (2) autoencoding. We find that two stages of\nlearning happen for both training regimes, and that compression does occur,\neven for an autoencoder. Sampling images by conditioning on hidden layers'\nactivations offers an intuitive visualisation to understand what a ResNets\nlearns to forget.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 13:02:11 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Darlow", "Luke Nicholas", ""], ["Storkey", "Amos", ""]]}, {"id": "2003.06259", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Michal Valko, R\\'emi Munos", "title": "Taylor Expansion Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the application of Taylor expansions in\nreinforcement learning. In particular, we propose Taylor expansion policy\noptimization, a policy optimization formalism that generalizes prior work\n(e.g., TRPO) as a first-order special case. We also show that Taylor expansions\nintimately relate to off-policy evaluation. Finally, we show that this new\nformulation entails modifications which improve the performance of several\nstate-of-the-art distributed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 13:14:19 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Tang", "Yunhao", ""], ["Valko", "Michal", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "2003.06281", "submitter": "Stefan T. Radev", "authors": "Stefan T. Radev, Ulf K. Mertens, Andreass Voss, Lynton Ardizzone,\n  Ullrich K\\\"othe", "title": "BayesFlow: Learning complex stochastic models with invertible neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Estimating the parameters of mathematical models is a common problem in\nalmost all branches of science. However, this problem can prove notably\ndifficult when processes and model descriptions become increasingly complex and\nan explicit likelihood function is not available. With this work, we propose a\nnovel method for globally amortized Bayesian inference based on invertible\nneural networks which we call BayesFlow. The method uses simulation to learn a\nglobal estimator for the probabilistic mapping from observed data to underlying\nmodel parameters. A neural network pre-trained in this way can then, without\nadditional training or optimization, infer full posteriors on arbitrary many\nreal datasets involving the same model family. In addition, our method\nincorporates a summary network trained to embed the observed data into\nmaximally informative summary statistics. Learning summary statistics from data\nmakes the method applicable to modeling scenarios where standard inference\ntechniques with hand-crafted summary statistics fail. We demonstrate the\nutility of BayesFlow on challenging intractable models from population\ndynamics, epidemiology, cognitive science and ecology. We argue that BayesFlow\nprovides a general framework for building amortized Bayesian parameter\nestimation machines for any forward model from which data can be simulated.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 13:39:31 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 12:18:55 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 14:01:38 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 19:28:55 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Radev", "Stefan T.", ""], ["Mertens", "Ulf K.", ""], ["Voss", "Andreass", ""], ["Ardizzone", "Lynton", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2003.06311", "submitter": "Rajesh Kumar Korupalli V", "authors": "Korupalli V Rajesh Kumar and Susan Elias", "title": "Predictive Analysis for Detection of Human Neck Postures using a robust\n  integration of kinetics and kinematics", "comments": "12 pages, 15 figures, To appear in the Journal of Computer Methods in\n  Biomechanics and Biomedical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human neck postures and movements need to be monitored, measured, quantified\nand analyzed, as a preventive measure in healthcare applications. Improper neck\npostures are an increasing source of neck musculoskeletal disorders, requiring\ntherapy and rehabilitation. The motivation for the research presented in this\npaper was the need to develop a notification mechanism for improper neck usage.\nKinematic data captured by sensors have limitations in accurately classifying\nthe neck postures. Hence, we propose an integrated use of kinematic and kinetic\ndata to efficiently classify neck postures. Using machine learning algorithms\nwe obtained 100% accuracy in the predictive analysis of this data. The research\nanalysis and discussions show that the kinetic data of the Hyoid muscles can\naccurately detect the neck posture given the corresponding kinematic data\ncaptured by the neck-band. The proposed robust platform for the integration of\nkinematic and kinetic data has enabled the design of a smart neck-band for the\nprevention of neck musculoskeletal disorders.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:10:42 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Kumar", "Korupalli V Rajesh", ""], ["Elias", "Susan", ""]]}, {"id": "2003.06315", "submitter": "Maria Santamaria", "authors": "Maria Santamaria, Ebroul Izquierdo, Saverio Blasi, Marta Mrak", "title": "Estimation of Rate Control Parameters for Video Coding Using CNN", "comments": "5 pages, 5 figures, 4 tables", "journal-ref": "IEEE International Conference on Visual Communications and Image\n  Processing (VCIP 2018), Taichung, Taiwan, 9 -12 December 2018", "doi": "10.1109/VCIP.2018.8698721", "report-no": null, "categories": "eess.IV cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rate-control is essential to ensure efficient video delivery. Typical\nrate-control algorithms rely on bit allocation strategies, to appropriately\ndistribute bits among frames. As reference frames are essential for exploiting\ntemporal redundancies, intra frames are usually assigned a larger portion of\nthe available bits. In this paper, an accurate method to estimate number of\nbits and quality of intra frames is proposed, which can be used for bit\nallocation in a rate-control scheme. The algorithm is based on deep learning,\nwhere networks are trained using the original frames as inputs, while\ndistortions and sizes of compressed frames after encoding are used as ground\ntruths. Two approaches are proposed where either local or global distortions\nare predicted.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 14:18:43 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Santamaria", "Maria", ""], ["Izquierdo", "Ebroul", ""], ["Blasi", "Saverio", ""], ["Mrak", "Marta", ""]]}, {"id": "2003.06321", "submitter": "Jielei Chu", "authors": "Jielei Chu, Jing Liu, Hongjun Wang, Zhiguo Gong and Tianrui Li", "title": "Minor Constraint Disturbances for Deep Semi-supervised Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In high-dimensional data space, semi-supervised feature learning based on\nEuclidean distance shows instability under a broad set of conditions.\nFurthermore, the scarcity and high cost of labels prompt us to explore new\nsemi-supervised learning methods with the fewest labels. In this paper, we\ndevelop a novel Minor Constraint Disturbances-based Deep Semi-supervised\nFeature Learning framework (MCD-DSFL) from the perspective of probability\ndistribution for feature representation. There are two fundamental modules in\nthe proposed framework: one is a Minor Constraint Disturbances-based restricted\nBoltzmann machine with Gaussian visible units (MCDGRBM) for modelling\ncontinuous data and the other is a Minor Constraint Disturbances-based\nrestricted Boltzmann machine (MCDRBM) for modelling binary data. The Minor\nConstraint Disturbances (MCD) consist of less instance-level constraints which\nare produced by only two randomly selected labels from each class. The\nKullback-Leibler (KL) divergences of the MCD are fused into the Contrastive\nDivergence (CD) learning for training the proposed MCDGRBM and MCDRBM models.\nThen, the probability distributions of hidden layer features are as similar as\npossible in the same class and they are as dissimilar as possible in the\ndifferent classes simultaneously. Despite the weak influence of the MCD for our\nshallow models (MCDGRBM and MCDRBM), the proposed deep MCD-DSFL framework\nimproves the representation capability significantly under its leverage effect.\nThe semi-supervised strategy based on the KL divergence of the MCD\nsignificantly reduces the reliance on the labels and improves the stability of\nthe semi-supervised feature learning in high-dimensional space simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 14:33:16 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Chu", "Jielei", ""], ["Liu", "Jing", ""], ["Wang", "Hongjun", ""], ["Gong", "Zhiguo", ""], ["Li", "Tianrui", ""]]}, {"id": "2003.06340", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein\n  and Caroline Uhler", "title": "On Alignment in Deep Linear Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the properties of alignment, a form of implicit regularization, in\nlinear neural networks under gradient descent. We define alignment for fully\nconnected networks with multidimensional outputs and show that it is a natural\nextension of alignment in networks with 1-dimensional outputs as defined by Ji\nand Telgarsky, 2018. While in fully connected networks, there always exists a\nglobal minimum corresponding to an aligned solution, we analyze alignment as it\nrelates to the training process. Namely, we characterize when alignment is an\ninvariant of training under gradient descent by providing necessary and\nsufficient conditions for this invariant to hold. In such settings, the\ndynamics of gradient descent simplify, thereby allowing us to provide an\nexplicit learning rate under which the network converges linearly to a global\nminimum. We then analyze networks with layer constraints such as convolutional\nnetworks. In this setting, we prove that gradient descent is equivalent to\nprojected gradient descent, and that alignment is impossible with sufficiently\nlarge datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 15:13:37 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 01:12:33 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Nichani", "Eshaan", ""], ["Bernstein", "Daniel", ""], ["Uhler", "Caroline", ""]]}, {"id": "2003.06344", "submitter": "Jiawei Zhou", "authors": "Jiawei Zhou, Zhiying Xu, Alexander M. Rush, Minlan Yu", "title": "Automating Botnet Detection with Graph Neural Networks", "comments": "Data and code available\n  https://github.com/harvardnlp/botnet-detection . Accepted as a workshop paper\n  in MLSys 2020 Conference", "journal-ref": "AutoML for Networking and Systems Workshop of MLSys 2020\n  Conference", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets are now a major source for many network attacks, such as DDoS attacks\nand spam. However, most traditional detection methods heavily rely on\nheuristically designed multi-stage detection criteria. In this paper, we\nconsider the neural network design challenges of using modern deep learning\ntechniques to learn policies for botnet detection automatically. To generate\ntraining data, we synthesize botnet connections with different underlying\ncommunication patterns overlaid on large-scale real networks as datasets. To\ncapture the important hierarchical structure of centralized botnets and the\nfast-mixing structure for decentralized botnets, we tailor graph neural\nnetworks (GNN) to detect the properties of these structures. Experimental\nresults show that GNNs are better able to capture botnet structure than\nprevious non-learning methods when trained with appropriate data, and that\ndeeper GNNs are crucial for learning difficult botnet topologies. We believe\nour data and studies can be useful for both the network security and graph\nlearning communities.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 15:34:33 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zhou", "Jiawei", ""], ["Xu", "Zhiying", ""], ["Rush", "Alexander M.", ""], ["Yu", "Minlan", ""]]}, {"id": "2003.06350", "submitter": "Emmanuel Bengio", "authors": "Emmanuel Bengio, Joelle Pineau, Doina Precup", "title": "Interference and Generalization in Temporal Difference Learning", "comments": "Submitted to ICML 2020. 20 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the link between generalization and interference in\ntemporal-difference (TD) learning. Interference is defined as the inner product\nof two different gradients, representing their alignment. This quantity emerges\nas being of interest from a variety of observations about neural networks,\nparameter sharing and the dynamics of learning. We find that TD easily leads to\nlow-interference, under-generalizing parameters, while the effect seems\nreversed in supervised learning. We hypothesize that the cause can be traced\nback to the interplay between the dynamics of interference and bootstrapping.\nThis is supported empirically by several observations: the negative\nrelationship between the generalization gap and interference in TD, the\nnegative effect of bootstrapping on interference and the local coherence of\ntargets, and the contrast between the propagation rate of information in TD(0)\nversus TD($\\lambda$) and regression tasks such as Monte-Carlo policy\nevaluation. We hope that these new findings can guide the future discovery of\nbetter bootstrapping methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 15:49:58 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Bengio", "Emmanuel", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""]]}, {"id": "2003.06365", "submitter": "Yuan Gao", "authors": "Ziming Gao, Yuan Gao, Yi Hu, Zhengyong Jiang, Jionglong Su", "title": "Application of Deep Q-Network in Portfolio Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning algorithms and Neural Networks are widely applied to many\ndifferent areas such as stock market prediction, face recognition and\npopulation analysis. This paper will introduce a strategy based on the classic\nDeep Reinforcement Learning algorithm, Deep Q-Network, for portfolio management\nin stock market. It is a type of deep neural network which is optimized by Q\nLearning. To make the DQN adapt to financial market, we first discretize the\naction space which is defined as the weight of portfolio in different assets so\nthat portfolio management becomes a problem that Deep Q-Network can solve.\nNext, we combine the Convolutional Neural Network and dueling Q-net to enhance\nthe recognition ability of the algorithm. Experimentally, we chose five\nlowrelevant American stocks to test the model. The result demonstrates that the\nDQN based strategy outperforms the ten other traditional strategies. The profit\nof DQN algorithm is 30% more than the profit of other strategies. Moreover, the\nSharpe ratio associated with Max Drawdown demonstrates that the risk of policy\nmade with DQN is the lowest.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 16:20:51 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Gao", "Ziming", ""], ["Gao", "Yuan", ""], ["Hu", "Yi", ""], ["Jiang", "Zhengyong", ""], ["Su", "Jionglong", ""]]}, {"id": "2003.06377", "submitter": "Sarit Khirirat", "authors": "Sarit Khirirat, Sindri Magn\\'usson, Arda Aytekin, Mikael Johansson", "title": "A flexible framework for communication-efficient machine learning: from\n  HPC to IoT", "comments": "27 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing scale of machine learning tasks, it has become essential\nto reduce the communication between computing nodes. Early work on gradient\ncompression focused on the bottleneck between CPUs and GPUs, but\ncommunication-efficiency is now needed in a variety of different system\narchitectures, from high-performance clusters to energy-constrained IoT\ndevices. In the current practice, compression levels are typically chosen\nbefore training and settings that work well for one task may be vastly\nsuboptimal for another dataset on another architecture. In this paper, we\npropose a flexible framework which adapts the compression level to the true\ngradient at each iteration, maximizing the improvement in the objective\nfunction that is achieved per communicated bit. Our framework is easy to adapt\nfrom one technology to the next by modeling how the communication cost depends\non the compression level for the specific technology. Theoretical results and\npractical experiments indicate that the automatic tuning strategies\nsignificantly increase communication efficiency on several state-of-the-art\ncompression schemes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 16:49:08 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 07:58:19 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Khirirat", "Sarit", ""], ["Magn\u00fasson", "Sindri", ""], ["Aytekin", "Arda", ""], ["Johansson", "Mikael", ""]]}, {"id": "2003.06417", "submitter": "Deepak Pathak", "authors": "Scott Emmons, Ajay Jain, Michael Laskin, Thanard Kurutach, Pieter\n  Abbeel, Deepak Pathak", "title": "Sparse Graphical Memory for Robust Planning", "comments": "Accepted at NeurIPS 2020. Video and code at\n  https://mishalaskin.github.io/sgm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To operate effectively in the real world, agents should be able to act from\nhigh-dimensional raw sensory input such as images and achieve diverse goals\nacross long time-horizons. Current deep reinforcement and imitation learning\nmethods can learn directly from high-dimensional inputs but do not scale well\nto long-horizon tasks. In contrast, classical graphical methods like A* search\nare able to solve long-horizon tasks, but assume that the state space is\nabstracted away from raw sensory input. Recent works have attempted to combine\nthe strengths of deep learning and classical planning; however, dominant\nmethods in this domain are still quite brittle and scale poorly with the size\nof the environment. We introduce Sparse Graphical Memory (SGM), a new data\nstructure that stores states and feasible transitions in a sparse memory. SGM\naggregates states according to a novel two-way consistency objective, adapting\nclassic state aggregation criteria to goal-conditioned RL: two states are\nredundant when they are interchangeable both as goals and as starting states.\nTheoretically, we prove that merging nodes according to two-way consistency\nleads to an increase in shortest path lengths that scales only linearly with\nthe merging threshold. Experimentally, we show that SGM significantly\noutperforms current state of the art methods on long horizon, sparse-reward\nvisual navigation tasks. Project video and code are available at\nhttps://mishalaskin.github.io/sgm/\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 17:59:32 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:55:04 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 21:37:49 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Emmons", "Scott", ""], ["Jain", "Ajay", ""], ["Laskin", "Michael", ""], ["Kurutach", "Thanard", ""], ["Abbeel", "Pieter", ""], ["Pathak", "Deepak", ""]]}, {"id": "2003.06428", "submitter": "Chih-Yuan Yang", "authors": "Chih-Yuan Yang and Ravi Sahita", "title": "Towards a Resilient Machine Learning Classifier -- a Case Study of\n  Ransomware Detection", "comments": "Conference on Applied Machine Learning for Information Security 2019,\n  Washington DC (CAMLIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The damage caused by crypto-ransomware, due to encryption, is difficult to\nrevert and cause data losses. In this paper, a machine learning (ML) classifier\nwas built to early detect ransomware (called crypto-ransomware) that uses\ncryptography by program behavior. If a signature-based detection was missed, a\nbehavior-based detector can be the last line of defense to detect and contain\nthe damages. We find that input/output activities of ransomware and the\nfile-content entropy are unique traits to detect crypto-ransomware. A\ndeep-learning (DL) classifier can detect ransomware with a high accuracy and a\nlow false positive rate. We conduct an adversarial research against the models\ngenerated. We use simulated ransomware programs to launch a gray-box analysis\nto probe the weakness of ML classifiers and to improve model robustness. In\naddition to accuracy and resiliency, trustworthiness is the other key criteria\nfor a quality detector. Making sure that the correct information was used for\ninference is important for a security application. The Integrated Gradient\nmethod was used to explain the deep learning model and also to reveal why false\nnegatives evade the detection. The approaches to build and to evaluate a\nreal-world detector were demonstrated and discussed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 18:02:19 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yang", "Chih-Yuan", ""], ["Sahita", "Ravi", ""]]}, {"id": "2003.06441", "submitter": "Yuya Yoshikawa", "authors": "Yuya Yoshikawa, Tomoharu Iwata", "title": "Neural Generators of Sparse Local Linear Models for Achieving both\n  Accuracy and Interpretability", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For reliability, it is important that the predictions made by machine\nlearning methods are interpretable by human. In general, deep neural networks\n(DNNs) can provide accurate predictions, although it is difficult to interpret\nwhy such predictions are obtained by DNNs. On the other hand, interpretation of\nlinear models is easy, although their predictive performance would be low since\nreal-world data is often intrinsically non-linear. To combine both the benefits\nof the high predictive performance of DNNs and high interpretability of linear\nmodels into a single model, we propose neural generators of sparse local linear\nmodels (NGSLLs). The sparse local linear models have high flexibility as they\ncan approximate non-linear functions. The NGSLL generates sparse linear weights\nfor each sample using DNNs that take original representations of each sample\n(e.g., word sequence) and their simplified representations (e.g., bag-of-words)\nas input. By extracting features from the original representations, the weights\ncan contain rich information to achieve high predictive performance.\nAdditionally, the prediction is interpretable because it is obtained by the\ninner product between the simplified representations and the sparse weights,\nwhere only a small number of weights are selected by our gate module in the\nNGSLL. In experiments with real-world datasets, we demonstrate the\neffectiveness of the NGSLL quantitatively and qualitatively by evaluating\nprediction performance and visualizing generated weights on image and text\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 18:49:36 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yoshikawa", "Yuya", ""], ["Iwata", "Tomoharu", ""]]}, {"id": "2003.06505", "submitter": "Jonas Mueller", "authors": "Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro\n  Larroy, Mu Li, Alexander Smola", "title": "AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce AutoGluon-Tabular, an open-source AutoML framework that requires\nonly a single line of Python to train highly accurate machine learning models\non an unprocessed tabular dataset such as a CSV file. Unlike existing AutoML\nframeworks that primarily focus on model/hyperparameter selection,\nAutoGluon-Tabular succeeds by ensembling multiple models and stacking them in\nmultiple layers. Experiments reveal that our multi-layer combination of many\nmodels offers better use of allocated training time than seeking out the best.\nA second contribution is an extensive evaluation of public and commercial\nAutoML platforms including TPOT, H2O, AutoWEKA, auto-sklearn, AutoGluon, and\nGoogle AutoML Tables. Tests on a suite of 50 classification and regression\ntasks from Kaggle and the OpenML AutoML Benchmark reveal that AutoGluon is\nfaster, more robust, and much more accurate. We find that AutoGluon often even\noutperforms the best-in-hindsight combination of all of its competitors. In two\npopular Kaggle competitions, AutoGluon beat 99% of the participating data\nscientists after merely 4h of training on the raw data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:10:39 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Erickson", "Nick", ""], ["Mueller", "Jonas", ""], ["Shirkov", "Alexander", ""], ["Zhang", "Hang", ""], ["Larroy", "Pedro", ""], ["Li", "Mu", ""], ["Smola", "Alexander", ""]]}, {"id": "2003.06508", "submitter": "Ellango Jothimurugesan", "authors": "Ashraf Tahmasbi, Ellango Jothimurugesan, Srikanta Tirthapura, Phillip\n  B. Gibbons", "title": "DriftSurf: A Risk-competitive Learning Algorithm under Concept Drift", "comments": "32 pages, 12 figures. Submitted to NeurIPS 2020. Replaced to include\n  revision of Lemma 2 and additional experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning from streaming data, a change in the data distribution, also\nknown as concept drift, can render a previously-learned model inaccurate and\nrequire training a new model. We present an adaptive learning algorithm that\nextends previous drift-detection-based methods by incorporating drift detection\ninto a broader stable-state/reactive-state process. The advantage of our\napproach is that we can use aggressive drift detection in the stable state to\nachieve a high detection rate, but mitigate the false positive rate of\nstandalone drift detection via a reactive state that reacts quickly to true\ndrifts while eliminating most false positives. The algorithm is generic in its\nbase learner and can be applied across a variety of supervised learning\nproblems. Our theoretical analysis shows that the risk of the algorithm is\ncompetitive to an algorithm with oracle knowledge of when (abrupt) drifts\noccur. Experiments on synthetic and real datasets with concept drifts confirm\nour theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:25:25 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 15:05:33 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tahmasbi", "Ashraf", ""], ["Jothimurugesan", "Ellango", ""], ["Tirthapura", "Srikanta", ""], ["Gibbons", "Phillip B.", ""]]}, {"id": "2003.06511", "submitter": "Haiyun He", "authors": "Haiyun He, Qiaosheng Zhang, and Vincent Y. F. Tan", "title": "Optimal Change-Point Detection with Training Sequences in the Large and\n  Moderate Deviations Regimes", "comments": "31 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a novel offline change-point detection problem from\nan information-theoretic perspective. In contrast to most related works, we\nassume that the knowledge of the underlying pre- and post-change distributions\nare not known and can only be learned from the training sequences which are\navailable. We further require the probability of the \\emph{estimation error} to\ndecay either exponentially or sub-exponentially fast (corresponding\nrespectively to the large and moderate deviations regimes in information theory\nparlance). Based on the training sequences as well as the test sequence\nconsisting of a single change-point, we design a change-point estimator and\nfurther show that this estimator is optimal by establishing matching (strong)\nconverses. This leads to a full characterization of the optimal confidence\nwidth (i.e., half the width of the confidence interval within which the true\nchange-point is located at with high probability) as a function of the\nundetected error, under both the large and moderate deviations regimes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:39:40 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 03:13:44 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 10:58:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["He", "Haiyun", ""], ["Zhang", "Qiaosheng", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2003.06513", "submitter": "Yifan Gong", "authors": "Yifan Gong, Zheng Zhan, Zhengang Li, Wei Niu, Xiaolong Ma, Wenhao\n  Wang, Bin Ren, Caiwen Ding, Xue Lin, Xiaolin Xu, and Yanzhi Wang", "title": "A Privacy-Preserving-Oriented DNN Pruning and Mobile Acceleration\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning of deep neural networks (DNNs) has been proposed to satisfy\nthe limited storage and computing capability of mobile edge devices. However,\nprevious pruning methods mainly focus on reducing the model size and/or\nimproving performance without considering the privacy of user data. To mitigate\nthis concern, we propose a privacy-preserving-oriented pruning and mobile\nacceleration framework that does not require the private training dataset. At\nthe algorithm level of the proposed framework, a systematic weight pruning\ntechnique based on the alternating direction method of multipliers (ADMM) is\ndesigned to iteratively solve the pattern-based pruning problem for each layer\nwith randomly generated synthetic data. In addition, corresponding\noptimizations at the compiler level are leveraged for inference accelerations\non devices. With the proposed framework, users could avoid the time-consuming\npruning process for non-experts and directly benefit from compressed models.\nExperimental results show that the proposed framework outperforms three\nstate-of-art end-to-end DNN frameworks, i.e., TensorFlow-Lite, TVM, and MNN,\nwith speedup up to 4.2X, 2.5X, and 2.0X, respectively, with almost no accuracy\nloss, while preserving data privacy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:52:03 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 00:45:39 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Gong", "Yifan", ""], ["Zhan", "Zheng", ""], ["Li", "Zhengang", ""], ["Niu", "Wei", ""], ["Ma", "Xiaolong", ""], ["Wang", "Wenhao", ""], ["Ren", "Bin", ""], ["Ding", "Caiwen", ""], ["Lin", "Xue", ""], ["Xu", "Xiaolin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2003.06516", "submitter": "Isotta Landi", "authors": "Isotta Landi, Benjamin S. Glicksberg, Hao-Chih Lee, Sarah Cherng,\n  Giulia Landi, Matteo Danieletto, Joel T. Dudley, Cesare Furlanello, and\n  Riccardo Miotto", "title": "Deep Representation Learning of Electronic Health Records to Unlock\n  Patient Stratification at Scale", "comments": "C.F. and R.M. share senior authorship", "journal-ref": "npj Digit. Med. 3, 96 (2020)", "doi": "10.1038/s41746-020-0301-z", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving disease subtypes from electronic health records (EHRs) can guide\nnext-generation personalized medicine. However, challenges in summarizing and\nrepresenting patient data prevent widespread practice of scalable EHR-based\nstratification analysis. Here we present an unsupervised framework based on\ndeep learning to process heterogeneous EHRs and derive patient representations\nthat can efficiently and effectively enable patient stratification at scale. We\nconsidered EHRs of 1,608,741 patients from a diverse hospital cohort comprising\nof a total of 57,464 clinical concepts. We introduce a representation learning\nmodel based on word embeddings, convolutional neural networks, and autoencoders\n(i.e., ConvAE) to transform patient trajectories into low-dimensional latent\nvectors. We evaluated these representations as broadly enabling patient\nstratification by applying hierarchical clustering to different multi-disease\nand disease-specific patient cohorts. ConvAE significantly outperformed several\nbaselines in a clustering task to identify patients with different complex\nconditions, with 2.61 entropy and 0.31 purity average scores. When applied to\nstratify patients within a certain condition, ConvAE led to various clinically\nrelevant subtypes for different disorders, including type 2 diabetes,\nParkinson's disease and Alzheimer's disease, largely related to comorbidities,\ndisease progression, and symptom severity. With these results, we demonstrate\nthat ConvAE can generate patient representations that lead to clinically\nmeaningful insights. This scalable framework can help better understand varying\netiologies in heterogeneous sub-populations and unlock patterns for EHR-based\nresearch in the realm of personalized medicine.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 00:04:20 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 10:28:54 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Landi", "Isotta", ""], ["Glicksberg", "Benjamin S.", ""], ["Lee", "Hao-Chih", ""], ["Cherng", "Sarah", ""], ["Landi", "Giulia", ""], ["Danieletto", "Matteo", ""], ["Dudley", "Joel T.", ""], ["Furlanello", "Cesare", ""], ["Miotto", "Riccardo", ""]]}, {"id": "2003.06559", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, David Wagner", "title": "Minimum-Norm Adversarial Examples on KNN and KNN-Based Models", "comments": "3rd Deep Learning and Security Workshop (co-located with the 41st\n  IEEE Symposium on Security and Privacy)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the robustness against adversarial examples of kNN classifiers and\nclassifiers that combine kNN with neural networks. The main difficulty lies in\nthe fact that finding an optimal attack on kNN is intractable for typical\ndatasets. In this work, we propose a gradient-based attack on kNN and kNN-based\ndefenses, inspired by the previous work by Sitawarin & Wagner [1]. We\ndemonstrate that our attack outperforms their method on all of the models we\ntested with only a minimal increase in the computation time. The attack also\nbeats the state-of-the-art attack [2] on kNN when k > 1 using less than 1% of\nits running time. We hope that this attack can be used as a new baseline for\nevaluating the robustness of kNN and its variants.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 05:36:33 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Wagner", "David", ""]]}, {"id": "2003.06560", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Shagun Sodhani, Joelle Pineau and William L. Hamilton", "title": "Evaluating Logical Generalization in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has highlighted the role of relational inductive biases in\nbuilding learning agents that can generalize and reason in a compositional\nmanner. However, while relational learning algorithms such as graph neural\nnetworks (GNNs) show promise, we do not understand how effectively these\napproaches can adapt to new tasks. In this work, we study the task of logical\ngeneralization using GNNs by designing a benchmark suite grounded in\nfirst-order logic. Our benchmark suite, GraphLog, requires that learning\nalgorithms perform rule induction in different synthetic logics, represented as\nknowledge graphs. GraphLog consists of relation prediction tasks on 57 distinct\nlogical domains. We use GraphLog to evaluate GNNs in three different setups:\nsingle-task supervised learning, multi-task pretraining, and continual\nlearning. Unlike previous benchmarks, our approach allows us to precisely\ncontrol the logical relationship between the different tasks. We find that the\nability for models to generalize and adapt is strongly determined by the\ndiversity of the logical rules they encounter during training, and our results\nhighlight new challenges for the design of GNN models. We publicly release the\ndataset and code used to generate and interact with the dataset at\nhttps://www.cs.mcgill.ca/~ksinha4/graphlog.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 05:45:55 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Sinha", "Koustuv", ""], ["Sodhani", "Shagun", ""], ["Pineau", "Joelle", ""], ["Hamilton", "William L.", ""]]}, {"id": "2003.06566", "submitter": "Puneet Mangla", "authors": "Puneet Mangla, Vedant Singh, Shreyas Jayant Havaldar, Vineeth N\n  Balasubramanian", "title": "On the benefits of defining vicinal distributions in latent space", "comments": "$\\textbf{Best Paper Award}$ at CVPR 2021 Workshop on\n  $\\textbf{Adversarial Machine Learning in Real-World Computer Vision\n  (AML-CV)}$. Also accepted at ICLR 2021 Workshops on $\\textbf{Robust-Reliable\n  Machine Learning}$ (Oral) and $\\textbf{Generalization beyond the training\n  distribution}$ (Abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vicinal risk minimization (VRM) principle is an empirical risk\nminimization (ERM) variant that replaces Dirac masses with vicinal functions.\nThere is strong numerical and theoretical evidence showing that VRM outperforms\nERM in terms of generalization if appropriate vicinal functions are chosen.\nMixup Training (MT), a popular choice of vicinal distribution, improves the\ngeneralization performance of models by introducing globally linear behavior in\nbetween training examples. Apart from generalization, recent works have shown\nthat mixup trained models are relatively robust to input\nperturbations/corruptions and at the same time are calibrated better than their\nnon-mixup counterparts. In this work, we investigate the benefits of defining\nthese vicinal distributions like mixup in latent space of generative models\nrather than in input space itself. We propose a new approach - \\textit{VarMixup\n(Variational Mixup)} - to better sample mixup images by using the latent\nmanifold underlying the data. Our empirical studies on CIFAR-10, CIFAR-100, and\nTiny-ImageNet demonstrate that models trained by performing mixup in the latent\nmanifold learned by VAEs are inherently more robust to various input\ncorruptions/perturbations, are significantly better calibrated, and exhibit\nmore local-linear loss landscapes.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 06:45:26 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 06:47:02 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 05:19:45 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mangla", "Puneet", ""], ["Singh", "Vedant", ""], ["Havaldar", "Shreyas Jayant", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2003.06581", "submitter": "Bo-Kyeong Kim Ph.D.", "authors": "Bo-Kyeong Kim, Sungjin Park, Geonmin Kim, Soo-Young Lee", "title": "Semi-supervised Disentanglement with Independent Vector Variational\n  Autoencoders", "comments": "24 pages: 10 p for main paper (8 figures) and 14 p for supplementary\n  material (12 figures). A shortened version of this paper is currently under\n  review by a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to separate the generative factors of data into two latent vectors in\na variational autoencoder. One vector captures class factors relevant to target\nclassification tasks, while the other vector captures style factors relevant to\nthe remaining information. To learn the discrete class features, we introduce\nsupervision using a small amount of labeled data, which can simply yet\neffectively reduce the effort required for hyperparameter tuning performed in\nexisting unsupervised methods. Furthermore, we introduce a learning objective\nto encourage statistical independence between the vectors. We show that (i)\nthis vector independence term exists within the result obtained on decomposing\nthe evidence lower bound with multiple latent vectors, and (ii) encouraging\nsuch independence along with reducing the total correlation within the vectors\nenhances disentanglement performance. Experiments conducted on several image\ndatasets demonstrate that the disentanglement achieved via our method can\nimprove classification performance and generation controllability.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 09:20:22 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Kim", "Bo-Kyeong", ""], ["Park", "Sungjin", ""], ["Kim", "Geonmin", ""], ["Lee", "Soo-Young", ""]]}, {"id": "2003.06646", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Toshihiko Yamasaki", "title": "Investigating Generalization in Neural Networks under Optimally Evolved\n  Training Perturbations", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generalization properties of neural networks\nunder input perturbations and show that minimal training data corruption by a\nfew pixel modifications can cause drastic overfitting. We propose an\nevolutionary algorithm to search for optimal pixel perturbations using novel\ncost function inspired from literature in domain adaptation that explicitly\nmaximizes the generalization gap and domain divergence between clean and\ncorrupted images. Our method outperforms previous pixel-based data distribution\nshift methods on state-of-the-art Convolutional Neural Networks (CNNs)\narchitectures. Interestingly, we find that the choice of optimization plays an\nimportant role in generalization robustness due to the empirical observation\nthat SGD is resilient to such training data corruption unlike adaptive\noptimization techniques (ADAM). Our source code is available at\nhttps://github.com/subhajitchaudhury/evo-shift.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 14:38:07 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "2003.06686", "submitter": "Zack Hodari", "authors": "Zack Hodari, Catherine Lai, Simon King", "title": "Perception of prosodic variation for speech synthesis using an\n  unsupervised discrete representation of F0", "comments": "Published to the 10th ISCA International Conference on Speech Prosody\n  (SP2020)", "journal-ref": null, "doi": "10.21437/SpeechProsody.2020-197", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In English, prosody adds a broad range of information to segment sequences,\nfrom information structure (e.g. contrast) to stylistic variation (e.g.\nexpression of emotion). However, when learning to control prosody in\ntext-to-speech voices, it is not clear what exactly the control is modifying.\nExisting research on discrete representation learning for prosody has\ndemonstrated high naturalness, but no analysis has been performed on what these\nrepresentations capture, or if they can generate meaningfully-distinct variants\nof an utterance. We present a phrase-level variational autoencoder with a\nmulti-modal prior, using the mode centres as \"intonation codes\". Our evaluation\nestablishes which intonation codes are perceptually distinct, finding that the\nintonation codes from our multi-modal latent model were significantly more\ndistinct than a baseline using k-means clustering. We carry out a follow-up\nqualitative study to determine what information the codes are carrying. Most\ncommonly, listeners commented on the intonation codes having a statement or\nquestion style. However, many other affect-related styles were also reported,\nincluding: emotional, uncertain, surprised, sarcastic, passive aggressive, and\nupset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 19:17:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hodari", "Zack", ""], ["Lai", "Catherine", ""], ["King", "Simon", ""]]}, {"id": "2003.06693", "submitter": "Ping-Yeh Chiang", "authors": "Ping-Yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph\n  Studer, Tom Goldstein", "title": "Certified Defenses for Adversarial Patches", "comments": "International Conference on Learning Representations, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial patch attacks are among one of the most practical threat models\nagainst real-world computer vision systems. This paper studies certified and\nempirical defenses against patch attacks. We begin with a set of experiments\nshowing that most existing defenses, which work by pre-processing input images\nto mitigate adversarial patches, are easily broken by simple white-box\nadversaries. Motivated by this finding, we propose the first certified defense\nagainst patch attacks, and propose faster methods for its training.\nFurthermore, we experiment with different patch shapes for testing, obtaining\nsurprisingly good robustness transfer across shapes, and present preliminary\nresults on certified defense against sparse attacks. Our complete\nimplementation can be found on:\nhttps://github.com/Ping-C/certifiedpatchdefense.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 19:57:31 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 15:51:40 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chiang", "Ping-Yeh", ""], ["Ni", "Renkun", ""], ["Abdelkader", "Ahmed", ""], ["Zhu", "Chen", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}, {"id": "2003.06699", "submitter": "Maria Nyamukuru", "authors": "Maria T. Nyamukuru and Kofi M. Odame", "title": "Tiny Eats: Eating Detection on a Microcontroller", "comments": "5 pages, 7 figures, 2 tables, Sensys-ML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in low power highly efficient wearable devices\nfor automatic dietary monitoring (ADM) [1]. The success of deep neural networks\nin audio event classification problems makes them ideal for this task. Deep\nneural networks are, however, not only computationally intensive and energy\ninefficient but also require a large amount of memory. To address these\nchallenges, we propose a shallow gated recurrent unit (GRU) architecture\nsuitable for resource-constrained applications. This paper describes the\nimplementation of the Tiny Eats GRU, a shallow GRU neural network, on a low\npower micro-controller, Arm Cortex M0+, to classify eating episodes. Tiny Eats\nGRU is a hybrid of the traditional GRU [2] and eGRU [3] to make it small and\nfast enough to fit on the Arm Cortex M0+ with comparable accuracy to the\ntraditional GRU. The Tiny Eats GRU utilizes only 4% of the Arm Cortex M0+\nmemory and identifies eating or non-eating episodes with 6 ms latency and\naccuracy of 95.15%.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:43:30 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nyamukuru", "Maria T.", ""], ["Odame", "Kofi M.", ""]]}, {"id": "2003.06700", "submitter": "Xipeng Shen", "authors": "Shaoshan Liu, Bin Ren, Xipeng Shen, Yanzhi Wang", "title": "CoCoPIE: Making Mobile AI Sweet As PIE --Compression-Compilation\n  Co-Design Goes a Long Way", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming hardware is the major constraint for enabling real-time mobile\nintelligence, the industry has mainly dedicated their efforts to developing\nspecialized hardware accelerators for machine learning and inference. This\narticle challenges the assumption. By drawing on a recent real-time AI\noptimization framework CoCoPIE, it maintains that with effective\ncompression-compiler co-design, it is possible to enable real-time artificial\nintelligence on mainstream end devices without special hardware. CoCoPIE is a\nsoftware framework that holds numerous records on mobile AI: the first\nframework that supports all main kinds of DNNs, from CNNs to RNNs, transformer,\nlanguage models, and so on; the fastest DNN pruning and acceleration framework,\nup to 180X faster compared with current DNN pruning on other frameworks such as\nTensorFlow-Lite; making many representative AI applications able to run in\nreal-time on off-the-shelf mobile devices that have been previously regarded\npossible only with special hardware support; making off-the-shelf mobile\ndevices outperform a number of representative ASIC and FPGA solutions in terms\nof energy efficiency and/or performance.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:53:05 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 10:45:20 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 21:05:24 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Liu", "Shaoshan", ""], ["Ren", "Bin", ""], ["Shen", "Xipeng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2003.06706", "submitter": "Rickard Br\\\"uel Gabrielsson", "authors": "Rickard Br\\\"uel-Gabrielsson", "title": "Universal Function Approximation on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we produce a framework for constructing universal function\napproximators on graph isomorphism classes. We prove how this framework comes\nwith a collection of theoretically desirable properties and enables novel\nanalysis. We show how this allows us to achieve state-of-the-art performance on\nfour different well-known datasets in graph classification and separate classes\nof graphs that other graph-learning methods cannot. Our approach is inspired by\npersistent homology, dependency parsing for NLP, and multivalued functions. The\ncomplexity of the underlying algorithm is O(#edges x #nodes) and code is\npublicly available\n(https://github.com/bruel-gabrielsson/universal-function-approximation-on-graphs).\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 21:12:33 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:06:02 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 07:58:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Br\u00fcel-Gabrielsson", "Rickard", ""]]}, {"id": "2003.06709", "submitter": "Bei Peng", "authors": "Bei Peng, Tabish Rashid, Christian A. Schroeder de Witt,\n  Pierre-Alexandre Kamienny, Philip H. S. Torr, Wendelin B\\\"ohmer, Shimon\n  Whiteson", "title": "FACMAC: Factored Multi-Agent Centralised Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose FACtored Multi-Agent Centralised policy gradients (FACMAC), a new\nmethod for cooperative multi-agent reinforcement learning in both discrete and\ncontinuous action spaces. Like MADDPG, a popular multi-agent actor-critic\nmethod, our approach uses deep deterministic policy gradients to learn\npolicies. However, FACMAC learns a centralised but factored critic, which\ncombines per-agent utilities into the joint action-value function via a\nnon-linear monotonic function, as in QMIX, a popular multi-agent Q-learning\nalgorithm. However, unlike QMIX, there are no inherent constraints on factoring\nthe critic. We thus also employ a nonmonotonic factorisation and empirically\ndemonstrate that its increased representational capacity allows it to solve\nsome tasks that cannot be solved with monolithic, or monotonically factored\ncritics. In addition, FACMAC uses a centralised policy gradient estimator that\noptimises over the entire joint action space, rather than optimising over each\nagent's action space separately as in MADDPG. This allows for more coordinated\npolicy changes and fully reaps the benefits of a centralised critic. We\nevaluate FACMAC on variants of the multi-agent particle environments, a novel\nmulti-agent MuJoCo benchmark, and a challenging set of StarCraft II\nmicromanagement tasks. Empirical results demonstrate FACMAC's superior\nperformance over MADDPG and other baselines on all three domains.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 21:29:09 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 14:24:57 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 05:32:55 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 21:02:07 GMT"}, {"version": "v5", "created": "Fri, 7 May 2021 14:03:40 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Peng", "Bei", ""], ["Rashid", "Tabish", ""], ["de Witt", "Christian A. Schroeder", ""], ["Kamienny", "Pierre-Alexandre", ""], ["Torr", "Philip H. S.", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2003.06729", "submitter": "I. Zeki Yalniz", "authors": "Karishma Sharma, Pinar Donmez, Enming Luo, Yan Liu, I. Zeki Yalniz", "title": "NoiseRank: Unsupervised Label Noise Reduction with Dependence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label noise is increasingly prevalent in datasets acquired from noisy\nchannels. Existing approaches that detect and remove label noise generally rely\non some form of supervision, which is not scalable and error-prone. In this\npaper, we propose NoiseRank, for unsupervised label noise reduction using\nMarkov Random Fields (MRF). We construct a dependence model to estimate the\nposterior probability of an instance being incorrectly labeled given the\ndataset, and rank instances based on their estimated probabilities. Our method\n1) Does not require supervision from ground-truth labels, or priors on label or\nnoise distribution. 2) It is interpretable by design, enabling transparency in\nlabel noise removal. 3) It is agnostic to classifier architecture/optimization\nframework and content modality. These advantages enable wide applicability in\nreal noise settings, unlike prior works constrained by one or more conditions.\nNoiseRank improves state-of-the-art classification on Food101-N (~20% noise),\nand is effective on high noise Clothing-1M (~40% noise).\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 01:10:25 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Sharma", "Karishma", ""], ["Donmez", "Pinar", ""], ["Luo", "Enming", ""], ["Liu", "Yan", ""], ["Yalniz", "I. Zeki", ""]]}, {"id": "2003.06740", "submitter": "Max Simchowitz", "authors": "Esther Rolf and Max Simchowitz and Sarah Dean and Lydia T. Liu and\n  Daniel Bj\\\"orkegren and Moritz Hardt and Joshua Blumenstock", "title": "Balancing Competing Objectives with Noisy Data: Score-Based Classifiers\n  for Welfare-Aware Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While real-world decisions involve many competing objectives, algorithmic\ndecisions are often evaluated with a single objective function. In this paper,\nwe study algorithmic policies which explicitly trade off between a private\nobjective (such as profit) and a public objective (such as social welfare). We\nanalyze a natural class of policies which trace an empirical Pareto frontier\nbased on learned scores, and focus on how such decisions can be made in noisy\nor data-limited regimes. Our theoretical results characterize the optimal\nstrategies in this class, bound the Pareto errors due to inaccuracies in the\nscores, and show an equivalence between optimal strategies and a rich class of\nfairness-constrained profit-maximizing policies. We then present empirical\nresults in two different contexts -- online content recommendation and\nsustainable abalone fisheries -- to underscore the applicability of our\napproach to a wide range of practical decisions. Taken together, these results\nshed light on inherent trade-offs in using machine learning for decisions that\nimpact social welfare.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 02:49:39 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 00:34:56 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 01:00:08 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 03:57:38 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Rolf", "Esther", ""], ["Simchowitz", "Max", ""], ["Dean", "Sarah", ""], ["Liu", "Lydia T.", ""], ["Bj\u00f6rkegren", "Daniel", ""], ["Hardt", "Moritz", ""], ["Blumenstock", "Joshua", ""]]}, {"id": "2003.06746", "submitter": "Yan Hong", "authors": "Yan Hong, Li Niu, Jianfu Zhang, Liqing Zhang", "title": "Beyond without Forgetting: Multi-Task Learning for Classification with\n  Disjoint Datasets", "comments": "This paper is accepted by ICME 2020(http://www.2020.ieeeicme.org/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task Learning (MTL) for classification with disjoint datasets aims to\nexplore MTL when one task only has one labeled dataset. In existing methods,\nfor each task, the unlabeled datasets are not fully exploited to facilitate\nthis task. Inspired by semi-supervised learning, we use unlabeled datasets with\npseudo labels to facilitate each task. However, there are two major issues: 1)\nthe pseudo labels are very noisy; 2) the unlabeled datasets and the labeled\ndataset for each task has considerable data distribution mismatch. To address\nthese issues, we propose our MTL with Selective Augmentation (MTL-SA) method to\nselect the training samples in unlabeled datasets with confident pseudo labels\nand close data distribution to the labeled dataset. Then, we use the selected\ntraining samples to add information and use the remaining training samples to\npreserve information. Extensive experiments on face-centric and human-centric\napplications demonstrate the effectiveness of our MTL-SA method.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 03:19:18 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hong", "Yan", ""], ["Niu", "Li", ""], ["Zhang", "Jianfu", ""], ["Zhang", "Liqing", ""]]}, {"id": "2003.06769", "submitter": "Lei Wang", "authors": "Lei Wang, Wenbin Huang, Yuanpeng Li, Julian Evans, Sailing He", "title": "Multi-AI competing and winning against humans in iterated\n  Rock-Paper-Scissors game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting and modeling human behavior and finding trends within human\ndecision-making processes is a major problem of social science. Rock Paper\nScissors (RPS) is the fundamental strategic question in many game theory\nproblems and real-world competitions. Finding the right approach to beat a\nparticular human opponent is challenging. Here we use an AI (artificial\nintelligence) algorithm based on Markov Models of one fixed memory length\n(abbreviated as \"single AI\") to compete against humans in an iterated RPS game.\nWe model and predict human competition behavior by combining many Markov Models\nwith different fixed memory lengths (abbreviated as \"multi-AI\"), and develop an\narchitecture of multi-AI with changeable parameters to adapt to different\ncompetition strategies. We introduce a parameter called \"focus length\" (a\npositive number such as 5 or 10) to control the speed and sensitivity for our\nmulti-AI to adapt to the opponent's strategy change. The focus length is the\nnumber of previous rounds that the multi-AI should look at when determining\nwhich Single-AI has the best performance and should choose to play for the next\ngame. We experimented with 52 different people, each playing 300 rounds\ncontinuously against one specific multi-AI model, and demonstrated that our\nstrategy could win against more than 95% of human opponents.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 06:39:59 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 04:57:39 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Lei", ""], ["Huang", "Wenbin", ""], ["Li", "Yuanpeng", ""], ["Evans", "Julian", ""], ["He", "Sailing", ""]]}, {"id": "2003.06778", "submitter": "Mark Collier", "authors": "Mark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton, Jesse\n  Berent", "title": "A Simple Probabilistic Method for Deep Classification under\n  Input-Dependent Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets with noisy labels are a common occurrence in practical applications\nof classification methods. We propose a simple probabilistic method for\ntraining deep classifiers under input-dependent (heteroscedastic) label noise.\nWe assume an underlying heteroscedastic generative process for noisy labels. To\nmake gradient based training feasible we use a temperature parameterized\nsoftmax as a smooth approximation to the assumed generative process. We\nillustrate that the softmax temperature controls a bias-variance trade-off for\nthe approximation. By tuning the softmax temperature, we improve accuracy,\nlog-likelihood and calibration on both image classification benchmarks with\ncontrolled label noise as well as Imagenet-21k which has naturally occurring\nlabel noise. For image segmentation, our method increases the mean IoU on the\nPASCAL VOC and Cityscapes datasets by more than 1% over the state-of-the-art\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 08:15:15 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:08:08 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 20:08:51 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Collier", "Mark", ""], ["Mustafa", "Basil", ""], ["Kokiopoulou", "Efi", ""], ["Jenatton", "Rodolphe", ""], ["Berent", "Jesse", ""]]}, {"id": "2003.06795", "submitter": "John Lawson", "authors": "John Lawson", "title": "Towards automated kernel selection in machine learning systems: A SYCL\n  case study", "comments": "4 pages, 4 figures, 1 table. Accepted to AsHES workshop at IPDPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated tuning of compute kernels is a popular area of research, mainly\nfocused on finding optimal kernel parameters for a problem with fixed input\nsizes. This approach is good for deploying machine learning models, where the\nnetwork topology is constant, but machine learning research often involves\nchanging network topologies and hyperparameters. Traditional kernel auto-tuning\nhas limited impact in this case; a more general selection of kernels is\nrequired for libraries to accelerate machine learning research.\n  In this paper we present initial results using machine learning to select\nkernels in a case study deploying high performance SYCL kernels in libraries\nthat target a range of heterogeneous devices from desktop GPUs to embedded\naccelerators. The techniques investigated apply more generally and could\nsimilarly be integrated with other heterogeneous programming systems. By\ncombining auto-tuning and machine learning these kernel selection processes can\nbe deployed with little developer effort to achieve high performance on new\nhardware.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 11:23:36 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Lawson", "John", ""]]}, {"id": "2003.06804", "submitter": "Chris U. Carmona", "authors": "Chris U. Carmona and Geoff K. Nicholls", "title": "Semi-Modular Inference: enhanced learning in multi-modular models by\n  tempering the influence of components", "comments": "for associated R package to reproduce results, see\n  https://github.com/christianu7/aistats2020smi", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian statistical inference loses predictive optimality when generative\nmodels are misspecified.\n  Working within an existing coherent loss-based generalisation of Bayesian\ninference, we show existing Modular/Cut-model inference is coherent, and write\ndown a new family of Semi-Modular Inference (SMI) schemes, indexed by an\ninfluence parameter, with Bayesian inference and Cut-models as special cases.\nWe give a meta-learning criterion and estimation procedure to choose the\ninference scheme. This returns Bayesian inference when there is no\nmisspecification.\n  The framework applies naturally to Multi-modular models. Cut-model inference\nallows directed information flow from well-specified modules to misspecified\nmodules, but not vice versa. An existing alternative power posterior method\ngives tunable but undirected control of information flow, improving prediction\nin some settings. In contrast, SMI allows tunable and directed information flow\nbetween modules.\n  We illustrate our methods on two standard test cases from the literature and\na motivating archaeological data set.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 11:55:55 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Carmona", "Chris U.", ""], ["Nicholls", "Geoff K.", ""]]}, {"id": "2003.06814", "submitter": "ShawnXY Yang", "authors": "Xiao Yang, Yinpeng Dong, Tianyu Pang, Jun Zhu, Hang Su", "title": "Towards Privacy Protection by Generating Adversarial Identity Masks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As billions of personal data such as photos are shared through social media\nand network, the privacy and security of data have drawn an increasing\nattention. Several attempts have been made to alleviate the leakage of identity\ninformation with the aid of image obfuscation techniques. However, most of the\npresent results are either perceptually unsatisfactory or ineffective against\nreal-world recognition systems. In this paper, we argue that an algorithm for\nprivacy protection must block the ability of automatic inference of the\nidentity and at the same time, make the resultant image natural from the users'\npoint of view. To achieve this, we propose a targeted identity-protection\niterative method (TIP-IM), which can generate natural face images by adding\nadversarial identity masks to conceal ones' identity against a recognition\nsystem. Extensive experiments on various state-of-the-art face recognition\nmodels demonstrate the effectiveness of our proposed method on alleviating the\nidentity leakage of face images, without sacrificing? the visual quality of the\nprotected images.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 12:45:10 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Zhu", "Jun", ""], ["Su", "Hang", ""]]}, {"id": "2003.06820", "submitter": "Amir Rahimi", "authors": "Amir Rahimi, Amirreza Shaban, Ching-An Cheng, Richard Hartley, Byron\n  Boots", "title": "Intra Order-preserving Functions for Calibration of Multi-Class Neural\n  Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting calibrated confidence scores for multi-class deep networks is\nimportant for avoiding rare but costly mistakes. A common approach is to learn\na post-hoc calibration function that transforms the output of the original\nnetwork into calibrated confidence scores while maintaining the network's\naccuracy. However, previous post-hoc calibration techniques work only with\nsimple calibration functions, potentially lacking sufficient representation to\ncalibrate the complex function landscape of deep networks. In this work, we aim\nto learn general post-hoc calibration functions that can preserve the top-k\npredictions of any deep network. We call this family of functions intra\norder-preserving functions. We propose a new neural network architecture that\nrepresents a class of intra order-preserving functions by combining common\nneural network components. Additionally, we introduce order-invariant and\ndiagonal sub-families, which can act as regularization for better\ngeneralization when the training data size is small. We show the effectiveness\nof the proposed method across a wide range of datasets and classifiers. Our\nmethod outperforms state-of-the-art post-hoc calibration methods, namely\ntemperature scaling and Dirichlet calibration, in several evaluation metrics\nfor the task.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 12:57:21 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 06:59:28 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Rahimi", "Amir", ""], ["Shaban", "Amirreza", ""], ["Cheng", "Ching-An", ""], ["Hartley", "Richard", ""], ["Boots", "Byron", ""]]}, {"id": "2003.06868", "submitter": "Maximilian Schleich", "authors": "Leopoldo Bertossi, Jordan Li, Maximilian Schleich, Dan Suciu,\n  Zografoula Vagena", "title": "Causality-based Explanation of Classification Outcomes", "comments": "16 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple definition of an explanation for the outcome of a\nclassifier based on concepts from causality. We compare it with previously\nproposed notions of explanation, and study their complexity. We conduct an\nexperimental evaluation with two real datasets from the financial domain.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 17:00:37 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 04:24:18 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Li", "Jordan", ""], ["Schleich", "Maximilian", ""], ["Suciu", "Dan", ""], ["Vagena", "Zografoula", ""]]}, {"id": "2003.06878", "submitter": "Yusuke Tashiro", "authors": "Yusuke Tashiro, Yang Song, Stefano Ermon", "title": "Diversity can be Transferred: Output Diversification for White- and\n  Black-box Attacks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks often involve random perturbations of the inputs drawn\nfrom uniform or Gaussian distributions, e.g., to initialize optimization-based\nwhite-box attacks or generate update directions in black-box attacks. These\nsimple perturbations, however, could be sub-optimal as they are agnostic to the\nmodel being attacked. To improve the efficiency of these attacks, we propose\nOutput Diversified Sampling (ODS), a novel sampling strategy that attempts to\nmaximize diversity in the target model's outputs among the generated samples.\nWhile ODS is a gradient-based strategy, the diversity offered by ODS is\ntransferable and can be helpful for both white-box and black-box attacks via\nsurrogate models. Empirically, we demonstrate that ODS significantly improves\nthe performance of existing white-box and black-box attacks. In particular, ODS\nreduces the number of queries needed for state-of-the-art black-box attacks on\nImageNet by a factor of two.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 17:49:25 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:44:53 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 00:12:48 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Tashiro", "Yusuke", ""], ["Song", "Yang", ""], ["Ermon", "Stefano", ""]]}, {"id": "2003.06898", "submitter": "Fei Feng Ms.", "authors": "Fei Feng, Ruosong Wang, Wotao Yin, Simon S. Du, Lin F. Yang", "title": "Provably Efficient Exploration for Reinforcement Learning Using\n  Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the prevailing paradigm of using unsupervised learning for\nefficient exploration in reinforcement learning (RL) problems\n[tang2017exploration,bellemare2016unifying], we investigate when this paradigm\nis provably efficient. We study episodic Markov decision processes with rich\nobservations generated from a small number of latent states. We present a\ngeneral algorithmic framework that is built upon two components: an\nunsupervised learning algorithm and a no-regret tabular RL algorithm.\nTheoretically, we prove that as long as the unsupervised learning algorithm\nenjoys a polynomial sample complexity guarantee, we can find a near-optimal\npolicy with sample complexity polynomial in the number of latent states, which\nis significantly smaller than the number of observations. Empirically, we\ninstantiate our framework on a class of hard exploration problems to\ndemonstrate the practicality of our theory.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:23:59 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:17:18 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 23:48:01 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 01:04:54 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Feng", "Fei", ""], ["Wang", "Ruosong", ""], ["Yin", "Wotao", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""]]}, {"id": "2003.06899", "submitter": "Andre Mendes", "authors": "Andre Mendes, Julian Togelius, Leandro dos Santos Coelho", "title": "Adversarial Encoder-Multi-Task-Decoder for Multi-Stage Processes", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-stage processes, decisions occur in an ordered sequence of stages.\nEarly stages usually have more observations with general information\n(easier/cheaper to collect), while later stages have fewer observations but\nmore specific data. This situation can be represented by a dual funnel\nstructure, in which the sample size decreases from one stage to the other while\nthe information increases. Training classifiers in this scenario is challenging\nsince information in the early stages may not contain distinct patterns to\nlearn (underfitting). In contrast, the small sample size in later stages can\ncause overfitting. We address both cases by introducing a framework that\ncombines adversarial autoencoders (AAE), multi-task learning (MTL), and\nmulti-label semi-supervised learning (MLSSL). We improve the decoder of the AAE\nwith an MTL component so it can jointly reconstruct the original input and use\nfeature nets to predict the features for the next stages. We also introduce a\nsequence constraint in the output of an MLSSL classifier to guarantee the\nsequential pattern in the predictions. Using real-world data from different\ndomains (selection process, medical diagnosis), we show that our approach\noutperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:30:31 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mendes", "Andre", ""], ["Togelius", "Julian", ""], ["Coelho", "Leandro dos Santos", ""]]}, {"id": "2003.06926", "submitter": "Daniele Musso", "authors": "Daniele Musso", "title": "Stochastic gradient descent with random learning rate", "comments": "improved theoretical and experimental analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to optimize neural networks with a uniformly-distributed random\nlearning rate. The associated stochastic gradient descent algorithm can be\napproximated by continuous stochastic equations and analyzed within the\nFokker-Planck formalism. In the small learning rate regime, the training\nprocess is characterized by an effective temperature which depends on the\naverage learning rate, the mini-batch size and the momentum of the optimization\nalgorithm. By comparing the random learning rate protocol with cyclic and\nconstant protocols, we suggest that the random choice is generically the best\nstrategy in the small learning rate regime, yielding better regularization\nwithout extra computational cost. We provide supporting evidence through\nexperiments on both shallow, fully-connected and deep, convolutional neural\nnetworks for image classification on the MNIST and CIFAR10 datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 21:36:46 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 15:26:43 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 13:58:34 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 13:42:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Musso", "Daniele", ""]]}, {"id": "2003.06959", "submitter": "Pei Xu", "authors": "Pei Xu and Ioannis Karamouzas", "title": "Adaptive Discretization for Continuous Control using Particle Filtering\n  Policy Network", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling the movements of highly articulated agents and robots has been a\nlong-standing challenge to model-free deep reinforcement learning. In this\npaper, we propose a simple, yet general, framework for improving the\nperformance of policy gradient algorithms by discretizing the continuous action\nspace. Instead of using a fixed set of predetermined atomic actions, we exploit\nparticle filtering to adaptively discretize actions during training and track\nthe posterior policy distribution represented as a mixture of Gaussians. The\nresulting policy can replace the original continuous policy of any given policy\ngradient algorithm without changing its underlying model architecture. We\ndemonstrate the applicability of our approach to state-of-the-art on-policy and\noff-policy baselines in challenging control tasks. Baselines using our\nparticle-based policies achieve better final performance and speed of\nconvergence as compared to corresponding continuous implementations and\nimplementations that rely on fixed discretization schemes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 00:35:36 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 15:27:37 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 22:49:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Xu", "Pei", ""], ["Karamouzas", "Ioannis", ""]]}, {"id": "2003.06961", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, George Michailidis", "title": "Online detection of local abrupt changes in high-dimensional Gaussian\n  graphical models", "comments": "40 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of identifying change points in high-dimensional Gaussian\ngraphical models (GGMs) in an online fashion is of interest, due to new\napplications in biology, economics and social sciences. The offline version of\nthe problem, where all the data are a priori available, has led to a number of\nmethods and associated algorithms involving regularized loss functions.\nHowever, for the online version, there is currently only a single work in the\nliterature that develops a sequential testing procedure and also studies its\nasymptotic false alarm probability and power. The latter test is best suited\nfor the detection of change points driven by global changes in the structure of\nthe precision matrix of the GGM, in the sense that many edges are involved.\nNevertheless, in many practical settings the change point is driven by local\nchanges, in the sense that only a small number of edges exhibit changes. To\nthat end, we develop a novel test to address this problem that is based on the\n$\\ell_\\infty$ norm of the normalized covariance matrix of an appropriately\nselected portion of incoming data. The study of the asymptotic distribution of\nthe proposed test statistic under the null (no presence of a change point) and\nthe alternative (presence of a change point) hypotheses requires new technical\ntools that examine maxima of graph-dependent Gaussian random variables, and\nthat of independent interest. It is further shown that these tools lead to the\nimposition of mild regularity conditions for key model parameters, instead of\nmore stringent ones required by leveraging previously used tools in related\nproblems in the literature. Numerical work on synthetic data illustrates the\ngood performance of the proposed detection procedure both in terms of\ncomputational and statistical efficiency across numerous experimental settings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 00:41:34 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Michailidis", "George", ""]]}, {"id": "2003.06973", "submitter": "Avgoustinos Vouros", "authors": "Avgoustinos Vouros and Eleni Vasilaki", "title": "A semi-supervised sparse K-Means algorithm", "comments": "Under consideration at Pattern Recognition Letters. 2 figures, 1\n  table, supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of data clustering with unidentified feature quality\nand when a small amount of labelled data is provided. An unsupervised sparse\nclustering method can be employed in order to detect the subgroup of features\nnecessary for clustering and a semi-supervised method can use the labelled data\nto create constraints and enhance the clustering solution. In this paper we\npropose a K-Means variant that employs these techniques. We show that the\nalgorithm maintains the high performance of other semi-supervised algorithms\nand in addition preserves the ability to identify informative from\nuninformative features. We examine the performance of the algorithm on\nsynthetic and real world data sets. We use scenarios of different number and\ntypes of constraints as well as different clustering initialisation methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 02:05:23 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 15:06:12 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 15:16:34 GMT"}, {"version": "v4", "created": "Tue, 12 May 2020 18:14:26 GMT"}, {"version": "v5", "created": "Sun, 18 Oct 2020 14:11:47 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Vouros", "Avgoustinos", ""], ["Vasilaki", "Eleni", ""]]}, {"id": "2003.06979", "submitter": "Bhavya Kailkhura", "authors": "Saikiran Bulusu, Bhavya Kailkhura, Bo Li, Pramod K. Varshney, Dawn\n  Song", "title": "Anomalous Example Detection in Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) is vulnerable to out-of-distribution and adversarial\nexamples resulting in incorrect outputs. To make DL more robust, several\nposthoc (or runtime) anomaly detection techniques to detect (and discard) these\nanomalous samples have been proposed in the recent past. This survey tries to\nprovide a structured and comprehensive overview of the research on anomaly\ndetection for DL based applications. We provide a taxonomy for existing\ntechniques based on their underlying assumptions and adopted approaches. We\ndiscuss various techniques in each of the categories and provide the relative\nstrengths and weaknesses of the approaches. Our goal in this survey is to\nprovide an easier yet better understanding of the techniques belonging to\ndifferent categories in which research has been done on this topic. Finally, we\nhighlight the unsolved research challenges while applying anomaly detection\ntechniques in DL systems and present some high-impact future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 02:47:23 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 21:59:16 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bulusu", "Saikiran", ""], ["Kailkhura", "Bhavya", ""], ["Li", "Bo", ""], ["Varshney", "Pramod K.", ""], ["Song", "Dawn", ""]]}, {"id": "2003.07017", "submitter": "Yining Wang", "authors": "Yining Wang and Xi Chen and Xiangyu Chang and Dongdong Ge", "title": "Uncertainty Quantification for Demand Prediction in Contextual Dynamic\n  Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven sequential decision has found a wide range of applications in\nmodern operations management, such as dynamic pricing, inventory control, and\nassortment optimization. Most existing research on data-driven sequential\ndecision focuses on designing an online policy to maximize the revenue.\nHowever, the research on uncertainty quantification on the underlying true\nmodel function (e.g., demand function), a critical problem for practitioners,\nhas not been well explored. In this paper, using the problem of demand function\nprediction in dynamic pricing as the motivating example, we study the problem\nof constructing accurate confidence intervals for the demand function. The main\nchallenge is that sequentially collected data leads to significant\ndistributional bias in the maximum likelihood estimator or the empirical risk\nminimization estimate, making classical statistics approaches such as the\nWald's test no longer valid. We address this challenge by developing a debiased\napproach and provide the asymptotic normality guarantee of the debiased\nestimator. Based this the debiased estimator, we provide both point-wise and\nuniform confidence intervals of the demand function.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:21:58 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 16:39:33 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Xi", ""], ["Chang", "Xiangyu", ""], ["Ge", "Dongdong", ""]]}, {"id": "2003.07070", "submitter": "Tiago Peixoto", "authors": "Tiago P. Peixoto", "title": "Merge-split Markov chain Monte Carlo for community detection", "comments": "13 pages, 6 figures. Code available at\n  https://graph-tool.skewed.de/static/doc/demos/inference/inference.html", "journal-ref": "Phys. Rev. E 102, 012305 (2020)", "doi": "10.1103/PhysRevE.102.012305", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a Markov chain Monte Carlo scheme based on merges and splits of\ngroups that is capable of efficiently sampling from the posterior distribution\nof network partitions, defined according to the stochastic block model (SBM).\nWe demonstrate how schemes based on the move of single nodes between groups\nsystematically fail at correctly sampling from the posterior distribution even\non small networks, and how our merge-split approach behaves significantly\nbetter, and improves the mixing time of the Markov chain by several orders of\nmagnitude in typical cases. We also show how the scheme can be\nstraightforwardly extended to nested versions of the SBM, yielding\nasymptotically exact samples of hierarchical network partitions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 08:26:35 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 21:24:44 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 18:12:23 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 16:45:49 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Peixoto", "Tiago P.", ""]]}, {"id": "2003.07077", "submitter": "Ya-Lin Zhang", "authors": "Ya-Lin Zhang and Longfei Li", "title": "Interpretable MTL from Heterogeneous Domains using Boosted Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) aims at improving the generalization performance of\nseveral related tasks by leveraging useful information contained in them.\nHowever, in industrial scenarios, interpretability is always demanded, and the\ndata of different tasks may be in heterogeneous domains, making the existing\nmethods unsuitable or unsatisfactory. In this paper, following the philosophy\nof boosted tree, we proposed a two-stage method. In stage one, a common model\nis built to learn the commonalities using the common features of all instances.\nDifferent from the training of conventional boosted tree model, we proposed a\nregularization strategy and an early-stopping mechanism to optimize the\nmulti-task learning process. In stage two, started by fitting the residual\nerror of the common model, a specific model is constructed with the\ntask-specific instances to further boost the performance. Experiments on both\nbenchmark and real-world datasets validate the effectiveness of the proposed\nmethod. What's more, interpretability can be naturally obtained from the tree\nbased method, satisfying the industrial needs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 08:58:51 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Zhang", "Ya-Lin", ""], ["Li", "Longfei", ""]]}, {"id": "2003.07088", "submitter": "Tanvi Verma", "authors": "Tanvi Verma, Pradeep Varakantham", "title": "Value Variance Minimization for Learning Approximate Equilibrium in\n  Aggregation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For effective matching of resources (e.g., taxis, food, bikes, shopping\nitems) to customer demand, aggregation systems have been extremely successful.\nIn aggregation systems, a central entity (e.g., Uber, Food Panda, Ofo)\naggregates supply (e.g., drivers, delivery personnel) and matches demand to\nsupply on a continuous basis (sequential decisions). Due to the objective of\nthe central entity to maximize its profits, individual suppliers get sacrificed\nthereby creating incentive for individuals to leave the system. In this paper,\nwe consider the problem of learning approximate equilibrium solutions (win-win\nsolutions) in aggregation systems, so that individuals have an incentive to\nremain in the aggregation system.\n  Unfortunately, such systems have thousands of agents and have to consider\ndemand uncertainty and the underlying problem is a (Partially Observable)\nStochastic Game. Given the significant complexity of learning or planning in a\nstochastic game, we make three key contributions: (a) To exploit\ninfinitesimally small contribution of each agent and anonymity (reward and\ntransitions between agents are dependent on agent counts) in interactions, we\nrepresent this as a Multi-Agent Reinforcement Learning (MARL) problem that\nbuilds on insights from non-atomic congestion games model; (b) We provide a\nnovel variance reduction mechanism for moving joint solution towards Nash\nEquilibrium that exploits the infinitesimally small contribution of each agent;\nand finally (c) We provide detailed results on three different domains to\ndemonstrate the utility of our approach in comparison to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:02:42 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Verma", "Tanvi", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "2003.07132", "submitter": "Aijun Zhang", "authors": "Zebin Yang, Aijun Zhang, Agus Sudjianto", "title": "GAMI-Net: An Explainable Neural Network based on Generalized Additive\n  Models with Structured Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability is an inevitable problem when using neural\nnetwork models in real applications. In this paper, an explainable neural\nnetwork based on generalized additive models with structured interactions\n(GAMI-Net) is proposed to pursue a good balance between prediction accuracy and\nmodel interpretability. GAMI-Net is a disentangled feedforward network with\nmultiple additive subnetworks; each subnetwork consists of multiple hidden\nlayers and is designed for capturing one main effect or one pairwise\ninteraction. Three interpretability aspects are further considered, including\na) sparsity, to select the most significant effects for parsimonious\nrepresentations; b) heredity, a pairwise interaction could only be included\nwhen at least one of its parent main effects exists; and c) marginal clarity,\nto make main effects and pairwise interactions mutually distinguishable. An\nadaptive training algorithm is developed, where main effects are first trained\nand then pairwise interactions are fitted to the residuals. Numerical\nexperiments on both synthetic functions and real-world datasets show that the\nproposed model enjoys superior interpretability and it maintains competitive\nprediction accuracy in comparison to the explainable boosting machine and other\nclassic machine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 11:51:38 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 15:02:15 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yang", "Zebin", ""], ["Zhang", "Aijun", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2003.07158", "submitter": "Jianbin Lin Lin", "authors": "Jianbin Lin, Daixin Wang, Lu Guan, Yin Zhao, Binqiang Zhao, Jun Zhou,\n  Xiaolong Li, and Yuan Qi", "title": "RNE: A Scalable Network Embedding for Billion-scale Recommendation", "comments": "PAKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-16145-3_34", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays designing a real recommendation system has been a critical problem\nfor both academic and industry. However, due to the huge number of users and\nitems, the diversity and dynamic property of the user interest, how to design a\nscalable recommendation system, which is able to efficiently produce effective\nand diverse recommendation results on billion-scale scenarios, is still a\nchallenging and open problem for existing methods. In this paper, given the\nuser-item interaction graph, we propose RNE, a data-efficient\nRecommendation-based Network Embedding method, to give personalized and diverse\nitems to users. Specifically, we propose a diversity- and dynamics-aware\nneighbor sampling method for network embedding. On the one hand, the method is\nable to preserve the local structure between the users and items while modeling\nthe diversity and dynamic property of the user interest to boost the\nrecommendation quality. On the other hand the sampling method can reduce the\ncomplexity of the whole method theoretically to make it possible for\nbillion-scale recommendation. We also implement the designed algorithm in a\ndistributed way to further improves its scalability. Experimentally, we deploy\nRNE on a recommendation scenario of Taobao, the largest E-commerce platform in\nChina, and train it on a billion-scale user-item graph. As is shown on several\nonline metrics on A/B testing, RNE is able to achieve both high-quality and\ndiverse results compared with CF-based methods. We also conduct the offline\nexperiments on Pinterest dataset comparing with several state-of-the-art\nrecommendation methods and network embedding methods. The results demonstrate\nthat our method is able to produce a good result while runs much faster than\nthe baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 07:08:57 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 06:47:20 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Lin", "Jianbin", ""], ["Wang", "Daixin", ""], ["Guan", "Lu", ""], ["Zhao", "Yin", ""], ["Zhao", "Binqiang", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.07160", "submitter": "Bingqing Yu", "authors": "Bingqing Yu, Jacopo Tagliabue, Ciro Greco and Federico Bianchi", "title": "\"An Image is Worth a Thousand Features\": Scalable Product\n  Representations for In-Session Type-Ahead Personalization", "comments": null, "journal-ref": null, "doi": "10.1145/3366424.3386198", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of personalizing query completion in a digital\ncommerce setting, in which the bounce rate is typically high and recurring\nusers are rare. We focus on in-session personalization and improve a standard\nnoisy channel model by injecting dense vectors computed from product images at\nquery time. We argue that image-based personalization displays several\nadvantages over alternative proposals (from data availability to business\nscalability), and provide quantitative evidence and qualitative support on the\neffectiveness of the proposed methods. Finally, we show how a shared vector\nspace between similar shops can be used to improve the experience of users\nbrowsing across sites, opening up the possibility of applying zero-shot\nunsupervised personalization to increase conversions. This will prove to be\nparticularly relevant to retail groups that manage multiple brands and/or\nwebsites and to multi-tenant SaaS providers that serve multiple clients in the\nsame space.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 18:41:56 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yu", "Bingqing", ""], ["Tagliabue", "Jacopo", ""], ["Greco", "Ciro", ""], ["Bianchi", "Federico", ""]]}, {"id": "2003.07162", "submitter": "Jiwei Tan", "authors": "Xiang Li, Chao Wang, Jiwei Tan, Xiaoyi Zeng, Dan Ou, Bo Zheng", "title": "Adversarial Multimodal Representation Learning for Click-Through Rate\n  Prediction", "comments": "Accepted to WWW 2020, 10 pages", "journal-ref": null, "doi": "10.1145/3366423.3380163", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For better user experience and business effectiveness, Click-Through Rate\n(CTR) prediction has been one of the most important tasks in E-commerce.\nAlthough extensive CTR prediction models have been proposed, learning good\nrepresentation of items from multimodal features is still less investigated,\nconsidering an item in E-commerce usually contains multiple heterogeneous\nmodalities. Previous works either concatenate the multiple modality features,\nthat is equivalent to giving a fixed importance weight to each modality; or\nlearn dynamic weights of different modalities for different items through\ntechnique like attention mechanism. However, a problem is that there usually\nexists common redundant information across multiple modalities. The dynamic\nweights of different modalities computed by using the redundant information may\nnot correctly reflect the different importance of each modality. To address\nthis, we explore the complementarity and redundancy of modalities by\nconsidering modality-specific and modality-invariant features differently. We\npropose a novel Multimodal Adversarial Representation Network (MARN) for the\nCTR prediction task. A multimodal attention network first calculates the\nweights of multiple modalities for each item according to its modality-specific\nfeatures. Then a multimodal adversarial network learns modality-invariant\nrepresentations where a double-discriminators strategy is introduced. Finally,\nwe achieve the multimodal item representations by combining both\nmodality-specific and modality-invariant representations. We conduct extensive\nexperiments on both public and industrial datasets, and the proposed method\nconsistently achieves remarkable improvements to the state-of-the-art methods.\nMoreover, the approach has been deployed in an operational E-commerce system\nand online A/B testing further demonstrates the effectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 15:50:23 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Li", "Xiang", ""], ["Wang", "Chao", ""], ["Tan", "Jiwei", ""], ["Zeng", "Xiaoyi", ""], ["Ou", "Dan", ""], ["Zheng", "Bo", ""]]}, {"id": "2003.07180", "submitter": "Kushal Chakrabarti", "authors": "Kushal Chakrabarti, Nirupam Gupta and Nikhil Chopra", "title": "Iterative Pre-Conditioning to Expedite the Gradient-Descent Method", "comments": "Accepted for the proceedings of the 2020 American Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of multi-agent distributed optimization. In\nthis problem, there are multiple agents in the system, and each agent only\nknows its local cost function. The objective for the agents is to collectively\ncompute a common minimum of the aggregate of all their local cost functions. In\nprinciple, this problem is solvable using a distributed variant of the\ntraditional gradient-descent method, which is an iterative method. However, the\nspeed of convergence of the traditional gradient-descent method is highly\ninfluenced by the conditioning of the optimization problem being solved.\nSpecifically, the method requires a large number of iterations to converge to a\nsolution if the optimization problem is ill-conditioned.\n  In this paper, we propose an iterative pre-conditioning approach that can\nsignificantly attenuate the influence of the problem's conditioning on the\nconvergence-speed of the gradient-descent method. The proposed pre-conditioning\napproach can be easily implemented in distributed systems and has minimal\ncomputation and communication overhead. For now, we only consider a specific\ndistributed optimization problem wherein the individual local cost functions of\nthe agents are quadratic. Besides the theoretical guarantees, the improved\nconvergence speed of our approach is demonstrated through experiments on a real\ndata-set.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 16:30:01 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 04:04:42 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Chakrabarti", "Kushal", ""], ["Gupta", "Nirupam", ""], ["Chopra", "Nikhil", ""]]}, {"id": "2003.07182", "submitter": "Vincent Huang", "authors": "Bradley Butcher, Vincent S. Huang, Jeremy Reffin, Sema K. Sgaier,\n  Grace Charles, Novi Quadrianto", "title": "Causal datasheet: An approximate guide to practically assess Bayesian\n  networks in the real world", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In solving real-world problems like changing healthcare-seeking behaviors,\ndesigning interventions to improve downstream outcomes requires an\nunderstanding of the causal links within the system. Causal Bayesian Networks\n(BN) have been proposed as one such powerful method. In real-world\napplications, however, confidence in the results of BNs are often moderate at\nbest. This is due in part to the inability to validate against some ground\ntruth, as the DAG is not available. This is especially problematic if the\nlearned DAG conflicts with pre-existing domain doctrine. At the policy level,\none must justify insights generated by such analysis, preferably accompanying\nthem with uncertainty estimation. Here we propose a causal extension to the\ndatasheet concept proposed by Gebru et al (2018) to include approximate BN\nperformance expectations for any given dataset. To generate the results for a\nprototype Causal Datasheet, we constructed over 30,000 synthetic datasets with\nproperties mirroring characteristics of real data. We then recorded the results\ngiven by state-of-the-art structure learning algorithms. These results were\nused to populate the Causal Datasheet, and recommendations were automatically\ngenerated dependent on expected performance. As a proof of concept, we used our\nCausal Datasheet Generation Tool (CDG-T) to assign expected performance\nexpectations to a maternal health survey we conducted in Uttar Pradesh, India.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 23:31:11 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Butcher", "Bradley", ""], ["Huang", "Vincent S.", ""], ["Reffin", "Jeremy", ""], ["Sgaier", "Sema K.", ""], ["Charles", "Grace", ""], ["Quadrianto", "Novi", ""]]}, {"id": "2003.07186", "submitter": "Stefan Wunsch", "authors": "Stefan Wunsch and Simon J\\\"orger and Roger Wolf and G\\\"unter Quast", "title": "Optimal statistical inference in the presence of systematic\n  uncertainties using neural network optimization based on binned Poisson\n  likelihoods with nuisance parameters", "comments": null, "journal-ref": "Comput Softw Big Sci 5, 4 (2021)", "doi": "10.1007/s41781-020-00049-5", "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analysis in science, e.g., high-energy particle physics, is often\nsubject to an intractable likelihood if the observables and observations span a\nhigh-dimensional input space. Typically the problem is solved by reducing the\ndimensionality using feature engineering and histograms, whereby the latter\ntechnique allows to build the likelihood using Poisson statistics. However, in\nthe presence of systematic uncertainties represented by nuisance parameters in\nthe likelihood, the optimal dimensionality reduction with a minimal loss of\ninformation about the parameters of interest is not known. This work presents a\nnovel strategy to construct the dimensionality reduction with neural networks\nfor feature engineering and a differential formulation of histograms so that\nthe full workflow can be optimized with the result of the statistical\ninference, e.g., the variance of a parameter of interest, as objective. We\ndiscuss how this approach results in an estimate of the parameters of interest\nthat is close to optimal and the applicability of the technique is demonstrated\nwith a simple example based on pseudo-experiments and a more complex example\nfrom high-energy particle physics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 13:27:18 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 08:09:07 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 09:23:38 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Wunsch", "Stefan", ""], ["J\u00f6rger", "Simon", ""], ["Wolf", "Roger", ""], ["Quast", "G\u00fcnter", ""]]}, {"id": "2003.07193", "submitter": "Gustavo Paiva Guedes", "authors": "Flavio Carvalho and Gustavo Paiva Guedes", "title": "TF-IDFC-RF: A Novel Supervised Term Weighting Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis is a branch of Affective Computing usually considered a\nbinary classification task. In this line of reasoning, Sentiment Analysis can\nbe applied in several contexts to classify the attitude expressed in text\nsamples, for example, movie reviews, sarcasm, among others. A common approach\nto represent text samples is the use of the Vector Space Model to compute\nnumerical feature vectors consisting of the weight of terms. The most popular\nterm weighting scheme is TF-IDF (Term Frequency - Inverse Document Frequency).\nIt is an Unsupervised Weighting Scheme (UWS) since it does not consider the\nclass information in the weighting of terms. Apart from that, there are\nSupervised Weighting Schemes (SWS), which consider the class information on\nterm weighting calculation. Several SWS have been recently proposed,\ndemonstrating better results than TF-IDF. In this scenario, this work presents\na comparative study on different term weighting schemes and proposes a novel\nsupervised term weighting scheme, named as TF-IDFC-RF (Term Frequency - Inverse\nDocument Frequency in Class - Relevance Frequency). The effectiveness of\nTF-IDFC-RF is validated with SVM (Support Vector Machine) and NB (Naive Bayes)\nclassifiers on four commonly used Sentiment Analysis datasets. TF-IDFC-RF shows\npromising results, outperforming all other weighting schemes on two datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 21:31:46 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 03:23:15 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Carvalho", "Flavio", ""], ["Guedes", "Gustavo Paiva", ""]]}, {"id": "2003.07201", "submitter": "Maria B\\.ankestad", "authors": "Maria B{\\aa}nkestad, Jens Sj\\\"olund, Jalil Taghia, Thomas Sch\\\"on", "title": "The Elliptical Processes: a Family of Fat-tailed Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the elliptical processes -- a family of non-parametric\nprobabilistic models that subsumes the Gaussian process and the Student-t\nprocess. This generalization includes a range of new fat-tailed behaviors yet\nretains computational tractability. We base the elliptical processes on a\nrepresentation of elliptical distributions as a continuous mixture of Gaussian\ndistributions and derive closed-form expressions for the marginal and\nconditional distributions. We perform numerical experiments on robust\nregression using an elliptical process defined by a piecewise constant mixing\ndistribution, and show advantages compared with a Gaussian process. The\nelliptical processes may become a replacement for Gaussian processes in several\nsettings, including when the likelihood is not Gaussian or when accurate tail\nmodeling is critical.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 08:36:39 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 07:27:47 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["B\u00e5nkestad", "Maria", ""], ["Sj\u00f6lund", "Jens", ""], ["Taghia", "Jalil", ""], ["Sch\u00f6n", "Thomas", ""]]}, {"id": "2003.07274", "submitter": "Diogo Lopes", "authors": "Diogo Lopes and Ant\\'onio Ramires Fernandes and St\\'ephane Clain", "title": "An Hybrid Method for the Estimation of the Breast Mechanical Parameters", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several numerical models that describe real phenomena being used to\nsolve complex problems. For example, an accurate numerical breast model can\nprovide assistance to surgeons with visual information of the breast as a\nresult of a surgery simulation. The process of finding the model parameters\nrequires numeric inputs, either based in medical imaging techniques, or other\nmeasures. Inputs can be processed by iterative methods (inverse elasticity\nsolvers). Such solvers are highly robust and provide solutions within the\nrequired degree of accuracy. However, their computational complexity is costly.\nOn the other hand, machine learning based approaches provide outputs in\nreal-time. Although high accuracy rates can be achieved, these methods are not\nexempt from producing solutions outside the required degree of accuracy. In the\ncontext of real life situations, a non accurate solution might present\ncomplications to the patient.\n  We present an hybrid parameter estimation method to take advantage of the\npositive features of each of the aforementioned approaches. Our method\npreserves both the real-time performance of deep-learning methods, and the\nreliability of inverse elasticity solvers. The underlying reasoning behind our\nproposal is the fact that deep-learning methods, such as neural networks, can\nprovide accurate results in the majority of cases and they just need a\nfail-safe system to ensure its reliability. Hence, we propose using a\nMultilayer Neural Networks (MNN) to get an estimation which is in turn\nvalidated by a iterative solver. In case the MNN provides an estimation not\nwithin the required accuracy range, the solver refines the estimation until the\nrequired accuracy is achieved. Based on our results we can conclude that the\npresented hybrid method is able to complement the computational performance of\nMNNs with the robustness of iterative solver approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 11:21:37 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Lopes", "Diogo", ""], ["Fernandes", "Ant\u00f3nio Ramires", ""], ["Clain", "St\u00e9phane", ""]]}, {"id": "2003.07305", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Abhishek Gupta, Sergey Levine", "title": "DisCor: Corrective Feedback in Reinforcement Learning via Distribution\n  Correction", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning can learn effective policies for a wide range of\ntasks, but is notoriously difficult to use due to instability and sensitivity\nto hyperparameters. The reasons for this remain unclear. When using standard\nsupervised methods (e.g., for bandits), on-policy data collection provides\n\"hard negatives\" that correct the model in precisely those states and actions\nthat the policy is likely to visit. We call this phenomenon \"corrective\nfeedback.\" We show that bootstrapping-based Q-learning algorithms do not\nnecessarily benefit from this corrective feedback, and training on the\nexperience collected by the algorithm is not sufficient to correct errors in\nthe Q-function. In fact, Q-learning and related methods can exhibit\npathological interactions between the distribution of experience collected by\nthe agent and the policy induced by training on that experience, leading to\npotential instability, sub-optimal convergence, and poor results when learning\nfrom noisy, sparse or delayed rewards. We demonstrate the existence of this\nproblem, both theoretically and empirically. We then show that a specific\ncorrection to the data distribution can mitigate this issue. Based on these\nobservations, we propose a new algorithm, DisCor, which computes an\napproximation to this optimal distribution and uses it to re-weight the\ntransitions used for training, resulting in substantial improvements in a range\nof challenging RL settings, such as multi-task learning and learning from noisy\nreward signals. Blog post presenting a summary of this work is available at:\nhttps://bair.berkeley.edu/blog/2020/03/16/discor/.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 16:18:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Kumar", "Aviral", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""]]}, {"id": "2003.07329", "submitter": "Jize Zhang", "authors": "Jize Zhang and Bhavya Kailkhura and T. Yong-Jin Han", "title": "Mix-n-Match: Ensemble and Compositional Methods for Uncertainty\n  Calibration in Deep Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies the problem of post-hoc calibration of machine learning\nclassifiers. We introduce the following desiderata for uncertainty calibration:\n(a) accuracy-preserving, (b) data-efficient, and (c) high expressive power. We\nshow that none of the existing methods satisfy all three requirements, and\ndemonstrate how Mix-n-Match calibration strategies (i.e., ensemble and\ncomposition) can help achieve remarkably better data-efficiency and expressive\npower while provably maintaining the classification accuracy of the original\nclassifier. Mix-n-Match strategies are generic in the sense that they can be\nused to improve the performance of any off-the-shelf calibrator. We also reveal\npotential issues in standard evaluation practices. Popular approaches (e.g.,\nhistogram-based expected calibration error (ECE)) may provide misleading\nresults especially in small-data regime. Therefore, we propose an alternative\ndata-efficient kernel density-based estimator for a reliable evaluation of the\ncalibration performance and prove its asymptotically unbiasedness and\nconsistency. Our approaches outperform state-of-the-art solutions on both the\ncalibration as well as the evaluation tasks in most of the experimental\nsettings. Our codes are available at\nhttps://github.com/zhang64-llnl/Mix-n-Match-Calibration.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:00:35 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 06:44:30 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zhang", "Jize", ""], ["Kailkhura", "Bhavya", ""], ["Han", "T. Yong-Jin", ""]]}, {"id": "2003.07336", "submitter": "Carole-Jean Wu", "authors": "Carole-Jean Wu and Robin Burke and Ed H. Chi and Joseph Konstan and\n  Julian McAuley and Yves Raimond and Hao Zhang", "title": "Developing a Recommendation Benchmark for MLPerf Training and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based recommendation models are used pervasively and broadly,\nfor example, to recommend movies, products, or other information most relevant\nto users, in order to enhance the user experience. Among various application\ndomains which have received significant industry and academia research\nattention, such as image classification, object detection, language and speech\ntranslation, the performance of deep learning-based recommendation models is\nless well explored, even though recommendation tasks unarguably represent\nsignificant AI inference cycles at large-scale datacenter fleets. To advance\nthe state of understanding and enable machine learning system development and\noptimization for the commerce domain, we aim to define an industry-relevant\nrecommendation benchmark for the MLPerf Training andInference Suites. The paper\nsynthesizes the desirable modeling strategies for personalized recommendation\nsystems. We lay out desirable characteristics of recommendation model\narchitectures and data sets. We then summarize the discussions and advice from\nthe MLPerf Recommendation Advisory Board.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:13:00 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 12:52:16 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Wu", "Carole-Jean", ""], ["Burke", "Robin", ""], ["Chi", "Ed H.", ""], ["Konstan", "Joseph", ""], ["McAuley", "Julian", ""], ["Raimond", "Yves", ""], ["Zhang", "Hao", ""]]}, {"id": "2003.07337", "submitter": "Koulik Khamaru", "authors": "Koulik Khamaru, Ashwin Pananjady, Feng Ruan, Martin J. Wainwright,\n  Michael I. Jordan", "title": "Is Temporal Difference Learning Optimal? An Instance-Dependent Analysis", "comments": "38 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of policy evaluation in discounted Markov decision\nprocesses, and provide instance-dependent guarantees on the $\\ell_\\infty$-error\nunder a generative model. We establish both asymptotic and non-asymptotic\nversions of local minimax lower bounds for policy evaluation, thereby providing\nan instance-dependent baseline by which to compare algorithms. Theory-inspired\nsimulations show that the widely-used temporal difference (TD) algorithm is\nstrictly suboptimal when evaluated in a non-asymptotic setting, even when\ncombined with Polyak-Ruppert iterate averaging. We remedy this issue by\nintroducing and analyzing variance-reduced forms of stochastic approximation,\nshowing that they achieve non-asymptotic, instance-dependent optimality up to\nlogarithmic factors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:15:28 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Khamaru", "Koulik", ""], ["Pananjady", "Ashwin", ""], ["Ruan", "Feng", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2003.07339", "submitter": "Aidan O'Sullivan Dr", "authors": "Adrian Kelly and Aidan O'Sullivan and Patrick de Mars and Antoine\n  Marot", "title": "Reinforcement Learning for Electricity Network Operation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the background material required for the Learning to Run\nPower Networks Challenge. The challenge is focused on using Reinforcement\nLearning to train an agent to manage the real-time operations of a power grid,\nbalancing power flows and making interventions to maintain stability. We\npresent an introduction to power systems targeted at the machine learning\ncommunity and an introduction to reinforcement learning targeted at the power\nsystems community. This is to enable and encourage broader participation in the\nchallenge and collaboration between these two communities.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:21:35 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Kelly", "Adrian", ""], ["O'Sullivan", "Aidan", ""], ["de Mars", "Patrick", ""], ["Marot", "Antoine", ""]]}, {"id": "2003.07399", "submitter": "Alexander Lidiak", "authors": "Alexander Lidiak and Zhexuan Gong", "title": "Unsupervised machine learning of quantum phase transitions using\n  diffusion maps", "comments": "11 pages, 10 figures. Version published in Physical Review Letters", "journal-ref": "Phys. Rev. Lett. 125, 225701 (2020)", "doi": "10.1103/PhysRevLett.125.225701", "report-no": null, "categories": "quant-ph cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental quantum simulators have become large and complex enough that\ndiscovering new physics from the huge amount of measurement data can be quite\nchallenging, especially when little theoretical understanding of the simulated\nmodel is available. Unsupervised machine learning methods are particularly\npromising in overcoming this challenge. For the specific task of learning\nquantum phase transitions, unsupervised machine learning methods have primarily\nbeen developed for phase transitions characterized by simple order parameters,\ntypically linear in the measured observables. However, such methods often fail\nfor more complicated phase transitions, such as those involving incommensurate\nphases, valence-bond solids, topological order, and many-body localization. We\nshow that the diffusion map method, which performs nonlinear dimensionality\nreduction and spectral clustering of the measurement data, has significant\npotential for learning such complex phase transitions unsupervised. This method\nworks for measurements of local observables in a single basis and is thus\nreadily applicable to many experimental quantum simulators as a versatile tool\nfor learning various quantum phases and phase transitions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:40:13 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 22:58:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Lidiak", "Alexander", ""], ["Gong", "Zhexuan", ""]]}, {"id": "2003.07406", "submitter": "Tharindu Cyril Weerasooriya", "authors": "Tharindu Cyril Weerasooriya, Tong Liu, Christopher M. Homan", "title": "Neighborhood-based Pooling for Population-level Label Distribution\n  Learning", "comments": null, "journal-ref": "Proceedings of the 24th European Conference on Artificial\n  Intelligence 2020", "doi": "10.3233/FAIA200130", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised machine learning often requires human-annotated data. While\nannotator disagreement is typically interpreted as evidence of noise,\npopulation-level label distribution learning (PLDL) treats the collection of\nannotations for each data item as a sample of the opinions of a population of\nhuman annotators, among whom disagreement may be proper and expected, even with\nno noise present. From this perspective, a typical training set may contain a\nlarge number of very small-sized samples, one for each data item, none of\nwhich, by itself, is large enough to be considered representative of the\nunderlying population's beliefs about that item. We propose an algorithmic\nframework and new statistical tests for PLDL that account for sampling size. We\napply them to previously proposed methods for sharing labels across similar\ndata items. We also propose new approaches for label sharing, which we call\nneighborhood-based pooling.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:52:56 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 23:13:00 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Weerasooriya", "Tharindu Cyril", ""], ["Liu", "Tong", ""], ["Homan", "Christopher M.", ""]]}, {"id": "2003.07410", "submitter": "Sungho Shin", "authors": "Sungho Shin, Qiugang Lu, Victor M. Zavala", "title": "Unifying Theorems for Subspace Identification and Dynamic Mode\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents unifying results for subspace identification (SID) and\ndynamic mode decomposition (DMD) for autonomous dynamical systems. We observe\nthat SID seeks to solve an optimization problem to estimate an extended\nobservability matrix and a state sequence that minimizes the prediction error\nfor the state-space model. Moreover, we observe that DMD seeks to solve a\nrank-constrained matrix regression problem that minimizes the prediction error\nof an extended autoregressive model. We prove that existence conditions for\nperfect (error-free) state-space and low-rank extended autoregressive models\nare equivalent and that the SID and DMD optimization problems are equivalent.\nWe exploit these results to propose a SID-DMD algorithm that delivers a\nprovably optimal model and that is easy to implement. We demonstrate our\ndevelopments using a case study that aims to build dynamical models directly\nfrom video data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:03:04 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Shin", "Sungho", ""], ["Lu", "Qiugang", ""], ["Zavala", "Victor M.", ""]]}, {"id": "2003.07415", "submitter": "Parastoo Alinia", "authors": "Parastoo Alinia, Iman Mirzadeh, and Hassan Ghasemzadeh", "title": "ActiLabel: A Combinatorial Transfer Learning Framework for Activity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor-based human activity recognition has become a critical component of\nmany emerging applications ranging from behavioral medicine to gaming. However,\nan unprecedented increase in the diversity of sensor devices in the\nInternet-of-Things era has limited the adoption of activity recognition models\nfor use across different domains. We propose ActiLabel a combinatorial\nframework that learns structural similarities among the events in an arbitrary\ndomain and those of a different domain. The structural similarities are\ncaptured through a graph model, referred to as the it dependency graph, which\nabstracts details of activity patterns in low-level signal and feature space.\nThe activity labels are then autonomously learned by finding an optimal tiered\nmapping between the dependency graphs. Extensive experiments based on three\npublic datasets demonstrate the superiority of ActiLabel over state-of-the-art\ntransfer learning and deep learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:19:08 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Alinia", "Parastoo", ""], ["Mirzadeh", "Iman", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2003.07422", "submitter": "Piotr Zielinski", "authors": "Piotr Zielinski, Shankar Krishnan, Satrajit Chatterjee", "title": "Weak and Strong Gradient Directions: Explaining Memorization,\n  Generalization, and Hardness of Examples at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Coherent Gradients (CGH) is a recently proposed hypothesis to explain why\nover-parameterized neural networks trained with gradient descent generalize\nwell even though they have sufficient capacity to memorize the training set.\nThe key insight of CGH is that, since the overall gradient for a single step of\nSGD is the sum of the per-example gradients, it is strongest in directions that\nreduce the loss on multiple examples if such directions exist. In this paper,\nwe validate CGH on ResNet, Inception, and VGG models on ImageNet. Since the\ntechniques presented in the original paper do not scale beyond toy models and\ndatasets, we propose new methods. By posing the problem of suppressing weak\ngradient directions as a problem of robust mean estimation, we develop a\ncoordinate-based median of means approach. We present two versions of this\nalgorithm, M3, which partitions a mini-batch into 3 groups and computes the\nmedian, and a more efficient version RM3, which reuses gradients from previous\ntwo time steps to compute the median. Since they suppress weak gradient\ndirections without requiring per-example gradients, they can be used to train\nmodels at scale. Experimentally, we find that they indeed greatly reduce\noverfitting (and memorization) and thus provide the first convincing evidence\nthat CGH holds at scale. We also propose a new test of CGH that does not depend\non adding noise to training labels or on suppressing weak gradient directions.\nUsing the intuition behind CGH, we posit that the examples learned early in the\ntraining process (i.e., \"easy\" examples) are precisely those that have more in\ncommon with other training examples. Therefore, as per CGH, the easy examples\nshould generalize better amongst themselves than the hard examples amongst\nthemselves. We validate this hypothesis with detailed experiments, and believe\nthat it provides further orthogonal evidence for CGH.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:32:11 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 17:33:03 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Zielinski", "Piotr", ""], ["Krishnan", "Shankar", ""], ["Chatterjee", "Satrajit", ""]]}, {"id": "2003.07429", "submitter": "Lili Zheng", "authors": "Lili Zheng, Garvesh Raskutti, Rebecca Willett, Benjamin Mark", "title": "Context-dependent self-exciting point processes: models, methods, and\n  risk bounds in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional autoregressive point processes model how current events\ntrigger or inhibit future events, such as activity by one member of a social\nnetwork can affect the future activity of his or her neighbors. While past work\nhas focused on estimating the underlying network structure based solely on the\ntimes at which events occur on each node of the network, this paper examines\nthe more nuanced problem of estimating context-dependent networks that reflect\nhow features associated with an event (such as the content of a social media\npost) modulate the strength of influences among nodes. Specifically, we\nleverage ideas from compositional time series and regularization methods in\nmachine learning to conduct network estimation for high-dimensional marked\npoint processes. Two models and corresponding estimators are considered in\ndetail: an autoregressive multinomial model suited to categorical marks and a\nlogistic-normal model suited to marks with mixed membership in different\ncategories. Importantly, the logistic-normal model leads to a convex negative\nlog-likelihood objective and captures dependence across categories. We provide\ntheoretical guarantees for both estimators, which we validate by simulations\nand a synthetic data-generating model. We further validate our methods through\ntwo real data examples and demonstrate the advantages and disadvantages of both\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 20:22:43 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Zheng", "Lili", ""], ["Raskutti", "Garvesh", ""], ["Willett", "Rebecca", ""], ["Mark", "Benjamin", ""]]}, {"id": "2003.07443", "submitter": "Gustavo De Rosa", "authors": "Mateus Roder, Gustavo Henrique de Rosa, Jo\\~ao Paulo Papa", "title": "Learnergy: Energy-based Machine Learners", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the last years, machine learning techniques have been broadly\nencouraged in the context of deep learning architectures. An exciting algorithm\ndenoted as Restricted Boltzmann Machine relies on energy- and\nprobabilistic-based nature to tackle the most diverse applications, such as\nclassification, reconstruction, and generation of images and signals.\nNevertheless, one can see they are not adequately renowned compared to other\nwell-known deep learning techniques, e.g., Convolutional Neural Networks. Such\nbehavior promotes the lack of researches and implementations around the\nliterature, coping with the challenge of sufficiently comprehending these\nenergy-based systems. Therefore, in this paper, we propose a Python-inspired\nframework in the context of energy-based architectures, denoted as Learnergy.\nEssentially, Learnergy is built upon PyTorch to provide a more friendly\nenvironment and a faster prototyping workspace and possibly the usage of CUDA\ncomputations, speeding up their computational time.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:14:32 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:39:03 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Roder", "Mateus", ""], ["de Rosa", "Gustavo Henrique", ""], ["Papa", "Jo\u00e3o Paulo", ""]]}, {"id": "2003.07445", "submitter": "John Karanicolas", "authors": "Shipra Malhotra and John Karanicolas", "title": "A Numerical Transform of Random Forest Regressors corrects\n  Systematically-Biased Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, random forest models have become widely used as a\nrobust method for high-dimensional data regression tasks. In part, the\npopularity of these models arises from the fact that they require little\nhyperparameter tuning and are not very susceptible to overfitting. Random\nforest regression models are comprised of an ensemble of decision trees that\nindependently predict the value of a (continuous) dependent variable;\npredictions from each of the trees are ultimately averaged to yield an overall\npredicted value from the forest. Using a suite of representative real-world\ndatasets, we find a systematic bias in predictions from random forest models.\nWe find that this bias is recapitulated in simple synthetic datasets,\nregardless of whether or not they include irreducible error (noise) in the\ndata, but that models employing boosting do not exhibit this bias. Here we\ndemonstrate the basis for this problem, and we use the training data to define\na numerical transformation that fully corrects it. Application of this\ntransformation yields improved predictions in every one of the real-world and\nsynthetic datasets evaluated in our study.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:18:06 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Malhotra", "Shipra", ""], ["Karanicolas", "John", ""]]}, {"id": "2003.07450", "submitter": "Heng Chang", "authors": "Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Somayeh Sojoudi,\n  Junzhou Huang, Wenwu Zhu", "title": "Spectral Graph Attention Network with Fast Eigen-approximation", "comments": "Accepted by Deep Learning on Graphs: Method and Applications\n  (DLG-KDD21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variants of Graph Neural Networks (GNNs) for representation learning have\nbeen proposed recently and achieved fruitful results in various fields. Among\nthem, Graph Attention Network (GAT) first employs a self-attention strategy to\nlearn attention weights for each edge in the spatial domain. However, learning\nthe attentions over edges can only focus on the local information of graphs and\ngreatly increases the computational costs. In this paper, we first introduce\nthe attention mechanism in the spectral domain of graphs and present Spectral\nGraph Attention Network (SpGAT) that learns representations for different\nfrequency components regarding weighted filters and graph wavelets bases. In\nthis way, SpGAT can better capture global patterns of graphs in an efficient\nmanner with much fewer learned parameters than that of GAT. Further, to reduce\nthe computational cost of SpGAT brought by the eigen-decomposition, we propose\na fast approximation variant SpGAT-Cheby. We thoroughly evaluate the\nperformance of SpGAT and SpGAT-Cheby in semi-supervised node classification\ntasks and verify the effectiveness of the learned attentions in the spectral\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:49:34 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 11:58:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Chang", "Heng", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Wenbing", ""], ["Sojoudi", "Somayeh", ""], ["Huang", "Junzhou", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2003.07460", "submitter": "Bo Huang", "authors": "Yican Chen, Zhi Luo, Xia Wu, Huidong Yang, and Bo Huang", "title": "u-net CNN based fourier ptychography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier ptychography is a recently explored imaging method for overcoming the\ndiffraction limit of conventional cameras with applications in microscopy and\nyielding high-resolution images. In order to splice together low-resolution\nimages taken under different illumination angles of coherent light source, an\niterative phase retrieval algorithm is adopted. However, the reconstruction\nprocedure is slow and needs a good many of overlap in the Fourier domain for\nthe continuous recorded low-resolution images and is also worse under system\naberrations such as noise or random update sequence. In this paper, we propose\na new retrieval algorithm that is based on convolutional neural networks. Once\nwell trained, our model can perform high-quality reconstruction rapidly by\nusing the graphics processing unit. The experiments demonstrate that our model\nachieves better reconstruction results and is more robust under system\naberrations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 22:48:44 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chen", "Yican", ""], ["Luo", "Zhi", ""], ["Wu", "Xia", ""], ["Yang", "Huidong", ""], ["Huang", "Bo", ""]]}, {"id": "2003.07477", "submitter": "Elie Aljalbout", "authors": "Elie Aljalbout and Florian Walter and Florian R\\\"ohrbein and Alois\n  Knoll", "title": "Task-Independent Spiking Central Pattern Generator: A Learning-Based\n  Approach", "comments": "Neural Processing Letters", "journal-ref": null, "doi": "10.1007/s11063-020-10224-9", "report-no": null, "categories": "cs.NE cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Legged locomotion is a challenging task in the field of robotics but a rather\nsimple one in nature. This motivates the use of biological methodologies as\nsolutions to this problem. Central pattern generators are neural networks that\nare thought to be responsible for locomotion in humans and some animal species.\nAs for robotics, many attempts were made to reproduce such systems and use them\nfor a similar goal. One interesting design model is based on spiking neural\nnetworks. This model is the main focus of this work, as its contribution is not\nlimited to engineering but also applicable to neuroscience. This paper\nintroduces a new general framework for building central pattern generators that\nare task-independent, biologically plausible, and rely on learning methods. The\nabilities and properties of the presented approach are not only evaluated in\nsimulation but also in a robotic experiment. The results are very promising as\nthe used robot was able to perform stable walking at different speeds and to\nchange speed within the same gait cycle.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 00:01:38 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Aljalbout", "Elie", ""], ["Walter", "Florian", ""], ["R\u00f6hrbein", "Florian", ""], ["Knoll", "Alois", ""]]}, {"id": "2003.07494", "submitter": "Mostafa Karimi", "authors": "Kahkashan Afrin, Ashif S. Iquebal, Mostafa Karimi, Allyson Souris, Se\n  Yoon Lee, and Bani K. Mallick", "title": "Directionally Dependent Multi-View Clustering Using Copula Model", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0238996", "report-no": null, "categories": "stat.ME q-bio.GN stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent biomedical scientific problems, it is a fundamental issue to\nintegratively cluster a set of objects from multiple sources of datasets. Such\nproblems are mostly encountered in genomics, where data is collected from\nvarious sources, and typically represent distinct yet complementary\ninformation. Integrating these data sources for multi-source clustering is\nchallenging due to their complex dependence structure including directional\ndependency. Particularly in genomics studies, it is known that there is certain\ndirectional dependence between DNA expression, DNA methylation, and RNA\nexpression, widely called The Central Dogma.\n  Most of the existing multi-view clustering methods either assume an\nindependent structure or pair-wise (non-directional) dependency, thereby\nignoring the directional relationship. Motivated by this, we propose a\ncopula-based multi-view clustering model where a copula enables the model to\naccommodate the directional dependence existing in the datasets. We conduct a\nsimulation experiment where the simulated datasets exhibiting inherent\ndirectional dependence: it turns out that ignoring the directional dependence\nnegatively affects the clustering performance. As a real application, we\napplied our model to the breast cancer tumor samples collected from The Cancer\nGenome Altas (TCGA).\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 02:04:10 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 15:34:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Afrin", "Kahkashan", ""], ["Iquebal", "Ashif S.", ""], ["Karimi", "Mostafa", ""], ["Souris", "Allyson", ""], ["Lee", "Se Yoon", ""], ["Mallick", "Bani K.", ""]]}, {"id": "2003.07521", "submitter": "Mengjiao Yang", "authors": "Mengjiao Yang, Bo Dai, Hanjun Dai, Dale Schuurmans", "title": "Energy-Based Processes for Exchangeable Data", "comments": null, "journal-ref": "PMLR 119:2302-2312, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been growing interest in modeling sets with\nexchangeability such as point clouds. A shortcoming of current approaches is\nthat they restrict the cardinality of the sets considered or can only express\nlimited forms of distribution over unobserved data. To overcome these\nlimitations, we introduce Energy-Based Processes (EBPs), which extend energy\nbased models to exchangeable data while allowing neural network\nparameterizations of the energy function. A key advantage of these models is\nthe ability to express more flexible distributions over sets without\nrestricting their cardinality. We develop an efficient training procedure for\nEBPs that demonstrates state-of-the-art performance on a variety of tasks such\nas point cloud generation, classification, denoising, and image completion.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:26:02 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 15:54:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Yang", "Mengjiao", ""], ["Dai", "Bo", ""], ["Dai", "Hanjun", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2003.07545", "submitter": "Zhaonan Qu", "authors": "Zhaonan Qu, Yinyu Ye, Zhengyuan Zhou", "title": "Diagonal Preconditioning: Theory and Algorithms", "comments": "Under review, previous version wrong draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagonal preconditioning has been a staple technique in optimization and\nmachine learning. It often reduces the condition number of the design or\nHessian matrix it is applied to, thereby speeding up convergence. However,\nrigorous analyses of how well various diagonal preconditioning procedures\nimprove the condition number of the preconditioned matrix and how that\ntranslates into improvements in optimization are rare. In this paper, we first\nprovide an analysis of a popular diagonal preconditioning technique based on\ncolumn standard deviation and its effect on the condition number using random\nmatrix theory. Then we identify a class of design matrices whose condition\nnumbers can be reduced significantly by this procedure. We then study the\nproblem of optimal diagonal preconditioning to improve the condition number of\nany full-rank matrix and provide a bisection algorithm and a potential\nreduction algorithm with $O(\\log(\\frac{1}{\\epsilon}))$ iteration complexity,\nwhere each iteration consists of an SDP feasibility problem and a Newton update\nusing the Nesterov-Todd direction, respectively. Finally, we extend the optimal\ndiagonal preconditioning algorithm to an adaptive setting and compare its\nempirical performance at reducing the condition number and speeding up\nconvergence for regression and classification problems with that of another\nadaptive preconditioning technique, namely batch normalization, that is\nessential in training machine learning models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 05:48:27 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 00:37:49 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Qu", "Zhaonan", ""], ["Ye", "Yinyu", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2003.07554", "submitter": "Saurabh Garg", "authors": "Saurabh Garg, Yifan Wu, Sivaraman Balakrishnan, Zachary C. Lipton", "title": "A Unified View of Label Shift Estimation", "comments": "Accepted at Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under label shift, the label distribution p(y) might change but the\nclass-conditional distributions p(x|y) do not. There are two dominant\napproaches for estimating the label marginal. BBSE, a moment-matching approach\nbased on confusion matrices, is provably consistent and provides interpretable\nerror bounds. However, a maximum likelihood estimation approach, which we call\nMLLS, dominates empirically. In this paper, we present a unified view of the\ntwo methods and the first theoretical characterization of MLLS. Our\ncontributions include (i) consistency conditions for MLLS, which include\ncalibration of the classifier and a confusion matrix invertibility condition\nthat BBSE also requires; (ii) a unified framework, casting BBSE as roughly\nequivalent to MLLS for a particular choice of calibration method; and (iii) a\ndecomposition of MLLS's finite-sample error into terms reflecting\nmiscalibration and estimation error. Our analysis attributes BBSE's statistical\ninefficiency to a loss of information due to coarse calibration. Experiments on\nsynthetic data, MNIST, and CIFAR10 support our findings.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 06:28:50 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 20:04:15 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 19:23:32 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Garg", "Saurabh", ""], ["Wu", "Yifan", ""], ["Balakrishnan", "Sivaraman", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2003.07577", "submitter": "Yuhang Li", "authors": "Yuhang Li, Wei Wang, Haoli Bai, Ruihao Gong, Xin Dong, and Fengwei Yu", "title": "Efficient Bitwidth Search for Practical Mixed Precision Neural Network", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization has rapidly become one of the most widely used methods\nto compress and accelerate deep neural networks. Recent efforts propose to\nquantize weights and activations from different layers with different precision\nto improve the overall performance. However, it is challenging to find the\noptimal bitwidth (i.e., precision) for weights and activations of each layer\nefficiently. Meanwhile, it is yet unclear how to perform convolution for\nweights and activations of different precision efficiently on generic hardware\nplatforms. To resolve these two issues, in this paper, we first propose an\nEfficient Bitwidth Search (EBS) algorithm, which reuses the meta weights for\ndifferent quantization bitwidth and thus the strength for each candidate\nprecision can be optimized directly w.r.t the objective without superfluous\ncopies, reducing both the memory and computational cost significantly. Second,\nwe propose a binary decomposition algorithm that converts weights and\nactivations of different precision into binary matrices to make the mixed\nprecision convolution efficient and practical. Experiment results on CIFAR10\nand ImageNet datasets demonstrate our mixed precision QNN outperforms the\nhandcrafted uniform bitwidth counterparts and other mixed precision techniques.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 08:27:48 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Li", "Yuhang", ""], ["Wang", "Wei", ""], ["Bai", "Haoli", ""], ["Gong", "Ruihao", ""], ["Dong", "Xin", ""], ["Yu", "Fengwei", ""]]}, {"id": "2003.07578", "submitter": "Guoxian Yu", "authors": "Tingting Yu, Guoxian Yu, Jun Wang, Maozu Guo", "title": "Partial Multi-label Learning with Label and Feature Collaboration", "comments": "16 pages, 4 figures, accepted to DASFAA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial multi-label learning (PML) models the scenario where each training\ninstance is annotated with a set of candidate labels, and only some of the\nlabels are relevant. The PML problem is practical in real-world scenarios, as\nit is difficult and even impossible to obtain precisely labeled samples.\nSeveral PML solutions have been proposed to combat with the prone misled by the\nirrelevant labels concealed in the candidate labels, but they generally focus\non the smoothness assumption in feature space or low-rank assumption in label\nspace, while ignore the negative information between features and labels.\nSpecifically, if two instances have largely overlapped candidate labels,\nirrespective of their feature similarity, their ground-truth labels should be\nsimilar; while if they are dissimilar in the feature and candidate label space,\ntheir ground-truth labels should be dissimilar with each other. To achieve a\ncredible predictor on PML data, we propose a novel approach called PML-LFC\n(Partial Multi-label Learning with Label and Feature Collaboration). PML-LFC\nestimates the confidence values of relevant labels for each instance using the\nsimilarity from both the label and feature spaces, and trains the desired\npredictor with the estimated confidence values. PML-LFC achieves the predictor\nand the latent label matrix in a reciprocal reinforce manner by a unified\nmodel, and develops an alternative optimization procedure to optimize them.\nExtensive empirical study on both synthetic and real-world datasets\ndemonstrates the superiority of PML-LFC.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 08:34:45 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Yu", "Tingting", ""], ["Yu", "Guoxian", ""], ["Wang", "Jun", ""], ["Guo", "Maozu", ""]]}, {"id": "2003.07602", "submitter": "Malik Magdon-Ismail", "authors": "Malik Magdon-Ismail", "title": "Machine Learning the Phenomenology of COVID-19 From Early Infection\n  Dynamics", "comments": "Test data up to April 02. Reorganized a little", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust data-driven machine learning analysis of the COVID-19\npandemic from its early infection dynamics, specifically infection counts over\ntime. The goal is to extract actionable public health insights. These insights\ninclude the infectious force, the rate of a mild infection becoming serious,\nestimates for asymtomatic infections and predictions of new infections over\ntime. We focus on USA data starting from the first confirmed infection on\nJanuary 20 2020. Our methods reveal significant asymptomatic (hidden)\ninfection, a lag of about 10 days, and we quantitatively confirm that the\ninfectious force is strong with about a 0.14% transition from mild to serious\ninfection. Our methods are efficient, robust and general, being agnostic to the\nspecific virus and applicable to different populations or cohorts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 09:42:14 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 02:05:04 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 13:21:58 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Magdon-Ismail", "Malik", ""]]}, {"id": "2003.07611", "submitter": "Seongok Ryu", "authors": "Soojung Yang, Kyung Hoon Lee, and Seongok Ryu", "title": "A comprehensive study on the prediction reliability of graph neural\n  networks for virtual screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction models based on deep neural networks are increasingly gaining\nattention for fast and accurate virtual screening systems. For decision makings\nin virtual screening, researchers find it useful to interpret an output of\nclassification system as probability, since such interpretation allows them to\nfilter out more desirable compounds. However, probabilistic interpretation\ncannot be correct for models that hold over-parameterization problems or\ninappropriate regularizations, leading to unreliable prediction and decision\nmaking. In this regard, we concern the reliability of neural prediction models\non molecular properties, especially when models are trained with sparse data\npoints and imbalanced distributions. This work aims to propose guidelines for\ntraining reliable models, we thus provide methodological details and ablation\nstudies on the following train principles. We investigate the effects of model\narchitectures, regularization methods, and loss functions on the prediction\nperformance and reliability of classification results. Moreover, we evaluate\nprediction reliability of models on virtual screening scenario. Our result\nhighlights that correct choice of regularization and inference methods is\nevidently important to achieve high success rate, especially in data imbalanced\nsituation. All experiments were performed under a single unified model\nimplementation to alleviate external randomness in model training and to enable\nprecise comparison of results.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:13:31 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Yang", "Soojung", ""], ["Lee", "Kyung Hoon", ""], ["Ryu", "Seongok", ""]]}, {"id": "2003.07621", "submitter": "Erik-Jan van Kesteren", "authors": "Laura Boeschoten, Erik-Jan van Kesteren, Ayoub Bagheri, Daniel L.\n  Oberski", "title": "Fair inference on error-prone outcomes", "comments": "Online supplementary code is available at\n  https://dx.doi.org/10.5281/zenodo.3708150", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fair inference in supervised learning is an important and active area of\nresearch, yielding a range of useful methods to assess and account for fairness\ncriteria when predicting ground truth targets. As shown in recent work,\nhowever, when target labels are error-prone, potential prediction unfairness\ncan arise from measurement error. In this paper, we show that, when an\nerror-prone proxy target is used, existing methods to assess and calibrate\nfairness criteria do not extend to the true target variable of interest. To\nremedy this problem, we suggest a framework resulting from the combination of\ntwo existing literatures: fair ML methods, such as those found in the\ncounterfactual fairness literature on the one hand, and, on the other,\nmeasurement models found in the statistical literature. We discuss these\napproaches and their connection resulting in our framework. In a healthcare\ndecision problem, we find that using a latent variable model to account for\nmeasurement error removes the unfairness detected previously.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:31:59 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Boeschoten", "Laura", ""], ["van Kesteren", "Erik-Jan", ""], ["Bagheri", "Ayoub", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2003.07631", "submitter": "Wojciech Samek", "authors": "Wojciech Samek, Gr\\'egoire Montavon, Sebastian Lapuschkin, Christopher\n  J. Anders, Klaus-Robert M\\\"uller", "title": "Explaining Deep Neural Networks and Beyond: A Review of Methods and\n  Applications", "comments": "30 pages, 20 figures", "journal-ref": null, "doi": "10.1109/JPROC.2021.3060483", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the broader and highly successful usage of machine learning in industry\nand the sciences, there has been a growing demand for Explainable AI.\nInterpretability and explanation methods for gaining a better understanding\nabout the problem solving abilities and strategies of nonlinear Machine\nLearning, in particular, deep neural networks, are therefore receiving\nincreased attention. In this work we aim to (1) provide a timely overview of\nthis active emerging field, with a focus on 'post-hoc' explanations, and\nexplain its theoretical foundations, (2) put interpretability algorithms to a\ntest both from a theory and comparative evaluation perspective using extensive\nsimulations, (3) outline best practice aspects i.e. how to best include\ninterpretation methods into the standard usage of machine learning and (4)\ndemonstrate successful usage of explainable AI in a representative selection of\napplication scenarios. Finally, we discuss challenges and possible future\ndirections of this exciting foundational field of machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:45:51 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 12:39:41 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Samek", "Wojciech", ""], ["Montavon", "Gr\u00e9goire", ""], ["Lapuschkin", "Sebastian", ""], ["Anders", "Christopher J.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2003.07658", "submitter": "Dongrui Wu", "authors": "Ziang Liu, Xue Jiang, Hanbin Luo, Weili Fang, Jiajing Liu, and Dongrui\n  Wu", "title": "Pool-Based Unsupervised Active Learning for Regression Using Iterative\n  Representativeness-Diversity Maximization (iRDM)", "comments": null, "journal-ref": "Pattern Recognition Letters, 142:11-19, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) selects the most beneficial unlabeled samples to label,\nand hence a better machine learning model can be trained from the same number\nof labeled samples. Most existing active learning for regression (ALR)\napproaches are supervised, which means the sampling process must use some label\ninformation, or an existing regression model. This paper considers completely\nunsupervised ALR, i.e., how to select the samples to label without knowing any\ntrue label information. We propose a novel unsupervised ALR approach, iterative\nrepresentativeness-diversity maximization (iRDM), to optimally balance the\nrepresentativeness and the diversity of the selected samples. Experiments on 12\ndatasets from various domains demonstrated its effectiveness. Our iRDM can be\napplied to both linear regression and kernel regression, and it even\nsignificantly outperforms supervised ALR when the number of labeled samples is\nsmall.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 12:20:46 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 22:07:38 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Liu", "Ziang", ""], ["Jiang", "Xue", ""], ["Luo", "Hanbin", ""], ["Fang", "Weili", ""], ["Liu", "Jiajing", ""], ["Wu", "Dongrui", ""]]}, {"id": "2003.07680", "submitter": "Po-Ming Law", "authors": "Po-Ming Law, Sana Malik, Fan Du, Moumita Sinha", "title": "Designing Tools for Semi-Automated Detection of Machine Learning Biases:\n  An Interview Study", "comments": "Proceedings of the CHI 2020 Workshop on Detection and Design for\n  Cognitive Biases in People and Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models often make predictions that bias against certain\nsubgroups of input data. When undetected, machine learning biases can\nconstitute significant financial and ethical implications. Semi-automated tools\nthat involve humans in the loop could facilitate bias detection. Yet, little is\nknown about the considerations involved in their design. In this paper, we\nreport on an interview study with 11 machine learning practitioners for\ninvestigating the needs surrounding semi-automated bias detection tools. Based\non the findings, we highlight four considerations in designing to guide system\ndesigners who aim to create future tools for bias detection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:18:58 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 01:41:40 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Law", "Po-Ming", ""], ["Malik", "Sana", ""], ["Du", "Fan", ""], ["Sinha", "Moumita", ""]]}, {"id": "2003.07692", "submitter": "Anirudh Mani", "authors": "Anirudh Mani, Shruti Palaskar, Nimshi Venkat Meripo, Sandeep Konam,\n  Florian Metze", "title": "ASR Error Correction and Domain Adaptation Using Machine Translation", "comments": "Accepted for Oral Presentation at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-the-shelf pre-trained Automatic Speech Recognition (ASR) systems are an\nincreasingly viable service for companies of any size building speech-based\nproducts. While these ASR systems are trained on large amounts of data, domain\nmismatch is still an issue for many such parties that want to use this service\nas-is leading to not so optimal results for their task. We propose a simple\ntechnique to perform domain adaptation for ASR error correction via machine\ntranslation. The machine translation model is a strong candidate to learn a\nmapping from out-of-domain ASR errors to in-domain terms in the corresponding\nreference files. We use two off-the-shelf ASR systems in this work: Google ASR\n(commercial) and the ASPIRE model (open-source). We observe 7% absolute\nimprovement in word error rate and 4 point absolute improvement in BLEU score\nin Google ASR output via our proposed method. We also evaluate ASR error\ncorrection via a downstream task of Speaker Diarization that captures speaker\nstyle, syntax, structure and semantic improvements we obtain via ASR\ncorrection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 20:05:38 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Mani", "Anirudh", ""], ["Palaskar", "Shruti", ""], ["Meripo", "Nimshi Venkat", ""], ["Konam", "Sandeep", ""], ["Metze", "Florian", ""]]}, {"id": "2003.07701", "submitter": "Gabriel Gon\\c{c}alves", "authors": "Gabriel F. N. Gon\\c{c}alves, Assen Batchvarov, Yuyi Liu, Yuxin Liu,\n  Lachlan Mason, Indranil Pan, Omar K. Matar", "title": "Data-driven surrogate modelling and benchmarking for process equipment", "comments": null, "journal-ref": "Data-Centric Engineering (2020), 1, E7", "doi": "10.1017/dce.2020.8", "report-no": null, "categories": "cs.CE cs.LG physics.flu-dyn stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In chemical process engineering, surrogate models of complex systems are\noften necessary for tasks of domain exploration, sensitivity analysis of the\ndesign parameters, and optimization. A suite of computational fluid dynamics\n(CFD) simulations geared toward chemical process equipment modeling has been\ndeveloped and validated with experimental results from the literature. Various\nregression-based active learning strategies are explored with these CFD\nsimulators in-the-loop under the constraints of a limited function evaluation\nbudget. Specifically, five different sampling strategies and five regression\ntechniques are compared, considering a set of four test cases of industrial\nsignificance and varying complexity. Gaussian process regression was observed\nto have a consistently good performance for these applications. The present\nquantitative study outlines the pros and cons of the different available\ntechniques and highlights the best practices for their adoption. The test cases\nand tools are available with an open-source license to ensure reproducibility\nand engage the wider research community in contributing to both the CFD models\nand developing and benchmarking new improved algorithms tailored to this field.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 18:22:43 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 14:42:14 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Gon\u00e7alves", "Gabriel F. N.", ""], ["Batchvarov", "Assen", ""], ["Liu", "Yuyi", ""], ["Liu", "Yuxin", ""], ["Mason", "Lachlan", ""], ["Pan", "Indranil", ""], ["Matar", "Omar K.", ""]]}, {"id": "2003.07704", "submitter": "Pirmin Ebner", "authors": "P. P. Ebner and A. Eltelt", "title": "Audio inpainting with generative adversarial network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the ability of Wasserstein Generative Adversarial Network (WGAN) to\ngenerate missing audio content which is, in context, (statistically similar) to\nthe sound and the neighboring borders. We deal with the challenge of audio\ninpainting long range gaps (500 ms) using WGAN models. We improved the quality\nof the inpainting part using a new proposed WGAN architecture that uses a\nshort-range and a long-range neighboring borders compared to the classical WGAN\nmodel. The performance was compared with two different audio instruments (piano\nand guitar) and on virtuoso pianists together with a string orchestra. The\nobjective difference grading (ODG) was used to evaluate the performance of both\narchitectures. The proposed model outperforms the classical WGAN model and\nimproves the reconstruction of high-frequency content. Further, we got better\nresults for instruments where the frequency spectrum is mainly in the lower\nrange where small noises are less annoying for human ear and the inpainting\npart is more perceptible. Finally, we could show that better test results for\naudio dataset were reached where a particular instrument is accompanist by\nother instruments if we train the network only on this particular instrument\nneglecting the other instruments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 09:17:01 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ebner", "P. P.", ""], ["Eltelt", "A.", ""]]}, {"id": "2003.07718", "submitter": "Allison Chaney", "authors": "Allison J.B. Chaney, Archit Verma, Young-suk Lee, Barbara E.\n  Engelhardt", "title": "Nonparametric Deconvolution Models", "comments": "33 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe nonparametric deconvolution models (NDMs), a family of Bayesian\nnonparametric models for collections of data in which each observation is the\naverage over the features from heterogeneous particles. For example, these\ntypes of data are found in elections, where we observe precinct-level vote\ntallies (observations) of individual citizens' votes (particles) across each of\nthe candidates or ballot measures (features), where each voter is part of a\nspecific voter cohort or demographic (factor). Like the hierarchical Dirichlet\nprocess, NDMs rely on two tiers of Dirichlet processes to explain the data with\nan unknown number of latent factors; each observation is modeled as a weighted\naverage of these latent factors. Unlike existing models, NDMs recover how\nfactor distributions vary locally for each observation. This uniquely allows\nNDMs both to deconvolve each observation into its constituent factors, and also\nto describe how the factor distributions specific to each observation vary\nacross observations and deviate from the corresponding global factors. We\npresent variational inference techniques for this family of models and study\nits performance on simulated data and voting data from California. We show that\nincluding local factors improves estimates of global factors and provides a\nnovel scaffold for exploring data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 13:38:43 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chaney", "Allison J. B.", ""], ["Verma", "Archit", ""], ["Lee", "Young-suk", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "2003.07729", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Antonio G. Marques, Georgios B. Giannakis", "title": "Tensor Graph Convolutional Networks for Multi-relational and Robust\n  Learning", "comments": "Graph Convolutinal Networks, Robustness, Adversarial Attacks,\n  Semi-supervised learning, Multi-relational/Heterogenous networks. arXiv admin\n  note: text overlap with arXiv:1910.09590, arXiv:1811.02061", "journal-ref": null, "doi": "10.1109/TSP.2020.3028495", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The era of \"data deluge\" has sparked renewed interest in graph-based learning\nmethods and their widespread applications ranging from sociology and biology to\ntransportation and communications. In this context of graph-aware methods, the\npresent paper introduces a tensor-graph convolutional network (TGCN) for\nscalable semi-supervised learning (SSL) from data associated with a collection\nof graphs, that are represented by a tensor. Key aspects of the novel TGCN\narchitecture are the dynamic adaptation to different relations in the tensor\ngraph via learnable weights, and the consideration of graph-based regularizers\nto promote smoothness and alleviate over-parameterization. The ultimate goal is\nto design a powerful learning architecture able to: discover complex and highly\nnonlinear data associations, combine (and select) multiple types of relations,\nscale gracefully with the graph size, and remain robust to perturbations on the\ngraph edges. The proposed architecture is relevant not only in applications\nwhere the nodes are naturally involved in different relations (e.g., a\nmulti-relational graph capturing family, friendship and work relations in a\nsocial network), but also in robust learning setups where the graph entails a\ncertain level of uncertainty, and the different tensor slabs correspond to\ndifferent versions (realizations) of the nominal graph. Numerical tests\nshowcase that the proposed architecture achieves markedly improved performance\nrelative to standard GCNs, copes with state-of-the-art adversarial attacks, and\nleads to remarkable SSL performance over protein-to-protein interaction\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 02:33:21 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Marques", "Antonio G.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "2003.07740", "submitter": "Jong Chul Ye", "authors": "Eunju Cha, Gyutaek Oh, Jong Chul Ye", "title": "Geometric Approaches to Increase the Expressivity of Deep Neural\n  Networks for MR Reconstruction", "comments": "Accepted for IEEE JSTSP Special Issue on Domain Enriched Learning for\n  Medical Imaging", "journal-ref": null, "doi": "10.1109/JSTSP.2020.2982777", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning approaches have been extensively investigated to\nreconstruct images from accelerated magnetic resonance image (MRI) acquisition.\nAlthough these approaches provide significant performance gain compared to\ncompressed sensing MRI (CS-MRI), it is not clear how to choose a suitable\nnetwork architecture to balance the trade-off between network complexity and\nperformance. Recently, it was shown that an encoder-decoder convolutional\nneural network (CNN) can be interpreted as a piecewise linear basis-like\nrepresentation, whose specific representation is determined by the ReLU\nactivation patterns for a given input image. Thus, the expressivity or the\nrepresentation power is determined by the number of piecewise linear regions.\nAs an extension of this geometric understanding, this paper proposes a\nsystematic geometric approach using bootstrapping and subnetwork aggregation\nusing an attention module to increase the expressivity of the underlying neural\nnetwork. Our method can be implemented in both k-space domain and image domain\nthat can be trained in an end-to-end manner. Experimental results show that the\nproposed schemes significantly improve reconstruction performance with\nnegligible complexity increases.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 14:18:37 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Cha", "Eunju", ""], ["Oh", "Gyutaek", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2003.07743", "submitter": "Wei Hu", "authors": "Zequn Sun and Qingheng Zhang and Wei Hu and Chengming Wang and Muhao\n  Chen and Farahnaz Akrami and Chengkai Li", "title": "A Benchmarking Study of Embedding-based Entity Alignment for Knowledge\n  Graphs", "comments": "Accepted in the 46th International Conference on Very Large Data\n  Bases (VLDB 2020)", "journal-ref": null, "doi": "10.14778/3407790.3407828", "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment seeks to find entities in different knowledge graphs (KGs)\nthat refer to the same real-world object. Recent advancement in KG embedding\nimpels the advent of embedding-based entity alignment, which encodes entities\nin a continuous embedding space and measures entity similarities based on the\nlearned embeddings. In this paper, we conduct a comprehensive experimental\nstudy of this emerging field. We survey 23 recent embedding-based entity\nalignment approaches and categorize them based on their techniques and\ncharacteristics. We also propose a new KG sampling algorithm, with which we\ngenerate a set of dedicated benchmark datasets with various heterogeneity and\ndistributions for a realistic evaluation. We develop an open-source library\nincluding 12 representative embedding-based entity alignment approaches, and\nextensively evaluate these approaches, to understand their strengths and\nlimitations. Additionally, for several directions that have not been explored\nin current approaches, we perform exploratory experiments and report our\npreliminary findings for future studies. The benchmark datasets, open-source\nlibrary and experimental results are all accessible online and will be duly\nmaintained.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 05:32:06 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:47:26 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Sun", "Zequn", ""], ["Zhang", "Qingheng", ""], ["Hu", "Wei", ""], ["Wang", "Chengming", ""], ["Chen", "Muhao", ""], ["Akrami", "Farahnaz", ""], ["Li", "Chengkai", ""]]}, {"id": "2003.07756", "submitter": "Yaniv Yacoby", "authors": "Yaniv Yacoby, Weiwei Pan, Finale Doshi-Velez", "title": "Characterizing and Avoiding Problematic Global Optima of Variational\n  Autoencoders", "comments": "Accepted at the Proceedings of The 2nd Symposium on Advances in\n  Approximate Bayesian Inference 2019", "journal-ref": "PMLR 118:1-17, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-encoders (VAEs) are deep generative latent variable models\nconsisting of two components: a generative model that captures a data\ndistribution p(x) by transforming a distribution p(z) over latent space, and an\ninference model that infers likely latent codes for each data point (Kingma and\nWelling, 2013). Recent work shows that traditional training methods tend to\nyield solutions that violate modeling desiderata: (1) the learned generative\nmodel captures the observed data distribution but does so while ignoring the\nlatent codes, resulting in codes that do not represent the data (e.g. van den\nOord et al. (2017); Kim et al. (2018)); (2) the aggregate of the learned latent\ncodes does not match the prior p(z). This mismatch means that the learned\ngenerative model will be unable to generate realistic data with samples from\np(z)(e.g. Makhzani et al. (2015); Tomczak and Welling (2017)). In this paper,\nwe demonstrate that both issues stem from the fact that the global optima of\nthe VAE training objective often correspond to undesirable solutions. Our\nanalysis builds on two observations: (1) the generative model is unidentifiable\n- there exist many generative models that explain the data equally well, each\nwith different (and potentially unwanted) properties and (2) bias in the VAE\nobjective - the VAE objective may prefer generative models that explain the\ndata poorly but have posteriors that are easy to approximate. We present a\nnovel inference method, LiBI, mitigating the problems identified in our\nanalysis. On synthetic datasets, we show that LiBI can learn generative models\nthat capture the data distribution and inference models that better satisfy\nmodeling assumptions when traditional methods struggle to do so.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 15:14:25 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Yacoby", "Yaniv", ""], ["Pan", "Weiwei", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2003.07775", "submitter": "Stefan Lenz", "authors": "Stefan Lenz, Harald Binder", "title": "Deep generative models in DataSHIELD", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best way to calculate statistics from medical data is to use the data of\nindividual patients. In some settings, this data is difficult to obtain due to\nprivacy restrictions. In Germany, for example, it is not possible to pool\nroutine data from different hospitals for research purposes without the consent\nof the patients. The DataSHIELD software provides an infrastructure and a set\nof statistical methods for joint analyses of distributed data. The contained\nalgorithms are reformulated to work with aggregated data from the participating\nsites instead of the individual data. If a desired algorithm is not implemented\nin DataSHIELD or cannot be reformulated in such a way, using artificial data is\nan alternative. We present a methodology together with a software\nimplementation that builds on DataSHIELD to create artificial data that\npreserve complex patterns from distributed individual patient data. Such data\nsets of artificial patients, which are not linked to real patients, can then be\nused for joint analyses. We use deep Boltzmann machines (DBMs) as generative\nmodels for capturing the distribution of data. For the implementation, we\nemploy the package \"BoltzmannMachines\" from the Julia programming language and\nwrap it for use with DataSHIELD, which is based on R. As an exemplary\napplication, we conduct a distributed analysis with DBMs on a synthetic data\nset, which simulates genetic variant data. Patterns from the original data can\nbe recovered in the artificial data using hierarchical clustering of the\nvirtual patients, demonstrating the feasibility of the approach. Our\nimplementation adds to DataSHIELD the ability to generate artificial data that\ncan be used for various analyses, e. g. for pattern recognition with deep\nlearning. This also demonstrates more generally how DataSHIELD can be flexibly\nextended with advanced algorithms from languages other than R.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:15:06 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lenz", "Stefan", ""], ["Binder", "Harald", ""]]}, {"id": "2003.07779", "submitter": "Andre Mendes", "authors": "Andre Mendes, Julian Togelius, Leandro dos Santos Coelho", "title": "Unified Multi-Domain Learning and Data Imputation using Adversarial\n  Autoencoder", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework that can combine multi-domain learning (MDL),\ndata imputation (DI) and multi-task learning (MTL) to improve performance for\nclassification and regression tasks in different domains. The core of our\nmethod is an adversarial autoencoder that can: (1) learn to produce\ndomain-invariant embeddings to reduce the difference between domains; (2) learn\nthe data distribution for each domain and correctly perform data imputation on\nmissing data. For MDL, we use the Maximum Mean Discrepancy (MMD) measure to\nalign the domain distributions. For DI, we use an adversarial approach where a\ngenerator fill in information for missing data and a discriminator tries to\ndistinguish between real and imputed values. Finally, using the universal\nfeature representation in the embeddings, we train a classifier using MTL that\ngiven input from any domain, can predict labels for all domains. We demonstrate\nthe superior performance of our approach compared to other state-of-art methods\nin three distinct settings, DG-DI in image recognition with unstructured data,\nMTL-DI in grade estimation with structured data and MDMTL-DI in a selection\nprocess using mixed data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:55:07 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Mendes", "Andre", ""], ["Togelius", "Julian", ""], ["Coelho", "Leandro dos Santos", ""]]}, {"id": "2003.07780", "submitter": "Meng Chen", "authors": "Meng Chen, Xiaohui Yu, Yang Liu", "title": "TraLFM: Latent Factor Modeling of Traffic Trajectory Data", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Transportation Systems 20 (12),\n  4624-4634, 2019", "doi": "10.1109/TITS.2019.2912075", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of positioning devices (e.g., GPS) has given rise to a\nvast body of human movement data, often in the form of trajectories.\nUnderstanding human mobility patterns could benefit many location-based\napplications. In this paper, we propose a novel generative model called TraLFM\nvia latent factor modeling to mine human mobility patterns underlying traffic\ntrajectories. TraLFM is based on three key observations: (1) human mobility\npatterns are reflected by the sequences of locations in the trajectories; (2)\nhuman mobility patterns vary with people; and (3) human mobility patterns tend\nto be cyclical and change over time. Thus, TraLFM models the joint action of\nsequential, personal and temporal factors in a unified way, and brings a new\nperspective to many applications such as latent factor analysis and next\nlocation prediction. We perform thorough empirical studies on two real\ndatasets, and the experimental results confirm that TraLFM outperforms the\nstate-of-the-art methods significantly in these applications.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:41:39 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chen", "Meng", ""], ["Yu", "Xiaohui", ""], ["Liu", "Yang", ""]]}, {"id": "2003.07782", "submitter": "Meng Chen", "authors": "Meng Chen, Xiaohui Yu, Yang Liu", "title": "MPE: A Mobility Pattern Embedding Model for Predicting Next Locations", "comments": null, "journal-ref": "World Wide Web, 22(6), 2901-2920, 2019", "doi": "10.1007/s11280-018-0616-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide spread use of positioning and photographing devices gives rise to a\ndeluge of traffic trajectory data (e.g., vehicle passage records and taxi\ntrajectory data), with each record having at least three attributes: object ID,\nlocation ID, and time-stamp. In this paper, we propose a novel mobility pattern\nembedding model called MPE to shed the light on people's mobility patterns in\ntraffic trajectory data from multiple aspects, including sequential, personal,\nand temporal factors. MPE has two salient features: (1) it is capable of\ncasting various types of information (object, location and time) to an\nintegrated low-dimensional latent space; (2) it considers the effect of\n``phantom transitions'' arising from road networks in traffic trajectory data.\nThis embedding model opens the door to a wide range of applications such as\nnext location prediction and visualization. Experimental results on two\nreal-world datasets show that MPE is effective and outperforms the\nstate-of-the-art methods significantly in a variety of tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 05:24:32 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Chen", "Meng", ""], ["Yu", "Xiaohui", ""], ["Liu", "Yang", ""]]}, {"id": "2003.07802", "submitter": "Edgar Dobriban", "authors": "Alnur Ali, Edgar Dobriban, and Ryan J. Tibshirani", "title": "The Implicit Regularization of Stochastic Gradient Flow for Least\n  Squares", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the implicit regularization of mini-batch stochastic gradient\ndescent, when applied to the fundamental problem of least squares regression.\nWe leverage a continuous-time stochastic differential equation having the same\nmoments as stochastic gradient descent, which we call stochastic gradient flow.\nWe give a bound on the excess risk of stochastic gradient flow at time $t$,\nover ridge regression with tuning parameter $\\lambda = 1/t$. The bound may be\ncomputed from explicit constants (e.g., the mini-batch size, step size, number\nof iterations), revealing precisely how these quantities drive the excess risk.\nNumerical examples show the bound can be small, indicating a tight relationship\nbetween the two estimators. We give a similar result relating the coefficients\nof stochastic gradient flow and ridge. These results hold under no conditions\non the data matrix $X$, and across the entire optimization path (not just at\nconvergence).\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:37:25 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 21:55:36 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ali", "Alnur", ""], ["Dobriban", "Edgar", ""], ["Tibshirani", "Ryan J.", ""]]}, {"id": "2003.07849", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Tatsuya Harada", "title": "Blur, Noise, and Compression Robust Generative Adversarial Networks", "comments": "Accepted to CVPR 2021. Project page:\n  https://takuhirok.github.io/BNCR-GAN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have gained considerable attention\nowing to their ability to reproduce images. However, they can recreate training\nimages faithfully despite image degradation in the form of blur, noise, and\ncompression, generating similarly degraded images. To solve this problem, the\nrecently proposed noise robust GAN (NR-GAN) provides a partial solution by\ndemonstrating the ability to learn a clean image generator directly from noisy\nimages using a two-generator model comprising image and noise generators.\nHowever, its application is limited to noise, which is relatively easy to\ndecompose owing to its additive and reversible characteristics, and its\napplication to irreversible image degradation, in the form of blur,\ncompression, and combination of all, remains a challenge. To address these\nproblems, we propose blur, noise, and compression robust GAN (BNCR-GAN) that\ncan learn a clean image generator directly from degraded images without\nknowledge of degradation parameters (e.g., blur kernel types, noise amounts, or\nquality factor values). Inspired by NR-GAN, BNCR-GAN uses a multiple-generator\nmodel composed of image, blur-kernel, noise, and quality-factor generators.\nHowever, in contrast to NR-GAN, to address irreversible characteristics, we\nintroduce masking architectures adjusting degradation strength values in a\ndata-driven manner using bypasses before and after degradation. Furthermore, to\nsuppress uncertainty caused by the combination of blur, noise, and compression,\nwe introduce adaptive consistency losses imposing consistency between\nirreversible degradation processes according to the degradation strengths. We\ndemonstrate the effectiveness of BNCR-GAN through large-scale comparative\nstudies on CIFAR-10 and a generality analysis on FFHQ. In addition, we\ndemonstrate the applicability of BNCR-GAN in image restoration.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 17:56:22 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:49:46 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Harada", "Tatsuya", ""]]}, {"id": "2003.07859", "submitter": "Saif Jabari", "authors": "Yue Wang, Esha Sarkar, Wenqing Li, Michail Maniatakos, Saif Eddin\n  Jabari", "title": "Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement\n  Learning-based Traffic Congestion Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the introduction of autonomous vehicles (AVs) in\ntraffic could help reduce traffic jams. Deep reinforcement learning methods\ndemonstrate good performance in complex control problems, including autonomous\nvehicle control, and have been used in state-of-the-art AV controllers.\nHowever, the use of deep neural networks (DNNs) renders automated driving\nvulnerable to machine learning-based attacks. In this work, we explore\nbackdooring/trojanning of DRL-based AV controllers. We develop a trigger design\nmethodology that is based on well-established principles of traffic physics.\nThe malicious actions include vehicle deceleration and acceleration to cause\nstop-and-go traffic waves to emerge (congestion attacks), or AV acceleration\nresulting in the AV crashing into the vehicle in front (insurance attack). In\nthe pre-injection stage, we consider the stealth of this backdoor attack by\nselecting triggers that are closest to the genuine data. We demonstrate our\nattack in simulated traffic on a circular track. Experimental results show that\nthe backdoored model does not compromise the performance of normal operation\nwith the maximum decrease in cumulative rewards being 1%, but it can be\nmaliciously activated to cause a crash or congestion when the corresponding\ntriggers appear. We also discuss the effectiveness of state-of-the-art defenses\ntowards the presented attacks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 08:20:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 10:47:54 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 09:19:00 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wang", "Yue", ""], ["Sarkar", "Esha", ""], ["Li", "Wenqing", ""], ["Maniatakos", "Michail", ""], ["Jabari", "Saif Eddin", ""]]}, {"id": "2003.07896", "submitter": "Yihan Li", "authors": "Lawrence G. Phillips, David B. Grimes, Yihan Jessie Li", "title": "Teacher-Student Domain Adaptation for Biosensor Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to domain adaptation, addressing the case where data\nfrom the source domain is abundant, labelled data from the target domain is\nlimited or non-existent, and a small amount of paired source-target data is\navailable. The method is designed for developing deep learning models that\ndetect the presence of medical conditions based on data from consumer-grade\nportable biosensors. It addresses some of the key problems in this area,\nnamely, the difficulty of acquiring large quantities of clinically labelled\ndata from the biosensor, and the noise and ambiguity that can affect the\nclinical labels. The idea is to pre-train an expressive model on a large\ndataset of labelled recordings from a sensor modality for which data is\nabundant, and then to adapt the model's lower layers so that its predictions on\nthe target modality are similar to the original model's on paired examples from\nthe source modality. We show that the pre-trained model's predictions provide a\nsubstantially better learning signal than the clinician-provided labels, and\nthat this teacher-student technique significantly outperforms both a naive\napplication of supervised deep learning and a label-supervised version of\ndomain adaptation on a synthetic dataset and in a real-world case study on\nsleep apnea. By reducing the volume of data required and obviating the need for\nlabels, our approach should reduce the cost associated with developing\nhigh-performance deep learning models for biosensors.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:09:53 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 08:03:26 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Phillips", "Lawrence G.", ""], ["Grimes", "David B.", ""], ["Li", "Yihan Jessie", ""]]}, {"id": "2003.07898", "submitter": "Kun Chen", "authors": "Kun Chen, Ruipeng Dong, Wanwan Xu, Zemin Zheng", "title": "Statistically Guided Divide-and-Conquer for Sparse Factorization of\n  Large Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse factorization of a large matrix is fundamental in modern\nstatistical learning. In particular, the sparse singular value decomposition\nand its variants have been utilized in multivariate regression, factor\nanalysis, biclustering, vector time series modeling, among others. The appeal\nof this factorization is owing to its power in discovering a\nhighly-interpretable latent association network, either between samples and\nvariables or between responses and predictors. However, many existing methods\nare either ad hoc without a general performance guarantee, or are\ncomputationally intensive, rendering them unsuitable for large-scale studies.\nWe formulate the statistical problem as a sparse factor regression and tackle\nit with a divide-and-conquer approach. In the first stage of division, we\nconsider both sequential and parallel approaches for simplifying the task into\na set of co-sparse unit-rank estimation (CURE) problems, and establish the\nstatistical underpinnings of these commonly-adopted and yet poorly understood\ndeflation methods. In the second stage of division, we innovate a contended\nstagewise learning technique, consisting of a sequence of simple incremental\nupdates, to efficiently trace out the whole solution paths of CURE. Our\nalgorithm has a much lower computational complexity than alternating convex\nsearch, and the choice of the step size enables a flexible and principled\ntradeoff between statistical accuracy and computational efficiency. Our work is\namong the first to enable stagewise learning for non-convex problems, and the\nidea can be applicable in many multi-convex problems. Extensive simulation\nstudies and an application in genetics demonstrate the effectiveness and\nscalability of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:12:21 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Chen", "Kun", ""], ["Dong", "Ruipeng", ""], ["Xu", "Wanwan", ""], ["Zheng", "Zemin", ""]]}, {"id": "2003.07904", "submitter": "Chao Yan", "authors": "Chao Yan, Ziqi Zhang, Steve Nyemba, Bradley A. Malin", "title": "Generating Electronic Health Records with Multiple Data Types and\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing electronic health records (EHRs) on a large scale may lead to privacy\nintrusions. Recent research has shown that risks may be mitigated by simulating\nEHRs through generative adversarial network (GAN) frameworks. Yet the methods\ndeveloped to date are limited because they 1) focus on generating data of a\nsingle type (e.g., diagnosis codes), neglecting other data types (e.g.,\ndemographics, procedures or vital signs) and 2) do not represent constraints\nbetween features. In this paper, we introduce a method to simulate EHRs\ncomposed of multiple data types by 1) refining the GAN model, 2) accounting for\nfeature constraints, and 3) incorporating key utility measures for such\ngeneration tasks. Our analysis with over $770,000$ EHRs from Vanderbilt\nUniversity Medical Center demonstrates that the new model achieves higher\nperformance in terms of retaining basic statistics, cross-feature correlations,\nlatent structural properties, feature constraints and associated patterns from\nreal data, without sacrificing privacy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:25:16 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 22:01:37 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yan", "Chao", ""], ["Zhang", "Ziqi", ""], ["Nyemba", "Steve", ""], ["Malin", "Bradley A.", ""]]}, {"id": "2003.07921", "submitter": "Colin Hansen", "authors": "Colin B. Hansen, Vishwesh Nath, Diego A. Mesa, Yuankai Huo, Bennett A.\n  Landman, Thomas A. Lasko", "title": "The Value of Nullspace Tuning Using Partial Label Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised learning, information from unlabeled examples is used to\nimprove the model learned from labeled examples. But in some learning problems,\npartial label information can be inferred from otherwise unlabeled examples and\nused to further improve the model. In particular, partial label information\nexists when subsets of training examples are known to have the same label, even\nthough the label itself is missing. By encouraging a model to give the same\nlabel to all such examples, we can potentially improve its performance. We call\nthis encouragement \\emph{Nullspace Tuning} because the difference vector\nbetween any pair of examples with the same label should lie in the nullspace of\na linear model. In this paper, we investigate the benefit of using partial\nlabel information using a careful comparison framework over well-characterized\npublic datasets. We show that the additional information provided by partial\nlabels reduces test error over good semi-supervised methods usually by a factor\nof 2, up to a factor of 5.5 in the best case. We also show that adding\nNullspace Tuning to the newer and state-of-the-art MixMatch method decreases\nits test error by up to a factor of 1.8.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 20:08:02 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Hansen", "Colin B.", ""], ["Nath", "Vishwesh", ""], ["Mesa", "Diego A.", ""], ["Huo", "Yuankai", ""], ["Landman", "Bennett A.", ""], ["Lasko", "Thomas A.", ""]]}, {"id": "2003.07926", "submitter": "William Hsieh Prof.", "authors": "William W. Hsieh", "title": "Improving predictions by nonlinear regression models from outlying input\n  data", "comments": "26 pages, 12 figures. Preprint of a paper accepted for publication by\n  the Journal of Environmental Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying machine learning/statistical methods to the environmental\nsciences, nonlinear regression (NLR) models often perform only slightly better\nand occasionally worse than linear regression (LR). The proposed reason for\nthis conundrum is that NLR models can give predictions much worse than LR when\ngiven input data which lie outside the domain used in model training.\nContinuous unbounded variables are widely used in environmental sciences,\nwhence not uncommon for new input data to lie far outside the training domain.\nFor six environmental datasets, inputs in the test data were classified as\n\"outliers\" and \"non-outliers\" based on the Mahalanobis distance from the\ntraining input data. The prediction scores (mean absolute error, Spearman\ncorrelation) showed NLR to outperform LR for the non-outliers, but often\nunderperform LR for the outliers. An approach based on Occam's Razor (OR) was\nproposed, where linear extrapolation was used instead of nonlinear\nextrapolation for the outliers. The linear extrapolation to the outlier domain\nwas based on the NLR model within the non-outlier domain. This\nNLR$_{\\mathrm{OR}}$ approach reduced occurrences of very poor extrapolation by\nNLR, and it tended to outperform NLR and LR for the outliers. In conclusion,\ninput test data should be screened for outliers. For outliers, the unreliable\nNLR predictions can be replaced by NLR$_{\\mathrm{OR}}$ or LR predictions, or by\nissuing a \"no reliable prediction\" warning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 20:28:21 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Hsieh", "William W.", ""]]}, {"id": "2003.07937", "submitter": "Yassir Jedra", "authors": "Yassir Jedra and Alexandre Proutiere", "title": "Finite-time Identification of Stable Linear Systems: Optimality of the\n  Least-Squares Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.SY eess.SY stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new finite-time analysis of the estimation error of the Ordinary\nLeast Squares (OLS) estimator for stable linear time-invariant systems. We\ncharacterize the number of observed samples (the length of the observed\ntrajectory) sufficient for the OLS estimator to be $(\\varepsilon,\\delta)$-PAC,\ni.e., to yield an estimation error less than $\\varepsilon$ with probability at\nleast $1-\\delta$. We show that this number matches existing sample complexity\nlower bounds [1,2] up to universal multiplicative factors (independent of\n($\\varepsilon,\\delta)$ and of the system). This paper hence establishes the\noptimality of the OLS estimator for stable systems, a result conjectured in\n[1]. Our analysis of the performance of the OLS estimator is simpler, sharper,\nand easier to interpret than existing analyses. It relies on new concentration\nresults for the covariates matrix.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 20:59:17 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 20:50:34 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 17:54:55 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Jedra", "Yassir", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2003.07952", "submitter": "Raquel Aoki", "authors": "Raquel Aoki and Martin Ester", "title": "ParKCa: Causal Inference with Partially Known Causes", "comments": "12 pages, 4 figures, Pacific Symposium on Biocomputing - 2021 World\n  Scientific Publishing Co., Singapore, http://psb.stanford.edu/", "journal-ref": "Pacific Symposium on Biocomputing - 2021 World Scientific\n  Publishing Co., Singapore, http://psb.stanford.edu/", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for causal inference from observational data are an alternative for\nscenarios where collecting counterfactual data or realizing a randomized\nexperiment is not possible. Adopting a stacking approach, our proposed method\nParKCA combines the results of several causal inference methods to learn new\ncauses in applications with some known causes and many potential causes. We\nvalidate ParKCA in two Genome-wide association studies, one real-world and one\nsimulated dataset. Our results show that ParKCA can infer more causes than\nexisting methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 21:36:56 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 18:08:23 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 01:14:59 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 22:13:54 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Aoki", "Raquel", ""], ["Ester", "Martin", ""]]}, {"id": "2003.07953", "submitter": "Shounak Chattopadhyay", "authors": "Shounak Chattopadhyay, Antik Chakraborty, David B. Dunson", "title": "Nearest Neighbor Dirichlet Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is a rich literature on Bayesian nonparametric methods for unknown\ndensities. The most popular approach relies on Dirichlet process mixture\nmodels. These models characterize the unknown density as a kernel convolution\nwith an unknown almost surely discrete mixing measure, which is given a\nDirichlet process prior. Such models are very flexible and have good\nperformance in many settings, but posterior computation typically relies on\nMarkov chain Monte Carlo algorithms that can be complex and inefficient. As a\nsimple alternative, we propose a class of nearest neighbor-Dirichlet processes.\nThe approach starts by grouping the data into neighborhoods based on standard\nalgorithms. Within each neighborhood, the density is characterized via a\nBayesian parametric model, such as a Gaussian with unknown parameters.\nAssigning a Dirichlet prior to the weights on these local kernels, we obtain a\nsimple pseudo-posterior for the weights and kernel parameters. A simple and\nembarrassingly parallel Monte Carlo algorithm is proposed to sample from the\nresulting pseudo-posterior for the unknown density. Desirable asymptotic\nproperties are shown, and the methods are evaluated in simulation studies and\napplied to a motivating data set in the context of classification.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 21:39:11 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 00:21:27 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chattopadhyay", "Shounak", ""], ["Chakraborty", "Antik", ""], ["Dunson", "David B.", ""]]}, {"id": "2003.07977", "submitter": "Sarah Hooper", "authors": "Sarah M. Hooper, Jared A. Dunnmon, Matthew P. Lungren, Sanjiv Sam\n  Gambhir, Christopher R\\'e, Adam S. Wang and Bhavik N. Patel", "title": "Assessing Robustness to Noise: Low-Cost Head CT Triage", "comments": "AI for Affordable Healthcare Workshop at ICLR 2020. First two authors\n  have equal contribution; last two authors have equal contribution. Revision\n  made to manuscript header according to workshop guidelines on 3/28/20", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated medical image classification with convolutional neural networks\n(CNNs) has great potential to impact healthcare, particularly in\nresource-constrained healthcare systems where fewer trained radiologists are\navailable. However, little is known about how well a trained CNN can perform on\nimages with the increased noise levels, different acquisition protocols, or\nadditional artifacts that may arise when using low-cost scanners, which can be\nunderrepresented in datasets collected from well-funded hospitals. In this\nwork, we investigate how a model trained to triage head computed tomography\n(CT) scans performs on images acquired with reduced x-ray tube current, fewer\nprojections per gantry rotation, and limited angle scans. These changes can\nreduce the cost of the scanner and demands on electrical power but come at the\nexpense of increased image noise and artifacts. We first develop a model to\ntriage head CTs and report an area under the receiver operating characteristic\ncurve (AUROC) of 0.77. We then show that the trained model is robust to reduced\ntube current and fewer projections, with the AUROC dropping only 0.65% for\nimages acquired with a 16x reduction in tube current and 0.22% for images\nacquired with 8x fewer projections. Finally, for significantly degraded images\nacquired by a limited angle scan, we show that a model trained specifically to\nclassify such images can overcome the technological limitations to\nreconstruction and maintain an AUROC within 0.09% of the original model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 22:49:37 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 03:51:08 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hooper", "Sarah M.", ""], ["Dunnmon", "Jared A.", ""], ["Lungren", "Matthew P.", ""], ["Gambhir", "Sanjiv Sam", ""], ["R\u00e9", "Christopher", ""], ["Wang", "Adam S.", ""], ["Patel", "Bhavik N.", ""]]}, {"id": "2003.07981", "submitter": "Margarida Carvalho", "authors": "Jorge Oliveira, Margarida Carvalho, Diogo Marcelo Nogueira, Miguel\n  Coimbra", "title": "Segmentation and Optimal Region Selection of Physiological Signals using\n  Deep Neural Networks and Combinatorial Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physiological signals, such as the electrocardiogram and the phonocardiogram\nare very often corrupted by noisy sources. Usually, artificial intelligent\nalgorithms analyze the signal regardless of its quality. On the other hand,\nphysicians use a completely orthogonal strategy. They do not assess the entire\nrecording, instead they search for a segment where the fundamental and abnormal\nwaves are easily detected, and only then a prognostic is attempted.\n  Inspired by this fact, a new algorithm that automatically selects an optimal\nsegment for a post-processing stage, according to a criteria defined by the\nuser is proposed. In the process, a Neural Network is used to compute the\noutput state probability distribution for each sample. Using the aforementioned\nquantities, a graph is designed, whereas state transition constraints are\nphysically imposed into the graph and a set of constraints are used to retrieve\na subset of the recording that maximizes the likelihood function, proposed by\nthe user.\n  The developed framework is tested and validated in two applications. In both\ncases, the system performance is boosted significantly, e.g in heart sound\nsegmentation, sensitivity increases 2.4% when compared to the standard\napproaches in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 23:15:15 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Oliveira", "Jorge", ""], ["Carvalho", "Margarida", ""], ["Nogueira", "Diogo Marcelo", ""], ["Coimbra", "Miguel", ""]]}, {"id": "2003.07982", "submitter": "Ramesh Sah", "authors": "Ramesh Kumar Sah and Hassan Ghasemzadeh", "title": "Adversarial Transferability in Wearable Sensor Systems", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is used for inference and decision making in wearable sensor\nsystems. However, recent studies have found that machine learning algorithms\nare easily fooled by the addition of adversarial perturbations to their inputs.\nWhat is more interesting is that adversarial examples generated for one machine\nlearning system is also effective against other systems. This property of\nadversarial examples is called transferability. In this work, we take the first\nstride in studying adversarial transferability in wearable sensor systems from\nthe following perspectives: 1) transferability between machine learning\nsystems, 2) transferability across subjects, 3) transferability across sensor\nbody locations, and 4) transferability across datasets. We found strong\nuntargeted transferability in most cases. Targeted attacks were less successful\nwith success scores from $0\\%$ to $80\\%$. The transferability of adversarial\nexamples depends on many factors such as the inclusion of data from all\nsubjects, sensor body position, number of samples in the dataset, type of\nlearning algorithm, and the distribution of source and target system dataset.\nThe transferability of adversarial examples decreases sharply when the data\ndistribution of the source and target system becomes more distinct. We also\nprovide guidelines for the community for designing robust sensor systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 23:19:52 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 16:10:42 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sah", "Ramesh Kumar", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2003.08011", "submitter": "Guang Chao Wang", "authors": "Guang Chao Wang, Kenny Gross, and Akshay Subramaniam", "title": "ContainerStress: Autonomous Cloud-Node Scoping Framework for Big-Data ML\n  Use Cases", "comments": "To be published in 6th Annual Conf. on Computational Science &\n  Computational Intelligence (CSCI'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying big-data Machine Learning (ML) services in a cloud environment\npresents a challenge to the cloud vendor with respect to the cloud container\nconfiguration sizing for any given customer use case. OracleLabs has developed\nan automated framework that uses nested-loop Monte Carlo simulation to\nautonomously scale any size customer ML use cases across the range of cloud\nCPU-GPU \"Shapes\" (configurations of CPUs and/or GPUs in Cloud containers\navailable to end customers). Moreover, the OracleLabs and NVIDIA authors have\ncollaborated on a ML benchmark study which analyzes the compute cost and GPU\nacceleration of any ML prognostic algorithm and assesses the reduction of\ncompute cost in a cloud container comprising conventional CPUs and NVIDIA GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:51:42 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Wang", "Guang Chao", ""], ["Gross", "Kenny", ""], ["Subramaniam", "Akshay", ""]]}, {"id": "2003.08051", "submitter": "Chuang Ma", "authors": "Qing Tian, Chuang Ma, Meng Cao, Songcan Chen", "title": "Unsupervised Domain Adaptation Through Transferring both the\n  Source-Knowledge and Target-Relatedness Simultaneously", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) is an emerging research topic in the\nfield of machine learning and pattern recognition, which aims to help the\nlearning of unlabeled target domain by transferring knowledge from the source\ndomain. To perform UDA, a variety of methods have been proposed, most of which\nconcentrate on the scenario of single source and single target domain (1S1T).\nHowever, in real applications, usually single source domain with multiple\ntarget domains are involved (1SmT), which cannot be handled directly by those\n1S1T models. Unfortunately, although a few related works on 1SmT UDA have been\nproposed, nearly none of them model the source domain knowledge and leverage\nthe target-relatedness jointly. To overcome these shortcomings, we herein\npropose a more general 1SmT UDA model through transferring both the\nSource-Knowledge and Target-Relatedness, UDA-SKTR for short. In this way, not\nonly the supervision knowledge from the source domain, but also the potential\nrelatedness among the target domains are simultaneously modeled for\nexploitation in the process of 1SmT UDA. In addition, we construct an\nalternating optimization algorithm to solve the variables of the proposed model\nwith convergence guarantee. Finally, through extensive experiments on both\nbenchmark and real datasets, we validate the effectiveness and superiority of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 05:27:28 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 05:33:04 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Tian", "Qing", ""], ["Ma", "Chuang", ""], ["Cao", "Meng", ""], ["Chen", "Songcan", ""]]}, {"id": "2003.08063", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Michelangelo Bin, Jinkyoo Park,\n  Atsushi Yamashita, Hajime Asama", "title": "Stable Neural Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a provably stable variant of neural ordinary differential\nequations (neural ODEs) whose trajectories evolve on an energy functional\nparametrised by a neural network. Stable neural flows provide an implicit\nguarantee on asymptotic stability of the depth-flows, leading to robustness\nagainst input perturbations and low computational burden for the numerical\nsolver. The learning procedure is cast as an optimal control problem, and an\napproximate solution is proposed based on adjoint sensivity analysis. We\nfurther introduce novel regularizers designed to ease the optimization process\nand speed up convergence. The proposed model class is evaluated on non-linear\nclassification and function approximation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 06:27:21 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Bin", "Michelangelo", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "2003.08082", "submitter": "Tzu-Ming Harry Hsu", "authors": "Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown", "title": "Federated Visual Classification with Real-World Data Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables visual models to be trained on-device, bringing\nadvantages for user privacy (data need never leave the device), but challenges\nin terms of data diversity and quality. Whilst typical models in the datacenter\nare trained using data that are independent and identically distributed (IID),\ndata at source are typically far from IID. Furthermore, differing quantities of\ndata are typically available at each device (imbalance). In this work, we\ncharacterize the effect these real-world data distributions have on distributed\nlearning, using as a benchmark the standard Federated Averaging (FedAvg)\nalgorithm. To do so, we introduce two new large-scale datasets for species and\nlandmark classification, with realistic per-user data splits that simulate\nreal-world edge learning scenarios. We also develop two new algorithms (FedVC,\nFedIR) that intelligently resample and reweight over the client pool, bringing\nlarge improvements in accuracy and stability in training. The datasets are made\navailable online.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 07:55:49 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 01:13:08 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 14:25:27 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Hsu", "Tzu-Ming Harry", ""], ["Qi", "Hang", ""], ["Brown", "Matthew", ""]]}, {"id": "2003.08089", "submitter": "Jay Whang", "authors": "Jay Whang, Qi Lei, Alexandros G. Dimakis", "title": "Solving Inverse Problems with a Flow-based Noise Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study image inverse problems with a normalizing flow prior. Our\nformulation views the solution as the maximum a posteriori estimate of the\nimage conditioned on the measurements. This formulation allows us to use noise\nmodels with arbitrary dependencies as well as non-linear forward operators. We\nempirically validate the efficacy of our method on various inverse problems,\nincluding compressed sensing with quantized measurements and denoising with\nhighly structured noise patterns. We also present initial theoretical recovery\nguarantees for solving inverse problems with a flow prior.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 08:33:49 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 06:35:13 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 07:46:59 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Whang", "Jay", ""], ["Lei", "Qi", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "2003.08093", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh and Meisam Razaviyayn", "title": "Solving Non-Convex Non-Differentiable Min-Max Games using Proximal\n  Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Min-max saddle point games appear in a wide range of applications in machine\nleaning and signal processing. Despite their wide applicability, theoretical\nstudies are mostly limited to the special convex-concave structure. While some\nrecent works generalized these results to special smooth non-convex cases, our\nunderstanding of non-smooth scenarios is still limited. In this work, we study\nspecial form of non-smooth min-max games when the objective function is\n(strongly) convex with respect to one of the player's decision variable. We\nshow that a simple multi-step proximal gradient descent-ascent algorithm\nconverges to $\\epsilon$-first-order Nash equilibrium of the min-max game with\nthe number of gradient evaluations being polynomial in $1/\\epsilon$. We will\nalso show that our notion of stationarity is stronger than existing ones in the\nliterature. Finally, we evaluate the performance of the proposed algorithm\nthrough adversarial attack on a LASSO estimator.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 08:38:34 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Barazandeh", "Babak", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2003.08109", "submitter": "Remi Jezequel", "authors": "R\\'emi J\\'ez\\'equel (SIERRA), Pierre Gaillard (SIERRA), Alessandro\n  Rudi (SIERRA)", "title": "Efficient improper learning for online logistic regression", "comments": null, "journal-ref": "Conference on Learning Theory 2020, Jul 2020, Graz, Austria", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of online logistic regression and consider the regret\nwith respect to the 2-ball of radius B. It is known (see [Hazan et al., 2014])\nthat any proper algorithm which has logarithmic regret in the number of samples\n(denoted n) necessarily suffers an exponential multiplicative constant in B. In\nthis work, we design an efficient improper algorithm that avoids this\nexponential constant while preserving a logarithmic regret. Indeed, [Foster et\nal., 2018] showed that the lower bound does not apply to improper algorithms\nand proposed a strategy based on exponential weights with prohibitive\ncomputational complexity. Our new algorithm based on regularized empirical risk\nminimization with surrogate losses satisfies a regret scaling as O(B log(Bn))\nwith a per-round time-complexity of order O(d^2).\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 09:16:14 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 14:00:39 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 08:01:06 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["J\u00e9z\u00e9quel", "R\u00e9mi", "", "SIERRA"], ["Gaillard", "Pierre", "", "SIERRA"], ["Rudi", "Alessandro", "", "SIERRA"]]}, {"id": "2003.08197", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Manzil Zaheer, Yuan Wang, Amr Ahmed", "title": "Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies", "comments": "ICLR 2021, code can be found at\n  http://github.com/pliang279/sparse_discrete", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continuous representations of discrete objects such as text, users,\nmovies, and URLs lies at the heart of many applications including language and\nuser modeling. When using discrete objects as input to neural networks, we\noften ignore the underlying structures (e.g., natural groupings and\nsimilarities) and embed the objects independently into individual vectors. As a\nresult, existing methods do not scale to large vocabulary sizes. In this paper,\nwe design a simple and efficient embedding algorithm that learns a small set of\nanchor embeddings and a sparse transformation matrix. We call our method Anchor\n& Transform (ANT) as the embeddings of discrete objects are a sparse linear\ncombination of the anchors, weighted according to the transformation matrix.\nANT is scalable, flexible, and end-to-end trainable. We further provide a\nstatistical interpretation of our algorithm as a Bayesian nonparametric prior\nfor embeddings that encourages sparsity and leverages natural groupings among\nobjects. By deriving an approximate inference algorithm based on Small Variance\nAsymptotics, we obtain a natural extension that automatically learns the\noptimal number of anchors instead of having to tune it as a hyperparameter. On\ntext classification, language modeling, and movie recommendation benchmarks, we\nshow that ANT is particularly suitable for large vocabulary sizes and\ndemonstrates stronger performance with fewer parameters (up to 40x compression)\nas compared to existing compression baselines.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 13:07:51 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 03:51:17 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 04:43:51 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 06:11:05 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Liang", "Paul Pu", ""], ["Zaheer", "Manzil", ""], ["Wang", "Yuan", ""], ["Ahmed", "Amr", ""]]}, {"id": "2003.08221", "submitter": "Jun Seo", "authors": "Jun Seo, Sung Whan Yoon, Jaekyun Moon", "title": "Task-Adaptive Clustering for Semi-Supervised Few-Shot Classification", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning aims to handle previously unseen tasks using only a small\namount of new training data. In preparing (or meta-training) a few-shot\nlearner, however, massive labeled data are necessary. In the real world,\nunfortunately, labeled data are expensive and/or scarce. In this work, we\npropose a few-shot learner that can work well under the semi-supervised setting\nwhere a large portion of training data is unlabeled. Our method employs\nexplicit task-conditioning in which unlabeled sample clustering for the current\ntask takes place in a new projection space different from the embedding feature\nspace. The conditioned clustering space is linearly constructed so as to\nquickly close the gap between the class centroids for the current task and the\nindependent per-class reference vectors meta-trained across tasks. In a more\ngeneral setting, our method introduces a concept of controlling the degree of\ntask-conditioning for meta-learning: the amount of task-conditioning varies\nwith the number of repetitive updates for the clustering space. Extensive\nsimulation results based on the miniImageNet and tieredImageNet datasets show\nstate-of-the-art semi-supervised few-shot classification performance of the\nproposed method. Simulation results also indicate that the proposed\ntask-adaptive clustering shows graceful degradation with a growing number of\ndistractor samples, i.e., unlabeled sample images coming from outside the\ncandidate classes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 13:50:19 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Seo", "Jun", ""], ["Yoon", "Sung Whan", ""], ["Moon", "Jaekyun", ""]]}, {"id": "2003.08246", "submitter": "Ning Ma", "authors": "Ning Ma, Jiajun Bu, Jieyu Yang, Zhen Zhang, Chengwei Yao, Zhi Yu,\n  Sheng Zhou and Xifeng Yan", "title": "Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification aims to extract accurate information from\ngraph-structured data for classification and is becoming more and more\nimportant in graph learning community. Although Graph Neural Networks (GNNs)\nhave been successfully applied to graph classification tasks, most of them\noverlook the scarcity of labeled graph data in many applications. For example,\nin bioinformatics, obtaining protein graph labels usually needs laborious\nexperiments. Recently, few-shot learning has been explored to alleviate this\nproblem with only given a few labeled graph samples of test classes. The shared\nsub-structures between training classes and test classes are essential in\nfew-shot graph classification. Exiting methods assume that the test classes\nbelong to the same set of super-classes clustered from training classes.\nHowever, according to our observations, the label spaces of training classes\nand test classes usually do not overlap in real-world scenario. As a result,\nthe existing methods don't well capture the local structures of unseen test\nclasses. To overcome the limitation, in this paper, we propose a direct method\nto capture the sub-structures with well initialized meta-learner within a few\nadaptation steps. More specifically, (1) we propose a novel framework\nconsisting of a graph meta-learner, which uses GNNs based modules for fast\nadaptation on graph data, and a step controller for the robustness and\ngeneralization of meta-learner; (2) we provide quantitative analysis for the\nframework and give a graph-dependent upper bound of the generalization error\nbased on our framework; (3) the extensive experiments on real-world datasets\ndemonstrate that our framework gets state-of-the-art results on several\nfew-shot graph classification tasks compared to baselines.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 14:38:48 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 06:22:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ma", "Ning", ""], ["Bu", "Jiajun", ""], ["Yang", "Jieyu", ""], ["Zhang", "Zhen", ""], ["Yao", "Chengwei", ""], ["Yu", "Zhi", ""], ["Zhou", "Sheng", ""], ["Yan", "Xifeng", ""]]}, {"id": "2003.08259", "submitter": "Nishanth Dikkala", "authors": "Constantinos Daskalakis, Nishanth Dikkala and Ioannis Panageas", "title": "Logistic-Regression with peer-group effects via inference in higher\n  order Ising models", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin glass models, such as the Sherrington-Kirkpatrick, Hopfield and Ising\nmodels, are all well-studied members of the exponential family of discrete\ndistributions, and have been influential in a number of application domains\nwhere they are used to model correlation phenomena on networks. Conventionally\nthese models have quadratic sufficient statistics and consequently capture\ncorrelations arising from pairwise interactions. In this work we study\nextensions of these to models with higher-order sufficient statistics, modeling\nbehavior on a social network with peer-group effects. In particular, we model\nbinary outcomes on a network as a higher-order spin glass, where the behavior\nof an individual depends on a linear function of their own vector of covariates\nand some polynomial function of the behavior of others, capturing peer-group\neffects. Using a {\\em single}, high-dimensional sample from such model our goal\nis to recover the coefficients of the linear function as well as the strength\nof the peer-group effects. The heart of our result is a novel approach for\nshowing strong concavity of the log pseudo-likelihood of the model, implying\nstatistical error rate of $\\sqrt{d/n}$ for the Maximum Pseudo-Likelihood\nEstimator (MPLE), where $d$ is the dimensionality of the covariate vectors and\n$n$ is the size of the network (number of nodes). Our model generalizes vanilla\nlogistic regression as well as the peer-effect models studied in recent works,\nand our results extend these results to accommodate higher-order interactions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:02:47 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Panageas", "Ioannis", ""]]}, {"id": "2003.08302", "submitter": "Liao Zhu", "authors": "Robert A. Jarrow, Rinald Murataj, Martin T. Wells, Liao Zhu", "title": "The Low-volatility Anomaly and the Adaptive Multi-Factor Model", "comments": "29 pages, 11 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides a new explanation of the low-volatility anomaly. We use\nthe Adaptive Multi-Factor (AMF) model estimated by the Groupwise Interpretable\nBasis Selection (GIBS) algorithm to find those basis assets significantly\nrelated to low and high volatility portfolios. These two portfolios load on\nvery different factors, indicating that volatility is not an independent risk,\nbut that it's related to existing risk factors. The out-performance of the\nlow-volatility portfolio is due to the (equilibrium) performance of these\nloaded risk factors. The AMF model outperforms the Fama-French 5-factor model\nboth in-sample and out-of-sample.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 20:08:31 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 22:56:31 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jarrow", "Robert A.", ""], ["Murataj", "Rinald", ""], ["Wells", "Martin T.", ""], ["Zhu", "Liao", ""]]}, {"id": "2003.08334", "submitter": "Huynh Van Luong", "authors": "Huynh Van Luong, Boris Joukovsky, Nikos Deligiannis", "title": "Interpretable Deep Recurrent Neural Networks via Unfolding Reweighted\n  $\\ell_1$-$\\ell_1$ Minimization: Architecture Design and Generalization\n  Analysis", "comments": "Pre-print: 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding methods---for example, the learned iterative shrinkage\nthresholding algorithm (LISTA)---design deep neural networks as learned\nvariations of optimization methods. These networks have been shown to achieve\nfaster convergence and higher accuracy than the original optimization methods.\nIn this line of research, this paper develops a novel deep recurrent neural\nnetwork (coined reweighted-RNN) by the unfolding of a reweighted\n$\\ell_1$-$\\ell_1$ minimization algorithm and applies it to the task of\nsequential signal reconstruction. To the best of our knowledge, this is the\nfirst deep unfolding method that explores reweighted minimization. Due to the\nunderlying reweighted minimization model, our RNN has a different\nsoft-thresholding function (alias, different activation functions) for each\nhidden unit in each layer. Furthermore, it has higher network expressivity than\nexisting deep unfolding RNN models due to the over-parameterizing weights.\nImportantly, we establish theoretical generalization error bounds for the\nproposed reweighted-RNN model by means of Rademacher complexity. The bounds\nreveal that the parameterization of the proposed reweighted-RNN ensures good\ngeneralization. We apply the proposed reweighted-RNN to the problem of video\nframe reconstruction from low-dimensional measurements, that is, sequential\nframe reconstruction. The experimental results on the moving MNIST dataset\ndemonstrate that the proposed deep reweighted-RNN significantly outperforms\nexisting RNN models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:02:10 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Van Luong", "Huynh", ""], ["Joukovsky", "Boris", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2003.08342", "submitter": "Witold Rudnicki", "authors": "Krzysztof Mnich and Agnieszka Kitlas Goli\\'nska and Aneta Polewko-Klim\n  and Witold R. Rudnicki", "title": "Bootstrap Bias Corrected Cross Validation applied to Super Learning", "comments": "14 pages, 4 tables, 1 figure, submitted to International Conference\n  on Computational Science, Amsterdam 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Super learner algorithm can be applied to combine results of multiple base\nlearners to improve quality of predictions. The default method for verification\nof super learner results is by nested cross validation. It has been proposed by\nTsamardinos et al., that nested cross validation can be replaced by resampling\nfor tuning hyper-parameters of the learning algorithms. We apply this idea to\nverification of super learner and compare with other verification methods,\nincluding nested cross validation. Tests were performed on artificial data sets\nof diverse size and on seven real, biomedical data sets. The resampling method,\ncalled Bootstrap Bias Correction, proved to be a reasonably precise and very\ncost-efficient alternative for nested cross validation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:12:42 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Mnich", "Krzysztof", ""], ["Goli\u0144ska", "Agnieszka Kitlas", ""], ["Polewko-Klim", "Aneta", ""], ["Rudnicki", "Witold R.", ""]]}, {"id": "2003.08353", "submitter": "Marc Brittain", "authors": "Marc Brittain, Xuxi Yang, Peng Wei", "title": "A Deep Multi-Agent Reinforcement Learning Approach to Autonomous\n  Separation Assurance", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel deep multi-agent reinforcement learning framework is proposed to\nidentify and resolve conflicts among a variable number of aircraft in a\nhigh-density, stochastic, and dynamic sector. Currently the sector capacity is\nconstrained by human air traffic controller's cognitive limitation. We\ninvestigate the feasibility of a new concept (autonomous separation assurance)\nand a new approach to push the sector capacity above human cognitive\nlimitation. We propose the concept of using distributed vehicle autonomy to\nensure separation, instead of a centralized sector air traffic controller. Our\nproposed framework utilizes Proximal Policy Optimization (PPO) that we modify\nto incorporate an attention network. This allows the agents to have access to\nvariable aircraft information in the sector in a scalable, efficient approach\nto achieve high traffic throughput under uncertainty. Agents are trained using\na centralized learning, decentralized execution scheme where one neural network\nis learned and shared by all agents. The proposed framework is validated on\nthree challenging case studies in the BlueSky air traffic control environment.\nNumerical results show the proposed framework significantly reduces offline\ntraining time, increases performance, and results in a more efficient policy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:50:34 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 16:46:52 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Brittain", "Marc", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "2003.08356", "submitter": "Bo Huang", "authors": "Cankun Qiu, Zhi Luo, Xia Wu, Huidong Yang, Bo Huang", "title": "Inverse design of multilayer nanoparticles using artificial neural\n  networks and genetic algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The light scattering of multilayer nanoparticles can be solved by Maxwell\nequations. However, it is difficult to solve the inverse design of multilayer\nnanoparticles by using the traditional trial-and-error method. Here, we present\na method for forward simulation and inverse design of multilayer nanoparticles.\nWe combine the global search ability of genetic algorithm with the local search\nability of neural network. First, the genetic algorithm is used to find a\nsuitable solution, and then the neural network is used to fine-tune it. Due to\nthe non-unique relationship between physical structures and optical responses,\nwe first train a forward neural network, and then it is applied to the inverse\ndesign of multilayer nanoparticles. Not only here, this method can easily be\nextended to predict and find the best design parameters for other optical\nstructures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 22:49:30 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Qiu", "Cankun", ""], ["Luo", "Zhi", ""], ["Wu", "Xia", ""], ["Yang", "Huidong", ""], ["Huang", "Bo", ""]]}, {"id": "2003.08359", "submitter": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k", "authors": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k, \\\"Ozkan Akbunar, Ali R{\\i}za Ekti, Ali\n  G\\\"or\\c{c}in, G\\\"une\\c{s} Karabulut Kurt, Khalid A. Qaraqe", "title": "Spectrum Sensing and Signal Identification with Deep Learning based on\n  Spectral Correlation Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Spectrum sensing is one of the means of utilizing the scarce source of\nwireless spectrum efficiently. In this paper, a convolutional neural network\n(CNN) model employing spectral correlation function which is an effective\ncharacterization of cyclostationarity property, is proposed for wireless\nspectrum sensing and signal identification. The proposed method classifies\nwireless signals without a priori information and it is implemented in two\ndifferent settings entitled CASE1 and CASE2. In CASE1, signals are jointly\nsensed and classified. In CASE2, sensing and classification are conducted in a\nsequential manner. In contrary to the classical spectrum sensing techniques,\nthe proposed CNN method does not require a statistical decision process and\ndoes not need to know the distinct features of signals beforehand.\nImplementation of the method on the measured overthe-air real-world signals in\ncellular bands indicates important performance gains when compared to the\nsignal classifying deep learning networks available in the literature and\nagainst classical sensing methods. Even though the implementation herein is\nover cellular signals, the proposed approach can be extended to the detection\nand classification of any signal that exhibits cyclostationary features.\nFinally, the measurement-based dataset which is utilized to validate the method\nis shared for the purposes of reproduction of the results and further research\nand development.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 06:56:26 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:35:25 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 09:03:58 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 16:45:38 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tekb\u0131y\u0131k", "K\u00fcr\u015fat", ""], ["Akbunar", "\u00d6zkan", ""], ["Ekti", "Ali R\u0131za", ""], ["G\u00f6r\u00e7in", "Ali", ""], ["Kurt", "G\u00fcne\u015f Karabulut", ""], ["Qaraqe", "Khalid A.", ""]]}, {"id": "2003.08365", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Yiting Chen, Liyao Xiang, Haotian Ma, Jie Shi, Quanshi\n  Zhang", "title": "Deep Quaternion Features for Privacy Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to revise the neural network to construct the\nquaternion-valued neural network (QNN), in order to prevent intermediate-layer\nfeatures from leaking input information. The QNN uses quaternion-valued\nfeatures, where each element is a quaternion. The QNN hides input information\ninto a random phase of quaternion-valued features. Even if attackers have\nobtained network parameters and intermediate-layer features, they cannot\nextract input information without knowing the target phase. In this way, the\nQNN can effectively protect the input privacy. Besides, the output accuracy of\nQNNs only degrades mildly compared to traditional neural networks, and the\ncomputational cost is much less than other privacy-preserving methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:38:24 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 09:37:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Yiting", ""], ["Xiang", "Liyao", ""], ["Ma", "Haotian", ""], ["Shi", "Jie", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2003.08371", "submitter": "Lev Utkin", "authors": "Maxim S. Kovalev, Lev V. Utkin, Ernest M. Kasimov", "title": "SurvLIME: A method for explaining machine learning survival models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method called SurvLIME for explaining machine learning survival models\nis proposed. It can be viewed as an extension or modification of the well-known\nmethod LIME. The main idea behind the proposed method is to apply the Cox\nproportional hazards model to approximate the survival model at the local area\naround a test example. The Cox model is used because it considers a linear\ncombination of the example covariates such that coefficients of the covariates\ncan be regarded as quantitative impacts on the prediction. Another idea is to\napproximate cumulative hazard functions of the explained model and the Cox\nmodel by using a set of perturbed points in a local area around the point of\ninterest. The method is reduced to solving an unconstrained convex optimization\nproblem. A lot of numerical experiments demonstrate the SurvLIME efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:48:42 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Kovalev", "Maxim S.", ""], ["Utkin", "Lev V.", ""], ["Kasimov", "Ernest M.", ""]]}, {"id": "2003.08414", "submitter": "Frederik Wenkel M.Sc.", "authors": "Yimeng Min (1), Frederik Wenkel (2 and 1), Guy Wolf (2 and 1) ((1)\n  Mila - Quebec AI Institute, Montr\\'eal, QC, Canada, (2) Department of\n  Mathematics & Statistics, Universit\\'e de Montr\\'eal, Montr\\'eal, QC, Canada)", "title": "Scattering GCN: Overcoming Oversmoothness in Graph Convolutional\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have shown promising results in\nprocessing graph data by extracting structure-aware features. This gave rise to\nextensive work in geometric deep learning, focusing on designing network\narchitectures that ensure neuron activations conform to regularity patterns\nwithin the input graph. However, in most cases the graph structure is only\naccounted for by considering the similarity of activations between adjacent\nnodes, which limits the capabilities of such methods to discriminate between\nnodes in a graph. Here, we propose to augment conventional GCNs with geometric\nscattering transforms and residual convolutions. The former enables band-pass\nfiltering of graph signals, thus alleviating the so-called oversmoothing often\nencountered in GCNs, while the latter is introduced to clear the resulting\nfeatures of high-frequency noise. We establish the advantages of the presented\nScattering GCN with both theoretical results establishing the complementary\nbenefits of scattering and GCN features, as well as experimental results\nshowing the benefits of our method compared to leading graph neural networks\nfor semi-supervised node classification, including the recently proposed GAT\nnetwork that typically alleviates oversmoothing using graph attention\nmechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 18:03:08 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 05:30:36 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Min", "Yimeng", "", "2 and 1"], ["Wenkel", "Frederik", "", "2 and 1"], ["Wolf", "Guy", "", "2 and 1"]]}, {"id": "2003.08420", "submitter": "Fei Ding", "authors": "Fei Ding, Xiaohong Zhang, Justin Sybrandt, Ilya Safro", "title": "Unsupervised Hierarchical Graph Representation Learning by Mutual\n  Information Maximization", "comments": "7 pages, 2 figures, 4 tables", "journal-ref": "the 16th International Workshop on Mining and Learning with Graphs\n  (MLG 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning based on graph neural networks (GNNs) can\ngreatly improve the performance of downstream tasks, such as node and graph\nclassification. However, the general GNN models do not aggregate node\ninformation in a hierarchical manner, and can miss key higher-order structural\nfeatures of many graphs. The hierarchical aggregation also enables the graph\nrepresentations to be explainable. In addition, supervised graph representation\nlearning requires labeled data, which is expensive and error-prone. To address\nthese issues, we present an unsupervised graph representation learning method,\nUnsupervised Hierarchical Graph Representation (UHGR), which can generate\nhierarchical representations of graphs. Our method focuses on maximizing mutual\ninformation between \"local\" and high-level \"global\" representations, which\nenables us to learn the node embeddings and graph embeddings without any\nlabeled data. To demonstrate the effectiveness of the proposed method, we\nperform the node and graph classification using the learned node and graph\nembeddings. The results show that the proposed method achieves comparable\nresults to state-of-the-art supervised methods on several benchmarks. In\naddition, our visualization of hierarchical representations indicates that our\nmethod can capture meaningful and interpretable clusters.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 18:21:48 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 23:04:54 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 03:05:29 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Ding", "Fei", ""], ["Zhang", "Xiaohong", ""], ["Sybrandt", "Justin", ""], ["Safro", "Ilya", ""]]}, {"id": "2003.08469", "submitter": "Julia Moosbauer", "authors": "Abhijeet Parida, Aadhithya Sankar, Rami Eisawy, Tom Finck, Benedikt\n  Wiestler, Franz Pfister, Julia Moosbauer", "title": "Train, Learn, Expand, Repeat", "comments": "Published as a workshop paper at AI4AH, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality labeled data is essential to successfully train supervised\nmachine learning models. Although a large amount of unlabeled data is present\nin the medical domain, labeling poses a major challenge: medical professionals\nwho can expertly label the data are a scarce and expensive resource. Making\nmatters worse, voxel-wise delineation of data (e.g. for segmentation tasks) is\ntedious and suffers from high inter-rater variance, thus dramatically limiting\navailable training data. We propose a recursive training strategy to perform\nthe task of semantic segmentation given only very few training samples with\npixel-level annotations. We expand on this small training set having cheaper\nimage-level annotations using a recursive training strategy. We apply this\ntechnique on the segmentation of intracranial hemorrhage (ICH) in CT (computed\ntomography) scans of the brain, where typically few annotated data is\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 20:55:38 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 12:25:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Parida", "Abhijeet", ""], ["Sankar", "Aadhithya", ""], ["Eisawy", "Rami", ""], ["Finck", "Tom", ""], ["Wiestler", "Benedikt", ""], ["Pfister", "Franz", ""], ["Moosbauer", "Julia", ""]]}, {"id": "2003.08485", "submitter": "Aniket Anand Deshmukh", "authors": "Aniket Anand Deshmukh, Abhimanu Kumar, Levi Boyles, Denis Charles,\n  Eren Manavoglu, Urun Dogan", "title": "Self-Supervised Contextual Bandits in Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits are a common problem faced by machine learning\npractitioners in domains as diverse as hypothesis testing to product\nrecommendations. There have been a lot of approaches in exploiting rich data\nrepresentations for contextual bandit problems with varying degree of success.\nSelf-supervised learning is a promising approach to find rich data\nrepresentations without explicit labels. In a typical self-supervised learning\nscheme, the primary task is defined by the problem objective (e.g. clustering,\nclassification, embedding generation etc.) and the secondary task is defined by\nthe self-supervision objective (e.g. rotation prediction, words in\nneighborhood, colorization, etc.). In the usual self-supervision, we learn\nimplicit labels from the training data for a secondary task. However, in the\ncontextual bandit setting, we don't have the advantage of getting implicit\nlabels due to lack of data in the initial phase of learning. We provide a novel\napproach to tackle this issue by combining a contextual bandit objective with a\nself supervision objective. By augmenting contextual bandit learning with\nself-supervision we get a better cumulative reward. Our results on eight\npopular computer vision datasets show substantial gains in cumulative reward.\nWe provide cases where the proposed scheme doesn't perform optimally and give\nalternative methods for better learning in these cases.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 22:06:34 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Deshmukh", "Aniket Anand", ""], ["Kumar", "Abhimanu", ""], ["Boyles", "Levi", ""], ["Charles", "Denis", ""], ["Manavoglu", "Eren", ""], ["Dogan", "Urun", ""]]}, {"id": "2003.08494", "submitter": "Andreas Robinson", "authors": "Andreas Robinson", "title": "Progress Extrapolating Algorithmic Learning to Arbitrary Sequence\n  Lengths", "comments": "7 pages, 1 figure, 1 table, minor edits to clarify explanations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network models for algorithmic tasks have led to significant\nimprovements in extrapolation to sequences much longer than training, but it\nremains an outstanding problem that the performance still degrades for very\nlong or adversarial sequences. We present alternative architectures and\nloss-terms to address these issues, and our testing of these approaches has not\ndetected any remaining extrapolation errors within memory constraints. We focus\non linear time algorithmic tasks including copy, parentheses parsing, and\nbinary addition. First, activation binning was used to discretize the trained\nnetwork in order to avoid computational drift from continuous operations, and a\nbinning-based digital loss term was added to encourage discretizable\nrepresentations. In addition, a localized differentiable memory (LDM)\narchitecture, in contrast to distributed memory access, addressed remaining\nextrapolation errors and avoided unbounded growth of internal computational\nstates. Previous work has found that algorithmic extrapolation issues can also\nbe alleviated with approaches relying on program traces, but the current effort\ndoes not rely on such traces.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 22:41:53 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 16:22:04 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Robinson", "Andreas", ""]]}, {"id": "2003.08500", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi, Nan Wu, David Smith, Mohamed Ali Kaafar", "title": "The Cost of Privacy in Asynchronous Differentially-Private Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training machine learning models using Training data located on\nmultiple private and geographically-scattered servers with different privacy\nsettings. Due to the distributed nature of the data, communicating with all\ncollaborating private data owners simultaneously may prove challenging or\naltogether impossible. In this paper, we develop differentially-private\nasynchronous algorithms for collaboratively training machine-learning models on\nmultiple private datasets. The asynchronous nature of the algorithms implies\nthat a central learner interacts with the private data owners one-on-one\nwhenever they are available for communication without needing to aggregate\nquery responses to construct gradients of the entire fitness function.\nTherefore, the algorithm efficiently scales to many data owners. We define the\ncost of privacy as the difference between the fitness of a privacy-preserving\nmachine-learning model and the fitness of trained machine-learning model in the\nabsence of privacy concerns. We prove that we can forecast the performance of\nthe proposed privacy-preserving asynchronous algorithms. We demonstrate that\nthe cost of privacy has an upper bound that is inversely proportional to the\ncombined size of the training datasets squared and the sum of the privacy\nbudgets squared. We validate the theoretical results with experiments on\nfinancial and medical datasets. The experiments illustrate that collaboration\namong more than 10 data owners with at least 10,000 records with privacy\nbudgets greater than or equal to 1 results in a superior machine-learning model\nin comparison to a model trained in isolation on only one of the datasets,\nillustrating the value of collaboration and the cost of the privacy. The number\nof the collaborating datasets can be lowered if the privacy budget is higher.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 23:06:28 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 04:53:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Farokhi", "Farhad", ""], ["Wu", "Nan", ""], ["Smith", "David", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "2003.08533", "submitter": "Ngoc Mai Tran", "authors": "Hanlin Zhu, Xue Li, Liuyang Sun, Fei He, Zhengtuo Zhao, Lan Luan, Ngoc\n  Mai Tran and Chong Xie", "title": "Clustering with Fast, Automated and Reproducible assessment applied to\n  longitudinal neural tracking", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across many areas, from neural tracking to database entity resolution, manual\nassessment of clusters by human experts presents a bottleneck in rapid\ndevelopment of scalable and specialized clustering methods. To solve this\nproblem we develop C-FAR, a novel method for Fast, Automated and Reproducible\nassessment of multiple hierarchical clustering algorithms simultaneously. Our\nalgorithm takes any number of hierarchical clustering trees as input, then\nstrategically queries pairs for human feedback, and outputs an optimal\nclustering among those nominated by these trees. While it is applicable to\nlarge dataset in any domain that utilizes pairwise comparisons for assessment,\nour flagship application is the cluster aggregation step in spike-sorting, the\ntask of assigning waveforms (spikes) in recordings to neurons. On simulated\ndata of 96 neurons under adverse conditions, including drifting and 25\\%\nblackout, our algorithm produces near-perfect tracking relative to the ground\ntruth. Our runtime scales linearly in the number of input trees, making it a\ncompetitive computational tool. These results indicate that C-FAR is highly\nsuitable as a model selection and assessment tool in clustering tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 01:33:00 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Zhu", "Hanlin", ""], ["Li", "Xue", ""], ["Sun", "Liuyang", ""], ["He", "Fei", ""], ["Zhao", "Zhengtuo", ""], ["Luan", "Lan", ""], ["Tran", "Ngoc Mai", ""], ["Xie", "Chong", ""]]}, {"id": "2003.08559", "submitter": "Wenjin Wang", "authors": "Wenjin Wang, Yunqing Hu, Yin Zhang", "title": "Lifelong Learning with Searchable Extension Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning remains an open problem. One of its main difficulties is\ncatastrophic forgetting. Many dynamic expansion approaches have been proposed\nto address this problem, but they all use homogeneous models of predefined\nstructure for all tasks. The common original model and expansion structures\nignore the requirement of different model structures on different tasks, which\nleads to a less compact model for multiple tasks and causes the model size to\nincrease rapidly as the number of tasks increases. Moreover, they can not\nperform best on all tasks. To solve those problems, in this paper, we propose a\nnew lifelong learning framework named Searchable Extension Units (SEU) by\nintroducing Neural Architecture Search into lifelong learning, which breaks\ndown the need for a predefined original model and searches for specific\nextension units for different tasks, without compromising the performance of\nthe model on different tasks. Our approach can obtain a much more compact model\nwithout catastrophic forgetting. The experimental results on the PMNIST, the\nsplit CIFAR10 dataset, the split CIFAR100 dataset, and the Mixture dataset\nempirically prove that our method can achieve higher accuracy with much smaller\nmodel, whose size is about 25-33 percentage of that of the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:45:51 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Wang", "Wenjin", ""], ["Hu", "Yunqing", ""], ["Zhang", "Yin", ""]]}, {"id": "2003.08572", "submitter": "Jungwoon Shin", "authors": "Jungwoon Shin", "title": "Bipartite Link Prediction based on Topological Features via 2-hop Path", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of real-world systems can be modeled as bipartite networks. One of\nthe most powerful and simple link prediction methods is Linear-Graph\nAutoencoder(LGAE) which has promising performance on challenging tasks such as\nlink prediction and node clustering. LGAE relies on simple linear model w.r.t.\nthe adjacency matrix of the graph to learn vector space representations of\nnodes. In this paper, we consider the case of bipartite link predictions where\nnode attributes are unavailable. When using LGAE, we propose to multiply the\nreconstructed adjacency matrix with a symmetrically normalized training\nadjacency matrix. As a result, 2-hop paths are formed which we use as the\npredicted adjacency matrix to evaluate the performance of our model.\nExperimental results on both synthetic and real-world dataset show our approach\nconsistently outperforms Graph Autoencoder and Linear Graph Autoencoder model\nin 10 out of 12 bipartite dataset and reaches competitive performances in 2\nother bipartite dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 05:07:54 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Shin", "Jungwoon", ""]]}, {"id": "2003.08573", "submitter": "Hrushikesh Loya", "authors": "Hrushikesh Loya, Pranav Poduval, Deepak Anand, Neeraj Kumar, and Amit\n  Sethi", "title": "Uncertainty Estimation in Cancer Survival Prediction", "comments": "5 pages, Accepted at AI4AH Workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival models are used in various fields, such as the development of cancer\ntreatment protocols. Although many statistical and machine learning models have\nbeen proposed to achieve accurate survival predictions, little attention has\nbeen paid to obtain well-calibrated uncertainty estimates associated with each\nprediction. The currently popular models are opaque and untrustworthy in that\nthey often express high confidence even on those test cases that are not\nsimilar to the training samples, and even when their predictions are wrong. We\npropose a Bayesian framework for survival models that not only gives more\naccurate survival predictions but also quantifies the survival uncertainty\nbetter. Our approach is a novel combination of variational inference for\nuncertainty estimation, neural multi-task logistic regression for estimating\nnonlinear and time-varying risk models, and an additional sparsity-inducing\nprior to work with high dimensional data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 05:08:01 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 16:40:03 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Loya", "Hrushikesh", ""], ["Poduval", "Pranav", ""], ["Anand", "Deepak", ""], ["Kumar", "Neeraj", ""], ["Sethi", "Amit", ""]]}, {"id": "2003.08579", "submitter": "Mike Ludkovski", "authors": "Xiong Lyu and Mike Ludkovski", "title": "Adaptive Batching for Gaussian Process Surrogates with Application in\n  Noisy Level Set Estimation", "comments": "36 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop adaptive replicated designs for Gaussian process metamodels of\nstochastic experiments. Adaptive batching is a natural extension of sequential\ndesign heuristics with the benefit of replication growing as response features\nare learned, inputs concentrate, and the metamodeling overhead rises. Motivated\nby the problem of learning the level set of the mean simulator response we\ndevelop four novel schemes: Multi-Level Batching (MLB), Ratchet Batching (RB),\nAdaptive Batched Stepwise Uncertainty Reduction (ABSUR), Adaptive Design with\nStepwise Allocation (ADSA) and Deterministic Design with Stepwise Allocation\n(DDSA). Our algorithms simultaneously (MLB, RB and ABSUR) or sequentially (ADSA\nand DDSA) determine the sequential design inputs and the respective number of\nreplicates. Illustrations using synthetic examples and an application in\nquantitative finance (Bermudan option pricing via Regression Monte Carlo) show\nthat adaptive batching brings significant computational speed-ups with minimal\nloss of modeling fidelity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 05:30:16 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 05:56:02 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Lyu", "Xiong", ""], ["Ludkovski", "Mike", ""]]}, {"id": "2003.08615", "submitter": "Ali Balali", "authors": "Ali Balali, Masoud Asadpour, Ricardo Campos, Adam Jatowt", "title": "Joint Event Extraction along Shortest Dependency Paths using Graph\n  Convolutional Networks", "comments": null, "journal-ref": "Knowledge-Based Systems, Volume 210, Year 2020, Page 106492", "doi": "10.1016/j.knosys.2020.106492", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event extraction (EE) is one of the core information extraction tasks, whose\npurpose is to automatically identify and extract information about incidents\nand their actors from texts. This may be beneficial to several domains such as\nknowledge bases, question answering, information retrieval and summarization\ntasks, to name a few. The problem of extracting event information from texts is\nlongstanding and usually relies on elaborately designed lexical and syntactic\nfeatures, which, however, take a large amount of human effort and lack\ngeneralization. More recently, deep neural network approaches have been adopted\nas a means to learn underlying features automatically. However, existing\nnetworks do not make full use of syntactic features, which play a fundamental\nrole in capturing very long-range dependencies. Also, most approaches extract\neach argument of an event separately without considering associations between\narguments which ultimately leads to low efficiency, especially in sentences\nwith multiple events. To address the two above-referred problems, we propose a\nnovel joint event extraction framework that aims to extract multiple event\ntriggers and arguments simultaneously by introducing shortest dependency path\n(SDP) in the dependency graph. We do this by eliminating irrelevant words in\nthe sentence, thus capturing long-range dependencies. Also, an attention-based\ngraph convolutional network is proposed, to carry syntactically related\ninformation along the shortest paths between argument candidates that captures\nand aggregates the latent associations between arguments; a problem that has\nbeen overlooked by most of the literature. Our results show a substantial\nimprovement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 07:48:38 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Balali", "Ali", ""], ["Asadpour", "Masoud", ""], ["Campos", "Ricardo", ""], ["Jatowt", "Adam", ""]]}, {"id": "2003.08670", "submitter": "Takashi Takahashi", "authors": "Takashi Takahashi, Yoshiyuki Kabashima", "title": "Semi-analytic approximate stability selection for correlated data in\n  generalized linear models", "comments": "34 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the variable selection problem of generalized linear models\n(GLMs). Stability selection (SS) is a promising method proposed for solving\nthis problem. Although SS provides practical variable selection criteria, it is\ncomputationally demanding because it needs to fit GLMs to many re-sampled\ndatasets. We propose a novel approximate inference algorithm that can conduct\nSS without the repeated fitting. The algorithm is based on the replica method\nof statistical mechanics and vector approximate message passing of information\ntheory. For datasets characterized by rotation-invariant matrix ensembles, we\nderive state evolution equations that macroscopically describe the dynamics of\nthe proposed algorithm. We also show that their fixed points are consistent\nwith the replica symmetric solution obtained by the replica method. Numerical\nexperiments indicate that the algorithm exhibits fast convergence and high\napproximation accuracy for both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 10:43:12 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 03:10:40 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Takahashi", "Takashi", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "2003.08673", "submitter": "Viraj Kulkarni", "authors": "Viraj Kulkarni, Milind Kulkarni, Aniruddha Pant", "title": "Survey of Personalization Techniques for Federated Learning", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables machine learning models to learn from private\ndecentralized data without compromising privacy. The standard formulation of\nfederated learning produces one shared model for all clients. Statistical\nheterogeneity due to non-IID distribution of data across devices often leads to\nscenarios where, for some clients, the local models trained solely on their\nprivate data perform better than the global shared model thus taking away their\nincentive to participate in the process. Several techniques have been proposed\nto personalize global models to work better for individual clients. This paper\nhighlights the need for personalization and surveys recent research on this\ntopic.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 10:47:55 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kulkarni", "Viraj", ""], ["Kulkarni", "Milind", ""], ["Pant", "Aniruddha", ""]]}, {"id": "2003.08723", "submitter": "Steffen Wiewel", "authors": "Steffen Wiewel, Byungsoo Kim, Vinicius C. Azevedo, Barbara\n  Solenthaler, Nils Thuerey", "title": "Latent Space Subdivision: Stable and Controllable Time Predictions for\n  Fluid Flow", "comments": "https://ge.in.tum.de/publications/latent-space-subdivision/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end trained neural networkarchitecture to robustly\npredict the complex dynamics of fluid flows with high temporal stability. We\nfocus on single-phase smoke simulations in 2D and 3D based on the\nincompressible Navier-Stokes (NS) equations, which are relevant for a wide\nrange of practical problems. To achieve stable predictions for long-term flow\nsequences, a convolutional neural network (CNN) is trained for spatial\ncompression in combination with a temporal prediction network that consists of\nstacked Long Short-Term Memory (LSTM) layers. Our core contribution is a novel\nlatent space subdivision (LSS) to separate the respective input quantities into\nindividual parts of the encoded latent space domain. This allows to\ndistinctively alter the encoded quantities without interfering with the\nremaining latent space values and hence maximizes external control. By\nselectively overwriting parts of the predicted latent space points, our\nproposed method is capable to robustly predict long-term sequences of complex\nphysics problems. In addition, we highlight the benefits of a recurrent\ntraining on the latent space creation, which is performed by the spatial\ncompression network.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 12:38:52 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Wiewel", "Steffen", ""], ["Kim", "Byungsoo", ""], ["Azevedo", "Vinicius C.", ""], ["Solenthaler", "Barbara", ""], ["Thuerey", "Nils", ""]]}, {"id": "2003.08725", "submitter": "Yi Liu", "authors": "Yi Liu, James J.Q. Yu, Jiawen Kang, Dusit Niyato, Shuyu Zhang", "title": "Privacy-preserving Traffic Flow Prediction: A Federated Learning\n  Approach", "comments": "This paper is in the second round of under review of the IEEE\n  Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2020.2991401", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing traffic flow forecasting approaches by deep learning models achieve\nexcellent success based on a large volume of datasets gathered by governments\nand organizations. However, these datasets may contain lots of user's private\ndata, which is challenging the current prediction approaches as user privacy is\ncalling for the public concern in recent years. Therefore, how to develop\naccurate traffic prediction while preserving privacy is a significant problem\nto be solved, and there is a trade-off between these two objectives. To address\nthis challenge, we introduce a privacy-preserving machine learning technique\nnamed federated learning and propose a Federated Learning-based Gated Recurrent\nUnit neural network algorithm (FedGRU) for traffic flow prediction. FedGRU\ndiffers from current centralized learning methods and updates universal\nlearning models through a secure parameter aggregation mechanism rather than\ndirectly sharing raw data among organizations. In the secure parameter\naggregation mechanism, we adopt a Federated Averaging algorithm to reduce the\ncommunication overhead during the model parameter transmission process.\nFurthermore, we design a Joint Announcement Protocol to improve the scalability\nof FedGRU. We also propose an ensemble clustering-based scheme for traffic flow\nprediction by grouping the organizations into clusters before applying FedGRU\nalgorithm. Through extensive case studies on a real-world dataset, it is shown\nthat FedGRU's prediction accuracy is 90.96% higher than the advanced deep\nlearning models, which confirm that FedGRU can achieve accurate and timely\ntraffic prediction without compromising the privacy and security of raw data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 13:07:49 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Liu", "Yi", ""], ["Yu", "James J. Q.", ""], ["Kang", "Jiawen", ""], ["Niyato", "Dusit", ""], ["Zhang", "Shuyu", ""]]}, {"id": "2003.08730", "submitter": "Markus Fiedler", "authors": "Selim Ickin and Markus Fiedler and Konstantinos Vandikas", "title": "Customized Video QoE Estimation with Algorithm-Agnostic Transfer\n  Learning", "comments": "6 pages, 4 figures, 6 tables, 18 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of QoE models by means of Machine Learning (ML) is\nchallenging, amongst others due to small-size datasets, lack of diversity in\nuser profiles in the source domain, and too much diversity in the target\ndomains of QoE models. Furthermore, datasets can be hard to share between\nresearch entities, as the machine learning models and the collected user data\nfrom the user studies may be IPR- or GDPR-sensitive. This makes a decentralized\nlearning-based framework appealing for sharing and aggregating learned\nknowledge in-between the local models that map the obtained metrics to the user\nQoE, such as Mean Opinion Scores (MOS). In this paper, we present a transfer\nlearning-based ML model training approach, which allows decentralized local\nmodels to share generic indicators on MOS to learn a generic base model, and\nthen customize the generic base model further using additional features that\nare unique to those specific localized (and potentially sensitive) QoE nodes.\nWe show that the proposed approach is agnostic to specific ML algorithms,\nstacked upon each other, as it does not necessitate the collaborating localized\nnodes to run the same ML algorithm. Our reproducible results reveal the\nadvantages of stacking various generic and specific models with corresponding\nweight factors. Moreover, we identify the optimal combination of algorithms and\nweight factors for the corresponding localized QoE nodes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:28:10 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Ickin", "Selim", ""], ["Fiedler", "Markus", ""], ["Vandikas", "Konstantinos", ""]]}, {"id": "2003.08745", "submitter": "Alice Plebe", "authors": "Alice Plebe and Mauro Da Lio", "title": "On the Road with 16 Neurons: Mental Imagery with Bio-inspired Deep\n  Neural Networks", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a strategy for visual prediction in the context of\nautonomous driving. Humans, when not distracted or drunk, are still the best\ndrivers you can currently find. For this reason we take inspiration from two\ntheoretical ideas about the human mind and its neural organization. The first\nidea concerns how the brain uses a hierarchical structure of neuron ensembles\nto extract abstract concepts from visual experience and code them into compact\nrepresentations. The second idea suggests that these neural perceptual\nrepresentations are not neutral but functional to the prediction of the future\nstate of affairs in the environment. Similarly, the prediction mechanism is not\nneutral but oriented to the current planning of a future action. We identify\nwithin the deep learning framework two artificial counterparts of the\naforementioned neurocognitive theories. We find a correspondence between the\nfirst theoretical idea and the architecture of convolutional autoencoders,\nwhile we translate the second theory into a training procedure that learns\ncompact representations which are not neutral but oriented to driving tasks,\nfrom two distinct perspectives. From a static perspective, we force groups of\nneural units in the compact representations to distinctly represent specific\nconcepts crucial to the driving task. From a dynamic perspective, we encourage\nthe compact representations to be predictive of how the current road scenario\nwill change in the future. We successfully learn compact representations that\nuse as few as 16 neural units for each of the two basic driving concepts we\nconsider: car and lane. We prove the efficiency of our proposed perceptual\nrepresentations on the SYNTHIA dataset. Our source code is available at\nhttps://github.com/3lis/rnn_vae\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:46:29 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Plebe", "Alice", ""], ["Da Lio", "Mauro", ""]]}, {"id": "2003.08749", "submitter": "Yaser Banadaki", "authors": "Yaser Banadaki, Nariman Razaviarab, Hadi Fekrmandi, and Safura Sharifi", "title": "Toward Enabling a Reliable Quality Monitoring System for Additive\n  Manufacturing Process using Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cond-mat.mtrl-sci cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive Manufacturing (AM) is a crucial component of the smart industry. In\nthis paper, we propose an automated quality grading system for the AM process\nusing a deep convolutional neural network (CNN) model. The CNN model is trained\noffline using the images of the internal and surface defects in the\nlayer-by-layer deposition of materials and tested online by studying the\nperformance of detecting and classifying the failure in AM process at different\nextruder speeds and temperatures. The model demonstrates the accuracy of 94%\nand specificity of 96%, as well as above 75% in three classifier measures of\nthe Fscore, the sensitivity, and precision for classifying the quality of the\nprinting process in five grades in real-time. The proposed online model adds an\nautomated, consistent, and non-contact quality control signal to the AM process\nthat eliminates the manual inspection of parts after they are entirely built.\nThe quality monitoring signal can also be used by the machine to suggest\nremedial actions by adjusting the parameters in real-time. The proposed quality\npredictive model serves as a proof-of-concept for any type of AM machines to\nproduce reliable parts with fewer quality hiccups while limiting the waste of\nboth time and materials.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 20:49:20 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Banadaki", "Yaser", ""], ["Razaviarab", "Nariman", ""], ["Fekrmandi", "Hadi", ""], ["Sharifi", "Safura", ""]]}, {"id": "2003.08750", "submitter": "Joshua Levy", "authors": "Joshua J. Levy, Rebecca M. Lebeaux, Anne G. Hoen, Brock C.\n  Christensen, Louis J. Vaickus, Todd A. MacKenzie", "title": "Longevity Associated Geometry Identified in Satellite Images: Sidewalks,\n  Driveways and Hiking Trails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance: Following a century of increase, life expectancy in the United\nStates has stagnated and begun to decline in recent decades. Using satellite\nimages and street view images prior work has demonstrated associations of the\nbuilt environment with income, education, access to care and health factors\nsuch as obesity. However, assessment of learned image feature relationships\nwith variation in crude mortality rate across the United States has been\nlacking.\n  Objective: Investigate prediction of county-level mortality rates in the U.S.\nusing satellite images.\n  Design: Satellite images were extracted with the Google Static Maps\napplication programming interface for 430 counties representing approximately\n68.9% of the US population. A convolutional neural network was trained using\ncrude mortality rates for each county in 2015 to predict mortality. Learned\nimage features were interpreted using Shapley Additive Feature Explanations,\nclustered, and compared to mortality and its associated covariate predictors.\n  Main Outcomes and Measures: County mortality was predicted using satellite\nimages.\n  Results: Predicted mortality from satellite images in a held-out test set of\ncounties was strongly correlated to the true crude mortality rate (Pearson\nr=0.72). Learned image features were clustered, and we identified 10 clusters\nthat were associated with education, income, geographical region, race and age.\n  Conclusion and Relevance: The application of deep learning techniques to\nremotely-sensed features of the built environment can serve as a useful\npredictor of mortality in the United States. Tools that are able to identify\nimage features associated with health-related outcomes can inform targeted\npublic health interventions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 20:23:11 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Levy", "Joshua J.", ""], ["Lebeaux", "Rebecca M.", ""], ["Hoen", "Anne G.", ""], ["Christensen", "Brock C.", ""], ["Vaickus", "Louis J.", ""], ["MacKenzie", "Todd A.", ""]]}, {"id": "2003.08753", "submitter": "Al Amin Hosain", "authors": "Al Amin Hosain, Panneer Selvam Santhalingam, Parth Pathak, Huzefa\n  Rangwala and Jana Kosecka", "title": "FineHand: Learning Hand Shapes for American Sign Language Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  American Sign Language recognition is a difficult gesture recognition\nproblem, characterized by fast, highly articulate gestures. These are comprised\nof arm movements with different hand shapes, facial expression and head\nmovements. Among these components, hand shape is the vital, often the most\ndiscriminative part of a gesture. In this work, we present an approach for\neffective learning of hand shape embeddings, which are discriminative for ASL\ngestures. For hand shape recognition our method uses a mix of manually labelled\nhand shapes and high confidence predictions to train deep convolutional neural\nnetwork (CNN). The sequential gesture component is captured by recursive neural\nnetwork (RNN) trained on the embeddings learned in the first stage. We will\ndemonstrate that higher quality hand shape models can significantly improve the\naccuracy of final video gesture classification in challenging conditions with\nvariety of speakers, different illumination and significant motion blurr. We\ncompare our model to alternative approaches exploiting different modalities and\nrepresentations of the data and show improved video gesture recognition\naccuracy on GMU-ASL51 benchmark dataset\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 23:32:08 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Hosain", "Al Amin", ""], ["Santhalingam", "Panneer Selvam", ""], ["Pathak", "Parth", ""], ["Rangwala", "Huzefa", ""], ["Kosecka", "Jana", ""]]}, {"id": "2003.08755", "submitter": "Francesco Bardozzo", "authors": "Francesco Bardozzo, Borja De La Osa, Lubomira Horanska, Javier\n  Fumanal-Idocin, Mattia delli Priscoli, Luigi Troiano, Roberto Tagliaferri,\n  Javier Fernandez, Humberto Bustince", "title": "Adaptive binarization based on fuzzy integrals", "comments": "11 pages, 3 figures, 3 algorithms, Journal paper under a revision of\n  IEEE Transactions on Image Processing", "journal-ref": null, "doi": "10.1016/j.inffus.2020.10.020", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive binarization methodologies threshold the intensity of the pixels\nwith respect to adjacent pixels exploiting the integral images. In turn, the\nintegral images are generally computed optimally using the summed-area-table\nalgorithm (SAT). This document presents a new adaptive binarization technique\nbased on fuzzy integral images through an efficient design of a modified SAT\nfor fuzzy integrals. We define this new methodology as FLAT (Fuzzy Local\nAdaptive Thresholding). The experimental results show that the proposed\nmethodology have produced an image quality thresholding often better than\ntraditional algorithms and saliency neural networks. We propose a new\ngeneralization of the Sugeno and CF 1,2 integrals to improve existing results\nwith an efficient integral image computation. Therefore, these new generalized\nfuzzy integrals can be used as a tool for grayscale processing in real-time and\ndeep-learning applications. Index Terms: Image Thresholding, Image Processing,\nFuzzy Integrals, Aggregation Functions\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:30:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bardozzo", "Francesco", ""], ["De La Osa", "Borja", ""], ["Horanska", "Lubomira", ""], ["Fumanal-Idocin", "Javier", ""], ["Priscoli", "Mattia delli", ""], ["Troiano", "Luigi", ""], ["Tagliaferri", "Roberto", ""], ["Fernandez", "Javier", ""], ["Bustince", "Humberto", ""]]}, {"id": "2003.08756", "submitter": "Mohammad Javad Shafiee", "authors": "Mohammad Javad Shafiee, Ahmadreza Jeddi, Amir Nazemi, Paul Fieguth,\n  and Alexander Wong", "title": "Deep Neural Network Perception Models and Robust Autonomous Driving\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the robustness of deep learning models in autonomous\ndriving applications and discusses the practical solutions to address that.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:02:05 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Jeddi", "Ahmadreza", ""], ["Nazemi", "Amir", ""], ["Fieguth", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "2003.08760", "submitter": "Minh Vu", "authors": "Minh H. Vu, Tommy L\\\"ofstedt, Tufve Nyholm, Raphael Sznitman", "title": "A Question-Centric Model for Visual Question Answering in Medical\n  Imaging", "comments": "Accepted at IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.2978284", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods have proven extremely effective at performing a variety\nof medical image analysis tasks. With their potential use in clinical routine,\ntheir lack of transparency has however been one of their few weak points,\nraising concerns regarding their behavior and failure modes. While most\nresearch to infer model behavior has focused on indirect strategies that\nestimate prediction uncertainties and visualize model support in the input\nimage space, the ability to explicitly query a prediction model regarding its\nimage content offers a more direct way to determine the behavior of trained\nmodels. To this end, we present a novel Visual Question Answering approach that\nallows an image to be queried by means of a written question. Experiments on a\nvariety of medical and natural image datasets show that by fusing image and\nquestion features in a novel way, the proposed approach achieves an equal or\nhigher accuracy compared to current methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:16:16 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Vu", "Minh H.", ""], ["L\u00f6fstedt", "Tommy", ""], ["Nyholm", "Tufve", ""], ["Sznitman", "Raphael", ""]]}, {"id": "2003.08763", "submitter": "A. Ben Hamza", "authors": "David Pickup, Xianfang Sun, Paul L Rosin, Ralph R Martin, Z Cheng,\n  Zhouhui Lian, Masaki Aono, A Ben Hamza, A Bronstein, M Bronstein, S Bu,\n  Umberto Castellani, S Cheng, Valeria Garro, Andrea Giachetti, Afzal Godil,\n  Luca Isaia, J Han, Henry Johan, L Lai, Bo Li, C Li, Haisheng Li, Roee Litman,\n  X Liu, Z Liu, Yijuan Lu, L Sun, G Tam, Atsushi Tatsuma, J Ye", "title": "Shape retrieval of non-rigid 3d human models", "comments": "International Journal of Computer Vision, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D models of humans are commonly used within computer graphics and vision,\nand so the ability to distinguish between body shapes is an important shape\nretrieval problem. We extend our recent paper which provided a benchmark for\ntesting non-rigid 3D shape retrieval algorithms on 3D human models. This\nbenchmark provided a far stricter challenge than previous shape benchmarks. We\nhave added 145 new models for use as a separate training set, in order to\nstandardise the training data used and provide a fairer comparison. We have\nalso included experiments with the FAUST dataset of human scans. All\nparticipants of the previous benchmark study have taken part in the new tests\nreported here, many providing updated results using the new data. In addition,\nfurther participants have also taken part, and we provide extra analysis of the\nretrieval results. A total of 25 different shape retrieval methods.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 20:03:16 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Pickup", "David", ""], ["Sun", "Xianfang", ""], ["Rosin", "Paul L", ""], ["Martin", "Ralph R", ""], ["Cheng", "Z", ""], ["Lian", "Zhouhui", ""], ["Aono", "Masaki", ""], ["Hamza", "A Ben", ""], ["Bronstein", "A", ""], ["Bronstein", "M", ""], ["Bu", "S", ""], ["Castellani", "Umberto", ""], ["Cheng", "S", ""], ["Garro", "Valeria", ""], ["Giachetti", "Andrea", ""], ["Godil", "Afzal", ""], ["Isaia", "Luca", ""], ["Han", "J", ""], ["Johan", "Henry", ""], ["Lai", "L", ""], ["Li", "Bo", ""], ["Li", "C", ""], ["Li", "Haisheng", ""], ["Litman", "Roee", ""], ["Liu", "X", ""], ["Liu", "Z", ""], ["Lu", "Yijuan", ""], ["Sun", "L", ""], ["Tam", "G", ""], ["Tatsuma", "Atsushi", ""], ["Ye", "J", ""]]}, {"id": "2003.08771", "submitter": "Tim Oosterhuis", "authors": "Tim Oosterhuis and Lambert Schomaker", "title": "\"Who is Driving around Me?\" Unique Vehicle Instance Classification using\n  Deep Neural Features", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being aware of other traffic is a prerequisite for self-driving cars to\noperate in the real world. In this paper, we show how the intrinsic feature\nmaps of an object detection CNN can be used to uniquely identify vehicles from\na dash-cam feed. Feature maps of a pretrained `YOLO' network are used to create\n700 deep integrated feature signatures (DIFS) from 20 different images of 35\nvehicles from a high resolution dataset and 340 signatures from 20 different\nimages of 17 vehicles of a lower resolution tracking benchmark dataset. The\nYOLO network was trained to classify general object categories, e.g. classify a\ndetected object as a `car' or `truck'. 5-Fold nearest neighbor (1NN)\nclassification was used on DIFS created from feature maps in the middle layers\nof the network to correctly identify unique vehicles at a rate of 96.7\\% for\nthe high resolution data and with a rate of 86.8\\% for the lower resolution\ndata. We conclude that a deep neural detection network trained to distinguish\nbetween different classes can be successfully used to identify different\ninstances belonging to the same class, through the creation of deep integrated\nfeature signatures (DIFS).\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 13:57:46 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Oosterhuis", "Tim", ""], ["Schomaker", "Lambert", ""]]}, {"id": "2003.08773", "submitter": "Eddie Yan", "authors": "Eddie Yan and Yanping Huang", "title": "Do CNNs Encode Data Augmentations?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentations are important ingredients in the recipe for training\nrobust neural networks, especially in computer vision. A fundamental question\nis whether neural network features encode data augmentation transformations. To\nanswer this question, we introduce a systematic approach to investigate which\nlayers of neural networks are the most predictive of augmentation\ntransformations. Our approach uses features in pre-trained vision models with\nminimal additional processing to predict common properties transformed by\naugmentation (scale, aspect ratio, hue, saturation, contrast, and brightness).\nSurprisingly, neural network features not only predict data augmentation\ntransformations, but they predict many transformations with high accuracy.\nAfter validating that neural networks encode features corresponding to\naugmentation transformations, we show that these features are encoded in the\nearly layers of modern CNNs, though the augmentation signal fades in deeper\nlayers.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 00:42:23 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 18:02:18 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Yan", "Eddie", ""], ["Huang", "Yanping", ""]]}, {"id": "2003.08774", "submitter": "Agnieszka Grabska-Barwinska", "authors": "Agnieszka Grabska-Barwi\\'nska", "title": "Measuring and improving the quality of visual explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of to explain neural network decisions goes hand in hand with\ntheir safe deployment. Several methods have been proposed to highlight features\nimportant for a given network decision. However, there is no consensus on how\nto measure effectiveness of these methods. We propose a new procedure for\nevaluating explanations. We use it to investigate visual explanations extracted\nfrom a range of possible sources in a neural network. We quantify the benefit\nof combining these sources and challenge a recent appeal for taking bias\nparameters into account. We support our conclusions with a general assessment\nof the impact of bias parameters in ImageNet classifiers\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 00:52:00 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 10:00:58 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Grabska-Barwi\u0144ska", "Agnieszka", ""]]}, {"id": "2003.08793", "submitter": "Jingda Du", "authors": "Zhenshen Qu, Jingda Du, Yong Cao, Qiuyu Guan and Pengbo Zhao", "title": "Deep Active Learning for Remote Sensing Object Detection", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, CNN object detectors have achieved high accuracy on remote sensing\nimages but require huge labor and time costs on annotation. In this paper, we\npropose a new uncertainty-based active learning which can select images with\nmore information for annotation and detector can still reach high performance\nwith a fraction of the training images. Our method not only analyzes objects'\nclassification uncertainty to find least confident objects but also considers\ntheir regression uncertainty to declare outliers. Besides, we bring out two\nextra weights to overcome two difficulties in remote sensing datasets,\nclass-imbalance and difference in images' objects amount. We experiment our\nactive learning algorithm on DOTA dataset with CenterNet as object detector. We\nachieve same-level performance as full supervision with only half images. We\neven override full supervision with 55% images and augmented weights on least\nconfident images.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 15:57:36 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Qu", "Zhenshen", ""], ["Du", "Jingda", ""], ["Cao", "Yong", ""], ["Guan", "Qiuyu", ""], ["Zhao", "Pengbo", ""]]}, {"id": "2003.08797", "submitter": "Maciej Pajak", "authors": "Shayne Shaw, Maciej Pajak, Aneta Lisowska, Sotirios A Tsaftaris,\n  Alison Q O'Neil", "title": "Teacher-Student chain for efficient semi-supervised histology image\n  classification", "comments": "AI for Affordable Healthcare (AI4AH) workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning shows great potential for the domain of digital pathology. An\nautomated digital pathology system could serve as a second reader, perform\ninitial triage in large screening studies, or assist in reporting. However, it\nis expensive to exhaustively annotate large histology image databases, since\nmedical specialists are a scarce resource. In this paper, we apply the\nsemi-supervised teacher-student knowledge distillation technique proposed by\nYalniz et al. (2019) to the task of quantifying prognostic features in\ncolorectal cancer. We obtain accuracy improvements through extending this\napproach to a chain of students, where each student's predictions are used to\ntrain the next student i.e. the student becomes the teacher. Using the chain\napproach, and only 0.5% labelled data (the remaining 99.5% in the unlabelled\npool), we match the accuracy of training on 100% labelled data. At lower\npercentages of labelled data, similar gains in accuracy are seen, allowing some\nrecovery of accuracy even from a poor initial choice of labelled training set.\nIn conclusion, this approach shows promise for reducing the annotation burden,\nthus increasing the affordability of automated digital pathology systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 14:01:43 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 09:53:31 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Shaw", "Shayne", ""], ["Pajak", "Maciej", ""], ["Lisowska", "Aneta", ""], ["Tsaftaris", "Sotirios A", ""], ["O'Neil", "Alison Q", ""]]}, {"id": "2003.08798", "submitter": "Joseph K J", "authors": "K J Joseph, Jathushan Rajasegaran, Salman Khan, Fahad Shahbaz Khan,\n  Vineeth Balasubramanian", "title": "Incremental Object Detection via Meta-Learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a real-world setting, object instances from new classes can be\ncontinuously encountered by object detectors. When existing object detectors\nare applied to such scenarios, their performance on old classes deteriorates\nsignificantly. A few efforts have been reported to address this limitation, all\nof which apply variants of knowledge distillation to avoid catastrophic\nforgetting. We note that although distillation helps to retain previous\nlearning, it obstructs fast adaptability to new tasks, which is a critical\nrequirement for incremental learning. In this pursuit, we propose a\nmeta-learning approach that learns to reshape model gradients, such that\ninformation across incremental tasks is optimally shared. This ensures a\nseamless information transfer via a meta-learned gradient preconditioning that\nminimizes forgetting and maximizes knowledge transfer. In comparison to\nexisting meta-learning methods, our approach is task-agnostic, allows\nincremental addition of new-classes and scales to high-capacity models for\nobject detection. We evaluate our approach on a variety of incremental learning\nsettings defined on PASCAL-VOC and MS COCO datasets, where our approach\nperforms favourably well against state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 13:40:00 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 06:23:43 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Joseph", "K J", ""], ["Rajasegaran", "Jathushan", ""], ["Khan", "Salman", ""], ["Khan", "Fahad Shahbaz", ""], ["Balasubramanian", "Vineeth", ""]]}, {"id": "2003.08802", "submitter": "Maosen Li", "authors": "Maosen Li, Siheng Chen, Yangheng Zhao, Ya Zhang, Yanfeng Wang, Qi Tian", "title": "Dynamic Multiscale Graph Neural Networks for 3D Skeleton-Based Human\n  Motion Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel dynamic multiscale graph neural networks (DMGNN) to predict\n3D skeleton-based human motions. The core idea of DMGNN is to use a multiscale\ngraph to comprehensively model the internal relations of a human body for\nmotion feature learning. This multiscale graph is adaptive during training and\ndynamic across network layers. Based on this graph, we propose a multiscale\ngraph computational unit (MGCU) to extract features at individual scales and\nfuse features across scales. The entire model is action-category-agnostic and\nfollows an encoder-decoder framework. The encoder consists of a sequence of\nMGCUs to learn motion features. The decoder uses a proposed graph-based gate\nrecurrent unit to generate future poses. Extensive experiments show that the\nproposed DMGNN outperforms state-of-the-art methods in both short and long-term\npredictions on the datasets of Human 3.6M and CMU Mocap. We further investigate\nthe learned multiscale graphs for the interpretability. The codes could be\ndownloaded from https://github.com/limaosen0/DMGNN.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 02:49:51 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Li", "Maosen", ""], ["Chen", "Siheng", ""], ["Zhao", "Yangheng", ""], ["Zhang", "Ya", ""], ["Wang", "Yanfeng", ""], ["Tian", "Qi", ""]]}, {"id": "2003.08803", "submitter": "Asifullah Khan", "authors": "Anabia Sohail, Muhammad Ahsan Mukhtar, Asifullah Khan, Muhammad Mohsin\n  Zafar, Aneela Zameer, Saranjam Khan", "title": "Deep Object Detection based Mitosis Analysis in Breast Cancer\n  Histopathological Images", "comments": "Tables: 4, Figures 11, Pages: 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evaluation of breast tissue biopsies for mitotic nuclei detection\nis considered an important prognostic biomarker in tumor grading and cancer\nprogression. However, automated mitotic nuclei detection poses several\nchallenges because of the unavailability of pixel-level annotations, different\nmorphological configurations of mitotic nuclei, their sparse representation,\nand close resemblance with non-mitotic nuclei. These challenges undermine the\nprecision of the automated detection model and thus make detection difficult in\na single phase. This work proposes an end-to-end detection system for mitotic\nnuclei identification in breast cancer histopathological images. Deep object\ndetection-based Mask R-CNN is adapted for mitotic nuclei detection that\ninitially selects the candidate mitotic region with maximum recall. However, in\nthe second phase, these candidate regions are refined by multi-object loss\nfunction to improve the precision. The performance of the proposed detection\nmodel shows improved discrimination ability (F-score of 0.86) for mitotic\nnuclei with significant precision (0.86) as compared to the two-stage detection\nmodels (F-score of 0.701) on TUPAC16 dataset. Promising results suggest that\nthe deep object detection-based model has the potential to learn the\ncharacteristic features of mitotic nuclei from weakly annotated data and\nsuggests that it can be adapted for the identification of other nuclear bodies\nin histopathological images.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 00:51:16 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Sohail", "Anabia", ""], ["Mukhtar", "Muhammad Ahsan", ""], ["Khan", "Asifullah", ""], ["Zafar", "Muhammad Mohsin", ""], ["Zameer", "Aneela", ""], ["Khan", "Saranjam", ""]]}, {"id": "2003.08820", "submitter": "Alonso Silva", "authors": "Camila Fernandez (LINCS), Chung Shue Chen (LINCS), Pierre Gaillard\n  (SIERRA), Alonso Silva", "title": "Experimental Comparison of Semi-parametric, Parametric, and Machine\n  Learning Models for Time-to-Event Analysis Through the Concordance Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we make an experimental comparison of semi-parametric (Cox\nproportional hazards model, Aalen's additive regression model), parametric\n(Weibull AFT model), and machine learning models (Random Survival Forest,\nGradient Boosting with Cox Proportional Hazards Loss, DeepSurv) through the\nconcordance index on two different datasets (PBC and GBCSG2). We present two\ncomparisons: one with the default hyper-parameters of these models and one with\nthe best hyper-parameters found by randomized search.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 07:18:14 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Fernandez", "Camila", "", "LINCS"], ["Chen", "Chung Shue", "", "LINCS"], ["Gaillard", "Pierre", "", "SIERRA"], ["Silva", "Alonso", ""]]}, {"id": "2003.08821", "submitter": "Luke Darlow", "authors": "Luke Nicholas Darlow, Amos Storkey", "title": "DHOG: Deep Hierarchical Object Grouping", "comments": "15 pages, submitted to ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, a number of competitive methods have tackled unsupervised\nrepresentation learning by maximising the mutual information between the\nrepresentations produced from augmentations. The resulting representations are\nthen invariant to stochastic augmentation strategies, and can be used for\ndownstream tasks such as clustering or classification. Yet data augmentations\npreserve many properties of an image and so there is potential for a suboptimal\nchoice of representation that relies on matching easy-to-find features in the\ndata. We demonstrate that greedy or local methods of maximising mutual\ninformation (such as stochastic gradient optimisation) discover local optima of\nthe mutual information criterion; the resulting representations are also\nless-ideally suited to complex downstream tasks. Earlier work has not\nspecifically identified or addressed this issue. We introduce deep hierarchical\nobject grouping (DHOG) that computes a number of distinct discrete\nrepresentations of images in a hierarchical order, eventually generating\nrepresentations that better optimise the mutual information objective. We also\nfind that these representations align better with the downstream task of\ngrouping into underlying object classes. We tested DHOG on unsupervised\nclustering, which is a natural downstream test as the target representation is\na discrete labelling of the data. We achieved new state-of-the-art results on\nthe three main benchmarks without any prefiltering or Sobel-edge detection that\nproved necessary for many previous methods to work. We obtain accuracy\nimprovements of: 4.3% on CIFAR-10, 1.5% on CIFAR-100-20, and 7.2% on SVHN.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 14:11:48 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Darlow", "Luke Nicholas", ""], ["Storkey", "Amos", ""]]}, {"id": "2003.08823", "submitter": "Xin Sun", "authors": "Xin Sun, Zhenning Yang, Chi Zhang, Guohao Peng, Keck-Voon Ling", "title": "Conditional Gaussian Distribution Learning for Open Set Recognition", "comments": "Accepted to CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state-of-the-art performance in a wide\nrange of recognition/classification tasks. However, when applying deep learning\nto real-world applications, there are still multiple challenges. A typical\nchallenge is that unknown samples may be fed into the system during the testing\nphase and traditional deep neural networks will wrongly recognize the unknown\nsample as one of the known classes. Open set recognition is a potential\nsolution to overcome this problem, where the open set classifier should have\nthe ability to reject unknown samples as well as maintain high classification\naccuracy on known classes. The variational auto-encoder (VAE) is a popular\nmodel to detect unknowns, but it cannot provide discriminative representations\nfor known classification. In this paper, we propose a novel method, Conditional\nGaussian Distribution Learning (CGDL), for open set recognition. In addition to\ndetecting unknown samples, this method can also classify known samples by\nforcing different latent features to approximate different Gaussian models.\nMeanwhile, to avoid information hidden in the input vanishing in the middle\nlayers, we also adopt the probabilistic ladder architecture to extract\nhigh-level abstract features. Experiments on several standard image datasets\nreveal that the proposed method significantly outperforms the baseline method\nand achieves new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 14:32:08 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 08:43:22 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 08:10:23 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 11:52:11 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sun", "Xin", ""], ["Yang", "Zhenning", ""], ["Zhang", "Chi", ""], ["Peng", "Guohao", ""], ["Ling", "Keck-Voon", ""]]}, {"id": "2003.08837", "submitter": "Christian Berghoff", "authors": "Christian Berghoff and Matthias Neu and Arndt von Twickel", "title": "Vulnerabilities of Connectionist AI Applications: Evaluation and Defence", "comments": "20 pages, 8 figures, 1 table", "journal-ref": null, "doi": "10.3389/fdata.2020.00023", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the IT security of connectionist artificial\nintelligence (AI) applications, focusing on threats to integrity, one of the\nthree IT security goals. Such threats are for instance most relevant in\nprominent AI computer vision applications. In order to present a holistic view\non the IT security goal integrity, many additional aspects such as\ninterpretability, robustness and documentation are taken into account. A\ncomprehensive list of threats and possible mitigations is presented by\nreviewing the state-of-the-art literature. AI-specific vulnerabilities such as\nadversarial attacks and poisoning attacks as well as their AI-specific root\ncauses are discussed in detail. Additionally and in contrast to former reviews,\nthe whole AI supply chain is analysed with respect to vulnerabilities,\nincluding the planning, data acquisition, training, evaluation and operation\nphases. The discussion of mitigations is likewise not restricted to the level\nof the AI system itself but rather advocates viewing AI systems in the context\nof their supply chains and their embeddings in larger IT infrastructures and\nhardware devices. Based on this and the observation that adaptive attackers may\ncircumvent any single published AI-specific defence to date, the article\nconcludes that single protective measures are not sufficient but rather\nmultiple measures on different levels have to be combined to achieve a minimum\nlevel of IT security for AI applications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 12:33:59 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Berghoff", "Christian", ""], ["Neu", "Matthias", ""], ["von Twickel", "Arndt", ""]]}, {"id": "2003.08839", "submitter": "Mikayel Samvelyan", "authors": "Tabish Rashid, Mikayel Samvelyan, Christian Schroeder de Witt, Gregory\n  Farquhar, Jakob Foerster, Shimon Whiteson", "title": "Monotonic Value Function Factorisation for Deep Multi-Agent\n  Reinforcement Learning", "comments": "Extended version of the ICML 2018 conference paper (arXiv:1803.11485)", "journal-ref": "Journal of Machine Learning Research 21(178):1-51, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world settings, a team of agents must coordinate its behaviour\nwhile acting in a decentralised fashion. At the same time, it is often possible\nto train the agents in a centralised fashion where global state information is\navailable and communication constraints are lifted. Learning joint\naction-values conditioned on extra state information is an attractive way to\nexploit centralised learning, but the best strategy for then extracting\ndecentralised policies is unclear. Our solution is QMIX, a novel value-based\nmethod that can train decentralised policies in a centralised end-to-end\nfashion. QMIX employs a mixing network that estimates joint action-values as a\nmonotonic combination of per-agent values. We structurally enforce that the\njoint-action value is monotonic in the per-agent values, through the use of\nnon-negative weights in the mixing network, which guarantees consistency\nbetween the centralised and decentralised policies. To evaluate the performance\nof QMIX, we propose the StarCraft Multi-Agent Challenge (SMAC) as a new\nbenchmark for deep multi-agent reinforcement learning. We evaluate QMIX on a\nchallenging set of SMAC scenarios and show that it significantly outperforms\nexisting multi-agent reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 16:51:51 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 13:45:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Rashid", "Tabish", ""], ["Samvelyan", "Mikayel", ""], ["de Witt", "Christian Schroeder", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2003.08844", "submitter": "Ali Anaissi", "authors": "Ali Anaissi, Basem Suleiman, Seid Miad Zandavi", "title": "NeCPD: An Online Tensor Decomposition with Optimal Stochastic Gradient\n  Descent", "comments": "arXiv admin note: text overlap with arXiv:2003.04497", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-way data analysis has become an essential tool for capturing underlying\nstructures in higher-order datasets stored in tensor $\\mathcal{X} \\in\n\\mathbb{R} ^{I_1 \\times \\dots \\times I_N} $. $CANDECOMP/PARAFAC$ (CP)\ndecomposition has been extensively studied and applied to approximate\n$\\mathcal{X}$ by $N$ loading matrices $A^{(1)}, \\dots, A^{(N)}$ where $N$\nrepresents the order of the tensor. We propose a new efficient CP decomposition\nsolver named NeCPD for non-convex problem in multi-way online data based on\nstochastic gradient descent (SGD) algorithm. SGD is very useful in online\nsetting since it allows us to update $\\mathcal{X}^{(t+1)}$ in one single step.\nIn terms of global convergence, it is well known that SGD stuck in many saddle\npoints when it deals with non-convex problems. We study the Hessian matrix to\nidentify theses saddle points, and then try to escape them using the\nperturbation approach which adds little noise to the gradient update step. We\nfurther apply Nesterov's Accelerated Gradient (NAG) method in SGD algorithm to\noptimally accelerate the convergence rate and compensate Hessian computational\ndelay time per epoch. Experimental evaluation in the field of structural health\nmonitoring using laboratory-based and real-life structural datasets show that\nour method provides more accurate results compared with existing online tensor\nanalysis methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 04:44:05 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Anaissi", "Ali", ""], ["Suleiman", "Basem", ""], ["Zandavi", "Seid Miad", ""]]}, {"id": "2003.08863", "submitter": "Sanmay Ganguly", "authors": "Francesco Armando Di Bello, Sanmay Ganguly, Eilam Gross, Marumi Kado,\n  Michael Pitt, Lorenzo Santi, Jonathan Shlomi", "title": "Towards a Computer Vision Particle Flow", "comments": "15 pages, 10 figures. Note to admin : updating to journal version", "journal-ref": "Eur. Phys. J. C (2021) 81:107", "doi": "10.1140/epjc/s10052-021-08897-0", "report-no": null, "categories": "physics.data-an hep-ex hep-ph physics.ins-det stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In High Energy Physics experiments Particle Flow (PFlow) algorithms are\ndesigned to provide an optimal reconstruction of the nature and kinematic\nproperties of the particles produced within the detector acceptance during\ncollisions. At the heart of PFlow algorithms is the ability to distinguish the\ncalorimeter energy deposits of neutral particles from those of charged\nparticles, using the complementary measurements of charged particle tracking\ndevices, to provide a superior measurement of the particle content and\nkinematics. In this paper, a computer vision approach to this fundamental\naspect of PFlow algorithms, based on calorimeter images, is proposed. A\ncomparative study of the state of the art deep learning techniques is\nperformed. A significantly improved reconstruction of the neutral particle\ncalorimeter energy deposits is obtained in a context of large overlaps with the\ndeposits from charged particles. Calorimeter images with augmented finer\ngranularity are also obtained using super-resolution techniques.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 15:26:23 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 20:26:49 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 22:09:20 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Di Bello", "Francesco Armando", ""], ["Ganguly", "Sanmay", ""], ["Gross", "Eilam", ""], ["Kado", "Marumi", ""], ["Pitt", "Michael", ""], ["Santi", "Lorenzo", ""], ["Shlomi", "Jonathan", ""]]}, {"id": "2003.08876", "submitter": "Philip Becker-Ehmck", "authors": "Philip Becker-Ehmck, Maximilian Karl, Jan Peters, Patrick van der\n  Smagt", "title": "Learning to Fly via Deep Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to control robots without requiring engineered models has been a\nlong-term goal, promising diverse and novel applications. Yet, reinforcement\nlearning has only achieved limited impact on real-time robot control due to its\nhigh demand of real-world interactions. In this work, by leveraging a learnt\nprobabilistic model of drone dynamics, we learn a thrust-attitude controller\nfor a quadrotor through model-based reinforcement learning. No prior knowledge\nof the flight dynamics is assumed; instead, a sequential latent variable model,\nused generatively and as an online filter, is learnt from raw sensory input.\nThe controller and value function are optimised entirely by propagating\nstochastic analytic gradients through generated latent trajectories. We show\nthat \"learning to fly\" can be achieved with less than 30 minutes of experience\nwith a single drone, and can be deployed solely using onboard computational\nresources and sensors, on a self-built drone.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 15:55:39 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 10:54:35 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 10:41:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Becker-Ehmck", "Philip", ""], ["Karl", "Maximilian", ""], ["Peters", "Jan", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "2003.08904", "submitter": "Maurice Weber", "authors": "Maurice Weber, Xiaojun Xu, Bojan Karla\\v{s}, Ce Zhang, Bo Li", "title": "RAB: Provable Robustness Against Backdoor Attacks", "comments": "31 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep neural networks (DNNs) are highly\nvulnerable to adversarial attacks, including evasion and backdoor (poisoning)\nattacks. On the defense side, there have been intensive interests in both\nempirical and provable robustness against evasion attacks; however, provable\nrobustness against backdoor attacks remains largely unexplored. In this paper,\nwe focus on certifying robustness against backdoor attacks. To this end, we\nfirst provide a unified framework for robustness certification and show that it\nleads to a tight robustness condition for backdoor attacks. We then propose the\nfirst robust training process, RAB, to smooth the trained model and certify its\nrobustness against backdoor attacks. Moreover, we evaluate the certified\nrobustness of a family of \"smoothed\" models which are trained in a\ndifferentially private fashion, and show that they achieve better certified\nrobustness bounds. In addition, we theoretically show that it is possible to\ntrain the robust smoothed models efficiently for simple models such as\nK-nearest neighbor classifiers, and we propose an exact smooth-training\nalgorithm which eliminates the need to sample from a noise distribution.\nEmpirically, we conduct comprehensive experiments for different machine\nlearning (ML) models such as DNNs, differentially private DNNs, and K-NN models\non MNIST, CIFAR-10 and ImageNet datasets (focusing on binary classifiers), and\nprovide the first benchmark for certified robustness against backdoor attacks.\nIn addition, we evaluate K-NN models on a spambase tabular dataset to\ndemonstrate the advantages of the proposed exact algorithm. Both the\ntheoretical analysis and the comprehensive benchmark on diverse ML models and\ndatasets shed lights on further robust learning strategies against training\ntime attacks or other general adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:05:51 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 15:38:19 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 12:53:24 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 18:59:59 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Weber", "Maurice", ""], ["Xu", "Xiaojun", ""], ["Karla\u0161", "Bojan", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""]]}, {"id": "2003.08907", "submitter": "Brandon Carter", "authors": "Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford", "title": "Overinterpretation reveals image classification model pathologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classifiers are typically scored on their test set accuracy, but high\naccuracy can mask a subtle type of model failure. We find that high scoring\nconvolutional neural networks (CNN) exhibit troubling pathologies that allow\nthem to display high accuracy even in the absence of semantically salient\nfeatures. When a model provides a high-confidence decision without salient\nsupporting input features we say that the classifier has overinterpreted its\ninput, finding too much class-evidence in patterns that appear nonsensical to\nhumans. Here, we demonstrate that state of the art neural networks for CIFAR-10\nand ImageNet suffer from overinterpretation, and find CIFAR-10 trained models\nmake confident predictions even when 95% of an input image has been masked and\nhumans are unable to discern salient features in the remaining pixel subset.\nAlthough these patterns portend potential model fragility in real-world\ndeployment, they are in fact valid statistical patterns of the image\nclassification benchmark that alone suffice to attain high test accuracy. We\nfind that ensembling strategies can help mitigate model overinterpretation, and\nclassifiers which rely on more semantically meaningful features can improve\naccuracy over both the test set and out-of-distribution images from a different\nsource than the training data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:12:23 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Carter", "Brandon", ""], ["Jain", "Siddhartha", ""], ["Mueller", "Jonas", ""], ["Gifford", "David", ""]]}, {"id": "2003.08937", "submitter": "Amin Ghiasi", "authors": "Amin Ghiasi, Ali Shafahi and Tom Goldstein", "title": "Breaking certified defenses: Semantic adversarial examples with spoofed\n  robustness certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deflect adversarial attacks, a range of \"certified\" classifiers have been\nproposed. In addition to labeling an image, certified classifiers produce (when\npossible) a certificate guaranteeing that the input image is not an\n$\\ell_p$-bounded adversarial example. We present a new attack that exploits not\nonly the labelling function of a classifier, but also the certificate\ngenerator. The proposed method applies large perturbations that place images\nfar from a class boundary while maintaining the imperceptibility property of\nadversarial examples. The proposed \"Shadow Attack\" causes certifiably robust\nnetworks to mislabel an image and simultaneously produce a \"spoofed\"\ncertificate of robustness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:59:44 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Ghiasi", "Amin", ""], ["Shafahi", "Ali", ""], ["Goldstein", "Tom", ""]]}, {"id": "2003.08938", "submitter": "Huan Zhang", "authors": "Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Mingyan Liu, Duane\n  Boning, Cho-Jui Hsieh", "title": "Robust Deep Reinforcement Learning against Adversarial Perturbations on\n  State Observations", "comments": "Huan Zhang and Hongge Chen contributed equally", "journal-ref": "Advances in Neural Information Processing Systems 33 (2020):\n  21024-21037", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep reinforcement learning (DRL) agent observes its states through\nobservations, which may contain natural measurement errors or adversarial\nnoises. Since the observations deviate from the true states, they can mislead\nthe agent into making suboptimal actions. Several works have shown this\nvulnerability via adversarial attacks, but existing approaches on improving the\nrobustness of DRL under this setting have limited success and lack for\ntheoretical principles. We show that naively applying existing techniques on\nimproving robustness for classification tasks, like adversarial training, is\nineffective for many RL tasks. We propose the state-adversarial Markov decision\nprocess (SA-MDP) to study the fundamental properties of this problem, and\ndevelop a theoretically principled policy regularization which can be applied\nto a large family of DRL algorithms, including proximal policy optimization\n(PPO), deep deterministic policy gradient (DDPG) and deep Q networks (DQN), for\nboth discrete and continuous action control problems. We significantly improve\nthe robustness of PPO, DDPG and DQN agents under a suite of strong white box\nadversarial attacks, including new attacks of our own. Additionally, we find\nthat a robust policy noticeably improves DRL performance even without an\nadversary in a number of environments. Our code is available at\nhttps://github.com/chenhongge/StateAdvDRL.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:59:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:43:42 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 17:56:00 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 08:10:02 GMT"}, {"version": "v5", "created": "Mon, 18 Jan 2021 21:34:23 GMT"}, {"version": "v6", "created": "Thu, 21 Jan 2021 05:26:33 GMT"}, {"version": "v7", "created": "Wed, 14 Jul 2021 07:20:48 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Xiao", "Chaowei", ""], ["Li", "Bo", ""], ["Liu", "Mingyan", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2003.08954", "submitter": "Ali Milani", "authors": "Yuzhou Liu (1), Balaji Thoshkahna (2), Ali Milani (3), Trausti\n  Kristjansson (3) ((1) Ohio State University (2) Amazon Music, Bangalore (3)\n  Amazon Lab126, CA)", "title": "Voice and accompaniment separation in music using self-attention\n  convolutional neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music source separation has been a popular topic in signal processing for\ndecades, not only because of its technical difficulty, but also due to its\nimportance to many commercial applications, such as automatic karoake and\nremixing. In this work, we propose a novel self-attention network to separate\nvoice and accompaniment in music. First, a convolutional neural network (CNN)\nwith densely-connected CNN blocks is built as our base network. We then insert\nself-attention subnets at different levels of the base CNN to make use of the\nlong-term intra-dependency of music, i.e., repetition. Within self-attention\nsubnets, repetitions of the same musical patterns inform reconstruction of\nother repetitions, for better source separation performance. Results show the\nproposed method leads to 19.5% relative improvement in vocals separation in\nterms of SDR. We compare our methods with state-of-the-art systems i.e.\nMMDenseNet and MMDenseLSTM.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:00:56 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Liu", "Yuzhou", ""], ["Thoshkahna", "Balaji", ""], ["Milani", "Ali", ""], ["Kristjansson", "Trausti", ""]]}, {"id": "2003.08967", "submitter": "Alex Dytso", "authors": "Alex Dytso, Michael Fauss, and H. Vincent Poor", "title": "The Vector Poisson Channel: On the Linearity of the Conditional Mean\n  Estimator", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3025525", "report-no": null, "categories": "cs.IT eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies properties of the conditional mean estimator in vector\nPoisson noise. The main emphasis is to study conditions on prior distributions\nthat induce linearity of the conditional mean estimator. The paper consists of\ntwo main results. The first result shows that the only distribution that\ninduces the linearity of the conditional mean estimator is a product gamma\ndistribution. Moreover, it is shown that the conditional mean estimator cannot\nbe linear when the dark current parameter of the Poisson noise is non-zero. The\nsecond result produces a quantitative refinement of the first result.\nSpecifically, it is shown that if the conditional mean estimator is close to\nlinear in a mean squared error sense, then the prior distribution must be close\nto a product gamma distribution in terms of their characteristic functions.\nFinally, the results are compared to their Gaussian counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:21:33 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dytso", "Alex", ""], ["Fauss", "Michael", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2003.08978", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Generating new concepts with hybrid neuro-symbolic models", "comments": "Published in Proceedings of the 42nd Annual Meeting of the Cognitive\n  Science Society, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conceptual knowledge supports the ability to generate novel yet highly\nstructured concepts, and the form of this conceptual knowledge is of great\ninterest to cognitive scientists. One tradition has emphasized structured\nknowledge, viewing concepts as embedded in intuitive theories or organized in\ncomplex symbolic knowledge structures. A second tradition has emphasized\nstatistical knowledge, viewing conceptual knowledge as an emerging from the\nrich correlational structure captured by training neural networks and other\nstatistical models. In this paper, we explore a synthesis of these two\ntraditions through a novel neuro-symbolic model for generating new concepts.\nUsing simple visual concepts as a testbed, we bring together neural networks\nand symbolic probabilistic programs to learn a generative model of novel\nhandwritten characters. Two alternative models are explored with more generic\nneural network architectures. We compare each of these three models for their\nlikelihoods on held-out character classes and for the quality of their\nproductions, finding that our hybrid model learns the most convincing\nrepresentation and generalizes further from the training observations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:45:56 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 14:47:17 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 01:31:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2003.08983", "submitter": "J\\'er\\^ome Rony", "authors": "Malik Boudiaf, J\\'er\\^ome Rony, Imtiaz Masud Ziko, Eric Granger, Marco\n  Pedersoli, Pablo Piantanida, Ismail Ben Ayed", "title": "A unifying mutual information view of metric learning: cross-entropy vs.\n  pairwise losses", "comments": "ECCV 2020 (Spotlight) - Code available at:\n  https://github.com/jeromerony/dml_cross_entropy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, substantial research efforts in Deep Metric Learning (DML) focused\non designing complex pairwise-distance losses, which require convoluted schemes\nto ease optimization, such as sample mining or pair weighting. The standard\ncross-entropy loss for classification has been largely overlooked in DML. On\nthe surface, the cross-entropy may seem unrelated and irrelevant to metric\nlearning as it does not explicitly involve pairwise distances. However, we\nprovide a theoretical analysis that links the cross-entropy to several\nwell-known and recent pairwise losses. Our connections are drawn from two\ndifferent perspectives: one based on an explicit optimization insight; the\nother on discriminative and generative views of the mutual information between\nthe labels and the learned features. First, we explicitly demonstrate that the\ncross-entropy is an upper bound on a new pairwise loss, which has a structure\nsimilar to various pairwise losses: it minimizes intra-class distances while\nmaximizing inter-class distances. As a result, minimizing the cross-entropy can\nbe seen as an approximate bound-optimization (or Majorize-Minimize) algorithm\nfor minimizing this pairwise loss. Second, we show that, more generally,\nminimizing the cross-entropy is actually equivalent to maximizing the mutual\ninformation, to which we connect several well-known pairwise losses.\nFurthermore, we show that various standard pairwise losses can be explicitly\nrelated to one another via bound relationships. Our findings indicate that the\ncross-entropy represents a proxy for maximizing the mutual information -- as\npairwise losses do -- without the need for convoluted sample-mining heuristics.\nOur experiments over four standard DML benchmarks strongly support our\nfindings. We obtain state-of-the-art results, outperforming recent and complex\nDML methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:59:54 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 22:15:43 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Boudiaf", "Malik", ""], ["Rony", "J\u00e9r\u00f4me", ""], ["Ziko", "Imtiaz Masud", ""], ["Granger", "Eric", ""], ["Pedersoli", "Marco", ""], ["Piantanida", "Pablo", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "2003.08996", "submitter": "Luis Armando P\\'erez Rey", "authors": "Luis A. P\\'erez Rey", "title": "Disentanglement with Hyperspherical Latent Spaces using Diffusion\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A disentangled representation of a data set should be capable of recovering\nthe underlying factors that generated it. One question that arises is whether\nusing Euclidean space for latent variable models can produce a disentangled\nrepresentation when the underlying generating factors have a certain\ngeometrical structure. Take for example the images of a car seen from different\nangles. The angle has a periodic structure but a 1-dimensional representation\nwould fail to capture this topology. How can we address this problem? The\nsubmissions presented for the first stage of the NeurIPS2019 Disentanglement\nChallenge consist of a Diffusion Variational Autoencoder ($\\Delta$VAE) with a\nhyperspherical latent space which can, for example, recover periodic true\nfactors. The training of the $\\Delta$VAE is enhanced by incorporating a\nmodified version of the Evidence Lower Bound (ELBO) for tailoring the encoding\ncapacity of the posterior approximate.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 19:36:03 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Rey", "Luis A. P\u00e9rez", ""]]}, {"id": "2003.09018", "submitter": "M Tanjid Hasan Tonmoy", "authors": "Saif Mahmud, M Tanjid Hasan Tonmoy, Kishor Kumar Bhaumik, A K M\n  Mahbubur Rahman, M Ashraful Amin, Mohammad Shoyaib, Muhammad Asif Hossain\n  Khan, Amin Ahsan Ali", "title": "Human Activity Recognition from Wearable Sensor Data Using\n  Self-Attention", "comments": "Accepted for publication at the 24th European Conference on\n  Artificial Intelligence (ECAI-2020); 8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human Activity Recognition from body-worn sensor data poses an inherent\nchallenge in capturing spatial and temporal dependencies of time-series\nsignals. In this regard, the existing recurrent or convolutional or their\nhybrid models for activity recognition struggle to capture spatio-temporal\ncontext from the feature space of sensor reading sequence. To address this\ncomplex problem, we propose a self-attention based neural network model that\nforegoes recurrent architectures and utilizes different types of attention\nmechanisms to generate higher dimensional feature representation used for\nclassification. We performed extensive experiments on four popular publicly\navailable HAR datasets: PAMAP2, Opportunity, Skoda and USC-HAD. Our model\nachieve significant performance improvement over recent state-of-the-art models\nin both benchmark test subjects and Leave-one-subject-out evaluation. We also\nobserve that the sensor attention maps produced by our model is able capture\nthe importance of the modality and placement of the sensors in predicting the\ndifferent activity classes.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 14:16:57 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Mahmud", "Saif", ""], ["Tonmoy", "M Tanjid Hasan", ""], ["Bhaumik", "Kishor Kumar", ""], ["Rahman", "A K M Mahbubur", ""], ["Amin", "M Ashraful", ""], ["Shoyaib", "Mohammad", ""], ["Khan", "Muhammad Asif Hossain", ""], ["Ali", "Amin Ahsan", ""]]}, {"id": "2003.09022", "submitter": "John Mern", "authors": "John Mern and Dorsa Sadigh and Mykel J. Kochenderfer", "title": "Exchangeable Input Representations for Reinforcement Learning", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poor sample efficiency is a major limitation of deep reinforcement learning\nin many domains. This work presents an attention-based method to project neural\nnetwork inputs into an efficient representation space that is invariant under\nchanges to input ordering. We show that our proposed representation results in\nan input space that is a factor of $m!$ smaller for inputs of $m$ objects. We\nalso show that our method is able to represent inputs over variable numbers of\nobjects. Our experiments demonstrate improvements in sample efficiency for\npolicy gradient methods on a variety of tasks. We show that our representation\nallows us to solve problems that are otherwise intractable when using na\\\"ive\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 21:18:55 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Mern", "John", ""], ["Sadigh", "Dorsa", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2003.09040", "submitter": "Kensen Shi", "authors": "Kensen Shi, David Bieber, Rishabh Singh", "title": "TF-Coder: Program Synthesis for Tensor Manipulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success and popularity of deep learning is on the rise, partially due to\npowerful deep learning frameworks such as TensorFlow and PyTorch that make it\neasier to develop deep learning models. However, these libraries also come with\nsteep learning curves, since programming in these frameworks is quite different\nfrom traditional imperative programming with explicit loops and conditionals.\nIn this work, we present a tool called TF-Coder for programming by example in\nTensorFlow. TF-Coder uses a bottom-up weighted enumerative search, with\nvalue-based pruning of equivalent expressions and flexible type- and\nvalue-based filtering to ensure that expressions adhere to various requirements\nimposed by the TensorFlow library. We also train models that predict TensorFlow\noperations from features of the input and output tensors and natural language\ndescriptions of tasks, and use the models to prioritize relevant operations\nduring the search. TF-Coder solves 63 of 70 real-world tasks within 5 minutes,\noften achieving superhuman performance -- finding solutions that are simpler\nthan those written by TensorFlow experts, in less time as well.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 22:53:47 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 00:06:20 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 00:51:38 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Shi", "Kensen", ""], ["Bieber", "David", ""], ["Singh", "Rishabh", ""]]}, {"id": "2003.09077", "submitter": "Ju Sun", "authors": "Kshitij Tayal, Chieh-Hsin Lai, Vipin Kumar, Ju Sun", "title": "Inverse Problems, Deep Learning, and Symmetry Breaking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.SP math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many physical systems, inputs related by intrinsic system symmetries are\nmapped to the same output. When inverting such systems, i.e., solving the\nassociated inverse problems, there is no unique solution. This causes\nfundamental difficulties for deploying the emerging end-to-end deep learning\napproach. Using the generalized phase retrieval problem as an illustrative\nexample, we show that careful symmetry breaking on the training data can help\nget rid of the difficulties and significantly improve the learning performance.\nWe also extract and highlight the underlying mathematical principle of the\nproposed solution, which is directly applicable to other inverse problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 02:43:57 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Tayal", "Kshitij", ""], ["Lai", "Chieh-Hsin", ""], ["Kumar", "Vipin", ""], ["Sun", "Ju", ""]]}, {"id": "2003.09097", "submitter": "Rakshith Sharma Srinivasa", "authors": "Rakshith S Srinivasa, Mark A Davenport, Justin Romberg", "title": "Localized sketching for matrix multiplication and ridge regression", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sketched approximate matrix multiplication and ridge regression\nin the novel setting of localized sketching, where at any given point, only\npart of the data matrix is available. This corresponds to a block diagonal\nstructure on the sketching matrix. We show that, under mild conditions, block\ndiagonal sketching matrices require only O(stable rank / \\epsilon^2) and $O(\nstat. dim. \\epsilon)$ total sample complexity for matrix multiplication and\nridge regression, respectively. This matches the state-of-the-art bounds that\nare obtained using global sketching matrices. The localized nature of sketching\nconsidered allows for different parts of the data matrix to be sketched\nindependently and hence is more amenable to computation in distributed and\nstreaming settings and results in a smaller memory and computational footprint.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 04:25:32 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Srinivasa", "Rakshith S", ""], ["Davenport", "Mark A", ""], ["Romberg", "Justin", ""]]}, {"id": "2003.09103", "submitter": "Kai-Hung Chang", "authors": "Kai-Hung Chang (1), Chin-Yi Cheng (1) ((1) Autodesk Research)", "title": "Learning to simulate and design for structural engineering", "comments": "ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structural design process for buildings is time-consuming and laborious.\nTo automate this process, structural engineers combine optimization methods\nwith simulation tools to find an optimal design with minimal building mass\nsubject to building regulations. However, structural engineers in practice\noften avoid optimization and compromise on a suboptimal design for the majority\nof buildings, due to the large size of the design space, the iterative nature\nof the optimization methods, and the slow simulation tools. In this work, we\nformulate the building structures as graphs and create an end-to-end pipeline\nthat can learn to propose the optimal cross-sections of columns and beams by\ntraining together with a pre-trained differentiable structural simulator. The\nperformance of the proposed structural designs is comparable to the ones\noptimized by genetic algorithm (GA), with all the constraints satisfied. The\noptimal structural design with the reduced the building mass can not only lower\nthe material cost, but also decrease the carbon footprint.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 05:00:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 23:18:15 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 23:21:21 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Chang", "Kai-Hung", "", "Autodesk Research"], ["Cheng", "Chin-Yi", "", "Autodesk Research"]]}, {"id": "2003.09136", "submitter": "Anne Baillot", "authors": "David Lassner (TUB), Anne Baillot (3L.AM), Sergej Dogadov (TUB),\n  Klaus-Robert M\\\"uller (TUB), Shinichi Nakajima (TUB)", "title": "Automatic Identification of Types of Alterations in Historical\n  Manuscripts", "comments": "Accepted for publication in Digital Humanities Quarterly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alterations in historical manuscripts such as letters represent a promising\nfield of research. On the one hand, they help understand the construction of\ntext. On the other hand, topics that are being considered sensitive at the time\nof the manuscript gain coherence and contextuality when taking alterations into\naccount, especially in the case of deletions. The analysis of alterations in\nmanuscripts, though, is a traditionally very tedious work. In this paper, we\npresent a machine learning-based approach to help categorize alterations in\ndocuments. In particular, we present a new probabilistic model (Alteration\nLatent Dirichlet Allocation, alterLDA in the following) that categorizes\ncontent-related alterations. The method proposed here is developed based on\nexperiments carried out on the digital scholarly edition Berlin Intellectuals,\nfor which alterLDA achieves high performance in the recognition of alterations\non labelled data. On unlabelled data, applying alterLDA leads to interesting\nnew insights into the alteration behavior of authors, editors and other\nmanuscript contributors, as well as insights into sensitive topics in the\ncorrespondence of Berlin intellectuals around 1800. In addition to the findings\nbased on the digital scholarly edition Berlin Intellectuals, we present a\ngeneral framework for the analysis of text genesis that can be used in the\ncontext of other digital resources representing document variants. To that end,\nwe present in detail the methodological steps that are to be followed in order\nto achieve such results, giving thereby a prime example of an Machine Learning\napplication the Digital Humanities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 08:05:27 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 08:10:13 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 15:36:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Lassner", "David", "", "TUB"], ["Baillot", "Anne", "", "3L.AM"], ["Dogadov", "Sergej", "", "TUB"], ["M\u00fcller", "Klaus-Robert", "", "TUB"], ["Nakajima", "Shinichi", "", "TUB"]]}, {"id": "2003.09149", "submitter": "Magda Friedjungov\\'a", "authors": "Magda Friedjungov\\'a, Daniel Va\\v{s}ata, Tom\\'a\\v{s} Chobola, Marcel\n  Ji\\v{r}ina", "title": "Unsupervised Latent Space Translation Network", "comments": "To be published in conference proceedings of ESANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One task that is often discussed in a computer vision is the mapping of an\nimage from one domain to a corresponding image in another domain known as\nimage-to-image translation. Currently there are several approaches solving this\ntask. In this paper, we present an enhancement of the UNIT framework that aids\nin removing its main drawbacks. More specifically, we introduce an additional\nadversarial discriminator on the latent representation used instead of VAE,\nwhich enforces the latent space distributions of both domains to be similar. On\nMNIST and USPS domain adaptation tasks, this approach greatly outperforms\ncompeting approaches.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 08:41:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Friedjungov\u00e1", "Magda", ""], ["Va\u0161ata", "Daniel", ""], ["Chobola", "Tom\u00e1\u0161", ""], ["Ji\u0159ina", "Marcel", ""]]}, {"id": "2003.09176", "submitter": "Khadija Musayeva", "authors": "Khadija Musayeva", "title": "Sample Complexity Result for Multi-category Classifiers of Bounded\n  Variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We control the probability of the uniform deviation between empirical and\ngeneralization performances of multi-category classifiers by an empirical L1\n-norm covering number when these performances are defined on the basis of the\ntruncated hinge loss function. The only assumption made on the functions\nimplemented by multi-category classifiers is that they are of bounded variation\n(BV). For such classifiers, we derive the sample size estimate sufficient for\nthe mentioned performances to be close with high probability. Particularly, we\nare interested in the dependency of this estimate on the number C of classes.\nTo this end, first, we upper bound the scale-sensitive version of the\nVC-dimension, the fat-shattering dimension of sets of BV functions defined on\nR^d which gives a O(1/epsilon^d ) as the scale epsilon goes to zero. Secondly,\nwe provide a sharper decomposition result for the fat-shattering dimension in\nterms of C, which for sets of BV functions gives an improvement from O(C^(d/2\n+1)) to O(Cln^2(C)). This improvement then propagates to the sample complexity\nestimate.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 10:20:45 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 11:02:25 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Musayeva", "Khadija", ""]]}, {"id": "2003.09195", "submitter": "Zheng Peng", "authors": "Kangkang Deng and Zheng Peng", "title": "An Inexact Manifold Augmented Lagrangian Method for Adaptive Sparse\n  Canonical Correlation Analysis with Trace Lasso Regularization", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA for short) describes the relationship\nbetween two sets of variables by finding some linear combinations of these\nvariables that maximizing the correlation coefficient. However, in\nhigh-dimensional settings where the number of variables exceeds sample size, or\nin the case of that the variables are highly correlated, the traditional CCA is\nno longer appropriate. In this paper, an adaptive sparse version of CCA (ASCCA\nfor short) is proposed by using the trace Lasso regularization. The proposed\nASCCA reduces the instability of the estimator when the covariates are highly\ncorrelated, and thus improves its interpretation. The ASCCA is further\nreformulated to an optimization problem on Riemannian manifolds, and an\nmanifold inexact augmented Lagrangian method is then proposed for the resulting\noptimization problem. The performance of the ASCCA is compared with the other\nsparse CCA techniques in different simulation settings, which illustrates that\nthe ASCCA is feasible and efficient.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 10:57:01 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Deng", "Kangkang", ""], ["Peng", "Zheng", ""]]}, {"id": "2003.09198", "submitter": "Lorenzo Dall'Amico", "authors": "Lorenzo Dall'Amico, Romain Couillet, Nicolas Tremblay", "title": "A unified framework for spectral clustering in sparse graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers spectral community detection in the regime of sparse\nnetworks with heterogeneous degree distributions, for which we devise an\nalgorithm to efficiently retrieve communities. Specifically, we demonstrate\nthat a conveniently parametrized form of regularized Laplacian matrix can be\nused to perform spectral clustering in sparse networks, without suffering from\nits degree heterogeneity. Besides, we exhibit important connections between\nthis proposed matrix and the now popular non-backtracking matrix, the\nBethe-Hessian matrix, as well as the standard Laplacian matrix. Interestingly,\nas opposed to competitive methods, our proposed improved parametrization\ninherently accounts for the hardness of the classification problem. These\nfindings are summarized under the form of an algorithm capable of both\nestimating the number of communities and achieving high-quality community\nreconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 10:58:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Dall'Amico", "Lorenzo", ""], ["Couillet", "Romain", ""], ["Tremblay", "Nicolas", ""]]}, {"id": "2003.09229", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Hsiang-Fu Yu, Inderjit Dhillon, Cho-Jui Hsieh", "title": "Learning to Encode Position for Transformer with Continuous Dynamical\n  Model", "comments": "Code to be released in https://github.com/xuanqing94/FLOATER", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new way of learning to encode position information for\nnon-recurrent models, such as Transformer models. Unlike RNN and LSTM, which\ncontain inductive bias by loading the input tokens sequentially, non-recurrent\nmodels are less sensitive to position. The main reason is that position\ninformation among input units is not inherently encoded, i.e., the models are\npermutation equivalent; this problem justifies why all of the existing models\nare accompanied by a sinusoidal encoding/embedding layer at the input. However,\nthis solution has clear limitations: the sinusoidal encoding is not flexible\nenough as it is manually designed and does not contain any learnable\nparameters, whereas the position embedding restricts the maximum length of\ninput sequences. It is thus desirable to design a new position layer that\ncontains learnable parameters to adjust to different datasets and different\narchitectures. At the same time, we would also like the encodings to\nextrapolate in accordance with the variable length of inputs. In our proposed\nsolution, we borrow from the recent Neural ODE approach, which may be viewed as\na versatile continuous version of a ResNet. This model is capable of modeling\nmany kinds of dynamical systems. We model the evolution of encoded results\nalong position index by such a dynamical system, thereby overcoming the above\nlimitations of existing methods. We evaluate our new position layers on a\nvariety of neural machine translation and language understanding tasks, the\nexperimental results show consistent improvements over the baselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:41:41 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Liu", "Xuanqing", ""], ["Yu", "Hsiang-Fu", ""], ["Dhillon", "Inderjit", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2003.09280", "submitter": "Andrea Cini", "authors": "Andrea Cini, Carlo D'Eramo, Jan Peters, Cesare Alippi", "title": "Deep Reinforcement Learning with Weighted Q-Learning", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overestimation of the maximum action-value is a well-known problem that\nhinders Q-Learning performance, leading to suboptimal policies and unstable\nlearning. Among several Q-Learning variants proposed to address this issue,\nWeighted Q-Learning (WQL) effectively reduces the bias and shows remarkable\nresults in stochastic environments. WQL uses a weighted sum of the estimated\naction-values, where the weights correspond to the probability of each\naction-value being the maximum; however, the computation of these probabilities\nis only practical in the tabular settings. In this work, we provide the\nmethodological advances to benefit from the WQL properties in Deep\nReinforcement Learning (DRL), by using neural networks with Dropout Variational\nInference as an effective approximation of deep Gaussian processes. In\nparticular, we adopt the Concrete Dropout variant to obtain calibrated\nestimates of epistemic uncertainty in DRL. We show that model uncertainty in\nDRL can be useful not only for action selection, but also action evaluation. We\nanalyze how the novel Weighted Deep Q-Learning algorithm reduces the bias\nw.r.t. relevant baselines and provide empirical evidence of its advantages on\nseveral representative benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 13:57:40 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 15:12:02 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Cini", "Andrea", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Alippi", "Cesare", ""]]}, {"id": "2003.09291", "submitter": "Rafael Sousa", "authors": "Rafael T. Sousa, Lucas A. Pereira, Anderson S. Soares", "title": "Improving Irregularly Sampled Time Series Learning with Dense\n  Descriptors of Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning with irregularly sampled time series have been a\nchallenge to Machine Learning methods due to the obstacle of dealing with\nirregular time intervals. Some papers introduced recently recurrent neural\nnetwork models that deals with irregularity, but most of them rely on complex\nmechanisms to achieve a better performance. This work propose a novel method to\nrepresent timestamps (hours or dates) as dense vectors using sinusoidal\nfunctions, called Time Embeddings. As a data input method it and can be applied\nto most machine learning models. The method was evaluated with two predictive\ntasks from MIMIC III, a dataset of irregularly sampled time series of\nelectronic health records. Our tests showed an improvement to LSTM-based and\nclassical machine learning models, specially with very irregular data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 14:21:25 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Sousa", "Rafael T.", ""], ["Pereira", "Lucas A.", ""], ["Soares", "Anderson S.", ""]]}, {"id": "2003.09293", "submitter": "Nikhil Varma Keetha", "authors": "Nikhil Varma Keetha, Samson Anosh Babu P, Chandra Sekhara Rao\n  Annavarapu", "title": "U-Det: A Modified U-Net architecture with bidirectional feature network\n  for lung nodule segmentation", "comments": "14 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early diagnosis and analysis of lung cancer involve a precise and efficient\nlung nodule segmentation in computed tomography (CT) images. However, the\nanonymous shapes, visual features, and surroundings of the nodule in the CT\nimage pose a challenging problem to the robust segmentation of the lung\nnodules. This article proposes U-Det, a resource-efficient model architecture,\nwhich is an end to end deep learning approach to solve the task at hand. It\nincorporates a Bi-FPN (bidirectional feature network) between the encoder and\ndecoder. Furthermore, it uses Mish activation function and class weights of\nmasks to enhance segmentation efficiency. The proposed model is extensively\ntrained and evaluated on the publicly available LUNA-16 dataset consisting of\n1186 lung nodules. The U-Det architecture outperforms the existing U-Net model\nwith the Dice similarity coefficient (DSC) of 82.82% and achieves results\ncomparable to human experts.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 14:25:22 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Keetha", "Nikhil Varma", ""], ["P", "Samson Anosh Babu", ""], ["Annavarapu", "Chandra Sekhara Rao", ""]]}, {"id": "2003.09301", "submitter": "Minh N. H. Nguyen Dr.", "authors": "Minh N. H. Nguyen, Shashi Raj Pandey, Kyi Thar, Nguyen H. Tran,\n  Mingzhe Chen, Walid Saad, and Choong Seon Hong", "title": "Distributed and Democratized Learning: Philosophy and Research\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the availability of huge amounts of data and processing abilities,\ncurrent artificial intelligence (AI) systems are effective in solving complex\ntasks. However, despite the success of AI in different areas, the problem of\ndesigning AI systems that can truly mimic human cognitive capabilities such as\nartificial general intelligence, remains largely open. Consequently, many\nemerging cross-device AI applications will require a transition from\ntraditional centralized learning systems towards large-scale distributed AI\nsystems that can collaboratively perform multiple complex learning tasks. In\nthis paper, we propose a novel design philosophy called democratized learning\n(Dem-AI) whose goal is to build large-scale distributed learning systems that\nrely on the self-organization of distributed learning agents that are\nwell-connected, but limited in learning capabilities. Correspondingly, inspired\nby the societal groups of humans, the specialized groups of learning agents in\nthe proposed Dem-AI system are self-organized in a hierarchical structure to\ncollectively perform learning tasks more efficiently. As such, the Dem-AI\nlearning system can evolve and regulate itself based on the underlying duality\nof two processes which we call specialized and generalized processes. In this\nregard, we present a reference design as a guideline to realize future Dem-AI\nsystems, inspired by various interdisciplinary fields. Accordingly, we\nintroduce four underlying mechanisms in the design such as plasticity-stability\ntransition mechanism, self-organizing hierarchical structuring, specialized\nlearning, and generalization. Finally, we establish possible extensions and new\nchallenges for the existing learning approaches to provide better scalable,\nflexible, and more powerful learning systems with the new setting of Dem-AI.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 08:45:10 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 10:14:41 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Nguyen", "Minh N. H.", ""], ["Pandey", "Shashi Raj", ""], ["Thar", "Kyi", ""], ["Tran", "Nguyen H.", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2003.09311", "submitter": "Anirban Chatterjee", "authors": "Anirban Chatterjee, Subhadip Paul, Uddipto Dutta, Smaranya Dey", "title": "Drift-Adjusted And Arbitrated Ensemble Framework For Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Forecasting is at the core of many practical applications such as\nsales forecasting for business, rainfall forecasting for agriculture and many\nothers. Though this problem has been extensively studied for years, it is still\nconsidered a challenging problem due to complex and evolving nature of time\nseries data. Typical methods proposed for time series forecasting modeled\nlinear or non-linear dependencies between data observations. However it is a\ngenerally accepted notion that no one method is universally effective for all\nkinds of time series data. Attempts have been made to use dynamic and weighted\ncombination of heterogeneous and independent forecasting models and it has been\nfound to be a promising direction to tackle this problem. This method is based\non the assumption that different forecasters have different specialization and\nvarying performance for different distribution of data and weights are\ndynamically assigned to multiple forecasters accordingly. However in many\npractical time series data-set, the distribution of data slowly evolves with\ntime. We propose to employ a re-weighting based method to adjust the assigned\nweights to various forecasters in order to account for such distribution-drift.\nAn exhaustive testing was performed against both real-world and synthesized\ntime-series. Experimental results show the competitiveness of the method in\ncomparison to state-of-the-art approaches for combining forecasters and\nhandling drift.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:21:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chatterjee", "Anirban", ""], ["Paul", "Subhadip", ""], ["Dutta", "Uddipto", ""], ["Dey", "Smaranya", ""]]}, {"id": "2003.09322", "submitter": "Iqbal H. Sarker", "authors": "Sohrab Hossain, Ahmed Abtahee, Imran Kashem, Mohammed Moshiul Hoque\n  and Iqbal H. Sarker", "title": "Crime Prediction Using Spatio-Temporal Data", "comments": "International Conference on Computing Science, Communication and\n  Security (COMS2), 2020. Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crime is a punishable offence that is harmful for an individual and his\nsociety. It is obvious to comprehend the patterns of criminal activity to\nprevent them. Research can help society to prevent and solve crime activates.\nStudy shows that only 10 percent offenders commits 50 percent of the total\noffences. The enforcement team can respond faster if they have early\ninformation and pre-knowledge about crime activities of the different points of\na city. In this paper, supervised learning technique is used to predict crimes\nwith better accuracy. The proposed system predicts crimes by analyzing data-set\nthat contains records of previously committed crimes and their patterns. The\nsystem stands on two main algorithms - i) decision tree, and ii) k-nearest\nneighbor. Random Forest algorithm and Adaboost are used to increase the\naccuracy of the prediction. Finally, oversampling is used for better accuracy.\nThe proposed system is feed with a criminal-activity data set of twelve years\nof San Francisco city.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 16:19:19 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Hossain", "Sohrab", ""], ["Abtahee", "Ahmed", ""], ["Kashem", "Imran", ""], ["Hoque", "Mohammed Moshiul", ""], ["Sarker", "Iqbal H.", ""]]}, {"id": "2003.09347", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, Supriyo Chakraborty, David Wagner", "title": "Improving Adversarial Robustness Through Progressive Hardening", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training (AT) has become a popular choice for training robust\nnetworks. However, it tends to sacrifice clean accuracy heavily in favor of\nrobustness, and with a large perturbation, it can cause models to learn a\ntrivial solution, always predicting the same class. To address the above\nconcerns, we propose Adversarial Training with Early Stopping (ATES), guided by\nprinciples from curriculum learning that emphasizes on starting \"easy\" and\ngradually ramping up on the \"difficulty\" of training. ATES is derived from our\nformulation for curriculum learning in the adversarial setting which introduces\nan additional curriculum constraint to the normal adversarial loss. To satisfy\nthis constraint, we apply early stopping on the adversarial example generation\nstep when a specified level of difficulty is reached. ATES stabilizes network\ntraining even for a large perturbation norm and allows the network to operate\nat a better clean accuracy versus robustness trade-off curve compared to AT.\nThis leads to a significant improvement in both clean accuracy and robustness\ncompared to AT, TRADES, and the other baselines.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 20:59:45 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 17:24:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Chakraborty", "Supriyo", ""], ["Wagner", "David", ""]]}, {"id": "2003.09372", "submitter": "Anshuman Suri", "authors": "Anshuman Suri and David Evans", "title": "One Neuron to Fool Them All", "comments": "Updated 'PGD' columns of Table 1: numbers reported earlier for this\n  column were (100 - accuracy) instead of attack success rates. Observations\n  and conclusions remain unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite vast research in adversarial examples, the root causes of model\nsusceptibility are not well understood. Instead of looking at attack-specific\nrobustness, we propose a notion that evaluates the sensitivity of individual\nneurons in terms of how robust the model's output is to direct perturbations of\nthat neuron's output. Analyzing models from this perspective reveals\ndistinctive characteristics of standard as well as adversarially-trained robust\nmodels, and leads to several curious results. In our experiments on CIFAR-10\nand ImageNet, we find that attacks using a loss function that targets just a\nsingle sensitive neuron find adversarial examples nearly as effectively as ones\nthat target the full model. We analyze the properties of these sensitive\nneurons to propose a regularization term that can help a model achieve\nrobustness to a variety of different perturbation constraints while maintaining\naccuracy on natural data distributions. Code for all our experiments is\navailable at https://github.com/iamgroot42/sauron .\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 16:49:38 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 04:35:30 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Suri", "Anshuman", ""], ["Evans", "David", ""]]}, {"id": "2003.09374", "submitter": "Jerrin Thomas Panachakel", "authors": "Jerrin Thomas Panachakel, A.G. Ramakrishnan, T.V. Ananthapadmanabha", "title": "A Novel Deep Learning Architecture for Decoding Imagined Speech from EEG", "comments": "Preprint of the paper presented at IEEE AIBEC 2019, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in the field of deep learning have not been fully\nutilised for decoding imagined speech primarily because of the unavailability\nof sufficient training samples to train a deep network. In this paper, we\npresent a novel architecture that employs deep neural network (DNN) for\nclassifying the words \"in\" and \"cooperate\" from the corresponding EEG signals\nin the ASU imagined speech dataset. Nine EEG channels, which best capture the\nunderlying cortical activity, are chosen using common spatial pattern (CSP) and\nare treated as independent data vectors. Discrete wavelet transform (DWT) is\nused for feature extraction. To the best of our knowledge, so far DNN has not\nbeen employed as a classifier in decoding imagined speech. Treating the\nselected EEG channels corresponding to each imagined word as independent data\nvectors helps in providing sufficient number of samples to train a DNN. For\neach test trial, the final class label is obtained by applying a majority\nvoting on the classification results of the individual channels considered in\nthe trial. We have achieved accuracies comparable to the state-of-the-art\nresults. The results can be further improved by using a higher-density EEG\nacquisition system in conjunction with other deep learning techniques such as\nlong short-term memory.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:57:40 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Panachakel", "Jerrin Thomas", ""], ["Ramakrishnan", "A. G.", ""], ["Ananthapadmanabha", "T. V.", ""]]}, {"id": "2003.09375", "submitter": "Sihua Wang", "authors": "Sihua Wang, Mingzhe Chen, Changchuan Yin, Walid Saad, Choong Seon\n  Hong, Shuguang Cui, H. Vincent Poor", "title": "Federated Learning for Task and Resource Allocation in Wireless High\n  Altitude Balloon Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of minimizing energy and time consumption for task\ncomputation and transmission is studied in a mobile edge computing\n(MEC)-enabled balloon network. In the considered network, each user needs to\nprocess a computational task in each time instant, where high-altitude balloons\n(HABs), acting as flying wireless base stations, can use their powerful\ncomputational abilities to process the tasks offloaded from their associated\nusers. Since the data size of each user's computational task varies over time,\nthe HABs must dynamically adjust the user association, service sequence, and\ntask partition scheme to meet the users' needs. This problem is posed as an\noptimization problem whose goal is to minimize the energy and time consumption\nfor task computing and transmission by adjusting the user association, service\nsequence, and task allocation scheme. To solve this problem, a support vector\nmachine (SVM)-based federated learning (FL) algorithm is proposed to determine\nthe user association proactively. The proposed SVM-based FL method enables each\nHAB to cooperatively build an SVM model that can determine all user\nassociations without any transmissions of either user historical associations\nor computational tasks to other HABs. Given the prediction of the optimal user\nassociation, the service sequence and task allocation of each user can be\noptimized so as to minimize the weighted sum of the energy and time\nconsumption. Simulations with real data of city cellular traffic from the\nOMNILab at Shanghai Jiao Tong University show that the proposed algorithm can\nreduce the weighted sum of the energy and time consumption of all users by up\nto 16.1% compared to a conventional centralized method.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 14:18:25 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Wang", "Sihua", ""], ["Chen", "Mingzhe", ""], ["Yin", "Changchuan", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""], ["Cui", "Shuguang", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2003.09379", "submitter": "Steven Kleinegesse", "authors": "Steven Kleinegesse, Christopher Drovandi, Michael U. Gutmann", "title": "Sequential Bayesian Experimental Design for Implicit Models via Mutual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian experimental design (BED) is a framework that uses statistical\nmodels and decision making under uncertainty to optimise the cost and\nperformance of a scientific experiment. Sequential BED, as opposed to static\nBED, considers the scenario where we can sequentially update our beliefs about\nthe model parameters through data gathered in the experiment. A class of models\nof particular interest for the natural and medical sciences are implicit\nmodels, where the data generating distribution is intractable, but sampling\nfrom it is possible. Even though there has been a lot of work on static BED for\nimplicit models in the past few years, the notoriously difficult problem of\nsequential BED for implicit models has barely been touched upon. We address\nthis gap in the literature by devising a novel sequential design framework for\nparameter estimation that uses the Mutual Information (MI) between model\nparameters and simulated data as a utility function to find optimal\nexperimental designs, which has not been done before for implicit models. Our\napproach uses likelihood-free inference by ratio estimation to simultaneously\nestimate posterior distributions and the MI. During the sequential BED\nprocedure we utilise Bayesian optimisation to help us optimise the MI utility.\nWe find that our framework is efficient for the various implicit models tested,\nyielding accurate parameter estimates after only a few iterations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 16:52:10 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Kleinegesse", "Steven", ""], ["Drovandi", "Christopher", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "2003.09398", "submitter": "Gabriel Kalweit", "authors": "Gabriel Kalweit and Maria Huegle and Moritz Werling and Joschka\n  Boedecker", "title": "Deep Constrained Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world applications, reinforcement learning agents have to\noptimize multiple objectives while following certain rules or satisfying a list\nof constraints. Classical methods based on reward shaping, i.e. a weighted\ncombination of different objectives in the reward signal, or Lagrangian\nmethods, including constraints in the loss function, have no guarantees that\nthe agent satisfies the constraints at all points in time and can lead to\nundesired behavior. When a discrete policy is extracted from an action-value\nfunction, safe actions can be ensured by restricting the action space at\nmaximization, but can lead to sub-optimal solutions among feasible\nalternatives. In this work, we propose Constrained Q-learning, a novel\noff-policy reinforcement learning framework restricting the action space\ndirectly in the Q-update to learn the optimal Q-function for the induced\nconstrained MDP and the corresponding safe policy. In addition to single-step\nconstraints referring only to the next action, we introduce a formulation for\napproximate multi-step constraints under the current target policy based on\ntruncated value-functions. We analyze the advantages of Constrained Q-learning\nin the tabular case and compare Constrained DQN to reward shaping and\nLagrangian methods in the application of high-level decision making in\nautonomous driving, considering constraints for safety, keeping right and\ncomfort. We train our agent in the open-source simulator SUMO and on the real\nHighD data set.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 17:26:03 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 15:22:47 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kalweit", "Gabriel", ""], ["Huegle", "Maria", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "2003.09424", "submitter": "Mucahid Barstugan Asst. Prof. Dr", "authors": "Mucahid Barstugan, Umut Ozkaya, Saban Ozturk", "title": "Coronavirus (COVID-19) Classification using CT Images by Machine\n  Learning Methods", "comments": "The paper has 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents early phase detection of Coronavirus (COVID-19), which is\nnamed by World Health Organization (WHO), by machine learning methods. The\ndetection process was implemented on abdominal Computed Tomography (CT) images.\nThe expert radiologists detected from CT images that COVID-19 shows different\nbehaviours from other viral pneumonia. Therefore, the clinical experts specify\nthat COV\\.ID-19 virus needs to be diagnosed in early phase. For detection of\nthe COVID-19, four different datasets were formed by taking patches sized as\n16x16, 32x32, 48x48, 64x64 from 150 CT images. The feature extraction process\nwas applied to patches to increase the classification performance. Grey Level\nCo-occurrence Matrix (GLCM), Local Directional Pattern (LDP), Grey Level Run\nLength Matrix (GLRLM), Grey-Level Size Zone Matrix (GLSZM), and Discrete\nWavelet Transform (DWT) algorithms were used as feature extraction methods.\nSupport Vector Machines (SVM) classified the extracted features. 2-fold, 5-fold\nand 10-fold cross-validations were implemented during the classification\nprocess. Sensitivity, specificity, accuracy, precision, and F-score metrics\nwere used to evaluate the classification performance. The best classification\naccuracy was obtained as 99.68% with 10-fold cross-validation and GLSZM feature\nextraction method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 12:48:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Barstugan", "Mucahid", ""], ["Ozkaya", "Umut", ""], ["Ozturk", "Saban", ""]]}, {"id": "2003.09436", "submitter": "Anh Tran", "authors": "Anh Tran, Mike Eldred, Tim Wildey, Scott McCann, Jing Sun, Robert J.\n  Visintainer", "title": "aphBO-2GP-3B: A budgeted asynchronous parallel multi-acquisition\n  functions for constrained Bayesian optimization on high-performing computing\n  architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-fidelity complex engineering simulations are highly predictive, but also\ncomputationally expensive and often require substantial computational efforts.\nThe mitigation of computational burden is usually enabled through parallelism\nin high-performance cluster (HPC) architecture. In this paper, an asynchronous\nconstrained batch-parallel Bayesian optimization method is proposed to\nefficiently solve the computationally-expensive simulation-based optimization\nproblems on the HPC platform, with a budgeted computational resource, where the\nmaximum number of simulations is a constant. The advantages of this method are\nthree-fold. First, the efficiency of the Bayesian optimization is improved,\nwhere multiple input locations are evaluated massively parallel in an\nasynchronous manner to accelerate the optimization convergence with respect to\nphysical runtime. This efficiency feature is further improved so that when each\nof the inputs is finished, another input is queried without waiting for the\nwhole batch to complete. Second, the method can handle both known and unknown\nconstraints. Third, the proposed method considers several acquisition functions\nat the same time and sample based on an evolving probability mass distribution\nfunction using a modified GP-Hedge scheme, where parameters are corresponding\nto the performance of each acquisition function. The proposed framework is\ntermed aphBO-2GP-3B, which corresponds to asynchronous parallel hedge Bayesian\noptimization with two Gaussian processes and three batches. The aphBO-2GP-3B\nframework is demonstrated using two high-fidelity expensive industrial\napplications, where the first one is based on finite element analysis (FEA) and\nthe second one is based on computational fluid dynamics (CFD) simulations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:02:27 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 22:08:53 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Tran", "Anh", ""], ["Eldred", "Mike", ""], ["Wildey", "Tim", ""], ["McCann", "Scott", ""], ["Sun", "Jing", ""], ["Visintainer", "Robert J.", ""]]}, {"id": "2003.09443", "submitter": "Tristan Karch", "authors": "Tristan Karch, C\\'edric Colas, Laetitia Teodorescu, Cl\\'ement\n  Moulin-Frier and Pierre-Yves Oudeyer", "title": "Deep Sets for Generalization in RL", "comments": "15 pages, 10 figures, published as a workshop Paper at ICLR: Beyond\n  tabula rasa in RL (BeTR-RL). arXiv admin note: substantial text overlap with\n  arXiv:2002.09253", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the idea of encoding object-centered representations\nin the design of the reward function and policy architectures of a\nlanguage-guided reinforcement learning agent. This is done using a combination\nof object-wise permutation invariant networks inspired from Deep Sets and\ngated-attention mechanisms. In a 2D procedurally-generated world where agents\ntargeting goals in natural language navigate and interact with objects, we show\nthat these architectures demonstrate strong generalization capacities to\nout-of-distribution goals. We study the generalization to varying numbers of\nobjects at test time and further extend the object-centered architectures to\ngoals involving relational reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:22:40 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Karch", "Tristan", ""], ["Colas", "C\u00e9dric", ""], ["Teodorescu", "Laetitia", ""], ["Moulin-Frier", "Cl\u00e9ment", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2003.09451", "submitter": "Xiaohan Fu", "authors": "Xiaohan Fu, Lo-Bin Chang, Dongbin Xiu", "title": "Learning reduced systems via deep neural networks with memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general numerical approach for constructing governing equations\nfor unknown dynamical systems when only data on a subset of the state variables\nare available. The unknown equations for these observed variables are thus a\nreduced system of the complete set of state variables. Reduced systems possess\nmemory integrals, based on the well known Mori-Zwanzig (MZ) formulism. Our\nnumerical strategy to recover the reduced system starts by formulating a\ndiscrete approximation of the memory integral in the MZ formulation. The\nresulting unknown approximate MZ equations are of finite dimensional, in the\nsense that a finite number of past history data are involved. We then present a\ndeep neural network structure that directly incorporates the history terms to\nproduce memory in the network. The approach is suitable for any practical\nsystems with finite memory length. We then use a set of numerical examples to\ndemonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:35:32 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 02:00:26 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Fu", "Xiaohan", ""], ["Chang", "Lo-Bin", ""], ["Xiu", "Dongbin", ""]]}, {"id": "2003.09454", "submitter": "Paulo Hubert", "authors": "Paulo Hubert", "title": "Probabilistic learning of boolean functions applied to the binary\n  classification problem with categorical covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we cast the problem of binary classification in terms of\nestimating a partition on Bernoulli data. When the explanatory variables are\nall categorical, the problem can be modelled using the language of boolean\nfunctions. We offer a probabilistic analysis of the problem, and propose two\nalgorithms for learning boolean functions from binary data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:38:49 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Hubert", "Paulo", ""]]}, {"id": "2003.09461", "submitter": "Alexander Meinke", "authors": "Maximilian Augustin, Alexander Meinke, Matthias Hein", "title": "Adversarial Robustness on In- and Out-Distribution Improves\n  Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have led to major improvements in image classification but\nsuffer from being non-robust to adversarial changes, unreliable uncertainty\nestimates on out-distribution samples and their inscrutable black-box\ndecisions. In this work we propose RATIO, a training procedure for Robustness\nvia Adversarial Training on In- and Out-distribution, which leads to robust\nmodels with reliable and robust confidence estimates on the out-distribution.\nRATIO has similar generative properties to adversarial training so that visual\ncounterfactuals produce class specific features. While adversarial training\ncomes at the price of lower clean accuracy, RATIO achieves state-of-the-art\n$l_2$-adversarial robustness on CIFAR10 and maintains better clean accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 18:57:52 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 17:36:00 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Augustin", "Maximilian", ""], ["Meinke", "Alexander", ""], ["Hein", "Matthias", ""]]}, {"id": "2003.09465", "submitter": "Diana Cai", "authors": "Diana Cai, Rishit Sheth, Lester Mackey, Nicolo Fusi", "title": "Weighted Meta-Learning", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning leverages related source tasks to learn an initialization that\ncan be quickly fine-tuned to a target task with limited labeled examples.\nHowever, many popular meta-learning algorithms, such as model-agnostic\nmeta-learning (MAML), only assume access to the target samples for fine-tuning.\nIn this work, we provide a general framework for meta-learning based on\nweighting the loss of different source tasks, where the weights are allowed to\ndepend on the target samples. In this general setting, we provide upper bounds\non the distance of the weighted empirical risk of the source tasks and expected\ntarget risk in terms of an integral probability metric (IPM) and Rademacher\ncomplexity, which apply to a number of meta-learning settings including MAML\nand a weighted MAML variant. We then develop a learning algorithm based on\nminimizing the error bound with respect to an empirical IPM, including a\nweighted MAML algorithm, $\\alpha$-MAML. Finally, we demonstrate empirically on\nseveral regression problems that our weighted meta-learning algorithm is able\nto find better initializations than uniformly-weighted meta-learning\nalgorithms, such as MAML.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 19:00:42 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Cai", "Diana", ""], ["Sheth", "Rishit", ""], ["Mackey", "Lester", ""], ["Fusi", "Nicolo", ""]]}, {"id": "2003.09466", "submitter": "Rachel Cummings", "authors": "Qiaomei Li and Rachel Cummings and Yonatan Mintz", "title": "Optimal Local Explainer Aggregation for Interpretable Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for decision makers when incorporating black box machine\nlearned models into practice is being able to understand the predictions\nprovided by these models. One proposed set of methods is training surrogate\nexplainer models which approximate the more complex model. Explainer methods\nare generally classified as either local or global, depending on what portion\nof the data space they are purported to explain. The improved coverage of\nglobal explainers usually comes at the expense of explainer fidelity. One way\nof trading off the advantages of both approaches is to aggregate several local\nexplainers into a single explainer model with improved coverage. However, the\nproblem of aggregating these local explainers is computationally challenging,\nand existing methods only use heuristics to form these aggregations.\n  In this paper we propose a local explainer aggregation method which selects\nlocal explainers using non-convex optimization. In contrast to other heuristic\nmethods, we use an integer optimization framework to combine local explainers\ninto a near-global aggregate explainer. Our framework allows a decision-maker\nto directly tradeoff coverage and fidelity of the resulting aggregation through\nthe parameters of the optimization problem. We also propose a novel local\nexplainer algorithm based on information filtering. We evaluate our algorithmic\nframework on two healthcare datasets---the Parkinson's Progression Marker\nInitiative (PPMI) data set and a geriatric mobility dataset---which is\nmotivated by the anticipated need for explainable precision medicine. Our\nmethod outperforms existing local explainer aggregation methods in terms of\nboth fidelity and coverage of classification and improves on fidelity over\nexisting global explainer methods, particularly in multi-class settings where\nstate-of-the-art methods achieve 70% and ours achieves 90%.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 19:02:11 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 21:18:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Li", "Qiaomei", ""], ["Cummings", "Rachel", ""], ["Mintz", "Yonatan", ""]]}, {"id": "2003.09488", "submitter": "Liyuan Zheng", "authors": "Liyuan Zheng, Yuanyuan Shi, Lillian J. Ratliff, Baosen Zhang", "title": "Safe Reinforcement Learning of Control-Affine Systems with Vertex\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on finding reinforcement learning policies for control\nsystems with hard state and action constraints. Despite its success in many\ndomains, reinforcement learning is challenging to apply to problems with hard\nconstraints, especially if both the state variables and actions are\nconstrained. Previous works seeking to ensure constraint satisfaction, or\nsafety, have focused on adding a projection step to a learned policy. Yet, this\napproach requires solving an optimization problem at every policy execution\nstep, which can lead to significant computational costs.\n  To tackle this problem, this paper proposes a new approach, termed Vertex\nNetworks (VNs), with guarantees on safety during exploration and on learned\ncontrol policies by incorporating the safety constraints into the policy\nnetwork architecture. Leveraging the geometric property that all points within\na convex set can be represented as the convex combination of its vertices, the\nproposed algorithm first learns the convex combination weights and then uses\nthese weights along with the pre-calculated vertices to output an action. The\noutput action is guaranteed to be safe by construction. Numerical examples\nillustrate that the proposed VN algorithm outperforms vanilla reinforcement\nlearning in a variety of benchmark control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 20:32:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Zheng", "Liyuan", ""], ["Shi", "Yuanyuan", ""], ["Ratliff", "Lillian J.", ""], ["Zhang", "Baosen", ""]]}, {"id": "2003.09503", "submitter": "Zilong Zhao", "authors": "Zilong Zhao, Sophie Cerf, Bogdan Robu, Nicolas Marchand", "title": "Event-Based Control for Online Training of Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2020.2981984", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN) has become the most used method for image\nclassification tasks. During its training the learning rate and the gradient\nare two key factors to tune for influencing the convergence speed of the model.\nUsual learning rate strategies are time-based i.e. monotonous decay over time.\nRecent state-of-the-art techniques focus on adaptive gradient algorithms i.e.\nAdam and its versions. In this paper we consider an online learning scenario\nand we propose two Event-Based control loops to adjust the learning rate of a\nclassical algorithm E (Exponential)/PD (Proportional Derivative)-Control. The\nfirst Event-Based control loop will be implemented to prevent sudden drop of\nthe learning rate when the model is approaching the optimum. The second\nEvent-Based control loop will decide, based on the learning speed, when to\nswitch to the next data batch. Experimental evaluationis provided using two\nstate-of-the-art machine learning image datasets (CIFAR-10 and CIFAR-100).\nResults show the Event-Based E/PD is better than the original algorithm (higher\nfinal accuracy, lower final loss value), and the Double-Event-BasedE/PD can\naccelerate the training process, save up to 67% training time compared to\nstate-of-the-art algorithms and even result in better performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:29:03 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Zhao", "Zilong", ""], ["Cerf", "Sophie", ""], ["Robu", "Bogdan", ""], ["Marchand", "Nicolas", ""]]}, {"id": "2003.09504", "submitter": "Fahad Sohrab", "authors": "Fahad Sohrab, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj", "title": "Ellipsoidal Subspace Support Vector Data Description", "comments": null, "journal-ref": "IEEE Access, vol. 8, pp. 122013-122025, 2020", "doi": "10.1109/ACCESS.2020.3007123", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for transforming data into a\nlow-dimensional space optimized for one-class classification. The proposed\nmethod iteratively transforms data into a new subspace optimized for\nellipsoidal encapsulation of target class data. We provide both linear and\nnon-linear formulations for the proposed method. The method takes into account\nthe covariance of the data in the subspace; hence, it yields a more generalized\nsolution as compared to Subspace Support Vector Data Description for a\nhypersphere. We propose different regularization terms expressing the class\nvariance in the projected space. We compare the results with classic and\nrecently proposed one-class classification methods and achieve better results\nin the majority of cases. The proposed method is also noticed to converge much\nfaster than recently proposed Subspace Support Vector Data Description.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:31:03 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sohrab", "Fahad", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2003.09521", "submitter": "Kristian Snyder", "authors": "Kristian Snyder (1), Brennan Thomas (1), Ming-Lun Lu (2), Rashmi Jha\n  (1), Menekse S. Barim (2), Marie Hayden (2), Dwight Werren (2) ((1)\n  University of Cincinnati, (2) National Institute for Occupational Safety and\n  Health)", "title": "A deep learning approach for lower back-pain risk prediction during\n  manual lifting", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0247162", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Occupationally-induced back pain is a leading cause of reduced productivity\nin industry. Detecting when a worker is lifting incorrectly and at increased\nrisk of back injury presents significant possible benefits. These include\nincreased quality of life for the worker due to lower rates of back injury and\nfewer workers' compensation claims and missed time for the employer. However,\nrecognizing lifting risk provides a challenge due to typically small datasets\nand subtle underlying features in accelerometer and gyroscope data. A novel\nmethod to classify a lifting dataset using a 2D convolutional neural network\n(CNN) and no manual feature extraction is proposed in this paper; the dataset\nconsisted of 10 subjects lifting at various relative distances from the body\nwith 720 total trials. The proposed deep CNN displayed greater accuracy (90.6%)\ncompared to an alternative CNN and multilayer perceptron (MLP). A deep CNN\ncould be adapted to classify many other activities that traditionally pose\ngreater challenges in industrial environments due to their size and complexity.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 22:36:49 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Snyder", "Kristian", ""], ["Thomas", "Brennan", ""], ["Lu", "Ming-Lun", ""], ["Jha", "Rashmi", ""], ["Barim", "Menekse S.", ""], ["Hayden", "Marie", ""], ["Werren", "Dwight", ""]]}, {"id": "2003.09527", "submitter": "Zhongxia Zhang", "authors": "Zhongxia Zhang, Meng Wu", "title": "Predicting Real-Time Locational Marginal Prices: A GAN-Based Video\n  Prediction Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an unsupervised data-driven approach to predict\nreal-time locational marginal prices (RTLMPs). The proposed approach is built\nupon a general data structure for organizing system-wide heterogeneous market\ndata streams into the format of market data images and videos. Leveraging this\ngeneral data structure, the system-wide RTLMP prediction problem is formulated\nas a video prediction problem. A video prediction model based on generative\nadversarial networks (GAN) is proposed to learn the spatio-temporal\ncorrelations among historical RTLMPs and predict system-wide RTLMPs for the\nnext hour. An autoregressive moving average (ARMA) calibration method is\nadopted to improve the prediction accuracy. The proposed RTLMP prediction\nmethod takes public market data as inputs, without requiring any confidential\ninformation on system topology, model parameters, or market operating details.\nCase studies using public market data from ISO New England (ISO-NE) and\nSouthwest Power Pool (SPP) demonstrate that the proposed method is able to\nlearn spatio-temporal correlations among RTLMPs and perform accurate RTLMP\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 23:00:58 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Zhang", "Zhongxia", ""], ["Wu", "Meng", ""]]}, {"id": "2003.09534", "submitter": "Yan  Li", "authors": "Qianli Shen, Yan Li, Haoming Jiang, Zhaoran Wang, Tuo Zhao", "title": "Deep Reinforcement Learning with Robust and Smooth Policy", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved great empirical successes in\nvarious domains. However, the large search space of neural networks requires a\nlarge amount of data, which makes the current RL algorithms not sample\nefficient. Motivated by the fact that many environments with continuous state\nspace have smooth transitions, we propose to learn a smooth policy that behaves\nsmoothly with respect to states. We develop a new framework -- \\textbf{S}mooth\n\\textbf{R}egularized \\textbf{R}einforcement \\textbf{L}earning\n($\\textbf{SR}^2\\textbf{L}$), where the policy is trained with\nsmoothness-inducing regularization. Such regularization effectively constrains\nthe search space, and enforces smoothness in the learned policy. Moreover, our\nproposed framework can also improve the robustness of policy against\nmeasurement error in the state space, and can be naturally extended to\ndistribubutionally robust setting. We apply the proposed framework to both\non-policy (TRPO) and off-policy algorithm (DDPG). Through extensive\nexperiments, we demonstrate that our method achieves improved sample efficiency\nand robustness.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 00:10:29 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 02:11:26 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 23:30:52 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 02:20:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Shen", "Qianli", ""], ["Li", "Yan", ""], ["Jiang", "Haoming", ""], ["Wang", "Zhaoran", ""], ["Zhao", "Tuo", ""]]}, {"id": "2003.09553", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, Franziska Meier, Roberto Calandra, Trevor Darrell,\n  Marcus Rohrbach", "title": "Adversarial Continual Learning", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to learn new tasks without forgetting previously\nlearned ones. We hypothesize that representations learned to solve each task in\na sequence have a shared structure while containing some task-specific\nproperties. We show that shared features are significantly less prone to\nforgetting and propose a novel hybrid continual learning framework that learns\na disjoint representation for task-invariant and task-specific features\nrequired to solve a sequence of tasks. Our model combines architecture growth\nto prevent forgetting of task-specific skills and an experience replay approach\nto preserve shared skills. We demonstrate our hybrid approach is effective in\navoiding forgetting and show it is superior to both architecture-based and\nmemory-based approaches on class incrementally learning of a single dataset as\nwell as a sequence of multiple datasets in image classification. Our code is\navailable at\n\\url{https://github.com/facebookresearch/Adversarial-Continual-Learning}.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 02:08:17 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 15:42:20 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Meier", "Franziska", ""], ["Calandra", "Roberto", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "2003.09554", "submitter": "Evangelia Gergatsouli", "authors": "Evangelia Gergatsouli, Brendan Lucier, Christos Tzamos", "title": "Black-box Methods for Restoring Monotonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical applications, heuristic or approximation algorithms are\nused to efficiently solve the task at hand. However their solutions frequently\ndo not satisfy natural monotonicity properties of optimal solutions. In this\nwork we develop algorithms that are able to restore monotonicity in the\nparameters of interest. Specifically, given oracle access to a (possibly\nnon-monotone) multi-dimensional real-valued function $f$, we provide an\nalgorithm that restores monotonicity while degrading the expected value of the\nfunction by at most $\\varepsilon$. The number of queries required is at most\nlogarithmic in $1/\\varepsilon$ and exponential in the number of parameters. We\nalso give a lower bound showing that this exponential dependence is necessary.\nFinally, we obtain improved query complexity bounds for restoring the weaker\nproperty of $k$-marginal monotonicity. Under this property, every\n$k$-dimensional projection of the function $f$ is required to be monotone. The\nquery complexity we obtain only scales exponentially with $k$.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 02:19:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Gergatsouli", "Evangelia", ""], ["Lucier", "Brendan", ""], ["Tzamos", "Christos", ""]]}, {"id": "2003.09596", "submitter": "Rahul Singh", "authors": "Rahul Singh and P. R. Kumar", "title": "Learning in Networked Control Systems", "comments": "Submitted to CDC and LCSS\n  (http://ieee-cssletters.dei.unipd.it/index.php)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.DS math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design adaptive controller (learning rule) for a networked control system\n(NCS) in which data packets containing control information are transmitted\nacross a lossy wireless channel. We propose Upper Confidence Bounds for\nNetworked Control Systems (UCB-NCS), a learning rule that maintains confidence\nintervals for the estimates of plant parameters $(A_{(\\star)},B_{(\\star)})$,\nand channel reliability $p_{(\\star)}$, and utilizes the principle of optimism\nin the face of uncertainty while making control decisions. We provide\nnon-asymptotic performance guarantees for UCB-NCS by analyzing its \"regret\",\ni.e., performance gap from the scenario when\n$(A_{(\\star)},B_{(\\star)},p_{(\\star)})$ are known to the controller. We show\nthat with a high probability the regret can be upper-bounded as\n$\\tilde{O}\\left(C\\sqrt{T}\\right)$\\footnote{Here $\\tilde{O}$ hides logarithmic\nfactors.}, where $T$ is the operating time horizon of the system, and $C$ is a\nproblem dependent constant.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 07:16:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Singh", "Rahul", ""], ["Kumar", "P. R.", ""]]}, {"id": "2003.09615", "submitter": "Dingcheng Yang", "authors": "Dingcheng Yang, Wenjian Yu, Ao Zhou, Haoyuan Mu, Gary Yao, Xiaoyi Wang", "title": "DP-Net: Dynamic Programming Guided Deep Neural Network Compression", "comments": "7pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an effective scheme (called DP-Net) for compressing\nthe deep neural networks (DNNs). It includes a novel dynamic programming (DP)\nbased algorithm to obtain the optimal solution of weight quantization and an\noptimization process to train a clustering-friendly DNN. Experiments showed\nthat the DP-Net allows larger compression than the state-of-the-art\ncounterparts while preserving accuracy. The largest 77X compression ratio on\nWide ResNet is achieved by combining DP-Net with other compression techniques.\nFurthermore, the DP-Net is extended for compressing a robust DNN model with\nnegligible accuracy loss. At last, a custom accelerator is designed on FPGA to\nspeed up the inference computation with DP-Net.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 09:42:48 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Yang", "Dingcheng", ""], ["Yu", "Wenjian", ""], ["Zhou", "Ao", ""], ["Mu", "Haoyuan", ""], ["Yao", "Gary", ""], ["Wang", "Xiaoyi", ""]]}, {"id": "2003.09638", "submitter": "Chuan Chen", "authors": "Dalong Yang, Chuan Chen, Youhao Zheng, Zibin Zheng, Shih-wei Liao", "title": "An Uncoupled Training Architecture for Large Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) has been widely used in graph learning\ntasks. However, GCN-based models (GCNs) is an inherently coupled training\nframework repetitively conducting the complex neighboring aggregation, which\nleads to the limitation of flexibility in processing large-scale graph. With\nthe depth of layers increases, the computational and memory cost of GCNs grow\nexplosively due to the recursive neighborhood expansion. To tackle these\nissues, we present Node2Grids, a flexible uncoupled training framework that\nleverages the independent mapped data for obtaining the embedding. Instead of\ndirectly processing the coupled nodes as GCNs, Node2Grids supports a more\nefficacious method in practice, mapping the coupled graph data into the\nindependent grid-like data which can be fed into the efficient Convolutional\nNeural Network (CNN). This simple but valid strategy significantly saves memory\nand computational resource while achieving comparable results with the leading\nGCN-based models. Specifically, by ranking each node's influence through\ndegree, Node2Grids selects the most influential first-order as well as\nsecond-order neighbors with central node fusion information to construct the\ngrid-like data. For further improving the efficiency of downstream tasks, a\nsimple CNN-based neural network is employed to capture the significant\ninformation from the mapped grid-like data. Moreover, the grid-level attention\nmechanism is implemented, which enables implicitly specifying the different\nweights for neighboring nodes with different influences. In addition to the\ntypical transductive and inductive learning tasks, we also verify our framework\non million-scale graphs to demonstrate the superiority of the proposed\nNode2Grids model against the state-of-the-art GCN-based approaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 11:49:16 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 03:32:29 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Yang", "Dalong", ""], ["Chen", "Chuan", ""], ["Zheng", "Youhao", ""], ["Zheng", "Zibin", ""], ["Liao", "Shih-wei", ""]]}, {"id": "2003.09643", "submitter": "Eduardo C\\'esar Garrido-Merch\\'an", "authors": "Eduardo C. Garrido Merch\\'an, Luis C. Jariego P\\'erez", "title": "Towards Automatic Bayesian Optimization: A first step involving\n  acquisition functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization is the state of the art technique for the optimization\nof black boxes, i.e., functions where we do not have access to their analytical\nexpression nor its gradients, they are expensive to evaluate and its evaluation\nis noisy. The most popular application of bayesian optimization is the\nautomatic hyperparameter tuning of machine learning algorithms, where we obtain\nthe best configuration of machine learning algorithms by optimizing the\nestimation of the generalization error of these algorithms. Despite being\napplied with success, bayesian optimization methodologies also have\nhyperparameters that need to be configured such as the probabilistic surrogate\nmodel or the acquisition function used. A bad decision over the configuration\nof these hyperparameters implies obtaining bad quality results. Typically,\nthese hyperparameters are tuned by making assumptions of the objective function\nthat we want to evaluate but there are scenarios where we do not have any prior\ninformation about the objective function. In this paper, we propose a first\nattempt over automatic bayesian optimization by exploring several heuristics\nthat automatically tune the acquisition function of bayesian optimization. We\nillustrate the effectiveness of these heurisitcs in a set of benchmark problems\nand a hyperparameter tuning problem of a machine learning algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 12:22:45 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:48:37 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Merch\u00e1n", "Eduardo C. Garrido", ""], ["P\u00e9rez", "Luis C. Jariego", ""]]}, {"id": "2003.09647", "submitter": "Adam Peace", "authors": "Adam Peace", "title": "Applications of Deep Learning for Ill-Posed Inverse Problems Within\n  Optical Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Increasingly in medical imaging has emerged an issue surrounding the\nreconstruction of noisy images from raw measurement data. Where the forward\nproblem is the generation of raw measurement data from a ground truth image,\nthe inverse problem is the reconstruction of those images from the measurement\ndata. In most cases with medical imaging, classical inverse Radon transforms,\nsuch as an inverse Fourier transform for MRI, work well for recovering clean\nimages from the measured data. Unfortunately in the case of X-Ray CT, where\nundersampled data is very common, more than this is needed to resolve faithful\nand usable images. In this paper, we explore the history of classical methods\nfor solving the inverse problem for X-Ray CT, followed by an analysis of the\nstate of the art methods that utilize supervised deep learning. Finally, we\nwill provide some possible avenues for research in the future.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 12:54:45 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Peace", "Adam", ""]]}, {"id": "2003.09660", "submitter": "Zitao Liu", "authors": "Yang Hao, Wenbiao Ding, Zitao Liu", "title": "NeuCrowd: Neural Sampling Network for Representation Learning with\n  Crowdsourced Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning approaches require a massive amount of discriminative\ntraining data, which is unavailable in many scenarios, such as healthcare,\nsmart city, education, etc. In practice, people refer to crowdsourcing to get\nannotated labels. However, due to issues like data privacy, budget limitation,\nshortage of domain-specific annotators, the number of crowdsourced labels is\nstill very limited. Moreover, because of annotators' diverse expertises,\ncrowdsourced labels are often inconsistent. Thus, directly applying existing\nsupervised representation learning (SRL) algorithms may easily get the\noverfitting problem and yield suboptimal solutions. In this paper, we propose\n\\emph{NeuCrowd}, a unified framework for SRL from crowdsourced labels. The\nproposed framework (1) creates a sufficient number of high-quality\n\\emph{n}-tuplet training samples by utilizing safety-aware sampling and robust\nanchor generation; and (2) automatically learns a neural sampling network that\nadaptively learns to select effective samples for SRL networks. The proposed\nframework is evaluated on both one synthetic and three real-world data sets.\nThe results show that our approach outperforms a wide range of state-of-the-art\nbaselines in terms of prediction accuracy and AUC. To encourage the\nreproducible results, we make our code publicly available at\n\\url{https://github.com/crowd-data-mining/NeuCrowd}.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:38:18 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:46:33 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 02:02:24 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Hao", "Yang", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2003.09671", "submitter": "Bernhard C. Geiger", "authors": "Bernhard C. Geiger", "title": "On Information Plane Analyses of Neural Network Classifiers -- A Review", "comments": "12 pages, 3 figures; accepted for publication in IEEE Transactions on\n  Neural Networks and Learning Systems. (c) 2021 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the current literature concerned with information plane analyses of\nneural network classifiers. While the underlying information bottleneck theory\nand the claim that information-theoretic compression is causally linked to\ngeneralization are plausible, empirical evidence was found to be both\nsupporting and conflicting. We review this evidence together with a detailed\nanalysis of how the respective information quantities were estimated. Our\nsurvey suggests that compression visualized in information planes is not\nnecessarily information-theoretic, but is rather often compatible with\ngeometric compression of the latent representations. This insight gives the\ninformation plane a renewed justification.\n  Aside from this, we shed light on the problem of estimating mutual\ninformation in deterministic neural networks and its consequences.\nSpecifically, we argue that even in feed-forward neural networks the data\nprocessing inequality need not hold for estimates of mutual information.\nSimilarly, while a fitting phase, in which the mutual information between the\nlatent representation and the target increases, is necessary (but not\nsufficient) for good classification performance, depending on the specifics of\nmutual information estimation such a fitting phase need not be visible in the\ninformation plane.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 14:43:45 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 15:19:33 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 15:06:30 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Geiger", "Bernhard C.", ""]]}, {"id": "2003.09676", "submitter": "Duo Wang", "authors": "Yiren Zhao, Duo Wang, Xitong Gao, Robert Mullins, Pietro Lio, Mateja\n  Jamnik", "title": "Probabilistic Dual Network Architecture Search on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first differentiable Network Architecture Search (NAS) for\nGraph Neural Networks (GNNs). GNNs show promising performance on a wide range\nof tasks, but require a large amount of architecture engineering. First, graphs\nare inherently a non-Euclidean and sophisticated data structure, leading to\npoor adaptivity of GNN architectures across different datasets. Second, a\ntypical graph block contains numerous different components, such as aggregation\nand attention, generating a large combinatorial search space. To counter these\nproblems, we propose a Probabilistic Dual Network Architecture Search (PDNAS)\nframework for GNNs. PDNAS not only optimises the operations within a single\ngraph block (micro-architecture), but also considers how these blocks should be\nconnected to each other (macro-architecture). The dual architecture (micro- and\nmarco-architectures) optimisation allows PDNAS to find deeper GNNs on diverse\ndatasets with better performance compared to other graph NAS methods. Moreover,\nwe use a fully gradient-based search approach to update architectural\nparameters, making it the first differentiable graph NAS method. PDNAS\noutperforms existing hand-designed GNNs and NAS results, for example, on the\nPPI dataset, PDNAS beats its best competitors by 1.67 and 0.17 in F1 scores.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 15:06:47 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Zhao", "Yiren", ""], ["Wang", "Duo", ""], ["Gao", "Xitong", ""], ["Mullins", "Robert", ""], ["Lio", "Pietro", ""], ["Jamnik", "Mateja", ""]]}, {"id": "2003.09708", "submitter": "Dong Liu", "authors": "Dong Liu, Jianyu Zhao, Chenyang Yang, Lajos Hanzo", "title": "Accelerating Deep Reinforcement Learning With the Aid of Partial Model:\n  Energy-Efficient Predictive Video Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive power allocation is conceived for energy-efficient video streaming\nover mobile networks using deep reinforcement learning. The goal is to minimize\nthe accumulated energy consumption of each base station over a complete video\nstreaming session under the constraint that avoids video playback\ninterruptions. To handle the continuous state and action spaces, we resort to\ndeep deterministic policy gradient (DDPG) algorithm for solving the formulated\nproblem. In contrast to previous predictive power allocation policies that\nfirst predict future information with historical data and then optimize the\npower allocation based on the predicted information, the proposed policy\noperates in an on-line and end-to-end manner. By judiciously designing the\naction and state that only depend on slowly-varying average channel gains, we\nreduce the signaling overhead between the edge server and the base stations,\nand make it easier to learn a good policy. To further avoid playback\ninterruption throughout the learning process and improve the convergence speed,\nwe exploit the partially known model of the system dynamics by integrating the\nconcepts of safety layer, post-decision state, and virtual experiences into the\nbasic DDPG algorithm. Our simulation results show that the proposed policies\nconverge to the optimal policy that is derived based on perfect large-scale\nchannel prediction and outperform the first-predict-then-optimize policy in the\npresence of prediction errors. By harnessing the partially known model, the\nconvergence speed can be dramatically improved.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 17:36:53 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 01:30:00 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Liu", "Dong", ""], ["Zhao", "Jianyu", ""], ["Yang", "Chenyang", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2003.09711", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Yixuan Li, Xi Wu, Yingyu Liang, Somesh Jha", "title": "Robust Out-of-distribution Detection for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting anomalous inputs is critical for safely deploying deep learning\nmodels in the real world. Existing approaches for detecting out-of-distribution\n(OOD) examples work well when evaluated on natural samples drawn from a\nsufficiently different distribution than the training data distribution.\nHowever, in this paper, we show that existing detection mechanisms can be\nextremely brittle when evaluating on inputs with minimal adversarial\nperturbations which don't change their semantics. Formally, we introduce a\nnovel and challenging problem, Robust Out-of-Distribution Detection, and\npropose an algorithm that can fool existing OOD detectors by adding small\nperturbations to the inputs while preserving their semantics and thus the\ndistributional membership. We take a first step to solve this challenge, and\npropose an effective algorithm called ALOE, which performs robust training by\nexposing the model to both adversarially crafted inlier and outlier examples.\nOur method can be flexibly combined with, and render existing methods robust.\nOn common benchmark datasets, we show that ALOE substantially improves the\nrobustness of state-of-the-art OOD detection, with 58.4% AUROC improvement on\nCIFAR-10 and 46.59% improvement on CIFAR-100. Finally, we provide theoretical\nanalysis for our method, underpinning the empirical results above.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 17:46:28 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 04:16:09 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 23:16:31 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 00:46:48 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chen", "Jiefeng", ""], ["Li", "Yixuan", ""], ["Wu", "Xi", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""]]}, {"id": "2003.09712", "submitter": "Adish Singla", "authors": "Rati Devidze, Farnam Mansouri, Luis Haug, Yuxin Chen, Adish Singla", "title": "Understanding the Power and Limitations of Teaching with Imperfect\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine teaching studies the interaction between a teacher and a\nstudent/learner where the teacher selects training examples for the learner to\nlearn a specific task. The typical assumption is that the teacher has perfect\nknowledge of the task---this knowledge comprises knowing the desired learning\ntarget, having the exact task representation used by the learner, and knowing\nthe parameters capturing the learning dynamics of the learner. Inspired by\nreal-world applications of machine teaching in education, we consider the\nsetting where teacher's knowledge is limited and noisy, and the key research\nquestion we study is the following: When does a teacher succeed or fail in\neffectively teaching a learner using its imperfect knowledge? We answer this\nquestion by showing connections to how imperfect knowledge affects the\nteacher's solution of the corresponding machine teaching problem when\nconstructing optimal teaching sets. Our results have important implications for\ndesigning robust teaching algorithms for real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 17:53:26 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Devidze", "Rati", ""], ["Mansouri", "Farnam", ""], ["Haug", "Luis", ""], ["Chen", "Yuxin", ""], ["Singla", "Adish", ""]]}, {"id": "2003.09729", "submitter": "Ahmet Alacaoglu", "authors": "Ahmet Alacaoglu, Yura Malitsky, Panayotis Mertikopoulos, Volkan Cevher", "title": "A new regret analysis for Adam-type algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on a theory-practice gap for Adam and its variants\n(AMSgrad, AdamNC, etc.). In practice, these algorithms are used with a constant\nfirst-order moment parameter $\\beta_{1}$ (typically between $0.9$ and $0.99$).\nIn theory, regret guarantees for online convex optimization require a rapidly\ndecaying $\\beta_{1}\\to0$ schedule. We show that this is an artifact of the\nstandard analysis and propose a novel framework that allows us to derive\noptimal, data-dependent regret bounds with a constant $\\beta_{1}$, without\nfurther assumptions. We also demonstrate the flexibility of our analysis on a\nwide range of different algorithms and settings.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 19:19:51 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Alacaoglu", "Ahmet", ""], ["Malitsky", "Yura", ""], ["Mertikopoulos", "Panayotis", ""], ["Cevher", "Volkan", ""]]}, {"id": "2003.09736", "submitter": "Jeremy Wong", "authors": "Jeremy N. Wong, David J. Yoon, Angela P. Schoellig, Timothy D. Barfoot", "title": "Variational Inference with Parameter Learning Applied to Vehicle\n  Trajectory Estimation", "comments": "IEEE Robotics and Automation Letters (RA-L). 8 pages, 4 figures", "journal-ref": null, "doi": "10.1109/LRA.2020.3007381", "report-no": null, "categories": "cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present parameter learning in a Gaussian variational inference setting\nusing only noisy measurements (i.e., no groundtruth). This is demonstrated in\nthe context of vehicle trajectory estimation, although the method we propose is\ngeneral. The paper extends the Exactly Sparse Gaussian Variational Inference\n(ESGVI) framework, which has previously been used for large-scale nonlinear\nbatch state estimation. Our contribution is to additionally learn parameters of\nour system models (which may be difficult to choose in practice) within the\nESGVI framework. In this paper, we learn the covariances for the motion and\nsensor models used within vehicle trajectory estimation. Specifically, we learn\nthe parameters of a white-noise-on-acceleration motion model and the parameters\nof an Inverse-Wishart prior over measurement covariances for our sensor model.\nWe demonstrate our technique using a 36~km dataset consisting of a car using\nlidar to localize against a high-definition map; we learn the parameters on a\ntraining section of the data and then show that we achieve high-quality state\nestimates on a test section, even in the presence of outliers. Lastly, we show\nthat our framework can be used to solve pose graph optimization even with many\nfalse loop closures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 19:48:07 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 01:54:45 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Wong", "Jeremy N.", ""], ["Yoon", "David J.", ""], ["Schoellig", "Angela P.", ""], ["Barfoot", "Timothy D.", ""]]}, {"id": "2003.09737", "submitter": "Dongrui Wu", "authors": "Changming Zhao, Dongrui Wu, Jian Huang, Ye Yuan, Hai-Tao Zhang, Ruimin\n  Peng, Zhenhua Shi and Chenfeng Guo", "title": "BoostTree and BoostForest for Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap aggregating (Bagging) and boosting are two popular ensemble\nlearning approaches, which combine multiple base learners to generate a\ncomposite model for more accurate and more reliable performance. They have been\nwidely used in biology, engineering, healthcare, etc. This article proposes\nBoostForest, which is an ensemble learning approach using BoostTree as base\nlearners and can be used for both classification and regression. BoostTree\nconstructs a tree model by gradient boosting. It achieves high randomness\n(diversity) by sampling its parameters randomly from a parameter pool, and\nselecting a subset of features randomly at node splitting. BoostForest further\nincreases the randomness by bootstrapping the training data in constructing\ndifferent BoostTrees. BoostForest outperformed four classical ensemble learning\napproaches (Random Forest, Extra-Trees, XGBoost and LightGBM) on 34\nclassification and regression datasets. Remarkably, BoostForest has only one\nhyper-parameter (the number of BoostTrees), which can be easily specified. Our\ncode is publicly available, and the proposed ensemble learning framework can\nalso be used to combine many other base learners.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 19:52:13 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 16:11:25 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhao", "Changming", ""], ["Wu", "Dongrui", ""], ["Huang", "Jian", ""], ["Yuan", "Ye", ""], ["Zhang", "Hai-Tao", ""], ["Peng", "Ruimin", ""], ["Shi", "Zhenhua", ""], ["Guo", "Chenfeng", ""]]}, {"id": "2003.09756", "submitter": "Amir Zandieh", "authors": "Michael Kapralov, Navid Nouri, Ilya Razenshteyn, Ameya Velingker, Amir\n  Zandieh", "title": "Scaling up Kernel Ridge Regression via Locality Sensitive Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random binning features, introduced in the seminal paper of Rahimi and Recht\n(2007), are an efficient method for approximating a kernel matrix using\nlocality sensitive hashing. Random binning features provide a very simple and\nefficient way of approximating the Laplace kernel but unfortunately do not\napply to many important classes of kernels, notably ones that generate smooth\nGaussian processes, such as the Gaussian kernel and Matern kernel. In this\npaper, we introduce a simple weighted version of random binning features and\nshow that the corresponding kernel function generates Gaussian processes of any\ndesired smoothness. We show that our weighted random binning features provide a\nspectral approximation to the corresponding kernel matrix, leading to efficient\nalgorithms for kernel ridge regression. Experiments on large scale regression\ndatasets show that our method outperforms the accuracy of random Fourier\nfeatures method.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 21:41:16 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Kapralov", "Michael", ""], ["Nouri", "Navid", ""], ["Razenshteyn", "Ilya", ""], ["Velingker", "Ameya", ""], ["Zandieh", "Amir", ""]]}, {"id": "2003.09758", "submitter": "Nadiia Chepurko", "authors": "Nadiia Chepurko, Ryan Marcus, Emanuel Zgraggen, Raul Castro Fernandez,\n  Tim Kraska, David Karger", "title": "ARDA: Automatic Relational Data Augmentation for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning (\\AML) is a family of techniques to automate the\nprocess of training predictive models, aiming to both improve performance and\nmake machine learning more accessible. While many recent works have focused on\naspects of the machine learning pipeline like model selection, hyperparameter\ntuning, and feature selection, relatively few works have focused on automatic\ndata augmentation. Automatic data augmentation involves finding new features\nrelevant to the user's predictive task with minimal ``human-in-the-loop''\ninvolvement.\n  We present \\system, an end-to-end system that takes as input a dataset and a\ndata repository, and outputs an augmented data set such that training a\npredictive model on this augmented dataset results in improved performance. Our\nsystem has two distinct components: (1) a framework to search and join data\nwith the input data, based on various attributes of the input, and (2) an\nefficient feature selection algorithm that prunes out noisy or irrelevant\nfeatures from the resulting join. We perform an extensive empirical evaluation\nof different system components and benchmark our feature selection algorithm on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 21:55:22 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chepurko", "Nadiia", ""], ["Marcus", "Ryan", ""], ["Zgraggen", "Emanuel", ""], ["Fernandez", "Raul Castro", ""], ["Kraska", "Tim", ""], ["Karger", "David", ""]]}, {"id": "2003.09761", "submitter": "Tae Yoon Lee", "authors": "Devon Graham, Satish Kumar Sarraf, Taylor Lundy, Ali MohammadMehr,\n  Sara Uppal, Tae Yoon Lee, Hedayat Zarkoob, Scott Duke Kominers, Kevin\n  Leyton-Brown", "title": "Smarter Parking: Using AI to Identify Parking Inefficiencies in\n  Vancouver", "comments": "All the authors contributed equally. This paper is an outcome of\n  https://www.cs.ubc.ca/~kevinlb/teaching/cs532l%20-%202018-19/index.html. To\n  be submitted to a journal in transportation or urban planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-street parking is convenient, but has many disadvantages: on-street spots\ncome at the expense of other road uses such as traffic lanes, transit lanes,\nbike lanes, or parklets; drivers looking for parking contribute substantially\nto traffic congestion and hence to greenhouse gas emissions; safety is reduced\nboth due to the fact that drivers looking for spots are more distracted than\nother road users and that people exiting parked cars pose a risk to cyclists.\nThese social costs may not be worth paying when off-street parking lots are\nnearby and have surplus capacity. To see where this might be true in downtown\nVancouver, we used artificial intelligence techniques to estimate the amount of\ntime it would take drivers to both park on and off street for destinations\nthroughout the city. For on-street parking, we developed (1) a deep-learning\nmodel of block-by-block parking availability based on data from parking meters\nand audits and (2) a computational simulation of drivers searching for an\non-street spot. For off-street parking, we developed a computational simulation\nof the time it would take drivers drive from their original destination to the\nnearest city-owned off-street lot and then to queue for a spot based on traffic\nand lot occupancy data. Finally, in both cases we also computed the time it\nwould take the driver to walk from their parking spot to their original\ndestination. We compared these time estimates for destinations in each block of\nVancouver's downtown core and each hour of the day. We found many areas where\noff street would actually save drivers time over searching the streets for a\nspot, and many more where the time cost for parking off street was small. The\nidentification of such areas provides an opportunity for the city to repurpose\nvaluable curbside space for community-friendly uses more in line with its\ntransportation goals.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 22:34:57 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Graham", "Devon", ""], ["Sarraf", "Satish Kumar", ""], ["Lundy", "Taylor", ""], ["MohammadMehr", "Ali", ""], ["Uppal", "Sara", ""], ["Lee", "Tae Yoon", ""], ["Zarkoob", "Hedayat", ""], ["Kominers", "Scott Duke", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "2003.09772", "submitter": "Mo Yu", "authors": "Shiyu Chang, Yang Zhang, Mo Yu, Tommi S. Jaakkola", "title": "Invariant Rationalization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective rationalization improves neural network interpretability by\nidentifying a small subset of input features -- the rationale -- that best\nexplains or supports the prediction. A typical rationalization criterion, i.e.\nmaximum mutual information (MMI), finds the rationale that maximizes the\nprediction performance based only on the rationale. However, MMI can be\nproblematic because it picks up spurious correlations between the input\nfeatures and the output. Instead, we introduce a game-theoretic invariant\nrationalization criterion where the rationales are constrained to enable the\nsame predictor to be optimal across different environments. We show both\ntheoretically and empirically that the proposed rationales can rule out\nspurious correlations, generalize better to different test scenarios, and align\nbetter with human judgments. Our data and code are available.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 00:50:27 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Yu", "Mo", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "2003.09779", "submitter": "Sarah Ostadabbas", "authors": "Amirreza Farnoosh, Behnaz Rezaei, Eli Zachary Sennesh, Zulqarnain\n  Khan, Jennifer Dy, Ajay Satpute, J Benjamin Hutchinson, Jan-Willem van de\n  Meent, Sarah Ostadabbas", "title": "Deep Markov Spatio-Temporal Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep Markov spatio-temporal factorization (DMSTF), a generative\nmodel for dynamical analysis of spatio-temporal data. Like other factor\nanalysis methods, DMSTF approximates high dimensional data by a product between\ntime dependent weights and spatially dependent factors. These weights and\nfactors are in turn represented in terms of lower dimensional latents inferred\nusing stochastic variational inference. The innovation in DMSTF is that we\nparameterize weights in terms of a deep Markovian prior extendable with a\ndiscrete latent, which is able to characterize nonlinear multimodal temporal\ndynamics, and perform multidimensional time series forecasting. DMSTF learns a\nlow dimensional spatial latent to generatively parameterize spatial factors or\ntheir functional forms in order to accommodate high spatial dimensionality. We\nparameterize the corresponding variational distribution using a bidirectional\nrecurrent network in the low-level latent representations. This results in a\nflexible family of hierarchical deep generative factor analysis models that can\nbe extended to perform time series clustering or perform factor analysis in the\npresence of a control signal. Our experiments, which include simulated and\nreal-world data, demonstrate that DMSTF outperforms related methodologies in\nterms of predictive performance for unseen data, reveals meaningful clusters in\nthe data, and performs forecasting in a variety of domains with potentially\nnonlinear temporal transitions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 01:27:44 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 17:58:37 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Farnoosh", "Amirreza", ""], ["Rezaei", "Behnaz", ""], ["Sennesh", "Eli Zachary", ""], ["Khan", "Zulqarnain", ""], ["Dy", "Jennifer", ""], ["Satpute", "Ajay", ""], ["Hutchinson", "J Benjamin", ""], ["van de Meent", "Jan-Willem", ""], ["Ostadabbas", "Sarah", ""]]}, {"id": "2003.09788", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Deep Synthetic Minority Over-Sampling Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic Minority Over-sampling Technique (SMOTE) is the most popular\nover-sampling method. However, its random nature makes the synthesized data and\neven imbalanced classification results unstable. It means that in case of\nrunning SMOTE n different times, n different synthesized in-stances are\nobtained with n different classification results. To address this problem, we\nadapt the SMOTE idea in deep learning architecture. In this method, a deep\nneural network regression model is used to train the inputs and outputs of\ntraditional SMOTE. Inputs of the proposed deep regression model are two\nrandomly chosen data points which are concatenated to form a double size\nvector. The outputs of this model are corresponding randomly interpolated data\npoints between two randomly chosen vectors with original dimension. The\nexperimental results show that, Deep SMOTE can outperform traditional SMOTE in\nterms of precision, F1 score and Area Under Curve (AUC) in majority of test\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 02:44:46 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "2003.09795", "submitter": "Yanjun Han", "authors": "Yanjun Han, Zhengyuan Zhou, Tsachy Weissman", "title": "Optimal No-regret Learning in Repeated First-price Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.IT math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning in repeated first-price auctions with censored\nfeedback, where a bidder, only observing the winning bid at the end of each\nauction, learns to adaptively bid in order to maximize her cumulative payoff.\nTo achieve this goal, the bidder faces a challenging dilemma: if she wins the\nbid--the only way to achieve positive payoffs--then she is not able to observe\nthe highest bid of the other bidders, which we assume is iid drawn from an\nunknown distribution. This dilemma, despite being reminiscent of the\nexploration-exploitation trade-off in contextual bandits, cannot directly be\naddressed by the existing UCB or Thompson sampling algorithms in that\nliterature, mainly because contrary to the standard bandits setting, when a\npositive reward is obtained here, nothing about the environment can be learned.\n  In this paper, by exploiting the structural properties of first-price\nauctions, we develop the first learning algorithm that achieves\n$O(\\sqrt{T}\\log^2 T)$ regret bound when the bidder's private values are\nstochastically generated. We do so by providing an algorithm on a general class\nof problems, which we call monotone group contextual bandits, where the same\nregret bound is established under stochastically generated contexts. Further,\nby a novel lower bound argument, we characterize an $\\Omega(T^{2/3})$ lower\nbound for the case where the contexts are adversarially generated, thus\nhighlighting the impact of the contexts generation mechanism on the fundamental\nlearning limit. Despite this, we further exploit the structure of first-price\nauctions and develop a learning algorithm that operates sample-efficiently (and\ncomputationally efficiently) in the presence of adversarially generated private\nvalues. We establish an $O(\\sqrt{T}\\log^3 T)$ regret bound for this algorithm,\nhence providing a complete characterization of optimal learning guarantees for\nthis problem.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 03:32:09 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 20:56:11 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 06:42:43 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 22:18:17 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Han", "Yanjun", ""], ["Zhou", "Zhengyuan", ""], ["Weissman", "Tsachy", ""]]}, {"id": "2003.09821", "submitter": "Zan Shen", "authors": "Zan Shen, Jiang Qian, Bojin Zhuang, Shaojun Wang, Jing Xiao", "title": "BS-NAS: Broadening-and-Shrinking One-Shot NAS with Searchable Numbers of\n  Channels", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-Shot methods have evolved into one of the most popular methods in Neural\nArchitecture Search (NAS) due to weight sharing and single training of a\nsupernet. However, existing methods generally suffer from two issues:\npredetermined number of channels in each layer which is suboptimal; and model\naveraging effects and poor ranking correlation caused by weight coupling and\ncontinuously expanding search space. To explicitly address these issues, in\nthis paper, a Broadening-and-Shrinking One-Shot NAS (BS-NAS) framework is\nproposed, in which `broadening' refers to broadening the search space with a\nspring block enabling search for numbers of channels during training of the\nsupernet; while `shrinking' refers to a novel shrinking strategy gradually\nturning off those underperforming operations. The above innovations broaden the\nsearch space for wider representation and then shrink it by gradually removing\nunderperforming operations, followed by an evolutionary algorithm to\nefficiently search for the optimal architecture. Extensive experiments on\nImageNet illustrate the effectiveness of the proposed BS-NAS as well as the\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 06:32:47 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Shen", "Zan", ""], ["Qian", "Jiang", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "2003.09844", "submitter": "Thulasi Tholeti", "authors": "Thulasi Tholeti, Sheetal Kalyani", "title": "Tune smarter not harder: A principled approach to tuning learning rates\n  for shallow nets", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing (Volume: 68), Page(s): 5063\n  - 5078, Year: 2020", "doi": "10.1109/TSP.2020.3019655", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective hyper-parameter tuning is essential to guarantee the performance\nthat neural networks have come to be known for. In this work, a principled\napproach to choosing the learning rate is proposed for shallow feedforward\nneural networks. We associate the learning rate with the gradient Lipschitz\nconstant of the objective to be minimized while training. An upper bound on the\nmentioned constant is derived and a search algorithm, which always results in\nnon-divergent traces, is proposed to exploit the derived bound. It is shown\nthrough simulations that the proposed search method significantly outperforms\nthe existing tuning methods such as Tree Parzen Estimators (TPE). The proposed\nmethod is applied to three different existing applications: a) channel\nestimation in OFDM systems, b) prediction of the exchange currency rates and c)\noffset estimation in OFDM receivers, and it is shown to pick better learning\nrates than the existing methods using the same or lesser compute power.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 09:38:35 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 21:06:50 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 02:18:30 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Tholeti", "Thulasi", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "2003.09896", "submitter": "Eleftherios Spyromitros-Xioufis", "authors": "Eleftherios Spyromitros-Xioufis, Konstantinos Sechidis and Ioannis\n  Vlahavas", "title": "Multi-target regression via output space quantization", "comments": "International Joint Conference on Neural Networks (IJCNN) 19-25 July,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-target regression is concerned with the prediction of multiple\ncontinuous target variables using a shared set of predictors. Two key\nchallenges in multi-target regression are: (a) modelling target dependencies\nand (b) scalability to large output spaces. In this paper, a new multi-target\nregression method is proposed that tries to jointly address these challenges\nvia a novel problem transformation approach. The proposed method, called MRQ,\nis based on the idea of quantizing the output space in order to transform the\nmultiple continuous targets into one or more discrete ones. Learning on the\ntransformed output space naturally enables modeling of target dependencies\nwhile the quantization strategy can be flexibly parameterized to control the\ntrade-off between prediction accuracy and computational efficiency. Experiments\non a large collection of benchmark datasets show that MRQ is both highly\nscalable and also competitive with the state-of-the-art in terms of accuracy.\nIn particular, an ensemble version of MRQ obtains the best overall accuracy,\nwhile being an order of magnitude faster than the runner up method.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 13:57:40 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Spyromitros-Xioufis", "Eleftherios", ""], ["Sechidis", "Konstantinos", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "2003.09902", "submitter": "Jingxin Liu", "authors": "Jingxin Liu, Chang Xu, Chang Yin, Weiqiang Wu and You Song", "title": "K-Core based Temporal Graph Convolutional Network for Dynamic Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2020.3033829", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is a fundamental task in various applications\nthat strives to learn low-dimensional embeddings for nodes that can preserve\ngraph topology information. However, many existing methods focus on static\ngraphs while ignoring evolving graph patterns. Inspired by the success of graph\nconvolutional networks(GCNs) in static graph embedding, we propose a novel\nk-core based temporal graph convolutional network, the CTGCN, to learn node\nrepresentations for dynamic graphs. In contrast to previous dynamic graph\nembedding methods, CTGCN can preserve both local connective proximity and\nglobal structural similarity while simultaneously capturing graph dynamics. In\nthe proposed framework, the traditional graph convolution is generalized into\ntwo phases, feature transformation and feature aggregation, which gives the\nCTGCN more flexibility and enables the CTGCN to learn connective and structural\ninformation under the same framework. Experimental results on 7 real-world\ngraphs demonstrate that the CTGCN outperforms existing state-of-the-art graph\nembedding methods in several tasks, including link prediction and structural\nrole classification. The source code of this work can be obtained from\n\\url{https://github.com/jhljx/CTGCN}.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 14:15:27 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 10:37:34 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 06:30:28 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 12:13:04 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Liu", "Jingxin", ""], ["Xu", "Chang", ""], ["Yin", "Chang", ""], ["Wu", "Weiqiang", ""], ["Song", "You", ""]]}, {"id": "2003.09908", "submitter": "Chengtai Cao", "authors": "Fan Zhou and Chengtai Cao", "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks with\n  Experience Replay", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have recently received significant research\nattention due to their superior performance on a variety of graph-related\nlearning tasks. Most of the current works focus on either static or dynamic\ngraph settings, addressing a single particular task, e.g., node/graph\nclassification, link prediction. In this work, we investigate the question: can\nGNNs be applied to continuously learning a sequence of tasks? Towards that, we\nexplore the Continual Graph Learning (CGL) paradigm and present the Experience\nReplay based framework ER-GNN for CGL to alleviate the catastrophic forgetting\nproblem in existing GNNs. ER-GNN stores knowledge from previous tasks as\nexperiences and replays them when learning new tasks to mitigate the\ncatastrophic forgetting issue. We propose three experience node selection\nstrategies: mean of feature, coverage maximization, and influence maximization,\nto guide the process of selecting experience nodes. Extensive experiments on\nthree benchmark datasets demonstrate the effectiveness of our ER-GNN and shed\nlight on the incremental graph (non-Euclidean) structure learning.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 14:29:53 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 08:26:58 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhou", "Fan", ""], ["Cao", "Chengtai", ""]]}, {"id": "2003.09945", "submitter": "Xiaojie Guo", "authors": "Xiaojie Guo, Liang Zhao, Cameron Nowzari, Setareh Rafatirad, Houman\n  Homayoun, and Sai Manoj Pudukotai Dinakarrao", "title": "Deep Multi-attributed Graph Translation with Node-Edge Co-evolution", "comments": "This paper has won the Best Paper Award in International Conference\n  on Data Mining (ICDM), Beijing, China, 2019", "journal-ref": "International Conference on Data Mining (ICDM), Beijing, China,\n  2019, pp. 250-259", "doi": "10.1109/ICDM.2019.00035", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized from image and language translation, graph translation aims to\ngenerate a graph in the target domain by conditioning an input graph in the\nsource domain. This promising topic has attracted fast-increasing attention\nrecently. Existing works are limited to either merely predicting the node\nattributes of graphs with fixed topology or predicting only the graph topology\nwithout considering node attributes, but cannot simultaneously predict both of\nthem, due to substantial challenges: 1) difficulty in characterizing the\ninteractive, iterative, and asynchronous translation process of both nodes and\nedges and 2) difficulty in discovering and maintaining the inherent consistency\nbetween the node and edge in predicted graphs. These challenges prevent a\ngeneric, end-to-end framework for joint node and edge attributes prediction,\nwhich is a need for real-world applications such as malware confinement in IoT\nnetworks and structural-to-functional network translation. These real-world\napplications highly depend on hand-crafting and ad-hoc heuristic models, but\ncannot sufficiently utilize massive historical data. In this paper, we termed\nthis generic problem \"multi-attributed graph translation\" and developed a novel\nframework integrating both node and edge translations seamlessly. The novel\nedge translation path is generic, which is proven to be a generalization of the\nexisting topology translation models. Then, a spectral graph regularization\nbased on our non-parametric graph Laplacian is proposed in order to learn and\nmaintain the consistency of the predicted nodes and edges. Finally, extensive\nexperiments on both synthetic and real-world application data demonstrated the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 16:49:53 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 20:03:54 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Guo", "Xiaojie", ""], ["Zhao", "Liang", ""], ["Nowzari", "Cameron", ""], ["Rafatirad", "Setareh", ""], ["Homayoun", "Houman", ""], ["Dinakarrao", "Sai Manoj Pudukotai", ""]]}, {"id": "2003.09946", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas and Daniel Ramos and Roberto Paredes", "title": "On Calibration of Mixup Training for Deep Neural Networks", "comments": "To appear in S+SSPR2020", "journal-ref": null, "doi": "10.1007/978-3-030-73973-7_7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNN) represent the state of the art in many tasks.\nHowever, due to their overparameterization, their generalization capabilities\nare in doubt and still a field under study. Consequently, DNN can overfit and\nassign overconfident predictions -- effects that have been shown to affect the\ncalibration of the confidences assigned to unseen data. Data Augmentation (DA)\nstrategies have been proposed to regularize these models, being Mixup one of\nthe most popular due to its ability to improve the accuracy, the uncertainty\nquantification and the calibration of DNN. In this work however we argue and\nprovide empirical evidence that, due to its fundamentals, Mixup does not\nnecessarily improve calibration. Based on our observations we propose a new\nloss function that improves the calibration, and also sometimes the accuracy,\nof DNN trained with this DA technique. Our loss is inspired by Bayes decision\ntheory and introduces a new training framework for designing losses for\nprobabilistic modelling. We provide state-of-the-art accuracy with consistent\nimprovements in calibration performance. Appendix and code are provided here:\nhttps://github.com/jmaronas/calibration_MixupDNN_ARCLoss.pytorch.git\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 16:54:31 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 12:18:10 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 07:54:20 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 11:39:19 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Maro\u00f1as", "Juan", ""], ["Ramos", "Daniel", ""], ["Paredes", "Roberto", ""]]}, {"id": "2003.09957", "submitter": "Evgeny Burnaev", "authors": "Dmitrii Smolyakov and Evgeny Burnaev", "title": "Software System for Road Condition Forecast Correction", "comments": "11 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a monitoring system that allows increasing road\nsafety by predicting ice formation. The system consists of a network of road\nweather stations and intelligence data processing program module. The results\nwere achieved by combining physical models for forecasting road conditions\nbased on measurements from stations and machine learning models for detecting\nincorrect data and forecast correction.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:47:02 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Smolyakov", "Dmitrii", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2003.09960", "submitter": "Kaizheng Wang", "authors": "Kaizheng Wang, Yuling Yan, Mateo Diaz", "title": "Efficient Clustering for Stretched Mixtures: Landscape and Optimality", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a canonical clustering problem where one receives\nunlabeled samples drawn from a balanced mixture of two elliptical distributions\nand aims for a classifier to estimate the labels. Many popular methods\nincluding PCA and k-means require individual components of the mixture to be\nsomewhat spherical, and perform poorly when they are stretched. To overcome\nthis issue, we propose a non-convex program seeking for an affine transform to\nturn the data into a one-dimensional point cloud concentrating around -1 and 1,\nafter which clustering becomes easy. Our theoretical contributions are\ntwo-fold: (1) we show that the non-convex loss function exhibits desirable\nlandscape properties as long as the sample size exceeds some constant multiple\nof the dimension, and (2) we leverage this to prove that an efficient\nfirst-order algorithm achieves near-optimal statistical precision even without\ngood initialization. We also propose a general methodology for multi-class\nclustering tasks with flexible choices of feature transforms and loss\nobjectives.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:57:07 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 17:45:00 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Kaizheng", ""], ["Yan", "Yuling", ""], ["Diaz", "Mateo", ""]]}, {"id": "2003.09969", "submitter": "Stefan Steinerberger", "authors": "Adela DePavia, Stefan Steinerberger", "title": "Spectral Clustering Revisited: Information Hidden in the Fiedler Vector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DM cs.LG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the clustering problem on graphs: it is known that if\nthere are two underlying clusters, then the signs of the eigenvector\ncorresponding to the second largest eigenvalue of the adjacency matrix can\nreliably reconstruct the two clusters. We argue that the vertices for which the\neigenvector has the largest and the smallest entries, respectively, are\nunusually strongly connected to their own cluster and more reliably classified\nthan the rest. This can be regarded as a discrete version of the Hot Spots\nconjecture and should be useful in applications. We give a rigorous proof for\nthe stochastic block model and several examples.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 19:01:37 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["DePavia", "Adela", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "2003.10038", "submitter": "Hye Won Chung", "authors": "Jeonghwan Lee, Daesung Kim and Hye Won Chung", "title": "Robust Hypergraph Clustering via Convex Relaxation of Truncated MLE", "comments": "20 pages, 4 figure", "journal-ref": "Published at IEEE Journal on Selected Areas in Information Theory\n  (JSAIT), Issue 3, 2020", "doi": "10.1109/JSAIT.2020.3037170", "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study hypergraph clustering in the weighted $d$-uniform hypergraph\nstochastic block model ($d$\\textsf{-WHSBM}), where each edge consisting of $d$\nnodes from the same community has higher expected weight than the edges\nconsisting of nodes from different communities. We propose a new hypergraph\nclustering algorithm, called \\textsf{CRTMLE}, and provide its performance\nguarantee under the $d$\\textsf{-WHSBM} for general parameter regimes. We show\nthat the proposed method achieves the order-wise optimal or the best existing\nresults for approximately balanced community sizes. Moreover, our results\nsettle the first recovery guarantees for growing number of clusters of\nunbalanced sizes. Involving theoretical analysis and empirical results, we\ndemonstrate the robustness of our algorithm against the unbalancedness of\ncommunity sizes or the presence of outlier nodes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 01:02:28 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 12:08:34 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 04:52:06 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Lee", "Jeonghwan", ""], ["Kim", "Daesung", ""], ["Chung", "Hye Won", ""]]}, {"id": "2003.10041", "submitter": "Taro Makino", "authors": "Witold Oleszkiewicz, Taro Makino, Stanis{\\l}aw Jastrz\\k{e}bski, Tomasz\n  Trzci\\'nski, Linda Moy, Kyunghyun Cho, Laura Heacock, Krzysztof J. Geras", "title": "Understanding the robustness of deep neural network classifiers for\n  breast cancer screening", "comments": "Accepted as a workshop paper at AI4AH, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) show promise in breast cancer screening, but\ntheir robustness to input perturbations must be better understood before they\ncan be clinically implemented. There exists extensive literature on this\nsubject in the context of natural images that can potentially be built upon.\nHowever, it cannot be assumed that conclusions about robustness will transfer\nfrom natural images to mammogram images, due to significant differences between\nthe two image modalities. In order to determine whether conclusions will\ntransfer, we measure the sensitivity of a radiologist-level screening mammogram\nimage classifier to four commonly studied input perturbations that natural\nimage classifiers are sensitive to. We find that mammogram image classifiers\nare also sensitive to these perturbations, which suggests that we can build on\nthe existing literature. We also perform a detailed analysis on the effects of\nlow-pass filtering, and find that it degrades the visibility of clinically\nmeaningful features called microcalcifications. Since low-pass filtering\nremoves semantically meaningful information that is predictive of breast\ncancer, we argue that it is undesirable for mammogram image classifiers to be\ninvariant to it. This is in contrast to natural images, where we do not want\nDNNs to be sensitive to low-pass filtering due to its tendency to remove\ninformation that is human-incomprehensible.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 01:26:36 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Oleszkiewicz", "Witold", ""], ["Makino", "Taro", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Trzci\u0144ski", "Tomasz", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Heacock", "Laura", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2003.10076", "submitter": "Jinfei Liu", "authors": "Jinfei Liu", "title": "Absolute Shapley Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley value is a concept in cooperative game theory for measuring the\ncontribution of each participant, which was named in honor of Lloyd Shapley.\nShapley value has been recently applied in data marketplaces for compensation\nallocation based on their contribution to the models. Shapley value is the only\nvalue division scheme used for compensation allocation that meets three\ndesirable criteria: group rationality, fairness, and additivity. In cooperative\ngame theory, the marginal contribution of each contributor to each coalition is\na nonnegative value. However, in machine learning model training, the marginal\ncontribution of each contributor (data tuple) to each coalition (a set of data\ntuples) can be a negative value, i.e., the accuracy of the model trained by a\ndataset with an additional data tuple can be lower than the accuracy of the\nmodel trained by the dataset only.\n  In this paper, we investigate the problem of how to handle the negative\nmarginal contribution when computing Shapley value. We explore three\nphilosophies: 1) taking the original value (Original Shapley Value); 2) taking\nthe larger of the original value and zero (Zero Shapley Value); and 3) taking\nthe absolute value of the original value (Absolute Shapley Value). Experiments\non Iris dataset demonstrate that the definition of Absolute Shapley Value\nsignificantly outperforms the other two definitions in terms of evaluating data\nimportance (the contribution of each data tuple to the trained model).\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 04:26:30 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Jinfei", ""]]}, {"id": "2003.10113", "submitter": "Olivier Cappe", "authors": "Yoan Russac (DI-ENS), Olivier Capp\\'e (DI-ENS), Aur\\'elien Garivier\n  (UMPA-ENSL)", "title": "Algorithms for Non-Stationary Generalized Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical framework of Generalized Linear Models (GLM) can be applied\nto sequential problems involving categorical or ordinal rewards associated, for\ninstance, with clicks, likes or ratings. In the example of binary rewards,\nlogistic regression is well-known to be preferable to the use of standard\nlinear modeling. Previous works have shown how to deal with GLMs in contextual\nonline learning with bandit feedback when the environment is assumed to be\nstationary. In this paper, we relax this latter assumption and propose two\nupper confidence bound based algorithms that make use of either a sliding\nwindow or a discounted maximum-likelihood estimator. We provide theoretical\nguarantees on the behavior of these algorithms for general context sequences\nand in the presence of abrupt changes. These results take the form of high\nprobability upper bounds for the dynamic regret that are of order d^2/3 G^1/3\nT^2/3 , where d, T and G are respectively the dimension of the unknown\nparameter, the number of rounds and the number of breakpoints up to time T. The\nempirical performance of the algorithms is illustrated in simulated\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 07:44:59 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Russac", "Yoan", "", "DI-ENS"], ["Capp\u00e9", "Olivier", "", "DI-ENS"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2003.10126", "submitter": "Thomas Lartigue", "authors": "Thomas Lartigue (ARAMIS, CMAP), Stanley Durrleman (ARAMIS),\n  St\\'ephanie Allassonni\\`ere (CRC)", "title": "Deterministic Approximate EM Algorithm; Application to the Riemann\n  Approximation EM and the Tempered EM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation Maximisation (EM) algorithm is widely used to optimise\nnon-convex likelihood functions with hidden variables. Many authors modified\nits simple design to fit more specific situations. For instance the Expectation\n(E) step has been replaced by Monte Carlo (MC) approximations, Markov Chain\nMonte Carlo approximations, tempered approximations... Most of the well-studied\napproximations belong to the stochastic class. By comparison, the literature is\nlacking when it comes to deterministic approximations. In this paper, we\nintroduce a theoretical framework, with state-of-the-art convergence\nguarantees, for any deterministic approximation of the E step. We analyse\ntheoretically and empirically several approximations that fit into this\nframework. First, for cases with intractable E steps, we introduce a\ndeterministic alternative to the MC-EM, using Riemann sums. This method is easy\nto implement and does not require the tuning of hyper-parameters. Then, we\nconsider the tempered approximation, borrowed from the Simulated Annealing\noptimisation technique and meant to improve the EM solution. We prove that the\ntempered EM verifies the convergence guarantees for a wide range of temperature\nprofiles. We showcase empirically how it is able to escape adversarial\ninitialisations. Finally, we combine the Riemann and tempered approximations to\naccomplish both their purposes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 08:23:54 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 14:40:43 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Lartigue", "Thomas", "", "ARAMIS, CMAP"], ["Durrleman", "Stanley", "", "ARAMIS"], ["Allassonni\u00e8re", "St\u00e9phanie", "", "CRC"]]}, {"id": "2003.10130", "submitter": "Bo Jiang", "authors": "Bo Jiang and Ziyan Zhang", "title": "Incomplete Graph Representation and Learning via Partial Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are gaining increasing attention on graph data\nlearning tasks in recent years. However, in many applications, graph may be\ncoming in an incomplete form where attributes of graph nodes are partially\nunknown/missing. Existing GNNs are generally designed on complete graphs which\ncan not deal with attribute-incomplete graph data directly. To address this\nproblem, we develop a novel partial aggregation based GNNs, named Partial Graph\nNeural Networks (PaGNNs), for attribute-incomplete graph representation and\nlearning. Our work is motivated by the observation that the neighborhood\naggregation function in standard GNNs can be equivalently viewed as the\nneighborhood reconstruction formulation. Based on it, we define two novel\npartial aggregation (reconstruction) functions on incomplete graph and derive\nPaGNNs for incomplete graph data learning. Extensive experiments on several\ndatasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 08:29:59 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 09:23:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Jiang", "Bo", ""], ["Zhang", "Ziyan", ""]]}, {"id": "2003.10146", "submitter": "Gang Mei", "authors": "Kaifeng Gao, Gang Mei, Francesco Piccialli, Salvatore Cuomo, Jingzhi\n  Tu, Zenan Huo", "title": "Julia Language in Machine Learning: Algorithms, Applications, and Open\n  Issues", "comments": "Published in Computer Science Review", "journal-ref": "Computer Science Review, Volume 37, 2020, 100254", "doi": "10.1016/j.cosrev.2020.100254", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is driving development across many fields in science and\nengineering. A simple and efficient programming language could accelerate\napplications of machine learning in various fields. Currently, the programming\nlanguages most commonly used to develop machine learning algorithms include\nPython, MATLAB, and C/C ++. However, none of these languages well balance both\nefficiency and simplicity. The Julia language is a fast, easy-to-use, and\nopen-source programming language that was originally designed for\nhigh-performance computing, which can well balance the efficiency and\nsimplicity. This paper summarizes the related research work and developments in\nthe application of the Julia language in machine learning. It first surveys the\npopular machine learning algorithms that are developed in the Julia language.\nThen, it investigates applications of the machine learning algorithms\nimplemented with the Julia language. Finally, it discusses the open issues and\nthe potential future directions that arise in the use of the Julia language in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 09:31:02 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 10:52:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gao", "Kaifeng", ""], ["Mei", "Gang", ""], ["Piccialli", "Francesco", ""], ["Cuomo", "Salvatore", ""], ["Tu", "Jingzhi", ""], ["Huo", "Zenan", ""]]}, {"id": "2003.10159", "submitter": "Jonas Prellberg", "authors": "Jonas Prellberg, Oliver Kramer", "title": "Learned Weight Sharing for Deep Multi-Task Learning by Natural Evolution\n  Strategy and Stochastic Gradient Descent", "comments": "Accepted at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep multi-task learning, weights of task-specific networks are shared\nbetween tasks to improve performance on each single one. Since the question,\nwhich weights to share between layers, is difficult to answer, human-designed\narchitectures often share everything but a last task-specific layer. In many\ncases, this simplistic approach severely limits performance. Instead, we\npropose an algorithm to learn the assignment between a shared set of weights\nand task-specific layers. To optimize the non-differentiable assignment and at\nthe same time train the differentiable weights, learning takes place via a\ncombination of natural evolution strategy and stochastic gradient descent. The\nend result are task-specific networks that share weights but allow independent\ninference. They achieve lower test errors than baselines and methods from\nliterature on three multi-task learning datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 10:21:44 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Prellberg", "Jonas", ""], ["Kramer", "Oliver", ""]]}, {"id": "2003.10163", "submitter": "Alon Ziv", "authors": "Alon Ziv", "title": "Depth Enables Long-Term Memory for Recurrent Neural Networks", "comments": "This document is an extension of arXiv:1710.09431 in the form of a\n  Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key attribute that drives the unprecedented success of modern Recurrent\nNeural Networks (RNNs) on learning tasks which involve sequential data, is\ntheir ability to model intricate long-term temporal dependencies. However, a\nwell established measure of RNNs long-term memory capacity is lacking, and thus\nformal understanding of the effect of depth on their ability to correlate data\nthroughout time is limited. Specifically, existing depth efficiency results on\nconvolutional networks do not suffice in order to account for the success of\ndeep RNNs on data of varying lengths. In order to address this, we introduce a\nmeasure of the network's ability to support information flow across time,\nreferred to as the Start-End separation rank, which reflects the distance of\nthe function realized by the recurrent network from modeling no dependency\nbetween the beginning and end of the input sequence. We prove that deep\nrecurrent networks support Start-End separation ranks which are combinatorially\nhigher than those supported by their shallow counterparts. Thus, we establish\nthat depth brings forth an overwhelming advantage in the ability of recurrent\nnetworks to model long-term dependencies, and provide an exemplar of\nquantifying this key attribute. We empirically demonstrate the discussed\nphenomena on common RNNs through extensive experimental evaluation using the\noptimization technique of restricting the hidden-to-hidden matrix to being\northogonal. Finally, we employ the tool of quantum Tensor Networks to gain\nadditional graphic insights regarding the complexity brought forth by depth in\nrecurrent networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 10:29:14 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ziv", "Alon", ""]]}, {"id": "2003.10170", "submitter": "Yikuan Li", "authors": "Yikuan Li, Shishir Rao, Abdelaali Hassaine, Rema Ramakrishnan, Yajie\n  Zhu, Dexter Canoy, Gholamreza Salimi-Khorshidi, Thomas Lukasiewicz, Kazem\n  Rahimi", "title": "Deep Bayesian Gaussian Processes for Uncertainty Estimation in\n  Electronic Health Records", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major impediment to the wider use of deep learning for clinical decision\nmaking is the difficulty of assigning a level of confidence to model\npredictions. Currently, deep Bayesian neural networks and sparse Gaussian\nprocesses are the main two scalable uncertainty estimation methods. However,\ndeep Bayesian neural network suffers from lack of expressiveness, and more\nexpressive models such as deep kernel learning, which is an extension of sparse\nGaussian process, captures only the uncertainty from the higher level latent\nspace. Therefore, the deep learning model under it lacks interpretability and\nignores uncertainty from the raw data. In this paper, we merge features of the\ndeep Bayesian learning framework with deep kernel learning to leverage the\nstrengths of both methods for more comprehensive uncertainty estimation.\nThrough a series of experiments on predicting the first incidence of heart\nfailure, diabetes and depression applied to large-scale electronic medical\nrecords, we demonstrate that our method is better at capturing uncertainty than\nboth Gaussian processes and deep Bayesian neural networks in terms of\nindicating data insufficiency and distinguishing true positive and false\npositive predictions, with a comparable generalisation performance.\nFurthermore, by assessing the accuracy and area under the receiver operating\ncharacteristic curve over the predictive probability, we show that our method\nis less susceptible to making overconfident predictions, especially for the\nminority class in imbalanced datasets. Finally, we demonstrate how uncertainty\ninformation derived by the model can inform risk factor analysis towards model\ninterpretability.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 10:36:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Li", "Yikuan", ""], ["Rao", "Shishir", ""], ["Hassaine", "Abdelaali", ""], ["Ramakrishnan", "Rema", ""], ["Zhu", "Yajie", ""], ["Canoy", "Dexter", ""], ["Salimi-Khorshidi", "Gholamreza", ""], ["Lukasiewicz", "Thomas", ""], ["Rahimi", "Kazem", ""]]}, {"id": "2003.10181", "submitter": "Kacper Kielak", "authors": "Kacper Kielak", "title": "Importance of using appropriate baselines for evaluation of\n  data-efficiency in deep reinforcement learning for Atari", "comments": "11 pages, 2 figures. Paper has been originally submitted to ICLR2020\n  on 25 Sep 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has seen great advancements in the past few\nyears. Nevertheless, the consensus among the RL community is that currently\nused methods, despite all their benefits, suffer from extreme data\ninefficiency, especially in the rich visual domains like Atari. To circumvent\nthis problem, novel approaches were introduced that often claim to be much more\nefficient than popular variations of the state-of-the-art DQN algorithm. In\nthis paper, however, we demonstrate that the newly proposed techniques simply\nused unfair baselines in their experiments. Namely, we show that the actual\nimprovement in the efficiency came from allowing the algorithm for more\ntraining updates for each data sample, and not from employing the new methods.\nBy allowing DQN to execute network updates more frequently we manage to reach\nsimilar or better results than the recently proposed advancement, often at a\nfraction of complexity and computational costs. Furthermore, based on the\noutcomes of the study, we argue that the agent similar to the modified DQN that\nis presented in this paper should be used as a baseline for any future work\naimed at improving sample efficiency of deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 10:59:04 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 17:00:42 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Kielak", "Kacper", ""]]}, {"id": "2003.10199", "submitter": "Rongzhou Chen", "authors": "Chen Miao, Shaohua Ma", "title": "Eigen component analysis: A quantum theory incorporated machine learning\n  technique to find linearly maximum separable components", "comments": "34 pages, 14 figures, and source code is available on\n  https://github.com/chenmiaomiao/eca/ and don't hesitate to contact us for\n  further information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a linear system, the response to a stimulus is often superposed by its\nresponses to other decomposed stimuli. In quantum mechanics, a state is the\nsuperposition of multiple eigenstates. Here, by taking advantage of the phase\ndifference, a common feature as we identified in data sets, we propose eigen\ncomponent analysis (ECA), an interpretable linear learning model that\nincorporates the principle of quantum mechanics into the design of algorithm\ndesign for feature extraction, classification, dictionary and deep learning,\nand adversarial generation, etc. The simulation of ECA, possessing a measurable\n$class\\text{-}label$ $\\mathcal{H}$, on a classical computer outperforms the\nexisting classical linear models. Eigen component analysis network (ECAN), a\nnetwork of concatenated ECA models, enhances ECA and gains the potential to be\nnot only integrated with nonlinear models, but also an interface for deep\nneural networks to implement on a quantum computer, by analogizing a data set\nas recordings of quantum states. Therefore, ECA and ECAN promise to expand the\nfeasibility of linear learning models, by adopting the strategy of quantum\nmachine learning to replace heavy nonlinear models with succinct linear\noperations in tackling complexity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:02:02 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 13:40:50 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 13:24:30 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Miao", "Chen", ""], ["Ma", "Shaohua", ""]]}, {"id": "2003.10200", "submitter": "Sebastian Pina-Otey", "authors": "Sebastian Pina-Otey and Thorsten Lux and Federico S\\'anchez and Vicens\n  Gaitan", "title": "Efficient sampling generation from explicit densities via Normalizing\n  Flows", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications, such as computing the expected value of different\nmagnitudes, sampling from a known probability density function, the target\ndensity, is crucial but challenging through the inverse transform. In these\ncases, rejection and importance sampling require suitable proposal densities,\nwhich can be evaluated and sampled from efficiently. We will present a method\nbased on normalizing flows, proposing a solution for the common problem of\nexploding reverse Kullback-Leibler divergence due to the target density having\nvalues of 0 in regions of the flow transformation. The performance of the\nmethod will be demonstrated using a multi-mode complex density function.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:03:18 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Pina-Otey", "Sebastian", ""], ["Lux", "Thorsten", ""], ["S\u00e1nchez", "Federico", ""], ["Gaitan", "Vicens", ""]]}, {"id": "2003.10229", "submitter": "Hei Long Chan", "authors": "Anthony Hei-Long Chan, Yishan Luo, Lin Shi, Ronald Lok-Ming Lui", "title": "QC-SPHRAM: Quasi-conformal Spherical Harmonics Based Geometric\n  Distortions on Hippocampal Surfaces for Early Detection of the Alzheimer's\n  Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a disease classification model, called the QC-SPHARM, for the\nearly detection of the Alzheimer's Disease (AD). The proposed QC-SPHARM can\ndistinguish between normal control (NC) subjects and AD patients, as well as\nbetween amnestic mild cognitive impairment (aMCI) patients having high\npossibility progressing into AD and those who do not. Using the spherical\nharmonics (SPHARM) based registration, hippocampal surfaces segmented from the\nADNI data are individually registered to a template surface constructed from\nthe NC subjects using SPHARM. Local geometric distortions of the deformation\nfrom the template surface to each subject are quantified in terms of\nconformality distortions and curvatures distortions. The measurements are\ncombined with the spherical harmonics coefficients and the total volume change\nof the subject from the template. Afterwards, a t-test based feature selection\nmethod incorporating the bagging strategy is applied to extract those local\nregions having high discriminating power of the two classes. The disease\ndiagnosis machine can therefore be built using the data under the Support\nVector Machine (SVM) setting. Using 110 NC subjects and 110 AD patients from\nthe ADNI database, the proposed algorithm achieves 85:2% testing accuracy on 80\nrandom samples as testing subjects, with the incorporation of surface geometry\nin the classification machine. Using 20 aMCI patients who has advanced to AD\nduring a two-year period and another 20 aMCI patients who remain non-AD for the\nnext two years, the algorithm achieves 81:2% accuracy using 10 randomly picked\nsubjects as testing data. Our proposed method is 6%-15% better than other\nclassification models without the incorporation of surface geometry. The\nresults demonstrate the advantages of using local geometric distortions as the\ndiscriminating criterion for early AD diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 02:08:41 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chan", "Anthony Hei-Long", ""], ["Luo", "Yishan", ""], ["Shi", "Lin", ""], ["Lui", "Ronald Lok-Ming", ""]]}, {"id": "2003.10248", "submitter": "Mohammad Etemad", "authors": "Mohammad Etemad, Zahra Etemad, Amilcar Soares, Vania Bogorny, Stan\n  Matwin, Luis Torgo", "title": "Wise Sliding Window Segmentation: A classification-aided approach for\n  trajectory segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large amounts of mobility data are being generated from many different\nsources, and several data mining methods have been proposed for this data. One\nof the most critical steps for trajectory data mining is segmentation. This\ntask can be seen as a pre-processing step in which a trajectory is divided into\nseveral meaningful consecutive sub-sequences. This process is necessary because\ntrajectory patterns may not hold in the entire trajectory but on trajectory\nparts. In this work, we propose a supervised trajectory segmentation algorithm,\ncalled Wise Sliding Window Segmentation (WS-II). It processes the trajectory\ncoordinates to find behavioral changes in space and time, generating an error\nsignal that is further used to train a binary classifier for segmenting\ntrajectory data. This algorithm is flexible and can be used in different\ndomains. We evaluate our method over three real datasets from different domains\n(meteorology, fishing, and individuals movements), and compare it with four\nother trajectory segmentation algorithms: OWS, GRASP-UTS, CB-SMoT, and SPD. We\nobserved that the proposed algorithm achieves the highest performance for all\ndatasets with statistically significant differences in terms of the harmonic\nmean of purity and coverage.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:55:40 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Etemad", "Mohammad", ""], ["Etemad", "Zahra", ""], ["Soares", "Amilcar", ""], ["Bogorny", "Vania", ""], ["Matwin", "Stan", ""], ["Torgo", "Luis", ""]]}, {"id": "2003.10271", "submitter": "Lijun Sun Mr", "authors": "Xinyu Chen, Jinming Yang and Lijun Sun", "title": "A Nonconvex Low-Rank Tensor Completion Model for Spatiotemporal Traffic\n  Data Imputation", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2020.102673", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity and missing data problems are very common in spatiotemporal traffic\ndata collected from various sensing systems. Making accurate imputation is\ncritical to many applications in intelligent transportation systems. In this\npaper, we formulate the missing data imputation problem in spatiotemporal\ntraffic data in a low-rank tensor completion (LRTC) framework and define a\nnovel truncated nuclear norm (TNN) on traffic tensors of\nlocation$\\times$day$\\times$time of day. In particular, we introduce an\nuniversal rate parameter to control the degree of truncation on all tensor\nmodes in the proposed LRTC-TNN model, and this allows us to better characterize\nthe hidden patterns in spatiotemporal traffic data. Based on the framework of\nthe Alternating Direction Method of Multipliers (ADMM), we present an efficient\nalgorithm to obtain the optimal solution for each variable. We conduct\nnumerical experiments on four spatiotemporal traffic data sets, and our results\nshow that the proposed LRTC-TNN model outperforms many state-of-the-art\nimputation models with missing rates/patterns. Moreover, the proposed model\nalso outperforms other baseline models in extreme missing scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 13:27:01 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:43:52 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Chen", "Xinyu", ""], ["Yang", "Jinming", ""], ["Sun", "Lijun", ""]]}, {"id": "2003.10280", "submitter": "Fernando Gama", "authors": "Fernando Gama, Ekaterina Tolstaya, Alejandro Ribeiro", "title": "Graph Neural Networks for Decentralized Controllers", "comments": "Submitted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems comprised of autonomous agents arise in many relevant\nproblems such as multi-agent robotics, smart grids, or smart cities.\nControlling these systems is of paramount importance to guarantee a successful\ndeployment. Optimal centralized controllers are readily available but face\nlimitations in terms of scalability and practical implementation. Optimal\ndecentralized controllers, on the other hand, are difficult to find. In this\npaper, we propose a framework using graph neural networks (GNNs) to learn\ndecentralized controllers from data. While GNNs are naturally distributed\narchitectures, making them perfectly suited for the task, we adapt them to\nhandle delayed communications as well. Furthermore, they are equivariant and\nstable, leading to good scalability and transferability properties. The problem\nof flocking is explored to illustrate the potential of GNNs in learning\ndecentralized controllers.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 13:51:18 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 13:54:48 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gama", "Fernando", ""], ["Tolstaya", "Ekaterina", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2003.10287", "submitter": "Ana Fern\\'andez del R\\'io", "authors": "Ana Fern\\'andez del R\\'io, Anna Guitart and \\'Africa Peri\\'a\\~nez", "title": "A Time Series Approach To Player Churn and Conversion in Videogames", "comments": "Accepted for publication in IOS Press Intelligent Data Analysis", "journal-ref": "Intelligent Data Analysis, vol. 25, no. 1, pp. 177-203, 2021", "doi": "10.3233/IDA-194940", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Players of a free-to-play game are divided into three main groups: non-paying\nactive users, paying active users and inactive users. A State Space time series\napproach is then used to model the daily conversion rates between the different\ngroups, i.e., the probability of transitioning from one group to another. This\nallows, not only for predictions on how these rates are to evolve, but also for\na deeper understanding of the impact that in-game planning and calendar effects\nhave. It is also used in this work for the detection of marketing and promotion\ncampaigns about which no information is available. In particular, two different\nState Space formulations are considered and compared: an Autoregressive\nIntegrated Moving Average process and an Unobserved Components approach, in\nboth cases with a linear regression to explanatory variables. Both yield very\nclose estimations for covariate parameters, producing forecasts with similar\nperformances for most transition rates. While the Unobserved Components\napproach is more robust and needs less human intervention in regards to model\ndefinition, it produces significantly worse forecasts for non-paying user\nabandonment probability. More critically, it also fails to detect a plausible\nmarketing and promotion campaign scenario.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 20:16:52 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Guitart", "Anna", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "2003.10296", "submitter": "Pramod Rao", "authors": "Thong Nguyen, Duy Nguyen, Pramod Rao", "title": "Adaptive Name Entity Recognition under Highly Unbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For several purposes in Natural Language Processing (NLP), such as\nInformation Extraction, Sentiment Analysis or Chatbot, Named Entity Recognition\n(NER) holds an important role as it helps to determine and categorize entities\nin text into predefined groups such as the names of persons, locations,\nquantities, organizations or percentages, etc. In this report, we present our\nexperiments on a neural architecture composed of a Conditional Random Field\n(CRF) layer stacked on top of a Bi-directional LSTM (BI-LSTM) layer for solving\nNER tasks. Besides, we also employ a fusion input of embedding vectors (Glove,\nBERT), which are pre-trained on the huge corpus to boost the generalization\ncapacity of the model. Unfortunately, due to the heavy unbalanced distribution\ncross-training data, both approaches just attained a bad performance on less\ntraining samples classes. To overcome this challenge, we introduce an add-on\nclassification model to split sentences into two different sets: Weak and\nStrong classes and then designing a couple of Bi-LSTM-CRF models properly to\noptimize performance on each set. We evaluated our models on the test set and\ndiscovered that our method can improve performance for Weak classes\nsignificantly by using a very small data set (approximately 0.45\\%) compared to\nthe rest classes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 06:56:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Nguyen", "Thong", ""], ["Nguyen", "Duy", ""], ["Rao", "Pramod", ""]]}, {"id": "2003.10303", "submitter": "David Conal Higgins", "authors": "David Higgins and Vince I. Madai", "title": "From Bit To Bedside: A Practical Framework For Artificial Intelligence\n  Product Development In Healthcare", "comments": "30 pages, 4 figures", "journal-ref": "Advanced Intelligent Systems, 2020, 2000052", "doi": "10.1002/aisy.202000052", "report-no": null, "categories": "cs.CY cs.AI cs.HC stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial Intelligence (AI) in healthcare holds great potential to expand\naccess to high-quality medical care, whilst reducing overall systemic costs.\nDespite hitting the headlines regularly and many publications of\nproofs-of-concept, certified products are failing to breakthrough to the\nclinic. AI in healthcare is a multi-party process with deep knowledge required\nin multiple individual domains. The lack of understanding of the specific\nchallenges in the domain is, therefore, the major contributor to the failure to\ndeliver on the big promises. Thus, we present a decision perspective framework,\nfor the development of AI-driven biomedical products, from conception to market\nlaunch. Our framework highlights the risks, objectives and key results which\nare typically required to proceed through a three-phase process to the market\nlaunch of a validated medical AI product. We focus on issues related to\nClinical validation, Regulatory affairs, Data strategy and Algorithmic\ndevelopment. The development process we propose for AI in healthcare software\nstrongly diverges from modern consumer software development processes. We\nhighlight the key time points to guide founders, investors and key stakeholders\nthroughout their relevant part of the process. Our framework should be seen as\na template for innovation frameworks, which can be used to coordinate team\ncommunications and responsibilities towards a reasonable product development\nroadmap, thus unlocking the potential of AI in medicine.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:42:18 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Higgins", "David", ""], ["Madai", "Vince I.", ""]]}, {"id": "2003.10312", "submitter": "Sina Baghal", "authors": "Sina Baghal, Courtney Paquette, Stephen A. Vavasis", "title": "A termination criterion for stochastic gradient descent for binary\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new, simple, and computationally inexpensive termination test\nfor constant step-size stochastic gradient descent (SGD) applied to binary\nclassification on the logistic and hinge loss with homogeneous linear\npredictors. Our theoretical results support the effectiveness of our stopping\ncriterion when the data is Gaussian distributed. This presence of noise allows\nfor the possibility of non-separable data. We show that our test terminates in\na finite number of iterations and when the noise in the data is not too large,\nthe expected classifier at termination nearly minimizes the probability of\nmisclassification. Finally, numerical experiments indicate for both real and\nsynthetic data sets that our termination test exhibits a good degree of\npredictability on accuracy and running time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:00:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Baghal", "Sina", ""], ["Paquette", "Courtney", ""], ["Vavasis", "Stephen A.", ""]]}, {"id": "2003.10339", "submitter": "Dan Kushnir", "authors": "Dan Kushnir, Luca Venturi", "title": "Diffusion-based Deep Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable performance of deep neural networks depends on the\navailability of massive labeled data. To alleviate the load of data annotation,\nactive deep learning aims to select a minimal set of training points to be\nlabelled which yields maximal model accuracy. Most existing approaches\nimplement either an `exploration'-type selection criterion, which aims at\nexploring the joint distribution of data and labels, or a `refinement'-type\ncriterion which aims at localizing the detected decision boundaries. We propose\na versatile and efficient criterion that automatically switches from\nexploration to refinement when the distribution has been sufficiently mapped.\nOur criterion relies on a process of diffusing the existing label information\nover a graph constructed from the hidden representation of the data set as\nprovided by the neural network. This graph representation captures the\nintrinsic geometry of the approximated labeling function. The diffusion-based\ncriterion is shown to be advantageous as it outperforms existing criteria for\ndeep active learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:53:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Kushnir", "Dan", ""], ["Venturi", "Luca", ""]]}, {"id": "2003.10373", "submitter": "Shen Wang", "authors": "Dairui Liu, Jingxiang Sun, Shen Wang", "title": "BusTime: Which is the Right Prediction Model for My Bus Arrival Time?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of big data technologies, many smart transportation\napplications have been rapidly developed in recent years including bus arrival\ntime predictions. This type of applications help passengers to plan trips more\nefficiently without wasting unpredictable amount of waiting time at bus stops.\nMany studies focus on improving the prediction accuracy of various machine\nlearning and statistical models, while much less work demonstrate their\napplicability of being deployed and used in realistic urban settings. This\npaper tries to fill this gap by proposing a general and practical evaluation\nframework for analysing various widely used prediction models (i.e. delay,\nk-nearest-neighbour, kernel regression, additive model, and recurrent neural\nnetwork using long short term memory) for bus arrival time. In particular, this\nframework contains a raw bus GPS data pre-processing method that needs much\nless number of input data points while still maintain satisfactory prediction\nresults. This pre-processing method enables various models to predict arrival\ntime at bus stops only, by using a KD-tree based nearest point search method.\nBased on this framework, using raw bus GPS dataset in different scales from the\ncity of Dublin, Ireland, we also present preliminary results for city managers\nby analysing the practical strengths and weaknesses in both training and\npredicting stages of commonly used prediction models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 17:03:36 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Dairui", ""], ["Sun", "Jingxiang", ""], ["Wang", "Shen", ""]]}, {"id": "2003.10374", "submitter": "Christian A. Naesseth", "authors": "Christian A. Naesseth and Fredrik Lindsten and David Blei", "title": "Markovian Score Climbing: Variational Inference with KL(p||q)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern variational inference (VI) uses stochastic gradients to avoid\nintractable expectations, enabling large-scale probabilistic inference in\ncomplex models. VI posits a family of approximating distributions q and then\nfinds the member of that family that is closest to the exact posterior p.\nTraditionally, VI algorithms minimize the \"exclusive Kullback-Leibler (KL)\"\nKL(q || p), often for computational convenience. Recent research, however, has\nalso focused on the \"inclusive KL\" KL(p || q), which has good statistical\nproperties that makes it more appropriate for certain inference problems. This\npaper develops a simple algorithm for reliably minimizing the inclusive KL\nusing stochastic gradients with vanishing bias. This method, which we call\nMarkovian score climbing (MSC), converges to a local optimum of the inclusive\nKL. It does not suffer from the systematic errors inherent in existing methods,\nsuch as Reweighted Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which\nlead to bias in their final estimates. We illustrate convergence on a toy model\nand demonstrate the utility of MSC on Bayesian probit regression for\nclassification as well as a stochastic volatility model for financial data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 16:38:10 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 19:46:38 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Naesseth", "Christian A.", ""], ["Lindsten", "Fredrik", ""], ["Blei", "David", ""]]}, {"id": "2003.10375", "submitter": "Xuefei Ning", "authors": "Xuefei Ning, Guangjun Ge, Wenshuo Li, Zhenhua Zhu, Yin Zheng, Xiaoming\n  Chen, Zhen Gao, Yu Wang and Huazhong Yang", "title": "FTT-NAS: Discovering Fault-Tolerant Convolutional Neural Architecture", "comments": "24 pages; to appear in TODAES", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast evolvement of embedded deep-learning computing systems,\napplications powered by deep learning are moving from the cloud to the edge.\nWhen deploying neural networks (NNs) onto the devices under complex\nenvironments, there are various types of possible faults: soft errors caused by\ncosmic radiation and radioactive impurities, voltage instability, aging,\ntemperature variations, and malicious attackers. Thus the safety risk of\ndeploying NNs is now drawing much attention. In this paper, after the analysis\nof the possible faults in various types of NN accelerators, we formalize and\nimplement various fault models from the algorithmic perspective. We propose\nFault-Tolerant Neural Architecture Search (FT-NAS) to automatically discover\nconvolutional neural network (CNN) architectures that are reliable to various\nfaults in nowadays devices. Then we incorporate fault-tolerant training (FTT)\nin the search process to achieve better results, which is referred to as\nFTT-NAS. Experiments on CIFAR-10 show that the discovered architectures\noutperform other manually designed baseline architectures significantly, with\ncomparable or fewer floating-point operations (FLOPs) and parameters.\nSpecifically, with the same fault settings, F-FTT-Net discovered under the\nfeature fault model achieves an accuracy of 86.2% (VS. 68.1% achieved by\nMobileNet-V2), and W-FTT-Net discovered under the weight fault model achieves\nan accuracy of 69.6% (VS. 60.8% achieved by ResNet-20). By inspecting the\ndiscovered architectures, we find that the operation primitives, the weight\nquantization range, the capacity of the model, and the connection pattern have\ninfluences on the fault resilience capability of NN models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 17:17:14 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 16:15:18 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ning", "Xuefei", ""], ["Ge", "Guangjun", ""], ["Li", "Wenshuo", ""], ["Zhu", "Zhenhua", ""], ["Zheng", "Yin", ""], ["Chen", "Xiaoming", ""], ["Gao", "Zhen", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2003.10381", "submitter": "Oliver Scheel", "authors": "Alessandro Berlati, Oliver Scheel, Luigi Di Stefano, Federico Tombari", "title": "Ambiguity in Sequential Data: Predicting Uncertain Futures with\n  Recurrent Models", "comments": null, "journal-ref": "Robotics and Automation Letters 2020 (RA-L)", "doi": "10.1109/LRA.2020.2974716", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambiguity is inherently present in many machine learning tasks, but\nespecially for sequential models seldom accounted for, as most only output a\nsingle prediction. In this work we propose an extension of the Multiple\nHypothesis Prediction (MHP) model to handle ambiguous predictions with\nsequential data, which is of special importance, as often multiple futures are\nequally likely. Our approach can be applied to the most common recurrent\narchitectures and can be used with any loss function. Additionally, we\nintroduce a novel metric for ambiguous problems, which is better suited to\naccount for uncertainties and coincides with our intuitive understanding of\ncorrectness in the presence of multiple labels. We test our method on several\nexperiments and across diverse tasks dealing with time series data, such as\ntrajectory forecasting and maneuver prediction, achieving promising results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 09:15:42 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Berlati", "Alessandro", ""], ["Scheel", "Oliver", ""], ["Di Stefano", "Luigi", ""], ["Tombari", "Federico", ""]]}, {"id": "2003.10386", "submitter": "Ali Payani", "authors": "Ali Payani and Faramarz Fekri", "title": "Incorporating Relational Background Knowledge into Reinforcement\n  Learning via Differentiable Inductive Logic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational Reinforcement Learning (RRL) can offers various desirable\nfeatures. Most importantly, it allows for incorporating expert knowledge into\nthe learning, and hence leading to much faster learning and better\ngeneralization compared to the standard deep reinforcement learning. However,\nmost of the existing RRL approaches are either incapable of incorporating\nexpert background knowledge (e.g., in the form of explicit predicate language)\nor are not able to learn directly from non-relational data such as image. In\nthis paper, we propose a novel deep RRL based on a differentiable Inductive\nLogic Programming (ILP) that can effectively learn relational information from\nimage and present the state of the environment as first order logic predicates.\nAdditionally, it can take the expert background knowledge and incorporate it\ninto the learning problem using appropriate predicates. The differentiable ILP\nallows an end to end optimization of the entire framework for learning the\npolicy in RRL. We show the efficacy of this novel RRL framework using\nenvironments such as BoxWorld, GridWorld as well as relational reasoning for\nthe Sort-of-CLEVR dataset.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 16:56:11 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Payani", "Ali", ""], ["Fekri", "Faramarz", ""]]}, {"id": "2003.10388", "submitter": "Xxxx Lin Lin", "authors": "Yankun Ren and Jianbin Lin and Siliang Tang and Jun Zhou and Shuang\n  Yang and Yuan Qi and Xiang Ren", "title": "Generating Natural Language Adversarial Examples on a Large Scale with\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today text classification models have been widely used. However, these\nclassifiers are found to be easily fooled by adversarial examples. Fortunately,\nstandard attacking methods generate adversarial texts in a pair-wise way, that\nis, an adversarial text can only be created from a real-world text by replacing\na few words. In many applications, these texts are limited in numbers,\ntherefore their corresponding adversarial examples are often not diverse enough\nand sometimes hard to read, thus can be easily detected by humans and cannot\ncreate chaos at a large scale. In this paper, we propose an end to end solution\nto efficiently generate adversarial texts from scratch using generative models,\nwhich are not restricted to perturbing the given texts. We call it unrestricted\nadversarial text generation. Specifically, we train a conditional variational\nautoencoder (VAE) with an additional adversarial loss to guide the generation\nof adversarial examples. Moreover, to improve the validity of adversarial\ntexts, we utilize discrimators and the training framework of generative\nadversarial networks (GANs) to make adversarial texts consistent with real\ndata. Experimental results on sentiment analysis demonstrate the scalability\nand efficiency of our method. It can attack text classification models with a\nhigher success rate than existing methods, and provide acceptable quality for\nhumans in the meantime.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:21:35 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ren", "Yankun", ""], ["Lin", "Jianbin", ""], ["Tang", "Siliang", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""], ["Ren", "Xiang", ""]]}, {"id": "2003.10392", "submitter": "Lemeng Wu", "authors": "Lemeng Wu, Mao Ye, Qi Lei, Jason D. Lee, Qiang Liu", "title": "Steepest Descent Neural Architecture Optimization: Escaping Local\n  Optimum with Signed Neural Splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient and principled neural architecture optimization methods\nis a critical challenge of modern deep learning. Recently, Liu et al.[19]\nproposed a splitting steepest descent (S2D) method that jointly optimizes the\nneural parameters and architectures based on progressively growing network\nstructures by splitting neurons into multiple copies in a steepest descent\nfashion. However, S2D suffers from a local optimality issue when all the\nneurons become \"splitting stable\", a concept akin to local stability in\nparametric optimization. In this work, we develop a significant and surprising\nextension of the splitting descent framework that addresses the local\noptimality issue. The idea is to observe that the original S2D is unnecessarily\nrestricted to splitting neurons into positive weighted copies. By simply\nallowing both positive and negative weights during splitting, we can eliminate\nthe appearance of splitting stability in S2D and hence escape the local optima\nto obtain better performance. By incorporating signed splittings, we\nsignificantly extend the optimization power of splitting steepest descent both\ntheoretically and empirically. We verify our method on various challenging\nbenchmarks such as CIFAR-100, ImageNet and ModelNet40, on which we outperform\nS2D and other advanced methods on learning accurate and energy-efficient neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:09:27 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 03:58:24 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 23:43:46 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 21:31:58 GMT"}, {"version": "v5", "created": "Mon, 21 Jun 2021 01:07:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wu", "Lemeng", ""], ["Ye", "Mao", ""], ["Lei", "Qi", ""], ["Lee", "Jason D.", ""], ["Liu", "Qiang", ""]]}, {"id": "2003.10396", "submitter": "Christopher H Bennett", "authors": "Christopher H. Bennett, Ryan Dellana, T. Patrick Xiao, Ben Feinberg,\n  Sapan Agarwal, Suma Cardwell, Matthew J. Marinella, William Severa, Brad\n  Aimone", "title": "Evaluating complexity and resilience trade-offs in emerging memory\n  inference machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic-style inference only works well if limited hardware resources\nare maximized properly, e.g. accuracy continues to scale with parameters and\ncomplexity in the face of potential disturbance. In this work, we use realistic\ncrossbar simulations to highlight that compact implementations of deep neural\nnetworks are unexpectedly susceptible to collapse from multiple system\ndisturbances. Our work proposes a middle path towards high performance and\nstrong resilience utilizing the Mosaics framework, and specifically by re-using\nsynaptic connections in a recurrent neural network implementation that\npossesses a natural form of noise-immunity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:40:08 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bennett", "Christopher H.", ""], ["Dellana", "Ryan", ""], ["Xiao", "T. Patrick", ""], ["Feinberg", "Ben", ""], ["Agarwal", "Sapan", ""], ["Cardwell", "Suma", ""], ["Marinella", "Matthew J.", ""], ["Severa", "William", ""], ["Aimone", "Brad", ""]]}, {"id": "2003.10397", "submitter": "Charles Frye", "authors": "Charles G. Frye, James Simon, Neha S. Wadia, Andrew Ligeralde, Michael\n  R. DeWeese, Kristofer E. Bouchard", "title": "Critical Point-Finding Methods Reveal Gradient-Flat Regions of Deep\n  Network Losses", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that the loss functions of deep neural networks are highly\nnon-convex, gradient-based optimization algorithms converge to approximately\nthe same performance from many random initial points. One thread of work has\nfocused on explaining this phenomenon by characterizing the local curvature\nnear critical points of the loss function, where the gradients are near zero,\nand demonstrating that neural network losses enjoy a no-bad-local-minima\nproperty and an abundance of saddle points. We report here that the methods\nused to find these putative critical points suffer from a bad local minima\nproblem of their own: they often converge to or pass through regions where the\ngradient norm has a stationary point. We call these gradient-flat regions,\nsince they arise when the gradient is approximately in the kernel of the\nHessian, such that the loss is locally approximately linear, or flat, in the\ndirection of the gradient. We describe how the presence of these regions\nnecessitates care in both interpreting past results that claimed to find\ncritical points of neural network losses and in designing second-order methods\nfor optimizing neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:16:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Frye", "Charles G.", ""], ["Simon", "James", ""], ["Wadia", "Neha S.", ""], ["Ligeralde", "Andrew", ""], ["DeWeese", "Michael R.", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "2003.10409", "submitter": "Aukosh Jagannath", "authors": "Gerard Ben Arous, Reza Gheissari, Aukosh Jagannath", "title": "Online stochastic gradient descent on non-convex losses from\n  high-dimensional inference", "comments": "final version to appear at Jour. Mach. Learn. Res$.$", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is a popular algorithm for optimization\nproblems arising in high-dimensional inference tasks. Here one produces an\nestimator of an unknown parameter from independent samples of data by\niteratively optimizing a loss function. This loss function is random and often\nnon-convex. We study the performance of the simplest version of SGD, namely\nonline SGD, from a random start in the setting where the parameter space is\nhigh-dimensional.\n  We develop nearly sharp thresholds for the number of samples needed for\nconsistent estimation as one varies the dimension. Our thresholds depend only\non an intrinsic property of the population loss which we call the information\nexponent. In particular, our results do not assume uniform control on the loss\nitself, such as convexity or uniform derivative bounds. The thresholds we\nobtain are polynomial in the dimension and the precise exponent depends\nexplicitly on the information exponent. As a consequence of our results, we\nfind that except for the simplest tasks, almost all of the data is used simply\nin the initial search phase to obtain non-trivial correlation with the ground\ntruth. Upon attaining non-trivial correlation, the descent is rapid and\nexhibits law of large numbers type behavior.\n  We illustrate our approach by applying it to a wide set of inference tasks\nsuch as phase retrieval, and parameter estimation for generalized linear\nmodels, online PCA, and spiked tensor models, as well as to supervised learning\nfor single-layer networks with general activation functions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:34:06 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 04:22:38 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 19:00:50 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 17:56:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Arous", "Gerard Ben", ""], ["Gheissari", "Reza", ""], ["Jagannath", "Aukosh", ""]]}, {"id": "2003.10422", "submitter": "Anastasiia Koloskova", "authors": "Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi,\n  Sebastian U. Stich", "title": "A Unified Theory of Decentralized SGD with Changing Topology and Local\n  Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized stochastic optimization methods have gained a lot of attention\nrecently, mainly because of their cheap per iteration cost, data locality, and\ntheir communication-efficiency. In this paper we introduce a unified\nconvergence analysis that covers a large variety of decentralized SGD methods\nwhich so far have required different intuitions, have different applications,\nand which have been developed separately in various communities.\n  Our algorithmic framework covers local SGD updates and synchronous and\npairwise gossip updates on adaptive network topology. We derive universal\nconvergence rates for smooth (convex and non-convex) problems and the rates\ninterpolate between the heterogeneous (non-identically distributed data) and\niid-data settings, recovering linear convergence rates in many special cases,\nfor instance for over-parametrized models. Our proofs rely on weak assumptions\n(typically improving over prior work in several aspects) and recover (and\nimprove) the best known complexity results for a host of important scenarios,\nsuch as for instance coorperative SGD and federated averaging (local SGD).\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:49:15 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:24:03 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 14:07:36 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Koloskova", "Anastasia", ""], ["Loizou", "Nicolas", ""], ["Boreiri", "Sadra", ""], ["Jaggi", "Martin", ""], ["Stich", "Sebastian U.", ""]]}, {"id": "2003.10423", "submitter": "Xiaolong Wang", "authors": "Qian Long, Zihan Zhou, Abhibav Gupta, Fei Fang, Yi Wu, Xiaolong Wang", "title": "Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement\n  Learning", "comments": "The project page is https://sites.google.com/view/epciclr2020 .The\n  source code is released at https://github.com/qian18long/epciclr2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent games, the complexity of the environment can grow\nexponentially as the number of agents increases, so it is particularly\nchallenging to learn good policies when the agent population is large. In this\npaper, we introduce Evolutionary Population Curriculum (EPC), a curriculum\nlearning paradigm that scales up Multi-Agent Reinforcement Learning (MARL) by\nprogressively increasing the population of training agents in a stage-wise\nmanner. Furthermore, EPC uses an evolutionary approach to fix an objective\nmisalignment issue throughout the curriculum: agents successfully trained in an\nearly stage with a small population are not necessarily the best candidates for\nadapting to later stages with scaled populations. Concretely, EPC maintains\nmultiple sets of agents in each stage, performs mix-and-match and fine-tuning\nover these sets and promotes the sets of agents with the best adaptability to\nthe next stage. We implement EPC on a popular MARL algorithm, MADDPG, and\nempirically show that our approach consistently outperforms baselines by a\nlarge margin as the number of agents grows exponentially.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:49:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Long", "Qian", ""], ["Zhou", "Zihan", ""], ["Gupta", "Abhibav", ""], ["Fang", "Fei", ""], ["Wu", "Yi", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2003.10443", "submitter": "Subha Maity", "authors": "Subha Maity, Yuekai Sun, and Moulinath Banerjee", "title": "Minimax optimal approaches to the label shift problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimax rates of convergence in the label shift problem. In addition\nto the usual setting in which the learner only has access to unlabeled examples\nfrom the target domain, we also consider the setting in which a small number of\nlabeled examples from the target domain are available to the learner. Our study\nreveals a difference in the difficulty of the label shift problem in the two\nsettings. We attribute this difference to the availability of data from the\ntarget domain to estimate the class conditional distributions in the latter\nsetting. We also show that a distributional matching approach is minimax\nrate-optimal in the former setting.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:28:26 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 23:46:06 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Maity", "Subha", ""], ["Sun", "Yuekai", ""], ["Banerjee", "Moulinath", ""]]}, {"id": "2003.10482", "submitter": "Feliks Hibraj", "authors": "Feliks Hibraj, Marcello Pelillo, Saverio Salzo, Massimiliano Pontil", "title": "Efficient Tensor Kernel methods for sparse regression", "comments": "M.Sc. Thesis introducing a novel layout to efficiently store\n  symmetric tensor data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, classical kernel methods have been extended by the introduction of\nsuitable tensor kernels so to promote sparsity in the solution of the\nunderlying regression problem. Indeed, they solve an lp-norm regularization\nproblem, with p=m/(m-1) and m even integer, which happens to be close to a\nlasso problem. However, a major drawback of the method is that storing tensors\nrequires a considerable amount of memory, ultimately limiting its\napplicability. In this work we address this problem by proposing two advances.\nFirst, we directly reduce the memory requirement, by intriducing a new and more\nefficient layout for storing the data. Second, we use a Nystrom-type\nsubsampling approach, which allows for a training phase with a smaller number\nof data points, so to reduce the computational cost. Experiments, both on\nsynthetic and read datasets, show the effectiveness of the proposed\nimprovements. Finally, we take case of implementing the cose in C++ so to\nfurther speed-up the computation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:26:56 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Hibraj", "Feliks", ""], ["Pelillo", "Marcello", ""], ["Salzo", "Saverio", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "2003.10485", "submitter": "Alexander Suh", "authors": "Alexander Suh and Yuval Timen", "title": "Creating Synthetic Datasets via Evolution for Neural Program Synthesis", "comments": "10 pages, 0 figures, submitted to ICML 2020; experiments on Karel\n  domain added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis is the task of automatically generating a program\nconsistent with a given specification. A natural way to specify programs is to\nprovide examples of desired input-output behavior, and many current program\nsynthesis approaches have achieved impressive results after training on\nrandomly generated input-output examples. However, recent work has discovered\nthat some of these approaches generalize poorly to data distributions different\nfrom that of the randomly generated examples. We show that this problem applies\nto other state-of-the-art approaches as well and that current methods to\ncounteract this problem are insufficient. We then propose a new, adversarial\napproach to control the bias of synthetic data distributions and show that it\noutperforms current approaches.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:34:15 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 01:04:06 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Suh", "Alexander", ""], ["Timen", "Yuval", ""]]}, {"id": "2003.10523", "submitter": "Eren Can K{\\i}z{\\i}lda\\u{g}", "authors": "Matt Emschwiller, David Gamarnik, Eren C. K{\\i}z{\\i}lda\\u{g}, Ilias\n  Zadik", "title": "Neural Networks and Polynomial Regression. Demystifying the\n  Overparametrization Phenomena", "comments": "59 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of neural network models, overparametrization refers to the\nphenomena whereby these models appear to generalize well on the unseen data,\neven though the number of parameters significantly exceeds the sample sizes,\nand the model perfectly fits the in-training data. A conventional explanation\nof this phenomena is based on self-regularization properties of algorithms used\nto train the data. In this paper we prove a series of results which provide a\nsomewhat diverging explanation. Adopting a teacher/student model where the\nteacher network is used to generate the predictions and student network is\ntrained on the observed labeled data, and then tested on out-of-sample data, we\nshow that any student network interpolating the data generated by a teacher\nnetwork generalizes well, provided that the sample size is at least an explicit\nquantity controlled by data dimension and approximation guarantee alone,\nregardless of the number of internal nodes of either teacher or student\nnetwork.\n  Our claim is based on approximating both teacher and student networks by\npolynomial (tensor) regression models with degree depending on the desired\naccuracy and network depth only. Such a parametrization notably does not depend\non the number of internal nodes. Thus a message implied by our results is that\nparametrizing wide neural networks by the number of hidden nodes is misleading,\nand a more fitting measure of parametrization complexity is the number of\nregression coefficients associated with tensorized data. In particular, this\nsomewhat reconciles the generalization ability of neural networks with more\nclassical statistical notions of data complexity and generalization bounds. Our\nempirical results on MNIST and Fashion-MNIST datasets indeed confirm that\ntensorized regression achieves a good out-of-sample performance, even when the\ndegree of the tensor is at most two.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:09:31 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Emschwiller", "Matt", ""], ["Gamarnik", "David", ""], ["K\u0131z\u0131lda\u011f", "Eren C.", ""], ["Zadik", "Ilias", ""]]}, {"id": "2003.10536", "submitter": "Chris Cummins", "authors": "Chris Cummins, Zacharias V. Fisches, Tal Ben-Nun, Torsten Hoefler,\n  Hugh Leather", "title": "ProGraML: Graph-based Deep Learning for Program Optimization and\n  Analysis", "comments": "20 pages, author preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing complexity of computing systems places a tremendous burden on\noptimizing compilers, requiring ever more accurate and aggressive\noptimizations. Machine learning offers significant benefits for constructing\noptimization heuristics but there remains a gap between what state-of-the-art\nmethods achieve and the performance of an optimal heuristic. Closing this gap\nrequires improvements in two key areas: a representation that accurately\ncaptures the semantics of programs, and a model architecture with sufficient\nexpressiveness to reason about this representation.\n  We introduce ProGraML - Program Graphs for Machine Learning - a novel\ngraph-based program representation using a low level, language agnostic, and\nportable format; and machine learning models capable of performing complex\ndownstream tasks over these graphs. The ProGraML representation is a directed\nattributed multigraph that captures control, data, and call relations, and\nsummarizes instruction and operand types and ordering. Message Passing Neural\nNetworks propagate information through this structured representation, enabling\nwhole-program or per-vertex classification tasks.\n  ProGraML provides a general-purpose program representation that equips\nlearnable models to perform the types of program analysis that are fundamental\nto optimization. To this end, we evaluate the performance of our approach first\non a suite of traditional compiler analysis tasks: control flow reachability,\ndominator trees, data dependencies, variable liveness, and common subexpression\ndetection. On a benchmark dataset of 250k LLVM-IR files covering six source\nprogramming languages, ProGraML achieves an average 94.0 F1 score,\nsignificantly outperforming the state-of-the-art approaches. We then apply our\napproach to two high-level tasks - heterogeneous device mapping and program\nclassification - setting new state-of-the-art performance in both.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:27:00 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Cummins", "Chris", ""], ["Fisches", "Zacharias V.", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Leather", "Hugh", ""]]}, {"id": "2003.10538", "submitter": "Rong Du", "authors": "Rong Du, Sindri Magn\\'usson, Carlo Fischione", "title": "The Internet of Things as a Deep Neural Network", "comments": "3 figures, 1 table, 15 pages; The paper is under review in IEEE\n  Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in the Internet of Things (IoT) is field monitoring, where\nmultiple IoT nodes take measurements and communicate them to the base station\nor the cloud for processing, inference, and analysis. This communication\nbecomes costly when the measurements are high-dimensional (e.g., videos or\ntime-series data). The IoT networks with limited bandwidth and low power\ndevices may not be able to support such frequent transmissions with high data\nrates. To ensure communication efficiency, this article proposes to model the\nmeasurement compression at IoT nodes and the inference at the base station or\ncloud as a deep neural network (DNN). We propose a new framework where the data\nto be transmitted from nodes are the intermediate outputs of a layer of the\nDNN. We show how to learn the model parameters of the DNN and study the\ntrade-off between the communication rate and the inference accuracy. The\nexperimental results show that we can save approximately 96% transmissions with\nonly a degradation of 2.5% in inference accuracy. Our findings have the\npotentiality to enable many new IoT data analysis applications generating large\namount of measurements.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:36:16 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Du", "Rong", ""], ["Magn\u00fasson", "Sindri", ""], ["Fischione", "Carlo", ""]]}, {"id": "2003.10540", "submitter": "Evgeny Burnaev", "authors": "Ekaterina Artemova and Amir Bakarov and Aleksey Artemov and Evgeny\n  Burnaev and Maxim Sharaev", "title": "Data-driven models and computational tools for neurolinguistics: a\n  language technology perspective", "comments": "37 pages, 1 figure", "journal-ref": "Journal of Cognitive Science, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, our focus is the connection and influence of language\ntechnologies on the research in neurolinguistics. We present a review of brain\nimaging-based neurolinguistic studies with a focus on the natural language\nrepresentations, such as word embeddings and pre-trained language models.\nMutual enrichment of neurolinguistics and language technologies leads to\ndevelopment of brain-aware natural language representations. The importance of\nthis research area is emphasized by medical applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:41:51 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Artemova", "Ekaterina", ""], ["Bakarov", "Amir", ""], ["Artemov", "Aleksey", ""], ["Burnaev", "Evgeny", ""], ["Sharaev", "Maxim", ""]]}, {"id": "2003.10550", "submitter": "Amrit Singh Bedi", "authors": "Amrit Singh Bedi, Dheeraj Peddireddy, Vaneet Aggarwal, Alec Koppel", "title": "Sublinear Regret and Belief Complexity in Gaussian Process Bandits via\n  Information Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a framework for global search via maximum a\nposteriori updates rather than simulated annealing, and has gained prominence\nfor decision-making under uncertainty. In this work, we cast Bayesian\noptimization as a multi-armed bandit problem, where the payoff function is\nsampled from a Gaussian process (GP). Further, we focus on action selections\nvia upper confidence bound (UCB) or expected improvement (EI) due to their\nprevalent use in practice. Prior works using GPs for bandits cannot allow the\niteration horizon $T$ to be large, as the complexity of computing the posterior\nparameters scales cubically with the number of past observations. To circumvent\nthis computational burden, we propose a simple statistical test: only\nincorporate an action into the GP posterior when its conditional entropy\nexceeds an $\\epsilon$ threshold. Doing so permits us to derive sublinear regret\nbounds of GP bandit algorithms up to factors depending on the compression\nparameter $\\epsilon$ for both discrete and continuous action sets. Moreover,\nthe complexity of the GP posterior remains provably finite and depends on the\nShannon capacity of the observation space. Experimentally, we observe state of\nthe art accuracy and complexity tradeoffs for GP bandit algorithms applied to\nglobal optimization, suggesting the merits of compressed GPs in bandit\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 21:05:15 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 01:16:04 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Bedi", "Amrit Singh", ""], ["Peddireddy", "Dheeraj", ""], ["Aggarwal", "Vaneet", ""], ["Koppel", "Alec", ""]]}, {"id": "2003.10551", "submitter": "Li-Wei Lehman", "authors": "Rui Li, Zach Shahn, Jun Li, Mingyu Lu, Prithwish Chakraborty, Daby\n  Sow, Mohamed Ghalwash, Li-wei H. Lehman", "title": "G-Net: A Deep Learning Approach to G-computation for Counterfactual\n  Outcome Prediction Under Dynamic Treatment Regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual prediction is a fundamental task in decision-making.\nG-computation is a method for estimating expected counterfactual outcomes under\ndynamic time-varying treatment strategies. Existing G-computation\nimplementations have mostly employed classical regression models with limited\ncapacity to capture complex temporal and nonlinear dependence structures. This\npaper introduces G-Net, a novel sequential deep learning framework for\nG-computation that can handle complex time series data while imposing minimal\nmodeling assumptions and provide estimates of individual or population-level\ntime varying treatment effects. We evaluate alternative G-Net implementations\nusing realistically complex temporal simulated data obtained from CVSim, a\nmechanistic model of the cardiovascular system.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 21:08:51 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Li", "Rui", ""], ["Shahn", "Zach", ""], ["Li", "Jun", ""], ["Lu", "Mingyu", ""], ["Chakraborty", "Prithwish", ""], ["Sow", "Daby", ""], ["Ghalwash", "Mohamed", ""], ["Lehman", "Li-wei H.", ""]]}, {"id": "2003.10576", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani and Michael Field", "title": "Symmetry & critical points for a model shallow neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization problem associated with fitting two-layer ReLU\nnetworks with $k$ hidden neurons, where labels are assumed to be generated by a\n(teacher) neural network. We leverage the rich symmetry exhibited by such\nmodels to identify various families of critical points and express them as\npower series in $k^{-\\frac{1}{2}}$. These expressions are then used to derive\nestimates for several related quantities which imply that not all spurious\nminima are alike. In particular, we show that while the loss function at\ncertain types of spurious minima decays to zero like $k^{-1}$, in other cases\nthe loss converges to a strictly positive constant. The methods used depend on\nsymmetry, the geometry of group actions, bifurcation, and Artin's implicit\nfunction theorem.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 23:13:12 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 00:41:41 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 16:48:29 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 00:29:33 GMT"}, {"version": "v5", "created": "Thu, 11 Mar 2021 11:08:17 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Arjevani", "Yossi", ""], ["Field", "Michael", ""]]}, {"id": "2003.10577", "submitter": "Alireza Nooraiepour", "authors": "Alireza Nooraiepour and Sina Rezaei Aghdam", "title": "Learning End-to-End Codes for the BPSK-constrained Gaussian Wiretap\n  Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finite-length codes are learned for the Gaussian wiretap channel in an\nend-to-end manner assuming that the communication parties are equipped with\ndeep neural networks (DNNs), and communicate through binary phase-shift keying\n(BPSK) modulation scheme. The goal is to find codes via DNNs which allow a pair\nof transmitter and receiver to communicate reliably and securely in the\npresence of an adversary aiming at decoding the secret messages. Following the\ninformation-theoretic secrecy principles, the security is evaluated in terms of\nmutual information utilizing a deep learning tool called MINE (mutual\ninformation neural estimation). System performance is evaluated for different\nDNN architectures, designed based on the existing secure coding schemes, at the\ntransmitter. Numerical results demonstrate that the legitimate parties can\nindeed establish a secure transmission in this setting as the learned codes\nachieve points on almost the boundary of the equivocation region.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 23:26:36 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Nooraiepour", "Alireza", ""], ["Aghdam", "Sina Rezaei", ""]]}, {"id": "2003.10579", "submitter": "Sanghamitra Dutta", "authors": "Sanghamitra Dutta, Jianyu Wang, Gauri Joshi", "title": "Slow and Stale Gradients Can Win the Race", "comments": "Some of the results have appeared in AISTATS 2018. This is an\n  extended version with additional results, in particular, an adaptive\n  synchronicity strategy called AdaSync. arXiv admin note: substantial text\n  overlap with arXiv:1803.01113", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Stochastic Gradient Descent (SGD) when run in a synchronous\nmanner, suffers from delays in runtime as it waits for the slowest workers\n(stragglers). Asynchronous methods can alleviate stragglers, but cause gradient\nstaleness that can adversely affect the convergence error. In this work, we\npresent a novel theoretical characterization of the speedup offered by\nasynchronous methods by analyzing the trade-off between the error in the\ntrained model and the actual training runtime(wallclock time). The main novelty\nin our work is that our runtime analysis considers random straggling delays,\nwhich helps us design and compare distributed SGD algorithms that strike a\nbalance between straggling and staleness. We also provide a new error\nconvergence analysis of asynchronous SGD variants without bounded or\nexponential delay assumptions. Finally, based on our theoretical\ncharacterization of the error-runtime trade-off, we propose a method of\ngradually varying synchronicity in distributed SGD and demonstrate its\nperformance on CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 23:27:50 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Wang", "Jianyu", ""], ["Joshi", "Gauri", ""]]}, {"id": "2003.10580", "submitter": "Hieu Pham", "authors": "Hieu Pham, Zihang Dai, Qizhe Xie, Minh-Thang Luong, Quoc V. Le", "title": "Meta Pseudo Labels", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Meta Pseudo Labels, a semi-supervised learning method that\nachieves a new state-of-the-art top-1 accuracy of 90.2% on ImageNet, which is\n1.6% better than the existing state-of-the-art. Like Pseudo Labels, Meta Pseudo\nLabels has a teacher network to generate pseudo labels on unlabeled data to\nteach a student network. However, unlike Pseudo Labels where the teacher is\nfixed, the teacher in Meta Pseudo Labels is constantly adapted by the feedback\nof the student's performance on the labeled dataset. As a result, the teacher\ngenerates better pseudo labels to teach the student. Our code will be available\nat\nhttps://github.com/google-research/google-research/tree/master/meta_pseudo_labels.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 23:41:57 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 01:49:34 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 20:01:43 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 19:52:58 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Pham", "Hieu", ""], ["Dai", "Zihang", ""], ["Xie", "Qizhe", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""]]}, {"id": "2003.10595", "submitter": "Liwei Song", "authors": "Liwei Song, Prateek Mittal", "title": "Systematic Evaluation of Privacy Risks of Machine Learning Models", "comments": "Accepted by USENIX Security 2021, code is available at\n  https://github.com/inspire-group/membership-inference-evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are prone to memorizing sensitive data, making them\nvulnerable to membership inference attacks in which an adversary aims to guess\nif an input sample was used to train the model. In this paper, we show that\nprior work on membership inference attacks may severely underestimate the\nprivacy risks by relying solely on training custom neural network classifiers\nto perform attacks and focusing only on the aggregate results over data\nsamples, such as the attack accuracy. To overcome these limitations, we first\npropose to benchmark membership inference privacy risks by improving existing\nnon-neural network based inference attacks and proposing a new inference attack\nmethod based on a modification of prediction entropy. We also propose\nbenchmarks for defense mechanisms by accounting for adaptive adversaries with\nknowledge of the defense and also accounting for the trade-off between model\naccuracy and privacy risks. Using our benchmark attacks, we demonstrate that\nexisting defense approaches are not as effective as previously reported.\n  Next, we introduce a new approach for fine-grained privacy analysis by\nformulating and deriving a new metric called the privacy risk score. Our\nprivacy risk score metric measures an individual sample's likelihood of being a\ntraining member, which allows an adversary to identify samples with high\nprivacy risks and perform attacks with high confidence. We experimentally\nvalidate the effectiveness of the privacy risk score and demonstrate that the\ndistribution of privacy risk score across individual samples is heterogeneous.\nFinally, we perform an in-depth investigation for understanding why certain\nsamples have high privacy risks, including correlations with model sensitivity,\ngeneralization error, and feature embeddings. Our work emphasizes the\nimportance of a systematic and rigorous evaluation of privacy risks of machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:53:53 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 18:56:31 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Song", "Liwei", ""], ["Mittal", "Prateek", ""]]}, {"id": "2003.10596", "submitter": "Apurva Gandhi", "authors": "Apurva Gandhi and Shomik Jain", "title": "Adversarial Perturbations Fool Deepfake Detectors", "comments": "To appear in the proceedings of the International Joint Conference on\n  Neural Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses adversarial perturbations to enhance deepfake images and fool\ncommon deepfake detectors. We created adversarial perturbations using the Fast\nGradient Sign Method and the Carlini and Wagner L2 norm attack in both blackbox\nand whitebox settings. Detectors achieved over 95% accuracy on unperturbed\ndeepfakes, but less than 27% accuracy on perturbed deepfakes. We also explore\ntwo improvements to deepfake detectors: (i) Lipschitz regularization, and (ii)\nDeep Image Prior (DIP). Lipschitz regularization constrains the gradient of the\ndetector with respect to the input in order to increase robustness to input\nperturbations. The DIP defense removes perturbations using generative\nconvolutional neural networks in an unsupervised manner. Regularization\nimproved the detection of perturbed deepfakes on average, including a 10%\naccuracy boost in the blackbox case. The DIP defense achieved 95% accuracy on\nperturbed deepfakes that fooled the original detector, while retaining 98%\naccuracy in other cases on a 100 image subsample.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:54:02 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 05:41:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Gandhi", "Apurva", ""], ["Jain", "Shomik", ""]]}, {"id": "2003.10602", "submitter": "Christopher Bender", "authors": "Christopher M. Bender, Yang Li, Yifeng Shi, Michael K. Reiter, Junier\n  B. Oliva", "title": "Defense Through Diverse Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we develop a novel Bayesian neural network methodology to\nachieve strong adversarial robustness without the need for online adversarial\ntraining. Unlike previous efforts in this direction, we do not rely solely on\nthe stochasticity of network weights by minimizing the divergence between the\nlearned parameter distribution and a prior. Instead, we additionally require\nthat the model maintain some expected uncertainty with respect to all input\ncovariates. We demonstrate that by encouraging the network to distribute evenly\nacross inputs, the network becomes less susceptible to localized, brittle\nfeatures which imparts a natural robustness to targeted perturbations. We show\nempirical robustness on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 01:22:03 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Bender", "Christopher M.", ""], ["Li", "Yang", ""], ["Shi", "Yifeng", ""], ["Reiter", "Michael K.", ""], ["Oliva", "Junier B.", ""]]}, {"id": "2003.10613", "submitter": "Qingyu Zhao", "authors": "Soham Gadgil, Qingyu Zhao, Adolf Pfefferbaum, Edith V. Sullivan, Ehsan\n  Adeli, Kilian M. Pohl", "title": "Spatio-Temporal Graph Convolution for Resting-State fMRI Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Blood-Oxygen-Level-Dependent (BOLD) signal of resting-state fMRI\n(rs-fMRI) records the temporal dynamics of intrinsic functional networks in the\nbrain. However, existing deep learning methods applied to rs-fMRI either\nneglect the functional dependency between different brain regions in a network\nor discard the information in the temporal dynamics of brain activity. To\novercome those shortcomings, we propose to formulate functional connectivity\nnetworks within the context of spatio-temporal graphs. We train a\nspatio-temporal graph convolutional network (ST-GCN) on short sub-sequences of\nthe BOLD time series to model the non-stationary nature of functional\nconnectivity. Simultaneously, the model learns the importance of graph edges\nwithin ST-GCN to gain insight into the functional connectivities contributing\nto the prediction. In analyzing the rs-fMRI of the Human Connectome Project\n(HCP, N=1,091) and the National Consortium on Alcohol and Neurodevelopment in\nAdolescence (NCANDA, N=773), ST-GCN is significantly more accurate than common\napproaches in predicting gender and age based on BOLD signals. Furthermore, the\nbrain regions and functional connections significantly contributing to the\npredictions of our model are important markers according to the neuroscience\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 01:56:50 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 01:40:55 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 03:47:30 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Gadgil", "Soham", ""], ["Zhao", "Qingyu", ""], ["Pfefferbaum", "Adolf", ""], ["Sullivan", "Edith V.", ""], ["Adeli", "Ehsan", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "2003.10621", "submitter": "Kei Nemoto", "authors": "Kei Nemoto and Shweta Jain", "title": "A Pitfall of Learning from User-generated Data: In-depth Analysis of\n  Subjective Class Problem", "comments": "Under review by ECML PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in the supervised learning algorithms field implicitly assumes that\ntraining data is labeled by domain experts or at least semi-professional\nlabelers accessible through crowdsourcing services like Amazon Mechanical Turk.\nWith the advent of the Internet, data has become abundant and a large number of\nmachine learning based systems started being trained with user-generated data,\nusing categorical data as true labels. However, little work has been done in\nthe area of supervised learning with user-defined labels where users are not\nnecessarily experts and might be motivated to provide incorrect labels in order\nto improve their own utility from the system. In this article, we propose two\ntypes of classes in user-defined labels: subjective class and objective class -\nshowing that the objective classes are as reliable as if they were provided by\ndomain experts, whereas the subjective classes are subject to bias and\nmanipulation by the user. We define this as a subjective class issue and\nprovide a framework for detecting subjective labels in a dataset without\nquerying oracle. Using this framework, data mining practitioners can detect a\nsubjective class at an early stage of their projects, and avoid wasting their\nprecious time and resources by dealing with subjective class problem with\ntraditional machine learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 02:25:52 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Nemoto", "Kei", ""], ["Jain", "Shweta", ""]]}, {"id": "2003.10637", "submitter": "Ruixuan Liu", "authors": "Ruixuan Liu, Yang Cao, Masatoshi Yoshikawa, Hong Chen", "title": "FedSel: Federated SGD under Local Differential Privacy with Top-k\n  Dimension Selection", "comments": "18 pages, to be published in DASFAA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As massive data are produced from small gadgets, federated learning on mobile\ndevices has become an emerging trend. In the federated setting, Stochastic\nGradient Descent (SGD) has been widely used in federated learning for various\nmachine learning models. To prevent privacy leakages from gradients that are\ncalculated on users' sensitive data, local differential privacy (LDP) has been\nconsidered as a privacy guarantee in federated SGD recently. However, the\nexisting solutions have a dimension dependency problem: the injected noise is\nsubstantially proportional to the dimension $d$. In this work, we propose a\ntwo-stage framework FedSel for federated SGD under LDP to relieve this problem.\nOur key idea is that not all dimensions are equally important so that we\nprivately select Top-k dimensions according to their contributions in each\niteration of federated SGD. Specifically, we propose three private dimension\nselection mechanisms and adapt the gradient accumulation technique to stabilize\nthe learning process with noisy updates. We also theoretically analyze privacy,\naccuracy and time complexity of FedSel, which outperforms the state-of-the-art\nsolutions. Experiments on real-world and synthetic datasets verify the\neffectiveness and efficiency of our framework.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 03:31:21 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Liu", "Ruixuan", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""], ["Chen", "Hong", ""]]}, {"id": "2003.10643", "submitter": "Yoichi Matsuo", "authors": "Yoichi Matsuo, Tatsuaki Kimura and Ken Nishimatsu", "title": "DeepSIP: A System for Predicting Service Impact of Network Failure by\n  Temporal Multimodal CNN", "comments": "to appear in IEEE/IFIP International Workshop on Analytics for\n  Network and Service Management (AnNet 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a failure occurs in a network, network operators need to recognize\nservice impact, since service impact is essential information for handling\nfailures. In this paper, we propose Deep learning based Service Impact\nPrediction (DeepSIP), a system to predict the time to recovery from the failure\nand the loss of traffic volume due to the failure in a network element using a\ntemporal multimodal convolutional neural network (CNN). Since the time to\nrecovery is useful information for a service level agreement (SLA) and the loss\nof traffic volume is directly related to the severity of the failures, we\nregard these as the service impact. The service impact is challenging to\npredict, since a network element does not explicitly contain any information\nabout the service impact. Thus, we aim to predict the service impact from\nsyslog messages and traffic volume by extracting hidden information about\nfailures. To extract useful features for prediction from syslog messages and\ntraffic volume which are multimodal and strongly correlated, and have temporal\ndependencies, we use temporal multimodal CNN. We experimentally evaluated\nDeepSIP and DeepSIP reduced prediction error by approximately 50% in comparison\nwith other NN-based methods with a synthetic dataset.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 03:47:54 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Matsuo", "Yoichi", ""], ["Kimura", "Tatsuaki", ""], ["Nishimatsu", "Ken", ""]]}, {"id": "2003.10661", "submitter": "Xiaolie Li", "authors": "Xiaolei Li, Wenhua Song, Dazhi Gao, Wei Gao and Haozhong Wan", "title": "Training a U-Net based on a random mode-coupling matrix model to recover\n  acoustic interference striations", "comments": null, "journal-ref": null, "doi": "10.1121/10.0001125", "report-no": null, "categories": "stat.ML cs.LG eess.SP physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A U-Net is trained to recover acoustic interference striations (AISs) from\ndistorted ones. A random mode-coupling matrix model is introduced to generate a\nlarge number of training data quickly, which are used to train the U-Net. The\nperformance of AIS recovery of the U-Net is tested in range-dependent\nwaveguides with nonlinear internal waves (NLIWs). Although the random\nmode-coupling matrix model is not an accurate physical model, the test results\nshow that the U-Net successfully recovers AISs under different signal-to-noise\nratios (SNRs) and different amplitudes and widths of NLIWs for different\nshapes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 05:01:02 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Li", "Xiaolei", ""], ["Song", "Wenhua", ""], ["Gao", "Dazhi", ""], ["Gao", "Wei", ""], ["Wan", "Haozhong", ""]]}, {"id": "2003.10662", "submitter": "Piyush Gupta", "authors": "Piyush Gupta, Demetris Coleman, Joshua E. Siegel", "title": "Towards Safer Self-Driving Through Great PAIN (Physically Adversarial\n  Intelligent Networks)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated vehicles' neural networks suffer from overfit, poor\ngeneralizability, and untrained edge cases due to limited data availability.\nResearchers synthesize randomized edge-case scenarios to assist in the training\nprocess, though simulation introduces potential for overfit to latent rules and\nfeatures. Automating worst-case scenario generation could yield informative\ndata for improving self driving. To this end, we introduce a \"Physically\nAdversarial Intelligent Network\" (PAIN), wherein self-driving vehicles interact\naggressively in the CARLA simulation environment. We train two agents, a\nprotagonist and an adversary, using dueling double deep Q networks (DDDQNs)\nwith prioritized experience replay. The coupled networks alternately\nseek-to-collide and to avoid collisions such that the \"defensive\" avoidance\nalgorithm increases the mean-time-to-failure and distance traveled under\nnon-hostile operating conditions. The trained protagonist becomes more\nresilient to environmental uncertainty and less prone to corner case failures\nresulting in collisions than the agent trained without an adversary.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 05:04:13 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Gupta", "Piyush", ""], ["Coleman", "Demetris", ""], ["Siegel", "Joshua E.", ""]]}, {"id": "2003.10713", "submitter": "Gowthami Somepalli", "authors": "Gowthami Somepalli, Yexin Wu, Yogesh Balaji, Bhanukiran Vinzamuri,\n  Soheil Feizi", "title": "Unsupervised Anomaly Detection with Adversarial Mirrored AutoEncoders", "comments": "Updated the paper with more OOD detection baselines. Performed\n  ablation analysis on various components of AMA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting out of distribution (OOD) samples is of paramount importance in all\nMachine Learning applications. Deep generative modeling has emerged as a\ndominant paradigm to model complex data distributions without labels. However,\nprior work has shown that generative models tend to assign higher likelihoods\nto OOD samples compared to the data distribution on which they were trained.\nFirst, we propose Adversarial Mirrored Autoencoder (AMA), a variant of\nAdversarial Autoencoder, which uses a mirrored Wasserstein loss in the\ndiscriminator to enforce better semantic-level reconstruction. We also propose\na latent space regularization to learn a compact manifold for in-distribution\nsamples. The use of AMA produces better feature representations that improve\nanomaly detection performance. Second, we put forward an alternative measure of\nanomaly score to replace the reconstruction-based metric which has been\ntraditionally used in generative model-based anomaly detection methods. Our\nmethod outperforms the current state-of-the-art methods for anomaly detection\non several OOD detection benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 08:26:58 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 17:54:15 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2021 21:28:13 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Somepalli", "Gowthami", ""], ["Wu", "Yexin", ""], ["Balaji", "Yogesh", ""], ["Vinzamuri", "Bhanukiran", ""], ["Feizi", "Soheil", ""]]}, {"id": "2003.10769", "submitter": "Biraja Ghoshal", "authors": "Biraja Ghoshal, Allan Tucker", "title": "Estimating Uncertainty and Interpretability in Deep Learning for\n  Coronavirus (COVID-19) Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has achieved state of the art performance in medical imaging.\nHowever, these methods for disease detection focus exclusively on improving the\naccuracy of classification or predictions without quantifying uncertainty in a\ndecision. Knowing how much confidence there is in a computer-based medical\ndiagnosis is essential for gaining clinicians trust in the technology and\ntherefore improve treatment. Today, the 2019 Coronavirus (SARS-CoV-2)\ninfections are a major healthcare challenge around the world. Detecting\nCOVID-19 in X-ray images is crucial for diagnosis, assessment and treatment.\nHowever, diagnostic uncertainty in the report is a challenging and yet\ninevitable task for radiologist. In this paper, we investigate how drop-weights\nbased Bayesian Convolutional Neural Networks (BCNN) can estimate uncertainty in\nDeep Learning solution to improve the diagnostic performance of the\nhuman-machine team using publicly available COVID-19 chest X-ray dataset and\nshow that the uncertainty in prediction is highly correlates with accuracy of\nprediction. We believe that the availability of uncertainty-aware deep learning\nsolution will enable a wider adoption of Artificial Intelligence (AI) in a\nclinical setting.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 21:58:13 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 16:48:13 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ghoshal", "Biraja", ""], ["Tucker", "Allan", ""]]}, {"id": "2003.10775", "submitter": "Ori Linial", "authors": "Ori Linial, Neta Ravid, Danny Eytan, Uri Shalit", "title": "Generative ODE Modeling with Known Unknowns", "comments": null, "journal-ref": null, "doi": "10.1145/3450439.3451866", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several crucial applications, domain knowledge is encoded by a system of\nordinary differential equations (ODE), often stemming from underlying physical\nand biological processes. A motivating example is intensive care unit patients:\nthe dynamics of vital physiological functions, such as the cardiovascular\nsystem with its associated variables (heart rate, cardiac contractility and\noutput and vascular resistance) can be approximately described by a known\nsystem of ODEs. Typically, some of the ODE variables are directly observed\n(heart rate and blood pressure for example) while some are unobserved (cardiac\ncontractility, output and vascular resistance), and in addition many other\nvariables are observed but not modeled by the ODE, for example body\ntemperature. Importantly, the unobserved ODE variables are known-unknowns: We\nknow they exist and their functional dynamics, but cannot measure them\ndirectly, nor do we know the function tying them to all observed measurements.\nAs is often the case in medicine, and specifically the cardiovascular system,\nestimating these known-unknowns is highly valuable and they serve as targets\nfor therapeutic manipulations. Under this scenario we wish to learn the\nparameters of the ODE generating each observed time-series, and extrapolate the\nfuture of the ODE variables and the observations. We address this task with a\nvariational autoencoder incorporating the known ODE function, called GOKU-net\nfor Generative ODE modeling with Known Unknowns. We first validate our method\non videos of single and double pendulums with unknown length or mass; we then\napply it to a model of the cardiovascular system. We show that modeling the\nknown-unknowns allows us to successfully discover clinically meaningful\nunobserved system parameters, leads to much better extrapolation, and enables\nlearning using much smaller training sets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:21:06 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 11:31:46 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Linial", "Ori", ""], ["Ravid", "Neta", ""], ["Eytan", "Danny", ""], ["Shalit", "Uri", ""]]}, {"id": "2003.10780", "submitter": "Muhammad Abdullah Jamal", "authors": "Muhammad Abdullah Jamal and Matthew Brown and Ming-Hsuan Yang and\n  Liqiang Wang and Boqing Gong", "title": "Rethinking Class-Balanced Methods for Long-Tailed Visual Recognition\n  from a Domain Adaptation Perspective", "comments": "Accepted for publication at CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object frequency in the real world often follows a power law, leading to a\nmismatch between datasets with long-tailed class distributions seen by a\nmachine learning model and our expectation of the model to perform well on all\nclasses. We analyze this mismatch from a domain adaptation point of view. First\nof all, we connect existing class-balanced methods for long-tailed\nclassification to target shift, a well-studied scenario in domain adaptation.\nThe connection reveals that these methods implicitly assume that the training\ndata and test data share the same class-conditioned distribution, which does\nnot hold in general and especially for the tail classes. While a head class\ncould contain abundant and diverse training examples that well represent the\nexpected data at inference time, the tail classes are often short of\nrepresentative training data. To this end, we propose to augment the classic\nclass-balanced learning by explicitly estimating the differences between the\nclass-conditioned distributions with a meta-learning approach. We validate our\napproach with six benchmark datasets and three loss functions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:28:42 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Jamal", "Muhammad Abdullah", ""], ["Brown", "Matthew", ""], ["Yang", "Ming-Hsuan", ""], ["Wang", "Liqiang", ""], ["Gong", "Boqing", ""]]}, {"id": "2003.10783", "submitter": "Kengo Tajiri", "authors": "Kengo Tajiri and Yasuhiro Ikeda and Yuusuke Nakano and Keishiro\n  Watanabe", "title": "Dividing Deep Learning Model for Continuous Anomaly Detection of\n  Inconsistent ICT Systems", "comments": "Accepted for IEEE/IFIP Network Operations and Management Symposium\n  2020 (NOMS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health monitoring is important for maintaining reliable information and\ncommunications technology (ICT) systems. Anomaly detection methods based on\nmachine learning, which train a model for describing \"normality\" are promising\nfor monitoring the state of ICT systems. However, these methods cannot be used\nwhen the type of monitored log data changes from that of training data due to\nthe replacement of certain equipment. Therefore, such methods may dismiss an\nanomaly that appears when log data changes. To solve this problem, we propose\nan ICT-systems-monitoring method with deep learning models divided based on the\ncorrelation of log data. We also propose an algorithm for extracting the\ncorrelations of log data from a deep learning model and separating log data\nbased on the correlation. When some of the log data changes, our method can\ncontinue health monitoring with the divided models which are not affected by\nchanges in the log data. We present the results from experiments involving\nbenchmark data and real log data, which indicate that our method using divided\nmodels does not decrease anomaly detection accuracy and a model for anomaly\ndetection can be divided to continue monitoring a network state even if some\nthe log data change.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:32:00 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Tajiri", "Kengo", ""], ["Ikeda", "Yasuhiro", ""], ["Nakano", "Yuusuke", ""], ["Watanabe", "Keishiro", ""]]}, {"id": "2003.10784", "submitter": "Hiroki Ikeuchi", "authors": "Hiroki Ikeuchi, Akio Watanabe, Tsutomu Hirao, Makoto Morishita,\n  Masaaki Nishino, Yoichi Matsuo, Keishiro Watanabe", "title": "Recovery command generation towards automatic recovery in ICT systems by\n  Seq2Seq learning", "comments": "accepted for IEEE/IFIP Network Operations and Management Symposium\n  2020 (NOMS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in scale and complexity of ICT systems, their operation\nincreasingly requires automatic recovery from failures. Although it has become\npossible to automatically detect anomalies and analyze root causes of failures\nwith current methods, making decisions on what commands should be executed to\nrecover from failures still depends on manual operation, which is quite\ntime-consuming. Toward automatic recovery, we propose a method of estimating\nrecovery commands by using Seq2Seq, a neural network model. This model learns\ncomplex relationships between logs obtained from equipment and recovery\ncommands that operators executed in the past. When a new failure occurs, our\nmethod estimates plausible commands that recover from the failure on the basis\nof collected logs. We conducted experiments using a synthetic dataset and\nrealistic OpenStack dataset, demonstrating that our method can estimate\nrecovery commands with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:34:10 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Ikeuchi", "Hiroki", ""], ["Watanabe", "Akio", ""], ["Hirao", "Tsutomu", ""], ["Morishita", "Makoto", ""], ["Nishino", "Masaaki", ""], ["Matsuo", "Yoichi", ""], ["Watanabe", "Keishiro", ""]]}, {"id": "2003.10804", "submitter": "Feiyang Cai", "authors": "Feiyang Cai and Jiani Li and Xenofon Koutsoukos", "title": "Detecting Adversarial Examples in Learning-Enabled Cyber-Physical\n  Systems using Variational Autoencoder for Regression", "comments": "Accepted by Workshop on Assured Autonomous Systems (WAAS2020). arXiv\n  admin note: text overlap with arXiv:2001.10494", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-enabled components (LECs) are widely used in cyber-physical systems\n(CPS) since they can handle the uncertainty and variability of the environment\nand increase the level of autonomy. However, it has been shown that LECs such\nas deep neural networks (DNN) are not robust and adversarial examples can cause\nthe model to make a false prediction. The paper considers the problem of\nefficiently detecting adversarial examples in LECs used for regression in CPS.\nThe proposed approach is based on inductive conformal prediction and uses a\nregression model based on variational autoencoder. The architecture allows to\ntake into consideration both the input and the neural network prediction for\ndetecting adversarial, and more generally, out-of-distribution examples. We\ndemonstrate the method using an advanced emergency braking system implemented\nin an open source simulator for self-driving cars where a DNN is used to\nestimate the distance to an obstacle. The simulation results show that the\nmethod can effectively detect adversarial examples with a short detection\ndelay.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 11:15:33 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Cai", "Feiyang", ""], ["Li", "Jiani", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2003.10810", "submitter": "Hippolyte Dubois", "authors": "Hippolyte Dubois, Patrick Le Callet, Michael Hornberger, Hugo J.\n  Spiers, Antoine Coutrot", "title": "Capturing and Explaining Trajectory Singularities using Composite Signal\n  Neural Networks", "comments": "5 pages, 9 figures, submitted to Eusipco2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spatial trajectories are ubiquitous and complex signals. Their analysis is\ncrucial in many research fields, from urban planning to neuroscience. Several\napproaches have been proposed to cluster trajectories. They rely on\nhand-crafted features, which struggle to capture the spatio-temporal complexity\nof the signal, or on Artificial Neural Networks (ANNs) which can be more\nefficient but less interpretable. In this paper we present a novel ANN\narchitecture designed to capture the spatio-temporal patterns characteristic of\na set of trajectories, while taking into account the demographics of the\nnavigators. Hence, our model extracts markers linked to both behaviour and\ndemographics. We propose a composite signal analyser (CompSNN) combining three\nsimple ANN modules. Each of these modules uses different signal representations\nof the trajectory while remaining interpretable. Our CompSNN performs\nsignificantly better than its modules taken in isolation and allows to\nvisualise which parts of the signal were most useful to discriminate the\ntrajectories.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 12:53:15 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 13:29:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Dubois", "Hippolyte", ""], ["Callet", "Patrick Le", ""], ["Hornberger", "Michael", ""], ["Spiers", "Hugo J.", ""], ["Coutrot", "Antoine", ""]]}, {"id": "2003.10838", "submitter": "Ali Yekkehkhany", "authors": "Du Su, Ali Yekkehkhany, Yi Lu, Wenmiao Lu", "title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in\n  Adaptive Tutoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new application of embedding techniques for problem retrieval in\nadaptive tutoring. The objective is to retrieve problems whose mathematical\nconcepts are similar. There are two challenges: First, like sentences, problems\nhelpful to tutoring are never exactly the same in terms of the underlying\nconcepts. Instead, good problems mix concepts in innovative ways, while still\ndisplaying continuity in their relationships. Second, it is difficult for\nhumans to determine a similarity score that is consistent across a large enough\ntraining set. We propose a hierarchical problem embedding algorithm, called\nProb2Vec, that consists of abstraction and embedding steps. Prob2Vec achieves\n96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from\ndirectly applying state-of-the-art sentence embedding methods. It is\ninteresting that Prob2Vec is able to distinguish very fine-grained differences\namong problems, an ability humans need time and effort to acquire. In addition,\nthe sub-problem of concept labeling with imbalanced training data set is\ninteresting in its own right. It is a multi-label problem suffering from\ndimensionality explosion, which we propose ways to ameliorate. We propose the\nnovel negative pre-training algorithm that dramatically reduces false negative\nand positive ratios for classification, using an imbalanced training data set.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 00:16:14 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Su", "Du", ""], ["Yekkehkhany", "Ali", ""], ["Lu", "Yi", ""], ["Lu", "Wenmiao", ""]]}, {"id": "2003.10841", "submitter": "Abul Hashem Beg", "authors": "A. H. Beg, Md Zahidul Islam, Vladimir Estivill-Castro", "title": "Tree Index: A New Cluster Evaluation Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a cluster evaluation technique called Tree Index. Our Tree Index\nalgorithm aims at describing the structural information of the clustering\nrather than the quantitative format of cluster-quality indexes (where the\nrepresentation power of clustering is some cumulative error similar to vector\nquantization). Our Tree Index is finding margins amongst clusters for easy\nlearning without the complications of Minimum Description Length. Our Tree\nIndex produces a decision tree from the clustered data set, using the cluster\nidentifiers as labels. It combines the entropy of each leaf with their depth.\nIntuitively, a shorter tree with pure leaves generalizes the data well (the\nclusters are easy to learn because they are well separated). So, the labels are\nmeaningful clusters. If the clustering algorithm does not separate well, trees\nlearned from their results will be large and too detailed. We show that, on the\nclustering results (obtained by various techniques) on a brain dataset, Tree\nIndex discriminates between reasonable and non-sensible clusters. We confirm\nthe effectiveness of Tree Index through graphical visualizations. Tree Index\nevaluates the sensible solutions higher than the non-sensible solutions while\nexisting cluster-quality indexes fail to do so.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:41:12 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Beg", "A. H.", ""], ["Islam", "Md Zahidul", ""], ["Estivill-Castro", "Vladimir", ""]]}, {"id": "2003.10865", "submitter": "Aaron Klein", "authors": "Aaron Klein, Louis C. Tiao, Thibaut Lienart, Cedric Archambeau,\n  Matthias Seeger", "title": "Model-based Asynchronous Hyperparameter and Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model-based asynchronous multi-fidelity method for\nhyperparameter and neural architecture search that combines the strengths of\nasynchronous Hyperband and Gaussian process-based Bayesian optimization. At the\nheart of our method is a probabilistic model that can simultaneously reason\nacross hyperparameters and resource levels, and supports decision-making in the\npresence of pending evaluations. We demonstrate the effectiveness of our method\non a wide range of challenging benchmarks, for tabular data, image\nclassification and language modelling, and report substantial speed-ups over\ncurrent state-of-the-art methods. Our new methods, along with asynchronous\nbaselines, are implemented in a distributed framework which will be open\nsourced along with this publication.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:17:07 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 08:16:06 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Klein", "Aaron", ""], ["Tiao", "Louis C.", ""], ["Lienart", "Thibaut", ""], ["Archambeau", "Cedric", ""], ["Seeger", "Matthias", ""]]}, {"id": "2003.10870", "submitter": "Valerio Perrone", "authors": "Eric Hans Lee, Valerio Perrone, Cedric Archambeau, Matthias Seeger", "title": "Cost-aware Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a class of global optimization algorithms,\nsuitable for minimizing an expensive objective function in as few function\nevaluations as possible. While BO budgets are typically given in iterations,\nthis implicitly measures convergence in terms of iteration count and assumes\neach evaluation has identical cost. In practice, evaluation costs may vary in\ndifferent regions of the search space. For example, the cost of neural network\ntraining increases quadratically with layer size, which is a typical\nhyperparameter. Cost-aware BO measures convergence with alternative cost\nmetrics such as time, energy, or money, for which vanilla BO methods are\nunsuited. We introduce Cost Apportioned BO (CArBO), which attempts to minimize\nan objective function in as little cost as possible. CArBO combines a\ncost-effective initial design with a cost-cooled optimization phase which\ndepreciates a learned cost model as iterations proceed. On a set of 20\nblack-box function optimization problems we show that, given the same cost\nbudget, CArBO finds significantly better hyperparameter configurations than\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 14:51:04 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lee", "Eric Hans", ""], ["Perrone", "Valerio", ""], ["Archambeau", "Cedric", ""], ["Seeger", "Matthias", ""]]}, {"id": "2003.10874", "submitter": "Shahab Boumi", "authors": "Shahab Boumi, Adan Vela, Jacquelyn Chini", "title": "Quantifying the relationship between student enrollment patterns and\n  student performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplified categorizations have often led to college students being labeled\nas full-time or part-time students. However, at many universities student\nenrollment patterns can be much more complicated, as it is not uncommon for\nstudents to alternate between full-time and part-time enrollment each semester\nbased on finances, scheduling, or family needs. While prior research has\nestablished full-time students maintain better outcomes then their part-time\ncounterparts, limited study has examined the impact of enrollment patterns or\nstrategies on academic outcomes. In this paper, we applying a Hidden Markov\nModel to identify and cluster students' enrollment strategies into three\ndifferent categorizes: full-time, part-time, and mixed-enrollment strategies.\nBased the enrollment strategies we investigate and compare the academic\nperformance outcomes of each group, taking into account differences between\nfirst-time-in-college students and transfer students. Analysis of data\ncollected from the University of Central Florida from 2008 to 2017 indicates\nthat first-time-in-college students that apply a mixed enrollment strategy are\ncloser in performance to full-time students, as compared to part-time students.\nMore importantly, during their part-time semesters, mixed-enrollment students\nsignificantly outperform part-time students. Similarly, analysis of transfer\nstudents shows that a mixed-enrollment strategy is correlated a similar\ngraduation rates as the full-time enrollment strategy, and more than double the\ngraduation rate associated with part-time enrollment. Such a finding suggests\nthat increased engagement through the occasional full-time enrollment leads to\nbetter overall outcomes.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 02:29:30 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 13:28:29 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 14:17:16 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 00:33:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Boumi", "Shahab", ""], ["Vela", "Adan", ""], ["Chini", "Jacquelyn", ""]]}, {"id": "2003.10897", "submitter": "Ping Li", "authors": "Yunfeng Cai and Ping Li", "title": "An Inverse-free Truncated Rayleigh-Ritz Method for Sparse Generalized\n  Eigenvalue Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the sparse generalized eigenvalue problem (SGEP), which\naims to find the leading eigenvector with at most $k$ nonzero entries. SGEP\nnaturally arises in many applications in machine learning, statistics, and\nscientific computing, for example, the sparse principal component analysis\n(SPCA), the sparse discriminant analysis (SDA), and the sparse canonical\ncorrelation analysis (SCCA). In this paper, we focus on the development of a\nthree-stage algorithm named {\\em inverse-free truncated Rayleigh-Ritz method}\n({\\em IFTRR}) to efficiently solve SGEP. In each iteration of IFTRR, only a\nsmall number of matrix-vector products is required. This makes IFTRR\nwell-suited for large scale problems. Particularly, a new truncation strategy\nis proposed, which is able to find the support set of the leading eigenvector\neffectively. Theoretical results are developed to explain why IFTRR works well.\nNumerical simulations demonstrate the merits of IFTRR.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:53:55 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Cai", "Yunfeng", ""], ["Li", "Ping", ""]]}, {"id": "2003.10901", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Samuel Wauthier, Tim Verbelen, Bart Dhoedt", "title": "Dynamic Narrowing of VAE Bottlenecks Using GECO and L0 Regularization", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When designing variational autoencoders (VAEs) or other types of latent space\nmodels, the dimensionality of the latent space is typically defined upfront. In\nthis process, it is possible that the number of dimensions is under- or\noverprovisioned for the application at hand. In case the dimensionality is not\npredefined, this parameter is usually determined using time- and\nresource-consuming cross-validation. For these reasons we have developed a\ntechnique to shrink the latent space dimensionality of VAEs automatically and\non-the-fly during training using Generalized ELBO with Constrained Optimization\n(GECO) and the $L_0$-Augment-REINFORCE-Merge ($L_0$-ARM) gradient estimator.\nThe GECO optimizer ensures that we are not violating a predefined upper bound\non the reconstruction error. This paper presents the algorithmic details of our\nmethod along with experimental results on five different datasets. We find that\nour training procedure is stable and that the latent space can be pruned\neffectively without violating the GECO constraints.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:58:16 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 09:37:08 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 09:48:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["De Boom", "Cedric", ""], ["Wauthier", "Samuel", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2003.10903", "submitter": "Bj\\\"orn Lindenberg", "authors": "Bj\\\"orn Lindenberg, Jonas Nordqvist, Karl-Olof Lindahl", "title": "Distributional Reinforcement Learning with Ensembles", "comments": "15 pages, 2 figures", "journal-ref": "Algorithms 2020, 13, 118", "doi": "10.3390/a13050118", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that ensemble methods often provide enhanced performance in\nreinforcement learning. In this paper, we explore this concept further by using\ngroup-aided training within the distributional reinforcement learning paradigm.\nSpecifically, we propose an extension to categorical reinforcement learning,\nwhere distributional learning targets are implicitly based on the total\ninformation gathered by an ensemble. We empirically show that this may lead to\nmuch more robust initial learning, a stronger individual performance level, and\ngood efficiency on a per-sample basis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:59:54 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 15:49:49 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Lindenberg", "Bj\u00f6rn", ""], ["Nordqvist", "Jonas", ""], ["Lindahl", "Karl-Olof", ""]]}, {"id": "2003.10933", "submitter": "Zhuo Ma", "authors": "Yang Liu, Zhuo Ma, Ximeng Liu, Jian Liu, Zhongyuan Jiang, Jianfeng Ma,\n  Philip Yu, Kui Ren", "title": "Learn to Forget: Memorization Elimination for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the rapidly exploding amount of user data, more companies\nchoose to train various business-specified machine learning models, especially\nneural networks, to improve service quality. Nevertheless, the current machine\nlearning application is still a one-way trip for the user data. As long as\nusers contribute their data, there is no way to retreat the contribution. Such\nan irreversible setting has two potential risks: 1) from a legislative point of\nview, many national regulations emphasize that users should have the right to\nremove their personal data; 2) from a security point of view, the unintended\nmemorization of a neural network increases the possibility of an adversary to\nextract user's sensitive information. To this end, memorization elimination for\nmachine learning models becomes a popular research topic.\n  Considering that there is no uniform indicator to evaluate a memorization\nelimination method, we explore the concept of membership inference and define a\nnovel indicator, called forgetting rate. It well describes the transformation\nrate of the eliminated data from \"memorized\" to \"unknown\" after conducting\nmemorization elimination. Furthermore, we propose Forsaken, a method that\nallows users to eliminate the unintended memorization of their private data\nfrom a trained neural network. The unintended memorization here is formed by\nthe out-of-distribution but sensitive data inadvertently uploaded by users.\nCompared to prior work, our method avoids retraining, achieves higher\nforgetting rate, and causes less accuracy loss through a trainable dummy\ngradient generator.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:46:38 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 12:29:00 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Liu", "Yang", ""], ["Ma", "Zhuo", ""], ["Liu", "Ximeng", ""], ["Liu", "Jian", ""], ["Jiang", "Zhongyuan", ""], ["Ma", "Jianfeng", ""], ["Yu", "Philip", ""], ["Ren", "Kui", ""]]}, {"id": "2003.10975", "submitter": "Eduardo Augusto Barros De Moraes", "authors": "Eduardo A. Barros de Moraes, Hadi Salehi and Mohsen Zayernouri", "title": "Data-Driven Failure Prediction in Brittle Materials: A Phase-Field Based\n  Machine Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failure in brittle materials led by the evolution of micro- to macro-cracks\nunder repetitive or increasing loads is often catastrophic with no significant\nplasticity to advert the onset of fracture. Early failure detection with\nrespective location are utterly important features in any practical\napplication, both of which can be effectively addressed using artificial\nintelligence. In this paper, we develop a supervised machine learning (ML)\nframework to predict failure in an isothermal, linear elastic and isotropic\nphase-field model for damage and fatigue of brittle materials. Time-series data\nof the phase-field model is extracted from virtual sensing nodes at different\nlocations of the geometry. A pattern recognition scheme is introduced to\nrepresent time-series data/sensor nodes responses as a pattern with a\ncorresponding label, integrated with ML algorithms, used for damage\nclassification with identified patterns. We perform an uncertainty analysis by\nsuperposing random noise to the time-series data to assess the robustness of\nthe framework with noise-polluted data. Results indicate that the proposed\nframework is capable of predicting failure with acceptable accuracy even in the\npresence of high noise levels. The findings demonstrate satisfactory\nperformance of the supervised ML framework, and the applicability of artificial\nintelligence and ML to a practical engineering problem, i.,e, data-driven\nfailure prediction in brittle materials.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:13:08 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["de Moraes", "Eduardo A. Barros", ""], ["Salehi", "Hadi", ""], ["Zayernouri", "Mohsen", ""]]}, {"id": "2003.10976", "submitter": "Xue-She Wang", "authors": "Xue-She Wang, James D. Turner, Brian P. Mann", "title": "A Model-Free Sampling Method for Estimating Basins of Attraction Using\n  Hybrid Active Learning (HAL)", "comments": "Update: 1) add the schematic of the magnet-induced bistable system,\n  2) emphasize that the proposed method can be implemented when the system's\n  model is unknown. 6 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the basins of attraction (BoA) is often a paramount\nconsideration for nonlinear systems. Most existing approaches to determining a\nhigh-resolution BoA require prior knowledge of the system's dynamical model\n(e.g., differential equation or point mapping for continuous systems, cell\nmapping for discrete systems, etc.), which allows derivation of approximate\nanalytical solutions or parallel computing on a multi-core computer to find the\nBoA efficiently. However, these methods are typically impractical when the BoA\nmust be determined experimentally or when the system's model is unknown. This\npaper introduces a model-free sampling method for BoA. The proposed method is\nbased upon hybrid active learning (HAL) and is designed to find and label the\n\"informative\" samples, which efficiently determine the boundary of BoA. It\nconsists of three primary parts: 1) additional sampling on trajectories (AST)\nto maximize the number of samples obtained from each simulation or experiment;\n2) an active learning (AL) algorithm to exploit the local boundary of BoA; and\n3) a density-based sampling (DBS) method to explore the global boundary of BoA.\nAn example of estimating the BoA for a bistable nonlinear system is presented\nto show the high efficiency of our HAL sampling method.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:14:39 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 21:54:20 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Wang", "Xue-She", ""], ["Turner", "James D.", ""], ["Mann", "Brian P.", ""]]}, {"id": "2003.10992", "submitter": "Ping Li", "authors": "Yunfeng Cai and Ping Li", "title": "Solving the Robust Matrix Completion Problem via a System of Nonlinear\n  Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust matrix completion, which aims to recover a\nlow rank matrix $L_*$ and a sparse matrix $S_*$ from incomplete observations of\ntheir sum $M=L_*+S_*\\in\\mathbb{R}^{m\\times n}$. Algorithmically, the robust\nmatrix completion problem is transformed into a problem of solving a system of\nnonlinear equations, and the alternative direction method is then used to solve\nthe nonlinear equations. In addition, the algorithm is highly parallelizable\nand suitable for large scale problems. Theoretically, we characterize the\nsufficient conditions for when $L_*$ can be approximated by a low rank\napproximation of the observed $M_*$. And under proper assumptions, it is shown\nthat the algorithm converges to the true solution linearly. Numerical\nsimulations show that the simple method works as expected and is comparable\nwith state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:28:15 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Cai", "Yunfeng", ""], ["Li", "Ping", ""]]}, {"id": "2003.11059", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla, Benjamin M. Marlin", "title": "Integrating Physiological Time Series and Clinical Notes with Deep\n  Learning for Improved ICU Mortality Prediction", "comments": "Presented at ACM Conference on Health, Inference and Learning\n  (Workshop Track), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal\ndata about patients including clinical notes, sparse and irregularly sampled\nphysiological time series, lab results, and more. To date, most methods\ndesigned to learn predictive models from ICU EHR data have focused on a single\nmodality. In this paper, we leverage the recently proposed\ninterpolation-prediction deep learning architecture(Shukla and Marlin 2019) as\na basis for exploring how physiological time series data and clinical notes can\nbe integrated into a unified mortality prediction model. We study both early\nand late fusion approaches and demonstrate how the relative predictive value of\nclinical text and physiological data change over time. Our results show that a\nlate fusion approach can provide a statistically significant improvement in\nmortality prediction performance over using individual modalities in isolation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 18:25:49 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 21:00:52 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2003.11079", "submitter": "Wei Ye", "authors": "Wei Ye, Dominik Mautz, Christian Boehm, Ambuj Singh, Claudia Plant", "title": "Incorporating User's Preference into Attributed Graph Clustering", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2020.2976063", "report-no": null, "categories": "cs.LG cs.HC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering has been studied extensively on both plain graphs and\nattributed graphs. However, all these methods need to partition the whole graph\nto find cluster structures. Sometimes, based on domain knowledge, people may\nhave information about a specific target region in the graph and only want to\nfind a single cluster concentrated on this local region. Such a task is called\nlocal clustering. In contrast to global clustering, local clustering aims to\nfind only one cluster that is concentrating on the given seed vertex (and also\non the designated attributes for attributed graphs). Currently, very few\nmethods can deal with this kind of task. To this end, we propose two quality\nmeasures for a local cluster: Graph Unimodality (GU) and Attribute Unimodality\n(AU). The former measures the homogeneity of the graph structure while the\nlatter measures the homogeneity of the subspace that is composed of the\ndesignated attributes. We call their linear combination as Compactness.\nFurther, we propose LOCLU to optimize the Compactness score. The local cluster\ndetected by LOCLU concentrates on the region of interest, provides efficient\ninformation flow in the graph and exhibits a unimodal data distribution in the\nsubspace of the designated attributes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:07:22 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ye", "Wei", ""], ["Mautz", "Dominik", ""], ["Boehm", "Christian", ""], ["Singh", "Ambuj", ""], ["Plant", "Claudia", ""]]}, {"id": "2003.11086", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Jerry Li and Anastasia Voloshinov", "title": "Efficient Algorithms for Multidimensional Segmented Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of fixed design {\\em multidimensional\nsegmented regression}: Given noisy samples from a function $f$, promised to be\npiecewise linear on an unknown set of $k$ rectangles, we want to recover $f$ up\nto a desired accuracy in mean-squared error. We provide the first sample and\ncomputationally efficient algorithm for this problem in any fixed dimension.\nOur algorithm relies on a simple iterative merging approach, which is novel in\nthe multidimensional setting. Our experimental evaluation on both synthetic and\nreal datasets shows that our algorithm is competitive and in some cases\noutperforms state-of-the-art heuristics. Code of our implementation is\navailable at\n\\url{https://github.com/avoloshinov/multidimensional-segmented-regression}.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:39:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Li", "Jerry", ""], ["Voloshinov", "Anastasia", ""]]}, {"id": "2003.11102", "submitter": "Pedro Braga", "authors": "Hansenclever F. Bassani, Renie A. Delgado, Jose Nilton de O. Lima\n  Junior, Heitor R. Medeiros, Pedro H. M. Braga and Alain Tapp", "title": "Learning to Play Soccer by Reinforcement and Applying Sim-to-Real to\n  Compete in the Real World", "comments": null, "journal-ref": "LatinX in AI Research Workshop at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work presents an application of Reinforcement Learning (RL) for the\ncomplete control of real soccer robots of the IEEE Very Small Size Soccer\n(VSSS), a traditional league in the Latin American Robotics Competition (LARC).\nIn the VSSS league, two teams of three small robots play against each other. We\npropose a simulated environment in which continuous or discrete control\npolicies can be trained, and a Sim-to-Real method to allow using the obtained\npolicies to control a robot in the real world. The results show that the\nlearned policies display a broad repertoire of behaviors that are difficult to\nspecify by hand. This approach, called VSSS-RL, was able to beat the\nhuman-designed policy for the striker of the team ranked 3rd place in the 2018\nLARC, in 1-vs-1 matches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 20:23:18 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Bassani", "Hansenclever F.", ""], ["Delgado", "Renie A.", ""], ["Junior", "Jose Nilton de O. Lima", ""], ["Medeiros", "Heitor R.", ""], ["Braga", "Pedro H. M.", ""], ["Tapp", "Alain", ""]]}, {"id": "2003.11126", "submitter": "Ali Mousavi", "authors": "Ali Mousavi, Lihong Li, Qiang Liu, Denny Zhou", "title": "Black-box Off-policy Estimation for Infinite-Horizon Reinforcement\n  Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy estimation for long-horizon problems is important in many\nreal-life applications such as healthcare and robotics, where high-fidelity\nsimulators may not be available and on-policy evaluation is expensive or\nimpossible. Recently, \\cite{liu18breaking} proposed an approach that avoids the\n\\emph{curse of horizon} suffered by typical importance-sampling-based methods.\nWhile showing promising results, this approach is limited in practice as it\nrequires data be drawn from the \\emph{stationary distribution} of a\n\\emph{known} behavior policy. In this work, we propose a novel approach that\neliminates such limitations. In particular, we formulate the problem as solving\nfor the fixed point of a certain operator. Using tools from Reproducing Kernel\nHilbert Spaces (RKHSs), we develop a new estimator that computes importance\nratios of stationary distributions, without knowledge of how the off-policy\ndata are collected. We analyze its asymptotic consistency and finite-sample\ngeneralization. Experiments on benchmarks verify the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 21:44:51 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Mousavi", "Ali", ""], ["Li", "Lihong", ""], ["Liu", "Qiang", ""], ["Zhou", "Denny", ""]]}, {"id": "2003.11132", "submitter": "Thibaut Vidal", "authors": "Thibaut Vidal, Toni Pacheco, Maximilian Schiffer", "title": "Born-Again Tree Ensembles", "comments": "\"Born-Again Tree Ensembles\", proceedings of ICML 2020. The associated\n  source code is available at: https://github.com/vidalt/BA-Trees", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML). Vol. 119, pp. 9743-9753 (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning algorithms in finance, medicine, and criminal\njustice can deeply impact human lives. As a consequence, research into\ninterpretable machine learning has rapidly grown in an attempt to better\ncontrol and fix possible sources of mistakes and biases. Tree ensembles offer a\ngood prediction quality in various domains, but the concurrent use of multiple\ntrees reduces the interpretability of the ensemble. Against this background, we\nstudy born-again tree ensembles, i.e., the process of constructing a single\ndecision tree of minimum size that reproduces the exact same behavior as a\ngiven tree ensemble in its entire feature space. To find such a tree, we\ndevelop a dynamic-programming based algorithm that exploits sophisticated\npruning and bounding rules to reduce the number of recursive calls. This\nalgorithm generates optimal born-again trees for many datasets of practical\ninterest, leading to classifiers which are typically simpler and more\ninterpretable without any other form of compromise.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 22:17:21 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 19:12:09 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 15:52:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Vidal", "Thibaut", ""], ["Pacheco", "Toni", ""], ["Schiffer", "Maximilian", ""]]}, {"id": "2003.11164", "submitter": "Jiale Zhi", "authors": "Jiale Zhi, Rui Wang, Jeff Clune, Kenneth O. Stanley", "title": "Fiber: A Platform for Efficient Development and Distributed Training for\n  Reinforcement Learning and Population-Based Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning are consistently enabled by increasing\namounts of computation. Reinforcement learning (RL) and population-based\nmethods in particular pose unique challenges for efficiency and flexibility to\nthe underlying distributed computing frameworks. These challenges include\nfrequent interaction with simulations, the need for dynamic scaling, and the\nneed for a user interface with low adoption cost and consistency across\ndifferent backends. In this paper we address these challenges while still\nretaining development efficiency and flexibility for both research and\npractical applications by introducing Fiber, a scalable distributed computing\nframework for RL and population-based methods. Fiber aims to significantly\nexpand the accessibility of large-scale parallel computation to users of\notherwise complicated RL and population-based approaches without the need to\nfor specialized computational expertise.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 00:28:48 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zhi", "Jiale", ""], ["Wang", "Rui", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2003.11196", "submitter": "Xin Tong Thomson", "authors": "Xi Chen and Qiang Liu and Xin T. Tong", "title": "Dimension Independent Generalization Error by Stochastic Gradient\n  Descent", "comments": "60 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One classical canon of statistics is that large models are prone to\noverfitting, and model selection procedures are necessary for high dimensional\ndata. However, many overparameterized models, such as neural networks, perform\nvery well in practice, although they are often trained with simple online\nmethods and regularization. The empirical success of overparameterized models,\nwhich is often known as benign overfitting, motivates us to have a new look at\nthe statistical generalization theory for online optimization. In particular,\nwe present a general theory on the generalization error of stochastic gradient\ndescent (SGD) solutions for both convex and locally convex loss functions. We\nfurther discuss data and model conditions that lead to a ``low effective\ndimension\". Under these conditions, we show that the generalization error\neither does not depend on the ambient dimension $p$ or depends on $p$ via a\npoly-logarithmic factor. We also demonstrate that in several widely used\nstatistical models, the ``low effective dimension'' arises naturally in\noverparameterized settings. The studied statistical applications include both\nconvex models such as linear regression and logistic regression and non-convex\nmodels such as $M$-estimator and two-layer neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 03:08:41 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 06:13:47 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Chen", "Xi", ""], ["Liu", "Qiang", ""], ["Tong", "Xin T.", ""]]}, {"id": "2003.11197", "submitter": "Hoda Shajari", "authors": "Hoda Shajari, Anand Rangarajan", "title": "A Unified Framework for Multiclass and Multilabel Support Vector\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel integrated formulation for multiclass and multilabel\nsupport vector machines (SVMs). A number of approaches have been proposed to\nextend the original binary SVM to an all-in-one multiclass SVM. However, its\ndirect extension to a unified multilabel SVM has not been widely investigated.\nWe propose a straightforward extension to the SVM to cope with multiclass and\nmultilabel classification problems within a unified framework. Our framework\ndeviates from the conventional soft margin SVM framework with its direct\noppositional structure. In our formulation, class-specific weight vectors\n(normal vectors) are learned by maximizing their margin with respect to an\norigin and penalizing patterns when they get too close to this origin. As a\nresult, each weight vector chooses an orientation and a magnitude with respect\nto this origin in such a way that it best represents the patterns belonging to\nits corresponding class. Opposition between classes is introduced into the\nformulation via the minimization of pairwise inner products of weight vectors.\nWe also extend our framework to cope with nonlinear separability via standard\nreproducing kernel Hilbert spaces (RKHS). Biases which are closely related to\nthe origin need to be treated properly in both the original feature space and\nHilbert space. We have the flexibility to incorporate constraints into the\nformulation (if they better reflect the underlying geometry) and improve the\nperformance of the classifier. To this end, specifics and technicalities such\nas the origin in RKHS are addressed. Results demonstrates a competitive\nclassifier for both multiclass and multilabel classification problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 03:08:41 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Shajari", "Hoda", ""], ["Rangarajan", "Anand", ""]]}, {"id": "2003.11205", "submitter": "Charilaos Kanatsoulis", "authors": "Mikael S{\\o}rensen, Charilaos I. Kanatsoulis, and Nicholas D.\n  Sidiropoulos", "title": "Generalized Canonical Correlation Analysis: A Subspace Intersection\n  Approach", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3061218", "report-no": null, "categories": "cs.LG cs.IR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Canonical Correlation Analysis (GCCA) is an important tool that\nfinds numerous applications in data mining, machine learning, and artificial\nintelligence. It aims at finding `common' random variables that are strongly\ncorrelated across multiple feature representations (views) of the same set of\nentities. CCA and to a lesser extent GCCA have been studied from the\nstatistical and algorithmic points of view, but not as much from the standpoint\nof linear algebra. This paper offers a fresh algebraic perspective of GCCA\nbased on a (bi-)linear generative model that naturally captures its essence. It\nis shown that from a linear algebra point of view, GCCA is tantamount to\nsubspace intersection; and conditions under which the common subspace of the\ndifferent views is identifiable are provided. A novel GCCA algorithm is\nproposed based on subspace intersection, which scales up to handle large GCCA\ntasks. Synthetic as well as real data experiments are provided to showcase the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 04:04:25 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["S\u00f8rensen", "Mikael", ""], ["Kanatsoulis", "Charilaos I.", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2003.11227", "submitter": "Sahin Lale", "authors": "Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, Anima Anandkumar", "title": "Logarithmic Regret Bound in Partially Observable Linear Dynamical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of system identification and adaptive control in\npartially observable linear dynamical systems. Adaptive and closed-loop system\nidentification is a challenging problem due to correlations introduced in data\ncollection. In this paper, we present the first model estimation method with\nfinite-time guarantees in both open and closed-loop system identification.\nDeploying this estimation method, we propose adaptive control online learning\n(AdaptOn), an efficient reinforcement learning algorithm that adaptively learns\nthe system dynamics and continuously updates its controller through online\nlearning steps. AdaptOn estimates the model dynamics by occasionally solving a\nlinear regression problem through interactions with the environment. Using\npolicy re-parameterization and the estimated model, AdaptOn constructs\ncounterfactual loss functions to be used for updating the controller through\nonline gradient descent. Over time, AdaptOn improves its model estimates and\nobtains more accurate gradient updates to improve the controller. We show that\nAdaptOn achieves a regret upper bound of $\\text{polylog}\\left(T\\right)$, after\n$T$ time steps of agent-environment interaction. To the best of our knowledge,\nAdaptOn is the first algorithm that achieves $\\text{polylog}\\left(T\\right)$\nregret in adaptive control of unknown partially observable linear dynamical\nsystems which includes linear quadratic Gaussian (LQG) control.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 06:00:33 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 02:00:33 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Lale", "Sahin", ""], ["Azizzadenesheli", "Kamyar", ""], ["Hassibi", "Babak", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2003.11235", "submitter": "Guilin Li", "authors": "Bin Liu, Chenxu Zhu, Guilin Li, Weinan Zhang, Jincai Lai, Ruiming\n  Tang, Xiuqiang He, Zhenguo Li, Yong Yu", "title": "AutoFIS: Automatic Feature Interaction Selection in Factorization Models\n  for Click-Through Rate Prediction", "comments": "KDD 2020 ADS track oral accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning feature interactions is crucial for click-through rate (CTR)\nprediction in recommender systems. In most existing deep learning models,\nfeature interactions are either manually designed or simply enumerated.\nHowever, enumerating all feature interactions brings large memory and\ncomputation cost. Even worse, useless interactions may introduce noise and\ncomplicate the training process. In this work, we propose a two-stage algorithm\ncalled Automatic Feature Interaction Selection (AutoFIS). AutoFIS can\nautomatically identify important feature interactions for factorization models\nwith computational cost just equivalent to training the target model to\nconvergence. In the \\emph{search stage}, instead of searching over a discrete\nset of candidate feature interactions, we relax the choices to be continuous by\nintroducing the architecture parameters. By implementing a regularized\noptimizer over the architecture parameters, the model can automatically\nidentify and remove the redundant feature interactions during the training\nprocess of the model. In the \\emph{re-train stage}, we keep the architecture\nparameters serving as an attention unit to further boost the performance.\nOffline experiments on three large-scale datasets (two public benchmarks, one\nprivate) demonstrate that AutoFIS can significantly improve various FM based\nmodels. AutoFIS has been deployed onto the training platform of Huawei App\nStore recommendation service, where a 10-day online A/B test demonstrated that\nAutoFIS improved the DeepFM model by 20.3\\% and 20.1\\% in terms of CTR and CVR\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 06:53:54 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 02:04:20 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 14:19:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Liu", "Bin", ""], ["Zhu", "Chenxu", ""], ["Li", "Guilin", ""], ["Zhang", "Weinan", ""], ["Lai", "Jincai", ""], ["Tang", "Ruiming", ""], ["He", "Xiuqiang", ""], ["Li", "Zhenguo", ""], ["Yu", "Yong", ""]]}, {"id": "2003.11238", "submitter": "Krishnakumar Balasubramanian", "authors": "Jiaxiang Li, Krishnakumar Balasubramanian, Shiqian Ma", "title": "Stochastic Zeroth-order Riemannian Derivative Estimation and\n  Optimization", "comments": "Additional experimental results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic zeroth-order optimization over Riemannian submanifolds\nembedded in Euclidean space, where the task is to solve Riemannian optimization\nproblem with only noisy objective function evaluations. Towards this, our main\ncontribution is to propose estimators of the Riemannian gradient and Hessian\nfrom noisy objective function evaluations, based on a Riemannian version of the\nGaussian smoothing technique. The proposed estimators overcome the difficulty\nof the non-linearity of the manifold constraint and the issues that arise in\nusing Euclidean Gaussian smoothing techniques when the function is defined only\nover the manifold. We use the proposed estimators to solve Riemannian\noptimization problems in the following settings for the objective function: (i)\nstochastic and gradient-Lipschitz (in both nonconvex and geodesic convex\nsettings), (ii) sum of gradient-Lipschitz and non-smooth functions, and (iii)\nHessian-Lipschitz. For these settings, we analyze the oracle complexity of our\nalgorithms to obtain appropriately defined notions of $\\epsilon$-stationary\npoint or $\\epsilon$-approximate local minimizer. Notably, our complexities are\nindependent of the dimension of the ambient Euclidean space and depend only on\nthe intrinsic dimension of the manifold under consideration. We demonstrate the\napplicability of our algorithms by simulation results and real-world\napplications on black-box stiffness control for robotics and black-box attacks\nto neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 06:58:19 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 06:07:06 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 04:05:52 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Li", "Jiaxiang", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ma", "Shiqian", ""]]}, {"id": "2003.11242", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng", "title": "Safety-Aware Hardening of 3D Object Detection Neural Network Systems", "comments": "This version is similar to v1 with an added statement: \"The\n  evaluation using KITTI dataset in this paper is for knowledge dissemination\n  and scientific publication and is not for commercial use\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how state-of-the-art neural networks for 3D object detection using a\nsingle-stage pipeline can be made safety aware. We start with the safety\nspecification (reflecting the capability of other components) that partitions\nthe 3D input space by criticality, where the critical area employs a separate\ncriterion on robustness under perturbation, quality of bounding boxes, and the\ntolerance over false negatives demonstrated on the training set. In the\narchitecture design, we consider symbolic error propagation to allow\nfeature-level perturbation. Subsequently, we introduce a specialized loss\nfunction reflecting (1) the safety specification, (2) the use of single-stage\ndetection architecture, and finally, (3) the characterization of robustness\nunder perturbation. We also replace the commonly seen non-max-suppression\npost-processing algorithm by a safety-aware non-max-inclusion algorithm, in\norder to maintain the safety claim created by the neural network. The concept\nis detailed by extending the state-of-the-art PIXOR detector which creates\nobject bounding boxes in bird's eye view with inputs from point clouds.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 07:06:11 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 00:57:49 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 09:46:22 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Cheng", "Chih-Hong", ""]]}, {"id": "2003.11243", "submitter": "Liu Ziyin", "authors": "Liu Ziyin, Zihao Wang, Makoto Yamada, Masahito Ueda", "title": "Volumization as a Natural Generalization of Weight Decay", "comments": "18 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel regularization method, called \\textit{volumization}, for\nneural networks. Inspired by physics, we define a physical volume for the\nweight parameters in neural networks, and we show that this method is an\neffective way of regularizing neural networks. Intuitively, this method\ninterpolates between an $L_2$ and $L_\\infty$ regularization. Therefore, weight\ndecay and weight clipping become special cases of the proposed algorithm. We\nprove, on a toy example, that the essence of this method is a regularization\ntechnique to control bias-variance tradeoff. The method is shown to do well in\nthe categories where the standard weight decay method is shown to work well,\nincluding improving the generalization of networks and preventing memorization.\nMoreover, we show that the volumization might lead to a simple method for\ntraining a neural network whose weight is binary or ternary.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 07:13:55 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 10:05:45 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ziyin", "Liu", ""], ["Wang", "Zihao", ""], ["Yamada", "Makoto", ""], ["Ueda", "Masahito", ""]]}, {"id": "2003.11246", "submitter": "Renjie Wu", "authors": "Renjie Wu and Eamonn J. Keogh", "title": "FastDTW is approximate and Generally Slower than the Algorithm it\n  Approximates", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2020.3033752", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many time series data mining problems can be solved with repeated use of\ndistance measure. Examples of such tasks include similarity search, clustering,\nclassification, anomaly detection and segmentation. For over two decades it has\nbeen known that the Dynamic Time Warping (DTW) distance measure is the best\nmeasure to use for most tasks, in most domains. Because the classic DTW\nalgorithm has quadratic time complexity, many ideas have been introduced to\nreduce its amortized time, or to quickly approximate it. One of the most cited\napproximate approaches is FastDTW. The FastDTW algorithm has well over a\nthousand citations and has been explicitly used in several hundred research\nefforts. In this work, we make a surprising claim. In any realistic data mining\napplication, the approximate FastDTW is much slower than the exact DTW. This\nfact clearly has implications for the community that uses this algorithm:\nallowing it to address much larger datasets, get exact results, and do so in\nless time.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 07:26:02 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 22:23:34 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 23:10:43 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wu", "Renjie", ""], ["Keogh", "Eamonn J.", ""]]}, {"id": "2003.11249", "submitter": "Jongwon Choi", "authors": "Jongwon Choi, Kwang Moo Yi, Jihoon Kim, Jinho Choo, Byoungjip Kim,\n  Jin-Yeop Chang, Youngjune Gwon, Hyung Jin Chang", "title": "VaB-AL: Incorporating Class Imbalance and Difficulty with Variational\n  Bayes for Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning for discriminative models has largely been studied with the\nfocus on individual samples, with less emphasis on how classes are distributed\nor which classes are hard to deal with. In this work, we show that this is\nharmful. We propose a method based on the Bayes' rule, that can naturally\nincorporate class imbalance into the Active Learning framework. We derive that\nthree terms should be considered together when estimating the probability of a\nclassifier making a mistake for a given sample; i) probability of mislabelling\na class, ii) likelihood of the data given a predicted class, and iii) the prior\nprobability on the abundance of a predicted class. Implementing these terms\nrequires a generative model and an intractable likelihood estimation.\nTherefore, we train a Variational Auto Encoder (VAE) for this purpose. To\nfurther tie the VAE with the classifier and facilitate VAE training, we use the\nclassifiers' deep feature representations as input to the VAE. By considering\nall three probabilities, among them especially the data imbalance, we can\nsubstantially improve the potential of existing methods under limited data\nbudget. We show that our method can be applied to classification tasks on\nmultiple different datasets -- including one that is a real-world dataset with\nheavy data imbalance -- significantly outperforming the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 07:34:06 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 12:18:11 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Choi", "Jongwon", ""], ["Yi", "Kwang Moo", ""], ["Kim", "Jihoon", ""], ["Choo", "Jinho", ""], ["Kim", "Byoungjip", ""], ["Chang", "Jin-Yeop", ""], ["Gwon", "Youngjune", ""], ["Chang", "Hyung Jin", ""]]}, {"id": "2003.11266", "submitter": "Jun Yang", "authors": "Jun Yang, Fei Wang", "title": "Auto-Ensemble: An Adaptive Learning Rate Scheduling based Deep Learning\n  Model Ensembling", "comments": "14 pages, 8 figures, in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3041525", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ensembling deep learning models is a shortcut to promote its implementation\nin new scenarios, which can avoid tuning neural networks, losses and training\nalgorithms from scratch. However, it is difficult to collect sufficient\naccurate and diverse models through once training. This paper proposes\nAuto-Ensemble (AE) to collect checkpoints of deep learning model and ensemble\nthem automatically by adaptive learning rate scheduling algorithm. The\nadvantage of this method is to make the model converge to various local optima\nby scheduling the learning rate in once training. When the number of lo-cal\noptimal solutions tends to be saturated, all the collected checkpoints are used\nfor ensemble. Our method is universal, it can be applied to various scenarios.\nExperiment results on multiple datasets and neural networks demonstrate it is\neffective and competitive, especially on few-shot learning. Besides, we\nproposed a method to measure the distance among models. Then we can ensure the\naccuracy and diversity of collected models.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 08:17:31 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 02:14:42 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Yang", "Jun", ""], ["Wang", "Fei", ""]]}, {"id": "2003.11268", "submitter": "Farbod Taymouri", "authors": "Farbod Taymouri, Marcello La Rosa, Sarah Erfani, Zahra Dasht Bozorgi,\n  Ilya Verenich", "title": "Predictive Business Process Monitoring via Generative Adversarial Nets:\n  The Case of Next Event Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring aims to predict future characteristics of an\nongoing process case, such as case outcome or remaining timestamp. Recently,\nseveral predictive process monitoring methods based on deep learning such as\nLong Short-Term Memory or Convolutional Neural Network have been proposed to\naddress the problem of next event prediction. However, due to insufficient\ntraining data or sub-optimal network configuration and architecture, these\napproaches do not generalize well the problem at hand. This paper proposes a\nnovel adversarial training framework to address this shortcoming, based on an\nadaptation of Generative Adversarial Networks (GANs) to the realm of sequential\ntemporal data. The training works by putting one neural network against the\nother in a two-player game (hence the adversarial nature) which leads to\npredictions that are indistinguishable from the ground truth. We formally show\nthat the worst-case accuracy of the proposed approach is at least equal to the\naccuracy achieved in non-adversarial settings. From the experimental evaluation\nit emerges that the approach systematically outperforms all baselines both in\nterms of accuracy and earliness of the prediction, despite using a simple\nnetwork architecture and a naive feature encoding. Moreover, the approach is\nmore robust, as its accuracy is not affected by fluctuations over the case\nlength.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 08:31:28 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 09:44:10 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Taymouri", "Farbod", ""], ["La Rosa", "Marcello", ""], ["Erfani", "Sarah", ""], ["Bozorgi", "Zahra Dasht", ""], ["Verenich", "Ilya", ""]]}, {"id": "2003.11283", "submitter": "Jakramate Bootkrajang", "authors": "Jakramate Bootkrajang", "title": "Boosting Ridge Regression for High Dimensional Data Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ridge regression is a well established regression estimator which can\nconveniently be adapted for classification problems. One compelling reason is\nprobably the fact that ridge regression emits a closed-form solution thereby\nfacilitating the training phase. However in the case of high-dimensional\nproblems, the closed-form solution which involves inverting the regularised\ncovariance matrix is rather expensive to compute. The high computational demand\nof such operation also renders difficulty in constructing ensemble of ridge\nregressions. In this paper, we consider learning an ensemble of ridge\nregressors where each regressor is trained in its own randomly projected\nsubspace. Subspace regressors are later combined via adaptive boosting\nmethodology. Experiments based on five high-dimensional classification problems\ndemonstrated the effectiveness of the proposed method in terms of learning time\nand in some cases improved predictive performance can be observed.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 09:07:05 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Bootkrajang", "Jakramate", ""]]}, {"id": "2003.11285", "submitter": "Rui She", "authors": "Rui She and Pingyi Fan", "title": "MIM-Based GAN: Information Metric to Amplify Small Probability Events\n  Importance in Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In terms of Generative Adversarial Networks (GANs), the information metric to\ndiscriminate the generative data from the real data, lies in the key point of\ngeneration efficiency, which plays an important role in GAN-based applications,\nespecially in anomaly detection. As for the original GAN, there exist drawbacks\nfor its hidden information measure based on KL divergence on rare events\ngeneration and training performance for adversarial networks. Therefore, it is\nsignificant to investigate the metrics used in GANs to improve the generation\nability as well as bring gains in the training process. In this paper, we adopt\nthe exponential form, referred from the information measure, i.e. MIM, to\nreplace the logarithm form of the original GAN. This approach is called\nMIM-based GAN, has better performance on networks training and rare events\ngeneration. Specifically, we first discuss the characteristics of training\nprocess in this approach. Moreover, we also analyze its advantages on\ngenerating rare events in theory. In addition, we do simulations on the\ndatasets of MNIST and ODDS to see that the MIM-based GAN achieves\nstate-of-the-art performance on anomaly detection compared with some classical\nGANs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 09:11:56 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 12:33:51 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["She", "Rui", ""], ["Fan", "Pingyi", ""]]}, {"id": "2003.11316", "submitter": "Namhoon Lee", "authors": "Namhoon Lee, Thalaiyasingam Ajanthan, Philip H. S. Torr, Martin Jaggi", "title": "Understanding the Effects of Data Parallelism and Sparsity on Neural\n  Network Training", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two factors in neural network training: data parallelism and\nsparsity; here, data parallelism means processing training data in parallel\nusing distributed systems (or equivalently increasing batch size), so that\ntraining can be accelerated; for sparsity, we refer to pruning parameters in a\nneural network model, so as to reduce computational and memory cost. Despite\ntheir promising benefits, however, understanding of their effects on neural\nnetwork training remains elusive. In this work, we first measure these effects\nrigorously by conducting extensive experiments while tuning all metaparameters\ninvolved in the optimization. As a result, we find across various workloads of\ndata set, network model, and optimization algorithm that there exists a general\nscaling trend between batch size and number of training steps to convergence\nfor the effect of data parallelism, and further, difficulty of training under\nsparsity. Then, we develop a theoretical analysis based on the convergence\nproperties of stochastic gradient methods and smoothness of the optimization\nlandscape, which illustrates the observed phenomena precisely and generally,\nestablishing a better account of the effects of data parallelism and sparsity\non neural network training.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 10:49:22 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:32:08 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 08:35:13 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Lee", "Namhoon", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Torr", "Philip H. S.", ""], ["Jaggi", "Martin", ""]]}, {"id": "2003.11333", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat and Bogdan Gabrys", "title": "Accelerated learning algorithms of general fuzzy min-max neural network\n  using a novel hyperbox selection rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a method to accelerate the training process of a general\nfuzzy min-max neural network. The purpose is to reduce the unsuitable\nhyperboxes selected as the potential candidates of the expansion step of\nexisting hyperboxes to cover a new input pattern in the online learning\nalgorithms or candidates of the hyperbox aggregation process in the\nagglomerative learning algorithms. Our proposed approach is based on the\nmathematical formulas to form a branch-and-bound solution aiming to remove the\nhyperboxes which are certain not to satisfy expansion or aggregation\nconditions, and in turn, decreasing the training time of learning algorithms.\nThe efficiency of the proposed method is assessed over a number of widely used\ndata sets. The experimental results indicated the significant decrease in\ntraining time of the proposed approach for both online and agglomerative\nlearning algorithms. Notably, the training time of the online learning\nalgorithms is reduced from 1.2 to 12 times when using the proposed method,\nwhile the agglomerative learning algorithms are accelerated from 7 to 37 times\non average.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:26:18 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 10:22:19 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2003.11356", "submitter": "Sebastien Perez Vasseur Mr", "authors": "Sebasti\\'an P\\'erez Vasseur and Jos\\'e L. Aznarte", "title": "Probabilistic forecasting approaches for extreme NO$_2$ episodes: a\n  comparison of models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  High concentration episodes for NO$_2$ are increasingly dealt with by\nauthorities through traffic restrictions which are activated when air quality\ndeteriorates beyond certain thresholds. Foreseeing the probability that\npollutant concentrations reach those thresholds becomes thus a necessity.\nProbabilistic forecasting is a family of techniques that allow for the\nprediction of the expected distribution function instead of a single value. In\nthe case of NO$_2$, it allows for the calculation of future chances of\nexceeding thresholds and to detect pollution peaks. We thoroughly compared 10\nstate of the art probabilistic predictive models, using them to predict the\ndistribution of NO$_2$ concentrations in a urban location for a set of\nforecasting horizons (up to 60 hours). Quantile gradient boosted trees shows\nthe best performance, yielding the best results for both the expected value and\nthe forecast full distribution. Furthermore, we show how this approach can be\nused to detect pollution peaks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:45:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Vasseur", "Sebasti\u00e1n P\u00e9rez", ""], ["Aznarte", "Jos\u00e9 L.", ""]]}, {"id": "2003.11399", "submitter": "Silvia Makowski", "authors": "Silvia Makowski, Lena A. J\\\"ager, Lisa Schwetlick, Hans Trukenbrod,\n  Ralf Engbert, Tobias Scheffer", "title": "Discriminative Viewer Identification using Generative Models of Eye Gaze", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of identifying viewers of arbitrary images based on\ntheir eye gaze. Psychological research has derived generative stochastic models\nof eye movements. In order to exploit this background knowledge within a\ndiscriminatively trained classification model, we derive Fisher kernels from\ndifferent generative models of eye gaze. Experimentally, we find that the\nperformance of the classifier strongly depends on the underlying generative\nmodel. Using an SVM with Fisher kernel improves the classification performance\nover the underlying generative model.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 13:33:18 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Makowski", "Silvia", ""], ["J\u00e4ger", "Lena A.", ""], ["Schwetlick", "Lisa", ""], ["Trukenbrod", "Hans", ""], ["Engbert", "Ralf", ""], ["Scheffer", "Tobias", ""]]}, {"id": "2003.11403", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta and William B. Haskell", "title": "Convergence of Recursive Stochastic Algorithms using Wasserstein\n  Divergence", "comments": "34 pages, submitted to SIMODS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a unified framework, based on iterated random operator\ntheory, to analyze the convergence of constant stepsize recursive stochastic\nalgorithms (RSAs). RSAs use randomization to efficiently compute expectations,\nand so their iterates form a stochastic process. The key idea of our analysis\nis to lift the RSA into an appropriate higher-dimensional space and then\nexpress it as an equivalent Markov chain. Instead of determining the\nconvergence of this Markov chain (which may not converge under constant\nstepsize), we study the convergence of the distribution of this Markov chain.\nTo study this, we define a new notion of Wasserstein divergence. We show that\nif the distribution of the iterates in the Markov chain satisfy a contraction\nproperty with respect to the Wasserstein divergence, then the Markov chain\nadmits an invariant distribution. We show that convergence of a large family of\nconstant stepsize RSAs can be understood using this framework, and we provide\nseveral detailed examples.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 13:45:16 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 15:47:23 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Gupta", "Abhishek", ""], ["Haskell", "William B.", ""]]}, {"id": "2003.11413", "submitter": "Ivan Nazarov", "authors": "Ivan Nazarov and Evgeny Burnaev", "title": "Bayesian Sparsification Methods for Deep Complex-valued Networks", "comments": "Findings and conclusions unchanged. Improved overall presentation and\n  redid the plots with larger markers and annotations. Coherent story about\n  compression, CVNN, BI to SGVB with local reparameterization and additive\n  noise. Better coverage in lit-review, clearer connections of Dropout to\n  Bayes, VD, and pruning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With continual miniaturization ever more applications of deep learning can be\nfound in embedded systems, where it is common to encounter data with natural\ncomplex domain representation. To this end we extend Sparse Variational Dropout\nto complex-valued neural networks and verify the proposed Bayesian technique by\nconducting a large numerical study of the performance-compression trade-off of\nC-valued networks on two tasks: image recognition on MNIST-like and CIFAR10\ndatasets and music transcription on MusicNet. We replicate the state-of-the-art\nresult by Trabelsi et al. [2018] on MusicNet with a complex-valued network\ncompressed by 50-100x at a small performance penalty.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 13:57:16 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 03:53:14 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Nazarov", "Ivan", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2003.11423", "submitter": "Li-Chun Zhang", "authors": "Luis Sanguiao Sande and Li-Chun Zhang", "title": "Design-unbiased statistical learning in survey sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design-consistent model-assisted estimation has become the standard practice\nin survey sampling. However, a general theory is lacking so far, which allows\none to incorporate modern machine-learning techniques that can lead to\npotentially much more powerful assisting models. We propose a subsampling\nRao-Blackwell method, and develop a statistical learning theory for exactly\ndesign-unbiased estimation with the help of linear or non-linear prediction\nmodels. Our approach makes use of classic ideas from Statistical Science as\nwell as the rapidly growing field of Machine Learning. Provided rich auxiliary\ninformation, it can yield considerable efficiency gains over standard linear\nmodel-assisted methods, while ensuring valid estimation for the given target\npopulation, which is robust against potential mis-specifications of the\nassisting model at the individual level.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 14:27:39 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sande", "Luis Sanguiao", ""], ["Zhang", "Li-Chun", ""]]}, {"id": "2003.11435", "submitter": "Eero Siivola", "authors": "Eero Siivola, Akash Kumar Dhaka, Michael Riis Andersen, Javier\n  Gonzalez, Pablo Garcia Moreno, and Aki Vehtari", "title": "Preferential Batch Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research in Bayesian optimization (BO) has focused on \\emph{direct\nfeedback} scenarios, where one has access to exact, or perturbed, values of\nsome expensive-to-evaluate objective. This direction has been mainly driven by\nthe use of \\bo in machine learning hyper-parameter configuration problems.\nHowever, in domains such as modelling human preferences, A/B tests or\nrecommender systems, there is a need of methods that are able to replace direct\nfeedback with \\emph{preferential feedback}, obtained via rankings or pairwise\ncomparisons. In this work, we present Preferential Batch Bayesian Optimization\n(PBBO), a new framework that allows to find the optimum of a latent function of\ninterest, given any type of parallel preferential feedback for a group of two\nor more points. We do so by using a Gaussian process model with a likelihood\nspecially designed to enable parallel and efficient data collection mechanisms,\nwhich are key in modern machine learning. We show how the acquisitions\ndeveloped under this framework generalize and augment previous approaches in\nBayesian optimization, expanding the use of these techniques to a wider range\nof domains. An extensive simulation study shows the benefits of this approach,\nboth with simulated functions and four real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 14:59:15 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 06:50:19 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Siivola", "Eero", ""], ["Dhaka", "Akash Kumar", ""], ["Andersen", "Michael Riis", ""], ["Gonzalez", "Javier", ""], ["Moreno", "Pablo Garcia", ""], ["Vehtari", "Aki", ""]]}, {"id": "2003.11461", "submitter": "Shihao Xu", "authors": "Shihao Xu, Jing Fang, Xiping Hu, Edith Ngai, Yi Guo, Victor C.M.\n  Leung, Jun Cheng, Bin Hu", "title": "Emotion Recognition From Gait Analyses: Current Research and Future\n  Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human gait refers to a daily motion that represents not only mobility, but it\ncan also be used to identify the walker by either human observers or computers.\nRecent studies reveal that gait even conveys information about the walker's\nemotion. Individuals in different emotion states may show different gait\npatterns. The mapping between various emotions and gait patterns provides a new\nsource for automated emotion recognition. Compared to traditional emotion\ndetection biometrics, such as facial expression, speech and physiological\nparameters, gait is remotely observable, more difficult to imitate, and\nrequires less cooperation from the subject. These advantages make gait a\npromising source for emotion detection. This article reviews current research\non gait-based emotion detection, particularly on how gait parameters can be\naffected by different emotion states and how the emotion states can be\nrecognized through distinct gait patterns. We focus on the detailed methods and\ntechniques applied in the whole process of emotion recognition: data\ncollection, preprocessing, and classification. At last, we discuss possible\nfuture developments of efficient and effective gait-based emotion recognition\nusing the state of the art techniques on intelligent computation and big data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 08:22:33 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 11:28:02 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 01:39:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Xu", "Shihao", ""], ["Fang", "Jing", ""], ["Hu", "Xiping", ""], ["Ngai", "Edith", ""], ["Guo", "Yi", ""], ["Leung", "Victor C. M.", ""], ["Cheng", "Jun", ""], ["Hu", "Bin", ""]]}, {"id": "2003.11474", "submitter": "Gal Levy-Fix", "authors": "Gal Levy-Fix, Jason Zucker, Konstantin Stojanovic, and No\\'emie\n  Elhadad", "title": "Towards Patient Record Summarization Through Joint Phenotype Learning in\n  HIV Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying a patient's key problems over time is a common task for providers\nat the point care, yet a complex and time-consuming activity given current\nelectric health records. To enable a problem-oriented summarizer to identify a\npatient's comprehensive list of problems and their salience, we propose an\nunsupervised phenotyping approach that jointly learns a large number of\nphenotypes/problems across structured and unstructured data. To identify the\nappropriate granularity of the learned phenotypes, the model is trained on a\ntarget patient population of the same clinic. To enable the content\norganization of a problem-oriented summarizer, the model identifies phenotype\nrelatedness as well. The model leverages a correlated-mixed membership approach\nwith variational inference applied to heterogenous clinical data. In this\npaper, we focus our experiments on assessing the learned phenotypes and their\nrelatedness as learned from a specific patient population. We ground our\nexperiments in phenotyping patients from an HIV clinic in a large urban care\ninstitution (n=7,523), where patients have voluminous, longitudinal\ndocumentation, and where providers would benefit from summaries of these\npatient's medical histories, whether about their HIV or any comorbidities. We\nfind that the learned phenotypes and their relatedness are clinically valid\nwhen assessed qualitatively by clinical experts, and that the model surpasses\nbaseline in inferring phenotype-relatedness when comparing to existing\nexpert-curated condition groupings.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:41:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Levy-Fix", "Gal", ""], ["Zucker", "Jason", ""], ["Stojanovic", "Konstantin", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "2003.11489", "submitter": "Shibo Li", "authors": "Shibo Li, Wei Xing, Mike Kirby and Shandian Zhe", "title": "Scalable Variational Gaussian Process Regression Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process regression networks (GPRN) are powerful Bayesian models for\nmulti-output regression, but their inference is intractable. To address this\nissue, existing methods use a fully factorized structure (or a mixture of such\nstructures) over all the outputs and latent functions for posterior\napproximation, which, however, can miss the strong posterior dependencies among\nthe latent variables and hurt the inference quality. In addition, the updates\nof the variational parameters are inefficient and can be prohibitively\nexpensive for a large number of outputs. To overcome these limitations, we\npropose a scalable variational inference algorithm for GPRN, which not only\ncaptures the abundant posterior dependencies but also is much more efficient\nfor massive outputs. We tensorize the output space and introduce\ntensor/matrix-normal variational posteriors to capture the posterior\ncorrelations and to reduce the parameters. We jointly optimize all the\nparameters and exploit the inherent Kronecker product structure in the\nvariational model evidence lower bound to accelerate the computation. We\ndemonstrate the advantages of our method in several real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 16:39:47 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 12:19:24 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Li", "Shibo", ""], ["Xing", "Wei", ""], ["Kirby", "Mike", ""], ["Zhe", "Shandian", ""]]}, {"id": "2003.11492", "submitter": "Dhruti Dheda Ms.", "authors": "Dhruti Dheda and Ling Cheng", "title": "A multivariate water quality parameter prediction model using recurrent\n  neural network", "comments": "7 pages, 5 figures, 2 tables, submitted to the FUSION 2020 conference\n  for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global degradation of water resources is a matter of great concern,\nespecially for the survival of humanity. The effective monitoring and\nmanagement of existing water resources is necessary to achieve and maintain\noptimal water quality. The prediction of the quality of water resources will\naid in the timely identification of possible problem areas and thus increase\nthe efficiency of water management. The purpose of this research is to develop\na water quality prediction model based on water quality parameters through the\napplication of a specialised recurrent neural network (RNN), Long Short-Term\nMemory (LSTM) and the use of historical water quality data over several years.\nBoth multivariate single and multiple step LSTM models were developed, using a\nRectified Linear Unit (ReLU) activation function and a Root Mean Square\nPropagation (RMSprop) optimiser was developed. The single step model attained\nan error of 0.01 mg/L, whilst the multiple step model achieved a Root Mean\nSquared Error (RMSE) of 0.227 mg/L.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 16:49:52 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Dheda", "Dhruti", ""], ["Cheng", "Ling", ""]]}, {"id": "2003.11497", "submitter": "Karthik Bharath", "authors": "Huiling Le, Alexander Lewis, Karthik Bharath and Christopher Fallaize", "title": "A diffusion approach to Stein's method on Riemannian manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detail an approach to develop Stein's method for bounding integral metrics\non probability measures defined on a Riemannian manifold $\\mathbf{M}$. Our\napproach exploits the relationship between the generator of a diffusion on\n$\\mathbf{M}$ with target invariant measure and its characterising Stein\noperator. We consider a pair of such diffusions with different starting points,\nand investigate properties of solution to the Stein equation based on analysis\nof the distance process between the pair. Several examples elucidating the role\nof geometry of $\\mathbf{M}$ in these developments are presented.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:03:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Le", "Huiling", ""], ["Lewis", "Alexander", ""], ["Bharath", "Karthik", ""], ["Fallaize", "Christopher", ""]]}, {"id": "2003.11498", "submitter": "Shuai Tang", "authors": "Shuai Tang, Wesley J. Maddox, Charlie Dickens, Tom Diethe, Andreas\n  Damianou", "title": "Similarity of Neural Networks with Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A suitable similarity index for comparing learnt neural networks plays an\nimportant role in understanding the behaviour of the highly-nonlinear\nfunctions, and can provide insights on further theoretical analysis and\nempirical studies. We define two key steps when comparing models: firstly, the\nrepresentation abstracted from the learnt model, where we propose to leverage\nboth feature vectors and gradient ones (which are largely ignored in prior\nwork) into designing the representation of a neural network. Secondly, we\ndefine the employed similarity index which gives desired invariance properties,\nand we facilitate the chosen ones with sketching techniques for comparing\nvarious datasets efficiently. Empirically, we show that the proposed approach\nprovides a state-of-the-art method for computing similarity of neural networks\nthat are trained independently on different datasets and the tasks defined by\nthe datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:04:10 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Tang", "Shuai", ""], ["Maddox", "Wesley J.", ""], ["Dickens", "Charlie", ""], ["Diethe", "Tom", ""], ["Damianou", "Andreas", ""]]}, {"id": "2003.11504", "submitter": "Ali Senhaji", "authors": "Ali Senhaji, Jenni Raitoharju, Moncef Gabbouj and Alexandros Iosifidis", "title": "Not all domains are equally complex: Adaptive Multi-Domain Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches are highly specialized and require training separate\nmodels for different tasks. Multi-domain learning looks at ways to learn a\nmultitude of different tasks, each coming from a different domain, at once. The\nmost common approach in multi-domain learning is to form a domain agnostic\nmodel, the parameters of which are shared among all domains, and learn a small\nnumber of extra domain-specific parameters for each individual new domain.\nHowever, different domains come with different levels of difficulty;\nparameterizing the models of all domains using an augmented version of the\ndomain agnostic model leads to unnecessarily inefficient solutions, especially\nfor easy to solve tasks. We propose an adaptive parameterization approach to\ndeep neural networks for multi-domain learning. The proposed approach performs\non par with the original approach while reducing by far the number of\nparameters, leading to efficient multi-domain learning solutions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:16:00 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Senhaji", "Ali", ""], ["Raitoharju", "Jenni", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2003.11514", "submitter": "Javad Sharafi", "authors": "Javad Sharafi and Abbas Maarefparvar", "title": "Robustness Analysis of the Data-Selective Volterra NLMS Algorithm", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the data-selective adaptive Volterra filters have been proposed;\nhowever, up to now, there are not any theoretical analyses on its behavior\nrather than numerical simulations. Therefore, in this paper, we analyze the\nrobustness (in the sense of l2-stability) of the data-selective Volterra\nnormalized least-mean-square (DS-VNLMS) algorithm. First, we study the local\nrobustness of this algorithm at any iteration, then we propose a global bound\nfor the error/discrepancy in the coefficient vector. Also, we demonstrate that\nthe DS-VNLMS algorithm improves the parameter estimation for the majority of\nthe iterations that an update is implemented. Moreover, we prove that if the\nnoise bound is known, we can set the DS-VNLMS so that it never degrades the\nestimate. The simulation results corroborate the validity of the executed\nanalysis and demonstrate that the DS-VNLMS algorithm is robust against noise,\nno matter how its parameters are adopted.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:38:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sharafi", "Javad", ""], ["Maarefparvar", "Abbas", ""]]}, {"id": "2003.11515", "submitter": "Amy X. Lu", "authors": "Haoran Zhang, Amy X. Lu, Mohamed Abdalla, Matthew McDermott, Marzyeh\n  Ghassemi", "title": "Hurtful Words: Quantifying Biases in Clinical Contextual Word Embeddings", "comments": "Accepted at ACM CHIL 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the extent to which embeddings may encode\nmarginalized populations differently, and how this may lead to a perpetuation\nof biases and worsened performance on clinical tasks. We pretrain deep\nembedding models (BERT) on medical notes from the MIMIC-III hospital dataset,\nand quantify potential disparities using two approaches. First, we identify\ndangerous latent relationships that are captured by the contextual word\nembeddings using a fill-in-the-blank method with text from real clinical notes\nand a log probability bias score quantification. Second, we evaluate\nperformance gaps across different definitions of fairness on over 50 downstream\nclinical prediction tasks that include detection of acute and chronic\nconditions. We find that classifiers trained from BERT representations exhibit\nstatistically significant differences in performance, often favoring the\nmajority group with regards to gender, language, ethnicity, and insurance\nstatus. Finally, we explore shortcomings of using adversarial debiasing to\nobfuscate subgroup information in contextual word embeddings, and recommend\nbest practices for such deep embedding models in clinical settings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:21:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Lu", "Amy X.", ""], ["Abdalla", "Mohamed", ""], ["McDermott", "Matthew", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2003.11520", "submitter": "Radomir Popovi\\'c", "authors": "Radomir Popovi\\'c, Florian Lemmerich and Markus Strohmaier", "title": "Joint Multiclass Debiasing of Word Embeddings", "comments": "10 pages, 2 figures. To appear in the Proceedings of the 25th\n  International Symposium on Intelligent Systems (ISMIS 2020), May 2020, Graz,\n  Austria. Online appendix available at: https://git.io/JvL10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in Word Embeddings has been a subject of recent interest, along with\nefforts for its reduction. Current approaches show promising progress towards\ndebiasing single bias dimensions such as gender or race. In this paper, we\npresent a joint multiclass debiasing approach that is capable of debiasing\nmultiple bias dimensions simultaneously. In that direction, we present two\napproaches, HardWEAT and SoftWEAT, that aim to reduce biases by minimizing the\nscores of the Word Embeddings Association Test (WEAT). We demonstrate the\nviability of our methods by debiasing Word Embeddings on three classes of\nbiases (religion, gender and race) in three different publicly available word\nembeddings and show that our concepts can both reduce or even completely\neliminate bias, while maintaining meaningful relationships between vectors in\nword embeddings. Our work strengthens the foundation for more unbiased neural\nrepresentations of textual data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:06:37 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Popovi\u0107", "Radomir", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2003.11530", "submitter": "Ping Li", "authors": "Haiyan Yin, Dingcheng Li, Xu Li, Ping Li", "title": "Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving\n  Adversarial Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative models that can generate high-quality text with\nsufficient diversity is an important open problem for Natural Language\nGeneration (NLG) community. Recently, generative adversarial models have been\napplied extensively on text generation tasks, where the adversarially trained\ngenerators alleviate the exposure bias experienced by conventional maximum\nlikelihood approaches and result in promising generation quality. However, due\nto the notorious defect of mode collapse for adversarial training, the\nadversarially trained generators face a quality-diversity trade-off, i.e., the\ngenerator models tend to sacrifice generation diversity severely for increasing\ngeneration quality. In this paper, we propose a novel approach which aims to\nimprove the performance of adversarial text generation via efficiently\ndecelerating mode collapse of the adversarial training. To this end, we\nintroduce a cooperative training paradigm, where a language model is\ncooperatively trained with the generator and we utilize the language model to\nefficiently shape the data distribution of the generator against mode collapse.\nMoreover, instead of engaging the cooperative update for the generator in a\nprincipled way, we formulate a meta learning mechanism, where the cooperative\nupdate to the generator serves as a high level meta task, with an intuition of\nensuring the parameters of the generator after the adversarial update would\nstay resistant against mode collapse. In the experiment, we demonstrate our\nproposed approach can efficiently slow down the pace of mode collapse for the\nadversarial text generators. Overall, our proposed method is able to outperform\nthe baseline approaches with significant margins in terms of both generation\nquality and diversity in the testified domains.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 04:47:52 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Yin", "Haiyan", ""], ["Li", "Dingcheng", ""], ["Li", "Xu", ""], ["Li", "Ping", ""]]}, {"id": "2003.11561", "submitter": "Felipe Maia Polo", "authors": "Felipe Maia Polo, Itamar Ciochetti, Emerson Bertolo", "title": "Predicting Legal Proceedings Status: Approaches Based on Sequential Text\n  Data", "comments": "Published at the 18th International Conference on Artificial\n  Intelligence and Law (ICAIL) 2021 as an extended abstract", "journal-ref": null, "doi": "10.1145/3462757.3466138", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to develop predictive models to classify\nBrazilian legal proceedings in three possible classes of status: (i) archived\nproceedings, (ii) active proceedings, and (iii) suspended proceedings. This\nproblem's resolution is intended to assist public and private institutions in\nmanaging large portfolios of legal proceedings, providing gains in scale and\nefficiency. In this paper, legal proceedings are made up of sequences of short\ntexts called \"motions.\" We combined several natural language processing (NLP)\nand machine learning techniques to solve the problem. Although working with\nPortuguese NLP, which can be challenging due to lack of resources, our\napproaches performed remarkably well in the classification task, achieving\nmaximum accuracy of .93 and top average F1 Scores of .89 (macro) and .93\n(weighted). Furthermore, we could extract and interpret the patterns learned by\none of our models besides quantifying how those patterns relate to the\nclassification task. The interpretability step is important among machine\nlearning legal applications and gives us an exciting insight into how black-box\nmodels make decisions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 19:40:57 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 20:36:55 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 16:24:36 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 02:57:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Polo", "Felipe Maia", ""], ["Ciochetti", "Itamar", ""], ["Bertolo", "Emerson", ""]]}, {"id": "2003.11562", "submitter": "Abhilash Jain", "authors": "Abhilash Jain, Aku Ruohe, Stig-Arne Gr\\\"onroos, Mikko Kurimo", "title": "Finnish Language Modeling with Deep Transformer Models", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Transformers have recently taken the center stage in language modeling after\nLSTM's were considered the dominant model architecture for a long time. In this\nproject, we investigate the performance of the Transformer architectures-BERT\nand Transformer-XL for the language modeling task. We use a sub-word model\nsetting with the Finnish language and compare it to the previous State of the\nart (SOTA) LSTM model. BERT achieves a pseudo-perplexity score of 14.5, which\nis the first such measure achieved as far as we know. Transformer-XL improves\nupon the perplexity score to 73.58 which is 27\\% better than the LSTM model.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 15:12:03 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 10:02:24 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Jain", "Abhilash", ""], ["Ruohe", "Aku", ""], ["Gr\u00f6nroos", "Stig-Arne", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2003.11563", "submitter": "Elena Kochkina", "authors": "Harish Tayyar Madabushi, Elena Kochkina, Michael Castelle", "title": "Cost-Sensitive BERT for Generalisable Sentence Classification with\n  Imbalanced Data", "comments": "NLP4IF 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automatic identification of propaganda has gained significance in recent\nyears due to technological and social changes in the way news is generated and\nconsumed. That this task can be addressed effectively using BERT, a powerful\nnew architecture which can be fine-tuned for text classification tasks, is not\nsurprising. However, propaganda detection, like other tasks that deal with news\ndocuments and other forms of decontextualized social communication (e.g.\nsentiment analysis), inherently deals with data whose categories are\nsimultaneously imbalanced and dissimilar. We show that BERT, while capable of\nhandling imbalanced classes with no additional data augmentation, does not\ngeneralise well when the training and test data are sufficiently dissimilar (as\nis often the case with news sources, whose topics evolve over time). We show\nhow to address this problem by providing a statistical measure of similarity\nbetween datasets and a method of incorporating cost-weighting into BERT when\nthe training and test sets are dissimilar. We test these methods on the\nPropaganda Techniques Corpus (PTC) and achieve the second-highest score on\nsentence-level propaganda classification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:10:57 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Madabushi", "Harish Tayyar", ""], ["Kochkina", "Elena", ""], ["Castelle", "Michael", ""]]}, {"id": "2003.11566", "submitter": "Luis Oala", "authors": "Luis Oala, Cosmas Hei{\\ss}, Jan Macdonald, Maximilian M\\\"arz, Wojciech\n  Samek and Gitta Kutyniok", "title": "Interval Neural Networks: Uncertainty Scores", "comments": "LO and CH contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast, non-Bayesian method for producing uncertainty scores in\nthe output of pre-trained deep neural networks (DNNs) using a data-driven\ninterval propagating network. This interval neural network (INN) has interval\nvalued parameters and propagates its input using interval arithmetic. The INN\nproduces sensible lower and upper bounds encompassing the ground truth. We\nprovide theoretical justification for the validity of these bounds.\nFurthermore, its asymmetric uncertainty scores offer additional, directional\ninformation beyond what Gaussian-based, symmetric variance estimation can\nprovide. We find that noise in the data is adequately captured by the intervals\nproduced with our method. In numerical experiments on an image reconstruction\ntask, we demonstrate the practical utility of INNs as a proxy for the\nprediction error in comparison to two state-of-the-art uncertainty\nquantification methods. In summary, INNs produce fast, theoretically justified\nuncertainty scores for DNNs that are easy to interpret, come with added\ninformation and pose as improved error proxies - features that may prove useful\nin advancing the usability of DNNs especially in sensitive applications such as\nhealth care.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 18:03:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Oala", "Luis", ""], ["Hei\u00df", "Cosmas", ""], ["Macdonald", "Jan", ""], ["M\u00e4rz", "Maximilian", ""], ["Samek", "Wojciech", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "2003.11593", "submitter": "Hamid Jalalzai", "authors": "Hamid Jalalzai, Pierre Colombo, Chlo\\'e Clavel, Eric Gaussier,\n  Giovanna Varni, Emmanuel Vignon, Anne Sabourin", "title": "Heavy-tailed Representations, Text Polarity Classification & Data\n  Augmentation", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Dec\n  2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approaches to text representation in natural language rely on\nlearning embeddings on massive corpora which have convenient properties such as\ncompositionality and distance preservation. In this paper, we develop a novel\nmethod to learn a heavy-tailed embedding with desirable regularity properties\nregarding the distributional tails, which allows to analyze the points far away\nfrom the distribution bulk using the framework of multivariate extreme value\ntheory. In particular, a classifier dedicated to the tails of the proposed\nembedding is obtained which performance outperforms the baseline. This\nclassifier exhibits a scale invariance property which we leverage by\nintroducing a novel text generation method for label preserving dataset\naugmentation. Numerical experiments on synthetic and real text data demonstrate\nthe relevance of the proposed framework and confirm that this method generates\nmeaningful sentences with controllable attribute, e.g. positive or negative\nsentiment.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 19:24:05 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 15:49:21 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Jalalzai", "Hamid", ""], ["Colombo", "Pierre", ""], ["Clavel", "Chlo\u00e9", ""], ["Gaussier", "Eric", ""], ["Varni", "Giovanna", ""], ["Vignon", "Emmanuel", ""], ["Sabourin", "Anne", ""]]}, {"id": "2003.11608", "submitter": "Marius Jahrens", "authors": "Marius Jahrens and Thomas Martinetz", "title": "Solving Raven's Progressive Matrices with Multi-Layer Relation Networks", "comments": "6 pages, 6 figures, to be published in the Proceedings of the IJCNN\n  2020, source code available at\n  http://webmail.inb.uni-luebeck.de/exchange-supplement/PGM_MLRN_supplementary.zip", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raven's Progressive Matrices are a benchmark originally designed to test the\ncognitive abilities of humans. It has recently been adapted to test relational\nreasoning in machine learning systems. For this purpose the so-called\nProcedurally Generated Matrices dataset was set up, which is so far one of the\nmost difficult relational reasoning benchmarks. Here we show that deep neural\nnetworks are capable of solving this benchmark, reaching an accuracy of 98.0\npercent over the previous state-of-the-art of 62.6 percent by combining Wild\nRelation Networks with Multi-Layer Relation Networks and introducing Magnitude\nEncoding, an encoding scheme designed for late fusion architectures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:14:33 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Jahrens", "Marius", ""], ["Martinetz", "Thomas", ""]]}, {"id": "2003.11619", "submitter": "Christopher Snyder", "authors": "Christopher Snyder, Sriram Vishwanath", "title": "Deep Networks as Logical Circuits: Generalization and Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not only are Deep Neural Networks (DNNs) black box models, but also we\nfrequently conceptualize them as such. We lack good interpretations of the\nmechanisms linking inputs to outputs. Therefore, we find it difficult to\nanalyze in human-meaningful terms (1) what the network learned and (2) whether\nthe network learned. We present a hierarchical decomposition of the DNN\ndiscrete classification map into logical (AND/OR) combinations of intermediate\n(True/False) classifiers of the input. Those classifiers that can not be\nfurther decomposed, called atoms, are (interpretable) linear classifiers. Taken\ntogether, we obtain a logical circuit with linear classifier inputs that\ncomputes the same label as the DNN. This circuit does not structurally resemble\nthe network architecture, and it may require many fewer parameters, depending\non the configuration of weights. In these cases, we obtain simultaneously an\ninterpretation and generalization bound (for the original DNN), connecting two\nfronts which have historically been investigated separately. Unlike compression\ntechniques, our representation is. We motivate the utility of this perspective\nby studying DNNs in simple, controlled settings, where we obtain superior\ngeneralization bounds despite using only combinatorial information (e.g. no\nmargin information). We demonstrate how to \"open the black box\" on the MNIST\ndataset. We show that the learned, internal, logical computations correspond to\nsemantically meaningful (unlabeled) categories that allow DNN descriptions in\nplain English. We improve the generalization of an already trained network by\ninterpreting, diagnosing, and replacing components the logical circuit that is\nthe DNN.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:39:53 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:29:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Snyder", "Christopher", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "2003.11622", "submitter": "Constanza Fierro", "authors": "Constanza Fierro, Jorge P\\'erez, Javier Mora", "title": "Predicting Unplanned Readmissions with Highly Unstructured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have been successfully applied to predict unplanned\nreadmissions of patients in medical centers. The training data for these models\nis usually based on historical medical records that contain a significant\namount of free-text from admission reports, referrals, exam notes, etc. Most of\nthe models proposed so far are tailored to English text data and assume that\nelectronic medical records follow standards common in developed countries.\nThese two characteristics make them difficult to apply in developing countries\nthat do not necessarily follow international standards for registering patient\ninformation, or that store text information in languages other than English.\n  In this paper we propose a deep learning architecture for predicting\nunplanned readmissions that consumes data that is significantly less structured\ncompared with previous models in the literature. We use it to present the first\nresults for this task in a large clinical dataset that mainly contains Spanish\ntext data. The dataset is composed of almost 10 years of records in a Chilean\nmedical center. On this dataset, our model achieves results that are comparable\nto some of the most recent results obtained in US medical centers for the same\ntask (0.76 AUROC).\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 23:21:00 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:23:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Fierro", "Constanza", ""], ["P\u00e9rez", "Jorge", ""], ["Mora", "Javier", ""]]}, {"id": "2003.11627", "submitter": "Weizhe Lin", "authors": "Xiaodong Wu, Weizhe Lin, Zhilin Wang, and Elena Rastorgueva", "title": "Author2Vec: A Framework for Generating User Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online forums and social media platforms provide noisy but valuable data\nevery day. In this paper, we propose a novel end-to-end neural network-based\nuser embedding system, Author2Vec. The model incorporates sentence\nrepresentations generated by BERT (Bidirectional Encoder Representations from\nTransformers) with a novel unsupervised pre-training objective, authorship\nclassification, to produce better user embedding that encodes useful\nuser-intrinsic properties. This user embedding system was pre-trained on post\ndata of 10k Reddit users and was analyzed and evaluated on two user\nclassification benchmarks: depression detection and personality classification,\nin which the model proved to outperform traditional count-based and\nprediction-based methods. We substantiate that Author2Vec successfully encoded\nuseful user attributes and the generated user embedding performs well in\ndownstream classification tasks without further finetuning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 23:31:11 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Wu", "Xiaodong", ""], ["Lin", "Weizhe", ""], ["Wang", "Zhilin", ""], ["Rastorgueva", "Elena", ""]]}, {"id": "2003.11630", "submitter": "Marc-Etienne Brunet", "authors": "Elnaz Barshan, Marc-Etienne Brunet, Gintare Karolina Dziugaite", "title": "RelatIF: Identifying Explanatory Training Examples via Relative\n  Influence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the use of influence functions to identify relevant\ntraining examples that one might hope \"explain\" the predictions of a machine\nlearning model. One shortcoming of influence functions is that the training\nexamples deemed most \"influential\" are often outliers or mislabelled, making\nthem poor choices for explanation. In order to address this shortcoming, we\nseparate the role of global versus local influence. We introduce RelatIF, a new\nclass of criteria for choosing relevant training examples by way of an\noptimization objective that places a constraint on global influence. RelatIF\nconsiders the local influence that an explanatory example has on a prediction\nrelative to its global effects on the model. In empirical evaluations, we find\nthat the examples returned by RelatIF are more intuitive when compared to those\nfound using influence functions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:59:54 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Barshan", "Elnaz", ""], ["Brunet", "Marc-Etienne", ""], ["Dziugaite", "Gintare Karolina", ""]]}, {"id": "2003.11639", "submitter": "Clemens Jonathan Simon Schaefer", "authors": "Clemens JS Schaefer, Patrick Faley, Emre O Neftci, Siddharth Joshi", "title": "Memory Organization for Energy-Efficient Learning and Inference in\n  Digital Neuromorphic Accelerators", "comments": "submitted to ISCAS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy efficiency of neuromorphic hardware is greatly affected by the\nenergy of storing, accessing, and updating synaptic parameters. Various methods\nof memory organisation targeting energy-efficient digital accelerators have\nbeen investigated in the past, however, they do not completely encapsulate the\nenergy costs at a system level. To address this shortcoming and to account for\nvarious overheads, we synthesize the controller and memory for different\nencoding schemes and extract the energy costs from these synthesized blocks.\nAdditionally, we introduce functional encoding for structured connectivity such\nas the connectivity in convolutional layers. Functional encoding offers a 58%\nreduction in the energy to implement a backward pass and weight update in such\nlayers compared to existing index-based solutions. We show that for a 2 layer\nspiking neural network trained to retain a spatio-temporal pattern, bitmap\n(PB-BMP) based organization can encode the sparser networks more efficiently.\nThis form of encoding delivers a 1.37x improvement in energy efficiency coming\nat the cost of a 4% degradation in network retention accuracy as measured by\nthe van Rossum distance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:19:09 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Schaefer", "Clemens JS", ""], ["Faley", "Patrick", ""], ["Neftci", "Emre O", ""], ["Joshi", "Siddharth", ""]]}, {"id": "2003.11640", "submitter": "Xavier Hinaut", "authors": "Anthony Strock (Mnemosyne, LaBRI, IMN), Nicolas Rougier (Mnemosyne,\n  LaBRI, IMN), Xavier Hinaut (Mnemosyne, LaBRI, IMN)", "title": "Transfer between long-term and short-term memory using Conceptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG nlin.AO q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a recurrent neural network model of working memory combining\nshort-term and long-term components. e short-term component is modelled using a\ngated reservoir model that is trained to hold a value from an input stream when\na gate signal is on. e long-term component is modelled using conceptors in\norder to store inner temporal patterns (that corresponds to values). We combine\nthese two components to obtain a model where information can go from long-term\nmemory to short-term memory and vice-versa and we show how standard operations\non conceptors allow to combine long-term memories and describe their effect on\nshort-term memory.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:13:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Strock", "Anthony", "", "Mnemosyne, LaBRI, IMN"], ["Rougier", "Nicolas", "", "Mnemosyne,\n  LaBRI, IMN"], ["Hinaut", "Xavier", "", "Mnemosyne, LaBRI, IMN"]]}, {"id": "2003.11643", "submitter": "Sairamvinay Vijayaraghavan", "authors": "Sairamvinay Vijayaraghavan, Debraj Basu", "title": "Sentiment Analysis in Drug Reviews using Supervised Machine Learning\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis is an important algorithm in Natural Language Processing\nwhich is used to detect sentiment within some text. In our project, we had\nchosen to work on analyzing reviews of various drugs which have been reviewed\nin form of texts and have also been given a rating on a scale from 1-10. We had\nobtained this data set from the UCI machine learning repository which had 2\ndata sets: train and test (split as 75-25\\%). We had split the number rating\nfor the drug into three classes in general: positive (7-10), negative (1-4) or\nneutral(4-7). There are multiple reviews for the drugs that belong to a similar\ncondition and we decided to investigate how the reviews for different\nconditions use different words impact the ratings of the drugs. Our intention\nwas mainly to implement supervised machine learning classification algorithms\nthat predict the class of the rating using the textual review. We had primarily\nimplemented different embeddings such as Term Frequency Inverse Document\nFrequency (TFIDF) and the Count Vectors (CV). We had trained models on the most\npopular conditions such as \"Birth Control\", \"Depression\" and \"Pain\" within the\ndata set and obtained good results while predicting the test data sets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 20:13:11 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Vijayaraghavan", "Sairamvinay", ""], ["Basu", "Debraj", ""]]}, {"id": "2003.11644", "submitter": "Ankit Pal", "authors": "Ankit Pal, Muru Selvakumar and Malaikannan Sankarasubbu", "title": "Multi-Label Text Classification using Attention-based Graph Neural\n  Network", "comments": null, "journal-ref": "12th International Conference on Agents and Artificial\n  Intelligence (ICAART 2020)", "doi": "10.5220/0008940304940505", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In Multi-Label Text Classification (MLTC), one sample can belong to more than\none class. It is observed that most MLTC tasks, there are dependencies or\ncorrelations among labels. Existing methods tend to ignore the relationship\namong labels. In this paper, a graph attention network-based model is proposed\nto capture the attentive dependency structure among the labels. The graph\nattention network uses a feature matrix and a correlation matrix to capture and\nexplore the crucial dependencies between the labels and generate classifiers\nfor the task. The generated classifiers are applied to sentence feature vectors\nobtained from the text feature extraction network (BiLSTM) to enable end-to-end\ntraining. Attention allows the system to assign different weights to neighbor\nnodes per label, thus allowing it to learn the dependencies among labels\nimplicitly. The results of the proposed model are validated on five real-world\nMLTC datasets. The proposed model achieves similar or better performance\ncompared to the previous state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:12:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Pal", "Ankit", ""], ["Selvakumar", "Muru", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "2003.11645", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream\n  Tasks", "comments": "8 pages, 7 figures, 6 tables; added new references based on new input\n  in the result section about CI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word2Vec is a prominent model for natural language processing (NLP) tasks.\nSimilar inspiration is found in distributed embeddings for new state-of-the-art\n(SotA) deep neural networks. However, wrong combination of hyper-parameters can\nproduce poor quality vectors. The objective of this work is to empirically show\noptimal combination of hyper-parameters exists and evaluate various\ncombinations. We compare them with the released, pre-trained original word2vec\nmodel. Both intrinsic and extrinsic (downstream) evaluations, including named\nentity recognition (NER) and sentiment analysis (SA) were carried out. The\ndownstream tasks reveal that the best model is usually task-specific, high\nanalogy scores don't necessarily correlate positively with F1 scores and the\nsame applies to focus on data alone. Increasing vector dimension size after a\npoint leads to poor quality or performance. If ethical considerations to save\ntime, energy and the environment are made, then reasonably smaller corpora may\ndo just as well or even better in some cases. Besides, using a small corpus, we\nobtain better human-assigned WordSim scores, corresponding Spearman correlation\nand better downstream performances (with significance tests) compared to the\noriginal model, trained on 100 billion-word corpus.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 07:38:17 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 10:09:22 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 06:02:44 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2003.11652", "submitter": "Jathushan Rajasegaran", "authors": "Jathushan Rajasegaran, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan,\n  Mubarak Shah", "title": "iTAML: An Incremental Task-Agnostic Meta-learning Approach", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can continuously learn new knowledge as their experience grows. In\ncontrast, previous learning in deep neural networks can quickly fade out when\nthey are trained on a new task. In this paper, we hypothesize this problem can\nbe avoided by learning a set of generalized parameters, that are neither\nspecific to old nor new tasks. In this pursuit, we introduce a novel\nmeta-learning approach that seeks to maintain an equilibrium between all the\nencountered tasks. This is ensured by a new meta-update rule which avoids\ncatastrophic forgetting. In comparison to previous meta-learning techniques,\nour approach is task-agnostic. When presented with a continuum of data, our\nmodel automatically identifies the task and quickly adapts to it with just a\nsingle update. We perform extensive experiments on five datasets in a\nclass-incremental setting, leading to significant improvements over the state\nof the art methods (e.g., a 21.3% boost on CIFAR100 with 10 incremental tasks).\nSpecifically, on large-scale datasets that generally prove difficult cases for\nincremental learning, our approach delivers absolute gains as high as 19.1% and\n7.4% on ImageNet and MS-Celeb datasets, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 21:42:48 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Rajasegaran", "Jathushan", ""], ["Khan", "Salman", ""], ["Hayat", "Munawar", ""], ["Khan", "Fahad Shahbaz", ""], ["Shah", "Mubarak", ""]]}, {"id": "2003.11657", "submitter": "V\\'it Musil", "authors": "Michal Rol\\'inek, Paul Swoboda, Dominik Zietlow, Anselm Paulus, V\\'it\n  Musil, and Georg Martius", "title": "Deep Graph Matching via Blackbox Differentiation of Combinatorial\n  Solvers", "comments": "ECCV 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on recent progress at the intersection of combinatorial optimization\nand deep learning, we propose an end-to-end trainable architecture for deep\ngraph matching that contains unmodified combinatorial solvers. Using the\npresence of heavily optimized combinatorial solvers together with some\nimprovements in architecture design, we advance state-of-the-art on deep graph\nmatching benchmarks for keypoint correspondence. In addition, we highlight the\nconceptual advantages of incorporating solvers into deep learning\narchitectures, such as the possibility of post-processing with a strong\nmulti-graph matching solver or the indifference to changes in the training\nsetting. Finally, we propose two new challenging experimental setups. The code\nis available at https://github.com/martius-lab/blackbox-deep-graph-matching\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 21:53:12 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 10:15:33 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Rol\u00ednek", "Michal", ""], ["Swoboda", "Paul", ""], ["Zietlow", "Dominik", ""], ["Paulus", "Anselm", ""], ["Musil", "V\u00edt", ""], ["Martius", "Georg", ""]]}, {"id": "2003.11666", "submitter": "Vitaliy Chiley", "authors": "Atli Kosson, Vitaliy Chiley, Abhinav Venigalla, Joel Hestness, Urs\n  K\\\"oster", "title": "Pipelined Backpropagation at Scale: Training Large Models without\n  Batches", "comments": "Proceedings of the 4th MLSys Conference, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New hardware can substantially increase the speed and efficiency of deep\nneural network training. To guide the development of future hardware\narchitectures, it is pertinent to explore the hardware and machine learning\nproperties of alternative training algorithms. In this work we evaluate the use\nof small batch, fine-grained Pipelined Backpropagation, an asynchronous\npipeline parallel training algorithm that has significant hardware advantages.\nWe introduce two methods, Spike Compensation and Linear Weight Prediction, that\neffectively mitigate the downsides caused by the asynchronicity of Pipelined\nBackpropagation and outperform existing techniques in our setting. We show that\nappropriate normalization and small batch sizes can also aid training. With our\nmethods, fine-grained Pipelined Backpropagation using a batch size of one can\nmatch the accuracy of SGD for multiple networks trained on CIFAR-10 and\nImageNet. Simple scaling rules allow the use of existing hyperparameters for\ntraditional training without additional tuning.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:26:28 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 04:32:28 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 00:50:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kosson", "Atli", ""], ["Chiley", "Vitaliy", ""], ["Venigalla", "Abhinav", ""], ["Hestness", "Joel", ""], ["K\u00f6ster", "Urs", ""]]}, {"id": "2003.11687", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Patrick Coronado, Hemant Purohit, and Huzefa Rangwala", "title": "Common-Knowledge Concept Recognition for SEVA", "comments": "Source code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We build a common-knowledge concept recognition system for a Systems\nEngineer's Virtual Assistant (SEVA) which can be used for downstream tasks such\nas relation extraction, knowledge graph construction, and question-answering.\nThe problem is formulated as a token classification task similar to named\nentity extraction. With the help of a domain expert and text processing\nmethods, we construct a dataset annotated at the word-level by carefully\ndefining a labelling scheme to train a sequence model to recognize systems\nengineering concepts. We use a pre-trained language model and fine-tune it with\nthe labeled dataset of concepts. In addition, we also create some essential\ndatasets for information such as abbreviations and definitions from the systems\nengineering domain. Finally, we construct a simple knowledge graph using these\nextracted concepts along with some hyponym relations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 00:30:36 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Krishnan", "Jitin", ""], ["Coronado", "Patrick", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2003.11696", "submitter": "Wenyu Zhang", "authors": "Wenyu Zhang, Skyler Seto, Devesh K. Jha", "title": "CAZSL: Zero-Shot Regression for Pushing Models by Generalizing Through\n  Context", "comments": "Accepted at IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning accurate models of the physical world is required for a lot of\nrobotic manipulation tasks. However, during manipulation, robots are expected\nto interact with unknown workpieces so that building predictive models which\ncan generalize over a number of these objects is highly desirable. In this\npaper, we study the problem of designing deep learning agents which can\ngeneralize their models of the physical world by building context-aware\nlearning models. The purpose of these agents is to quickly adapt and/or\ngeneralize their notion of physics of interaction in the real world based on\ncertain features about the interacting objects that provide different contexts\nto the predictive models. With this motivation, we present context-aware zero\nshot learning (CAZSL, pronounced as casual) models, an approach utilizing a\nSiamese network architecture, embedding space masking and regularization based\non context variables which allows us to learn a model that can generalize to\ndifferent parameters or features of the interacting objects. We test our\nproposed learning algorithm on the recently released Omnipush datatset that\nallows testing of meta-learning capabilities using low-dimensional data. Codes\nfor CAZSL are available at https://www.merl.com/research/license/CAZSL.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 01:21:58 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 04:21:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Wenyu", ""], ["Seto", "Skyler", ""], ["Jha", "Devesh K.", ""]]}, {"id": "2003.11702", "submitter": "Muhammet Balcilar Dr.", "authors": "Muhammet Balcilar, Guillaume Renton, Pierre Heroux, Benoit Gauzere,\n  Sebastien Adam, Paul Honeine", "title": "Bridging the Gap Between Spectral and Spatial Domains in Graph Neural\n  Networks", "comments": "24 pages, 8figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at revisiting Graph Convolutional Neural Networks by bridging\nthe gap between spectral and spatial design of graph convolutions. We\ntheoretically demonstrate some equivalence of the graph convolution process\nregardless it is designed in the spatial or the spectral domain. The obtained\ngeneral framework allows to lead a spectral analysis of the most popular\nConvGNNs, explaining their performance and showing their limits. Moreover, the\nproposed framework is used to design new convolutions in spectral domain with a\ncustom frequency profile while applying them in the spatial domain. We also\npropose a generalization of the depthwise separable convolution framework for\ngraph convolutional networks, what allows to decrease the total number of\ntrainable parameters by keeping the capacity of the model. To the best of our\nknowledge, such a framework has never been used in the GNNs literature. Our\nproposals are evaluated on both transductive and inductive graph learning\nproblems. Obtained results show the relevance of the proposed method and\nprovide one of the first experimental evidence of transferability of spectral\nfilter coefficients from one graph to another. Our source codes are publicly\navailable at: https://github.com/balcilar/Spectral-Designed-Graph-Convolutions\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 01:49:24 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Balcilar", "Muhammet", ""], ["Renton", "Guillaume", ""], ["Heroux", "Pierre", ""], ["Gauzere", "Benoit", ""], ["Adam", "Sebastien", ""], ["Honeine", "Paul", ""]]}, {"id": "2003.11723", "submitter": "Yuntao Du", "authors": "Yuntao Du, Ruiting Zhang, Xiaowen Zhang, Yirong Yao, Hengyang Lu,\n  Chongjun Wang", "title": "Learning transferable and discriminative features for unsupervised\n  domain adaptation", "comments": "Accepted by IDA journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although achieving remarkable progress, it is very difficult to induce a\nsupervised classifier without any labeled data. Unsupervised domain adaptation\nis able to overcome this challenge by transferring knowledge from a labeled\nsource domain to an unlabeled target domain. Transferability and\ndiscriminability are two key criteria for characterizing the superiority of\nfeature representations to enable successful domain adaptation. In this paper,\na novel method called \\textit{learning TransFerable and Discriminative Features\nfor unsupervised domain adaptation} (TFDF) is proposed to optimize these two\nobjectives simultaneously. On the one hand, distribution alignment is performed\nto reduce domain discrepancy and learn more transferable representations.\nInstead of adopting \\textit{Maximum Mean Discrepancy} (MMD) which only captures\nthe first-order statistical information to measure distribution discrepancy, we\nadopt a recently proposed statistic called \\textit{Maximum Mean and Covariance\nDiscrepancy} (MMCD), which can not only capture the first-order statistical\ninformation but also capture the second-order statistical information in the\nreproducing kernel Hilbert space (RKHS). On the other hand, we propose to\nexplore both local discriminative information via manifold regularization and\nglobal discriminative information via minimizing the proposed \\textit{class\nconfusion} objective to learn more discriminative features, respectively. We\nintegrate these two objectives into the \\textit{Structural Risk Minimization}\n(RSM) framework and learn a domain-invariant classifier. Comprehensive\nexperiments are conducted on five real-world datasets and the results verify\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 03:15:09 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 03:54:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Du", "Yuntao", ""], ["Zhang", "Ruiting", ""], ["Zhang", "Xiaowen", ""], ["Yao", "Yirong", ""], ["Lu", "Hengyang", ""], ["Wang", "Chongjun", ""]]}, {"id": "2003.11741", "submitter": "Seongsik Park", "authors": "Seongsik Park, Seijoon Kim, Byunggook Na, Sungroh Yoon", "title": "T2FSNN: Deep Spiking Neural Networks with Time-to-first-spike Coding", "comments": "Accepted to DAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have gained considerable interest due to their\nenergy-efficient characteristics, yet lack of a scalable training algorithm has\nrestricted their applicability in practical machine learning problems. The deep\nneural network-to-SNN conversion approach has been widely studied to broaden\nthe applicability of SNNs. Most previous studies, however, have not fully\nutilized spatio-temporal aspects of SNNs, which has led to inefficiency in\nterms of number of spikes and inference latency. In this paper, we present\nT2FSNN, which introduces the concept of time-to-first-spike coding into deep\nSNNs using the kernel-based dynamic threshold and dendrite to overcome the\naforementioned drawback. In addition, we propose gradient-based optimization\nand early firing methods to further increase the efficiency of the T2FSNN.\nAccording to our results, the proposed methods can reduce inference latency and\nnumber of spikes to 22% and less than 1%, compared to those of burst coding,\nwhich is the state-of-the-art result on the CIFAR-100.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 04:39:12 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Na", "Byunggook", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2003.11755", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Eric Schmidt", "title": "A Survey of Deep Learning for Scientific Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, we have seen fundamental breakthroughs in core\nproblems in machine learning, largely driven by advances in deep neural\nnetworks. At the same time, the amount of data collected in a wide array of\nscientific domains is dramatically increasing in both size and complexity.\nTaken together, this suggests many exciting opportunities for deep learning\napplications in scientific settings. But a significant challenge to this is\nsimply knowing where to start. The sheer breadth and diversity of different\ndeep learning techniques makes it difficult to determine what scientific\nproblems might be most amenable to these methods, or which specific combination\nof methods might offer the most promising first approach. In this survey, we\nfocus on addressing this central issue, providing an overview of many widely\nused deep learning models, spanning visual, sequential and graph structured\ndata, associated tasks and different training methods, along with techniques to\nuse deep learning with less data and better interpret these complex models ---\ntwo central considerations for many scientific use cases. We also include\noverviews of the full design process, implementation tips, and links to a\nplethora of tutorials, research summaries and open-sourced deep learning\npipelines and pretrained models, developed by the community. We hope that this\nsurvey will help accelerate the use of deep learning across different\nscientific domains.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 06:16:08 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Raghu", "Maithra", ""], ["Schmidt", "Eric", ""]]}, {"id": "2003.11768", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Hugo Larochelle and Daniel Tarlow", "title": "On-the-Fly Adaptation of Source Code Models using Meta-Learning", "comments": "This paper has been withdrawn because we found a bug in the FOMAML\n  implementation that invalidates some of the key claims in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to adapt to unseen, local contexts is an important challenge that\nsuccessful models of source code must overcome. One of the most popular\napproaches for the adaptation of such models is dynamic evaluation. With\ndynamic evaluation, when running a model on an unseen file, the model is\nupdated immediately after having observed each token in that file. In this\nwork, we propose instead to frame the problem of context adaptation as a\nmeta-learning problem. We aim to train a base source code model that is best\nable to learn from information in a file to deliver improved predictions of\nmissing tokens. Unlike dynamic evaluation, this formulation allows us to select\nmore targeted information (support tokens) for adaptation, that is both before\nand after a target hole in a file. We consider an evaluation setting that we\ncall line-level maintenance, designed to reflect the downstream task of code\nauto-completion in an IDE. Leveraging recent developments in meta-learning such\nas first-order MAML and Reptile, we demonstrate improved performance in\nexperiments on a large scale Java GitHub corpus, compared to other adaptation\nbaselines including dynamic evaluation. Moreover, our analysis shows that,\ncompared to a non-adaptive baseline, our approach improves performance on\nidentifiers and literals by 44\\% and 15\\%, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 07:11:08 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 16:17:04 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Shrivastava", "Disha", ""], ["Larochelle", "Hugo", ""], ["Tarlow", "Daniel", ""]]}, {"id": "2003.11769", "submitter": "Ilsang Ohn", "authors": "Ilsang Ohn, Yongdai Kim", "title": "Nonconvex sparse regularization for deep neural networks and its\n  optimality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical studies proved that deep neural network (DNN) estimators\nobtained by minimizing empirical risk with a certain sparsity constraint can\nattain optimal convergence rates for regression and classification problems.\nHowever, the sparsity constraint requires to know certain properties of the\ntrue model, which are not available in practice. Moreover, computation is\ndifficult due to the discrete nature of the sparsity constraint. In this paper,\nwe propose a novel penalized estimation method for sparse DNNs, which resolves\nthe aforementioned problems existing in the sparsity constraint. We establish\nan oracle inequality for the excess risk of the proposed sparse-penalized DNN\nestimator and derive convergence rates for several learning tasks. In\nparticular, we prove that the sparse-penalized estimator can adaptively attain\nminimax convergence rates for various nonparametric regression problems. For\ncomputation, we develop an efficient gradient-based optimization algorithm that\nguarantees the monotonic reduction of the objective function.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 07:15:28 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Ohn", "Ilsang", ""], ["Kim", "Yongdai", ""]]}, {"id": "2003.11786", "submitter": "Dongrui Wu", "authors": "Ziang Liu and Dongrui Wu", "title": "Integrating Informativeness, Representativeness and Diversity in\n  Pool-Based Sequential Active Learning for Regression", "comments": "Int'l Joint Conf. on Neural Networks (IJCNN), Glasgow, UK, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world machine learning applications, unlabeled samples are easy\nto obtain, but it is expensive and/or time-consuming to label them. Active\nlearning is a common approach for reducing this data labeling effort. It\noptimally selects the best few samples to label, so that a better machine\nlearning model can be trained from the same number of labeled samples. This\npaper considers active learning for regression (ALR) problems. Three essential\ncriteria -- informativeness, representativeness, and diversity -- have been\nproposed for ALR. However, very few approaches in the literature have\nconsidered all three of them simultaneously. We propose three new ALR\napproaches, with different strategies for integrating the three criteria.\nExtensive experiments on 12 datasets in various domains demonstrated their\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 08:10:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Ziang", ""], ["Wu", "Dongrui", ""]]}, {"id": "2003.11816", "submitter": "Jirong Yi", "authors": "Zain Khan, Jirong Yi, Raghu Mudumbai, Xiaodong Wu, Weiyu Xu", "title": "Do Deep Minds Think Alike? Selective Adversarial Attacks for\n  Fine-Grained Manipulation of Multiple Deep Neural Networks", "comments": "9 pages, submitted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have demonstrated the existence of {\\it adversarial examples}\ntargeting a single machine learning system. In this paper we ask a simple but\nfundamental question of \"selective fooling\": given {\\it multiple} machine\nlearning systems assigned to solve the same classification problem and taking\nthe same input signal, is it possible to construct a perturbation to the input\nsignal that manipulates the outputs of these {\\it multiple} machine learning\nsystems {\\it simultaneously} in arbitrary pre-defined ways? For example, is it\npossible to selectively fool a set of \"enemy\" machine learning systems but does\nnot fool the other \"friend\" machine learning systems? The answer to this\nquestion depends on the extent to which these different machine learning\nsystems \"think alike\". We formulate the problem of \"selective fooling\" as a\nnovel optimization problem, and report on a series of experiments on the MNIST\ndataset. Our preliminary findings from these experiments show that it is in\nfact very easy to selectively manipulate multiple MNIST classifiers\nsimultaneously, even when the classifiers are identical in their architectures,\ntraining algorithms and training datasets except for random initialization\nduring training. This suggests that two nominally equivalent machine learning\nsystems do not in fact \"think alike\" at all, and opens the possibility for many\nnovel applications and deeper understandings of the working principles of deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 10:00:33 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Khan", "Zain", ""], ["Yi", "Jirong", ""], ["Mudumbai", "Raghu", ""], ["Wu", "Xiaodong", ""], ["Xu", "Weiyu", ""]]}, {"id": "2003.11827", "submitter": "Michael Welle", "authors": "Thomas Ziegler, Judith Butepage, Michael C. Welle, Anastasiia Varava,\n  Tonci Novkovic and Danica Kragic", "title": "Fashion Landmark Detection and Category Classification for Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on automated, image based identification of clothing categories and\nfashion landmarks has recently gained significant interest due to its potential\nimpact on areas such as robotic clothing manipulation, automated clothes\nsorting and recycling, and online shopping. Several public and annotated\nfashion datasets have been created to facilitate research advances in this\ndirection. In this work, we make the first step towards leveraging the data and\ntechniques developed for fashion image analysis in vision-based robotic\nclothing manipulation tasks. We focus on techniques that can generalize from\nlarge-scale fashion datasets to less structured, small datasets collected in a\nrobotic lab. Specifically, we propose training data augmentation methods such\nas elastic warping, and model adjustments such as rotation invariant\nconvolutions to make the model generalize better. Our experiments demonstrate\nthat our approach outperforms stateof-the art models with respect to clothing\ncategory classification and fashion landmark detection when tested on\npreviously unseen datasets. Furthermore, we present experimental results on a\nnew dataset composed of images where a robot holds different garments,\ncollected in our lab.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 10:53:26 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Ziegler", "Thomas", ""], ["Butepage", "Judith", ""], ["Welle", "Michael C.", ""], ["Varava", "Anastasiia", ""], ["Novkovic", "Tonci", ""], ["Kragic", "Danica", ""]]}, {"id": "2003.11830", "submitter": "Robert Sicks", "authors": "Robert Sicks, Ralf Korn, Stefanie Schwaar", "title": "A lower bound for the ELBO of the Bernoulli Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variational autoencoder (VAE) for binary data. Our main\ninnovations are an interpretable lower bound for its training objective, a\nmodified initialization and architecture of such a VAE that leads to faster\ntraining, and a decision support for finding the appropriate dimension of the\nlatent space via using a PCA. Numerical examples illustrate our theoretical\nresult and the performance of the new architecture.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 10:59:53 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Sicks", "Robert", ""], ["Korn", "Ralf", ""], ["Schwaar", "Stefanie", ""]]}, {"id": "2003.11842", "submitter": "Frank Glavin", "authors": "James Houston, Frank G. Glavin, Michael G. Madden", "title": "Robust Classification of High-Dimensional Spectroscopy Data Using Deep\n  Learning and Data Synthesis", "comments": "Journal of Chemical Information and Modeling", "journal-ref": null, "doi": "10.1021/acs.jcim.9b01037", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to classification of high dimensional\nspectroscopy data and demonstrates that it outperforms other current\nstate-of-the art approaches. The specific task we consider is identifying\nwhether samples contain chlorinated solvents or not, based on their Raman\nspectra. We also examine robustness to classification of outlier samples that\nare not represented in the training set (negative outliers). A novel\napplication of a locally-connected neural network (NN) for the binary\nclassification of spectroscopy data is proposed and demonstrated to yield\nimproved accuracy over traditionally popular algorithms. Additionally, we\npresent the ability to further increase the accuracy of the locally-connected\nNN algorithm through the use of synthetic training spectra and we investigate\nthe use of autoencoder based one-class classifiers and outlier detectors.\nFinally, a two-step classification process is presented as an alternative to\nthe binary and one-class classification paradigms. This process combines the\nlocally-connected NN classifier, the use of synthetic training data, and an\nautoencoder based outlier detector to produce a model which is shown to both\nproduce high classification accuracy, and be robust to the presence of negative\noutliers.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 11:33:52 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Houston", "James", ""], ["Glavin", "Frank G.", ""], ["Madden", "Michael G.", ""]]}, {"id": "2003.11915", "submitter": "Sebastiaan H\\\"oppner", "authors": "Bart Baesens, Sebastiaan H\\\"oppner, Irene Ortner, and Tim Verdonck", "title": "robROSE: A robust approach for dealing with imbalanced data in fraud\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge when trying to detect fraud is that the fraudulent\nactivities form a minority class which make up a very small proportion of the\ndata set. In most data sets, fraud occurs in typically less than 0.5% of the\ncases. Detecting fraud in such a highly imbalanced data set typically leads to\npredictions that favor the majority group, causing fraud to remain undetected.\nWe discuss some popular oversampling techniques that solve the problem of\nimbalanced data by creating synthetic samples that mimic the minority class. A\nfrequent problem when analyzing real data is the presence of anomalies or\noutliers. When such atypical observations are present in the data, most\noversampling techniques are prone to create synthetic samples that distort the\ndetection algorithm and spoil the resulting analysis. A useful tool for anomaly\ndetection is robust statistics, which aims to find the outliers by first\nfitting the majority of the data and then flagging data observations that\ndeviate from it. In this paper, we present a robust version of ROSE, called\nrobROSE, which combines several promising approaches to cope simultaneously\nwith the problem of imbalanced data and the presence of outliers. The proposed\nmethod achieves to enhance the presence of the fraud cases while ignoring\nanomalies. The good performance of our new sampling technique is illustrated on\nsimulated and real data sets and it is shown that robROSE can provide better\ninsight in the structure of the data. The source code of the robROSE algorithm\nis made freely available.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 16:11:07 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Baesens", "Bart", ""], ["H\u00f6ppner", "Sebastiaan", ""], ["Ortner", "Irene", ""], ["Verdonck", "Tim", ""]]}, {"id": "2003.11919", "submitter": "Patrick Hart C", "authors": "Patrick Hart and Alois Knoll", "title": "Counterfactual Policy Evaluation for Decision-Making in Autonomous\n  Driving", "comments": "Accepted at IROS 2020 PLC Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based approaches, such as reinforcement and imitation learning are\ngaining popularity in decision-making for autonomous driving. However, learned\npolicies often fail to generalize and cannot handle novel situations well.\nAsking and answering questions in the form of \"Would a policy perform well if\nthe other agents had behaved differently?\" can shed light on whether a policy\nhas seen similar situations during training and generalizes well. In this work,\na counterfactual policy evaluation is introduced that makes use of\ncounterfactual worlds - worlds in which the behaviors of others are non-actual.\nIf a policy can handle all counterfactual worlds well, it either has seen\nsimilar situations during training or it generalizes well and is deemed to be\nfit enough to be executed in the actual world. Additionally, by performing the\ncounterfactual policy evaluation, causal relations and the influence of\nchanging vehicle's behaviors on the surrounding vehicles becomes evident. To\nvalidate the proposed method, we learn a policy using reinforcement learning\nfor a lane merging scenario. In the application-phase, the policy is only\nexecuted after the counterfactual policy evaluation has been performed and if\nthe policy is found to be safe enough. We show that the proposed approach\nsignificantly decreases the collision-rate whilst maintaining a high\nsuccess-rate.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 10:02:30 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 16:10:19 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 14:30:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hart", "Patrick", ""], ["Knoll", "Alois", ""]]}, {"id": "2003.11923", "submitter": "Maryam Al Shehhi Dr", "authors": "Maryam R. Al Shehhi and Abdullah Kaya", "title": "Time series and machine learning to forecast the water quality from\n  satellite data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managing the quality of water for present and future generations of coastal\nregions should be a central concern of both citizens and public officials.\nRemote sensing can contribute to the management and monitoring of coastal water\nand pollutants. Algal blooms are a coastal pollutant that is a cause of\nconcern. Many satellite data, such as MODIS, have been used to generate\nwater-quality products to detect the blooms such as chlorophyll a (Chl-a), a\nphotosynthesis index called fluorescence line height (FLH), and sea surface\ntemperature (SST). It is important to characterize the spatial and temporal\nvariations of these water quality products by using the mathematical models of\nthese products. However, for monitoring, pollution control boards will need\nnowcasts and forecasts of any pollution. Therefore, we aim to predict the\nfuture values of the MODIS Chl-a, FLH, and SST of the water. This will not be\nlimited to one type of water but, rather, will cover different types of water\nvarying in depth and turbidity. This is very significant because the temporal\ntrend of Chl-a, FLH, and SST is dependent on the geospatial and water\nproperties. For this purpose, we will decompose the time series of each pixel\ninto several components: trend, intra-annual variations, seasonal cycle, and\nstochastic stationary. We explore three such time series machine learning\nmodels that can characterize the non-stationary time series data and predict\nfuture values, including the Seasonal ARIMA (Auto Regressive Integrated Moving\nAverage) (SARIMA), regression, and neural network. The results indicate that\nall these methods are effective at modelling Chl-a, FLH, and SST time series\nand predicting the values reasonably well. However, regression and neural\nnetwork are found to be the best at predicting Chl-a in all types of water\n(turbid and shallow). Meanwhile, the SARIMA model provides the best prediction\nof FLH and SST.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:16:44 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Shehhi", "Maryam R. Al", ""], ["Kaya", "Abdullah", ""]]}, {"id": "2003.11927", "submitter": "Jonathan Weyn", "authors": "Jonathan A. Weyn, Dale R. Durran, Rich Caruana", "title": "Improving data-driven global weather prediction using deep convolutional\n  neural networks on a cubed sphere", "comments": "Manuscript submitted to Journal of Advances in Modeling Earth Systems", "journal-ref": null, "doi": "10.1029/2020MS002109", "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a significantly-improved data-driven global weather forecasting\nframework using a deep convolutional neural network (CNN) to forecast several\nbasic atmospheric variables on a global grid. New developments in this\nframework include an offline volume-conservative mapping to a cubed-sphere\ngrid, improvements to the CNN architecture, and the minimization of the loss\nfunction over multiple steps in a prediction sequence. The cubed-sphere\nremapping minimizes the distortion on the cube faces on which convolution\noperations are performed and provides natural boundary conditions for padding\nin the CNN. Our improved model produces weather forecasts that are indefinitely\nstable and produce realistic weather patterns at lead times of several weeks\nand longer. For short- to medium-range forecasting, our model significantly\noutperforms persistence, climatology, and a coarse-resolution dynamical\nnumerical weather prediction (NWP) model. Unsurprisingly, our forecasts are\nworse than those from a high-resolution state-of-the-art operational NWP\nsystem. Our data-driven model is able to learn to forecast complex surface\ntemperature patterns from few input atmospheric state variables. On annual time\nscales, our model produces a realistic seasonal cycle driven solely by the\nprescribed variation in top-of-atmosphere solar forcing. Although it is\ncurrently less accurate than operational weather forecasting models, our\ndata-driven CNN executes much faster than those models, suggesting that machine\nlearning could prove to be a valuable tool for large-ensemble forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:57:34 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Weyn", "Jonathan A.", ""], ["Durran", "Dale R.", ""], ["Caruana", "Rich", ""]]}, {"id": "2003.11931", "submitter": "Yadong Zhang", "authors": "Yadong Zhang and Xin Chen", "title": "Triad State Space Construction for Chaotic Signal Classification with\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the well-known permutation entropy (PE), an effective image\nencoding scheme for chaotic time series, Triad State Space Construction (TSSC),\nis proposed. The TSSC image can recognize higher-order temporal patterns and\nidentify new forbidden regions in time series motifs beyond the Bandt-Pompe\nprobabilities. The Convolutional Neural Network (ConvNet) is widely used in\nimage classification. The ConvNet classifier based on TSSC images\n(TSSC-ConvNet) are highly accurate and very robust in the chaotic signal\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 14:15:41 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhang", "Yadong", ""], ["Chen", "Xin", ""]]}, {"id": "2003.11939", "submitter": "Sayan Ghosh", "authors": "Sayan Ghosh, Piyush Pandita, Steven Atkinson, Waad Subber, Yiming\n  Zhang, Natarajan Chennimalai Kumar, Suryarghya Chakrabarti, and Liping Wang", "title": "Advances in Bayesian Probabilistic Modeling for Industrial Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial applications frequently pose a notorious challenge for\nstate-of-the-art methods in the contexts of optimization, designing experiments\nand modeling unknown physical response. This problem is aggravated by limited\navailability of clean data, uncertainty in available physics-based models and\nadditional logistic and computational expense associated with experiments. In\nsuch a scenario, Bayesian methods have played an impactful role in alleviating\nthe aforementioned obstacles by quantifying uncertainty of different types\nunder limited resources. These methods, usually deployed as a framework, allows\ndecision makers to make informed choices under uncertainty while being able to\nincorporate information on the the fly, usually in the form of data, from\nmultiple sources while being consistent with the physical intuition about the\nproblem. This is a major advantage that Bayesian methods bring to fruition\nespecially in the industrial context. This paper is a compendium of the\nBayesian modeling methodology that is being consistently developed at GE\nResearch. The methodology, called GE's Bayesian Hybrid Modeling (GEBHM), is a\nprobabilistic modeling method, based on the Kennedy and O'Hagan framework, that\nhas been continuously scaled-up and industrialized over several years. In this\nwork, we explain the various advancements in GEBHM's methods and demonstrate\ntheir impact on several challenging industrial problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 14:30:24 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Ghosh", "Sayan", ""], ["Pandita", "Piyush", ""], ["Atkinson", "Steven", ""], ["Subber", "Waad", ""], ["Zhang", "Yiming", ""], ["Kumar", "Natarajan Chennimalai", ""], ["Chakrabarti", "Suryarghya", ""], ["Wang", "Liping", ""]]}, {"id": "2003.11940", "submitter": "Jiuyong Li", "authors": "Jiuyong Li, Weijia Zhang, Lin Liu, Kui Yu, Thuc Duy Le and Jixue Liu", "title": "A general framework for causal classification", "comments": "International Journal of Data Science and Analytics (2021). arXiv\n  admin note: text overlap with arXiv:1604.07212 by other authors", "journal-ref": null, "doi": "10.1007/s41060-021-00249-1", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, there is a need to predict the effect of an\nintervention on different individuals from data. For example, which customers\nare persuadable by a product promotion? which patients should be treated with a\ncertain type of treatment? These are typical causal questions involving the\neffect or the change in outcomes made by an intervention. The questions cannot\nbe answered with traditional classification methods as they only use\nassociations to predict outcomes. For personalised marketing, these questions\nare often answered with uplift modelling. The objective of uplift modelling is\nto estimate causal effect, but its literature does not discuss when the uplift\nrepresents causal effect. Causal heterogeneity modelling can solve the problem,\nbut its assumption of unconfoundedness is untestable in data. So practitioners\nneed guidelines in their applications when using the methods. In this paper, we\nuse causal classification for a set of personalised decision making problems,\nand differentiate it from classification. We discuss the conditions when causal\nclassification can be resolved by uplift (and causal heterogeneity) modelling\nmethods. We also propose a general framework for causal classification, by\nusing off-the-shelf supervised methods for flexible implementations.\nExperiments have shown two instantiations of the framework work for causal\nclassification and for uplift (causal heterogeneity) modelling, and are\ncompetitive with the other uplift (causal heterogeneity) modelling methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:40:22 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 00:53:53 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 02:12:11 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 01:03:16 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Jiuyong", ""], ["Zhang", "Weijia", ""], ["Liu", "Lin", ""], ["Yu", "Kui", ""], ["Le", "Thuc Duy", ""], ["Liu", "Jixue", ""]]}, {"id": "2003.11941", "submitter": "Wen-Ji Zhou", "authors": "Guangda Huzhang, Zhen-Jia Pang, Yongqing Gao, Yawen Liu, Weijie Shen,\n  Wen-Ji Zhou, Qing Da, An-Xiang Zeng, Han Yu, and Yang Yu, and Zhi-Hua Zhou", "title": "AliExpress Learning-To-Rank: Maximizing Online Model Performance without\n  Going Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-to-rank (LTR) has become a key technology in E-commerce\napplications. Most existing LTR approaches follow a supervised learning\nparadigm from offline labeled data collected from the online system. However,\nit has been noticed that previous LTR models can have a good validation\nperformance over offline validation data but have a poor online performance,\nand vice versa, which implies a possible large inconsistency between the\noffline and online evaluation. We investigate and confirm in this paper that\nsuch inconsistency exists and can have a significant impact on AliExpress\nSearch. Reasons for the inconsistency include the ignorance of item context\nduring the learning, and the offline data set is insufficient for learning the\ncontext. Therefore, this paper proposes an evaluator-generator framework for\nLTR with item context. The framework consists of an evaluator that generalizes\nto evaluate recommendations involving the context, and a generator that\nmaximizes the evaluator score by reinforcement learning, and a discriminator\nthat ensures the generalization of the evaluator. Extensive experiments in\nsimulation environments and AliExpress Search online system show that, firstly,\nthe classic data-based metrics on the offline dataset can show significant\ninconsistency with online performance, and can even be misleading. Secondly,\nthe proposed evaluator score is significantly more consistent with the online\nperformance than common ranking metrics. Finally, as the consequence, our\nmethod achieves a significant improvement (\\textgreater$2\\%$) in terms of\nConversion Rate (CR) over the industrial-level fine-tuned model in online A/B\ntests.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 10:27:44 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 13:09:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 02:09:02 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 05:14:10 GMT"}, {"version": "v5", "created": "Thu, 31 Dec 2020 10:04:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Huzhang", "Guangda", ""], ["Pang", "Zhen-Jia", ""], ["Gao", "Yongqing", ""], ["Liu", "Yawen", ""], ["Shen", "Weijie", ""], ["Zhou", "Wen-Ji", ""], ["Da", "Qing", ""], ["Zeng", "An-Xiang", ""], ["Yu", "Han", ""], ["Yu", "Yang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2003.11945", "submitter": "Lorenzo Rocutto", "authors": "Lorenzo Rocutto, Claudio Destri, Enrico Prati", "title": "Quantum Semantic Learning by Reverse Annealing an Adiabatic Quantum\n  Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Boltzmann Machines constitute a class of neural networks with applications to\nimage reconstruction, pattern classification and unsupervised learning in\ngeneral. Their most common variants, called Restricted Boltzmann Machines\n(RBMs) exhibit a good trade-off between computability on existing silicon-based\nhardware and generality of possible applications.\n  Still, the diffusion of RBMs is quite limited, since their training process\nproves to be hard. The advent of commercial Adiabatic Quantum Computers (AQCs)\nraised the expectation that the implementations of RBMs on such quantum devices\ncould increase the training speed with respect to conventional hardware. To\ndate, however, the implementation of RBM networks on AQCs has been limited by\nthe low qubit connectivity when each qubit acts as a node of the neural\nnetwork.\n  Here we demonstrate the feasibility of a complete RBM on AQCs, thanks to an\nembedding that associates its nodes to virtual qubits, thus outperforming\nprevious implementations based on incomplete graphs.\n  Moreover, to accelerate the learning, we implement a semantic quantum search\nwhich, contrary to previous proposals, takes the input data as initial boundary\nconditions to start each learning step of the RBM, thanks to a reverse\nannealing schedule. Such an approach, unlike the more conventional forward\nannealing schedule, allows sampling configurations in a meaningful neighborhood\nof the training data, mimicking the behavior of the classical Gibbs sampling\nalgorithm.\n  We show that the learning based on reverse annealing quickly raises the\nsampling probability of a meaningful subset of the set of the configurations.\nEven without a proper optimization of the annealing schedule, the RBM\nsemantically trained by reverse annealing achieves better scores on\nreconstruction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 01:33:33 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 15:46:47 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Rocutto", "Lorenzo", ""], ["Destri", "Claudio", ""], ["Prati", "Enrico", ""]]}, {"id": "2003.11948", "submitter": "Linh Ngo", "authors": "Anh Phan Tuan, Bach Tran, Thien Nguyen Huu, Linh Ngo Van, Khoat Than", "title": "Bag of biterms modeling for short texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing texts from social media encounters many challenges due to their\nunique characteristics of shortness, massiveness, and dynamic. Short texts do\nnot provide enough context information, causing the failure of the traditional\nstatistical models. Furthermore, many applications often face with massive and\ndynamic short texts, causing various computational challenges to the current\nbatch learning algorithms. This paper presents a novel framework, namely Bag of\nBiterms Modeling (BBM), for modeling massive, dynamic, and short text\ncollections. BBM comprises of two main ingredients: (1) the concept of Bag of\nBiterms (BoB) for representing documents, and (2) a simple way to help\nstatistical models to include BoB. Our framework can be easily deployed for a\nlarge class of probabilistic models, and we demonstrate its usefulness with two\nwell-known models: Latent Dirichlet Allocation (LDA) and Hierarchical Dirichlet\nProcess (HDP). By exploiting both terms (words) and biterms (pairs of words),\nthe major advantages of BBM are: (1) it enhances the length of the documents\nand makes the context more coherent by emphasizing the word connotation and\nco-occurrence via Bag of Biterms, (2) it inherits inference and learning\nalgorithms from the primitive to make it straightforward to design online and\nstreaming algorithms for short texts. Extensive experiments suggest that BBM\noutperforms several state-of-the-art models. We also point out that the BoB\nrepresentation performs better than the traditional representations (e.g, Bag\nof Words, tf-idf) even for normal texts.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 14:47:09 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Tuan", "Anh Phan", ""], ["Tran", "Bach", ""], ["Huu", "Thien Nguyen", ""], ["Van", "Linh Ngo", ""], ["Than", "Khoat", ""]]}, {"id": "2003.11958", "submitter": "Sabine Wieluch", "authors": "Sabine Wieluch and Friedhelm Schwenker", "title": "StrokeCoder: Path-Based Image Generation from Single Examples using\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates how a Transformer Neural Network can be used to learn\na Generative Model from a single path-based example image. We further show how\na data set can be generated from the example image and how the model can be\nused to generate a large set of deviated images, which still represent the\noriginal image's style and concept.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 14:55:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 11:51:53 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wieluch", "Sabine", ""], ["Schwenker", "Friedhelm", ""]]}, {"id": "2003.11964", "submitter": "Cynthia Rush", "authors": "Hangjin Liu and Cynthia Rush and Dror Baron", "title": "Rigorous State Evolution Analysis for Approximate Message Passing with\n  Side Information", "comments": "arXiv admin note: text overlap with arXiv:1902.00150", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common goal in many research areas is to reconstruct an unknown signal x\nfrom noisy linear measurements. Approximate message passing (AMP) is a class of\nlow-complexity algorithms that can be used for efficiently solving such\nhigh-dimensional regression tasks. Often, it is the case that side information\n(SI) is available during reconstruction. For this reason, a novel algorithmic\nframework that incorporates SI into AMP, referred to as approximate message\npassing with side information (AMP-SI), has been recently introduced. In this\nwork, we provide rigorous performance guarantees for AMP-SI when there are\nstatistical dependencies between the signal and SI pairs and the entries of the\nmeasurement matrix are independent and identically distributed Gaussian. The\nAMP-SI performance is shown to be provably tracked by a scalar iteration\nreferred to as state evolution. Moreover, we provide numerical examples that\ndemonstrate empirically that the SE can predict the AMP-SI mean square error\naccurately.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 16:11:18 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Hangjin", ""], ["Rush", "Cynthia", ""], ["Baron", "Dror", ""]]}, {"id": "2003.11991", "submitter": "Shantanu Gupta", "authors": "Shantanu Gupta, Zachary C. Lipton, David Childers", "title": "Estimating Treatment Effects with Observed Confounders and Mediators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a causal graph, the do-calculus can express treatment effects as\nfunctionals of the observational joint distribution that can be estimated\nempirically. Sometimes the do-calculus identifies multiple valid formulae,\nprompting us to compare the statistical properties of the corresponding\nestimators. For example, the backdoor formula applies when all confounders are\nobserved and the frontdoor formula applies when an observed mediator transmits\nthe causal effect. In this paper, we investigate the over-identified scenario\nwhere both confounders and mediators are observed, rendering both estimators\nvalid. Addressing the linear Gaussian causal model, we demonstrate that either\nestimator can dominate the other by an unbounded constant factor. Next, we\nderive an optimal estimator, which leverages all observed variables, and bound\nits finite-sample variance. We show that it strictly outperforms the backdoor\nand frontdoor estimators and that this improvement can be unbounded. We also\npresent a procedure for combining two datasets, one with observed confounders\nand another with observed mediators. Finally, we evaluate our methods on both\nsimulated data and the IHDP and JTPA datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:50:25 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 21:45:29 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 05:25:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gupta", "Shantanu", ""], ["Lipton", "Zachary C.", ""], ["Childers", "David", ""]]}, {"id": "2003.12009", "submitter": "Hao Tung", "authors": "Hao Tung, Chao Zheng, Xinsheng Mao, and Dahong Qian", "title": "Multi-Lead ECG Classification via an Information-Based Attention\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A novel structure based on channel-wise attention mechanism is\npresented in this paper. Embedding with the proposed structure, an efficient\nclassification model that accepts multi-lead electrocardiogram (ECG) as input\nis constructed. Methods: One-dimensional convolutional neural networks (CNN)\nhave proven to be effective in pervasive classification tasks, enabling the\nautomatic extraction of features while classifying targets. We implement the\nResidual connection and design a structure which can learn the weights from the\ninformation contained in different channels in the input feature map during the\ntraining process. An indicator named mean square deviation is introduced to\nmonitor the performance of a particular model segment in the classification\ntask on the two out of the five ECG classes. The data in the MIT-BIH arrhythmia\ndatabase is used and a series of control experiments is conducted. Results:\nUtilizing both leads of the ECG signals as input to the neural network\nclassifier can achieve better classification results than those from using\nsingle channel inputs in different application scenarios. Models embedded with\nthe channel-wise attention structure always achieve better scores on\nsensitivity and precision than the plain Resnet models. The proposed model\nexceeds the performance of most of the state-of-the-art models in ventricular\nectopic beats (VEB) classification, and achieves competitive scores for\nsupraventricular ectopic beats (SVEB). Conclusion: Adopting more lead ECG\nsignals as input can increase the dimensions of the input feature maps, helping\nto improve both the performance and generalization of the network model.\nSignificance: Due to its end-to-end characteristics, and the extensible\nintrinsic for multi-lead heart diseases diagnosing, the proposed model can be\nused for the real-time ECG tracking of ECG waveforms for Holter or wearable\ndevices.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 02:28:04 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Tung", "Hao", ""], ["Zheng", "Chao", ""], ["Mao", "Xinsheng", ""], ["Qian", "Dahong", ""]]}, {"id": "2003.12011", "submitter": "Saverio De Vito", "authors": "Saverio De Vito, Girolamo Di Francia, Elena Esposito, Sergio Ferlito,\n  Fabrizio Formisano and Ettore Massera", "title": "Adaptive machine learning strategies for network calibration of IoT\n  smart air quality monitoring devices", "comments": "Submitted to Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Air Quality Multi-sensors Systems (AQMS) are IoT devices based on low cost\nchemical microsensors array that recently have showed capable to provide\nrelatively accurate air pollutant quantitative estimations. Their availability\npermits to deploy pervasive Air Quality Monitoring (AQM) networks that will\nsolve the geographical sparseness issue that affect the current network of AQ\nRegulatory Monitoring Systems (AQRMS). Unfortunately their accuracy have shown\nlimited in long term field deployments due to negative influence of several\ntechnological issues including sensors poisoning or ageing, non target gas\ninterference, lack of fabrication repeatability, etc. Seasonal changes in\nprobability distribution of priors, observables and hidden context variables\n(i.e. non observable interferents) challenge field data driven calibration\nmodels which short to mid term performances recently rose to the attention of\nUrban authorithies and monitoring agencies. In this work, we address this non\nstationary framework with adaptive learning strategies in order to prolong the\nvalidity of multisensors calibration models enabling continuous learning.\nRelevant parameters influence in different network and note-to-node\nrecalibration scenario is analyzed. Results are hence useful for pervasive\ndeployment aimed to permanent high resolution AQ mapping in urban scenarios as\nwell as for the use of AQMS as AQRMS backup systems providing data when AQRMS\ndata are unavailable due to faults or scheduled mainteinance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 10:26:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["De Vito", "Saverio", ""], ["Di Francia", "Girolamo", ""], ["Esposito", "Elena", ""], ["Ferlito", "Sergio", ""], ["Formisano", "Fabrizio", ""], ["Massera", "Ettore", ""]]}, {"id": "2003.12012", "submitter": "Kaiping Zheng", "authors": "Kaiping Zheng, Shaofeng Cai, Horng Ruey Chua, Wei Wang, Kee Yuan\n  Ngiam, Beng Chin Ooi", "title": "TRACER: A Framework for Facilitating Accurate and Interpretable\n  Analytics for High Stakes Applications", "comments": "A version of this preprint will appear in ACM SIGMOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high stakes applications such as healthcare and finance analytics, the\ninterpretability of predictive models is required and necessary for domain\npractitioners to trust the predictions. Traditional machine learning models,\ne.g., logistic regression (LR), are easy to interpret in nature. However, many\nof these models aggregate time-series data without considering the temporal\ncorrelations and variations. Therefore, their performance cannot match up to\nrecurrent neural network (RNN) based models, which are nonetheless difficult to\ninterpret. In this paper, we propose a general framework TRACER to facilitate\naccurate and interpretable predictions, with a novel model TITV devised for\nhealthcare analytics and other high stakes applications such as financial\ninvestment and risk management. Different from LR and other existing RNN-based\nmodels, TITV is designed to capture both the time-invariant and the\ntime-variant feature importance using a feature-wise transformation subnetwork\nand a self-attention subnetwork, for the feature influence shared over the\nentire time series and the time-related importance respectively. Healthcare\nanalytics is adopted as a driving use case, and we note that the proposed\nTRACER is also applicable to other domains, e.g., fintech. We evaluate the\naccuracy of TRACER extensively in two real-world hospital datasets, and our\ndoctors/clinicians further validate the interpretability of TRACER in both the\npatient level and the feature level. Besides, TRACER is also validated in a\nhigh stakes financial application and a critical temperature forecasting\napplication. The experimental results confirm that TRACER facilitates both\naccurate and interpretable analytics for high stakes applications.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:06:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zheng", "Kaiping", ""], ["Cai", "Shaofeng", ""], ["Chua", "Horng Ruey", ""], ["Wang", "Wei", ""], ["Ngiam", "Kee Yuan", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "2003.12020", "submitter": "Saeed Mahloujifar", "authors": "Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody,\n  Abhradeep Thakurta", "title": "Obliviousness Makes Poisoning Adversaries Weaker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks have emerged as a significant security threat to machine\nlearning (ML) algorithms. It has been demonstrated that adversaries who make\nsmall changes to the training set, such as adding specially crafted data\npoints, can hurt the performance of the output model. Most of these attacks\nrequire the full knowledge of training data or the underlying data\ndistribution. In this paper we study the power of oblivious adversaries who do\nnot have any information about the training set. We show a separation between\noblivious and full-information poisoning adversaries. Specifically, we\nconstruct a sparse linear regression problem for which LASSO estimator is\nrobust against oblivious adversaries whose goal is to add a non-relevant\nfeatures to the model with certain poisoning budget. On the other hand,\nnon-oblivious adversaries, with the same budget, can craft poisoning examples\nbased on the rest of the training data and successfully add non-relevant\nfeatures to the model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:40:35 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "2003.12025", "submitter": "Saeed Khaki", "authors": "Saeed Khaki, Hieu Pham, Ye Han, Andy Kuhl, Wade Kent and Lizhi Wang", "title": "Convolutional Neural Networks for Image-based Corn Kernel Detection and\n  Counting", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": "10.3390/s20092721", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise in-season corn grain yield estimates enable farmers to make real-time\naccurate harvest and grain marketing decisions minimizing possible losses of\nprofitability. A well developed corn ear can have up to 800 kernels, but\nmanually counting the kernels on an ear of corn is labor-intensive, time\nconsuming and prone to human error. From an algorithmic perspective, the\ndetection of the kernels from a single corn ear image is challenging due to the\nlarge number of kernels at different angles and very small distance among the\nkernels. In this paper, we propose a kernel detection and counting method based\non a sliding window approach. The proposed method detect and counts all corn\nkernels in a single corn ear image taken in uncontrolled lighting conditions.\nThe sliding window approach uses a convolutional neural network (CNN) for\nkernel detection. Then, a non-maximum suppression (NMS) is applied to remove\noverlapping detections. Finally, windows that are classified as kernel are\npassed to another CNN regression model for finding the (x,y) coordinates of the\ncenter of kernel image patches. Our experiments indicate that the proposed\nmethod can successfully detect the corn kernels with a low detection error and\nis also able to detect kernels on a batch of corn ears positioned at different\nangles.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:46:23 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 02:02:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Khaki", "Saeed", ""], ["Pham", "Hieu", ""], ["Han", "Ye", ""], ["Kuhl", "Andy", ""], ["Kent", "Wade", ""], ["Wang", "Lizhi", ""]]}, {"id": "2003.12043", "submitter": "Markus Loecher", "authors": "Markus Loecher", "title": "From unbiased MDI Feature Importance to Explainable AI for Trees", "comments": "arXiv admin note: text overlap with arXiv:2003.02106", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attempt to give a unifying view of the various recent attempts to (i)\nimprove the interpretability of tree-based models and (ii) debias the the\ndefault variable-importance measure in random Forests, Gini importance. In\nparticular, we demonstrate a common thread among the out-of-bag based bias\ncorrection methods and their connection to local explanation for trees. In\naddition, we point out a bias caused by the inclusion of inbag data in the\nnewly developed explainable AI for trees algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 17:16:58 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 17:45:50 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 15:44:32 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Loecher", "Markus", ""]]}, {"id": "2003.12052", "submitter": "Hamidreza Ehteram", "authors": "Hamidreza Ehteram, Mohammad Ali Maddah-Ali, Mahtab Mirmohseni", "title": "Corella: A Private Multi Server Learning Approach based on Correlated\n  Queries", "comments": "13 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging applications of machine learning algorithms on mobile devices\nmotivate us to offload the computation tasks of training a model or deploying a\ntrained one to the cloud or at the edge of the network. One of the major\nchallenges in this setup is to guarantee the privacy of the client data.\nVarious methods have been proposed to protect privacy in the literature. Those\ninclude (i) adding noise to the client data, which reduces the accuracy of the\nresult, (ii) using secure multiparty computation (MPC), which requires\nsignificant communication among the computing nodes or with the client, (iii)\nrelying on homomorphic encryption (HE) methods, which significantly increases\ncomputation load at the servers. In this paper, we propose $\\textit{Corella}$\nas an alternative approach to protect the privacy of data. The proposed scheme\nrelies on a cluster of servers, where at most $T \\in \\mathbb{N}$ of them may\ncollude, each running a learning model (e.g., a deep neural network). Each\nserver is fed with the client data, added with $\\textit{strong}$ noise,\nindependent from user data. The variance of the noise is set to be large enough\nto make the information leakage to any subset of up to $T$ servers\ninformation-theoretically negligible. On the other hand, the added noises for\ndifferent servers are $\\textit{correlated}$. This correlation among the queries\nallows the parameters of the models running on different servers to be\n$\\textit{trained}$ such that the client can mitigate the contribution of the\nnoises by combining the outputs of the servers, and recover the final result\nwith high accuracy and with a minor computational effort. Simulation results\nfor various datasets demonstrate the accuracy of the proposed approach for the\nclassification, using deep neural networks, and the autoencoder, as supervised\nand unsupervised learning tasks, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 17:44:00 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 09:39:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ehteram", "Hamidreza", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Mirmohseni", "Mahtab", ""]]}, {"id": "2003.12060", "submitter": "Bin Liu", "authors": "Bin Liu, Yue Cao, Yutong Lin, Qi Li, Zheng Zhang, Mingsheng Long, Han\n  Hu", "title": "Negative Margin Matters: Understanding Margin in Few-shot Classification", "comments": "Code is available at https://github.com/bl0/negative-margin.few-shot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a negative margin loss to metric learning based\nfew-shot learning methods. The negative margin loss significantly outperforms\nregular softmax loss, and achieves state-of-the-art accuracy on three standard\nfew-shot classification benchmarks with few bells and whistles. These results\nare contrary to the common practice in the metric learning field, that the\nmargin is zero or positive. To understand why the negative margin loss performs\nwell for the few-shot classification, we analyze the discriminability of\nlearned features w.r.t different margins for training and novel classes, both\nempirically and theoretically. We find that although negative margin reduces\nthe feature discriminability for training classes, it may also avoid falsely\nmapping samples of the same novel class to multiple peaks or clusters, and thus\nbenefit the discrimination of novel classes. Code is available at\nhttps://github.com/bl0/negative-margin.few-shot.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 17:59:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Bin", ""], ["Cao", "Yue", ""], ["Lin", "Yutong", ""], ["Li", "Qi", ""], ["Zhang", "Zheng", ""], ["Long", "Mingsheng", ""], ["Hu", "Han", ""]]}, {"id": "2003.12091", "submitter": "Jesmin Jahan Tithi", "authors": "Jesmin Jahan Tithi, Sriram Aananthakrishnan, Fabrizio Petrini", "title": "Online and Real-time Object Tracking Algorithm with Extremely Small\n  Matrices", "comments": "5 Pages (4 Pages main paper, 5th page for reference), Accepted for\n  presentation in WHPC 2020 Summit which got canceled for Corona. But it will\n  not be published in Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online and Real-time Object Tracking is an interesting workload that can be\nused to track objects (e.g., car, human, animal) in a series of video sequences\nin real-time. For simple object tracking on edge devices, the output of object\ntracking could be as simple as drawing a bounding box around a detected object\nand in some cases, the input matrices used in such computation are quite small\n(e.g., 4x7, 3x3, 5x5, etc). As a result, the amount of actual work is low.\nTherefore, a typical multi-threading based parallelization technique can not\naccelerate the tracking application; instead, a throughput based\nparallelization technique where each thread operates on independent video\nsequences is more rewarding. In this paper, we share our experience in\nparallelizing a Simple Online and Real-time Tracking (SORT) application on\nshared-memory multicores.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 18:22:47 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 18:03:09 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Tithi", "Jesmin Jahan", ""], ["Aananthakrishnan", "Sriram", ""], ["Petrini", "Fabrizio", ""]]}, {"id": "2003.12101", "submitter": "Shulin Zeng", "authors": "Shulin Zeng, Guohao Dai, Hanbo Sun, Kai Zhong, Guangjun Ge, Kaiyuan\n  Guo, Yu Wang, Huazhong Yang", "title": "Enabling Efficient and Flexible FPGA Virtualization for Deep Learning in\n  the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGAs have shown great potential in providing low-latency and\nenergy-efficient solutions for deep neural network (DNN) inference\napplications. Currently, the majority of FPGA-based DNN accelerators in the\ncloud run in a time-division multiplexing way for multiple users sharing a\nsingle FPGA, and require re-compilation with $\\sim$100 s overhead. Such designs\nlead to poor isolation and heavy performance loss for multiple users, which are\nfar away from providing efficient and flexible FPGA virtualization for neither\npublic nor private cloud scenarios.\n  To solve these problems, we introduce a novel virtualization framework for\ninstruction architecture set (ISA) based on DNN accelerators by sharing a\nsingle FPGA. We enable the isolation by introducing a two-level instruction\ndispatch module and a multi-core based hardware resources pool. Such designs\nprovide isolated and runtime-programmable hardware resources, further leading\nto performance isolation for multiple users. On the other hand, to overcome the\nheavy re-compilation overheads, we propose a tiling-based instruction frame\npackage design and two-stage static-dynamic compilation. Only the light-weight\nruntime information is re-compiled with $\\sim$1 ms overhead, thus the\nperformance is guaranteed for the private cloud. Our extensive experimental\nresults show that the proposed virtualization design achieves 1.07-1.69x and\n1.88-3.12x throughput improvement over previous static designs using the\nsingle-core and the multi-core architectures, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 18:34:11 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Zeng", "Shulin", ""], ["Dai", "Guohao", ""], ["Sun", "Hanbo", ""], ["Zhong", "Kai", ""], ["Ge", "Guangjun", ""], ["Guo", "Kaiyuan", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2003.12120", "submitter": "John San Soucie", "authors": "John E. San Soucie, Heidi M. Sosik, Yogesh Girdhar", "title": "Gaussian-Dirichlet Random Fields for Inference over High Dimensional\n  Categorical Observations", "comments": "8 pages, 10 figures, accepted to proceedings of International\n  Conference on Robotics and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative model for the spatio-temporal distribution of high\ndimensional categorical observations. These are commonly produced by robots\nequipped with an imaging sensor such as a camera, paired with an image\nclassifier, potentially producing observations over thousands of categories.\nThe proposed approach combines the use of Dirichlet distributions to model\nsparse co-occurrence relations between the observed categories using a latent\nvariable, and Gaussian processes to model the latent variable's spatio-temporal\ndistribution. Experiments in this paper show that the resulting model is able\nto efficiently and accurately approximate the temporal distribution of high\ndimensional categorical measurements such as taxonomic observations of\nmicroscopic organisms in the ocean, even in unobserved (held out) locations,\nfar from other samples. This work's primary motivation is to enable deployment\nof informative path planning techniques over high dimensional categorical\nfields, which until now have been limited to scalar or low dimensional vector\nobservations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 19:29:23 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Soucie", "John E. San", ""], ["Sosik", "Heidi M.", ""], ["Girdhar", "Yogesh", ""]]}, {"id": "2003.12127", "submitter": "Matteo Aldeghi", "authors": "Florian H\\\"ase, Matteo Aldeghi, Riley J. Hickman, Lo\\\"ic M. Roch,\n  Al\\'an Aspuru-Guzik", "title": "Gryffin: An algorithm for Bayesian optimization of categorical variables\n  informed by expert knowledge", "comments": "19 pages, 6 figures (SI: 16 pages, 14 figures). Expanded background,\n  discussion, minor fixes and changes", "journal-ref": "Appl. Phys. Rev. 8 (2021) 031406", "doi": "10.1063/5.0048164", "report-no": null, "categories": "stat.ML cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing functional molecules and advanced materials requires complex design\nchoices: tuning continuous process parameters such as temperatures or flow\nrates, while simultaneously selecting catalysts or solvents. To date, the\ndevelopment of data-driven experiment planning strategies for autonomous\nexperimentation has largely focused on continuous process parameters despite\nthe urge to devise efficient strategies for the selection of categorical\nvariables. Here, we introduce Gryffin, a general purpose optimization framework\nfor the autonomous selection of categorical variables driven by expert\nknowledge. Gryffin augments Bayesian optimization based on kernel density\nestimation with smooth approximations to categorical distributions. Leveraging\ndomain knowledge in the form of physicochemical descriptors, Gryffin can\nsignificantly accelerate the search for promising molecules and materials.\nGryffin can further highlight relevant correlations between the provided\ndescriptors to inspire physical insights and foster scientific intuition. In\naddition to comprehensive benchmarks, we demonstrate the capabilities and\nperformance of Gryffin on three examples in materials science and chemistry:\n(i) the discovery of non-fullerene acceptors for organic solar cells, (ii) the\ndesign of hybrid organic-inorganic perovskites for light harvesting, and (iii)\nthe identification of ligands and process parameters for Suzuki-Miyaura\nreactions. Our results suggest that Gryffin, in its simplest form, is\ncompetitive with state-of-the-art categorical optimization algorithms. However,\nwhen leveraging domain knowledge provided via descriptors, Gryffin outperforms\nother approaches while simultaneously refining this domain knowledge to promote\nscientific understanding.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 19:52:32 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 22:47:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["H\u00e4se", "Florian", ""], ["Aldeghi", "Matteo", ""], ["Hickman", "Riley J.", ""], ["Roch", "Lo\u00efc M.", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "2003.12139", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao, Mattia Prosperi, Tianchen Lyu, Yi Guo, Jiang Bian", "title": "Integrating Crowdsourcing and Active Learning for Classification of\n  Work-Life Events from Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media, especially Twitter, is being increasingly used for research\nwith predictive analytics. In social media studies, natural language processing\n(NLP) techniques are used in conjunction with expert-based, manual and\nqualitative analyses. However, social media data are unstructured and must\nundergo complex manipulation for research use. The manual annotation is the\nmost resource and time-consuming process that multiple expert raters have to\nreach consensus on every item, but is essential to create gold-standard\ndatasets for training NLP-based machine learning classifiers. To reduce the\nburden of the manual annotation, yet maintaining its reliability, we devised a\ncrowdsourcing pipeline combined with active learning strategies. We\ndemonstrated its effectiveness through a case study that identifies job loss\nevents from individual tweets. We used Amazon Mechanical Turk platform to\nrecruit annotators from the Internet and designed a number of quality control\nmeasures to assure annotation accuracy. We evaluated 4 different active\nlearning strategies (i.e., least confident, entropy, vote entropy, and\nKullback-Leibler divergence). The active learning strategies aim at reducing\nthe number of tweets needed to reach a desired performance of automated\nclassification. Results show that crowdsourcing is useful to create\nhigh-quality annotations and active learning helps in reducing the number of\nrequired tweets, although there was no substantial difference among the\nstrategies tested.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 20:19:33 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 15:30:35 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Zhao", "Yunpeng", ""], ["Prosperi", "Mattia", ""], ["Lyu", "Tianchen", ""], ["Guo", "Yi", ""], ["Bian", "Jiang", ""]]}, {"id": "2003.12140", "submitter": "Casper Kaae S{\\o}nderby", "authors": "Casper Kaae S{\\o}nderby, Lasse Espeholt, Jonathan Heek, Mostafa\n  Dehghani, Avital Oliver, Tim Salimans, Shreya Agrawal, Jason Hickey, Nal\n  Kalchbrenner", "title": "MetNet: A Neural Weather Model for Precipitation Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather forecasting is a long standing scientific challenge with direct\nsocial and economic impact. The task is suitable for deep neural networks due\nto vast amounts of continuously collected data and a rich spatial and temporal\nstructure that presents long range dependencies. We introduce MetNet, a neural\nnetwork that forecasts precipitation up to 8 hours into the future at the high\nspatial resolution of 1 km$^2$ and at the temporal resolution of 2 minutes with\na latency in the order of seconds. MetNet takes as input radar and satellite\ndata and forecast lead time and produces a probabilistic precipitation map. The\narchitecture uses axial self-attention to aggregate the global context from a\nlarge input patch corresponding to a million square kilometers. We evaluate the\nperformance of MetNet at various precipitation thresholds and find that MetNet\noutperforms Numerical Weather Prediction at forecasts of up to 7 to 8 hours on\nthe scale of the continental United States.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 10:47:24 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 11:51:32 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["S\u00f8nderby", "Casper Kaae", ""], ["Espeholt", "Lasse", ""], ["Heek", "Jonathan", ""], ["Dehghani", "Mostafa", ""], ["Oliver", "Avital", ""], ["Salimans", "Tim", ""], ["Agrawal", "Shreya", ""], ["Hickey", "Jason", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "2003.12154", "submitter": "Fatemehsadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Mohammadkazem Taram, Ali Jalali, Ahmed\n  Taha Elthakeb, Dean Tullsen, Hadi Esmaeilzadeh", "title": "Not All Features Are Equal: Discovering Essential Features for\n  Preserving Prediction Privacy", "comments": "This paper is presented at the 2021 Web conference (WWW 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When receiving machine learning services from the cloud, the provider does\nnot need to receive all features; in fact, only a subset of the features are\nnecessary for the target prediction task. Discerning this subset is the key\nproblem of this work. We formulate this problem as a gradient-based\nperturbation maximization method that discovers this subset in the input\nfeature space with respect to the functionality of the prediction model used by\nthe provider. After identifying the subset, our framework, Cloak, suppresses\nthe rest of the features using utility-preserving constant values that are\ndiscovered through a separate gradient-based optimization process. We show that\nCloak does not necessarily require collaboration from the service provider\nbeyond its normal service, and can be applied in scenarios where we only have\nblack-box access to the service provider's model. We theoretically guarantee\nthat Cloak's optimizations reduce the upper bound of the Mutual Information\n(MI) between the data and the sifted representations that are sent out.\nExperimental results show that Cloak reduces the mutual information between the\ninput and the sifted representations by 85.01% with only a negligible reduction\nin utility (1.42%). In addition, we show that Cloak greatly diminishes\nadversaries' ability to learn and infer non-conducive features.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 20:45:09 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 05:02:25 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Taram", "Mohammadkazem", ""], ["Jalali", "Ali", ""], ["Elthakeb", "Ahmed Taha", ""], ["Tullsen", "Dean", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2003.12159", "submitter": "Shehryar Malik", "authors": "Shehryar Malik, Usman Anwar, Ali Ahmed and Alireza Aghasi", "title": "Learning To Solve Differential Equations Across Initial Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a lot of interest in using neural networks for\nsolving partial differential equations. A number of neural network-based\npartial differential equation solvers have been formulated which provide\nperformances equivalent, and in some cases even superior, to classical solvers.\nHowever, these neural solvers, in general, need to be retrained each time the\ninitial conditions or the domain of the partial differential equation changes.\nIn this work, we posit the problem of approximating the solution of a fixed\npartial differential equation for any arbitrary initial conditions as learning\na conditional probability distribution. We demonstrate the utility of our\nmethod on Burger's Equation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 21:29:22 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 18:38:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Malik", "Shehryar", ""], ["Anwar", "Usman", ""], ["Ahmed", "Ali", ""], ["Aghasi", "Alireza", ""]]}, {"id": "2003.12162", "submitter": "Bernardo P\\'erez Orozco", "authors": "Bernardo P\\'erez Orozco and Stephen J Roberts", "title": "Zero-shot and few-shot time series forecasting with ordinal regression\n  recurrent neural networks", "comments": "To appear at ESANN 2020; 6 pages, 2 figures, 1 link to repo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recurrent neural networks (RNNs) are state-of-the-art in several sequential\nlearning tasks, but they often require considerable amounts of data to\ngeneralise well. For many time series forecasting (TSF) tasks, only a few\ndozens of observations may be available at training time, which restricts use\nof this class of models. We propose a novel RNN-based model that directly\naddresses this problem by learning a shared feature embedding over the space of\nmany quantised time series. We show how this enables our RNN framework to\naccurately and reliably forecast unseen time series, even when there is little\nto no training data available.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 21:33:10 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Orozco", "Bernardo P\u00e9rez", ""], ["Roberts", "Stephen J", ""]]}, {"id": "2003.12169", "submitter": "Mengyue Hang", "authors": "Mengyue Hang, Jennifer Neville, Bruno Ribeiro", "title": "A Collective Learning Framework to Boost GNN Expressiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have recently been used for node and graph\nclassification tasks with great success, but GNNs model dependencies among the\nattributes of nearby neighboring nodes rather than dependencies among observed\nnode labels. In this work, we consider the task of inductive node\nclassification using GNNs in supervised and semi-supervised settings, with the\ngoal of incorporating label dependencies. Because current GNNs are not\nuniversal (i.e., most-expressive) graph representations, we propose a general\ncollective learning approach to increase the representation power of any\nexisting GNN. Our framework combines ideas from collective classification with\nself-supervised learning, and uses a Monte Carlo approach to sampling\nembeddings for inductive learning across graphs. We evaluate performance on\nfive real-world network datasets and demonstrate consistent, significant\nimprovement in node classification accuracy, for a variety of state-of-the-art\nGNNs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 22:07:28 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 20:42:07 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Hang", "Mengyue", ""], ["Neville", "Jennifer", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2003.12170", "submitter": "Ben Usman", "authors": "Ben Usman, Avneesh Sud, Nick Dufour, Kate Saenko", "title": "Log-Likelihood Ratio Minimizing Flows: Towards Robust and Quantifiable\n  Neural Distribution Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution alignment has many applications in deep learning, including\ndomain adaptation and unsupervised image-to-image translation. Most prior work\non unsupervised distribution alignment relies either on minimizing simple\nnon-parametric statistical distances such as maximum mean discrepancy or on\nadversarial alignment. However, the former fails to capture the structure of\ncomplex real-world distributions, while the latter is difficult to train and\ndoes not provide any universal convergence guarantees or automatic quantitative\nvalidation procedures. In this paper, we propose a new distribution alignment\nmethod based on a log-likelihood ratio statistic and normalizing flows. We show\nthat, under certain assumptions, this combination yields a deep neural\nlikelihood-based minimization objective that attains a known lower bound upon\nconvergence. We experimentally verify that minimizing the resulting objective\nresults in domain alignment that preserves the local structure of input\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 22:10:04 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:22:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Usman", "Ben", ""], ["Sud", "Avneesh", ""], ["Dufour", "Nick", ""], ["Saenko", "Kate", ""]]}, {"id": "2003.12193", "submitter": "Etai Littwin", "authors": "Etai Littwin, Tomer Galanti, Lior Wolf, Greg Yang", "title": "On Infinite-Width Hypernetworks", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  {\\em Hypernetworks} are architectures that produce the weights of a\ntask-specific {\\em primary network}. A notable application of hypernetworks in\nthe recent literature involves learning to output functional representations.\nIn these scenarios, the hypernetwork learns a representation corresponding to\nthe weights of a shallow MLP, which typically encodes shape or image\ninformation. While such representations have seen considerable success in\npractice, they remain lacking in the theoretical guarantees in the wide regime\nof the standard architectures. In this work, we study wide over-parameterized\nhypernetworks. We show that unlike typical architectures, infinitely wide\nhypernetworks do not guarantee convergence to a global minima under gradient\ndescent. We further show that convexity can be achieved by increasing the\ndimensionality of the hypernetwork's output, to represent wide MLPs. In the\ndually infinite-width regime, we identify the functional priors of these\narchitectures by deriving their corresponding GP and NTK kernels, the latter of\nwhich we refer to as the {\\em hyperkernel}. As part of this study, we make a\nmathematical contribution by deriving tight bounds on high order Taylor\nexpansion terms of standard fully connected ReLU networks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 00:50:29 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 07:49:39 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 21:08:59 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 09:08:52 GMT"}, {"version": "v5", "created": "Sun, 1 Nov 2020 15:18:31 GMT"}, {"version": "v6", "created": "Tue, 3 Nov 2020 08:00:21 GMT"}, {"version": "v7", "created": "Mon, 22 Feb 2021 23:10:56 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Littwin", "Etai", ""], ["Galanti", "Tomer", ""], ["Wolf", "Lior", ""], ["Yang", "Greg", ""]]}, {"id": "2003.12194", "submitter": "Philippe Chatigny", "authors": "Philippe Chatigny, Jean-Marc Patenaude, Shengrui Wang", "title": "Spatiotemporal Adaptive Neural Network for Long-term Forecasting of\n  Financial Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal decision-making in social settings is often based on forecasts from\ntime series (TS) data. Recently, several approaches using deep neural networks\n(DNNs) such as recurrent neural networks (RNNs) have been introduced for TS\nforecasting and have shown promising results. However, the applicability of\nthese approaches is being questioned for TS settings where there is a lack of\nquality training data and where the TS to forecast exhibit complex behaviors.\nExamples of such settings include financial TS forecasting, where producing\naccurate and consistent long-term forecasts is notoriously difficult. In this\nwork, we investigate whether DNN-based models can be used to forecast these TS\nconjointly by learning a joint representation of the series instead of\ncomputing the forecast from the raw time-series representations. To this end,\nwe make use of the dynamic factor graph (DFG) to build a multivariate\nautoregressive model. We investigate a common limitation of RNNs that rely on\nthe DFG framework and propose a novel variable-length attention-based mechanism\n(ACTM) to address it. With ACTM, it is possible to vary the autoregressive\norder of a TS model over time and model a larger set of probability\ndistributions than with previous approaches. Using this mechanism, we propose a\nself-supervised DNN architecture for multivariate TS forecasting that learns\nand takes advantage of the relationships between them. We test our model on two\ndatasets covering 19 years of investment fund activities. Our experimental\nresults show that the proposed approach significantly outperforms typical\nDNN-based and statistical models at forecasting the 21-day price trajectory. We\npoint out how improving forecasting accuracy and knowing which forecaster to\nuse can improve the excess return of autonomous trading strategies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 00:53:11 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:21:44 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 15:33:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chatigny", "Philippe", ""], ["Patenaude", "Jean-Marc", ""], ["Wang", "Shengrui", ""]]}, {"id": "2003.12198", "submitter": "Xingwei Hu Dr", "authors": "Xingwei Hu", "title": "Sorting Big Data by Revealed Preference with Application to College\n  Ranking", "comments": "43 pages, 1 figure, 5 theorems, and 1 lemma", "journal-ref": "Journal of Big Data, 2020", "doi": "10.1186/s40537-020-00300-1", "report-no": null, "categories": "stat.ML cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When ranking big data observations such as colleges in the United States,\ndiverse consumers reveal heterogeneous preferences. The objective of this paper\nis to sort out a linear ordering for these observations and to recommend\nstrategies to improve their relative positions in the ranking. A properly\nsorted solution could help consumers make the right choices, and governments\nmake wise policy decisions. Previous researchers have applied exogenous\nweighting or multivariate regression approaches to sort big data objects,\nignoring their variety and variability. By recognizing the diversity and\nheterogeneity among both the observations and the consumers, we instead apply\nendogenous weighting to these contradictory revealed preferences. The outcome\nis a consistent steady-state solution to the counterbalance equilibrium within\nthese contradictions. The solution takes into consideration the spillover\neffects of multiple-step interactions among the observations. When information\nfrom data is efficiently revealed in preferences, the revealed preferences\ngreatly reduce the volume of the required data in the sorting process. The\nemployed approach can be applied in many other areas, such as sports team\nranking, academic journal ranking, voting, and real effective exchange rates.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 01:11:47 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Hu", "Xingwei", ""]]}, {"id": "2003.12205", "submitter": "Huiqiang Zhong", "authors": "Huiqiang Zhong and Cunxiang Yin and Xiaohui Wu and Jinchang Luo and\n  JiaWei He", "title": "AirRL: A Reinforcement Learning Approach to Urban Air Quality Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban air pollution has become a major environmental problem that threatens\npublic health. It has become increasingly important to infer fine-grained urban\nair quality based on existing monitoring stations. One of the challenges is how\nto effectively select some relevant stations for air quality inference. In this\npaper, we propose a novel model based on reinforcement learning for urban air\nquality inference. The model consists of two modules: a station selector and an\nair quality regressor. The station selector dynamically selects the most\nrelevant monitoring stations when inferring air quality. The air quality\nregressor takes in the selected stations and makes air quality inference with\ndeep neural network. We conduct experiments on a real-world air quality dataset\nand our approach achieves the highest performance compared with several popular\nsolutions, and the experiments show significant effectiveness of proposed model\nin tackling problems of air quality inference.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 02:04:00 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Zhong", "Huiqiang", ""], ["Yin", "Cunxiang", ""], ["Wu", "Xiaohui", ""], ["Luo", "Jinchang", ""], ["He", "JiaWei", ""]]}, {"id": "2003.12206", "submitter": "Koustuv Sinha", "authors": "Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent\n  Larivi\\`ere, Alina Beygelzimer, Florence d'Alch\\'e-Buc, Emily Fox, Hugo\n  Larochelle", "title": "Improving Reproducibility in Machine Learning Research (A Report from\n  the NeurIPS 2019 Reproducibility Program)", "comments": "To appear at JMLR, 16 pages + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in machine learning research is to ensure that\npresented and published results are sound and reliable. Reproducibility, that\nis obtaining similar results as presented in a paper or talk, using the same\ncode and data (when available), is a necessary step to verify the reliability\nof research findings. Reproducibility is also an important step to promote open\nand accessible research, thereby allowing the scientific community to quickly\nintegrate new findings and convert ideas to practice. Reproducibility also\npromotes the use of robust experimental workflows, which potentially reduce\nunintentional errors. In 2019, the Neural Information Processing Systems\n(NeurIPS) conference, the premier international conference for research in\nmachine learning, introduced a reproducibility program, designed to improve the\nstandards across the community for how we conduct, communicate, and evaluate\nmachine learning research. The program contained three components: a code\nsubmission policy, a community-wide reproducibility challenge, and the\ninclusion of the Machine Learning Reproducibility checklist as part of the\npaper submission process. In this paper, we describe each of these components,\nhow it was deployed, as well as what we were able to learn from this\ninitiative.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 02:16:25 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 03:40:18 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 15:42:14 GMT"}, {"version": "v4", "created": "Wed, 30 Dec 2020 21:32:34 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pineau", "Joelle", ""], ["Vincent-Lamarre", "Philippe", ""], ["Sinha", "Koustuv", ""], ["Larivi\u00e8re", "Vincent", ""], ["Beygelzimer", "Alina", ""], ["d'Alch\u00e9-Buc", "Florence", ""], ["Fox", "Emily", ""], ["Larochelle", "Hugo", ""]]}, {"id": "2003.12210", "submitter": "Shao-Bo Lin", "authors": "Shao-Bo Lin, Di Wang, Ding-Xuan Zhou", "title": "Distributed Kernel Ridge Regression with Communications", "comments": "38pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on generalization performance analysis for distributed\nalgorithms in the framework of learning theory. Taking distributed kernel ridge\nregression (DKRR) for example, we succeed in deriving its optimal learning\nrates in expectation and providing theoretically optimal ranges of the number\nof local processors. Due to the gap between theory and experiments, we also\ndeduce optimal learning rates for DKRR in probability to essentially reflect\nthe generalization performance and limitations of DKRR. Furthermore, we propose\na communication strategy to improve the learning performance of DKRR and\ndemonstrate the power of communications in DKRR via both theoretical\nassessments and numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 02:42:43 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Lin", "Shao-Bo", ""], ["Wang", "Di", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "2003.12236", "submitter": "Fengxiang He", "authors": "Fengxiang He, Bohan Wang, Dacheng Tao", "title": "Piecewise linear activations substantially shape the loss surfaces of\n  neural networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the loss surface of a neural network is fundamentally important\nto the understanding of deep learning. This paper presents how piecewise linear\nactivation functions substantially shape the loss surfaces of neural networks.\nWe first prove that {\\it the loss surfaces of many neural networks have\ninfinite spurious local minima} which are defined as the local minima with\nhigher empirical risks than the global minima. Our result demonstrates that the\nnetworks with piecewise linear activations possess substantial differences to\nthe well-studied linear neural networks. This result holds for any neural\nnetwork with arbitrary depth and arbitrary piecewise linear activation\nfunctions (excluding linear functions) under most loss functions in practice.\nEssentially, the underlying assumptions are consistent with most practical\ncircumstances where the output layer is narrower than any hidden layer. In\naddition, the loss surface of a neural network with piecewise linear\nactivations is partitioned into multiple smooth and multilinear cells by\nnondifferentiable boundaries. The constructed spurious local minima are\nconcentrated in one cell as a valley: they are connected with each other by a\ncontinuous path, on which empirical risk is invariant. Further for\none-hidden-layer networks, we prove that all local minima in a cell constitute\nan equivalence class; they are concentrated in a valley; and they are all\nglobal minima in the cell.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 04:59:34 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["He", "Fengxiang", ""], ["Wang", "Bohan", ""], ["Tao", "Dacheng", ""]]}, {"id": "2003.12238", "submitter": "Chaoyang He", "authors": "Chaoyang He, Haishan Ye, Li Shen, Tong Zhang", "title": "MiLeNAS: Efficient Neural Architecture Search via Mixed-Level\n  Reformulation", "comments": "This paper is published in CVPR 2020 (IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recently proposed methods for Neural Architecture Search (NAS) can be\nformulated as bilevel optimization. For efficient implementation, its solution\nrequires approximations of second-order methods. In this paper, we demonstrate\nthat gradient errors caused by such approximations lead to suboptimality, in\nthe sense that the optimization procedure fails to converge to a (locally)\noptimal solution. To remedy this, this paper proposes \\mldas, a mixed-level\nreformulation for NAS that can be optimized efficiently and reliably. It is\nshown that even when using a simple first-order method on the mixed-level\nformulation, \\mldas\\ can achieve a lower validation error for NAS problems.\nConsequently, architectures obtained by our method achieve consistently higher\naccuracies than those obtained from bilevel optimization. Moreover, \\mldas\\\nproposes a framework beyond DARTS. It is upgraded via model size-based search\nand early stopping strategies to complete the search process in around 5 hours.\nExtensive experiments within the convolutional architecture search space\nvalidate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 05:06:54 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["He", "Chaoyang", ""], ["Ye", "Haishan", ""], ["Shen", "Li", ""], ["Zhang", "Tong", ""]]}, {"id": "2003.12239", "submitter": "Philip Amortila", "authors": "Philip Amortila, Doina Precup, Prakash Panangaden, Marc G. Bellemare", "title": "A Distributional Analysis of Sampling-Based Reinforcement Learning\n  Algorithms", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributional approach to theoretical analyses of reinforcement\nlearning algorithms for constant step-sizes. We demonstrate its effectiveness\nby presenting simple and unified proofs of convergence for a variety of\ncommonly-used methods. We show that value-based methods such as TD($\\lambda$)\nand $Q$-Learning have update rules which are contractive in the space of\ndistributions of functions, thus establishing their exponentially fast\nconvergence to a stationary distribution. We demonstrate that the stationary\ndistribution obtained by any algorithm whose target is an expected Bellman\nupdate has a mean which is equal to the true value function. Furthermore, we\nestablish that the distributions concentrate around their mean as the step-size\nshrinks. We further analyse the optimistic policy iteration algorithm, for\nwhich the contraction property does not hold, and formulate a probabilistic\npolicy improvement property which entails the convergence of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 05:13:29 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Amortila", "Philip", ""], ["Precup", "Doina", ""], ["Panangaden", "Prakash", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2003.12250", "submitter": "Anil Ramachandran", "authors": "Anil Ramachandran, Sunil Gupta, Santu Rana, Cheng Li, Svetha Venkatesh", "title": "Incorporating Expert Prior in Bayesian Optimisation via Space Warping", "comments": "21 Pages, 8 figures. To be published in Elsevier", "journal-ref": "Knowledge-Based Systems (2020) 105663", "doi": "10.1016/j.knosys.2020.105663", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a well-known sample-efficient method for the\noptimisation of expensive black-box functions. However when dealing with big\nsearch spaces the algorithm goes through several low function value regions\nbefore reaching the optimum of the function. Since the function evaluations are\nexpensive in terms of both money and time, it may be desirable to alleviate\nthis problem. One approach to subside this cold start phase is to use prior\nknowledge that can accelerate the optimisation. In its standard form, Bayesian\noptimisation assumes the likelihood of any point in the search space being the\noptimum is equal. Therefore any prior knowledge that can provide information\nabout the optimum of the function would elevate the optimisation performance.\nIn this paper, we represent the prior knowledge about the function optimum\nthrough a prior distribution. The prior distribution is then used to warp the\nsearch space in such a way that space gets expanded around the high probability\nregion of function optimum and shrinks around low probability region of\noptimum. We incorporate this prior directly in function model (Gaussian\nprocess), by redefining the kernel matrix, which allows this method to work\nwith any acquisition function, i.e. acquisition agnostic approach. We show the\nsuperiority of our method over standard Bayesian optimisation method through\noptimisation of several benchmark functions and hyperparameter tuning of two\nalgorithms: Support Vector Machine (SVM) and Random forest.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 06:18:49 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Ramachandran", "Anil", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Li", "Cheng", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2003.12260", "submitter": "H\\'elion Du Mas Des Bourboux", "authors": "Thomas Courtat, H\\'elion du Mas des Bourboux", "title": "A light neural network for modulation detection under impairments", "comments": "8 pages, 4 figures, presented at the conference \"Future Networks: 5G\n  and beyond, URSI-FR 2020\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural network architecture able to efficiently detect\nmodulation techniques in a portion of I/Q signals. This network is lighter by\nup to two orders of magnitude than other architectures working on the same or\nsimilar tasks. Moreover, the number of parameters does not depend on the signal\nduration, which allows processing stream of data, and results in a\nsignal-length invariant network. In addition, we develop a custom simulator\nable to model the different impairments the propagation channel and the\ndemodulator can bring to the recorded I/Q signal: random phase shifts, delays,\nroll-off, sampling rates, and frequency offsets. We benefit from this data set\nto train our neural network to be invariant to impairments and quantify its\naccuracy at disentangling between modulations under realistic real-life\nconditions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 07:26:42 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Courtat", "Thomas", ""], ["Bourboux", "H\u00e9lion du Mas des", ""]]}, {"id": "2003.12277", "submitter": "Negar Heidari", "authors": "Negar Heidari and Alexandros Iosifidis", "title": "Progressive Graph Convolutional Networks for Semi-Supervised Node\n  Classification", "comments": "11 pages, 4 figures, 4 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks have been successful in addressing graph-based\ntasks such as semi-supervised node classification. Existing methods use a\nnetwork structure defined by the user based on experimentation with fixed\nnumber of layers and neurons per layer and employ a layer-wise propagation rule\nto obtain the node embeddings. Designing an automatic process to define a\nproblem-dependant architecture for graph convolutional networks can greatly\nhelp to reduce the need for manual design of the structure of the model in the\ntraining process. In this paper, we propose a method to automatically build\ncompact and task-specific graph convolutional networks. Experimental results on\nwidely used publicly available datasets show that the proposed method\noutperforms related methods based on convolutional graph networks in terms of\nclassification performance and network compactness.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 08:32:16 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 09:27:09 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Heidari", "Negar", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2003.12283", "submitter": "Antonio Norelli", "authors": "Luca Cosmo, Antonio Norelli, Oshri Halimi, Ron Kimmel, Emanuele\n  Rodol\\`a", "title": "LIMP: Learning Latent Shape Representations with Metric Preservation\n  Priors", "comments": "24 pages (main article 14 + main bibliography 3 + supplementary 6 +\n  supplementary bibliography 1)", "journal-ref": null, "doi": "10.1007/978-3-030-58580-8_2", "report-no": null, "categories": "cs.LG cs.CG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we advocate the adoption of metric preservation as a powerful\nprior for learning latent representations of deformable 3D shapes. Key to our\nconstruction is the introduction of a geometric distortion criterion, defined\ndirectly on the decoded shapes, translating the preservation of the metric on\nthe decoding to the formation of linear paths in the underlying latent space.\nOur rationale lies in the observation that training samples alone are often\ninsufficient to endow generative models with high fidelity, motivating the need\nfor large training datasets. In contrast, metric preservation provides a\nrigorous way to control the amount of geometric distortion incurring in the\nconstruction of the latent space, leading in turn to synthetic samples of\nhigher quality. We further demonstrate, for the first time, the adoption of\ndifferentiable intrinsic distances in the backpropagation of a geodesic loss.\nOur geometric priors are particularly relevant in the presence of scarce\ntraining data, where learning any meaningful latent structure can be especially\nchallenging. The effectiveness and potential of our generative model is\nshowcased in applications of style transfer, content generation, and shape\ncompletion.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 08:53:34 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 13:14:57 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cosmo", "Luca", ""], ["Norelli", "Antonio", ""], ["Halimi", "Oshri", ""], ["Kimmel", "Ron", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "2003.12310", "submitter": "Michael Mayhew", "authors": "Michael B. Mayhew, Elizabeth Tran, Kirindi Choi, Uros Midic, Roland\n  Luethy, Nandita Damaraju and Ljubomir Buturovic", "title": "Optimization of Genomic Classifiers for Clinical Deployment: Evaluation\n  of Bayesian Optimization to Select Predictive Models of Acute Infection and\n  In-Hospital Mortality", "comments": "Preprint of an article published in Pacific Symposium on Biocomputing\n  \\c{opyright} [Year] World Scientific Publishing Co., Singapore,\n  http://psb.stanford.edu/ (12 pages, 3 figures); Supplementary Material\n  included (23 pages, 16 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute infection, if not rapidly and accurately detected, can lead to sepsis,\norgan failure and even death. Current detection of acute infection as well as\nassessment of a patient's severity of illness are imperfect. Characterization\nof a patient's immune response by quantifying expression levels of specific\ngenes from blood represents a potentially more timely and precise means of\naccomplishing both tasks. Machine learning methods provide a platform to\nleverage this 'host response' for development of deployment-ready\nclassification models. Prioritization of promising classifiers is dependent, in\npart, on hyperparameter optimization for which a number of approaches including\ngrid search, random sampling and Bayesian optimization have been shown to be\neffective. We compare HO approaches for the development of diagnostic\nclassifiers of acute infection and in-hospital mortality from gene expression\nof 29 diagnostic markers. We take a deployment-centered approach to our\ncomprehensive analysis, accounting for heterogeneity in our multi-study patient\ncohort with our choices of dataset partitioning and hyperparameter optimization\nobjective as well as assessing selected classifiers in external (as well as\ninternal) validation. We find that classifiers selected by Bayesian\noptimization for in-hospital mortality can outperform those selected by grid\nsearch or random sampling. However, in contrast to previous research: 1)\nBayesian optimization is not more efficient in selecting classifiers in all\ninstances compared to grid search or random sampling-based methods and 2) we\nnote marginal gains in classifier performance in only specific circumstances\nwhen using a common variant of Bayesian optimization (i.e. automatic relevance\ndetermination). Our analysis highlights the need for further practical,\ndeployment-centered benchmarking of HO approaches in the healthcare context.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 10:22:02 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 14:43:51 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 09:45:42 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Mayhew", "Michael B.", ""], ["Tran", "Elizabeth", ""], ["Choi", "Kirindi", ""], ["Midic", "Uros", ""], ["Luethy", "Roland", ""], ["Damaraju", "Nandita", ""], ["Buturovic", "Ljubomir", ""]]}, {"id": "2003.12317", "submitter": "Yuto Komori", "authors": "Yusuke Kubo, Yuto Komori, Toyonobu Okuyama, Hiroshi Tokieda", "title": "A copula-based visualization technique for a neural network", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning is defined as the extent to which humans\ncan comprehend the reason of a decision. However, a neural network is not\nconsidered interpretable due to the ambiguity in its decision-making process.\nTherefore, in this study, we propose a new algorithm that reveals which feature\nvalues the trained neural network considers important and which paths are\nmainly traced in the process of decision-making. In the proposed algorithm, the\nscore estimated by the correlation coefficients between the neural network\nlayers that can be calculated by applying the concept of a pair copula was\ndefined. We compared the estimated score with the feature importance values of\nRandom Forest, which is sometimes regarded as a highly interpretable algorithm,\nin the experiment and confirmed that the results were consistent with each\nother. This algorithm suggests an approach for compressing a neural network and\nits parameter tuning because the algorithm identifies the paths that contribute\nto the classification or prediction results.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 10:32:27 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Kubo", "Yusuke", ""], ["Komori", "Yuto", ""], ["Okuyama", "Toyonobu", ""], ["Tokieda", "Hiroshi", ""]]}, {"id": "2003.12365", "submitter": "Sharif Abuadbba Dr", "authors": "Sharif Abuadbba, Kyuyeon Kim, Minki Kim, Chandra Thapa, Seyit A.\n  Camtepe, Yansong Gao, Hyoungshick Kim, Surya Nepal", "title": "Can We Use Split Learning on 1D CNN Models for Privacy Preserving\n  Training?", "comments": "13 pages, Accepted at ACM ASIACCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new collaborative learning, called split learning, was recently introduced,\naiming to protect user data privacy without revealing raw input data to a\nserver. It collaboratively runs a deep neural network model where the model is\nsplit into two parts, one for the client and the other for the server.\nTherefore, the server has no direct access to raw data processed at the client.\nUntil now, the split learning is believed to be a promising approach to protect\nthe client's raw data; for example, the client's data was protected in\nhealthcare image applications using 2D convolutional neural network (CNN)\nmodels. However, it is still unclear whether the split learning can be applied\nto other deep learning models, in particular, 1D CNN.\n  In this paper, we examine whether split learning can be used to perform\nprivacy-preserving training for 1D CNN models. To answer this, we first design\nand implement an 1D CNN model under split learning and validate its efficacy in\ndetecting heart abnormalities using medical ECG data. We observed that the 1D\nCNN model under split learning can achieve the same accuracy of 98.9\\% like the\noriginal (non-split) model. However, our evaluation demonstrates that split\nlearning may fail to protect the raw data privacy on 1D CNN models. To address\nthe observed privacy leakage in split learning, we adopt two privacy leakage\nmitigation techniques: 1) adding more hidden layers to the client side and 2)\napplying differential privacy. Although those mitigation techniques are helpful\nin reducing privacy leakage, they have a significant impact on model accuracy.\nHence, based on those results, we conclude that split learning alone would not\nbe sufficient to maintain the confidentiality of raw sequential data in 1D CNN\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 06:06:14 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Abuadbba", "Sharif", ""], ["Kim", "Kyuyeon", ""], ["Kim", "Minki", ""], ["Thapa", "Chandra", ""], ["Camtepe", "Seyit A.", ""], ["Gao", "Yansong", ""], ["Kim", "Hyoungshick", ""], ["Nepal", "Surya", ""]]}, {"id": "2003.12366", "submitter": "Pinar Tozun", "authors": "Sebastian Baunsgaard and Sebastian B. Wrede and P{\\i}nar Tozun", "title": "Training for Speech Recognition on Coprocessors", "comments": "under submission to pvldb even though used acm style to submit here", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Speech Recognition (ASR) has increased in popularity in recent\nyears. The evolution of processor and storage technologies has enabled more\nadvanced ASR mechanisms, fueling the development of virtual assistants such as\nAmazon Alexa, Apple Siri, Microsoft Cortana, and Google Home. The interest in\nsuch assistants, in turn, has amplified the novel developments in ASR research.\nHowever, despite this popularity, there has not been a detailed training\nefficiency analysis of modern ASR systems. This mainly stems from: the\nproprietary nature of many modern applications that depend on ASR, like the\nones listed above; the relatively expensive co-processor hardware that is used\nto accelerate ASR by big vendors to enable such applications; and the absence\nof well-established benchmarks. The goal of this paper is to address the latter\ntwo of these challenges. The paper first describes an ASR model, based on a\ndeep neural network inspired by recent work in this domain, and our experiences\nbuilding it. Then we evaluate this model on three CPU-GPU co-processor\nplatforms that represent different budget categories. Our results demonstrate\nthat utilizing hardware acceleration yields good results even without high-end\nequipment. While the most expensive platform (10X price of the least expensive\none) converges to the initial accuracy target 10-30% and 60-70% faster than the\nother two, the differences among the platforms almost disappear at slightly\nhigher accuracy targets. In addition, our results further highlight both the\ndifficulty of evaluating ASR systems due to the complex, long, and resource\nintensive nature of the model training in this domain, and the importance of\nestablishing benchmarks for ASR.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 11:21:29 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Baunsgaard", "Sebastian", ""], ["Wrede", "Sebastian B.", ""], ["Tozun", "P\u0131nar", ""]]}, {"id": "2003.12381", "submitter": "Daniel Leite", "authors": "Charles Aguiar, Daniel Leite", "title": "Unsupervised Fuzzy eIX: Evolving Internal-eXternal Fuzzy Clustering", "comments": "8 pages, 9 figures, IEEE Conference on Evolving and Adaptive\n  Intelligent Systems (EAIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-varying classifiers, namely, evolving classifiers, play an important\nrole in a scenario in which information is available as a never-ending online\ndata stream. We present a new unsupervised learning method for numerical data\ncalled evolving Internal-eXternal Fuzzy clustering method (Fuzzy eIX). We\ndevelop the notion of double-boundary fuzzy granules and elaborate on its\nimplications. Type 1 and type 2 fuzzy inference systems can be obtained from\nthe projection of Fuzzy eIX granules. We perform the principle of the balanced\ninformation granularity within Fuzzy eIX classifiers to achieve a higher level\nof model understandability. Internal and external granules are updated from a\nnumerical data stream at the same time that the global granular structure of\nthe classifier is autonomously evolved. A synthetic nonstationary problem\ncalled Rotation of Twin Gaussians shows the behavior of the classifier. The\nFuzzy eIX classifier could keep up with its accuracy in a scenario in which\noffline-trained classifiers would clearly have their accuracy drastically\ndropped.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 16:17:27 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Aguiar", "Charles", ""], ["Leite", "Daniel", ""]]}, {"id": "2003.12386", "submitter": "Milad Taleby Ahvanooey", "authors": "Seyedeh Faezeh Farahbakhshian, Milad Taleby Ahvanooey", "title": "A New Gene Selection Algorithm using Fuzzy-Rough Set Theory for Tumor\n  Classification", "comments": "10 pages, 3 figures, 6 Tables", "journal-ref": "Control Engineering and Applied Informatics, Vol.22, No.1 pp.\n  14-23, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In statistics and machine learning, feature selection is the process of\npicking a subset of relevant attributes for utilizing in a predictive model.\nRecently, rough set-based feature selection techniques, that employ feature\ndependency to perform selection process, have been drawn attention.\nClassification of tumors based on gene expression is utilized to diagnose\nproper treatment and prognosis of the disease in bioinformatics applications.\nMicroarray gene expression data includes superfluous feature genes of high\ndimensionality and smaller training instances. Since exact supervised\nclassification of gene expression instances in such high-dimensional problems\nis very complex, the selection of appropriate genes is a crucial task for tumor\nclassification. In this study, we present a new technique for gene selection\nusing a discernibility matrix of fuzzy-rough sets. The proposed technique takes\ninto account the similarity of those instances that have the same and different\nclass labels to improve the gene selection results, while the state-of-the art\nprevious approaches only address the similarity of instances with different\nclass labels. To meet that requirement, we extend the Johnson reducer technique\ninto the fuzzy case. Experimental results demonstrate that this technique\nprovides better efficiency compared to the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 13:43:25 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Farahbakhshian", "Seyedeh Faezeh", ""], ["Ahvanooey", "Milad Taleby", ""]]}, {"id": "2003.12408", "submitter": "Xiaojie Mao", "authors": "Nathan Kallus, Xiaojie Mao", "title": "On the role of surrogates in the efficient estimation of treatment\n  effects with limited outcome data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating treatment effects when the outcome of\nprimary interest (e.g., long-term health status) is only seldom observed but\nabundant surrogate observations (e.g., short-term health outcomes) are\navailable. To investigate the role of surrogates in this setting, we derive the\nsemiparametric efficiency lower bounds of average treatment effect (ATE) both\nwith and without presence of surrogates, as well as several intermediary\nsettings. These bounds characterize the best-possible precision of ATE\nestimation in each case, and their difference quantifies the efficiency gains\nfrom optimally leveraging the surrogates in terms of key problem\ncharacteristics when only limited outcome data are available. We show these\nresults apply in two important regimes: when the number of surrogate\nobservations is comparable to primary-outcome observations and when the former\ndominates the latter. Importantly, we take a missing-data approach that\ncircumvents strong surrogate conditions which are commonly assumed in previous\nliterature but almost always fail in practice. To show how to leverage the\nefficiency gains of surrogate observations, we propose ATE estimators and\ninferential methods based on flexible machine learning methods to estimate\nnuisance parameters that appear in the influence functions. We show our\nestimators enjoy efficiency and robustness guarantees under weak conditions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 13:31:49 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "2003.12415", "submitter": "Naresh Balaji Ravichandran", "authors": "Naresh Balaji Ravichandran, Anders Lansner, Pawel Herman", "title": "Learning representations in Bayesian Confidence Propagation neural\n  networks", "comments": null, "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9207061", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised learning of hierarchical representations has been one of the\nmost vibrant research directions in deep learning during recent years. In this\nwork we study biologically inspired unsupervised strategies in neural networks\nbased on local Hebbian learning. We propose new mechanisms to extend the\nBayesian Confidence Propagating Neural Network (BCPNN) architecture, and\ndemonstrate their capability for unsupervised learning of salient hidden\nrepresentations when tested on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 13:47:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ravichandran", "Naresh Balaji", ""], ["Lansner", "Anders", ""], ["Herman", "Pawel", ""]]}, {"id": "2003.12423", "submitter": "Naeimeh Omidvar", "authors": "Naeimeh Omidvar, Mohammad Ali Maddah-Ali, Hamed Mahdavi", "title": "A Hybrid-Order Distributed SGD Method for Non-Convex Optimization to\n  Balance Communication Overhead, Computational Complexity, and Convergence\n  Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method of distributed stochastic gradient descent\n(SGD), with low communication load and computational complexity, and still fast\nconvergence. To reduce the communication load, at each iteration of the\nalgorithm, the worker nodes calculate and communicate some scalers, that are\nthe directional derivatives of the sample functions in some \\emph{pre-shared\ndirections}. However, to maintain accuracy, after every specific number of\niterations, they communicate the vectors of stochastic gradients. To reduce the\ncomputational complexity in each iteration, the worker nodes approximate the\ndirectional derivatives with zeroth-order stochastic gradient estimation, by\nperforming just two function evaluations rather than computing a first-order\ngradient vector. The proposed method highly improves the convergence rate of\nthe zeroth-order methods, guaranteeing order-wise faster convergence. Moreover,\ncompared to the famous communication-efficient methods of model averaging (that\nperform local model updates and periodic communication of the gradients to\nsynchronize the local models), we prove that for the general class of\nnon-convex stochastic problems and with reasonable choice of parameters, the\nproposed method guarantees the same orders of communication load and\nconvergence rate, while having order-wise less computational complexity.\nExperimental results on various learning problems in neural networks\napplications demonstrate the effectiveness of the proposed approach compared to\nvarious state-of-the-art distributed SGD methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 14:02:15 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Omidvar", "Naeimeh", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Mahdavi", "Hamed", ""]]}, {"id": "2003.12425", "submitter": "Akhil Mathur", "authors": "Akhil Mathur, Anton Isopoussu, Fahim Kawsar, Nadia Berthouze, Nicholas\n  D. Lane", "title": "Mic2Mic: Using Cycle-Consistent Generative Adversarial Networks to\n  Overcome Microphone Variability in Speech Systems", "comments": "Published at ACM IPSN 2019", "journal-ref": null, "doi": "10.1145/3302506.3310398", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile and embedded devices are increasingly using microphones and\naudio-based computational models to infer user context. A major challenge in\nbuilding systems that combine audio models with commodity microphones is to\nguarantee their accuracy and robustness in the real-world. Besides many\nenvironmental dynamics, a primary factor that impacts the robustness of audio\nmodels is microphone variability. In this work, we propose Mic2Mic -- a\nmachine-learned system component -- which resides in the inference pipeline of\naudio models and at real-time reduces the variability in audio data caused by\nmicrophone-specific factors. Two key considerations for the design of Mic2Mic\nwere: a) to decouple the problem of microphone variability from the audio task,\nand b) put a minimal burden on end-users to provide training data. With these\nin mind, we apply the principles of cycle-consistent generative adversarial\nnetworks (CycleGANs) to learn Mic2Mic using unlabeled and unpaired data\ncollected from different microphones. Our experiments show that Mic2Mic can\nrecover between 66% to 89% of the accuracy lost due to microphone variability\nfor two common audio tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 14:06:36 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Mathur", "Akhil", ""], ["Isopoussu", "Anton", ""], ["Kawsar", "Fahim", ""], ["Berthouze", "Nadia", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2003.12427", "submitter": "Ashkan Ertefaie", "authors": "Ashkan Ertefaie, James R. McKay, David Oslin and Robert L. Strawderman", "title": "Robust Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning is a regression-based approach that is widely used to formalize\nthe development of an optimal dynamic treatment strategy. Finite dimensional\nworking models are typically used to estimate certain nuisance parameters, and\nmisspecification of these working models can result in residual confounding\nand/or efficiency loss. We propose a robust Q-learning approach which allows\nestimating such nuisance parameters using data-adaptive techniques. We study\nthe asymptotic behavior of our estimators and provide simulation studies that\nhighlight the need for and usefulness of the proposed method in practice. We\nuse the data from the \"Extending Treatment Effectiveness of Naltrexone\"\nmulti-stage randomized trial to illustrate our proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 14:10:38 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ertefaie", "Ashkan", ""], ["McKay", "James R.", ""], ["Oslin", "David", ""], ["Strawderman", "Robert L.", ""]]}, {"id": "2003.12428", "submitter": "Yurui Ming", "authors": "Yurui Ming, Weiping Ding, Zehong Cao, Chin-Teng Lin", "title": "A General Approach for Using Deep Neural Network for Digital\n  Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technologies of the Internet of Things (IoT) facilitate digital contents such\nas images being acquired in a massive way. However, consideration from the\nprivacy or legislation perspective still demands the need for intellectual\ncontent protection. In this paper, we propose a general deep neural network\n(DNN) based watermarking method to fulfill this goal. Instead of training a\nneural network for protecting a specific image, we train on an image set and\nuse the trained model to protect a distinct test image set in a bulk manner.\nRespective evaluations both from the subjective and objective aspects confirm\nthe supremacy and practicability of our proposed method. To demonstrate the\nrobustness of this general neural watermarking mechanism, commonly used\nmanipulations are applied to the watermarked image to examine the corresponding\nextracted watermark, which still retains sufficient recognizable traits. To the\nbest of our knowledge, we are the first to propose a general way to perform\nwatermarking using DNN. Considering its performance and economy, it is\nconcluded that subsequent studies that generalize our work on utilizing DNN for\nintellectual content protection is a promising research trend.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 06:22:04 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ming", "Yurui", ""], ["Ding", "Weiping", ""], ["Cao", "Zehong", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2003.12437", "submitter": "Max Veit", "authors": "Max Veit, David M. Wilkins, Yang Yang, Robert A. DiStasio Jr., Michele\n  Ceriotti", "title": "Predicting molecular dipole moments by combining atomic partial charges\n  and atomic dipoles", "comments": "16 pages, 7 figures, plus supplementary information; added Materials\n  Cloud link and corrected values in Table I. To be published in the Journal of\n  Chemical Physics", "journal-ref": "J. Chem. Phys. 153(2), 024113 (2020)", "doi": "10.1063/5.0009106", "report-no": null, "categories": "physics.chem-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The molecular dipole moment ($\\boldsymbol{\\mu}$) is a central quantity in\nchemistry. It is essential in predicting infrared and sum-frequency generation\nspectra, as well as induction and long-range electrostatic interactions.\nFurthermore, it can be extracted directly from high-level quantum mechanical\ncalculations, making it an ideal target for machine learning (ML). In this\nwork, we choose to represent this quantity with a physically inspired ML model\nthat captures two distinct physical effects: local atomic polarization is\ncaptured within the symmetry-adapted Gaussian process regression (SA-GPR)\nframework, which assigns a (vector) dipole moment to each atom, while movement\nof charge across the entire molecule is captured by assigning a partial\n(scalar) charge to each atom. The resulting \"MuML\" models are fitted together\nto reproduce molecular $\\boldsymbol{\\mu}$ computed using high-level\ncoupled-cluster theory (CCSD) and density functional theory (DFT) on the QM7b\ndataset. The combined model shows excellent transferability when applied to a\nshowcase dataset of larger and more complex molecules, approaching the accuracy\nof DFT at a small fraction of the computational cost. We also demonstrate that\nthe uncertainty in the predictions can be estimated reliably using a calibrated\ncommittee model. The ultimate performance of the models depends, however, on\nthe details of the system at hand, with the scalar model being clearly superior\nwhen describing large molecules whose dipole is almost entirely generated by\ncharge separation. These observations point to the importance of simultaneously\naccounting for the local and non-local effects that contribute to\n$\\boldsymbol{\\mu}$; further, they define a challenging task to benchmark future\nmodels, particularly those aimed at the description of condensed phases.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 14:35:37 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 18:37:29 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 17:31:23 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Veit", "Max", ""], ["Wilkins", "David M.", ""], ["Yang", "Yang", ""], ["DiStasio", "Robert A.", "Jr."], ["Ceriotti", "Michele", ""]]}, {"id": "2003.12454", "submitter": "Ezequiel Alvarez", "authors": "Ezequiel Alvarez (ICAS, Argentina), Federico Lamagna (CAB, Argentina)\n  and Manuel Szewc (ICAS, Argentina)", "title": "A Machine Learning alternative to placebo-controlled clinical trials\n  upon new diseases: A primer", "comments": "Work originally aimed for COVID-19 outbreak. All scripts are open\n  source in github.com/ManuelSzewc/ML4DT/", "journal-ref": null, "doi": null, "report-no": "ICAS 048", "categories": "q-bio.QM cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The appearance of a new dangerous and contagious disease requires the\ndevelopment of a drug therapy faster than what is foreseen by usual mechanisms.\nMany drug therapy developments consist in investigating through different\nclinical trials the effects of different specific drug combinations by\ndelivering it into a test group of ill patients, meanwhile a placebo treatment\nis delivered to the remaining ill patients, known as the control group. We\ncompare the above technique to a new technique in which all patients receive a\ndifferent and reasonable combination of drugs and use this outcome to feed a\nNeural Network. By averaging out fluctuations and recognizing different patient\nfeatures, the Neural Network learns the pattern that connects the patients\ninitial state to the outcome of the treatments and therefore can predict the\nbest drug therapy better than the above method. In contrast to many available\nworks, we do not study any detail of drugs composition nor interaction, but\ninstead pose and solve the problem from a phenomenological point of view, which\nallows us to compare both methods. Although the conclusion is reached through\nmathematical modeling and is stable upon any reasonable model, this is a\nproof-of-concept that should be studied within other expertises before\nconfronting a real scenario. All calculations, tools and scripts have been made\nopen source for the community to test, modify or expand it. Finally it should\nbe mentioned that, although the results presented here are in the context of a\nnew disease in medical sciences, these are useful for any field that requires a\nexperimental technique with a control group.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 17:53:10 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Alvarez", "Ezequiel", "", "ICAS, Argentina"], ["Lamagna", "Federico", "", "CAB, Argentina"], ["Szewc", "Manuel", "", "ICAS, Argentina"]]}, {"id": "2003.12464", "submitter": "Jianyu Chen", "authors": "Jianyu Chen, Zhuo Xu and Masayoshi Tomizuka", "title": "End-to-end Autonomous Driving Perception with Sequential Latent\n  Representation Learning", "comments": "8 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current autonomous driving systems are composed of a perception system and a\ndecision system. Both of them are divided into multiple subsystems built up\nwith lots of human heuristics. An end-to-end approach might clean up the system\nand avoid huge efforts of human engineering, as well as obtain better\nperformance with increasing data and computation resources. Compared to the\ndecision system, the perception system is more suitable to be designed in an\nend-to-end framework, since it does not require online driving exploration. In\nthis paper, we propose a novel end-to-end approach for autonomous driving\nperception. A latent space is introduced to capture all relevant features\nuseful for perception, which is learned through sequential latent\nrepresentation learning. The learned end-to-end perception model is able to\nsolve the detection, tracking, localization and mapping problems altogether\nwith only minimum human engineering efforts and without storing any maps\nonline. The proposed method is evaluated in a realistic urban driving\nsimulator, with both camera image and lidar point cloud as sensor inputs. The\ncodes and videos of this work are available at our github repo and project\nwebsite.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 05:37:44 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 03:40:42 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chen", "Jianyu", ""], ["Xu", "Zhuo", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2003.12469", "submitter": "Steven Elsworth", "authors": "Steven Elsworth and Stefan G\\\"uttel", "title": "ABBA: Adaptive Brownian bridge-based symbolic aggregation of time series", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new symbolic representation of time series, called ABBA, is introduced. It\nis based on an adaptive polygonal chain approximation of the time series into a\nsequence of tuples, followed by a mean-based clustering to obtain the symbolic\nrepresentation. We show that the reconstruction error of this representation\ncan be modelled as a random walk with pinned start and end points, a so-called\nBrownian bridge. This insight allows us to make ABBA essentially\nparameter-free, except for the approximation tolerance which must be chosen.\nExtensive comparisons with the SAX and 1d-SAX representations are included in\nthe form of performance profiles, showing that ABBA is able to better preserve\nthe essential shape information of time series compared to other approaches.\nAdvantages and applications of ABBA are discussed, including its in-built\ndifferencing property and use for anomaly detection, and Python implementations\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 15:30:32 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Elsworth", "Steven", ""], ["G\u00fcttel", "Stefan", ""]]}, {"id": "2003.12537", "submitter": "Andreas Kirsch", "authors": "Andreas Kirsch, Clare Lyle, Yarin Gal", "title": "Unpacking Information Bottlenecks: Unifying Information-Theoretic\n  Objectives in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck principle offers both a mechanism to explain how\ndeep neural networks train and generalize, as well as a regularized objective\nwith which to train models. However, multiple competing objectives are proposed\nin the literature, and the information-theoretic quantities used in these\nobjectives are difficult to compute for large deep neural networks, which in\nturn limits their use as a training objective. In this work, we review these\nquantities and compare and unify previously proposed objectives, which allows\nus to develop surrogate objectives more friendly to optimization without\nrelying on cumbersome tools such as density estimation. We find that these\nsurrogate objectives allow us to apply the information bottleneck to modern\nneural network architectures. We demonstrate our insights on MNIST, CIFAR-10\nand Imagenette with modern DNN architectures (ResNets).\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 17:05:03 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 00:05:28 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 18:09:22 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Kirsch", "Andreas", ""], ["Lyle", "Clare", ""], ["Gal", "Yarin", ""]]}, {"id": "2003.12590", "submitter": "Martin Grohe", "authors": "Martin Grohe", "title": "word2vec, node2vec, graph2vec, X2vec: Towards a Theory of Vector\n  Embeddings of Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector representations of graphs and relational structures, whether\nhand-crafted feature vectors or learned representations, enable us to apply\nstandard data analysis and machine learning techniques to the structures. A\nwide range of methods for generating such embeddings have been studied in the\nmachine learning and knowledge representation literature. However, vector\nembeddings have received relatively little attention from a theoretical point\nof view.\n  Starting with a survey of embedding techniques that have been used in\npractice, in this paper we propose two theoretical approaches that we see as\ncentral for understanding the foundations of vector embeddings. We draw\nconnections between the various approaches and suggest directions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 18:23:55 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Grohe", "Martin", ""]]}, {"id": "2003.12597", "submitter": "Dhruv Patel", "authors": "Dhruv V. Patel, Assad A. Oberai", "title": "GAN-based Priors for Quantifying Uncertainty", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.28806.32322", "report-no": null, "categories": "stat.ML cs.CV cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference is used extensively to quantify the uncertainty in an\ninferred field given the measurement of a related field when the two are linked\nby a mathematical model. Despite its many applications, Bayesian inference\nfaces challenges when inferring fields that have discrete representations of\nlarge dimension, and/or have prior distributions that are difficult to\ncharacterize mathematically. In this work we demonstrate how the approximate\ndistribution learned by a deep generative adversarial network (GAN) may be used\nas a prior in a Bayesian update to address both these challenges. We\ndemonstrate the efficacy of this approach on two distinct, and remarkably\nbroad, classes of problems. The first class leads to supervised learning\nalgorithms for image classification with superior out of distribution detection\nand accuracy, and for image inpainting with built-in variance estimation. The\nsecond class leads to unsupervised learning algorithms for image denoising and\nfor solving physics-driven inverse problems.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 18:52:54 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Patel", "Dhruv V.", ""], ["Oberai", "Assad A.", ""]]}, {"id": "2003.12613", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Yuzhe Ma, Adish Singla, Xiaojin Zhu", "title": "Adaptive Reward-Poisoning Attacks against Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reward-poisoning attacks against reinforcement learning (RL), an attacker\ncan perturb the environment reward $r_t$ into $r_t+\\delta_t$ at each step, with\nthe goal of forcing the RL agent to learn a nefarious policy. We categorize\nsuch attacks by the infinity-norm constraint on $\\delta_t$: We provide a lower\nthreshold below which reward-poisoning attack is infeasible and RL is certified\nto be safe; we provide a corresponding upper threshold above which the attack\nis feasible. Feasible attacks can be further categorized as non-adaptive where\n$\\delta_t$ depends only on $(s_t,a_t, s_{t+1})$, or adaptive where $\\delta_t$\ndepends further on the RL agent's learning process at time $t$. Non-adaptive\nattacks have been the focus of prior works. However, we show that under mild\nconditions, adaptive attacks can achieve the nefarious policy in steps\npolynomial in state-space size $|S|$, whereas non-adaptive attacks require\nexponential steps. We provide a constructive proof that a Fast Adaptive Attack\nstrategy achieves the polynomial rate. Finally, we show that empirically an\nattacker can find effective reward-poisoning attacks using state-of-the-art\ndeep RL techniques.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:46:23 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 21:02:31 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Ma", "Yuzhe", ""], ["Singla", "Adish", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2003.12628", "submitter": "Edgar A. Bernal", "authors": "Trevor W. Richardson, Wencheng Wu, Lei Lin, Beilei Xu, Edgar A. Bernal", "title": "MCFlow: Monte Carlo Flow Models for Data Imputation", "comments": null, "journal-ref": "2020 Computer Vision and Pattern Recognition (CVPR)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the topic of data imputation, a foundational task in machine\nlearning that addresses issues with missing data. To that end, we propose\nMCFlow, a deep framework for imputation that leverages normalizing flow\ngenerative models and Monte Carlo sampling. We address the causality dilemma\nthat arises when training models with incomplete data by introducing an\niterative learning scheme which alternately updates the density estimate and\nthe values of the missing entries in the training data. We provide extensive\nempirical validation of the effectiveness of the proposed method on standard\nmultivariate and image datasets, and benchmark its performance against\nstate-of-the-art alternatives. We demonstrate that MCFlow is superior to\ncompeting methods in terms of the quality of the imputed data, as well as with\nregards to its ability to preserve the semantic structure of the data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 20:33:52 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Richardson", "Trevor W.", ""], ["Wu", "Wencheng", ""], ["Lin", "Lei", ""], ["Xu", "Beilei", ""], ["Bernal", "Edgar A.", ""]]}, {"id": "2003.12635", "submitter": "C. Seshadhri", "authors": "C. Seshadhri and Aneesh Sharma and Andrew Stolman and Ashish Goel", "title": "The impossibility of low rank representations for triangle-rich complex\n  networks", "comments": null, "journal-ref": "PNAS, March 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of complex networks is a significant development in modern science,\nand has enriched the social sciences, biology, physics, and computer science.\nModels and algorithms for such networks are pervasive in our society, and\nimpact human behavior via social networks, search engines, and recommender\nsystems to name a few. A widely used algorithmic technique for modeling such\ncomplex networks is to construct a low-dimensional Euclidean embedding of the\nvertices of the network, where proximity of vertices is interpreted as the\nlikelihood of an edge. Contrary to the common view, we argue that such graph\nembeddings do not}capture salient properties of complex networks. The two\nproperties we focus on are low degree and large clustering coefficients, which\nhave been widely established to be empirically true for real-world networks. We\nmathematically prove that any embedding (that uses dot products to measure\nsimilarity) that can successfully create these two properties must have rank\nnearly linear in the number of vertices. Among other implications, this\nestablishes that popular embedding techniques such as Singular Value\nDecomposition and node2vec fail to capture significant structural aspects of\nreal-world complex networks. Furthermore, we empirically study a number of\ndifferent embedding techniques based on dot product, and show that they all\nfail to capture the triangle structure.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 20:57:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Seshadhri", "C.", ""], ["Sharma", "Aneesh", ""], ["Stolman", "Andrew", ""], ["Goel", "Ashish", ""]]}, {"id": "2003.12643", "submitter": "Anderson Ara", "authors": "Anderson Ara, Mateus Maia, Samuel Mac\\^edo and Francisco Louzada", "title": "Random Machines Regression Approach: an ensemble support vector\n  regression model with free kernel choice", "comments": "arXiv admin note: text overlap with arXiv:1911.09411", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques always aim to reduce the generalized prediction\nerror. In order to reduce it, ensemble methods present a good approach\ncombining several models that results in a greater forecasting capacity. The\nRandom Machines already have been demonstrated as strong technique, i.e: high\npredictive power, to classification tasks, in this article we propose an\nprocedure to use the bagged-weighted support vector model to regression\nproblems. Simulation studies were realized over artificial datasets, and over\nreal data benchmarks. The results exhibited a good performance of Regression\nRandom Machines through lower generalization error without needing to choose\nthe best kernel function during tuning process.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 21:30:59 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Ara", "Anderson", ""], ["Maia", "Mateus", ""], ["Mac\u00eado", "Samuel", ""], ["Louzada", "Francisco", ""]]}, {"id": "2003.12659", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Razieh Nabi, Ilya Shpitser", "title": "Semiparametric Inference For Causal Effects In Graphical Models With\n  Hidden Variables", "comments": "73 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade witnessed the development of algorithms that completely solve\nthe identifiability problem for causal effects in hidden variable causal models\nassociated with directed acyclic graphs. However, much of this machinery\nremains underutilized in practice owing to the complexity of estimating\nidentifying functionals yielded by these algorithms. In this paper, we provide\nsimple graphical criteria and semiparametric estimators that bridge the gap\nbetween identification and estimation for causal effects involving a single\ntreatment and a single outcome. First, we provide influence function based\ndoubly robust estimators that cover a significant subset of hidden variable\ncausal models where the effect is identifiable. We further characterize an\nimportant subset of this class for which we demonstrate how to derive the\nestimator with the lowest asymptotic variance, i.e., one that achieves the\nsemiparametric efficiency bound. Finally, we provide semiparametric estimators\nfor any single treatment causal effect parameter identified via the\naforementioned algorithms. The resulting estimators resemble influence function\nbased estimators that are sequentially reweighted, and exhibit a partial double\nrobustness property, provided the parts of the likelihood corresponding to a\nset of weight models are correctly specified. Our methods are easy to implement\nand we demonstrate their utility through simulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 22:29:04 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Nabi", "Razieh", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2003.12699", "submitter": "Yunzong Xu", "authors": "David Simchi-Levi, Yunzong Xu", "title": "Bypassing the Monster: A Faster and Simpler Optimal Algorithm for\n  Contextual Bandits under Realizability", "comments": "Forthcoming in Mathematics of Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the general (stochastic) contextual bandit problem under the\nrealizability assumption, i.e., the expected reward, as a function of contexts\nand actions, belongs to a general function class $\\mathcal{F}$. We design a\nfast and simple algorithm that achieves the statistically optimal regret with\nonly ${O}(\\log T)$ calls to an offline regression oracle across all $T$ rounds.\nThe number of oracle calls can be further reduced to $O(\\log\\log T)$ if $T$ is\nknown in advance. Our results provide the first universal and optimal reduction\nfrom contextual bandits to offline regression, solving an important open\nproblem in the contextual bandit literature. A direct consequence of our\nresults is that any advances in offline regression immediately translate to\ncontextual bandits, statistically and computationally. This leads to faster\nalgorithms and improved regret guarantees for broader classes of contextual\nbandit problems.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 04:16:52 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 01:46:50 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 05:59:42 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 16:47:44 GMT"}, {"version": "v5", "created": "Sat, 10 Jul 2021 04:40:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Simchi-Levi", "David", ""], ["Xu", "Yunzong", ""]]}, {"id": "2003.12705", "submitter": "Yanmin Gong", "authors": "Rui Hu, Yuanxiong Guo, E. Paul. Ratazzi and Yanmin Gong", "title": "Differentially Private Federated Learning for Resource-Constrained\n  Internet of Things", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of smart devices having built-in sensors, Internet\nconnectivity, and programmable computation capability in the era of Internet of\nthings (IoT), tremendous data is being generated at the network edge. Federated\nlearning is capable of analyzing the large amount of data from a distributed\nset of smart devices without requiring them to upload their data to a central\nplace. However, the commonly-used federated learning algorithm is based on\nstochastic gradient descent (SGD) and not suitable for resource-constrained IoT\nenvironments due to its high communication resource requirement. Moreover, the\nprivacy of sensitive data on smart devices has become a key concern and needs\nto be protected rigorously. This paper proposes a novel federated learning\nframework called DP-PASGD for training a machine learning model efficiently\nfrom the data stored across resource-constrained smart devices in IoT while\nguaranteeing differential privacy. The optimal schematic design of DP-PASGD\nthat maximizes the learning performance while satisfying the limits on resource\ncost and privacy loss is formulated as an optimization problem, and an\napproximate solution method based on the convergence analysis of DP-PASGD is\ndeveloped to solve the optimization problem efficiently. Numerical results\nbased on real-world datasets verify the effectiveness of the proposed DP-PASGD\nscheme.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 04:32:54 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hu", "Rui", ""], ["Guo", "Yuanxiong", ""], ["Ratazzi", "E. Paul.", ""], ["Gong", "Yanmin", ""]]}, {"id": "2003.12725", "submitter": "Chence Shi", "authors": "Chence Shi, Minkai Xu, Hongyu Guo, Ming Zhang, Jian Tang", "title": "A Graph to Graphs Framework for Retrosynthesis Prediction", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in computational chemistry is to find a set of\nreactants to synthesize a target molecule, a.k.a. retrosynthesis prediction.\nExisting state-of-the-art methods rely on matching the target molecule with a\nlarge set of reaction templates, which are very computationally expensive and\nalso suffer from the problem of coverage. In this paper, we propose a novel\ntemplate-free approach called G2Gs by transforming a target molecular graph\ninto a set of reactant molecular graphs. G2Gs first splits the target molecular\ngraph into a set of synthons by identifying the reaction centers, and then\ntranslates the synthons to the final reactant graphs via a variational graph\ntranslation framework. Experimental results show that G2Gs significantly\noutperforms existing template-free approaches by up to 63% in terms of the\ntop-1 accuracy and achieves a performance close to that of state-of-the-art\ntemplate based approaches, but does not require domain knowledge and is much\nmore scalable.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 06:16:56 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:43:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shi", "Chence", ""], ["Xu", "Minkai", ""], ["Guo", "Hongyu", ""], ["Zhang", "Ming", ""], ["Tang", "Jian", ""]]}, {"id": "2003.12756", "submitter": "Meyer Scetbon", "authors": "Meyer Scetbon and Zaid Harchaoui", "title": "Harmonic Decompositions of Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a description of the function space and the smoothness class\nassociated with a convolutional network using the machinery of reproducing\nkernel Hilbert spaces. We show that the mapping associated with a convolutional\nnetwork expands into a sum involving elementary functions akin to spherical\nharmonics. This functional decomposition can be related to the functional ANOVA\ndecomposition in nonparametric statistics. Building off our functional\ncharacterization of convolutional networks, we obtain statistical bounds\nhighlighting an interesting trade-off between the approximation error and the\nestimation error.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 09:41:55 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 07:43:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Scetbon", "Meyer", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2003.12795", "submitter": "Zhikun Chen", "authors": "Zhikun Chen, Daofeng Li, Ming Zhao, Sihai Zhang, Jinkang Zhu", "title": "Semi-Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables massive distributed Information and\nCommunication Technology (ICT) devices to learn a global consensus model\nwithout any participants revealing their own data to the central server.\nHowever, the practicality, communication expense and non-independent and\nidentical distribution (Non-IID) data challenges in FL still need to be\nconcerned. In this work, we propose the Semi-Federated Learning (Semi-FL) which\ndiffers from the FL in two aspects, local clients clustering and in-cluster\ntraining. A sequential training manner is designed for our in-cluster training\nin this paper which enables the neighboring clients to share their learning\nmodels. The proposed Semi-FL can be easily applied to future mobile\ncommunication networks and require less up-link transmission bandwidth.\nNumerical experiments validate the feasibility, learning performance and the\nrobustness to Non-IID data of the proposed Semi-FL. The Semi-FL extends the\nexisting potentials of FL.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 14:08:59 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Chen", "Zhikun", ""], ["Li", "Daofeng", ""], ["Zhao", "Ming", ""], ["Zhang", "Sihai", ""], ["Zhu", "Jinkang", ""]]}, {"id": "2003.12796", "submitter": "Anti Ingel", "authors": "Anti Ingel, Novin Shahroudi, Markus K\\\"angsepp, Andre T\\\"attar,\n  Viacheslav Komisarenko, Meelis Kull", "title": "Correlated daily time series and forecasting in the M4 competition", "comments": null, "journal-ref": "International Journal of Forecasting, 36(1), 121-128 (2020)", "doi": "10.1016/j.ijforecast.2019.02.018", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participated in the M4 competition for time series forecasting and\ndescribe here our methods for forecasting daily time series. We used an\nensemble of five statistical forecasting methods and a method that we refer to\nas the correlator. Our retrospective analysis using the ground truth values\npublished by the M4 organisers after the competition demonstrates that the\ncorrelator was responsible for most of our gains over the naive constant\nforecasting method. We identify data leakage as one reason for its success,\npartly due to test data selected from different time intervals, and partly due\nto quality issues in the original time series. We suggest that future\nforecasting competitions should provide actual dates for the time series so\nthat some of those leakages could be avoided by the participants.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 14:17:05 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:00:48 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Ingel", "Anti", ""], ["Shahroudi", "Novin", ""], ["K\u00e4ngsepp", "Markus", ""], ["T\u00e4ttar", "Andre", ""], ["Komisarenko", "Viacheslav", ""], ["Kull", "Meelis", ""]]}, {"id": "2003.12815", "submitter": "Vihari Piratla Mr.", "authors": "Vihari Piratla, Praneeth Netrapalli, Sunita Sarawagi", "title": "Efficient Domain Generalization via Common-Specific Low-Rank\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization refers to the task of training a model which\ngeneralizes to new domains that are not seen during training. We present CSD\n(Common Specific Decomposition), for this setting,which jointly learns a common\ncomponent (which generalizes to new domains) and a domain specific component\n(which overfits on training domains). The domain specific components are\ndiscarded after training and only the common component is retained. The\nalgorithm is extremely simple and involves only modifying the final linear\nclassification layer of any given neural network architecture. We present a\nprincipled analysis to understand existing approaches, provide identifiability\nresults of CSD,and study effect of low-rank on domain generalization. We show\nthat CSD either matches or beats state of the art approaches for domain\ngeneralization based on domain erasure, domain perturbed data augmentation, and\nmeta-learning. Further diagnostics on rotated MNIST, where domains are\ninterpretable, confirm the hypothesis that CSD successfully disentangles common\nand domain specific components and hence leads to better domain generalization.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 15:17:41 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 04:28:06 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Piratla", "Vihari", ""], ["Netrapalli", "Praneeth", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "2003.12824", "submitter": "Hiroshi Kaizuka", "authors": "Hiroshi Kaizuka", "title": "Gradient-based Data Augmentation for Semi-Supervised Learning", "comments": "The lower bound of the inequality (line 2 on page 6 ) changed to fit\n  fact 1 (2). Typos in (9) corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised learning (SSL), a technique called consistency\nregularization (CR) achieves high performance. It has been proved that the\ndiversity of data used in CR is extremely important to obtain a model with high\ndiscrimination performance by CR. We propose a new data augmentation\n(Gradient-based Data Augmentation (GDA)) that is deterministically calculated\nfrom the image pixel value gradient of the posterior probability distribution\nthat is the model output. We aim to secure effective data diversity for CR by\nutilizing three types of GDA. On the other hand, it has been demonstrated that\nthe mixup method for labeled data and unlabeled data is also effective in SSL.\nWe propose an SSL method named MixGDA by combining various mixup methods and\nGDA. The discrimination performance achieved by MixGDA is evaluated against the\n13-layer CNN that is used as standard in SSL research. As a result, for\nCIFAR-10 (4000 labels), MixGDA achieves the same level of performance as the\nbest performance ever achieved. For SVHN (250 labels, 500 labels and 1000\nlabels) and CIFAR-100 (10000 labels), MixGDA achieves state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 15:57:20 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 01:10:27 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Kaizuka", "Hiroshi", ""]]}, {"id": "2003.12838", "submitter": "Botond Szabo", "authors": "Botond Szabo and Harry van Zanten", "title": "Distributed function estimation: adaptation using minimal communication", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether in a distributed setting, adaptive estimation of a\nsmooth function at the optimal rate is possible under minimal communication. It\nturns out that the answer depends on the risk considered and on the number of\nservers over which the procedure is distributed. We show that for the\n$L_\\infty$-risk, adaptively obtaining optimal rates under minimal communication\nis not possible. For the $L_2$-risk, it is possible over a range of\nregularities that depends on the relation between the number of local servers\nand the total sample size.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 16:44:06 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Szabo", "Botond", ""], ["van Zanten", "Harry", ""]]}, {"id": "2003.12843", "submitter": "Lorenzo Brigato", "authors": "L. Brigato and L. Iocchi", "title": "A Close Look at Deep Learning with Small Data", "comments": "Published at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we perform a wide variety of experiments with different deep\nlearning architectures on datasets of limited size. According to our study, we\nshow that model complexity is a critical factor when only a few samples per\nclass are available. Differently from the literature, we show that in some\nconfigurations, the state of the art can be improved using low complexity\nmodels. For instance, in problems with scarce training samples and without data\naugmentation, low-complexity convolutional neural networks perform comparably\nwell or better than state-of-the-art architectures. Moreover, we show that even\nstandard data augmentation can boost recognition performance by large margins.\nThis result suggests the development of more complex data\ngeneration/augmentation pipelines for cases when data is limited. Finally, we\nshow that dropout, a widely used regularization technique, maintains its role\nas a good regularizer even when data is scarce. Our findings are empirically\nvalidated on the sub-sampled versions of popular CIFAR-10, Fashion-MNIST and,\nSVHN benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 17:11:29 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 10:04:25 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 12:10:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Brigato", "L.", ""], ["Iocchi", "L.", ""]]}, {"id": "2003.12857", "submitter": "Chen Wei", "authors": "Chen Wei, Chuang Niu, Yiping Tang, Yue Wang, Haihong Hu, Jimin Liang", "title": "NPENAS: Neural Predictor Guided Evolution for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is a promising method for automatically\ndesign neural architectures. NAS adopts a search strategy to explore the\npredefined search space to find outstanding performance architecture with the\nminimum searching costs. Bayesian optimization and evolutionary algorithms are\ntwo commonly used search strategies, but they suffer from computationally\nexpensive, challenge to implement or inefficient exploration ability. In this\npaper, we propose a neural predictor guided evolutionary algorithm to enhance\nthe exploration ability of EA for NAS (NPENAS) and design two kinds of neural\npredictors. The first predictor is defined from Bayesian optimization and we\npropose a graph-based uncertainty estimation network as a surrogate model that\nis easy to implement and computationally efficient. The second predictor is a\ngraph-based neural network that directly outputs the performance prediction of\nthe input neural architecture. The NPENAS using the two neural predictors are\ndenoted as NPENAS-BO and NPENAS-NP respectively. In addition, we introduce a\nnew random architecture sampling method to overcome the drawbacks of the\nexisting sampling method. Extensive experiments demonstrate the superiority of\nNPENAS. Quantitative results on three NAS search spaces indicate that both\nNPENAS-BO and NPENAS-NP outperform most existing NAS algorithms, with NPENAS-BO\nachieving state-of-the-art performance on NASBench-201 and NPENAS-NP on\nNASBench-101 and DARTS, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 17:56:31 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 16:32:49 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 06:22:06 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wei", "Chen", ""], ["Niu", "Chuang", ""], ["Tang", "Yiping", ""], ["Wang", "Yue", ""], ["Hu", "Haihong", ""], ["Liang", "Jimin", ""]]}, {"id": "2003.12880", "submitter": "Chen-Yu Wei", "authors": "Alekh Agarwal, John Langford, Chen-Yu Wei", "title": "Federated Residual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new form of federated learning where the clients train\npersonalized local models and make predictions jointly with the server-side\nshared model. Using this new federated learning framework, the complexity of\nthe central shared model can be minimized while still gaining all the\nperformance benefits that joint training provides. Our framework is robust to\ndata heterogeneity, addressing the slow convergence problem traditional\nfederated learning methods face when the data is non-i.i.d. across clients. We\ntest the theory empirically and find substantial performance gains over\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 19:55:24 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Agarwal", "Alekh", ""], ["Langford", "John", ""], ["Wei", "Chen-Yu", ""]]}, {"id": "2003.12881", "submitter": "Marianne Menictas", "authors": "Marianne Menictas, Sabina Tomkins, Susan A Murphy", "title": "Streamlined Empirical Bayes Fitting of Linear Mixed Models in Mobile\n  Health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effect behavior change a successful algorithm must make high-quality\ndecisions in real-time. For example, a mobile health (mHealth) application\ndesigned to increase physical activity must make contextually relevant\nsuggestions to motivate users. While machine learning offers solutions for\ncertain stylized settings, such as when batch data can be processed offline,\nthere is a dearth of approaches which can deliver high-quality solutions under\nthe specific constraints of mHealth. We propose an algorithm which provides\nusers with contextualized and personalized physical activity suggestions. This\nalgorithm is able to overcome a challenge critical to mHealth that complex\nmodels be trained efficiently. We propose a tractable streamlined empirical\nBayes procedure which fits linear mixed effects models in large-data settings.\nOur procedure takes advantage of sparsity introduced by hierarchical random\neffects to efficiently learn the posterior distribution of a linear mixed\neffects model. A key contribution of this work is that we provide explicit\nupdates in order to learn both fixed effects, random effects and\nhyper-parameter values. We demonstrate the success of this approach in a mobile\nhealth (mHealth) reinforcement learning application, a domain in which fast\ncomputations are crucial for real time interventions. Not only is our approach\ncomputationally efficient, it is also easily implemented with closed form\nmatrix algebraic updates and we show improvements over state of the art\napproaches both in speed and accuracy of up to 99% and 56% respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 19:57:55 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Menictas", "Marianne", ""], ["Tomkins", "Sabina", ""], ["Murphy", "Susan A", ""]]}, {"id": "2003.12890", "submitter": "Vojtech Kejzlar", "authors": "Vojtech Kejzlar and Tapabrata Maiti", "title": "Variational Inference with Vine Copulas: An efficient Approach for\n  Bayesian Computer Model Calibration", "comments": "Submitted to the Statistics and Computing Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancements of computer architectures, the use of computational\nmodels proliferates to solve complex problems in many scientific applications\nsuch as nuclear physics and climate research. However, the potential of such\nmodels is often hindered because they tend to be computationally expensive and\nconsequently ill-fitting for uncertainty quantification. Furthermore, they are\nusually not calibrated with real-time observations. We develop a\ncomputationally efficient algorithm based on variational Bayes inference (VBI)\nfor calibration of computer models with Gaussian processes. Unfortunately, the\nspeed and scalability of VBI diminishes when applied to the calibration\nframework with dependent data. To preserve the efficiency of VBI, we adopt a\npairwise decomposition of the data likelihood using vine copulas that separate\nthe information on dependence structure in data from their marginal\ndistributions. We provide both theoretical and empirical evidence for the\ncomputational scalability of our methodology and describe all the necessary\ndetails for an efficient implementation of the proposed algorithm. We also\ndemonstrate the opportunities given by our method for practitioners on a real\ndata example through calibration of the Liquid Drop Model of nuclear binding\nenergies.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 21:05:16 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 02:49:21 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kejzlar", "Vojtech", ""], ["Maiti", "Tapabrata", ""]]}, {"id": "2003.12895", "submitter": "Amit Daniely", "authors": "Amit Daniely", "title": "Memorizing Gaussians with no over-parameterizaion via gradient decent on\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a single step of gradient decent over depth two network, with\n$q$ hidden neurons, starting from orthogonal initialization, can memorize\n$\\Omega\\left(\\frac{dq}{\\log^4(d)}\\right)$ independent and randomly labeled\nGaussians in $\\mathbb{R}^d$. The result is valid for a large class of\nactivation functions, which includes the absolute value.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 21:45:42 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Daniely", "Amit", ""]]}, {"id": "2003.12908", "submitter": "Andrew Warrington", "authors": "Andrew Warrington, Saeid Naderiparizi, Frank Wood", "title": "Coping With Simulators That Don't Always Return", "comments": "AISTATS 2020 camera ready, version 1.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deterministic models are approximations of reality that are easy to interpret\nand often easier to build than stochastic alternatives. Unfortunately, as\nnature is capricious, observational data can never be fully explained by\ndeterministic models in practice. Observation and process noise need to be\nadded to adapt deterministic models to behave stochastically, such that they\nare capable of explaining and extrapolating from noisy data. We investigate and\naddress computational inefficiencies that arise from adding process noise to\ndeterministic simulators that fail to return for certain inputs; a property we\ndescribe as \"brittle.\" We show how to train a conditional normalizing flow to\npropose perturbations such that the simulator succeeds with high probability,\nincreasing computational efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:05:10 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Warrington", "Andrew", ""], ["Naderiparizi", "Saeid", ""], ["Wood", "Frank", ""]]}, {"id": "2003.12909", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, Adish Singla", "title": "Policy Teaching via Environment Poisoning: Training-time Adversarial\n  Attacks against Reinforcement Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a security threat to reinforcement learning where an attacker\npoisons the learning environment to force the agent into executing a target\npolicy chosen by the attacker. As a victim, we consider RL agents whose\nobjective is to find a policy that maximizes average reward in undiscounted\ninfinite-horizon problem settings. The attacker can manipulate the rewards or\nthe transition dynamics in the learning environment at training-time and is\ninterested in doing so in a stealthy manner. We propose an optimization\nframework for finding an \\emph{optimal stealthy attack} for different measures\nof attack cost. We provide sufficient technical conditions under which the\nattack is feasible and provide lower/upper bounds on the attack cost. We\ninstantiate our attacks in two settings: (i) an \\emph{offline} setting where\nthe agent is doing planning in the poisoned environment, and (ii) an\n\\emph{online} setting where the agent is learning a policy using a\nregret-minimization framework with poisoned feedback. Our results show that the\nattacker can easily succeed in teaching any target policy to the victim under\nmild conditions and highlight a significant security threat to reinforcement\nlearning agents in practice.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:22:28 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:07:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Rakhsha", "Amin", ""], ["Radanovic", "Goran", ""], ["Devidze", "Rati", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2003.12935", "submitter": "Liyan Xie", "authors": "Anatoli Juditsky, Arkadi Nemirovski, Liyan Xie, Yao Xie", "title": "Convex Parameter Recovery for Interacting Marked Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new general modeling approach for multivariate discrete event\ndata with categorical interacting marks, which we refer to as marked Bernoulli\nprocesses. In the proposed model, the probability of an event of a specific\ncategory to occur in a location may be influenced by past events at this and\nother locations. We do not restrict interactions to be positive or decaying\nover time as it is commonly adopted, allowing us to capture an arbitrary shape\nof influence from historical events, locations, and events of different\ncategories. In our modeling, prior knowledge is incorporated by allowing\ngeneral convex constraints on model parameters. We develop two parameter\nestimation procedures utilizing the constrained Least Squares (LS) and Maximum\nLikelihood (ML) estimation, which are solved using variational inequalities\nwith monotone operators. We discuss different applications of our approach and\nillustrate the performance of proposed recovery routines on synthetic examples\nand a real-world police dataset.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 03:23:30 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 02:17:32 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 17:53:00 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""], ["Xie", "Liyan", ""], ["Xie", "Yao", ""]]}, {"id": "2003.12968", "submitter": "D. H. S. Maithripala", "authors": "Pathmanathan Pankayaraj, D. H. S. Maithripala, and J. M. Berg", "title": "A Decentralized Policy with Logarithmic Regret for a Class of\n  Multi-Agent Multi-Armed Bandit Problems with Option Unavailability\n  Constraints and Stochastic Communication Protocols", "comments": "Pre-print submitted for review to the 2020 CDC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a multi-armed bandit (MAB) problem in which multiple\nmobile agents receive rewards by sampling from a collection of spatially\ndispersed stochastic processes, called bandits. The goal is to formulate a\ndecentralized policy for each agent, in order to maximize the total cumulative\nreward over all agents, subject to option availability and inter-agent\ncommunication constraints. The problem formulation is motivated by applications\nin which a team of autonomous mobile robots cooperates to accomplish an\nexploration and exploitation task in an uncertain environment. Bandit locations\nare represented by vertices of the spatial graph. At any time, an agent's\noption consist of sampling the bandit at its current location, or traveling\nalong an edge of the spatial graph to a new bandit location. Communication\nconstraints are described by a directed, non-stationary, stochastic\ncommunication graph. At any time, agents may receive data only from their\ncommunication graph in-neighbors. For the case of a single agent on a fully\nconnected spatial graph, it is known that the expected regret for any optimal\npolicy is necessarily bounded below by a function that grows as the logarithm\nof time. A class of policies called upper confidence bound (UCB) algorithms\nasymptotically achieve logarithmic regret for the classical MAB problem. In\nthis paper, we propose a UCB-based decentralized motion and option selection\npolicy and a non-stationary stochastic communication protocol that guarantee\nlogarithmic regret. To our knowledge, this is the first such decentralized\npolicy for non-fully connected spatial graphs with communication constraints.\nWhen the spatial graph is fully connected and the communication graph is\nstationary, our decentralized algorithm matches or exceeds the best reported\nprior results from the literature.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 08:12:49 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 04:29:22 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Pankayaraj", "Pathmanathan", ""], ["Maithripala", "D. H. S.", ""], ["Berg", "J. M.", ""]]}, {"id": "2003.12970", "submitter": "Pengcheng Zeng", "authors": "Pengcheng Zeng and Zhixiang Lin", "title": "Elastic Coupled Co-clustering for Single-Cell Genomic Data", "comments": "18 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent advances in single-cell technologies have enabled us to profile\ngenomic features at unprecedented resolution and datasets from multiple domains\nare available, including datasets that profile different types of genomic\nfeatures and datasets that profile the same type of genomic features across\ndifferent species. These datasets typically have different powers in\nidentifying the unknown cell types through clustering, and data integration can\npotentially lead to a better performance of clustering algorithms. In this\nwork, we formulate the problem in an unsupervised transfer learning framework,\nwhich utilizes knowledge learned from auxiliary dataset to improve the\nclustering performance of target dataset. The degree of shared information\namong the target and auxiliary datasets can vary, and their distributions can\nalso be different. To address these challenges, we propose an elastic coupled\nco-clustering based transfer learning algorithm, by elastically propagating\nclustering knowledge obtained from the auxiliary dataset to the target dataset.\nImplementation on single-cell genomic datasets shows that our algorithm greatly\nimproves clustering performance over the traditional learning algorithms. The\nsource code and data sets are available at\nhttps://github.com/cuhklinlab/elasticC3.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 08:21:53 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 03:28:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zeng", "Pengcheng", ""], ["Lin", "Zhixiang", ""]]}, {"id": "2003.12985", "submitter": "Bihan Wen Dr", "authors": "Bihan Wen, Yanjun Li, Yuqi Li, and Yoram Bresler", "title": "A Set-Theoretic Study of the Relationships of Image Models and Priors\n  for Restoration Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image prior modeling is the key issue in image recovery, computational\nimaging, compresses sensing, and other inverse problems. Recent algorithms\ncombining multiple effective priors such as the sparse or low-rank models, have\ndemonstrated superior performance in various applications. However, the\nrelationships among the popular image models are unclear, and no theory in\ngeneral is available to demonstrate their connections. In this paper, we\npresent a theoretical analysis on the image models, to bridge the gap between\napplications and image prior understanding, including sparsity, group-wise\nsparsity, joint sparsity, and low-rankness, etc. We systematically study how\neffective each image model is for image restoration. Furthermore, we relate the\ndenoising performance improvement by combining multiple models, to the image\nmodel relationships. Extensive experiments are conducted to compare the\ndenoising results which are consistent with our analysis. On top of the\nmodel-based methods, we quantitatively demonstrate the image properties that\nare inexplicitly exploited by deep learning method, of which can further boost\nthe denoising performance by combining with its complementary image models.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 09:33:47 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wen", "Bihan", ""], ["Li", "Yanjun", ""], ["Li", "Yuqi", ""], ["Bresler", "Yoram", ""]]}, {"id": "2003.12990", "submitter": "Baoxiang Wang", "authors": "Andrej Bogdanov and Baoxiang Wang", "title": "Learning and Testing Variable Partitions", "comments": "Innovations in Theoretical Computer Science (ITCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $ $Let $F$ be a multivariate function from a product set $\\Sigma^n$ to an\nAbelian group $G$. A $k$-partition of $F$ with cost $\\delta$ is a partition of\nthe set of variables $\\mathbf{V}$ into $k$ non-empty subsets $(\\mathbf{X}_1,\n\\dots, \\mathbf{X}_k)$ such that $F(\\mathbf{V})$ is $\\delta$-close to\n$F_1(\\mathbf{X}_1)+\\dots+F_k(\\mathbf{X}_k)$ for some $F_1, \\dots, F_k$ with\nrespect to a given error metric. We study algorithms for agnostically learning\n$k$ partitions and testing $k$-partitionability over various groups and error\nmetrics given query access to $F$. In particular we show that\n  $1.$ Given a function that has a $k$-partition of cost $\\delta$, a partition\nof cost $\\mathcal{O}(k n^2)(\\delta + \\epsilon)$ can be learned in time\n$\\tilde{\\mathcal{O}}(n^2 \\mathrm{poly} (1/\\epsilon))$ for any $\\epsilon > 0$.\nIn contrast, for $k = 2$ and $n = 3$ learning a partition of cost $\\delta +\n\\epsilon$ is NP-hard.\n  $2.$ When $F$ is real-valued and the error metric is the 2-norm, a\n2-partition of cost $\\sqrt{\\delta^2 + \\epsilon}$ can be learned in time\n$\\tilde{\\mathcal{O}}(n^5/\\epsilon^2)$.\n  $3.$ When $F$ is $\\mathbb{Z}_q$-valued and the error metric is Hamming\nweight, $k$-partitionability is testable with one-sided error and\n$\\mathcal{O}(kn^3/\\epsilon)$ non-adaptive queries. We also show that even\ntwo-sided testers require $\\Omega(n)$ queries when $k = 2$.\n  This work was motivated by reinforcement learning control tasks in which the\nset of control variables can be partitioned. The partitioning reduces the task\ninto multiple lower-dimensional ones that are relatively easier to learn. Our\nsecond algorithm empirically increases the scores attained over previous\nheuristic partitioning methods applied in this context.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 10:12:32 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bogdanov", "Andrej", ""], ["Wang", "Baoxiang", ""]]}, {"id": "2003.13021", "submitter": "Witold Dzwinel Prof. dr", "authors": "Ludwik Bukowski, Witold Dzwinel", "title": "SuperNet -- An efficient method of neural networks ensembling", "comments": "This is MSc thesis of Ludwik Bukowski, defended at AGH University of\n  Science and Technology, WIET, Department of Computer Science, September 2019\n  consists of 42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main flaw of neural network ensembling is that it is exceptionally\ndemanding computationally, especially, if the individual sub-models are large\nneural networks, which must be trained separately. Having in mind that modern\nDNNs can be very accurate, they are already the huge ensembles of simple\nclassifiers, and that one can construct more thrifty compressed neural net of a\nsimilar performance for any ensemble, the idea of designing the expensive\nSuperNets can be questionable. The widespread belief that ensembling increases\nthe prediction time, makes it not attractive and can be the reason that the\nmain stream of ML research is directed towards developing better loss functions\nand learning strategies for more advanced and efficient neural networks. On the\nother hand, all these factors make the architectures more complex what may lead\nto overfitting and high computational complexity, that is, to the same flaws\nfor which the highly parametrized SuperNets ensembles are blamed. The goal of\nthe master thesis is to speed up the execution time required for ensemble\ngeneration. Instead of training K inaccurate sub-models, each of them can\nrepresent various phases of training (representing various local minima of the\nloss function) of a single DNN [Huang et al., 2017; Gripov et al., 2018]. Thus,\nthe computational performance of the SuperNet can be comparable to the maximum\nCPU time spent on training its single sub-model, plus usually much shorter CPU\ntime required for training the SuperNet coupling factors.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 13:47:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bukowski", "Ludwik", ""], ["Dzwinel", "Witold", ""]]}, {"id": "2003.13058", "submitter": "Alireza M. Javid", "authors": "Alireza M. Javid, Arun Venkitaraman, Mikael Skoglund, and Saikat\n  Chatterjee", "title": "High-dimensional Neural Feature Design for Layer-wise Reduction of\n  Training Cost", "comments": "2020 EURASIP Journal on Advances in Signal Processing", "journal-ref": null, "doi": "10.1186/s13634-020-00695-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a ReLU-based multilayer neural network by mapping the feature\nvectors to a higher dimensional space in every layer. We design the weight\nmatrices in every layer to ensure a reduction of the training cost as the\nnumber of layers increases. Linear projection to the target in the higher\ndimensional space leads to a lower training cost if a convex cost is minimized.\nAn $\\ell_2$-norm convex constraint is used in the minimization to reduce the\ngeneralization error and avoid overfitting. The regularization hyperparameters\nof the network are derived analytically to guarantee a monotonic decrement of\nthe training cost, and therefore, it eliminates the need for cross-validation\nto find the regularization hyperparameter in each layer. We show that the\nproposed architecture is norm-preserving and provides an invertible feature\nvector, and therefore, can be used to reduce the training cost of any other\nlearning method which employs linear projection to estimate the target.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 15:57:28 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 21:16:00 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Javid", "Alireza M.", ""], ["Venkitaraman", "Arun", ""], ["Skoglund", "Mikael", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2003.13070", "submitter": "Robin Hirt", "authors": "Robin Hirt, Akash Srivastava, Carlos Berg and Niklas K\\\"uhl", "title": "Sequential Transfer Machine Learning in Networks: Measuring the Impact\n  of Data and Neural Net Similarity on Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In networks of independent entities that face similar predictive tasks,\ntransfer machine learning enables to re-use and improve neural nets using\ndistributed data sets without the exposure of raw data. As the number of data\nsets in business networks grows and not every neural net transfer is\nsuccessful, indicators are needed for its impact on the target performance-its\ntransferability. We perform an empirical study on a unique real-world use case\ncomprised of sales data from six different restaurants. We train and transfer\nneural nets across these restaurant sales data and measure their\ntransferability. Moreover, we calculate potential indicators for\ntransferability based on divergences of data, data projections and a novel\nmetric for neural net similarity. We obtain significant negative correlations\nbetween the transferability and the tested indicators. Our findings allow to\nchoose the transfer path based on these indicators, which improves model\nperformance whilst simultaneously requiring fewer model transfers.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 16:41:15 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hirt", "Robin", ""], ["Srivastava", "Akash", ""], ["Berg", "Carlos", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2003.13074", "submitter": "Shafie Gholizadeh", "authors": "Shafie Gholizadeh, Armin Seyeditabari and Wlodek Zadrozny", "title": "A Novel Method of Extracting Topological Features from Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, topological data analysis has been utilized for a wide range\nof problems to deal with high dimensional noisy data. While text\nrepresentations are often high dimensional and noisy, there are only a few work\non the application of topological data analysis in natural language processing.\nIn this paper, we introduce a novel algorithm to extract topological features\nfrom word embedding representation of text that can be used for text\nclassification. Working on word embeddings, topological data analysis can\ninterpret the embedding high-dimensional space and discover the relations among\ndifferent embedding dimensions. We will use persistent homology, the most\ncommonly tool from topological data analysis, for our experiment. Examining our\ntopological algorithm on long textual documents, we will show our defined\ntopological features may outperform conventional text mining features.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 16:55:23 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 21:56:57 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gholizadeh", "Shafie", ""], ["Seyeditabari", "Armin", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "2003.13090", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Are Direct Links Necessary in RVFL NNs for Regression?", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random vector functional link network (RVFL) is widely used as a universal\napproximator for classification and regression problems. The big advantage of\nRVFL is fast training without backpropagation. This is because the weights and\nbiases of hidden nodes are selected randomly and stay untrained. Recently,\nalternative architectures with randomized learning are developed which differ\nfrom RVFL in that they have no direct links and a bias term in the output\nlayer. In this study, we investigate the effect of direct links and output node\nbias on the regression performance of RVFL. For generating random parameters of\nhidden nodes we use the classical method and two new methods recently proposed\nin the literature. We test the RVFL performance on several function\napproximation problems with target functions of different nature: nonlinear,\nnonlinear with strong fluctuations, nonlinear with linear component and linear.\nSurprisingly, we found that the direct links and output node bias do not play\nan important role in improving RVFL accuracy for typical nonlinear regression\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 17:55:35 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2003.13096", "submitter": "Jong Chul Ye", "authors": "Eunju Cha, Hyungjin Chung, Eung Yeop Kim, and Jong Chul Ye", "title": "Unsupervised Deep Learning for MR Angiography with Flexible Temporal\n  Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-resolved MR angiography (tMRA) has been widely used for dynamic contrast\nenhanced MRI (DCE-MRI) due to its highly accelerated acquisition. In tMRA, the\nperiphery of the k-space data are sparsely sampled so that neighbouring frames\ncan be merged to construct one temporal frame. However, this view-sharing\nscheme fundamentally limits the temporal resolution, and it is not possible to\nchange the view-sharing number to achieve different spatio-temporal resolution\ntrade-off. Although many deep learning approaches have been recently proposed\nfor MR reconstruction from sparse samples, the existing approaches usually\nrequire matched fully sampled k-space reference data for supervised training,\nwhich is not suitable for tMRA. This is because high spatio-temporal resolution\nground-truth images are not available for tMRA. To address this problem, here\nwe propose a novel unsupervised deep learning using optimal transport driven\ncycle-consistent generative adversarial network (cycleGAN). In contrast to the\nconventional cycleGAN with two pairs of generator and discriminator, the new\narchitecture requires just a single pair of generator and discriminator, which\nmakes the training much simpler and improves the performance. Reconstruction\nresults using in vivo tMRA data set confirm that the proposed method can\nimmediately generate high quality reconstruction results at various choices of\nview-sharing numbers, allowing us to exploit better trade-off between spatial\nand temporal resolution in time-resolved MR angiography.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 18:08:59 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Cha", "Eunju", ""], ["Chung", "Hyungjin", ""], ["Kim", "Eung Yeop", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2003.13135", "submitter": "Jonathan Young", "authors": "Jonathan D. Young, Bryan Andrews, Gregory F. Cooper, Xinghua Lu", "title": "Learning Latent Causal Structures with a Redundant Input Neural Network", "comments": "Proceedings of the 2020 KDD Workshop on Causal Discovery, in\n  Proceedings of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most causal discovery algorithms find causal structure among a set of\nobserved variables. Learning the causal structure among latent variables\nremains an important open problem, particularly when using high-dimensional\ndata. In this paper, we address a problem for which it is known that inputs\ncause outputs, and these causal relationships are encoded by a causal network\namong a set of an unknown number of latent variables. We developed a deep\nlearning model, which we call a redundant input neural network (RINN), with a\nmodified architecture and a regularized objective function to find causal\nrelationships between input, hidden, and output variables. More specifically,\nour model allows input variables to directly interact with all latent variables\nin a neural network to influence what information the latent variables should\nencode in order to generate the output variables accurately. In this setting,\nthe direct connections between input and latent variables makes the latent\nvariables partially interpretable; furthermore, the connectivity among the\nlatent variables in the neural network serves to model their potential causal\nrelationships to each other and to the output variables. A series of simulation\nexperiments provide support that the RINN method can successfully recover\nlatent causal structure between input and output variables.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:52:35 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:01:50 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 16:31:51 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Young", "Jonathan D.", ""], ["Andrews", "Bryan", ""], ["Cooper", "Gregory F.", ""], ["Lu", "Xinghua", ""]]}, {"id": "2003.13138", "submitter": "Shafie Gholizadeh", "authors": "Shafie Gholizadeh, Ketki Savle, Armin Seyeditabari and Wlodek Zadrozny", "title": "Topological Data Analysis in Text Classification: Extracting Features\n  with Additive Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the strength of Topological Data Analysis has been explored in many\nstudies on high dimensional numeric data, it is still a challenging task to\napply it to text. As the primary goal in topological data analysis is to define\nand quantify the shapes in numeric data, defining shapes in the text is much\nmore challenging, even though the geometries of vector spaces and conceptual\nspaces are clearly relevant for information retrieval and semantics. In this\npaper, we examine two different methods of extraction of topological features\nfrom text, using as the underlying representations of words the two most\npopular methods, namely word embeddings and TF-IDF vectors. To extract\ntopological features from the word embedding space, we interpret the embedding\nof a text document as high dimensional time series, and we analyze the topology\nof the underlying graph where the vertices correspond to different embedding\ndimensions. For topological data analysis with the TF-IDF representations, we\nanalyze the topology of the graph whose vertices come from the TF-IDF vectors\nof different blocks in the textual document. In both cases, we apply\nhomological persistence to reveal the geometric structures under different\ndistance resolutions. Our results show that these topological features carry\nsome exclusive information that is not captured by conventional text mining\nmethods. In our experiments we observe adding topological features to the\nconventional features in ensemble models improves the classification results\n(up to 5\\%). On the other hand, as expected, topological features by themselves\nmay be not sufficient for effective classification. It is an open problem to\nsee whether TDA features from word embeddings might be sufficient, as they seem\nto perform within a range of few points from top results obtained with a linear\nsupport vector classifier.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 21:02:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Gholizadeh", "Shafie", ""], ["Savle", "Ketki", ""], ["Seyeditabari", "Armin", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "2003.13153", "submitter": "Ji Chen", "authors": "Ji Chen, Xiaodong Li, Zongming Ma", "title": "Nonconvex Matrix Completion with Linearly Parameterized Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques of matrix completion aim to impute a large portion of missing\nentries in a data matrix through a small portion of observed ones, with broad\nmachine learning applications including collaborative filtering, pairwise\nranking, etc. In practice, additional structures are usually employed in order\nto improve the accuracy of matrix completion. Examples include subspace\nconstraints formed by side information in collaborative filtering, and skew\nsymmetry in pairwise ranking. This paper performs a unified analysis of\nnonconvex matrix completion with linearly parameterized factorization, which\ncovers the aforementioned examples as special cases. Importantly, uniform upper\nbounds for estimation errors are established for all local minima, provided\nthat the sampling rate satisfies certain conditions determined by the rank,\ncondition number, and incoherence parameter of the ground-truth low rank\nmatrix. Empirical efficiency of the proposed method is further illustrated by\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 22:40:47 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Chen", "Ji", ""], ["Li", "Xiaodong", ""], ["Ma", "Zongming", ""]]}, {"id": "2003.13161", "submitter": "Mei Dong", "authors": "Konstantin Shestopaloff, Mei Dong, Fan Gao, Wei Xu", "title": "DCMD: Distance-based Classification Using Mixture Distributions on\n  Microbiome Data", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1008799", "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in next generation sequencing techniques have allowed\nresearchers to conduct comprehensive research on microbiome and human diseases,\nwith recent studies identifying associations between human microbiome and\nhealth outcomes for a number of chronic conditions. However, microbiome data\nstructure, characterized by sparsity and skewness, presents challenges to\nbuilding effective classifiers. To address this, we present an innovative\napproach for distance-based classification using mixture distributions (DCMD).\nThe method aims to improve classification performance when using microbiome\ncommunity data, where the predictors are composed of sparse and heterogeneous\ncount data. This approach models the inherent uncertainty in sparse counts by\nestimating a mixture distribution for the sample data, and representing each\nobservation as a distribution, conditional on observed counts and the estimated\nmixture, which are then used as inputs for distance-based classification. The\nmethod is implemented into a k-means and k-nearest neighbours framework and we\nidentify two distance metrics that produce optimal results. The performance of\nthe model is assessed using simulations and applied to a human microbiome\nstudy, with results compared against a number of existing machine learning and\ndistance-based approaches. The proposed method is competitive when compared to\nthe machine learning approaches and showed a clear improvement over commonly\nused distance-based classifiers. The range of applicability and robustness make\nthe proposed method a viable alternative for classification using sparse\nmicrobiome count data.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 23:30:20 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Shestopaloff", "Konstantin", ""], ["Dong", "Mei", ""], ["Gao", "Fan", ""], ["Xu", "Wei", ""]]}, {"id": "2003.13212", "submitter": "Shixun Huang", "authors": "Shixun Huang, Zhifeng Bao, Guoliang Li, Yanghao Zhou, J.Shane\n  Culpepper", "title": "Temporal Network Representation Learning via Historical Neighborhoods\n  Aggregation", "comments": "28 Pages, published in 2020 IEEE International Conference on Data\n  Engineering (ICDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is an effective method to learn low-dimensional\nrepresentations of nodes, which can be applied to various real-life\napplications such as visualization, node classification, and link prediction.\nAlthough significant progress has been made on this problem in recent years,\nseveral important challenges remain, such as how to properly capture temporal\ninformation in evolving networks. In practice, most networks are continually\nevolving. Some networks only add new edges or nodes such as authorship\nnetworks, while others support removal of nodes or edges such as internet data\nrouting. If patterns exist in the changes of the network structure, we can\nbetter understand the relationships between nodes and the evolution of the\nnetwork, which can be further leveraged to learn node representations with more\nmeaningful information. In this paper, we propose the Embedding via Historical\nNeighborhoods Aggregation (EHNA) algorithm. More specifically, we first propose\na temporal random walk that can identify relevant nodes in historical\nneighborhoods which have impact on edge formations. Then we apply a deep\nlearning model which uses a custom attention mechanism to induce node\nembeddings that directly capture temporal information in the underlying feature\nrepresentation. We perform extensive experiments on a range of real-world\ndatasets, and the results demonstrate the effectiveness of our new approach in\nthe network reconstruction task and the link prediction task.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 04:18:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Huang", "Shixun", ""], ["Bao", "Zhifeng", ""], ["Li", "Guoliang", ""], ["Zhou", "Yanghao", ""], ["Culpepper", "J. Shane", ""]]}, {"id": "2003.13221", "submitter": "Andrew Warrington", "authors": "Frank Wood, Andrew Warrington, Saeid Naderiparizi, Christian Weilbach,\n  Vaden Masrani, William Harvey, Adam Scibior, Boyan Beronov, and Ali Nasseri", "title": "Planning as Inference in Epidemiological Models", "comments": "minor typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we demonstrate how existing software tools can be used to\nautomate parts of infectious disease-control policy-making via performing\ninference in existing epidemiological dynamics models. The kind of inference\ntasks undertaken include computing, for planning purposes, the posterior\ndistribution over putatively controllable, via direct policy-making choices,\nsimulation model parameters that give rise to acceptable disease progression\noutcomes. Neither the full capabilities of such inference automation software\ntools nor their utility for planning is widely disseminated at the current\ntime. Timely gains in understanding about these tools and how they can be used\nmay lead to more fine-grained and less economically damaging policy\nprescriptions, particularly during the current COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 05:10:26 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 02:17:11 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wood", "Frank", ""], ["Warrington", "Andrew", ""], ["Naderiparizi", "Saeid", ""], ["Weilbach", "Christian", ""], ["Masrani", "Vaden", ""], ["Harvey", "William", ""], ["Scibior", "Adam", ""], ["Beronov", "Boyan", ""], ["Nasseri", "Ali", ""]]}, {"id": "2003.13225", "submitter": "Mitchell Woodbright", "authors": "Mitchell D. Woodbright, Md Anisur Rahman, Md Zahidul Islam", "title": "A Novel Incremental Clustering Technique with Concept Drift Detection", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data are being collected from various aspects of life. These data can often\narrive in chunks/batches. Traditional static clustering algorithms are not\nsuitable for dynamic datasets, i.e., when data arrive in streams of\nchunks/batches. If we apply a conventional clustering technique over the\ncombined dataset, then every time a new batch of data comes, the process can be\nslow and wasteful. Moreover, it can be challenging to store the combined\ndataset in memory due to its ever-increasing size. As a result, various\nincremental clustering techniques have been proposed. These techniques need to\nefficiently update the current clustering result whenever a new batch arrives,\nto adapt the current clustering result/solution with the latest data. These\ntechniques also need the ability to detect concept drifts when the clustering\npattern of a new batch is significantly different from older batches.\nSometimes, clustering patterns may drift temporarily in a single batch while\nthe next batches do not exhibit the drift. Therefore, incremental clustering\ntechniques need the ability to detect a temporary drift and sustained drift. In\nthis paper, we propose an efficient incremental clustering algorithm called\nUIClust. It is designed to cluster streams of data chunks, even when there are\ntemporary or sustained concept drifts. We evaluate the performance of UIClust\nby comparing it with a recently published, high-quality incremental clustering\nalgorithm. We use real and synthetic datasets. We compare the results by using\nwell-known clustering evaluation criteria: entropy, sum of squared errors\n(SSE), and execution time. Our results show that UIClust outperforms the\nexisting technique in all our experiments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 05:20:35 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Woodbright", "Mitchell D.", ""], ["Rahman", "Md Anisur", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "2003.13226", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh N Mhaskar", "title": "Kernel based analysis of massive data", "comments": "Accepted for publication in Frontiers in Applied Mathematics and\n  Statistics, section Mathematics of Computation and Data Science. Special\n  issue on Fundamental Mathematical Topics in Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with massive data is a challenging task for machine learning. An\nimportant aspect of machine learning is function approximation. In the context\nof massive data, some of the commonly used tools for this purpose are sparsity,\ndivide-and-conquer, and distributed learning. In this paper, we develop a very\ngeneral theory of approximation by networks, which we have called eignets, to\nachieve local, stratified approximation. The very massive nature of the data\nallows us to use these eignets to solve inverse problems such as finding a good\napproximation to the probability law that governs the data, and finding the\nlocal smoothness of the target function near different points in the domain. In\nfact, we develop a wavelet-like representation using our eignets. Our theory is\napplicable to approximation on a general locally compact metric measure space.\nSpecial examples include approximation by periodic basis functions on the\ntorus, zonal function networks on a Euclidean sphere (including smooth ReLU\nnetworks), Gaussian networks, and approximation on manifolds. We construct\npre-fabricated networks so that no data-based training is required for the\napproximation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 05:25:09 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 05:33:34 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Mhaskar", "Hrushikesh N", ""]]}, {"id": "2003.13249", "submitter": "Jianfei Yang", "authors": "Jianfei Yang, Han Zou, Yuxun Zhou, Lihua Xie", "title": "Towards Stable and Comprehensive Domain Alignment: Max-Margin\n  Domain-Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation tackles the problem of transferring knowledge from a\nlabel-rich source domain to a label-scarce or even unlabeled target domain.\nRecently domain-adversarial training (DAT) has shown promising capacity to\nlearn a domain-invariant feature space by reversing the gradient propagation of\na domain classifier. However, DAT is still vulnerable in several aspects\nincluding (1) training instability due to the overwhelming discriminative\nability of the domain classifier in adversarial training, (2) restrictive\nfeature-level alignment, and (3) lack of interpretability or systematic\nexplanation of the learned feature space. In this paper, we propose a novel\nMax-margin Domain-Adversarial Training (MDAT) by designing an Adversarial\nReconstruction Network (ARN). The proposed MDAT stabilizes the gradient\nreversing in ARN by replacing the domain classifier with a reconstruction\nnetwork, and in this manner ARN conducts both feature-level and pixel-level\ndomain alignment without involving extra network structures. Furthermore, ARN\ndemonstrates strong robustness to a wide range of hyper-parameters settings,\ngreatly alleviating the task of model selection. Extensive empirical results\nvalidate that our approach outperforms other state-of-the-art domain alignment\nmethods. Moreover, reconstructing adapted features reveals the domain-invariant\nfeature space which conforms with our intuition.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 07:48:52 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Yang", "Jianfei", ""], ["Zou", "Han", ""], ["Zhou", "Yuxun", ""], ["Xie", "Lihua", ""]]}, {"id": "2003.13299", "submitter": "Shuichi Kawano", "authors": "Shengyi Wu, Kaito Shimamura, Kohei Yoshikawa, Kazuaki Murayama,\n  Shuichi Kawano", "title": "Variable fusion for Bayesian linear regression via spike-and-slab priors", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear regression models, fusion of coefficients is used to identify\npredictors having similar relationships with a response. This is called\nvariable fusion. This paper presents a novel variable fusion method in terms of\nBayesian linear regression models. We focus on hierarchical Bayesian models\nbased on a spike-and-slab prior approach. A spike-and-slab prior is tailored to\nperform variable fusion. To obtain estimates of the parameters, we develop a\nGibbs sampler for the parameters. Simulation studies and a real data analysis\nshow that our proposed method achieves better performance than previous\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 09:38:00 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 10:12:59 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 09:06:39 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Wu", "Shengyi", ""], ["Shimamura", "Kaito", ""], ["Yoshikawa", "Kohei", ""], ["Murayama", "Kazuaki", ""], ["Kawano", "Shuichi", ""]]}, {"id": "2003.13300", "submitter": "Adrian-Catalin Florea", "authors": "Razvan Andonie, Adrian-Catalin Florea", "title": "Weighted Random Search for CNN Hyperparameter Optimization", "comments": "11 pages, 2 figurs, journal article", "journal-ref": "International Journal of Computers Communications & Control, Vol\n  15, Nr 2, 2020", "doi": "10.15837/ijccc.2020.2.3868", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all model algorithms used in machine learning use two different sets\nof parameters: the training parameters and the meta-parameters\n(hyperparameters). While the training parameters are learned during the\ntraining phase, the values of the hyperparameters have to be specified before\nlearning starts. For a given dataset, we would like to find the optimal\ncombination of hyperparameter values, in a reasonable amount of time. This is a\nchallenging task because of its computational complexity. In previous work\n[11], we introduced the Weighted Random Search (WRS) method, a combination of\nRandom Search (RS) and probabilistic greedy heuristic. In the current paper, we\ncompare the WRS method with several state-of-the art hyperparameter\noptimization methods with respect to Convolutional Neural Network (CNN)\nhyperparameter optimization. The criterion is the classification accuracy\nachieved within the same number of tested combinations of hyperparameter\nvalues. According to our experiments, the WRS algorithm outperforms the other\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 09:40:14 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Andonie", "Razvan", ""], ["Florea", "Adrian-Catalin", ""]]}, {"id": "2003.13304", "submitter": "Jannis Walk", "authors": "Jannis Walk, Robin Hirt, Niklas K\\\"uhl and Erik R. Hersl{\\o}v", "title": "Half-empty or half-full? A Hybrid Approach to Predict Recycling Behavior\n  of Consumers to Increase Reverse Vending Machine Uptime", "comments": "Exploring Service Science : 10th International Conference on\n  Exploring Service Science, IESS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reverse Vending Machines (RVMs) are a proven instrument for facilitating\nclosed-loop plastic packaging recycling. A good customer experience at the RVM\nis crucial for a further proliferation of this technology. Bin full events are\nthe major reason for Reverse Vending Machine (RVM) downtime at the world leader\nin the RVM market. The paper at hand develops and evaluates an approach based\non machine learning and statistical approximation to foresee bin full events\nand, thus increase uptime of RVMs. Our approach relies on forecasting the\nhourly time series of returned beverage containers at a given RVM. We\ncontribute by developing and evaluating an approach for hourly forecasts in a\nretail setting - this combination of application domain and forecast\ngranularity is novel. A trace-driven simulation confirms that the\nforecasting-based approach leads to less downtime and costs than naive emptying\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 09:48:53 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Walk", "Jannis", ""], ["Hirt", "Robin", ""], ["K\u00fchl", "Niklas", ""], ["Hersl\u00f8v", "Erik R.", ""]]}, {"id": "2003.13321", "submitter": "Mohammadfarid Azampour", "authors": "Hannes Hase, Mohammad Farid Azampour, Maria Tirindelli, Magdalini\n  Paschali, Walter Simson, Emad Fatemizadeh and Nassir Navab", "title": "Ultrasound-Guided Robotic Navigation with Deep Reinforcement Learning", "comments": "Submitted for IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the first reinforcement learning (RL) based\nrobotic navigation method which utilizes ultrasound (US) images as an input.\nOur approach combines state-of-the-art RL techniques, specifically deep\nQ-networks (DQN) with memory buffers and a binary classifier for deciding when\nto terminate the task.\n  Our method is trained and evaluated on an in-house collected data-set of 34\nvolunteers and when compared to pure RL and supervised learning (SL)\ntechniques, it performs substantially better, which highlights the suitability\nof RL navigation for US-guided procedures. When testing our proposed model, we\nobtained a 82.91% chance of navigating correctly to the sacrum from 165\ndifferent starting positions on 5 different unseen simulated environments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:13:23 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 06:37:13 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Hase", "Hannes", ""], ["Azampour", "Mohammad Farid", ""], ["Tirindelli", "Maria", ""], ["Paschali", "Magdalini", ""], ["Simson", "Walter", ""], ["Fatemizadeh", "Emad", ""], ["Navab", "Nassir", ""]]}, {"id": "2003.13323", "submitter": "Leif Erik Andersson", "authors": "Leif Erik Andersson, Bart Doekemeijer, Daan van der Hoek, Jan-Willem\n  van Wingerden, Lars Imsland", "title": "Adaptation of Engineering Wake Models using Gaussian Process Regression\n  and High-Fidelity Simulation Data", "comments": "Initial submission to the Science of Making Torque from Wind (TORQUE)\n  2020 conference, 10 pages, 6 figures (16/6)", "journal-ref": null, "doi": "10.1088/1742-6596/1618/2/022043", "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the optimization of yaw control inputs of a\nnine-turbine wind farm. The wind farm is simulated using the high-fidelity\nsimulator SOWFA. The optimization is performed with a modifier adaptation\nscheme based on Gaussian processes. Modifier adaptation corrects for the\nmismatch between plant and model and helps to converge to the actual plan\noptimum. In the case study the modifier adaptation approach is compared with\nthe Bayesian optimization approach. Moreover, the use of two different\ncovariance functions in the Gaussian process regression is discussed. Practical\nrecommendations concerning the data preparation and application of the approach\nare given. It is shown that both the modifier adaptation and the Bayesian\noptimization approach can improve the power production with overall smaller yaw\nmisalignments in comparison to the Gaussian wake model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:22:57 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Andersson", "Leif Erik", ""], ["Doekemeijer", "Bart", ""], ["van der Hoek", "Daan", ""], ["van Wingerden", "Jan-Willem", ""], ["Imsland", "Lars", ""]]}, {"id": "2003.13326", "submitter": "Amir Hertz", "authors": "Amir Hertz, Rana Hanocka, Raja Giryes, Daniel Cohen-Or", "title": "PointGMM: a Neural GMM Network for Point Clouds", "comments": "CVPR 2020 -- final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds are a popular representation for 3D shapes. However, they encode\na particular sampling without accounting for shape priors or non-local\ninformation. We advocate for the use of a hierarchical Gaussian mixture model\n(hGMM), which is a compact, adaptive and lightweight representation that\nprobabilistically defines the underlying 3D surface. We present PointGMM, a\nneural network that learns to generate hGMMs which are characteristic of the\nshape class, and also coincide with the input point cloud. PointGMM is trained\nover a collection of shapes to learn a class-specific prior. The hierarchical\nrepresentation has two main advantages: (i) coarse-to-fine learning, which\navoids converging to poor local-minima; and (ii) (an unsupervised) consistent\npartitioning of the input shape. We show that as a generative model, PointGMM\nlearns a meaningful latent space which enables generating consistent\ninterpolations between existing shapes, as well as synthesizing novel shapes.\nWe also present a novel framework for rigid registration using PointGMM, that\nlearns to disentangle orientation from structure of an input shape.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:34:59 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hertz", "Amir", ""], ["Hanocka", "Rana", ""], ["Giryes", "Raja", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2003.13332", "submitter": "Paul Irofti", "authors": "Andrei Patrascu, Ciprian Paduraru, Paul Irofti", "title": "Stochastic Proximal Gradient Algorithm with Minibatches. Application to\n  Large Scale Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization lies at the core of most statistical learning models.\nThe recent great development of stochastic algorithmic tools focused\nsignificantly onto proximal gradient iterations, in order to find an efficient\napproach for nonsmooth (composite) population risk functions. The complexity of\nfinding optimal predictors by minimizing regularized risk is largely understood\nfor simple regularizations such as $\\ell_1/\\ell_2$ norms. However, more complex\nproperties desired for the predictor necessitates highly difficult regularizers\nas used in grouped lasso or graph trend filtering. In this chapter we develop\nand analyze minibatch variants of stochastic proximal gradient algorithm for\ngeneral composite objective functions with stochastic nonsmooth components. We\nprovide iteration complexity for constant and variable stepsize policies\nobtaining that, for minibatch size $N$, after\n$\\mathcal{O}(\\frac{1}{N\\epsilon})$ iterations $\\epsilon-$suboptimality is\nattained in expected quadratic distance to optimal solution. The numerical\ntests on $\\ell_2-$regularized SVMs and parametric sparse representation\nproblems confirm the theoretical behaviour and surpasses minibatch SGD\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:43:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Patrascu", "Andrei", ""], ["Paduraru", "Ciprian", ""], ["Irofti", "Paul", ""]]}, {"id": "2003.13339", "submitter": "Yang-Hui He", "authors": "Rehan Deen, Yang-Hui He, Seung-Joo Lee, and Andre Lukas", "title": "Machine Learning String Standard Models", "comments": "10 pages", "journal-ref": "CERN-TH-2020-050, CTPU-PTC-20-06", "doi": null, "report-no": null, "categories": "hep-th math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study machine learning of phenomenologically relevant properties of string\ncompactifications, which arise in the context of heterotic line bundle models.\nBoth supervised and unsupervised learning are considered. We find that, for a\nfixed compactification manifold, relatively small neural networks are capable\nof distinguishing consistent line bundle models with the correct gauge group\nand the correct chiral asymmetry from random models without these properties.\nThe same distinction can also be achieved in the context of unsupervised\nlearning, using an auto-encoder. Learning non-topological properties,\nspecifically the number of Higgs multiplets, turns out to be more difficult,\nbut is possible using sizeable networks and feature-enhanced data sets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:14:14 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Deen", "Rehan", ""], ["He", "Yang-Hui", ""], ["Lee", "Seung-Joo", ""], ["Lukas", "Andre", ""]]}, {"id": "2003.13350", "submitter": "Adri\\`a Puigdom\\`enech Badia", "authors": "Adri\\`a Puigdom\\`enech Badia, Bilal Piot, Steven Kapturowski, Pablo\n  Sprechmann, Alex Vitvitskyi, Daniel Guo, Charles Blundell", "title": "Agent57: Outperforming the Atari Human Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atari games have been a long-standing benchmark in the reinforcement learning\n(RL) community for the past decade. This benchmark was proposed to test general\ncompetency of RL algorithms. Previous work has achieved good average\nperformance by doing outstandingly well on many games of the set, but very\npoorly in several of the most challenging games. We propose Agent57, the first\ndeep RL agent that outperforms the standard human benchmark on all 57 Atari\ngames. To achieve this result, we train a neural network which parameterizes a\nfamily of policies ranging from very exploratory to purely exploitative. We\npropose an adaptive mechanism to choose which policy to prioritize throughout\nthe training process. Additionally, we utilize a novel parameterization of the\narchitecture that allows for more consistent and stable learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:33:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Piot", "Bilal", ""], ["Kapturowski", "Steven", ""], ["Sprechmann", "Pablo", ""], ["Vitvitskyi", "Alex", ""], ["Guo", "Daniel", ""], ["Blundell", "Charles", ""]]}, {"id": "2003.13360", "submitter": "Andrew Paskaramoorthy", "authors": "Andrew Paskaramoorthy (1), Terence van Zyl (1), Tim Gebbie (2)", "title": "A Framework for Online Investment Algorithms", "comments": "for associated code patterns, see\n  https://github.com/apaskara/Online_Invest_Algo", "journal-ref": "Investment Analysts Journal, 2020, 49:3", "doi": "10.1080/10293523.2020.1806460", "report-no": null, "categories": "q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial segmentation of an investment management process into a\nworkflow with silos of offline human operators can restrict silos from\ncollectively and adaptively pursuing a unified optimal investment goal. To meet\nthe investor's objectives, an online algorithm can provide an explicit\nincremental approach that makes sequential updates as data arrives at the\nprocess level. This is in stark contrast to offline (or batch) processes that\nare focused on making component level decisions prior to process level\nintegration. Here we present and report results for an integrated, and online\nframework for algorithmic portfolio management. This article provides a\nworkflow that can in-turn be embedded into a process level learning framework.\nThe workflow can be enhanced to refine signal generation and asset-class\nevolution and definitions. Our results confirm that we can use our framework in\nconjunction with resampling methods to outperform naive market capitalisation\nbenchmarks while making clear the extent of back-test over-fitting. We consider\nsuch an online update framework to be a crucial step towards developing\nintelligent portfolio selection algorithms that integrate financial theory,\ninvestor views, and data analysis with process-level learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:41:53 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Paskaramoorthy", "Andrew", ""], ["van Zyl", "Terence", ""], ["Gebbie", "Tim", ""]]}, {"id": "2003.13367", "submitter": "Karen Ullrich", "authors": "Karen Ullrich, Fabio Viola, Danilo Jimenez Rezende", "title": "Neural Communication Systems with Bandwidth-limited Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reliably transmitting messages despite information loss due to a noisy\nchannel is a core problem of information theory. One of the most important\naspects of real world communication, e.g. via wifi, is that it may happen at\nvarying levels of information transfer. The bandwidth-limited channel models\nthis phenomenon. In this study we consider learning coding with the\nbandwidth-limited channel (BWLC). Recently, neural communication models such as\nvariational autoencoders have been studied for the task of source compression.\nWe build upon this work by studying neural communication systems with the BWLC.\nSpecifically,we find three modelling choices that are relevant under expected\ninformation loss. First, instead of separating the sub-tasks of compression\n(source coding) and error correction (channel coding), we propose to model both\njointly. Framing the problem as a variational learning problem, we conclude\nthat joint systems outperform their separate counterparts when coding is\nperformed by flexible learnable function approximators such as neural networks.\nTo facilitate learning, we introduce a differentiable and computationally\nefficient version of the bandwidth-limited channel. Second, we propose a design\nto model missing information with a prior, and incorporate this into the\nchannel model. Finally, sampling from the joint model is improved by\nintroducing auxiliary latent variables in the decoder. Experimental results\njustify the validity of our design decisions through improved distortion and\nFID scores.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:58:30 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 09:56:13 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ullrich", "Karen", ""], ["Viola", "Fabio", ""], ["Rezende", "Danilo Jimenez", ""]]}, {"id": "2003.13370", "submitter": "Mohammad Hossein Rohban", "authors": "Amirreza Shaeiri, Rozhin Nobahari, Mohammad Hossein Rohban", "title": "Towards Deep Learning Models Resistant to Large Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial robustness has proven to be a required property of machine\nlearning algorithms. A key and often overlooked aspect of this problem is to\ntry to make the adversarial noise magnitude as large as possible to enhance the\nbenefits of the model robustness. We show that the well-established algorithm\ncalled \"adversarial training\" fails to train a deep neural network given a\nlarge, but reasonable, perturbation magnitude. In this paper, we propose a\nsimple yet effective initialization of the network weights that makes learning\non higher levels of noise possible. We next evaluate this idea rigorously on\nMNIST ($\\epsilon$ up to $\\approx 0.40$) and CIFAR10 ($\\epsilon$ up to $\\approx\n32/255$) datasets assuming the $\\ell_{\\infty}$ attack model. Additionally, in\norder to establish the limits of $\\epsilon$ in which the learning is feasible,\nwe study the optimal robust classifier assuming full access to the joint data\nand label distribution. Then, we provide some theoretical results on the\nadversarial accuracy for a simple multi-dimensional Bernoulli distribution,\nwhich yields some insights on the range of feasible perturbations for the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 12:03:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Shaeiri", "Amirreza", ""], ["Nobahari", "Rozhin", ""], ["Rohban", "Mohammad Hossein", ""]]}, {"id": "2003.13388", "submitter": "Muammar El Khatib", "authors": "Muammar El Khatib, Wibe A de Jong", "title": "ML4Chem: A Machine Learning Package for Chemistry and Materials Science", "comments": "32 pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML4Chem is an open-source machine learning library for chemistry and\nmaterials science. It provides an extendable platform to develop and deploy\nmachine learning models and pipelines and is targeted to the non-expert and\nexpert users. ML4Chem follows user-experience design and offers the needed\ntools to go from data preparation to inference. Here we introduce its atomistic\nmodule for the implementation, deployment, and reproducibility of atom-centered\nmodels. This module is composed of six core building blocks: data,\nfeaturization, models, model optimization, inference, and visualization. We\npresent their functionality and easiness of use with demonstrations utilizing\nneural networks and kernel ridge regression algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 00:28:19 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Khatib", "Muammar El", ""], ["de Jong", "Wibe A", ""]]}, {"id": "2003.13413", "submitter": "Jing Li", "authors": "Jing Li, Yuangang Pan, Yulei Sui, and Ivor W. Tsang", "title": "Secure Metric Learning via Differential Pairwise Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Distance Metric Learning (DML) has drawn much attention over the last two\ndecades. A number of previous works have shown that it performs well in\nmeasuring the similarities of individuals given a set of correctly labeled\npairwise data by domain experts. These important and precisely-labeled pairwise\ndata are often highly sensitive in real world (e.g., patients similarity). This\npaper studies, for the first time, how pairwise information can be leaked to\nattackers during distance metric learning, and develops differential pairwise\nprivacy (DPP), generalizing the definition of standard differential privacy,\nfor secure metric learning. Unlike traditional differential privacy which only\napplies to independent samples, thus cannot be used for pairwise data, DPP\nsuccessfully deals with this problem by reformulating the worst case.\nSpecifically, given the pairwise data, we reveal all the involved correlations\namong pairs in the constructed undirected graph. DPP is then formalized that\ndefines what kind of DML algorithm is private to preserve pairwise data. After\nthat, a case study employing the contrastive loss is exhibited to clarify the\ndetails of implementing a DPP-DML algorithm. Particularly, the sensitivity\nreduction technique is proposed to enhance the utility of the output distance\nmetric. Experiments both on a toy dataset and benchmarks demonstrate that the\nproposed scheme achieves pairwise data privacy without compromising the output\nperformance much (Accuracy declines less than 0.01 throughout all benchmark\ndatasets when the privacy budget is set at 4).\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 12:47:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Li", "Jing", ""], ["Pan", "Yuangang", ""], ["Sui", "Yulei", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2003.13422", "submitter": "Amir Mosavi Prof", "authors": "Saeed Nosratabadi, Amir Mosavi, Puhong Duan, Pedram Ghamisi", "title": "Data Science in Economics", "comments": "22pages, 4 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper provides the state of the art of data science in economics.\nThrough a novel taxonomy of applications and methods advances in data science\nare investigated. The data science advances are investigated in three\nindividual classes of deep learning models, ensemble models, and hybrid models.\nApplication domains include stock market, marketing, E-commerce, corporate\nbanking, and cryptocurrency. Prisma method, a systematic literature review\nmethodology is used to ensure the quality of the survey. The findings revealed\nthat the trends are on advancement of hybrid models as more than 51% of the\nreviewed articles applied hybrid model. On the other hand, it is found that\nbased on the RMSE accuracy metric, hybrid models had higher prediction accuracy\nthan other algorithms. While it is expected the trends go toward the\nadvancements of deep learning models.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:06:07 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Nosratabadi", "Saeed", ""], ["Mosavi", "Amir", ""], ["Duan", "Puhong", ""], ["Ghamisi", "Pedram", ""]]}, {"id": "2003.13428", "submitter": "Masayuki Karasuyama", "authors": "Shion Takeno, Yuhki Tsukada, Hitoshi Fukuoka, Toshiyuki Koyama, Motoki\n  Shiga, and Masayuki Karasuyama", "title": "Cost-effective search for lower-error region in material parameter space\n  using multifidelity Gaussian process modeling", "comments": "23 pages, 6 figures", "journal-ref": "Phys. Rev. Materials 4, 083802 (2020)", "doi": "10.1103/PhysRevMaterials.4.083802", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information regarding precipitate shapes is critical for estimating material\nparameters. Hence, we considered estimating a region of material parameter\nspace in which a computational model produces precipitates having shapes\nsimilar to those observed in the experimental images. This region, called the\nlower-error region (LER), reflects intrinsic information of the material\ncontained in the precipitate shapes. However, the computational cost of LER\nestimation can be high because the accurate computation of the model is\nrequired many times to better explore parameters. To overcome this difficulty,\nwe used a Gaussian-process-based multifidelity modeling, in which training data\ncan be sampled from multiple computations with different accuracy levels\n(fidelity). Lower-fidelity samples may have lower accuracy, but the\ncomputational cost is lower than that for higher-fidelity samples. Our proposed\nsampling procedure iteratively determines the most cost-effective pair of a\npoint and a fidelity level for enhancing the accuracy of LER estimation. We\ndemonstrated the efficiency of our method through estimation of the interface\nenergy and lattice mismatch between MgZn2 and {\\alpha}-Mg phases in an Mg-based\nalloy. The results showed that the sampling cost required to obtain accurate\nLER estimation could be drastically reduced.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 04:14:30 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Takeno", "Shion", ""], ["Tsukada", "Yuhki", ""], ["Fukuoka", "Hitoshi", ""], ["Koyama", "Toshiyuki", ""], ["Shiga", "Motoki", ""], ["Karasuyama", "Masayuki", ""]]}, {"id": "2003.13432", "submitter": "Zhen Han", "authors": "Zhen Han, Yunpu Ma, Yuyi Wang, Stephan G\\\"unnemann, Volker Tresp", "title": "Graph Hawkes Neural Network for Forecasting on Temporal Knowledge Graphs", "comments": "Automated Knowledge Base Construction 2020, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Hawkes process has become a standard method for modeling self-exciting\nevent sequences with different event types. A recent work has generalized the\nHawkes process to a neurally self-modulating multivariate point process, which\nenables the capturing of more complex and realistic impacts of past events on\nfuture events. However, this approach is limited by the number of possible\nevent types, making it impossible to model the dynamics of evolving graph\nsequences, where each possible link between two nodes can be considered as an\nevent type. The number of event types increases even further when links are\ndirectional and labeled. To address this issue, we propose the Graph Hawkes\nNeural Network that can capture the dynamics of evolving graph sequences and\ncan predict the occurrence of a fact in a future time instance. Extensive\nexperiments on large-scale temporal multi-relational databases, such as\ntemporal knowledge graphs, demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 12:56:50 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 07:48:29 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 21:48:23 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Han", "Zhen", ""], ["Ma", "Yunpu", ""], ["Wang", "Yuyi", ""], ["G\u00fcnnemann", "Stephan", ""], ["Tresp", "Volker", ""]]}, {"id": "2003.13438", "submitter": "Arman Rahbar", "authors": "Arman Rahbar, Ashkan Panahi, Chiranjib Bhattacharyya, Devdatt\n  Dubhashi, Morteza Haghir Chehreghani", "title": "On the Unreasonable Effectiveness of Knowledge Distillation: Analysis in\n  the Kernel Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD), i.e. one classifier being trained on the outputs\nof another classifier, is an empirically very successful technique for\nknowledge transfer between classifiers. It has even been observed that\nclassifiers learn much faster and more reliably if trained with the outputs of\nanother classifier as soft labels, instead of from ground truth data. However,\nthere has been little or no theoretical analysis of this phenomenon. We provide\nthe first theoretical analysis of KD in the setting of extremely wide two layer\nnon-linear networks in model and regime in (Arora et al., 2019; Du & Hu, 2019;\nCao & Gu, 2019). We prove results on what the student network learns and on the\nrate of convergence for the student network. Intriguingly, we also confirm the\nlottery ticket hypothesis (Frankle & Carbin, 2019) in this model. To prove our\nresults, we extend the repertoire of techniques from linear systems dynamics.\nWe give corresponding experimental analysis that validates the theoretical\nresults and yields additional insights.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 13:03:28 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 07:32:45 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Rahbar", "Arman", ""], ["Panahi", "Ashkan", ""], ["Bhattacharyya", "Chiranjib", ""], ["Dubhashi", "Devdatt", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2003.13441", "submitter": "Daniel Hain PhD.", "authors": "Daniel Hain, Roman Jurowetzki", "title": "Introduction to Rare-Event Predictive Modeling for Inferential\n  Statisticians -- A Hands-On Application in the Prediction of Breakthrough\n  Patents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a substantial development of quantitative methods,\nmostly led by the computer science community with the goal of developing better\nmachine learning applications, mainly focused on predictive modeling. However,\neconomic, management, and technology forecasting research has so far been\nhesitant to apply predictive modeling techniques and workflows. In this paper,\nwe introduce a machine learning (ML) approach to quantitative analysis geared\ntowards optimizing the predictive performance, contrasting it with standard\npractices inferential statistics, which focus on producing good parameter\nestimates. We discuss the potential synergies between the two fields against\nthe backdrop of this, at first glance, target-incompatibility. We discuss\nfundamental concepts in predictive modeling, such as out-of-sample model\nvalidation, variable and model selection, generalization, and hyperparameter\ntuning procedures. We are providing a hands-on predictive modeling introduction\nfor a quantitative social science audience while aiming at demystifying\ncomputer science jargon. We use the illustrative example of patent quality\nestimation - which should be a familiar topic of interest in the Scientometrics\ncommunity - guiding the reader through various model classes and procedures for\ndata pre-processing, modeling, and validation. We start off with more familiar\neasy to interpret model classes (Logit and Elastic Nets), continues with less\nfamiliar non-parametric approaches (Classification Trees, Random Forest,\nGradient Boosted Trees), and finally presents artificial neural network\narchitectures, first a simple feed-forward and then a deep autoencoder geared\ntowards rare-event prediction.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 13:06:25 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 14:36:32 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Hain", "Daniel", ""], ["Jurowetzki", "Roman", ""]]}, {"id": "2003.13461", "submitter": "Mohammad Mahdi Kamani", "authors": "Yuyang Deng, Mohammad Mahdi Kamani, Mehrdad Mahdavi", "title": "Adaptive Personalized Federated Learning", "comments": "[v3] Added convergence analysis for nonconvex losses and additional\n  experiments along with new baselines [v2] A new generalization analysis is\n  provided. Also, additional experiments are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigation of the degree of personalization in federated learning\nalgorithms has shown that only maximizing the performance of the global model\nwill confine the capacity of the local models to personalize. In this paper, we\nadvocate an adaptive personalized federated learning (APFL) algorithm, where\neach client will train their local models while contributing to the global\nmodel. We derive the generalization bound of mixture of local and global\nmodels, and find the optimal mixing parameter. We also propose a\ncommunication-efficient optimization method to collaboratively learn the\npersonalized models and analyze its convergence in both smooth strongly convex\nand nonconvex settings. The extensive experiments demonstrate the effectiveness\nof our personalization schema, as well as the correctness of established\ngeneralization theories.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 13:19:37 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:10:22 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 04:07:31 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Deng", "Yuyang", ""], ["Kamani", "Mohammad Mahdi", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "2003.13471", "submitter": "Luis Oala", "authors": "Jan Macdonald, Maximilian M\\\"arz, Luis Oala and Wojciech Samek", "title": "Interval Neural Networks as Instability Detectors for Image\n  Reconstructions", "comments": "JM, MM and LO contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the detection of instabilities that may occur when\nutilizing deep learning models for image reconstruction tasks. Although neural\nnetworks often empirically outperform traditional reconstruction methods, their\nusage for sensitive medical applications remains controversial. Indeed, in a\nrecent series of works, it has been demonstrated that deep learning approaches\nare susceptible to various types of instabilities, caused for instance by\nadversarial noise or out-of-distribution features. It is argued that this\nphenomenon can be observed regardless of the underlying architecture and that\nthere is no easy remedy. Based on this insight, the present work demonstrates\non two use cases how uncertainty quantification methods can be employed as\ninstability detectors. In particular, it is shown that the recently proposed\nInterval Neural Networks are highly effective in revealing instabilities of\nreconstructions. Such an ability is crucial to ensure a safe use of deep\nlearning-based methods for medical image reconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 01:34:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Macdonald", "Jan", ""], ["M\u00e4rz", "Maximilian", ""], ["Oala", "Luis", ""], ["Samek", "Wojciech", ""]]}, {"id": "2003.13478", "submitter": "Andrii Babii", "authors": "Andrii Babii", "title": "High-dimensional mixed-frequency IV regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a high-dimensional linear IV regression for the data\nsampled at mixed frequencies. We show that the high-dimensional slope parameter\nof a high-frequency covariate can be identified and accurately estimated\nleveraging on a low-frequency instrumental variable. The distinguishing feature\nof the model is that it allows handing high-dimensional datasets without\nimposing the approximate sparsity restrictions. We propose a\nTikhonov-regularized estimator and derive the convergence rate of its\nmean-integrated squared error for time series data. The estimator has a\nclosed-form expression that is easy to compute and demonstrates excellent\nperformance in our Monte Carlo experiments. We estimate the real-time price\nelasticity of supply on the Australian electricity spot market. Our estimates\nsuggest that the supply is relatively inelastic and that its elasticity is\nheterogeneous throughout the day.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 13:41:02 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Babii", "Andrii", ""]]}, {"id": "2003.13491", "submitter": "Giuseppe Di Benedetto", "authors": "Giuseppe Di Benedetto, Fran\\c{c}ois Caron, Yee Whye Teh", "title": "Non-exchangeable feature allocation models with sublinear growth of the\n  feature sizes", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature allocation models are popular models used in different applications\nsuch as unsupervised learning or network modeling. In particular, the Indian\nbuffet process is a flexible and simple one-parameter feature allocation model\nwhere the number of features grows unboundedly with the number of objects. The\nIndian buffet process, like most feature allocation models, satisfies a\nsymmetry property of exchangeability: the distribution is invariant under\npermutation of the objects. While this property is desirable in some cases, it\nhas some strong implications. Importantly, the number of objects sharing a\nparticular feature grows linearly with the number of objects. In this article,\nwe describe a class of non-exchangeable feature allocation models where the\nnumber of objects sharing a given feature grows sublinearly, where the rate can\nbe controlled by a tuning parameter. We derive the asymptotic properties of the\nmodel, and show that such model provides a better fit and better predictive\nperformances on various datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:14:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Di Benedetto", "Giuseppe", ""], ["Caron", "Fran\u00e7ois", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2003.13524", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Nicola Landro", "title": "OCmst: One-class Novelty Detection using Convolutional Neural Network\n  and Minimum Spanning Trees", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel model called One Class Minimum Spanning Tree (OCmst) for\nnovelty detection problem that uses a Convolutional Neural Network (CNN) as\ndeep feature extractor and graph-based model based on Minimum Spanning Tree\n(MST). In a novelty detection scenario, the training data is no polluted by\noutliers (abnormal class) and the goal is to recognize if a test instance\nbelongs to the normal class or to the abnormal class. Our approach uses the\ndeep features from CNN to feed a pair of MSTs built starting from each test\ninstance. To cut down the computational time we use a parameter $\\gamma$ to\nspecify the size of the MST's starting to the neighbours from the test\ninstance. To prove the effectiveness of the proposed approach we conducted\nexperiments on two publicly available datasets, well-known in literature and we\nachieved the state-of-the-art results on CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:55:39 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Landro", "Nicola", ""]]}, {"id": "2003.13530", "submitter": "Nicolas Schreuder", "authors": "Nicolas Schreuder", "title": "Bounding the expectation of the supremum of empirical processes indexed\n  by H\\\"older classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we provide upper bounds on the expectation of the supremum of\nempirical processes indexed by H\\\"older classes of any smoothness and for any\ndistribution supported on a bounded set in $\\mathbb R^d$. These results can be\nalternatively seen as non-asymptotic risk bounds, when the unknown distribution\nis estimated by its empirical counterpart, based on $n$ independent\nobservations, and the error of estimation is quantified by the integral\nprobability metrics (IPM). In particular, the IPM indexed by a H\\\"older class\nis considered and the corresponding rates are derived. These results\ninterpolate between the two well-known extreme cases: the rate $n^{-1/d}$\ncorresponding to the Wassertein-1 distance (the least smooth case) and the fast\nrate $n^{-1/2}$ corresponding to very smooth functions (for instance, functions\nfrom an RKHS defined by a bounded kernel).\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:58:42 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:48:21 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 09:34:56 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Schreuder", "Nicolas", ""]]}, {"id": "2003.13541", "submitter": "Simone Disabato", "authors": "Simone Disabato, Alessandro Falcetta, Alessio Mongelluzzo, Manuel\n  Roveri", "title": "A Privacy-Preserving Distributed Architecture for\n  Deep-Learning-as-a-Service", "comments": "Accepted to be published in: 2020 International Joint Conference on\n  Neural Networks (IJCNN), Glasgow, July 19--24, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning-as-a-service is a novel and promising computing paradigm aiming\nat providing machine/deep learning solutions and mechanisms through Cloud-based\ncomputing infrastructures. Thanks to its ability to remotely execute and train\ndeep learning models (that typically require high computational loads and\nmemory occupation), such an approach guarantees high performance, scalability,\nand availability. Unfortunately, such an approach requires to send information\nto be processed (e.g., signals, images, positions, sounds, videos) to the\nCloud, hence having potentially catastrophic-impacts on the privacy of users.\nThis paper introduces a novel distributed architecture for\ndeep-learning-as-a-service that is able to preserve the user sensitive data\nwhile providing Cloud-based machine and deep learning services. The proposed\narchitecture, which relies on Homomorphic Encryption that is able to perform\noperations on encrypted data, has been tailored for Convolutional Neural\nNetworks (CNNs) in the domain of image analysis and implemented through a\nclient-server REST-based approach. Experimental results show the effectiveness\nof the proposed architecture.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:12:03 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Disabato", "Simone", ""], ["Falcetta", "Alessandro", ""], ["Mongelluzzo", "Alessio", ""], ["Roveri", "Manuel", ""]]}, {"id": "2003.13561", "submitter": "Lev Reyzin", "authors": "Daniel Berend, Aryeh Kontorovich, Lev Reyzin, Thomas Robinson", "title": "On Biased Random Walks, Corrupted Intervals, and Learning Under\n  Adversarial Design", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle some fundamental problems in probability theory on corrupted random\nprocesses on the integer line. We analyze when a biased random walk is expected\nto reach its bottommost point and when intervals of integer points can be\ndetected under a natural model of noise. We apply these results to problems in\nlearning thresholds and intervals under a new model for learning under\nadversarial design.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:35:21 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Berend", "Daniel", ""], ["Kontorovich", "Aryeh", ""], ["Reyzin", "Lev", ""], ["Robinson", "Thomas", ""]]}, {"id": "2003.13563", "submitter": "Valerii Likhosherstov", "authors": "Krzysztof Choromanski, David Cheikhi, Jared Davis, Valerii\n  Likhosherstov, Achille Nazaret, Achraf Bahamou, Xingyou Song, Mrugank Akarte,\n  Jack Parker-Holder, Jacob Bergquist, Yuan Gao, Aldo Pacchiano, Tamas Sarlos,\n  Adrian Weller, Vikas Sindhwani", "title": "Stochastic Flows and Geometric Optimization on the Orthogonal Group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new class of stochastic, geometrically-driven optimization\nalgorithms on the orthogonal group $O(d)$ and naturally reductive homogeneous\nmanifolds obtained from the action of the rotation group $SO(d)$. We\ntheoretically and experimentally demonstrate that our methods can be applied in\nvarious fields of machine learning including deep, convolutional and recurrent\nneural networks, reinforcement learning, normalizing flows and metric learning.\nWe show an intriguing connection between efficient stochastic optimization on\nthe orthogonal group and graph theory (e.g. matching problem, partition\nfunctions over graphs, graph-coloring). We leverage the theory of Lie groups\nand provide theoretical results for the designed class of algorithms. We\ndemonstrate broad applicability of our methods by showing strong performance on\nthe seemingly unrelated tasks of learning world models to obtain stable\npolicies for the most difficult $\\mathrm{Humanoid}$ agent from\n$\\mathrm{OpenAI}$ $\\mathrm{Gym}$ and improving convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:37:50 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Cheikhi", "David", ""], ["Davis", "Jared", ""], ["Likhosherstov", "Valerii", ""], ["Nazaret", "Achille", ""], ["Bahamou", "Achraf", ""], ["Song", "Xingyou", ""], ["Akarte", "Mrugank", ""], ["Parker-Holder", "Jack", ""], ["Bergquist", "Jacob", ""], ["Gao", "Yuan", ""], ["Pacchiano", "Aldo", ""], ["Sarlos", "Tamas", ""], ["Weller", "Adrian", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "2003.13593", "submitter": "Tai Vu", "authors": "Tai Vu, Emily Wen, Roy Nehoran", "title": "How Not to Give a FLOP: Combining Regularization and Pruning for\n  Efficient Inference", "comments": "Citations added, typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The challenge of speeding up deep learning models during the deployment phase\nhas been a large, expensive bottleneck in the modern tech industry. In this\npaper, we examine the use of both regularization and pruning for reduced\ncomputational complexity and more efficient inference in Deep Neural Networks\n(DNNs). In particular, we apply mixup and cutout regularizations and soft\nfilter pruning to the ResNet architecture, focusing on minimizing\nfloating-point operations (FLOPs). Furthermore, by using regularization in\nconjunction with network pruning, we show that such a combination makes a\nsubstantial improvement over each of the two techniques individually.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:20:46 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:21:07 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Vu", "Tai", ""], ["Wen", "Emily", ""], ["Nehoran", "Roy", ""]]}, {"id": "2003.13606", "submitter": "Yuning You", "authors": "Yuning You, Tianlong Chen, Zhangyang Wang, Yang Shen", "title": "L$^2$-GCN: Layer-Wise and Learned Efficient Training of Graph\n  Convolutional Networks", "comments": "Supplementary materials are available at\n  https://yyou1996.github.io/files/cvpr2020_l2gcn_supplement.pdf. CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution networks (GCN) are increasingly popular in many\napplications, yet remain notoriously hard to train over large graph datasets.\nThey need to compute node representations recursively from their neighbors.\nCurrent GCN training algorithms suffer from either high computational costs\nthat grow exponentially with the number of layers, or high memory usage for\nloading the entire graph and node embeddings. In this paper, we propose a novel\nefficient layer-wise training framework for GCN (L-GCN), that disentangles\nfeature aggregation and feature transformation during training, hence greatly\nreducing time and memory complexities. We present theoretical analysis for\nL-GCN under the graph isomorphism framework, that L-GCN leads to as powerful\nGCNs as the more costly conventional training algorithm does, under mild\nconditions. We further propose L$^2$-GCN, which learns a controller for each\nlayer that can automatically adjust the training epochs per layer in L-GCN.\nExperiments show that L-GCN is faster than state-of-the-arts by at least an\norder of magnitude, with a consistent of memory usage not dependent on dataset\nsize, while maintaining comparable prediction performance. With the learned\ncontroller, L$^2$-GCN can further cut the training time in half. Our codes are\navailable at https://github.com/Shen-Lab/L2-GCN.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:37:56 GMT"}, {"version": "v10", "created": "Sun, 19 Jul 2020 14:05:38 GMT"}, {"version": "v11", "created": "Thu, 6 Aug 2020 03:09:04 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 01:33:46 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 23:45:39 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 20:20:36 GMT"}, {"version": "v5", "created": "Thu, 4 Jun 2020 01:12:44 GMT"}, {"version": "v6", "created": "Fri, 5 Jun 2020 14:16:41 GMT"}, {"version": "v7", "created": "Tue, 16 Jun 2020 04:06:34 GMT"}, {"version": "v8", "created": "Fri, 19 Jun 2020 21:08:26 GMT"}, {"version": "v9", "created": "Sat, 4 Jul 2020 21:55:06 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["You", "Yuning", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""], ["Shen", "Yang", ""]]}, {"id": "2003.13616", "submitter": "Yuxan Liu", "authors": "Yuxuan Liu, Jiangyong Duan and Juan Meng", "title": "Difference Attention Based Error Correction LSTM Model for Time Series\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1550/3/032121", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel model for time series prediction in which\ndifference-attention LSTM model and error-correction LSTM model are\nrespectively employed and combined in a cascade way. While difference-attention\nLSTM model introduces a difference feature to perform attention in traditional\nLSTM to focus on the obvious changes in time series. Error-correction LSTM\nmodel refines the prediction error of difference-attention LSTM model to\nfurther improve the prediction accuracy. Finally, we design a training strategy\nto jointly train the both models simultaneously. With additional difference\nfeatures and new principle learning framework, our model can improve the\nprediction accuracy in time series. Experiments on various time series are\nconducted to demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:48:30 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Liu", "Yuxuan", ""], ["Duan", "Jiangyong", ""], ["Meng", "Juan", ""]]}, {"id": "2003.13637", "submitter": "Barbara Franci Dott.", "authors": "Barbara Franci and Sergio Grammatico", "title": "A game-theoretic approach for Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a class of generative models,\nknown for producing accurate samples. The key feature of GANs is that there are\ntwo antagonistic neural networks: the generator and the discriminator. The main\nbottleneck for their implementation is that the neural networks are very hard\nto train. One way to improve their performance is to design reliable algorithms\nfor the adversarial process. Since the training can be cast as a stochastic\nNash equilibrium problem, we rewrite it as a variational inequality and\nintroduce an algorithm to compute an approximate solution. Specifically, we\npropose a stochastic relaxed forward-backward algorithm for GANs. We prove that\nwhen the pseudogradient mapping of the game is monotone, we have convergence to\nan exact solution or in a neighbourhood of it.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:14:41 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 16:27:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Franci", "Barbara", ""], ["Grammatico", "Sergio", ""]]}, {"id": "2003.13661", "submitter": "Ruihan Yang", "authors": "Ruihan Yang, Huazhe Xu, Yi Wu, Xiaolong Wang", "title": "Multi-Task Reinforcement Learning with Soft Modularization", "comments": "Our project page: https://rchalyang.github.io/SoftModule", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is a very challenging problem in reinforcement learning.\nWhile training multiple tasks jointly allow the policies to share parameters\nacross different tasks, the optimization problem becomes non-trivial: It\nremains unclear what parameters in the network should be reused across tasks,\nand how the gradients from different tasks may interfere with each other. Thus,\ninstead of naively sharing parameters across tasks, we introduce an explicit\nmodularization technique on policy representation to alleviate this\noptimization issue. Given a base policy network, we design a routing network\nwhich estimates different routing strategies to reconfigure the base network\nfor each task. Instead of directly selecting routes for each task, our\ntask-specific policy uses a method called soft modularization to softly combine\nall the possible routes, which makes it suitable for sequential tasks. We\nexperiment with various robotics manipulation tasks in simulation and show our\nmethod improves both sample efficiency and performance over strong baselines by\na large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:47:04 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 07:14:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yang", "Ruihan", ""], ["Xu", "Huazhe", ""], ["Wu", "Yi", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2003.13663", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Ruijie Wang, Shuochao Yao, Shengzhong Liu, Tarek\n  Abdelzaher", "title": "Revisiting Over-smoothing in Deep GCNs", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oversmoothing has been assumed to be the major cause of performance drop in\ndeep graph convolutional networks (GCNs). In this paper, we propose a new view\nthat deep GCNs can actually learn to anti-oversmooth during training. This work\ninterprets a standard GCN architecture as layerwise integration of a\nMulti-layer Perceptron (MLP) and graph regularization. We analyze and conclude\nthat before training, the final representation of a deep GCN does over-smooth,\nhowever, it learns anti-oversmoothing during training. Based on the conclusion,\nthe paper further designs a cheap but effective trick to improve GCN training.\nWe verify our conclusions and evaluate the trick on three citation networks and\nfurther provide insights on neighborhood aggregation in GCNs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:48:04 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 06:23:15 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 00:44:47 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 08:06:28 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 21:45:09 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yang", "Chaoqi", ""], ["Wang", "Ruijie", ""], ["Yao", "Shuochao", ""], ["Liu", "Shengzhong", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2003.13726", "submitter": "Sangwon Jung", "authors": "Sangwon Jung, Hongjoon Ahn, Sungmin Cha and Taesup Moon", "title": "Continual Learning with Node-Importance based Adaptive Group Sparse\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel regularization-based continual learning method, dubbed as\nAdaptive Group Sparsity based Continual Learning (AGS-CL), using two group\nsparsity-based penalties. Our method selectively employs the two penalties when\nlearning each node based its the importance, which is adaptively updated after\nlearning each new task. By utilizing the proximal gradient descent method for\nlearning, the exact sparsity and freezing of the model is guaranteed, and thus,\nthe learner can explicitly control the model capacity as the learning\ncontinues. Furthermore, as a critical detail, we re-initialize the weights\nassociated with unimportant nodes after learning each task in order to prevent\nthe negative transfer that causes the catastrophic forgetting and facilitate\nefficient learning of new tasks. Throughout the extensive experimental results,\nwe show that our AGS-CL uses much less additional memory space for storing the\nregularization parameters, and it significantly outperforms several\nstate-of-the-art baselines on representative continual learning benchmarks for\nboth supervised and reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:21:04 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:50:49 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 07:29:33 GMT"}, {"version": "v4", "created": "Sat, 29 May 2021 07:39:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jung", "Sangwon", ""], ["Ahn", "Hongjoon", ""], ["Cha", "Sungmin", ""], ["Moon", "Taesup", ""]]}, {"id": "2003.13741", "submitter": "Karl Kurzer", "authors": "Karl Kurzer, Christoph H\\\"ortnagl, J. Marius Z\\\"ollner", "title": "Parallelization of Monte Carlo Tree Search in Continuous Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) has proven to be capable of solving\nchallenging tasks in domains such as Go, chess and Atari. Previous research has\ndeveloped parallel versions of MCTS, exploiting today's multiprocessing\narchitectures. These studies focused on versions of MCTS for the discrete case.\nOur work builds upon existing parallelization strategies and extends them to\ncontinuous domains. In particular, leaf parallelization and root\nparallelization are studied and two final selection strategies that are\nrequired to handle continuous states in root parallelization are proposed. The\nevaluation of the resulting parallelized continuous MCTS is conducted using a\nchallenging cooperative multi-agent system trajectory planning task in the\ndomain of automated vehicles.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:43:59 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Kurzer", "Karl", ""], ["H\u00f6rtnagl", "Christoph", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2003.13754", "submitter": "Connor Coley", "authors": "Connor W. Coley, Natalie S. Eyke, Klavs F. Jensen", "title": "Autonomous discovery in the chemical sciences part I: Progress", "comments": "Revised version available at 10.1002/anie.201909987", "journal-ref": null, "doi": "10.1002/anie.201909987", "report-no": null, "categories": "q-bio.QM cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This two-part review examines how automation has contributed to different\naspects of discovery in the chemical sciences. In this first part, we describe\na classification for discoveries of physical matter (molecules, materials,\ndevices), processes, and models and how they are unified as search problems. We\nthen introduce a set of questions and considerations relevant to assessing the\nextent of autonomy. Finally, we describe many case studies of discoveries\naccelerated by or resulting from computer assistance and automation from the\ndomains of synthetic chemistry, drug discovery, inorganic chemistry, and\nmaterials science. These illustrate how rapid advancements in hardware\nautomation and machine learning continue to transform the nature of\nexperimentation and modelling.\n  Part two reflects on these case studies and identifies a set of open\nchallenges for the field.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:11:31 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Coley", "Connor W.", ""], ["Eyke", "Natalie S.", ""], ["Jensen", "Klavs F.", ""]]}, {"id": "2003.13755", "submitter": "Connor Coley", "authors": "Connor W. Coley, Natalie S. Eyke, Klavs F. Jensen", "title": "Autonomous discovery in the chemical sciences part II: Outlook", "comments": "Revised version available at 10.1002/anie.201909989", "journal-ref": null, "doi": "10.1002/anie.201909989", "report-no": null, "categories": "q-bio.QM cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This two-part review examines how automation has contributed to different\naspects of discovery in the chemical sciences. In this second part, we reflect\non a selection of exemplary studies. It is increasingly important to articulate\nwhat the role of automation and computation has been in the scientific process\nand how that has or has not accelerated discovery. One can argue that even the\nbest automated systems have yet to ``discover'' despite being incredibly useful\nas laboratory assistants. We must carefully consider how they have been and can\nbe applied to future problems of chemical discovery in order to effectively\ndesign and interact with future autonomous platforms.\n  The majority of this article defines a large set of open research directions,\nincluding improving our ability to work with complex data, build empirical\nmodels, automate both physical and computational experiments for validation,\nselect experiments, and evaluate whether we are making progress toward the\nultimate goal of autonomous discovery. Addressing these practical and\nmethodological challenges will greatly advance the extent to which autonomous\nsystems can make meaningful discoveries.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:11:35 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Coley", "Connor W.", ""], ["Eyke", "Natalie S.", ""], ["Jensen", "Klavs F.", ""]]}, {"id": "2003.13761", "submitter": "Yanmin Gong", "authors": "Rui Hu, Yuanxiong Guo, and Yanmin Gong", "title": "Concentrated Differentially Private and Utility Preserving Federated\n  Learning", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a machine learning setting where a set of edge devices\ncollaboratively train a model under the orchestration of a central server\nwithout sharing their local data. At each communication round of federated\nlearning, edge devices perform multiple steps of stochastic gradient descent\nwith their local data and then upload the computation results to the server for\nmodel update. During this process, the challenge of privacy leakage arises due\nto the information exchange between edge devices and the server when the server\nis not fully trusted. While some previous privacy-preserving mechanisms could\nreadily be used for federated learning, they usually come at a high cost on\nconvergence of the algorithm and utility of the learned model. In this paper,\nwe develop a federated learning approach that addresses the privacy challenge\nwithout much degradation on model utility through a combination of local\ngradient perturbation, secure aggregation, and zero-concentrated differential\nprivacy (zCDP). We provide a tight end-to-end privacy guarantee of our approach\nand analyze its theoretical convergence rates. Through extensive numerical\nexperiments on real-world datasets, we demonstrate the effectiveness of our\nproposed method and show its superior trade-off between privacy and model\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:20:42 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:31:59 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 22:12:30 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 15:12:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hu", "Rui", ""], ["Guo", "Yuanxiong", ""], ["Gong", "Yanmin", ""]]}, {"id": "2003.13767", "submitter": "David Hurwitz", "authors": "David Hurwitz", "title": "From Patterson Maps to Atomic Coordinates: Training a Deep Neural\n  Network to Solve the Phase Problem for a Simplified Case", "comments": "This work is a personal project of the author. The opinions expressed\n  in this article are the author's own and do not reflect the view of the\n  National Institutes of Health, the Department of Health and Human Services,\n  or the United States government. Email: hurwitz dot david at gmail dot com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.atom-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work demonstrates that, for a simple case of 10 randomly positioned\natoms, a neural network can be trained to infer atomic coordinates from\nPatterson maps. The network was trained entirely on synthetic data. For the\ntraining set, the network outputs were 3D maps of randomly positioned atoms.\nFrom each output map, a Patterson map was generated and used as input to the\nnetwork. The network generalized to cases not in the test set, inferring atom\npositions from Patterson maps.\n  A key finding in this work is that the Patterson maps presented to the\nnetwork input during training must uniquely describe the atomic coordinates\nthey are paired with on the network output or the network will not train and it\nwill not generalize. The network cannot train on conflicting data. Avoiding\nconflicts is handled in 3 ways: 1. Patterson maps are invariant to translation.\nTo remove this degree of freedom, output maps are centered on the average of\ntheir atom positions. 2. Patterson maps are invariant to centrosymmetric\ninversion. This conflict is removed by presenting the network output with both\nthe atoms used to make the Patterson Map and their centrosymmetry-related\ncounterparts simultaneously. 3. The Patterson map does not uniquely describe a\nset of coordinates because the origin for each vector in the Patterson map is\nambiguous. By adding empty space around the atoms in the output map, this\nambiguity is removed. Forcing output atoms to be closer than half the output\nbox edge dimension means the origin of each peak in the Patterson map must be\nthe origin to which it is closest.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:34:39 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Hurwitz", "David", ""]]}, {"id": "2003.13779", "submitter": "Hamada Zahera", "authors": "Hamada M. Zahera and Mohamed Ahmed Sherif, and Axel Ngonga", "title": "Semantic-based End-to-End Learning for Typhoon Intensity Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disaster prediction is one of the most critical tasks towards disaster\nsurveillance and preparedness. Existing technologies employ different machine\nlearning approaches to predict incoming disasters from historical environmental\ndata. However, for short-term disasters (e.g., earthquakes), historical data\nalone has a limited prediction capability. Therefore, additional sources of\nwarnings are required for accurate prediction. We consider social media as a\nsupplementary source of knowledge in addition to historical environmental data.\nHowever, social media posts (e.g., tweets) is very informal and contains only\nlimited content. To alleviate these limitations, we propose the combination of\nsemantically-enriched word embedding models to represent entities in tweets\nwith their semantic representations computed with the traditionalword2vec.\nMoreover, we study how the correlation between social media posts and typhoons\nmagnitudes (also called intensities)-in terms of volume and sentiments of\ntweets-. Based on these insights, we propose an end-to-end based framework that\nlearns from disaster-related tweets and environmental data to improve typhoon\nintensity prediction. This paper is an extension of our work originally\npublished in K-CAP 2019 [32]. We extended this paper by building our framework\nwith state-of-the-art deep neural models, up-dated our dataset with new\ntyphoons and their tweets to-date and benchmark our approach against recent\nbaselines in disaster prediction. Our experimental results show that our\napproach outperforms the accuracy of the state-of-the-art baselines in terms of\nF1-score with (CNN by12.1%and BiLSTM by3.1%) improvement compared with last\nexperiments\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 01:13:20 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 11:02:22 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zahera", "Hamada M.", ""], ["Sherif", "Mohamed Ahmed", ""], ["Ngonga", "Axel", ""]]}, {"id": "2003.13811", "submitter": "Nathan Powell", "authors": "Nathan Powell, Andrew Kurdila", "title": "Learning Theory for Estimation of Animal Motion Submanifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the formulation and experimental testing of a novel\nmethod for the estimation and approximation of submanifold models of animal\nmotion. It is assumed that the animal motion is supported on a configuration\nmanifold $Q$ that is a smooth, connected, regularly embedded Riemannian\nsubmanifold of Euclidean space $X\\approx \\mathbb{R}^d$ for some $d>0$, and that\nthe manifold $Q$ is homeomorphic to a known smooth, Riemannian manifold $S$.\nEstimation of the manifold is achieved by finding an unknown mapping\n$\\gamma:S\\rightarrow Q\\subset X$ that maps the manifold $S$ into $Q$. The\noverall problem is cast as a distribution-free learning problem over the\nmanifold of measurements $\\mathbb{Z}=S\\times X$. That is, it is assumed that\nexperiments generate a finite sets $\\{(s_i,x_i)\\}_{i=1}^m\\subset \\mathbb{Z}^m$\nof samples that are generated according to an unknown probability density $\\mu$\non $\\mathbb{Z}$. This paper derives approximations $\\gamma_{n,m}$ of $\\gamma$\nthat are based on the $m$ samples and are contained in an $N(n)$ dimensional\nspace of approximants. The paper defines sufficient conditions that shows that\nthe rates of convergence in $L^2_\\mu(S)$ correspond to those known for\nclassical distribution-free learning theory over Euclidean space. Specifically,\nthe paper derives sufficient conditions that guarantee rates of convergence\nthat have the form $$\\mathbb{E} \\left\n(\\|\\gamma_\\mu^j-\\gamma_{n,m}^j\\|_{L^2_\\mu(S)}^2\\right )\\leq C_1 N(n)^{-r} + C_2\n\\frac{N(n)\\log(N(n))}{m}$$for constants $C_1,C_2$ with\n$\\gamma_\\mu:=\\{\\gamma^1_\\mu,\\ldots,\\gamma^d_\\mu\\}$ the regressor function\n$\\gamma_\\mu:S\\rightarrow Q\\subset X$ and\n$\\gamma_{n,m}:=\\{\\gamma^1_{n,j},\\ldots,\\gamma^d_{n,m}\\}$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 20:54:51 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 15:35:54 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Powell", "Nathan", ""], ["Kurdila", "Andrew", ""]]}, {"id": "2003.13815", "submitter": "Mohammed Abdelsamea", "authors": "Asmaa Abbas, Mohammed M. Abdelsamea, Mohamed Medhat Gaber", "title": "Classification of COVID-19 in chest X-ray images using DeTraC deep\n  convolutional neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest X-ray is the first imaging technique that plays an important role in\nthe diagnosis of COVID-19 disease. Due to the high availability of large-scale\nannotated image datasets, great success has been achieved using convolutional\nneural networks (CNNs) for image recognition and classification. However, due\nto the limited availability of annotated medical images, the classification of\nmedical images remains the biggest challenge in medical diagnosis. Thanks to\ntransfer learning, an effective mechanism that can provide a promising solution\nby transferring knowledge from generic object recognition tasks to\ndomain-specific tasks. In this paper, we validate and adapt our previously\ndeveloped CNN, called Decompose, Transfer, and Compose (DeTraC), for the\nclassification of COVID-19 chest X-ray images. DeTraC can deal with any\nirregularities in the image dataset by investigating its class boundaries using\na class decomposition mechanism. The experimental results showed the capability\nof DeTraC in the detection of COVID-19 cases from a comprehensive image dataset\ncollected from several hospitals around the world. High accuracy of 95.12%\n(with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of\n93.36%) was achieved by DeTraC in the detection of COVID-19 X-ray images from\nnormal, and severe acute respiratory syndrome cases.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:18:45 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 08:54:31 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 12:02:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Abbas", "Asmaa", ""], ["Abdelsamea", "Mohammed M.", ""], ["Gaber", "Mohamed Medhat", ""]]}, {"id": "2003.13819", "submitter": "Milad Bakhshizadeh", "authors": "Milad Bakhshizadeh, Arian Maleki, Victor H. de la Pena", "title": "Sharp Concentration Results for Heavy-Tailed Distributions", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain concentration and large deviation for the sums of independent and\nidentically distributed random variables with heavy-tailed distributions. Our\nconcentration results are concerned with random variables whose distributions\nsatisfy $P(X>t) \\leq {\\rm e}^{- I(t)}$, where $I: \\mathbb{R} \\rightarrow\n\\mathbb{R}$ is an increasing function and $I(t)/t \\rightarrow \\alpha \\in [0,\n\\infty)$ as $t \\rightarrow \\infty$. Our main theorem can not only recover some\nof the existing results, such as the concentration of the sum of subWeibull\nrandom variables, but it can also produce new results for the sum of random\nvariables with heavier tails. We show that the concentration inequalities we\nobtain are sharp enough to offer large deviation results for the sums of\nindependent random variables as well. Our analyses which are based on standard\ntruncation arguments simplify, unify and generalize the existing results on the\nconcentration and large deviation of heavy-tailed random variables.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:05:29 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 15:12:56 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Bakhshizadeh", "Milad", ""], ["Maleki", "Arian", ""], ["de la Pena", "Victor H.", ""]]}, {"id": "2003.13821", "submitter": "Ayush Jain", "authors": "Ayush Jain, Dr. N.M. Meenachi, Dr. B. Venkatraman", "title": "NukeBERT: A Pre-trained language model for Low Resource Nuclear Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Significant advances have been made in recent years on Natural Language\nProcessing with machines surpassing human performance in many tasks, including\nbut not limited to Question Answering. The majority of deep learning methods\nfor Question Answering targets domains with large datasets and highly matured\nliterature. The area of Nuclear and Atomic energy has largely remained\nunexplored in exploiting non-annotated data for driving industry viable\napplications. Due to lack of dataset, a new dataset was created from the 7000\nresearch papers on nuclear domain. This paper contributes to research in\nunderstanding nuclear domain knowledge which is then evaluated on Nuclear\nQuestion Answering Dataset (NQuAD) created by nuclear domain experts as part of\nthis research. NQuAD contains 612 questions developed on 181 paragraphs\nrandomly selected from the IGCAR research paper corpus. In this paper, the\nNuclear Bidirectional Encoder Representational Transformers (NukeBERT) is\nproposed, which incorporates a novel technique for building BERT vocabulary to\nmake it suitable for tasks with less training data. The experiments evaluated\non NQuAD revealed that NukeBERT was able to outperform BERT significantly, thus\nvalidating the adopted methodology. Training NukeBERT is computationally\nexpensive and hence we will be open-sourcing the NukeBERT pretrained weights\nand NQuAD for fostering further research work in the nuclear domain.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:10:19 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 20:50:46 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jain", "Ayush", ""], ["Meenachi", "Dr. N. M.", ""], ["Venkatraman", "Dr. B.", ""]]}, {"id": "2003.13865", "submitter": "Pengtao Xie", "authors": "Xingyi Yang, Xuehai He, Jinyu Zhao, Yichen Zhang, Shanghang Zhang,\n  Pengtao Xie", "title": "COVID-CT-Dataset: A CT Scan Dataset about COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the outbreak time of COVID-19, computed tomography (CT) is a useful\nmanner for diagnosing COVID-19 patients. Due to privacy issues, publicly\navailable COVID-19 CT datasets are highly difficult to obtain, which hinders\nthe research and development of AI-powered diagnosis methods of COVID-19 based\non CTs. To address this issue, we build an open-sourced dataset -- COVID-CT,\nwhich contains 349 COVID-19 CT images from 216 patients and 463 non-COVID-19\nCTs. The utility of this dataset is confirmed by a senior radiologist who has\nbeen diagnosing and treating COVID-19 patients since the outbreak of this\npandemic. We also perform experimental studies which further demonstrate that\nthis dataset is useful for developing AI-based diagnosis models of COVID-19.\nUsing this dataset, we develop diagnosis methods based on multi-task learning\nand self-supervised learning, that achieve an F1 of 0.90, an AUC of 0.98, and\nan accuracy of 0.89. According to the senior radiologist, models with such\nperformance are good enough for clinical usage. The data and code are available\nat https://github.com/UCSD-AI4H/COVID-CT\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:27:24 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 02:08:25 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 20:14:22 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yang", "Xingyi", ""], ["He", "Xuehai", ""], ["Zhao", "Jinyu", ""], ["Zhang", "Yichen", ""], ["Zhang", "Shanghang", ""], ["Xie", "Pengtao", ""]]}, {"id": "2003.13866", "submitter": "Calvin Murdock", "authors": "Calvin Murdock, Simon Lucey", "title": "Dataless Model Selection with the Deep Frame Potential", "comments": "Oral presentation at the Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing a deep neural network architecture is a fundamental problem in\napplications that require balancing performance and parameter efficiency.\nStandard approaches rely on ad-hoc engineering or computationally expensive\nvalidation on a specific dataset. We instead attempt to quantify networks by\ntheir intrinsic capacity for unique and robust representations, enabling\nefficient architecture comparisons without requiring any data. Building upon\ntheoretical connections between deep learning and sparse approximation, we\npropose the deep frame potential: a measure of coherence that is approximately\nrelated to representation stability but has minimizers that depend only on\nnetwork structure. This provides a framework for jointly quantifying the\ncontributions of architectural hyper-parameters such as depth, width, and skip\nconnections. We validate its use as a criterion for model selection and\ndemonstrate correlation with generalization error on a variety of common\nresidual and densely connected network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:27:25 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Murdock", "Calvin", ""], ["Lucey", "Simon", ""]]}, {"id": "2003.13868", "submitter": "Manohar Karki", "authors": "Manohar Karki, Junghwan Cho, Seokhwan Ko", "title": "Lesion Conditional Image Generation for Improved Segmentation of\n  Intracranial Hemorrhage from CT Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data augmentation can effectively resolve a scarcity of images when training\nmachine-learning algorithms. It can make them more robust to unseen images. We\npresent a lesion conditional Generative Adversarial Network LcGAN to generate\nsynthetic Computed Tomography (CT) images for data augmentation. A lesion\nconditional image (segmented mask) is an input to both the generator and the\ndiscriminator of the LcGAN during training. The trained model generates\ncontextual CT images based on input masks. We quantify the quality of the\nimages by using a fully convolutional network (FCN) score and blurriness. We\nalso train another classification network to select better synthetic images.\nThese synthetic CT images are then augmented to our hemorrhagic lesion\nsegmentation network. By applying this augmentation method on 2.5%, 10% and 25%\nof original data, segmentation improved by 12.8%, 6% and 1.6% respectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:32:54 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Karki", "Manohar", ""], ["Cho", "Junghwan", ""], ["Ko", "Seokhwan", ""]]}, {"id": "2003.13869", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Rudrasis Chakraborty", "title": "ManifoldNorm: Extending normalizations on Riemannian Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many measurements in computer vision and machine learning manifest as\nnon-Euclidean data samples. Several researchers recently extended a number of\ndeep neural network architectures for manifold valued data samples. Researchers\nhave proposed models for manifold valued spatial data which are common in\nmedical image processing including processing of diffusion tensor imaging (DTI)\nwhere images are fields of $3\\times 3$ symmetric positive definite matrices or\nrepresentation in terms of orientation distribution field (ODF) where the\nidentification is in terms of field on hypersphere. There are other sequential\nmodels for manifold valued data that recently researchers have shown to be\neffective for group difference analysis in study for neuro-degenerative\ndiseases. Although, several of these methods are effective to deal with\nmanifold valued data, the bottleneck includes the instability in optimization\nfor deeper networks. In order to deal with these instabilities, researchers\nhave proposed residual connections for manifold valued data. One of the other\nremedies to deal with the instabilities including gradient explosion is to use\nnormalization techniques including {\\it batch norm} and {\\it group norm} etc..\nBut, so far there is no normalization techniques applicable for manifold valued\ndata. In this work, we propose a general normalization techniques for manifold\nvalued data. We show that our proposed manifold normalization technique have\nspecial cases including popular batch norm and group norm techniques. On the\nexperimental side, we focus on two types of manifold valued data including\nmanifold of symmetric positive definite matrices and hypersphere. We show the\nperformance gain in one synthetic experiment for moving MNIST dataset and one\nreal brain image dataset where the representation is in terms of orientation\ndistribution field (ODF).\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:45:43 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 22:44:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chakraborty", "Rudrasis", ""]]}, {"id": "2003.13874", "submitter": "Zitao Chen", "authors": "Zitao Chen, Guanpeng Li and Karthik Pattabiraman", "title": "A Low-cost Fault Corrector for Deep Neural Networks through Range\n  Restriction", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of deep neural networks (DNNs) in safety-critical domains has\nengendered serious reliability concerns. A prominent example is hardware\ntransient faults that are growing in frequency due to the progressive\ntechnology scaling, and can lead to failures in DNNs.\n  This work proposes Ranger, a low-cost fault corrector, which directly\nrectifies the faulty output due to transient faults without re-computation.\nDNNs are inherently resilient to benign faults (which will not cause output\ncorruption), but not to critical faults (which can result in erroneous output).\nRanger is an automated transformation to selectively restrict the value ranges\nin DNNs, which reduces the large deviations caused by critical faults and\ntransforms them to benign faults that can be tolerated by the inherent\nresilience of the DNNs. Our evaluation on 8 DNNs demonstrates Ranger\nsignificantly increases the error resilience of the DNNs (by 3x to 50x), with\nno loss in accuracy, and with negligible overheads.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 23:53:55 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 08:07:30 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 08:23:57 GMT"}, {"version": "v4", "created": "Mon, 29 Mar 2021 01:47:53 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Chen", "Zitao", ""], ["Li", "Guanpeng", ""], ["Pattabiraman", "Karthik", ""]]}, {"id": "2003.13881", "submitter": "Jean Honorio", "authors": "Abdulrahman Alabdulkareem and Jean Honorio", "title": "Information-Theoretic Lower Bounds for Zero-Order Stochastic Gradient\n  Estimation", "comments": null, "journal-ref": "IEEE International Symposium on Information Theory (ISIT), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the necessary number of samples to estimate the\ngradient of any multidimensional smooth (possibly non-convex) function in a\nzero-order stochastic oracle model. In this model, an estimator has access to\nnoisy values of the function, in order to produce the estimate of the gradient.\nWe also provide an analysis on the sufficient number of samples for the finite\ndifference method, a classical technique in numerical linear algebra. For $T$\nsamples and $d$ dimensions, our information-theoretic lower bound is\n$\\Omega(\\sqrt{d/T})$. We show that the finite difference method for a\nbounded-variance oracle has rate $O(d^{4/3}/\\sqrt{T})$ for functions with zero\nthird and higher order derivatives. These rates are tight for Gaussian oracles.\nThus, the finite difference method is not minimax optimal, and therefore there\nis space for the development of better gradient estimation methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:11:13 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 16:00:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Alabdulkareem", "Abdulrahman", ""], ["Honorio", "Jean", ""]]}, {"id": "2003.13913", "submitter": "Johann Brehmer Mr", "authors": "Johann Brehmer and Kyle Cranmer", "title": "Flows for simultaneous manifold learning and density estimation", "comments": "Code at https://github.com/johannbrehmer/manifold-flow , v2: multiple\n  new experiments, v3: added comparison with probabilistic auto-encoder", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce manifold-learning flows (M-flows), a new class of generative\nmodels that simultaneously learn the data manifold as well as a tractable\nprobability density on that manifold. Combining aspects of normalizing flows,\nGANs, autoencoders, and energy-based models, they have the potential to\nrepresent datasets with a manifold structure more faithfully and provide\nhandles on dimensionality reduction, denoising, and out-of-distribution\ndetection. We argue why such models should not be trained by maximum likelihood\nalone and present a new training algorithm that separates manifold and density\nupdates. In a range of experiments we demonstrate how M-flows learn the data\nmanifold and allow for better inference than standard flows in the ambient data\nspace.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 02:07:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 21:01:51 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 16:10:19 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Brehmer", "Johann", ""], ["Cranmer", "Kyle", ""]]}, {"id": "2003.13933", "submitter": "Yongxin Chen", "authors": "Rahul Singh, Isabel Haasler, Qinsheng Zhang, Johan Karlsson, Yongxin\n  Chen", "title": "Inference with Aggregate Data: An Optimal Transport Approach", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider inference (filtering) problems over probabilistic graphical\nmodels with aggregate data generated by a large population of individuals. We\npropose a new efficient belief propagation type algorithm over tree-structured\ngraphs with polynomial computational complexity as well as a global convergence\nguarantee. This is in contrast to previous methods that either exhibit\nprohibitive complexity as the population grows or do not guarantee convergence.\nOur method is based on optimal transport, or more specifically, multi-marginal\noptimal transport theory. In particular, we consider an inference problem with\naggregate observations, that can be seen as a structured multi-marginal optimal\ntransport problem where the cost function decomposes according to the\nunderlying graph. Consequently, the celebrated Sinkhorn/iterative scaling\nalgorithm for multi-marginal optimal transport can be leveraged together with\nthe standard belief propagation algorithm to establish an efficient inference\nscheme which we call Sinkhorn belief propagation (SBP). We further specialize\nthe SBP algorithm to cases associated with hidden Markov models due to their\nsignificance in control and estimation. We demonstrate the performance of our\nalgorithm on applications such as inferring population flow from aggregate\nobservations. We also show that in the special case where the observations are\ngenerated by a single individual, our algorithm naturally reduces to the\nstandard belief propagation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 03:12:20 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 00:35:30 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Singh", "Rahul", ""], ["Haasler", "Isabel", ""], ["Zhang", "Qinsheng", ""], ["Karlsson", "Johan", ""], ["Chen", "Yongxin", ""]]}, {"id": "2003.13964", "submitter": "Sukmin Yun", "authors": "Sukmin Yun, Jongjin Park, Kimin Lee, Jinwoo Shin", "title": "Regularizing Class-wise Predictions via Self-knowledge Distillation", "comments": "Accepted to CVPR 2020. Code is available at\n  https://github.com/alinlab/cs-kd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with millions of parameters may suffer from poor\ngeneralization due to overfitting. To mitigate the issue, we propose a new\nregularization method that penalizes the predictive distribution between\nsimilar samples. In particular, we distill the predictive distribution between\ndifferent samples of the same label during training. This results in\nregularizing the dark knowledge (i.e., the knowledge on wrong predictions) of a\nsingle network (i.e., a self-knowledge distillation) by forcing it to produce\nmore meaningful and consistent predictions in a class-wise manner.\nConsequently, it mitigates overconfident predictions and reduces intra-class\nvariations. Our experimental results on various image classification tasks\ndemonstrate that the simple yet powerful method can significantly improve not\nonly the generalization ability but also the calibration performance of modern\nconvolutional neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 06:03:51 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 05:28:07 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Yun", "Sukmin", ""], ["Park", "Jongjin", ""], ["Lee", "Kimin", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2003.13969", "submitter": "Mingkui Tan", "authors": "Chendi Rao, Jiezhang Cao, Runhao Zeng, Qi Chen, Huazhu Fu, Yanwu Xu,\n  Mingkui Tan", "title": "A Thorough Comparison Study on Adversarial Attacks and Defenses for\n  Common Thorax Disease Classification in Chest X-rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNNs) have made great progress on automated\ndiagnosis with chest X-rays images. However, DNNs are vulnerable to adversarial\nexamples, which may cause misdiagnoses to patients when applying the DNN based\nmethods in disease detection. Recently, there is few comprehensive studies\nexploring the influence of attack and defense methods on disease detection,\nespecially for the multi-label classification problem. In this paper, we aim to\nreview various adversarial attack and defense methods on chest X-rays. First,\nthe motivations and the mathematical representations of attack and defense\nmethods are introduced in details. Second, we evaluate the influence of several\nstate-of-the-art attack and defense methods for common thorax disease\nclassification in chest X-rays. We found that the attack and defense methods\nhave poor performance with excessive iterations and large perturbations. To\naddress this, we propose a new defense method that is robust to different\ndegrees of perturbations. This study could provide new insights into\nmethodological development for the community.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 06:21:03 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Rao", "Chendi", ""], ["Cao", "Jiezhang", ""], ["Zeng", "Runhao", ""], ["Chen", "Qi", ""], ["Fu", "Huazhu", ""], ["Xu", "Yanwu", ""], ["Tan", "Mingkui", ""]]}, {"id": "2003.13977", "submitter": "Rodrigo de Medrano", "authors": "Rodrigo de Medrano, Jos\\'e L. Aznarte", "title": "A Spatio-Temporal Spot-Forecasting Framework for Urban Traffic\n  Prediction", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": "10.1016/j.asoc.2020.106615", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal forecasting is an open research field whose interest is\ngrowing exponentially. In this work we focus on creating a complex deep neural\nframework for spatio-temporal traffic forecasting with comparatively very good\nperformance and that shows to be adaptable over several spatio-temporal\nconditions while remaining easy to understand and interpret. Our proposal is\nbased on an interpretable attention-based neural network in which several\nmodules are combined in order to capture key spatio-temporal time series\ncomponents. Through extensive experimentation, we show how the results of our\napproach are stable and better than those of other state-of-the-art\nalternatives.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 06:44:34 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 05:26:45 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["de Medrano", "Rodrigo", ""], ["Aznarte", "Jos\u00e9 L.", ""]]}, {"id": "2003.13987", "submitter": "Nora Castner", "authors": "Nora Castner, Thomas K\\\"ubler, Katharina Scheiter, Juilane Richter,\n  Th\\'er\\'ese Eder, Fabian H\\\"uttig, Constanze Keutel, Enkelejda Kasneci", "title": "Deep semantic gaze embedding and scanpath comparison for expertise\n  classification during OPT viewing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling eye movement indicative of expertise behavior is decisive in user\nevaluation. However, it is indisputable that task semantics affect gaze\nbehavior. We present a novel approach to gaze scanpath comparison that\nincorporates convolutional neural networks (CNN) to process scene information\nat the fixation level. Image patches linked to respective fixations are used as\ninput for a CNN and the resulting feature vectors provide the temporal and\nspatial gaze information necessary for scanpath similarity comparison.We\nevaluated our proposed approach on gaze data from expert and novice dentists\ninterpreting dental radiographs using a local alignment similarity score. Our\napproach was capable of distinguishing experts from novices with 93% accuracy\nwhile incorporating the image semantics. Moreover, our scanpath comparison\nusing image patch features has the potential to incorporate task semantics from\na variety of tasks\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 07:00:59 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Castner", "Nora", ""], ["K\u00fcbler", "Thomas", ""], ["Scheiter", "Katharina", ""], ["Richter", "Juilane", ""], ["Eder", "Th\u00e9r\u00e9se", ""], ["H\u00fcttig", "Fabian", ""], ["Keutel", "Constanze", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2003.14021", "submitter": "Juan Manuel Coria", "authors": "Juan M. Coria, Herv\\'e Bredin, Sahar Ghannay, Sophie Rosset", "title": "A Comparison of Metric Learning Loss Functions for End-To-End Speaker\n  Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing popularity of metric learning approaches, very little\nwork has attempted to perform a fair comparison of these techniques for speaker\nverification. We try to fill this gap and compare several metric learning loss\nfunctions in a systematic manner on the VoxCeleb dataset. The first family of\nloss functions is derived from the cross entropy loss (usually used for\nsupervised classification) and includes the congenerous cosine loss, the\nadditive angular margin loss, and the center loss. The second family of loss\nfunctions focuses on the similarity between training samples and includes the\ncontrastive loss and the triplet loss. We show that the additive angular margin\nloss function outperforms all other loss functions in the study, while learning\nmore robust representations. Based on a combination of SincNet trainable\nfeatures and the x-vector architecture, the network used in this paper brings\nus a step closer to a really-end-to-end speaker verification system, when\ncombined with the additive angular margin loss, while still being competitive\nwith the x-vector baseline. In the spirit of reproducible research, we also\nrelease open source Python code for reproducing our results, and share\npretrained PyTorch models on torch.hub that can be used either directly or\nafter fine-tuning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 08:36:07 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Coria", "Juan M.", ""], ["Bredin", "Herv\u00e9", ""], ["Ghannay", "Sahar", ""], ["Rosset", "Sophie", ""]]}, {"id": "2003.14058", "submitter": "Yuan Gao", "authors": "Yuan Gao, Haoping Bai, Zequn Jie, Jiayi Ma, Kui Jia, and Wei Liu", "title": "MTL-NAS: Task-Agnostic Neural Architecture Search towards\n  General-Purpose Multi-Task Learning", "comments": "Accepted to CVPR2020. The first two authors contribute equally", "journal-ref": "IEEE Conference on Computer Vision and Pattern Recognition, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to incorporate neural architecture search (NAS) into\ngeneral-purpose multi-task learning (GP-MTL). Existing NAS methods typically\ndefine different search spaces according to different tasks. In order to adapt\nto different task combinations (i.e., task sets), we disentangle the GP-MTL\nnetworks into single-task backbones (optionally encode the task priors), and a\nhierarchical and layerwise features sharing/fusing scheme across them. This\nenables us to design a novel and general task-agnostic search space, which\ninserts cross-task edges (i.e., feature fusion connections) into fixed\nsingle-task network backbones. Moreover, we also propose a novel single-shot\ngradient-based search algorithm that closes the performance gap between the\nsearched architectures and the final evaluation architecture. This is realized\nwith a minimum entropy regularization on the architecture weights during the\nsearch phase, which makes the architecture weights converge to near-discrete\nvalues and therefore achieves a single model. As a result, our searched model\ncan be directly used for evaluation without (re-)training from scratch. We\nperform extensive experiments using different single-task backbones on various\ntask sets, demonstrating the promising performance obtained by exploiting the\nhierarchical and layerwise features, as well as the desirable generalizability\nto different i) task sets and ii) single-task backbones. The code of our paper\nis available at https://github.com/bhpfelix/MTLNAS.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 09:49:14 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Gao", "Yuan", ""], ["Bai", "Haoping", ""], ["Jie", "Zequn", ""], ["Ma", "Jiayi", ""], ["Jia", "Kui", ""], ["Liu", "Wei", ""]]}, {"id": "2003.14089", "submitter": "Matthieu Geist", "authors": "Nino Vieillard, Tadashi Kozuno, Bruno Scherrer, Olivier Pietquin,\n  R\\'emi Munos, Matthieu Geist", "title": "Leverage the Average: an Analysis of KL Regularization in RL", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent Reinforcement Learning (RL) algorithms making use of Kullback-Leibler\n(KL) regularization as a core component have shown outstanding performance.\nYet, only little is understood theoretically about why KL regularization helps,\nso far. We study KL regularization within an approximate value iteration scheme\nand show that it implicitly averages q-values. Leveraging this insight, we\nprovide a very strong performance bound, the very first to combine two\ndesirable aspects: a linear dependency to the horizon (instead of quadratic)\nand an error propagation term involving an averaging effect of the estimation\nerrors (instead of an accumulation effect). We also study the more general case\nof an additional entropy regularizer. The resulting abstract scheme encompasses\nmany existing RL algorithms. Some of our assumptions do not hold with neural\nnetworks, so we complement this theoretical analysis with an extensive\nempirical study.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 10:55:06 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 13:03:12 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 15:03:00 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 11:46:15 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 14:12:57 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Vieillard", "Nino", ""], ["Kozuno", "Tadashi", ""], ["Scherrer", "Bruno", ""], ["Pietquin", "Olivier", ""], ["Munos", "R\u00e9mi", ""], ["Geist", "Matthieu", ""]]}, {"id": "2003.14093", "submitter": "Harshad Khadilkar", "authors": "Harshad Khadilkar, Tanuja Ganu, Deva P Seetharam", "title": "Optimising Lockdown Policies for Epidemic Control using Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the ongoing Covid-19 pandemic, several reports and studies\nhave attempted to model and predict the spread of the disease. There is also\nintense debate about policies for limiting the damage, both to health and to\nthe economy. On the one hand, the health and safety of the population is the\nprincipal consideration for most countries. On the other hand, we cannot ignore\nthe potential for long-term economic damage caused by strict nation-wide\nlockdowns. In this working paper, we present a quantitative way to compute\nlockdown decisions for individual cities or regions, while balancing health and\neconomic considerations. Furthermore, these policies are learnt automatically\nby the proposed algorithm, as a function of disease parameters (infectiousness,\ngestation period, duration of symptoms, probability of death) and population\ncharacteristics (density, movement propensity). We account for realistic\nconsiderations such as imperfect lockdowns, and show that the policy obtained\nusing reinforcement learning is a viable quantitative approach towards\nlockdowns.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:04:18 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 11:28:25 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Khadilkar", "Harshad", ""], ["Ganu", "Tanuja", ""], ["Seetharam", "Deva P", ""]]}, {"id": "2003.14127", "submitter": "Gerome Vivar", "authors": "Gerome Vivar, Kamilia Mullakaeva, Andreas Zwergal, Nassir Navab, and\n  Seyed-Ahmad Ahmadi", "title": "Peri-Diagnostic Decision Support Through Cost-Efficient Feature\n  Acquisition at Test-Time", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59713-9_55", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis (CADx) algorithms in medicine provide\npatient-specific decision support for physicians. These algorithms are usually\napplied after full acquisition of high-dimensional multimodal examination data,\nand often assume feature-completeness. This, however, is rarely the case due to\nexamination costs, invasiveness, or a lack of indication. A sub-problem in\nCADx, which to our knowledge has received very little attention among the CADx\ncommunity so far, is to guide the physician during the entire peri-diagnostic\nworkflow, including the acquisition stage. We model the following question,\nasked from a physician's perspective: \"Given the evidence collected so far,\nwhich examination should I perform next, in order to achieve the most accurate\nand efficient diagnostic prediction?\". In this work, we propose a novel\napproach which is enticingly simple: use dropout at the input layer, and\nintegrated gradients of the trained network at test-time to attribute feature\nimportance dynamically. We validate and explain the effectiveness of our\nproposed approach using two public medical and two synthetic datasets. Results\nshow that our proposed approach is more cost- and feature-efficient than prior\napproaches and achieves a higher overall accuracy. This directly translates to\nless unnecessary examinations for patients, and a quicker, less costly and more\naccurate decision support for the physician.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 12:00:44 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 12:24:07 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Vivar", "Gerome", ""], ["Mullakaeva", "Kamilia", ""], ["Zwergal", "Andreas", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2003.14162", "submitter": "Daniel Gedon", "authors": "Daniel Gedon, Niklas Wahlstr\\\"om, Thomas B. Sch\\\"on, Lennart Ljung", "title": "Deep State Space Models for Nonlinear System Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep state space models (SSMs) are an actively researched model class for\ntemporal models developed in the deep learning community which have a close\nconnection to classic SSMs. The use of deep SSMs as a black-box identification\nmodel can describe a wide range of dynamics due to the flexibility of deep\nneural networks. Additionally, the probabilistic nature of the model class\nallows the uncertainty of the system to be modelled. In this work a deep SSM\nclass and its parameter learning algorithm are explained in an effort to extend\nthe toolbox of nonlinear identification methods with a deep learning based\nmethod. Six recent deep SSMs are evaluated in a first unified implementation on\nnonlinear system identification benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 12:57:39 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 08:18:02 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 12:34:04 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Gedon", "Daniel", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Ljung", "Lennart", ""]]}, {"id": "2003.14166", "submitter": "Florian Golemo", "authors": "Sai Rajeswar, Fahim Mannan, Florian Golemo, J\\'er\\^ome\n  Parent-L\\'evesque, David Vazquez, Derek Nowrouzezahrai, Aaron Courville", "title": "Pix2Shape: Towards Unsupervised Learning of 3D Scenes from Images using\n  a View-based Representation", "comments": "This is a pre-print of an article published in International Journal\n  of Computer Vision. The final authenticated version is available online at:\n  https://doi.org/10.1007/s11263-020-01322-1", "journal-ref": "International Journal of Computer Vision, (2020), 1-16", "doi": "10.1007/s11263-020-01322-1", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We infer and generate three-dimensional (3D) scene information from a single\ninput image and without supervision. This problem is under-explored, with most\nprior work relying on supervision from, e.g., 3D ground-truth, multiple images\nof a scene, image silhouettes or key-points. We propose Pix2Shape, an approach\nto solve this problem with four components: (i) an encoder that infers the\nlatent 3D representation from an image, (ii) a decoder that generates an\nexplicit 2.5D surfel-based reconstruction of a scene from the latent code (iii)\na differentiable renderer that synthesizes a 2D image from the surfel\nrepresentation, and (iv) a critic network trained to discriminate between\nimages generated by the decoder-renderer and those from a training\ndistribution. Pix2Shape can generate complex 3D scenes that scale with the\nview-dependent on-screen resolution, unlike representations that capture\nworld-space resolution, i.e., voxels or meshes. We show that Pix2Shape learns a\nconsistent scene representation in its encoded latent space and that the\ndecoder can then be applied to this latent representation in order to\nsynthesize the scene from a novel viewpoint. We evaluate Pix2Shape with\nexperiments on the ShapeNet dataset as well as on a novel benchmark we\ndeveloped, called 3D-IQTT, to evaluate models based on their ability to enable\n3d spatial reasoning. Qualitative and quantitative evaluation demonstrate\nPix2Shape's ability to solve scene reconstruction, generation, and\nunderstanding tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 03:01:34 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:22:58 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Rajeswar", "Sai", ""], ["Mannan", "Fahim", ""], ["Golemo", "Florian", ""], ["Parent-L\u00e9vesque", "J\u00e9r\u00f4me", ""], ["Vazquez", "David", ""], ["Nowrouzezahrai", "Derek", ""], ["Courville", "Aaron", ""]]}, {"id": "2003.14210", "submitter": "Valentin Khrulkov", "authors": "Sergey Kolesnikov and Valentin Khrulkov", "title": "Sample Efficient Ensemble Learning with Catalyst.RL", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.00027", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Catalyst.RL, an open-source PyTorch framework for reproducible and\nsample efficient reinforcement learning (RL) research. Main features of\nCatalyst.RL include large-scale asynchronous distributed training, efficient\nimplementations of various RL algorithms and auxiliary tricks, such as n-step\nreturns, value distributions, hyperbolic reinforcement learning, etc. To\ndemonstrate the effectiveness of Catalyst.RL, we applied it to a physics-based\nreinforcement learning challenge \"NeurIPS 2019: Learn to Move -- Walk Around\"\nwith the objective to build a locomotion controller for a human musculoskeletal\nmodel. The environment is computationally expensive, has a high-dimensional\ncontinuous action space and is stochastic. Our team took the 2nd place,\ncapitalizing on the ability of Catalyst.RL to train high-quality and\nsample-efficient RL agents in only a few hours of training time. The\nimplementation along with experiments is open-sourced so results can be\nreproduced and novel ideas tried out.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 12:45:35 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 22:17:13 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kolesnikov", "Sergey", ""], ["Khrulkov", "Valentin", ""]]}, {"id": "2003.14250", "submitter": "Joshua Agterberg", "authors": "Joshua Agterberg, Minh Tang, Carey E. Priebe", "title": "On Two Distinct Sources of Nonidentifiability in Latent Position Random\n  Graph Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two separate and distinct sources of nonidentifiability arise naturally in\nthe context of latent position random graph models, though neither are unique\nto this setting. In this paper we define and examine these two\nnonidentifiabilities, dubbed subspace nonidentifiability and model-based\nnonidentifiability, in the context of random graph inference. We give examples\nwhere each type of nonidentifiability comes into play, and we show how in\ncertain settings one need worry about one or the other type of\nnonidentifiability. Then, we characterize the limit for model-based\nnonidentifiability both with and without subspace nonidentifiability. We\nfurther obtain additional limiting results for covariances and $U$-statistics\nof stochastic block models and generalized random dot product graphs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:41:02 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Agterberg", "Joshua", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2003.14257", "submitter": "Artur Sokolovsky", "authors": "A. Sokolovsky, T. Gross, J. Bacardit", "title": "Is it feasible to detect FLOSS version release events from textual\n  messages? A case study on Stack Overflow", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0246464", "report-no": null, "categories": "cs.SE cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic Detection and Tracking (TDT) is a very active research question within\nthe area of text mining, generally applied to news feeds and Twitter datasets,\nwhere topics and events are detected. The notion of \"event\" is broad, but\ntypically it applies to occurrences that can be detected from a single post or\na message. Little attention has been drawn to what we call \"micro-events\",\nwhich, due to their nature, cannot be detected from a single piece of textual\ninformation. The study investigates the feasibility of micro-event detection on\ntextual data using a sample of messages from the Stack Overflow Q&A platform\nand Free/Libre Open Source Software (FLOSS) version releases from Libraries.io\ndataset. We build pipelines for detection of micro-events using three different\nestimators whose parameters are optimized using a grid search approach. We\nconsider two feature spaces: LDA topic modeling with sentiment analysis, and\nhSBM topics with sentiment analysis. The feature spaces are optimized using the\nrecursive feature elimination with cross validation (RFECV) strategy.\n  In our experiments we investigate whether there is a characteristic change in\nthe topics distribution or sentiment features before or after micro-events take\nplace and we thoroughly evaluate the capacity of each variant of our analysis\npipeline to detect micro-events. Additionally, we perform a detailed\nstatistical analysis of the models, including influential cases, variance\ninflation factors, validation of the linearity assumption, pseudo R squared\nmeasures and no-information rate. Finally, in order to study limits of\nmicro-event detection, we design a method for generating micro-event synthetic\ndatasets with similar properties to the real-world data, and use them to\nidentify the micro-event detectability threshold for each of the evaluated\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:55:38 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 10:50:58 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 12:49:35 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Sokolovsky", "A.", ""], ["Gross", "T.", ""], ["Bacardit", "J.", ""]]}, {"id": "2003.14263", "submitter": "Paula Gordaliza", "authors": "Philippe Besse, Eustasio del Barrio, Paula Gordaliza, Jean-Michel\n  Loubes and Laurent Risser", "title": "A survey of bias in Machine Learning through the prism of Statistical\n  Parity for the Adult Data Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications based on Machine Learning models have now become an\nindispensable part of the everyday life and the professional world. A critical\nquestion then recently arised among the population: Do algorithmic decisions\nconvey any type of discrimination against specific groups of population or\nminorities? In this paper, we show the importance of understanding how a bias\ncan be introduced into automatic decisions. We first present a mathematical\nframework for the fair learning problem, specifically in the binary\nclassification setting. We then propose to quantify the presence of bias by\nusing the standard Disparate Impact index on the real and well-known Adult\nincome data set. Finally, we check the performance of different approaches\naiming to reduce the bias in binary classification outcomes. Importantly, we\nshow that some intuitive methods are ineffective. This sheds light on the fact\ntrying to make fair machine learning models may be a particularly challenging\ntask, in particular when the training observations contain a bias.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:48:36 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 11:16:10 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Besse", "Philippe", ""], ["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""], ["Risser", "Laurent", ""]]}, {"id": "2003.14285", "submitter": "Liam Hiley BSc", "authors": "Liam Hiley and Alun Preece and Yulia Hicks and Supriyo Chakraborty and\n  Prudhvi Gurram and Richard Tomsett", "title": "Explaining Motion Relevance for Activity Recognition in Video Deep\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A small subset of explainability techniques developed initially for image\nrecognition models has recently been applied for interpretability of 3D\nConvolutional Neural Network models in activity recognition tasks. Much like\nthe models themselves, the techniques require little or no modification to be\ncompatible with 3D inputs. However, these explanation techniques regard spatial\nand temporal information jointly. Therefore, using such explanation techniques,\na user cannot explicitly distinguish the role of motion in a 3D model's\ndecision. In fact, it has been shown that these models do not appropriately\nfactor motion information into their decision. We propose a selective relevance\nmethod for adapting the 2D explanation techniques to provide motion-specific\nexplanations, better aligning them with the human understanding of motion as\nconceptually separate from static spatial features. We demonstrate the utility\nof our method in conjunction with several widely-used 2D explanation methods,\nand show that it improves explanation selectivity for motion. Our results show\nthat the selective relevance method can not only provide insight on the role\nplayed by motion in the model's decision -- in effect, revealing and\nquantifying the model's spatial bias -- but the method also simplifies the\nresulting explanations for human consumption.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 15:19:04 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Hiley", "Liam", ""], ["Preece", "Alun", ""], ["Hicks", "Yulia", ""], ["Chakraborty", "Supriyo", ""], ["Gurram", "Prudhvi", ""], ["Tomsett", "Richard", ""]]}, {"id": "2003.14286", "submitter": "Nicolas Donati", "authors": "Nicolas Donati and Abhishek Sharma and Maks Ovsjanikov", "title": "Deep Geometric Functional Maps: Robust Feature Learning for Shape\n  Correspondence", "comments": "main paper 8 pages, supplementary 5 pages 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel learning-based approach for computing correspondences\nbetween non-rigid 3D shapes. Unlike previous methods that either require\nextensive training data or operate on handcrafted input descriptors and thus\ngeneralize poorly across diverse datasets, our approach is both accurate and\nrobust to changes in shape structure. Key to our method is a feature-extraction\nnetwork that learns directly from raw shape geometry, combined with a novel\nregularized map extraction layer and loss, based on the functional map\nrepresentation. We demonstrate through extensive experiments in challenging\nshape matching scenarios that our method can learn from less training data than\nexisting supervised approaches and generalizes significantly better than\ncurrent descriptor-based learning methods. Our source code is available at:\nhttps://github.com/LIX-shape-analysis/GeomFmaps.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 15:20:17 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Donati", "Nicolas", ""], ["Sharma", "Abhishek", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2003.14297", "submitter": "Idan Azuri", "authors": "Idan Azuri, Daphna Weinshall", "title": "Generative Latent Implicit Conditional Optimization when Learning from\n  Small Sample", "comments": "Published at ICPR 2020", "journal-ref": "Proc. ICPR, January 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the long-standing problem of learning from a small sample, to\nwhich end we propose a novel method called GLICO (Generative Latent Implicit\nConditional Optimization). GLICO learns a mapping from the training examples to\na latent space and a generator that generates images from vectors in the latent\nspace. Unlike most recent works, which rely on access to large amounts of\nunlabeled data, GLICO does not require access to any additional data other than\nthe small set of labeled points. In fact, GLICO learns to synthesize completely\nnew samples for every class using as little as 5 or 10 examples per class, with\nas few as 10 such classes without imposing any prior. GLICO is then used to\naugment the small training set while training a classifier on the small sample.\nTo this end, our proposed method samples the learned latent space using\nspherical interpolation, and generates new examples using the trained\ngenerator. Empirical results show that the new sampled set is diverse enough,\nleading to improvement in image classification in comparison with the state of\nthe art, when trained on small samples obtained from CIFAR-10, CIFAR-100, and\nCUB-200.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 15:38:45 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:24:44 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 10:51:13 GMT"}, {"version": "v4", "created": "Sun, 18 Oct 2020 13:57:09 GMT"}, {"version": "v5", "created": "Tue, 15 Dec 2020 12:01:47 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Azuri", "Idan", ""], ["Weinshall", "Daphna", ""]]}, {"id": "2003.14304", "submitter": "Eric L. Manibardo", "authors": "Eric L. Manibardo, Ibai La\\~na, Jesus L. Lobo and Javier Del Ser", "title": "New Perspectives on the Use of Online Learning for Congestion Level\n  Prediction over Traffic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on classification over time series data. When a time series\nis generated by non-stationary phenomena, the pattern relating the series with\nthe class to be predicted may evolve over time (concept drift). Consequently,\npredictive models aimed to learn this pattern may become eventually obsolete,\nhence failing to sustain performance levels of practical use. To overcome this\nmodel degradation, online learning methods incrementally learn from new data\nsamples arriving over time, and accommodate eventual changes along the data\nstream by implementing assorted concept drift strategies. In this manuscript we\nelaborate on the suitability of online learning methods to predict the road\ncongestion level based on traffic speed time series data. We draw interesting\ninsights on the performance degradation when the forecasting horizon is\nincreased. As opposed to what is done in most literature, we provide evidence\nof the importance of assessing the distribution of classes over time before\ndesigning and tuning the learning model. This previous exercise may give a hint\nof the predictability of the different congestion levels under target.\nExperimental results are discussed over real traffic speed data captured by\ninductive loops deployed over Seattle (USA). Several online learning methods\nare analyzed, from traditional incremental learning algorithms to more\nelaborated deep learning models. As shown by the reported results, when\nincreasing the prediction horizon, the performance of all models degrade\nseverely due to the distribution of classes along time, which supports our\nclaim about the importance of analyzing this distribution prior to the design\nof the model.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 09:44:57 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Manibardo", "Eric L.", ""], ["La\u00f1a", "Ibai", ""], ["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""]]}, {"id": "2003.14310", "submitter": "Abhinandan Dalal", "authors": "Arindam Roy Chowdhury, Abhinandan Dalal and Shubhajit Sen", "title": "Accelerography: Feasibility of Gesture Typing using Accelerometer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to look into the feasibility of constructing alphabets\nusing gestures. The main idea is to construct gestures, that are easy to\nremember, not cumbersome to reproduce and easily identifiable. We construct\ngestures for the entire English alphabet and provide an algorithm to identify\nthe gestures, even when they are constructed continuously. We tackle the\nproblem statistically, taking into account the problem of randomness in the\nhand movement gestures of users, and achieve an average accuracy of 97.33% with\nthe entire English alphabet.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:12:46 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Chowdhury", "Arindam Roy", ""], ["Dalal", "Abhinandan", ""], ["Sen", "Shubhajit", ""]]}, {"id": "2003.14328", "submitter": "Valentin Stanev G.", "authors": "Haotong Liang, Valentin Stanev, A. Gilad Kusne, Ichiro Takeuchi", "title": "CRYSPNet: Crystal Structure Predictions via Neural Network", "comments": "30 pages, 12 figures, 5 tables", "journal-ref": "Phys. Rev. Materials 4, 123802 (2020)", "doi": "10.1103/PhysRevMaterials.4.123802", "report-no": null, "categories": "cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure is the most basic and important property of crystalline solids; it\ndetermines directly or indirectly most materials characteristics. However,\npredicting crystal structure of solids remains a formidable and not fully\nsolved problem. Standard theoretical tools for this task are computationally\nexpensive and at times inaccurate. Here we present an alternative approach\nutilizing machine learning for crystal structure prediction. We developed a\ntool called Crystal Structure Prediction Network (CRYSPNet) that can predict\nthe Bravais lattice, space group, and lattice parameters of an inorganic\nmaterial based only on its chemical composition. CRYSPNet consists of a series\nof neural network models, using as inputs predictors aggregating the properties\nof the elements constituting the compound. It was trained and validated on more\nthan 100,000 entries from the Inorganic Crystal Structure Database. The tool\ndemonstrates robust predictive capability and outperforms alternative\nstrategies by a large margin. Made available to the public (at\nhttps://github.com/AuroraLHT/cryspnet), it can be used both as an independent\nprediction engine or as a method to generate candidate structures for further\ncomputational and/or experimental validation.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:05:18 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Liang", "Haotong", ""], ["Stanev", "Valentin", ""], ["Kusne", "A. Gilad", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2003.14366", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski and Ali H. Sayed", "title": "Second-Order Guarantees in Centralized, Federated and Decentralized\n  Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advances in data collection and processing capabilities have allowed\nfor the use of increasingly complex models that give rise to nonconvex\noptimization problems. These formulations, however, can be arbitrarily\ndifficult to solve in general, in the sense that even simply verifying that a\ngiven point is a local minimum can be NP-hard [1]. Still, some relatively\nsimple algorithms have been shown to lead to surprisingly good empirical\nresults in many contexts of interest. Perhaps the most prominent example is the\nsuccess of the backpropagation algorithm for training neural networks. Several\nrecent works have pursued rigorous analytical justification for this phenomenon\nby studying the structure of the nonconvex optimization problems and\nestablishing that simple algorithms, such as gradient descent and its\nvariations, perform well in converging towards local minima and avoiding\nsaddle-points. A key insight in these analyses is that gradient perturbations\nplay a critical role in allowing local descent algorithms to efficiently\ndistinguish desirable from undesirable stationary points and escape from the\nlatter. In this article, we cover recent results on second-order guarantees for\nstochastic first-order optimization algorithms in centralized, federated, and\ndecentralized architectures.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:54:22 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2003.14398", "submitter": "Wenbo Gao", "authors": "Wenbo Gao and Laura Graesser and Krzysztof Choromanski and Xingyou\n  Song and Nevena Lazic and Pannag Sanketi and Vikas Sindhwani and Navdeep\n  Jaitly", "title": "Robotic Table Tennis with Model-Free Reinforcement Learning", "comments": "V2: new URL of supplementary video. 8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-free algorithm for learning efficient policies capable of\nreturning table tennis balls by controlling robot joints at a rate of 100Hz. We\ndemonstrate that evolutionary search (ES) methods acting on CNN-based policy\narchitectures for non-visual inputs and convolving across time learn compact\ncontrollers leading to smooth motions. Furthermore, we show that with\nappropriately tuned curriculum learning on the task and rewards, policies are\ncapable of developing multi-modal styles, specifically forehand and backhand\nstroke, whilst achieving 80\\% return rate on a wide range of ball throws. We\nobserve that multi-modality does not require any architectural priors, such as\nmulti-head architectures or hierarchical policies.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:46:43 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 20:18:07 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Gao", "Wenbo", ""], ["Graesser", "Laura", ""], ["Choromanski", "Krzysztof", ""], ["Song", "Xingyou", ""], ["Lazic", "Nevena", ""], ["Sanketi", "Pannag", ""], ["Sindhwani", "Vikas", ""], ["Jaitly", "Navdeep", ""]]}]