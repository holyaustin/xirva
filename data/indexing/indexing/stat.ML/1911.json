[{"id": "1911.00002", "submitter": "Pablo Moreno-Mu\\~noz", "authors": "Pablo Moreno-Mu\\~noz, Antonio Art\\'es-Rodr\\'iguez and Mauricio A.\n  \\'Alvarez", "title": "Continual Multi-task Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of continual learning in multi-task Gaussian process\n(GP) models for handling sequential input-output observations. Our approach\nextends the existing prior-posterior recursion of online Bayesian inference,\ni.e.\\ past posterior discoveries become future prior beliefs, to the infinite\nfunctional space setting of GP. For a reason of scalability, we introduce\nvariational inference together with an sparse approximation based on inducing\ninputs. As a consequence, we obtain tractable continual lower-bounds where two\nnovel Kullback-Leibler (KL) divergences intervene in a natural way. The key\ntechnical property of our method is the recursive reconstruction of conditional\nGP priors conditioned on the variational parameters learned so far. To achieve\nthis goal, we introduce a novel factorization of past variational\ndistributions, where the predictive GP equation propagates the posterior\nuncertainty forward. We then demonstrate that it is possible to derive GP\nmodels over many types of sequential observations, either discrete or\ncontinuous and amenable to stochastic optimization. The continual inference\napproach is also applicable to scenarios where potential multi-channel or\nheterogeneous observations might appear. Extensive experiments demonstrate that\nthe method is fully scalable, shows a reliable performance and is robust to\nuncertainty error propagation over a plenty of synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:49:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1911.00025", "submitter": "Raymond A. Yeh", "authors": "Iou-Jen Liu, Raymond A. Yeh, Alexander G. Schwing", "title": "PIC: Permutation Invariant Critic for Multi-Agent Deep Reinforcement\n  Learning", "comments": "Accepted to CORL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample efficiency and scalability to a large number of agents are two\nimportant goals for multi-agent reinforcement learning systems. Recent works\ngot us closer to those goals, addressing non-stationarity of the environment\nfrom a single agent's perspective by utilizing a deep net critic which depends\non all observations and actions. The critic input concatenates agent\nobservations and actions in a user-specified order. However, since deep nets\naren't permutation invariant, a permuted input changes the critic output\ndespite the environment remaining identical. To avoid this inefficiency, we\npropose a 'permutation invariant critic' (PIC), which yields identical output\nirrespective of the agent permutation. This consistent representation enables\nour model to scale to 30 times more agents and to achieve improvements of test\nepisode reward between 15% to 50% on the challenging multi-agent particle\nenvironment (MPE).\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:04:42 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Liu", "Iou-Jen", ""], ["Yeh", "Raymond A.", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1911.00030", "submitter": "Saurabh Sahu", "authors": "Saurabh Sahu, Rahul Gupta, Carol Espy-Wilson", "title": "Modeling Feature Representations for Affective Speech using Generative\n  Adversarial Networks", "comments": null, "journal-ref": "TAFFC-2019-08-0222.R2", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition is a classic field of research with a typical setup\nextracting features and feeding them through a classifier for prediction. On\nthe other hand, generative models jointly capture the distributional\nrelationship between emotions and the feature profiles. Relatively recently,\nGenerative Adversarial Networks (GANs) have surfaced as a new class of\ngenerative models and have shown considerable success in modeling distributions\nin the fields of computer vision and natural language understanding. In this\nwork, we experiment with variants of GAN architectures to generate feature\nvectors corresponding to an emotion in two ways: (i) A generator is trained\nwith samples from a mixture prior. Each mixture component corresponds to an\nemotional class and can be sampled to generate features from the corresponding\nemotion. (ii) A one-hot vector corresponding to an emotion can be explicitly\nused to generate the features. We perform analysis on such models and also\npropose different metrics used to measure the performance of the GAN models in\ntheir ability to generate realistic synthetic samples. Apart from evaluation on\na given dataset of interest, we perform a cross-corpus study where we study the\nutility of the synthetic samples as additional training data in low resource\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:09:45 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Sahu", "Saurabh", ""], ["Gupta", "Rahul", ""], ["Espy-Wilson", "Carol", ""]]}, {"id": "1911.00038", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Keith Bonawitz, Peter Kairouz, Daniel Ramage, Ziteng\n  Sun", "title": "Context-Aware Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a strong notion of privacy for individual\nusers that often comes at the expense of a significant drop in utility. The\nclassical definition of LDP assumes that all elements in the data domain are\nequally sensitive. However, in many applications, some symbols are more\nsensitive than others. This work proposes a context-aware framework of local\ndifferential privacy that allows a privacy designer to incorporate the\napplication's context into the privacy definition. For binary data domains, we\nprovide a universally optimal privatization scheme and highlight its\nconnections to Warner's randomized response (RR) and Mangat's improved\nresponse. Motivated by geolocation and web search applications, for $k$-ary\ndata domains, we consider two special cases of context-aware LDP:\nblock-structured LDP and high-low LDP. We study discrete distribution\nestimation and provide communication-efficient, sample-optimal schemes and\ninformation-theoretic lower bounds for both models. We show that using\ncontextual information can require fewer samples than classical LDP to achieve\nthe same accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:15:33 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 23:00:22 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Acharya", "Jayadev", ""], ["Bonawitz", "Keith", ""], ["Kairouz", "Peter", ""], ["Ramage", "Daniel", ""], ["Sun", "Ziteng", ""]]}, {"id": "1911.00055", "submitter": "Ali Sadeghian", "authors": "Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, Daisy Zhe Wang", "title": "DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning probabilistic logical rules\nfor inductive and interpretable link prediction. Despite the importance of\ninductive link prediction, most previous works focused on transductive link\nprediction and cannot manage previously unseen entities. Moreover, they are\nblack-box models that are not easily explainable for humans. We propose DRUM, a\nscalable and differentiable approach for mining first-order logical rules from\nknowledge graphs which resolves these problems. We motivate our method by\nmaking a connection between learning confidence scores for each rule and\nlow-rank tensor approximation. DRUM uses bidirectional RNNs to share useful\ninformation across the tasks of learning rules for different relations. We also\nempirically demonstrate the efficiency of DRUM over existing rule mining\nmethods for inductive link prediction on a variety of benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:51:33 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sadeghian", "Ali", ""], ["Armandpour", "Mohammadreza", ""], ["Ding", "Patrick", ""], ["Wang", "Daisy Zhe", ""]]}, {"id": "1911.00061", "submitter": "Yuval Heffetz", "authors": "Yuval Heffetz, Roman Vainstein, Gilad Katz, Lior Rokach", "title": "DeepLine: AutoML Tool for Pipelines Generation using Deep Reinforcement\n  Learning and Hierarchical Actions Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning (AutoML) is an area of research aimed at\nautomating machine learning (ML) activities that currently require human\nexperts. One of the most challenging tasks in this field is the automatic\ngeneration of end-to-end ML pipelines: combining multiple types of ML\nalgorithms into a single architecture used for end-to-end analysis of\npreviously-unseen data. This task has two challenging aspects: the first is the\nneed to explore a large search space of algorithms and pipeline architectures.\nThe second challenge is the computational cost of training and evaluating\nmultiple pipelines. In this study we present DeepLine, a reinforcement learning\nbased approach for automatic pipeline generation. Our proposed approach\nutilizes an efficient representation of the search space and leverages past\nknowledge gained from previously-analyzed datasets to make the problem more\ntractable. Additionally, we propose a novel hierarchical-actions algorithm that\nserves as a plugin, mediating the environment-agent interaction in deep\nreinforcement learning problems. The plugin significantly speeds up the\ntraining process of our model. Evaluation on 56 datasets shows that DeepLine\noutperforms state-of-the-art approaches both in accuracy and in computational\ncost.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:06:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Heffetz", "Yuval", ""], ["Vainstein", "Roman", ""], ["Katz", "Gilad", ""], ["Rokach", "Lior", ""]]}, {"id": "1911.00068", "submitter": "Curtis Northcutt", "authors": "Curtis G. Northcutt, Lu Jiang, Isaac L. Chuang", "title": "Confident Learning: Estimating Uncertainty in Dataset Labels", "comments": "Published in Journal of Artificial Intelligence Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research (JAIR) (2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning exists in the context of data, yet notions of confidence typically\nfocus on model predictions, not label quality. Confident learning (CL) is an\nalternative approach which focuses instead on label quality by characterizing\nand identifying label errors in datasets, based on the principles of pruning\nnoisy data, counting with probabilistic thresholds to estimate noise, and\nranking examples to train with confidence. Whereas numerous studies have\ndeveloped these principles independently, here, we combine them, building on\nthe assumption of a class-conditional noise process to directly estimate the\njoint distribution between noisy (given) labels and uncorrupted (unknown)\nlabels. This results in a generalized CL which is provably consistent and\nexperimentally performant. We present sufficient conditions where CL exactly\nfinds label errors, and show CL performance exceeding seven recent competitive\napproaches for learning with noisy labels on the CIFAR dataset. Uniquely, the\nCL framework is not coupled to a specific data modality or model (e.g., we use\nCL to find several label errors in the presumed error-free MNIST dataset and\nimprove sentiment classification on text data in Amazon Reviews). We also\nemploy CL on ImageNet to quantify ontological class overlap (e.g., estimating\n645 \"missile\" images are mislabeled as their parent class \"projectile\"), and\nmoderately increase model accuracy (e.g., for ResNet) by cleaning data prior to\ntraining. These results are replicable using the open-source cleanlab release.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:26:33 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 22:16:56 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 08:12:20 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2021 23:56:53 GMT"}, {"version": "v5", "created": "Thu, 8 Apr 2021 20:00:05 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Northcutt", "Curtis G.", ""], ["Jiang", "Lu", ""], ["Chuang", "Isaac L.", ""]]}, {"id": "1911.00077", "submitter": "Alexandros Iosifidis", "authors": "William Lund Sommer and Alexandros Iosifidis", "title": "Text-to-image synthesis method evaluation based on visual patterns", "comments": "11 pages, including supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly used evaluation metric for text-to-image synthesis is the\nInception score (IS) \\cite{inceptionscore}, which has been shown to be a\nquality metric that correlates well with human judgment. However, IS does not\nreveal properties of the generated images indicating the ability of a\ntext-to-image synthesis method to correctly convey semantics of the input text\ndescriptions. In this paper, we introduce an evaluation metric and a visual\nevaluation method allowing for the simultaneous estimation of the realism,\nvariety and semantic accuracy of generated images. The proposed method uses a\npre-trained Inception network \\cite{inceptionnet} to produce high dimensional\nrepresentations for both real and generated images. These image representations\nare then visualized in a $2$-dimensional feature space defined by the\nt-distributed Stochastic Neighbor Embedding (t-SNE) \\cite{tsne}. Visual\nconcepts are determined by clustering the real image representations, and are\nsubsequently used to evaluate the similarity of the generated images to the\nreal ones by classifying them to the closest visual concept. The resulting\nclassification accuracy is shown to be a effective gauge for the semantic\naccuracy of text-to-image synthesis methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:50:42 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sommer", "William Lund", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1911.00081", "submitter": "Hao-Chih Lee", "authors": "Hao-Chih Lee, Matteo Danieletto, Riccardo Miotto, Sarah T. Cherng and\n  Joel T. Dudley", "title": "Scaling structural learning with NO-BEARS to infer causal transcriptome\n  networks", "comments": "Preprint of an article submitted for consideration in Pacific\n  Symposium on Biocomputing copyright 2019 World Scientific Publishing Co.,\n  Singapore, http://psb.stanford.edu/http://psb.stanford.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Constructing gene regulatory networks is a critical step in revealing disease\nmechanisms from transcriptomic data. In this work, we present NO-BEARS, a novel\nalgorithm for estimating gene regulatory networks. The NO-BEARS algorithm is\nbuilt on the basis of the NOTEARS algorithm with two improvements. First, we\npropose a new constraint and its fast approximation to reduce the computational\ncost of the NO-TEARS algorithm. Next, we introduce a polynomial regression loss\nto handle non-linearity in gene expressions. Our implementation utilizes modern\nGPU computation that can decrease the time of hours-long CPU computation to\nseconds. Using synthetic data, we demonstrate improved performance, both in\nprocessing time and accuracy, on inferring gene regulatory networks from gene\nexpression data.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:52:18 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lee", "Hao-Chih", ""], ["Danieletto", "Matteo", ""], ["Miotto", "Riccardo", ""], ["Cherng", "Sarah T.", ""], ["Dudley", "Joel T.", ""]]}, {"id": "1911.00089", "submitter": "Michael Hauser", "authors": "Yiwei Fu, Samer Saab Jr, Asok Ray and Michael Hauser", "title": "A Dynamically Controlled Recurrent Neural Network for Modeling Dynamical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel neural network architecture, called the\nDynamically Controlled Recurrent Neural Network (DCRNN), specifically designed\nto model dynamical systems that are governed by ordinary differential equations\n(ODEs). The current state vectors of these types of dynamical systems only\ndepend on their state-space models, along with the respective inputs and\ninitial conditions. Long Short-Term Memory (LSTM) networks, which have proven\nto be very effective for memory-based tasks, may fail to model physical\nprocesses as they tend to memorize, rather than learn how to capture the\ninformation on the underlying dynamics. The proposed DCRNN includes learnable\nskip-connections across previously hidden states, and introduces a\nregularization term in the loss function by relying on Lyapunov stability\ntheory. The regularizer enables the placement of eigenvalues of the transfer\nfunction induced by the DCRNN to desired values, thereby acting as an internal\ncontroller for the hidden state trajectory. The results show that, for\nforecasting a chaotic dynamical system, the DCRNN outperforms the LSTM in $100$\nout of $100$ randomized experiments by reducing the mean squared error of the\nLSTM's forecasting by $80.0\\% \\pm 3.0\\%$.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 20:22:38 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Fu", "Yiwei", ""], ["Saab", "Samer", "Jr"], ["Ray", "Asok", ""], ["Hauser", "Michael", ""]]}, {"id": "1911.00103", "submitter": "Haibin Chang", "authors": "Nanzhe Wang, Dongxiao Zhang, Haibin Chang, Heng Li", "title": "Deep Learning of Subsurface Flow via Theory-guided Neural Network", "comments": null, "journal-ref": "Journal of Hydrology, 2020, 584, 124700", "doi": "10.1016/j.jhydrol.2020.124700", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active researches are currently being performed to incorporate the wealth of\nscientific knowledge into data-driven approaches (e.g., neural networks) in\norder to improve the latter's effectiveness. In this study, the Theory-guided\nNeural Network (TgNN) is proposed for deep learning of subsurface flow. In the\nTgNN, as supervised learning, the neural network is trained with available\nobservations or simulation data while being simultaneously guided by theory\n(e.g., governing equations, other physical constraints, engineering controls,\nand expert knowledge) of the underlying problem. The TgNN can achieve higher\naccuracy than the ordinary Artificial Neural Network (ANN) because the former\nprovides physically feasible predictions and can be more readily generalized\nbeyond the regimes covered with the training data. Furthermore, the TgNN model\nis proposed for subsurface flow with heterogeneous model parameters. Several\nnumerical cases of two-dimensional transient saturated flow are introduced to\ntest the performance of the TgNN. In the learning process, the loss function\ncontains data mismatch, as well as PDE constraint, engineering control, and\nexpert knowledge. After obtaining the parameters of the neural network by\nminimizing the loss function, a TgNN model is built that not only fits the\ndata, but also adheres to physical/engineering constraints. Predicting the\nfuture response can be easily realized by the TgNN model. In addition, the TgNN\nmodel is tested in more complicated scenarios, such as prediction with changed\nboundary conditions, learning from noisy data or outliers, transfer learning,\nand engineering controls. Numerical results demonstrate that the TgNN model\nachieves much better predictability, reliability, and generalizability than ANN\nmodels due to the physical/engineering constraints in the former.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 08:49:57 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Wang", "Nanzhe", ""], ["Zhang", "Dongxiao", ""], ["Chang", "Haibin", ""], ["Li", "Heng", ""]]}, {"id": "1911.00104", "submitter": "Nabeel Seedat", "authors": "Nabeel Seedat and Christopher Kanan", "title": "Towards calibrated and scalable uncertainty representations for neural\n  networks", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019): 4th workshop on Bayesian Deep Learning, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications it is critical to know the uncertainty of a neural\nnetwork's predictions. While a variety of neural network parameter estimation\nmethods have been proposed for uncertainty estimation, they have not been\nrigorously compared across uncertainty measures. We assess four of these\nparameter estimation methods to calibrate uncertainty estimation using four\ndifferent uncertainty measures: entropy, mutual information, aleatoric\nuncertainty and epistemic uncertainty. We evaluate the calibration of these\nparameter estimation methods using expected calibration error. Additionally, we\npropose a novel method of neural network parameter estimation called RECAST,\nwhich combines cosine annealing with warm restarts with Stochastic Gradient\nLangevin Dynamics, capturing more diverse parameter distributions. When\nbenchmarked against mutilated image data, we show that RECAST is\nwell-calibrated and when combined with predictive entropy and epistemic\nuncertainty it offers the best calibrated measure of uncertainty when compared\nto recent methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 02:29:55 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 01:30:14 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 02:19:35 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Seedat", "Nabeel", ""], ["Kanan", "Christopher", ""]]}, {"id": "1911.00108", "submitter": "Roman Vainshtein", "authors": "Doron Laadan, Roman Vainshtein, Yarden Curiel, Gilad Katz, Lior Rokach", "title": "RankML: a Meta Learning-Based Approach for Pre-Ranking Machine Learning\n  Pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of digital data has created multiple opportunities for\norganizations and individuals to leverage machine learning (ML) to transform\nthe way they operate. However, the shortage of experts in the field of machine\nlearning -- data scientists -- is often a setback to the use of ML. In an\nattempt to alleviate this shortage, multiple approaches for the automation of\nmachine learning have been proposed in recent years. While these approaches are\neffective, they often require a great deal of time and computing resources. In\nthis study, we propose RankML, a meta-learning based approach for predicting\nthe performance of whole machine learning pipelines. Given a previously-unseen\ndataset, a performance metric, and a set of candidate pipelines, RankML\nimmediately produces a ranked list of all pipelines based on their predicted\nperformance. Extensive evaluation on 244 datasets, both in regression and\nclassification tasks, shows that our approach either outperforms or is\ncomparable to state-of-the-art, computationally heavy approaches while\nrequiring a fraction of the time and computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:05:24 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 16:03:39 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Laadan", "Doron", ""], ["Vainshtein", "Roman", ""], ["Curiel", "Yarden", ""], ["Katz", "Gilad", ""], ["Rokach", "Lior", ""]]}, {"id": "1911.00149", "submitter": "Michael Churchill", "authors": "R.M. Churchill and the DIII-D team", "title": "Deep convolutional neural networks for multi-scale time-series\n  classification and application to disruption prediction in fusion devices", "comments": "Accepted at the Second Workshop on Machine Learning and the Physical\n  Sciences (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": "10.1063/1.5144458", "report-no": null, "categories": "physics.plasm-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-scale, mutli-physics nature of fusion plasmas makes predicting\nplasma events challenging. Recent advances in deep convolutional neural network\narchitectures (CNN) utilizing dilated convolutions enable accurate predictions\non sequences which have long-range, multi-scale characteristics, such as the\ntime-series generated by diagnostic instruments observing fusion plasmas. Here\nwe apply this neural network architecture to the popular problem of disruption\nprediction in fusion tokamaks, utilizing raw data from a single diagnostic, the\nElectron Cyclotron Emission imaging (ECEi) diagnostic from the DIII-D tokamak.\nECEi measures a fundamental plasma quantity (electron temperature) with high\ntemporal resolution over the entire plasma discharge, making it sensitive to a\nnumber of potential pre-disruptions markers with different temporal and spatial\nscales. Promising, initial disruption prediction results are obtained training\na deep CNN with large receptive field (~30k), achieving an $F_1$-score of ~91%\non individual time-slices using only the ECEi data.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 23:27:56 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 16:54:04 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Churchill", "R. M.", ""], ["team", "the DIII-D", ""]]}, {"id": "1911.00171", "submitter": "Vinicius G. Goecks", "authors": "Ritwik Bera, Vinicius G. Goecks, Gregory M. Gremillion, John Valasek,\n  and Nicholas R. Waytowich", "title": "PODNet: A Neural Network for Discovery of Plannable Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration has been widely studied in machine learning but\nbecomes challenging when the demonstrated trajectories are unstructured and\nfollow different objectives. This short-paper proposes PODNet, Plannable Option\nDiscovery Network, addressing how to segment an unstructured set of\ndemonstrated trajectories for option discovery. This enables learning from\ndemonstration to perform multiple tasks and plan high-level trajectories based\non the discovered option labels. PODNet combines a custom categorical\nvariational autoencoder, a recurrent option inference network,\noption-conditioned policy network, and option dynamics model in an end-to-end\nlearning architecture. Due to the concurrently trained option-conditioned\npolicy network and option dynamics model, the proposed architecture has\nimplications in multi-task and hierarchical learning, explainable and\ninterpretable artificial intelligence, and applications where the agent is\nrequired to learn only from observations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:09:46 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 07:04:21 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:51:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bera", "Ritwik", ""], ["Goecks", "Vinicius G.", ""], ["Gremillion", "Gregory M.", ""], ["Valasek", "John", ""], ["Waytowich", "Nicholas R.", ""]]}, {"id": "1911.00179", "submitter": "Yifei Wang", "authors": "Yifei Wang, Rui Liu, Yong Chen, Hui Zhangs and Zhiwen Ye", "title": "Regularized Non-negative Spectral Embedding for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Clustering is a popular technique to split data points into groups,\nespecially for complex datasets. The algorithms in the Spectral Clustering\nfamily typically consist of multiple separate stages (such as similarity matrix\nconstruction, low-dimensional embedding, and K-Means clustering as post\nprocessing), which may lead to sub-optimal results because of the possible\nmismatch between different stages. In this paper, we propose an end-to-end\nsingle-stage learning method to clustering called Regularized Non-negative\nSpectral Embedding (RNSE) which extends Spectral Clustering with the adaptive\nlearning of similarity matrix and meanwhile utilizes non-negative constraints\nto facilitate one-step clustering (directly from data points to clustering\nlabels). Two well-founded methods, successive alternating projection and\nstrategic multiplicative update, are employed to work out the quite challenging\noptimization problems in RNSE. Extensive experiments on both synthetic and\nreal-world datasets demonstrate RNSE superior clustering performance to some\nstate-of-the-art competitors.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:52:36 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Wang", "Yifei", ""], ["Liu", "Rui", ""], ["Chen", "Yong", ""], ["Zhangs", "Hui", ""], ["Ye", "Zhiwen", ""]]}, {"id": "1911.00184", "submitter": "Sreelekha Guggilam", "authors": "Sreelekha Guggilam and Syed M. A. Zaidi and Varun Chandola and Abani\n  K. Patra", "title": "Integrated Clustering and Anomaly Detection (INCAD) for Streaming Data\n  (Revised)", "comments": "13 pages; fixes typos in equations 5,6,9,10 on inference using Gibbs\n  sampling", "journal-ref": "ICCS 2019. Lecture Notes in Computer Science, vol 11539. Springer,\n  Cham,", "doi": "10.1007/978-3-030-22747-0_4", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current clustering based anomaly detection methods use scoring schema\nand thresholds to classify anomalies. These methods are often tailored to\ntarget specific data sets with \"known\" number of clusters. The paper provides a\nstreaming clustering and anomaly detection algorithm that does not require\nstrict arbitrary thresholds on the anomaly scores or knowledge of the number of\nclusters while performing probabilistic anomaly detection and clustering\nsimultaneously. This ensures that the cluster formation is not impacted by the\npresence of anomalous data, thereby leading to more reliable definition of\n\"normal vs abnormal\" behavior. The motivations behind developing the INCAD\nmodel and the path that leads to the streaming model is discussed.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 02:27:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Guggilam", "Sreelekha", ""], ["Zaidi", "Syed M. A.", ""], ["Chandola", "Varun", ""], ["Patra", "Abani K.", ""]]}, {"id": "1911.00190", "submitter": "Lucas Mentch", "authors": "Lucas Mentch and Siyu Zhou", "title": "Randomization as Regularization: A Degrees of Freedom Explanation for\n  Random Forest Success", "comments": "To Appear in the Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests remain among the most popular off-the-shelf supervised machine\nlearning tools with a well-established track record of predictive accuracy in\nboth regression and classification settings. Despite their empirical success as\nwell as a bevy of recent work investigating their statistical properties, a\nfull and satisfying explanation for their success has yet to be put forth. Here\nwe aim to take a step forward in this direction by demonstrating that the\nadditional randomness injected into individual trees serves as a form of\nimplicit regularization, making random forests an ideal model in low\nsignal-to-noise ratio (SNR) settings. Specifically, from a model-complexity\nperspective, we show that the mtry parameter in random forests serves much the\nsame purpose as the shrinkage penalty in explicitly regularized regression\nprocedures like lasso and ridge regression. To highlight this point, we design\na randomized linear-model-based forward selection procedure intended as an\nanalogue to tree-based random forests and demonstrate its surprisingly strong\nempirical performance. Numerous demonstrations on both real and synthetic data\nare provided.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 03:13:12 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 07:27:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mentch", "Lucas", ""], ["Zhou", "Siyu", ""]]}, {"id": "1911.00197", "submitter": "Pengfei Zhou", "authors": "Pengfei Zhou, Tianyi Li and Pan Zhang", "title": "Phase transitions and optimal algorithms for semi-supervised\n  classifications on graphs: from belief propagation to graph convolution\n  network", "comments": "18 pages, 21 figures", "journal-ref": "Phys. Rev. Research 2, 033325 (2020)", "doi": "10.1103/PhysRevResearch.2.033325", "report-no": null, "categories": "cond-mat.stat-mech cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform theoretical and algorithmic studies for the problem of clustering\nand semi-supervised classification on graphs with both pairwise relational\ninformation and single-point feature information, upon a joint stochastic block\nmodel for generating synthetic graphs with both edges and node features.\nAsymptotically exact analysis based on the Bayesian inference of the underlying\nmodel are conducted, using the cavity method in statistical physics.\nTheoretically, we identify a phase transition of the generative model, which\nputs fundamental limits on the ability of all possible algorithms in the\nclustering task of the underlying model. Algorithmically, we propose a belief\npropagation algorithm that is asymptotically optimal on the generative model,\nand can be further extended to a belief propagation graph convolution neural\nnetwork (BPGCN) for semi-supervised classification on graphs. For the first\ntime, well-controlled benchmark datasets with asymptotially exact properties\nand optimal solutions could be produced for the evaluation of graph convolution\nneural networks, and for the theoretical understanding of their strengths and\nweaknesses. In particular, on these synthetic benchmark networks we observe\nthat existing graph convolution neural networks are subject to an sparsity\nissue and an ovefitting issue in practice, both of which are successfully\novercome by our BPGCN. Moreover, when combined with classic neural network\nmethods, BPGCN yields extraordinary classification performances on some\nreal-world datasets that have never been achieved before.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 04:27:11 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:55:11 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zhou", "Pengfei", ""], ["Li", "Tianyi", ""], ["Zhang", "Pan", ""]]}, {"id": "1911.00212", "submitter": "Siyu Huang", "authors": "Tao Jin, Siyu Huang, Yingming Li, Zhongfei Zhang", "title": "Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video\n  Captioning", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenging task of video captioning which aims to\ngenerate descriptions for video data. Recently, the attention-based\nencoder-decoder structures have been widely used in video captioning. In\nexisting literature, the attention weights are often built from the information\nof an individual modality, while, the association relationships between\nmultiple modalities are neglected. Motivated by this observation, we propose a\nvideo captioning model with High-Order Cross-Modal Attention (HOCA) where the\nattention weights are calculated based on the high-order correlation tensor to\ncapture the frame-level cross-modal interaction of different modalities\nsufficiently. Furthermore, we novelly introduce Low-Rank HOCA which adopts\ntensor decomposition to reduce the extremely large space requirement of HOCA,\nleading to a practical and efficient implementation in real-world applications.\nExperimental results on two benchmark datasets, MSVD and MSR-VTT, show that\nLow-rank HOCA establishes a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:53:50 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Jin", "Tao", ""], ["Huang", "Siyu", ""], ["Li", "Yingming", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1911.00216", "submitter": "Yahya H. Ezzeldin", "authors": "Osama A. Hanna, Yahya H. Ezzeldin, Tara Sadjadpour, Christina\n  Fragouli, Suhas Diggavi", "title": "On Distributed Quantization for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed feature quantization, where the goal\nis to enable a pretrained classifier at a central node to carry out its\nclassification on features that are gathered from distributed nodes through\ncommunication constrained channels. We propose the design of distributed\nquantization schemes specifically tailored to the classification task: unlike\nquantization schemes that help the central node reconstruct the original signal\nas accurately as possible, our focus is not reconstruction accuracy, but\ninstead correct classification. Our work does not make any apriori\ndistributional assumptions on the data, but instead uses training data for the\nquantizer design. Our main contributions include: we prove NP-hardness of\nfinding optimal quantizers in the general case; we design an optimal scheme for\na special case; we propose quantization algorithms, that leverage discrete\nneural representations and training data, and can be designed in\npolynomial-time for any number of features, any number of classes, and\narbitrary division of features across the distributed nodes. We find that\ntailoring the quantizers to the classification task can offer significant\nsavings: as compared to alternatives, we can achieve more than a factor of two\nreduction in terms of the number of bits communicated, for the same\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:10:49 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Hanna", "Osama A.", ""], ["Ezzeldin", "Yahya H.", ""], ["Sadjadpour", "Tara", ""], ["Fragouli", "Christina", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1911.00218", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald,\n  Trong Nghia Hoang", "title": "Statistical Model Aggregation via Parameter Matching", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating models learned from sequestered,\npossibly heterogeneous datasets. Exploiting tools from Bayesian nonparametrics,\nwe develop a general meta-modeling framework that learns shared global latent\nstructures by identifying correspondences among local model parameterizations.\nOur proposed framework is model-independent and is applicable to a wide range\nof model types. After verifying our approach on simulated data, we demonstrate\nits utility in aggregating Gaussian topic models, hierarchical Dirichlet\nprocess based hidden Markov models, and sparse Gaussian processes with\napplications spanning text summarization, motion capture analysis, and\ntemperature forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:24:38 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Agarwal", "Mayank", ""], ["Ghosh", "Soumya", ""], ["Greenewald", "Kristjan", ""], ["Hoang", "Trong Nghia", ""]]}, {"id": "1911.00219", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, Nilesh Agrawal, Partha\n  Talukdar", "title": "InteractE: Improving Convolution-based Knowledge Graph Embeddings by\n  Increasing Feature Interactions", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing knowledge graphs suffer from incompleteness, which can be\nalleviated by inferring missing links based on known facts. One popular way to\naccomplish this is to generate low-dimensional embeddings of entities and\nrelations, and use these to make inferences. ConvE, a recently proposed\napproach, applies convolutional filters on 2D reshapings of entity and relation\nembeddings in order to capture rich interactions between their components.\nHowever, the number of interactions that ConvE can capture is limited. In this\npaper, we analyze how increasing the number of these interactions affects link\nprediction performance, and utilize our observations to propose InteractE.\nInteractE is based on three key ideas -- feature permutation, a novel feature\nreshaping, and circular convolution. Through extensive experiments, we find\nthat InteractE outperforms state-of-the-art convolutional link prediction\nbaselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%,\n7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets\nrespectively. The results validate our central hypothesis -- that increasing\nfeature interaction is beneficial to link prediction performance. We make the\nsource code of InteractE available to encourage reproducible research.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:26:09 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 06:56:20 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 17:06:41 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Sanyal", "Soumya", ""], ["Nitin", "Vikram", ""], ["Agrawal", "Nilesh", ""], ["Talukdar", "Partha", ""]]}, {"id": "1911.00223", "submitter": "Huanbiao Zhu", "authors": "Huanbiao Zhu and Werner Stuetzle", "title": "A Simple and Efficient Method to Compute a Single Linkage Dendrogram", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of computing a single linkage dendrogram. A possible\napproach is to: (i) Form an edge weighted graph $G$ over the data, with edge\nweights reflecting dissimilarities. (ii) Calculate the MST $T$ of $G$. (iii)\nBreak the longest edge of $T$ thereby splitting it into subtrees $T_L$, $T_R$.\n(iv) Apply the splitting process recursively to the subtrees. This approach has\nthe attractive feature that Prim's algorithm for MST construction calculates\ndistances as needed, and hence there is no need to ever store the inter-point\ndistance matrix. The recursive partitioning algorithm requires us to determine\nthe vertices (and edges) of $T_L$ and $T_R$. We show how this can be done\neasily and efficiently using information generated by Prim's algorithm without\nany additional computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:36:51 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Zhu", "Huanbiao", ""], ["Stuetzle", "Werner", ""]]}, {"id": "1911.00234", "submitter": "Rishi Hazra", "authors": "Rishi Hazra and Parag Dutta and Shubham Gupta and Mohammed Abdul\n  Qaathir and Ambedkar Dukkipati", "title": "Active$^2$ Learning: Actively reducing redundancies in Active Learning\n  methods for Sequence Tagging and Machine Translation", "comments": "Accepted in NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning is a powerful tool for natural language processing (NLP)\nproblems, successful solutions to these problems rely heavily on large amounts\nof annotated samples. However, manually annotating data is expensive and\ntime-consuming. Active Learning (AL) strategies reduce the need for huge\nvolumes of labeled data by iteratively selecting a small number of examples for\nmanual annotation based on their estimated utility in training the given model.\nIn this paper, we argue that since AL strategies choose examples independently,\nthey may potentially select similar examples, all of which may not contribute\nsignificantly to the learning process. Our proposed approach,\nActive$\\mathbf{^2}$ Learning (A$\\mathbf{^2}$L), actively adapts to the deep\nlearning model being trained to eliminate such redundant examples chosen by an\nAL strategy. We show that A$\\mathbf{^2}$L is widely applicable by using it in\nconjunction with several different AL strategies and NLP tasks. We empirically\ndemonstrate that the proposed approach is further able to reduce the data\nrequirements of state-of-the-art AL strategies by $\\approx \\mathbf{3-25\\%}$ on\nan absolute scale on multiple NLP tasks while achieving the same performance\nwith virtually no additional computation overhead.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:31:02 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 16:50:09 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 06:56:32 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 09:22:16 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Hazra", "Rishi", ""], ["Dutta", "Parag", ""], ["Gupta", "Shubham", ""], ["Qaathir", "Mohammed Abdul", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1911.00251", "submitter": "Fan Ang", "authors": "Fan Ang, Li Chen, Nan Zhao, Yunfei Chen, Weidong Wang, F. Richard Yu", "title": "Robust Federated Learning with Noisy Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a communication-efficient training process that\nalternates between local training at the edge devices and averaging the updated\nlocal model at the central server. Nevertheless, it is impractical to achieve a\nperfect acquisition of the local models in wireless communication due to noise,\nwhich also brings serious effects on federated learning. To tackle this\nchallenge, we propose a robust design for federated learning to alleviate the\neffects of noise in this paper. Considering noise in the two aforementioned\nsteps, we first formulate the training problem as a parallel optimization for\neach node under the expectation-based model and the worst-case model. Due to\nthe non-convexity of the problem, a regularization for the loss function\napproximation method is proposed to make it tractable. Regarding the worst-case\nmodel, we develop a feasible training scheme which utilizes the sampling-based\nsuccessive convex approximation algorithm to tackle the unavailable maxima or\nminima noise condition and the non-convex issue of the objective function.\nFurthermore, the convergence rates of both new designs are analyzed from a\ntheoretical point of view. Finally, the improvement of prediction accuracy and\nthe reduction of loss function are demonstrated via simulations for the\nproposed designs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:25:34 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ang", "Fan", ""], ["Chen", "Li", ""], ["Zhao", "Nan", ""], ["Chen", "Yunfei", ""], ["Wang", "Weidong", ""], ["Yu", "F. Richard", ""]]}, {"id": "1911.00262", "submitter": "Marko Mihajlovic", "authors": "Marko Mihajlovic, Ning Xiong", "title": "Finding the most similar textual documents using Case-Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, huge amounts of unstructured textual data on the Internet\nare a big difficulty for AI algorithms to provide the best recommendations for\nusers and their search queries. Since the Internet became widespread, a lot of\nresearch has been done in the field of Natural Language Processing (NLP) and\nmachine learning. Almost every solution transforms documents into Vector Space\nModels (VSM) in order to apply AI algorithms over them. One such approach is\nbased on Case-Based Reasoning (CBR). Therefore, the most important part of\nthose systems is to compute the similarity between numerical data points. In\n2016, the new similarity TS-SS metric is proposed, which showed\nstate-of-the-art results in the field of textual mining for unsupervised\nlearning. However, no one before has investigated its performances for\nsupervised learning (classification task). In this work, we devised a CBR\nsystem capable of finding the most similar documents for a given query aiming\nto investigate performances of the new state-of-the-art metric, TS-SS, in\naddition to the two other geometrical similarity measures --- Euclidean\ndistance and Cosine similarity --- that showed the best predictive results over\nseveral benchmark corpora. The results show surprising inappropriateness of\nTS-SS measure for high dimensional features.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:46:35 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Mihajlovic", "Marko", ""], ["Xiong", "Ning", ""]]}, {"id": "1911.00265", "submitter": "Hiroaki Sasaki", "authors": "Hiroaki Sasaki, Takashi Takenouchi, Ricardo Monti, Aapo Hyv\\\"arinen", "title": "Robust contrastive learning and nonlinear ICA in the presence of\n  outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear independent component analysis (ICA) is a general framework for\nunsupervised representation learning, and aimed at recovering the latent\nvariables in data. Recent practical methods perform nonlinear ICA by solving a\nseries of classification problems based on logistic regression. However, it is\nwell-known that logistic regression is vulnerable to outliers, and thus the\nperformance can be strongly weakened by outliers. In this paper, we first\ntheoretically analyze nonlinear ICA models in the presence of outliers. Our\nanalysis implies that estimation in nonlinear ICA can be seriously hampered\nwhen outliers exist on the tails of the (noncontaminated) target density, which\nhappens in a typical case of contamination by outliers. We develop two robust\nnonlinear ICA methods based on the {\\gamma}-divergence, which is a robust\nalternative to the KL-divergence in logistic regression. The proposed methods\nare shown to have desired robustness properties in the context of nonlinear\nICA. We also experimentally demonstrate that the proposed methods are very\nrobust and outperform existing methods in the presence of outliers. Finally,\nthe proposed method is applied to ICA-based causal discovery and shown to find\na plausible causal relationship on fMRI data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:50:01 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sasaki", "Hiroaki", ""], ["Takenouchi", "Takashi", ""], ["Monti", "Ricardo", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "1911.00289", "submitter": "Heechang Ryu", "authors": "Kiwook Bae, Heechang Ryu, Hayong Shin", "title": "Does Adam optimizer keep close to the optimal point?", "comments": "Accepted as a workshop paper at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adaptive optimizer for training neural networks has continually evolved\nto overcome the limitations of the previously proposed adaptive methods. Recent\nstudies have found the rare counterexamples that Adam cannot converge to the\noptimal point. Those counterexamples reveal the distortion of Adam due to a\nsmall second momentum from a small gradient. Unlike previous studies, we show\nAdam cannot keep closer to the optimal point for not only the counterexamples\nbut also a general convex region when the effective learning rate exceeds the\ncertain bound. Subsequently, we propose an algorithm that overcomes Adam's\nlimitation and ensures that it can reach and stay at the optimal point region.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:21:00 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Bae", "Kiwook", ""], ["Ryu", "Heechang", ""], ["Shin", "Hayong", ""]]}, {"id": "1911.00292", "submitter": "William Trouleau", "authors": "Farnood Salehi, William Trouleau, Matthias Grossglauser, Patrick\n  Thiran", "title": "Learning Hawkes Processes from a Handful of Events", "comments": "Appearing at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the causal-interaction network of multivariate Hawkes processes is a\nuseful task in many applications. Maximum-likelihood estimation is the most\ncommon approach to solve the problem in the presence of long observation\nsequences. However, when only short sequences are available, the lack of data\namplifies the risk of overfitting and regularization becomes critical. Due to\nthe challenges of hyper-parameter tuning, state-of-the-art methods only\nparameterize regularizers by a single shared hyper-parameter, hence limiting\nthe power of representation of the model. To solve both issues, we develop in\nthis work an efficient algorithm based on variational expectation-maximization.\nOur approach is able to optimize over an extended set of hyper-parameters. It\nis also able to take into account the uncertainty in the model parameters by\nlearning a posterior distribution over them. Experimental results on both\nsynthetic and real datasets show that our approach significantly outperforms\nstate-of-the-art methods under short observation sequences.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:40:27 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Salehi", "Farnood", ""], ["Trouleau", "William", ""], ["Grossglauser", "Matthias", ""], ["Thiran", "Patrick", ""]]}, {"id": "1911.00294", "submitter": "Adam Foster", "authors": "Adam Foster, Martin Jankowiak, Matthew O'Meara, Yee Whye Teh, Tom\n  Rainforth", "title": "A Unified Stochastic Gradient Approach to Designing Bayesian-Optimal\n  Experiments", "comments": "Published as a conference paper at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fully stochastic gradient based approach to Bayesian optimal\nexperimental design (BOED). Our approach utilizes variational lower bounds on\nthe expected information gain (EIG) of an experiment that can be simultaneously\noptimized with respect to both the variational and design parameters. This\nallows the design process to be carried out through a single unified stochastic\ngradient ascent procedure, in contrast to existing approaches that typically\nconstruct a pointwise EIG estimator, before passing this estimator to a\nseparate optimizer. We provide a number of different variational objectives\nincluding the novel adaptive contrastive estimation (ACE) bound. Finally, we\nshow that our gradient-based approaches are able to provide effective design\noptimization in substantially higher dimensional settings than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:45:12 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 15:16:45 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Foster", "Adam", ""], ["Jankowiak", "Martin", ""], ["O'Meara", "Matthew", ""], ["Teh", "Yee Whye", ""], ["Rainforth", "Tom", ""]]}, {"id": "1911.00298", "submitter": "Stefano Almi", "authors": "Stefano Almi, Massimo Fornasier, Richard Huber", "title": "Data-driven Evolutions of Critical Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are concerned with the learnability of energies from data\nobtained by observing time evolutions of their critical points starting at\nrandom initial equilibria. As a byproduct of our theoretical framework we\nintroduce the novel concept of mean-field limit of critical point evolutions\nand of their energy balance as a new form of transport. We formulate the energy\nlearning as a variational problem, minimizing the discrepancy of energy\ncompetitors from fulfilling the equilibrium condition along any trajectory of\ncritical points originated at random initial equilibria. By Gamma-convergence\narguments we prove the convergence of minimal solutions obtained from finite\nnumber of observations to the exact energy in a suitable sense. The abstract\nframework is actually fully constructive and numerically implementable. Hence,\nthe approximation of the energy from a finite number of observations of past\nevolutions allows to simulate further evolutions, which are fully data-driven.\nAs we aim at a precise quantitative analysis, and to provide concrete examples\nof tractable solutions, we present analytic and numerical results on the\nreconstruction of an elastic energy for a one-dimensional model of thin\nnonlinear-elastic rod.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 11:00:56 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Almi", "Stefano", ""], ["Fornasier", "Massimo", ""], ["Huber", "Richard", ""]]}, {"id": "1911.00313", "submitter": "Yannis Papanikolaou", "authors": "Yannis Papanikolaou, Ian Roberts, Andrea Pierleoni", "title": "Deep Bidirectional Transformers for Relation Extraction without\n  Supervision", "comments": null, "journal-ref": "EMNLP DeepLo workshop 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework to deal with relation extraction tasks in cases\nwhere there is complete lack of supervision, either in the form of gold\nannotations, or relations from a knowledge base. Our approach leverages\nsyntactic parsing and pre-trained word embeddings to extract few but precise\nrelations,which are then used to annotate a larger cor-pus, in a manner\nidentical to distant supervision. The resulting data set is employed to fine\ntune a pre-trained BERT model in order to perform relation extraction.\nEmpirical evaluation on four data sets from the biomedical domain shows that\nour method significantly outperforms two simple baselines for unsupervised\nrelation extraction and, even if not using any supervision at all, achieves\nslightly worse results than the state-of-the-art in three out of four data\nsets. Importantly, we show that it is possible to successfully fine tune a\nlarge pre-trained language model with noisy data, as op-posed to previous works\nthat rely on gold data for fine tuning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 11:47:28 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Papanikolaou", "Yannis", ""], ["Roberts", "Ian", ""], ["Pierleoni", "Andrea", ""]]}, {"id": "1911.00332", "submitter": "Daniel Goldfarb", "authors": "Daniel Goldfarb, Scott Evans", "title": "Causal Inference via Conditional Kolmogorov Complexity using MDL Binning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments have linked causal inference with Algorithmic Information\nTheory, and methods have been developed that utilize Conditional Kolmogorov\nComplexity to determine causation between two random variables. We present a\nmethod for inferring causal direction between continuous variables by using an\nMDL Binning technique for data discretization and complexity calculation. Our\nmethod captures the shape of the data and uses it to determine which variable\nhas more information about the other. Its high predictive performance and\nrobustness is shown on several real world use cases.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 01:53:36 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 20:43:46 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Goldfarb", "Daniel", ""], ["Evans", "Scott", ""]]}, {"id": "1911.00348", "submitter": "Heinke Hihn", "authors": "Heinke Hihn and Daniel A. Braun", "title": "Hierarchical Expert Networks for Meta-Learning", "comments": "Presented at the 4th ICML Workshop on Life Long Machine Learning,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of meta-learning is to train a model on a variety of learning tasks,\nsuch that it can adapt to new problems within only a few iterations. Here we\npropose a principled information-theoretic model that optimally partitions the\nunderlying problem space such that specialized expert decision-makers solve the\nresulting sub-problems. To drive this specialization we impose the same kind of\ninformation processing constraints both on the partitioning and the expert\ndecision-makers. We argue that this specialization leads to efficient\nadaptation to new tasks. To demonstrate the generality of our approach we\nevaluate three meta-learning domains: image classification, regression, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:23:52 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 09:23:59 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 12:27:14 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 17:03:56 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 15:18:43 GMT"}, {"version": "v6", "created": "Tue, 4 Feb 2020 12:10:39 GMT"}, {"version": "v7", "created": "Wed, 9 Sep 2020 16:38:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hihn", "Heinke", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1911.00359", "submitter": "Marie-Anne Lachaux", "authors": "Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav\n  Chaudhary, Francisco Guzm\\'an, Armand Joulin, Edouard Grave", "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training text representations have led to significant improvements in\nmany areas of natural language processing. The quality of these models benefits\ngreatly from the size of the pretraining corpora as long as its quality is\npreserved. In this paper, we describe an automatic pipeline to extract massive\nhigh-quality monolingual datasets from Common Crawl for a variety of languages.\nOur pipeline follows the data processing introduced in fastText (Mikolov et\nal., 2017; Grave et al., 2018), that deduplicates documents and identifies\ntheir language. We augment this pipeline with a filtering step to select\ndocuments that are close to high quality corpora like Wikipedia.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 13:09:28 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 00:03:54 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Wenzek", "Guillaume", ""], ["Lachaux", "Marie-Anne", ""], ["Conneau", "Alexis", ""], ["Chaudhary", "Vishrav", ""], ["Guzm\u00e1n", "Francisco", ""], ["Joulin", "Armand", ""], ["Grave", "Edouard", ""]]}, {"id": "1911.00385", "submitter": "Joseph Tassarotti", "authors": "Joseph Tassarotti, Koundinya Vajjha, Anindya Banerjee, Jean-Baptiste\n  Tristan", "title": "A Formal Proof of PAC Learnability for Decision Stumps", "comments": "13 pages, appeared in Certified Programs and Proofs (CPP) 2021", "journal-ref": null, "doi": "10.1145/3437992.3439917", "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal proof in Lean of probably approximately correct (PAC)\nlearnability of the concept class of decision stumps. This classic result in\nmachine learning theory derives a bound on error probabilities for a simple\ntype of classifier. Though such a proof appears simple on paper, analytic and\nmeasure-theoretic subtleties arise when carrying it out fully formally. Our\nproof is structured so as to separate reasoning about deterministic properties\nof a learning function from proofs of measurability and analysis of\nprobabilities.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:02:39 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:37:47 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 22:38:00 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Tassarotti", "Joseph", ""], ["Vajjha", "Koundinya", ""], ["Banerjee", "Anindya", ""], ["Tristan", "Jean-Baptiste", ""]]}, {"id": "1911.00400", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos", "title": "Sparsely Activated Networks: A new method for decomposing and\n  compressing data", "comments": "PhD Thesis in Greek, 158 pages for the main text, 23 supplementary\n  pages for presentation, arXiv:1907.06592, arXiv:1904.13216, arXiv:1902.11122", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature on unsupervised learning focused on designing structural\npriors with the aim of learning meaningful features, but without considering\nthe description length of the representations. In this thesis, first we\nintroduce the{\\phi}metric that evaluates unsupervised models based on their\nreconstruction accuracy and the degree of compression of their internal\nrepresentations. We then present and define two activation functions (Identity,\nReLU) as base of reference and three sparse activation functions (top-k\nabsolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize\nthe previously defined metric $\\varphi$. We lastly present Sparsely Activated\nNetworks (SANs) that consist of kernels with shared weights that, during\nencoding, are convolved with the input and then passed through a sparse\nactivation function. During decoding, the same weights are convolved with the\nsparse activation map and subsequently the partial reconstructions from each\nweight are summed to reconstruct the input. We compare SANs using the five\npreviously defined activation functions on a variety of datasets (Physionet,\nUCI-epilepsy, MNIST, FMNIST) and show that models that are selected using\n$\\varphi$ have small description representation length and consist of\ninterpretable kernels.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 20:11:29 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""]]}, {"id": "1911.00405", "submitter": "George Moustakides", "authors": "George V. Moustakides and Kalliopi Basioti", "title": "Training Neural Networks for Likelihood/Density Ratio Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various problems in Engineering and Statistics require the computation of the\nlikelihood ratio function of two probability densities. In classical approaches\nthe two densities are assumed known or to belong to some known parametric\nfamily. In a data-driven version we replace this requirement with the\navailability of data sampled from the densities of interest. For most well\nknown problems in Detection and Hypothesis testing we develop solutions by\nproviding neural network based estimates of the likelihood ratio or its\ntransformations. This task necessitates the definition of proper optimizations\nwhich can be used for the training of the network. The main purpose of this\nwork is to offer a simple and unified methodology for defining such\noptimization problems with guarantees that the solution is indeed the desired\nfunction. Our results are extended to cover estimates for likelihood ratios of\nconditional densities and estimates for statistics encountered in local\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:31:59 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:13:22 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Moustakides", "George V.", ""], ["Basioti", "Kalliopi", ""]]}, {"id": "1911.00418", "submitter": "Samyadeep Basu", "authors": "Samyadeep Basu, Xuchen You, Soheil Feizi", "title": "On Second-Order Group Influence Functions for Black-Box Predictions", "comments": "To Appear in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid adoption of machine learning systems in sensitive\napplications, there is an increasing need to make black-box models explainable.\nOften we want to identify an influential group of training samples in a\nparticular test prediction for a given machine learning model. Existing\ninfluence functions tackle this problem by using first-order approximations of\nthe effect of removing a sample from the training set on model parameters. To\ncompute the influence of a group of training samples (rather than an individual\npoint) in model predictions, the change in optimal model parameters after\nremoving that group from the training set can be large. Thus, in such cases,\nthe first-order approximation can be loose. In this paper, we address this\nissue and propose second-order influence functions for identifying influential\ngroups in test-time predictions. For linear models, across different sizes and\ntypes of groups, we show that using the proposed second-order influence\nfunction improves the correlation between the computed influence values and the\nground truth ones. We also show that second-order influence functions could be\nused with optimization techniques to improve the selection of the most\ninfluential group for a test-sample.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:14:06 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 01:11:59 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Basu", "Samyadeep", ""], ["You", "Xuchen", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.00443", "submitter": "Florent  Sureau", "authors": "Florent Sureau, Alexis Lechat, Jean-Luc Starck", "title": "Deep Learning for space-variant deconvolution in galaxy surveys", "comments": null, "journal-ref": "A&A 641, A67 (2020)", "doi": "10.1051/0004-6361/201937039", "report-no": null, "categories": "astro-ph.IM eess.IV stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deconvolution of large survey images with millions of galaxies requires to\ndevelop a new generation of methods which can take into account a space variant\nPoint Spread Function (PSF) and have to be at the same time accurate and fast.\nWe investigate in this paper how Deep Learning (DL) could be used to perform\nthis task. We employ a U-Net Deep Neural Network (DNN) architecture to learn in\na supervised setting parameters adapted for galaxy image processing and study\ntwo strategies for deconvolution. The first approach is a post-processing of a\nmere Tikhonov deconvolution with closed form solution and the second one is an\niterative deconvolution framework based on the Alternating Direction Method of\nMultipliers (ADMM). Our numerical results based on GREAT3 simulations with\nrealistic galaxy images and PSFs show that our two approaches outperforms\nstandard techniques based on convex optimization, whether assessed in galaxy\nimage reconstruction or shape recovery. The approach based on Tikhonov\ndeconvolution leads to the most accurate results except for ellipticity errors\nat high signal to noise ratio where the ADMM approach performs slightly better,\nis also more computation-time efficient to process a large number of galaxies,\nand is therefore recommended in this scenario.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:11:48 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 13:13:31 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Sureau", "Florent", ""], ["Lechat", "Alexis", ""], ["Starck", "Jean-Luc", ""]]}, {"id": "1911.00459", "submitter": "Danfei Xu", "authors": "Danfei Xu, Misha Denil", "title": "Positive-Unlabeled Reward Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning reward functions from data is a promising path towards achieving\nscalable Reinforcement Learning (RL) for robotics. However, a major challenge\nin training agents from learned reward models is that the agent can learn to\nexploit errors in the reward model to achieve high reward behaviors that do not\ncorrespond to the intended task. These reward delusions can lead to unintended\nand even dangerous behaviors. On the other hand, adversarial imitation learning\nframeworks tend to suffer the opposite problem, where the discriminator learns\nto trivially distinguish agent and expert behavior, resulting in reward models\nthat produce low reward signal regardless of the input state. In this paper, we\nconnect these two classes of reward learning methods to positive-unlabeled (PU)\nlearning, and we show that by applying a large-scale PU learning algorithm to\nthe reward learning problem, we can address both the reward under- and\nover-estimation problems simultaneously. Our approach drastically improves both\nGAIL and supervised reward learning, without any additional assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:47:44 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Xu", "Danfei", ""], ["Denil", "Misha", ""]]}, {"id": "1911.00465", "submitter": "Shahin Boluki", "authors": "Siamak Zamani Dadaneh, Shahin Boluki, Mingyuan Zhou and Xiaoning Qian", "title": "ARSM Gradient Estimator for Supervised Learning to Rank", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for supervised learning to rank. In our model, the\nrelevance labels are assumed to follow a categorical distribution whose\nprobabilities are constructed based on a scoring function. We optimize the\ntraining objective with respect to the multivariate categorical variables with\nan unbiased and low-variance gradient estimator. Learning-to-rank methods can\ngenerally be categorized into pointwise, pairwise, and listwise approaches.\nAlthough our scoring function is pointwise, the proposed framework permits\nflexibility over the choice of the loss function. In our new model, the loss\nfunction need not be differentiable and can either be pointwise or listwise.\nOur proposed method achieves better or comparable results on two datasets\ncompared with existing pairwise and listwise methods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:05:29 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 05:36:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dadaneh", "Siamak Zamani", ""], ["Boluki", "Shahin", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1911.00467", "submitter": "Art Owen", "authors": "Masayoshi Mase and Art B. Owen and Benjamin Seiler", "title": "Explaining black box decisions by Shapley cohort refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variable importance measure to quantify the impact of\nindividual input variables to a black box function. Our measure is based on the\nShapley value from cooperative game theory. Many measures of variable\nimportance operate by changing some predictor values with others held fixed,\npotentially creating unlikely or even logically impossible combinations. Our\ncohort Shapley measure uses only observed data points. Instead of changing the\nvalue of a predictor we include or exclude subjects similar to the target\nsubject on that predictor to form a similarity cohort. Then we apply Shapley\nvalue to the cohort averages. We connect variable importance measures from\nexplainable AI to function decompositions from global sensitivity analysis. We\nintroduce a squared cohort Shapley value that splits previously studied Shapley\neffects over subjects, consistent with a Shapley axiom.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:10:20 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 23:57:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Mase", "Masayoshi", ""], ["Owen", "Art B.", ""], ["Seiler", "Benjamin", ""]]}, {"id": "1911.00472", "submitter": "Michael Kuchnik", "authors": "Michael Kuchnik and George Amvrosiadis and Virginia Smith", "title": "Progressive Compressed Records: Taking a Byte out of Deep Learning Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning training accesses vast amounts of data at high velocity, posing\nbandwidth challenges for datasets retrieved over commodity networks and storage\ndevices. A common approach to reduce bandwidth involves resizing or compressing\ndata prior to training. We introduce a way to dynamically reduce the overhead\nof fetching and transporting data with a method we term Progressive Compressed\nRecords (PCRs). PCRs deviate from previous storage formats by combining\nprogressive compression with an efficient on-disk layout to view a single\ndataset at multiple qualities---all without adding to the total dataset size.\nWe implement PCRs and evaluate them on a range of datasets: ImageNet, HAM10000,\nStanford Cars, and CelebA-HQ. Our results show that: (i) the amount of\ncompression a dataset can tolerate depends on the training task, (ii) PCRs\nenable tasks to readily access appropriate levels of compression at\nruntime---resulting in a 2x speedup in training time on average over baseline\nformats, and (iii) the appropriate compression level for a task can be selected\nat runtime.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:28:56 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 00:03:15 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 01:17:15 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kuchnik", "Michael", ""], ["Amvrosiadis", "George", ""], ["Smith", "Virginia", ""]]}, {"id": "1911.00482", "submitter": "Hao Yan", "authors": "Nurettin Sergin, Hao Yan", "title": "High-dimensional Nonlinear Profile Monitoring based on Deep\n  Probabilistic Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide accessibility of imaging and profile sensors in modern industrial\nsystems created an abundance of high-dimensional sensing variables. This led to\na a growing interest in the research of high-dimensional process monitoring.\nHowever, most of the approaches in the literature assume the in-control\npopulation to lie on a linear manifold with a given basis (i.e., spline,\nwavelet, kernel, etc) or an unknown basis (i.e., principal component analysis\nand its variants), which cannot be used to efficiently model profiles with a\nnonlinear manifold which is common in many real-life cases. We propose deep\nprobabilistic autoencoders as a viable unsupervised learning approach to model\nsuch manifolds. To do so, we formulate nonlinear and probabilistic extensions\nof the monitoring statistics from classical approaches as the expected\nreconstruction error (ERE) and the KL-divergence (KLD) based monitoring\nstatistics. Through extensive simulation study, we provide insights on why\nlatent-space based statistics are unreliable and why residual-space based ones\ntypically perform much better for deep learning based approaches. Finally, we\ndemonstrate the superiority of deep probabilistic models via both simulation\nstudy and a real-life case study involving images of defects from a hot steel\nrolling process.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:47:49 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sergin", "Nurettin", ""], ["Yan", "Hao", ""]]}, {"id": "1911.00493", "submitter": "Veit Elser", "authors": "Veit Elser", "title": "Learning Without Loss", "comments": "52 pages, 24 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new approach for training neural networks where all loss\nfunctions are replaced by hard constraints. The same approach is very\nsuccessful in phase retrieval, where signals are reconstructed from magnitude\nconstraints and general characteristics (sparsity, support, etc.). Instead of\ntaking gradient steps, the optimizer in the constraint based approach, called\nrelaxed-reflect-reflect (RRR), derives its steps from projections to local\nconstraints. In neural networks one such projection makes the minimal\nmodification to the inputs $x$, the associated weights $w$, and the\npre-activation value $y$ at each neuron, to satisfy the equation $x\\cdot w=y$.\nThese projections, along with a host of other local projections (constraining\npre- and post-activations, etc.) can be partitioned into two sets such that all\nthe projections in each set can be applied concurrently, across the network and\nacross all data in the training batch. This partitioning into two sets is\nanalogous to the situation in phase retrieval and the setting for which the\ngeneral purpose RRR optimizer was designed. Owing to the novelty of the method,\nthis paper also serves as a self-contained tutorial. Starting with a\nsingle-layer network that performs non-negative matrix factorization, and\nconcluding with a generative model comprising an autoencoder and classifier,\nall applications and their implementations by projections are described in\ncomplete detail. Although the new approach has the potential to extend the\nscope of neural networks (e.g. by defining activation not through functions but\nconstraint sets), most of the featured models are standard to allow comparison\nwith stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:20:08 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Elser", "Veit", ""]]}, {"id": "1911.00502", "submitter": "Xinshi Chen", "authors": "Xinshi Chen", "title": "Review: Ordinary Differential Equations For Deep Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.00640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To better understand and improve the behavior of neural networks, a recent\nline of works bridged the connection between ordinary differential equations\n(ODEs) and deep neural networks (DNNs). The connections are made in two folds:\n(1) View DNN as ODE discretization; (2) View the training of DNN as solving an\noptimal control problem. The former connection motivates people either to\ndesign neural architectures based on ODE discretization schemes or to replace\nDNN by a continuous model characterized by ODEs. Several works demonstrated\ndistinct advantages of using a continuous model instead of traditional DNN in\nsome specific applications. The latter connection is inspiring. Based on\nPontryagin's maximum principle, which is popular in the optimal control\nliterature, some developed new optimization methods for training neural\nnetworks and some developed algorithms to train the infinite-deep continuous\nmodel with low memory-cost. This paper is organized as follows: In Section 2,\nthe relation between neural architecture and ODE discretization is introduced.\nSome architectures are not motivated by ODE, but they are later found to be\nassociated with some specific discretization schemes. Some architectures are\ndesigned based on ODE discretization and expected to achieve some special\nproperties. Section 3 formulates the optimization problem where a traditional\nneural network is replaced by a continuous model (ODE). The formulated\noptimization problem is an optimal control problem. Therefore, two different\ntypes of controls will also be discussed in this section. In Section 4, we will\ndiscuss how we can utilize the optimization methods that are popular in optimal\ncontrol literature to help the training of machine learning problems. Finally,\ntwo applications of using a continuous model will be shown in Section 5 and 6\nto demonstrate some of its advantages over traditional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 04:26:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chen", "Xinshi", ""]]}, {"id": "1911.00515", "submitter": "Gustav M{\\aa}rtensson", "authors": "Gustav M{\\aa}rtensson, Daniel Ferreira, Tobias Granberg, Lena\n  Cavallin, Ketil Oppedal, Alessandro Padovani, Irena Rektorova, Laura Bonanni,\n  Matteo Pardini, Milica Kramberger, John-Paul Taylor, Jakub Hort, J\\'on\n  Sn{\\ae}dal, Jaime Kulisevsky, Frederic Blanc, Angelo Antonini, Patrizia\n  Mecocci, Bruno Vellas, Magda Tsolaki, Iwona K{\\l}oszewska, Hilkka Soininen,\n  Simon Lovestone, Andrew Simmons, Dag Aarsland, Eric Westman", "title": "The reliability of a deep learning model in clinical out-of-distribution\n  MRI data: a multicohort study", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.media.2020.101714", "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) methods have in recent years yielded impressive results in\nmedical imaging, with the potential to function as clinical aid to\nradiologists. However, DL models in medical imaging are often trained on public\nresearch cohorts with images acquired with a single scanner or with strict\nprotocol harmonization, which is not representative of a clinical setting. The\naim of this study was to investigate how well a DL model performs in unseen\nclinical data sets---collected with different scanners, protocols and disease\npopulations---and whether more heterogeneous training data improves\ngeneralization. In total, 3117 MRI scans of brains from multiple dementia\nresearch cohorts and memory clinics, that had been visually rated by a\nneuroradiologist according to Scheltens' scale of medial temporal atrophy\n(MTA), were included in this study. By training multiple versions of a\nconvolutional neural network on different subsets of this data to predict MTA\nratings, we assessed the impact of including images from a wider distribution\nduring training had on performance in external memory clinic data. Our results\nshowed that our model generalized well to data sets acquired with similar\nprotocols as the training data, but substantially worse in clinical cohorts\nwith visibly different tissue contrasts in the images. This implies that future\nDL studies investigating performance in out-of-distribution (OOD) MRI data need\nto assess multiple external cohorts for reliable results. Further, by including\ndata from a wider range of scanners and protocols the performance improved in\nOOD data, which suggests that more heterogeneous training data makes the model\ngeneralize better. To conclude, this is the most comprehensive study to date\ninvestigating the domain shift in deep learning on MRI data, and we advocate\nrigorous evaluation of DL models on clinical data prior to being certified for\ndeployment.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:52:16 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["M\u00e5rtensson", "Gustav", ""], ["Ferreira", "Daniel", ""], ["Granberg", "Tobias", ""], ["Cavallin", "Lena", ""], ["Oppedal", "Ketil", ""], ["Padovani", "Alessandro", ""], ["Rektorova", "Irena", ""], ["Bonanni", "Laura", ""], ["Pardini", "Matteo", ""], ["Kramberger", "Milica", ""], ["Taylor", "John-Paul", ""], ["Hort", "Jakub", ""], ["Sn\u00e6dal", "J\u00f3n", ""], ["Kulisevsky", "Jaime", ""], ["Blanc", "Frederic", ""], ["Antonini", "Angelo", ""], ["Mecocci", "Patrizia", ""], ["Vellas", "Bruno", ""], ["Tsolaki", "Magda", ""], ["K\u0142oszewska", "Iwona", ""], ["Soininen", "Hilkka", ""], ["Lovestone", "Simon", ""], ["Simmons", "Andrew", ""], ["Aarsland", "Dag", ""], ["Westman", "Eric", ""]]}, {"id": "1911.00567", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, David Brandfonbrener, Emma Brunskill, Matteo Pirotta,\n  Alessandro Lazaric", "title": "Frequentist Regret Bounds for Randomized Least-Squares Value Iteration", "comments": "AISTATS 2020; minor bug fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration-exploitation dilemma in finite-horizon\nreinforcement learning (RL). When the state space is large or continuous,\ntraditional tabular approaches are unfeasible and some form of function\napproximation is mandatory. In this paper, we introduce an\noptimistically-initialized variant of the popular randomized least-squares\nvalue iteration (RLSVI), a model-free algorithm where exploration is induced by\nperturbing the least-squares approximation of the action-value function. Under\nthe assumption that the Markov decision process has low-rank transition\ndynamics, we prove that the frequentist regret of RLSVI is upper-bounded by\n$\\widetilde O(d^2 H^2 \\sqrt{T})$ where $ d $ are the feature dimension, $ H $\nis the horizon, and $ T $ is the total number of steps. To the best of our\nknowledge, this is the first frequentist regret analysis for randomized\nexploration with function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:48:57 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 16:09:41 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 00:37:56 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 01:21:42 GMT"}, {"version": "v5", "created": "Mon, 22 Jun 2020 02:09:50 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zanette", "Andrea", ""], ["Brandfonbrener", "David", ""], ["Brunskill", "Emma", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1911.00569", "submitter": "Yaniv Yacoby", "authors": "Yaniv Yacoby, Weiwei Pan, Finale Doshi-Velez", "title": "Mitigating the Effects of Non-Identifiability on Inference for Bayesian\n  Neural Networks with Latent Variables", "comments": "Accepted at ICML's Uncertainty and Robustness in Deep Learning\n  Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks with Latent Variables (BNN+LVs) provide\nuncertainties in prediction estimates by explicitly modeling model uncertainty\n(via priors on network weights) and environmental stochasticity (via a latent\ninput noise variable). In this work, we first show that BNN+LV suffers from a\nserious form of non-identifiability: explanatory power can be transferred\nbetween model parameters and input noise while fitting the data equally well.\nWe demonstrate that as a result, the posterior mode over the network weights\nand latent variables is asymptotically biased away from the ground truth, and\nas a result, traditional inference methods may yield parameters that generalize\npoorly and mis-estimate uncertainty. Next, we develop a novel inference\nprocedure that explicitly mitigates the effects of likelihood\nnon-identifiability during training and yields high quality predictions as well\nas uncertainty estimates. We demonstrate that our inference method improves\nupon benchmark methods across a range of synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:51:10 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 02:12:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Yacoby", "Yaniv", ""], ["Pan", "Weiwei", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1911.00605", "submitter": "Ziyuan Pu", "authors": "Ziyuan Pu, Zhiyong Cui, Shuo Wang, Qianmu Li, Yinhai Wang", "title": "Time-Aware Gated Recurrent Unit Networks for Road Surface Friction\n  Prediction Using Historical Data", "comments": null, "journal-ref": "IET Intelligent Transport Systems. 14.4 (2020): 213-219", "doi": "10.1049/iet-its.2019.0428", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate road surface friction prediction algorithm can enable intelligent\ntransportation systems to share timely road surface condition to the public for\nincreasing the safety of the road users. Previously, scholars developed\nmultiple prediction models for forecasting road surface conditions using\nhistorical data. However, road surface condition data cannot be perfectly\ncollected at every timestamp, e.g. the data collected by on-vehicle sensors may\nbe influenced when vehicles cannot travel due to economic cost issue or weather\nissues. Such resulted missing values in the collected data can damage the\neffectiveness and accuracy of the existing prediction methods since they are\nassumed to have the input data with a fixed temporal resolution. This study\nproposed a road surface friction prediction model employing a Gated Recurrent\nUnit network-based decay mechanism (GRU-D) to handle the missing values. The\nevaluation results present that the proposed GRU-D networks outperform all\nbaseline models. The impact of missing rate on predictive accuracy, learning\nefficiency and learned decay rate are analyzed as well. The findings can help\nimprove the prediction accuracy and efficiency of forecasting road surface\nfriction using historical data sets with missing values, therefore mitigating\nthe impact of wet or icy road conditions on traffic safety.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 22:27:24 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Pu", "Ziyuan", ""], ["Cui", "Zhiyong", ""], ["Wang", "Shuo", ""], ["Li", "Qianmu", ""], ["Wang", "Yinhai", ""]]}, {"id": "1911.00616", "submitter": "Eduardo Soares Mr", "authors": "Eduardo Soares, Plamen Angelov", "title": "Novelty Detection and Learning from Extremely Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we offer a method and algorithm, which make possible fully\nautonomous (unsupervised) detection of new classes, and learning following a\nvery parsimonious training priming (few labeled data samples only). Moreover,\nnew unknown classes may appear at a later stage and the proposed xClass method\nand algorithm are able to successfully discover this and learn from the data\nautonomously. Furthermore, the features (inputs to the classifier) are\nautomatically sub-selected by the algorithm based on the accumulated data\ndensity per feature per class. As a result, a highly efficient, lean,\nhuman-understandable, autonomously self-learning model (which only needs an\nextremely parsimonious priming) emerges from the data. To validate our proposal\nwe tested it on two challenging problems, including imbalanced Caltech-101 data\nset and iRoads dataset. Not only we achieved higher precision, but, more\nsignificantly, we only used a single class beforehand, while other methods used\nall the available classes) and we generated interpretable models with smaller\nnumber of features used, through extremely weak and weak supervision.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:51:08 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Soares", "Eduardo", ""], ["Angelov", "Plamen", ""]]}, {"id": "1911.00617", "submitter": "Mikael Henaff", "authors": "Mikael Henaff", "title": "Explicit Explore-Exploit Algorithms in Continuous State Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based algorithm for reinforcement learning (RL) which\nconsists of explicit exploration and exploitation phases, and is applicable in\nlarge or infinite state spaces. The algorithm maintains a set of dynamics\nmodels consistent with current experience and explores by finding policies\nwhich induce high disagreement between their state predictions. It then\nexploits using the refined set of models or experience gathered during\nexploration. We show that under realizability and optimal planning assumptions,\nour algorithm provably finds a near-optimal policy with a number of samples\nthat is polynomial in a structural complexity measure which we show to be low\nin several natural settings. We then give a practical approximation using\nneural networks and demonstrate its performance and sample efficiency in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:58:05 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:21:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Henaff", "Mikael", ""]]}, {"id": "1911.00623", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Junyao Guo, Jiayi Liu, Samarth Tripathi, Unmesh Kurup,\n  Mohak Shah", "title": "On-Device Machine Learning: An Algorithms and Learning Theory\n  Perspective", "comments": "Edge Learning, TinyML, Resource Constrained Machine Learning, Deep\n  learning on device, Statistical Learning Theory, 45 pages survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant paradigm for using machine learning models on a device is to\ntrain a model in the cloud and perform inference using the trained model on the\ndevice. However, with increasing number of smart devices and improved hardware,\nthere is interest in performing model training on the device. Given this surge\nin interest, a comprehensive survey of the field from a device-agnostic\nperspective sets the stage for both understanding the state-of-the-art and for\nidentifying open challenges and future avenues of research. However, on-device\nlearning is an expansive field with connections to a large number of related\ntopics in AI and machine learning (including online learning, model adaptation,\none/few-shot learning, etc.). Hence, covering such a large number of topics in\na single survey is impractical. This survey finds a middle ground by\nreformulating the problem of on-device learning as resource constrained\nlearning where the resources are compute and memory. This reformulation allows\ntools, techniques, and algorithms from a wide variety of research areas to be\ncompared equitably. In addition to summarizing the state-of-the-art, the survey\nalso identifies a number of challenges and next steps for both the algorithmic\nand theoretical aspects of on-device learning.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 01:16:02 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 07:04:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Dhar", "Sauptik", ""], ["Guo", "Junyao", ""], ["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1911.00630", "submitter": "Tal Ben-Nun", "authors": "Peter Gr\\\"onquist, Tal Ben-Nun, Nikoli Dryden, Peter Dueben, Luca\n  Lavarini, Shigang Li, Torsten Hoefler", "title": "Predicting Weather Uncertainty with Deep Convnets", "comments": "Poster presentation at NeurIPS2019 \"Machine Learning and the Physical\n  Sciences\" Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern weather forecast models perform uncertainty quantification using\nensemble prediction systems, which collect nonparametric statistics based on\nmultiple perturbed simulations. To provide accurate estimation, dozens of such\ncomputationally intensive simulations must be run. We show that deep neural\nnetworks can be used on a small set of numerical weather simulations to\nestimate the spread of a weather forecast, significantly reducing computational\ncost. To train the system, we both modify the 3D U-Net architecture and explore\nmodels that incorporate temporal data. Our models serve as a starting point to\nimprove uncertainty quantification in current real-time weather forecasting\nsystems, which is vital for predicting extreme events.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 02:41:33 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:13:45 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Gr\u00f6nquist", "Peter", ""], ["Ben-Nun", "Tal", ""], ["Dryden", "Nikoli", ""], ["Dueben", "Peter", ""], ["Lavarini", "Luca", ""], ["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1911.00638", "submitter": "Samuel Daulton", "authors": "Samuel Daulton, Shaun Singh, Vashist Avadhanula, Drew Dimmery, Eytan\n  Bakshy", "title": "Thompson Sampling for Contextual Bandit Problems with Auxiliary Safety\n  Constraints", "comments": "To appear at NeurIPS 2019, Workshop on Safety and Robustness in\n  Decision Making. 11 pages (including references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in contextual bandit optimization and reinforcement learning\nhave garnered interest in applying these methods to real-world sequential\ndecision making problems. Real-world applications frequently have constraints\nwith respect to a currently deployed policy. Many of the existing\nconstraint-aware algorithms consider problems with a single objective (the\nreward) and a constraint on the reward with respect to a baseline policy.\nHowever, many important applications involve multiple competing objectives and\nauxiliary constraints. In this paper, we propose a novel Thompson sampling\nalgorithm for multi-outcome contextual bandit problems with auxiliary\nconstraints. We empirically evaluate our algorithm on a synthetic problem.\nLastly, we apply our method to a real world video transcoding problem and\nprovide a practical way for navigating the trade-off between safety and\nperformance using Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 03:41:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Daulton", "Samuel", ""], ["Singh", "Shaun", ""], ["Avadhanula", "Vashist", ""], ["Dimmery", "Drew", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1911.00645", "submitter": "Qingcan Wang", "authors": "Lei Wu, Qingcan Wang and Chao Ma", "title": "Global Convergence of Gradient Descent for Deep Linear Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the global convergence of gradient descent for deep linear\nresidual networks by proposing a new initialization: zero-asymmetric (ZAS)\ninitialization. It is motivated by avoiding stable manifolds of saddle points.\nWe prove that under the ZAS initialization, for an arbitrary target matrix,\ngradient descent converges to an $\\varepsilon$-optimal point in $O(L^3\n\\log(1/\\varepsilon))$ iterations, which scales polynomially with the network\ndepth $L$. Our result and the $\\exp(\\Omega(L))$ convergence time for the\nstandard initialization (Xavier or near-identity) [Shamir, 2018] together\ndemonstrate the importance of the residual structure and the initialization in\nthe optimization for deep linear neural networks, especially when $L$ is large.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 04:14:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wu", "Lei", ""], ["Wang", "Qingcan", ""], ["Ma", "Chao", ""]]}, {"id": "1911.00658", "submitter": "Xiaofei Wang", "authors": "Bin Wang, Xiaofei Wang, Jianhua Guo", "title": "Global Adaptive Generative Adjustment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many traditional signal recovery approaches can behave well basing on the\npenalized likelihood. However, they have to meet with the difficulty in the\nselection of hyperparameters or tuning parameters in the penalties. In this\narticle, we propose a global adaptive generative adjustment (GAGA) algorithm\nfor signal recovery, in which multiple hyperpameters are automatically learned\nand alternatively updated with the signal. We further prove that the output of\nour algorithm directly guarantees the consistency of model selection and the\nasymptotic normality of signal estimate. Moreover, we also propose a variant\nGAGA algorithm for improving the computational efficiency in the\nhigh-dimensional data analysis. Finally, in the simulated experiment, we\nconsider the consistency of the outputs of our algorithms, and compare our\nalgorithms to other penalized likelihood methods: the Adaptive LASSO, the SCAD\nand the MCP. The simulation results support the efficiency of our algorithms\nfor signal recovery, and demonstrate that our algorithms outperform the other\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 05:38:36 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 13:11:05 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Wang", "Bin", ""], ["Wang", "Xiaofei", ""], ["Guo", "Jianhua", ""]]}, {"id": "1911.00674", "submitter": "Zhibin Liao", "authors": "Zhibin Liao, Hany Girgis, Amir Abdi, Hooman Vaseli, Jorden\n  Hetherington, Robert Rohling, Ken Gin, Teresa Tsang, Purang Abolmaesumi", "title": "On Modelling Label Uncertainty in Deep Neural Networks: Automatic\n  Estimation of Intra-observer Variability in 2D Echocardiography Quality\n  Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty of labels in clinical data resulting from intra-observer\nvariability can have direct impact on the reliability of assessments made by\ndeep neural networks. In this paper, we propose a method for modelling such\nuncertainty in the context of 2D echocardiography (echo), which is a routine\nprocedure for detecting cardiovascular disease at point-of-care. Echo imaging\nquality and acquisition time is highly dependent on the operator's experience\nlevel. Recent developments have shown the possibility of automating echo image\nquality quantification by mapping an expert's assessment of quality to the echo\nimage via deep learning techniques. Nevertheless, the observer variability in\nthe expert's assessment can impact the quality quantification accuracy. Here,\nwe aim to model the intra-observer variability in echo quality assessment as an\naleatoric uncertainty modelling regression problem with the introduction of a\nnovel method that handles the regression problem with categorical labels. A key\nfeature of our design is that only a single forward pass is sufficient to\nestimate the level of uncertainty for the network output. Compared to the $0.11\n\\pm 0.09$ absolute error (in a scale from 0 to 1) archived by the conventional\nregression method, the proposed method brings the error down to $0.09 \\pm\n0.08$, where the improvement is statistically significant and equivalents to\n$5.7\\%$ test accuracy improvement. The simplicity of the proposed approach\nmeans that it could be generalized to other applications of deep learning in\nmedical imaging, where there is often uncertainty in clinical labels.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 07:51:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liao", "Zhibin", ""], ["Girgis", "Hany", ""], ["Abdi", "Amir", ""], ["Vaseli", "Hooman", ""], ["Hetherington", "Jorden", ""], ["Rohling", "Robert", ""], ["Gin", "Ken", ""], ["Tsang", "Teresa", ""], ["Abolmaesumi", "Purang", ""]]}, {"id": "1911.00675", "submitter": "Otmar Ertl", "authors": "Otmar Ertl", "title": "ProbMinHash -- A Class of Locality-Sensitive Hash Algorithms for the\n  (Probability) Jaccard Similarity", "comments": "to be published in TKDE, source code available at\n  https://github.com/oertl/probminhash", "journal-ref": null, "doi": "10.1109/TKDE.2020.3021176", "report-no": null, "categories": "cs.DS cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability Jaccard similarity was recently proposed as a natural\ngeneralization of the Jaccard similarity to measure the proximity of sets whose\nelements are associated with relative frequencies or probabilities. In\ncombination with a hash algorithm that maps those weighted sets to compact\nsignatures which allow fast estimation of pairwise similarities, it constitutes\na valuable method for big data applications such as near-duplicate detection,\nnearest neighbor search, or clustering. This paper introduces a class of\none-pass locality-sensitive hash algorithms that are orders of magnitude faster\nthan the original approach. The performance gain is achieved by calculating\nsignature components not independently, but collectively. Four different\nalgorithms are proposed based on this idea. Two of them are statistically\nequivalent to the original approach and can be used as drop-in replacements.\nThe other two may even improve the estimation error by introducing statistical\ndependence between signature components. Moreover, the presented techniques can\nbe specialized for the conventional Jaccard similarity, resulting in highly\nefficient algorithms that outperform traditional minwise hashing and that are\nable to compete with the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 07:58:10 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 21:16:52 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 10:29:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ertl", "Otmar", ""]]}, {"id": "1911.00677", "submitter": "Harvineet Singh", "authors": "Harvineet Singh, Rina Singh, Vishwali Mhasawade, Rumi Chunara", "title": "Fairness Violations and Mitigation under Covariate Shift", "comments": "11 pages main and 7 pages supplementary, To appear at ACM FAccT '21,\n  Previous arXiv version arXiv:1911.00677v1 was presented at Workshop on Fair\n  ML for Health '19", "journal-ref": null, "doi": "10.1145/3442188.3445865", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning fair prediction models for unseen test sets\ndistributed differently from the train set. Stability against changes in data\ndistribution is an important mandate for responsible deployment of models. The\ndomain adaptation literature addresses this concern, albeit with the notion of\nstability limited to that of prediction accuracy. We identify sufficient\nconditions under which stable models, both in terms of prediction accuracy and\nfairness, can be learned. Using the causal graph describing the data and the\nanticipated shifts, we specify an approach based on feature selection that\nexploits conditional independencies in the data to estimate accuracy and\nfairness metrics for the test set. We show that for specific fairness\ndefinitions, the resulting model satisfies a form of worst-case optimality. In\ncontext of a healthcare task, we illustrate the advantages of the approach in\nmaking more equitable decisions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 08:10:58 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 20:03:54 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Singh", "Harvineet", ""], ["Singh", "Rina", ""], ["Mhasawade", "Vishwali", ""], ["Chunara", "Rumi", ""]]}, {"id": "1911.00685", "submitter": "Shengxin Zhu", "authors": "Shengxin Zhu and Andrew J Wathen", "title": "Sparse inversion for derivative of log determinant", "comments": "15", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for Gaussian process, marginal likelihood methods or restricted\nmaximum likelihood methods often require derivatives of log determinant terms.\nThese log determinants are usually parametric with variance parameters of the\nunderlying statistical models. This paper demonstrates that, when the\nunderlying matrix is sparse, how to take the advantage of sparse\ninversion---selected inversion which share the same sparsity as the original\nmatrix---to accelerate evaluating the derivative of log determinant.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 09:22:38 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhu", "Shengxin", ""], ["Wathen", "Andrew J", ""]]}, {"id": "1911.00686", "submitter": "Janis Keuper", "authors": "Ricard Durall, Margret Keuper, Franz-Josef Pfreundt, Janis Keuper", "title": "Unmasking DeepFakes with simple Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have recently achieved impressive results for many\nreal-world applications, successfully generating high-resolution and diverse\nsamples from complex datasets. Due to this improvement, fake digital contents\nhave proliferated growing concern and spreading distrust in image content,\nleading to an urgent need for automated ways to detect these AI-generated fake\nimages.\n  Despite the fact that many face editing algorithms seem to produce realistic\nhuman faces, upon closer examination, they do exhibit artifacts in certain\ndomains which are often hidden to the naked eye. In this work, we present a\nsimple way to detect such fake face images - so-called DeepFakes. Our method is\nbased on a classical frequency domain analysis followed by basic classifier.\nCompared to previous systems, which need to be fed with large amounts of\nlabeled data, our approach showed very good results using only a few annotated\ntraining samples and even achieved good accuracies in fully unsupervised\nscenarios. For the evaluation on high resolution face images, we combined\nseveral public datasets of real and fake faces into a new benchmark: Faces-HQ.\nGiven such high-resolution images, our approach reaches a perfect\nclassification accuracy of 100% when it is trained on as little as 20 annotated\nsamples. In a second experiment, in the evaluation of the medium-resolution\nimages of the CelebA dataset, our method achieves 100% accuracy supervised and\n96% in an unsupervised setting. Finally, evaluating a low-resolution video\nsequences of the FaceForensics++ dataset, our method achieves 91% accuracy\ndetecting manipulated videos.\n  Source Code: https://github.com/cc-hpc-itwm/DeepFakeDetection\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 09:42:25 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 08:24:41 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:51:41 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Durall", "Ricard", ""], ["Keuper", "Margret", ""], ["Pfreundt", "Franz-Josef", ""], ["Keuper", "Janis", ""]]}, {"id": "1911.00688", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Hikaru Kawarazaki", "title": "Model Specification Test with Unlabeled Data: Approach from Covariate\n  Shift", "comments": "The proof was wrong", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework of the model specification test in regression\nusing unlabeled test data. In many cases, we have conducted statistical\ninferences based on the assumption that we can correctly specify a model.\nHowever, it is difficult to confirm whether a model is correctly specified. To\novercome this problem, existing works have devised statistical tests for model\nspecification. Existing works have defined a correctly specified model in\nregression as a model with zero conditional mean of the error term over train\ndata only. Extending the definition in conventional statistical tests, we\ndefine a correctly specified model as a model with zero conditional mean of the\nerror term over any distribution of the explanatory variable. This definition\nis a natural consequence of the orthogonality of the explanatory variable and\nthe error term. If a model does not satisfy this condition, the model might\nlack robustness with regards to the distribution shift. The proposed method\nwould enable us to reject a misspecified model under our definition. By\napplying the proposed method, we can obtain a model that predicts the label for\nthe unlabeled test data well without losing the interpretability of the model.\nIn experiments, we show how the proposed method works for synthetic and\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 10:06:17 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 07:42:42 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kato", "Masahiro", ""], ["Kawarazaki", "Hikaru", ""]]}, {"id": "1911.00714", "submitter": "Yu Qi", "authors": "Yu Qi, Bin Liu, Yueming Wang, Gang Pan", "title": "Dynamic Ensemble Modeling Approach to Nonstationary Neural Decoding in\n  Brain-Computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interfaces (BCIs) have enabled prosthetic device control by\ndecoding motor movements from neural activities. Neural signals recorded from\ncortex exhibit nonstationary property due to abrupt noises and neuroplastic\nchanges in brain activities during motor control. Current state-of-the-art\nneural signal decoders such as Kalman filter assume fixed relationship between\nneural activities and motor movements, thus will fail if this assumption is not\nsatisfied. We propose a dynamic ensemble modeling (DyEnsemble) approach that is\ncapable of adapting to changes in neural signals by employing a proper\ncombination of decoding functions. The DyEnsemble method firstly learns a set\nof diverse candidate models. Then, it dynamically selects and combines these\nmodels online according to Bayesian updating mechanism. Our method can mitigate\nthe effect of noises and cope with different task behaviors by automatic model\nswitching, thus gives more accurate predictions. Experiments with neural data\ndemonstrate that the DyEnsemble method outperforms Kalman filters remarkably,\nand its advantage is more obvious with noisy signals.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 13:41:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Qi", "Yu", ""], ["Liu", "Bin", ""], ["Wang", "Yueming", ""], ["Pan", "Gang", ""]]}, {"id": "1911.00730", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "Estimating Certain Integral Probability Metric (IPM) is as Hard as\n  Estimating under the IPM", "comments": "15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1908.10324", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimax optimal rates for estimating a range of Integral\nProbability Metrics (IPMs) between two unknown probability measures, based on\n$n$ independent samples from them. Curiously, we show that estimating the IPM\nitself between probability measures, is not significantly easier than\nestimating the probability measures under the IPM. We prove that the minimax\noptimal rates for these two problems are multiplicatively equivalent, up to a\n$\\log \\log (n)/\\log (n)$ factor.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 15:12:10 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1911.00731", "submitter": "Saber Salehkaleybar", "authors": "Arsalan Sharifnassab, Saber Salehkaleybar, S. Jamaloddin Golestani", "title": "Order Optimal One-Shot Distributed Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.04634", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed statistical optimization in one-shot setting, where\nthere are $m$ machines each observing $n$ i.i.d. samples. Based on its observed\nsamples, each machine then sends an $O(\\log(mn))$-length message to a server,\nat which a parameter minimizing an expected loss is to be estimated. We propose\nan algorithm called Multi-Resolution Estimator (MRE) whose expected error is no\nlarger than $\\tilde{O}\\big(m^{-{1}/{\\max(d,2)}} n^{-1/2}\\big)$, where $d$ is\nthe dimension of the parameter space. This error bound meets existing lower\nbounds up to poly-logarithmic factors, and is thereby order optimal. The\nexpected error of MRE, unlike existing algorithms, tends to zero as the number\nof machines ($m$) goes to infinity, even when the number of samples per machine\n($n$) remains upper bounded by a constant. This property of the MRE algorithm\nmakes it applicable in new machine learning paradigms where $m$ is much larger\nthan $n$.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 15:14:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sharifnassab", "Arsalan", ""], ["Salehkaleybar", "Saber", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1911.00756", "submitter": "Neha Das", "authors": "Neha Das, Maximilian Karl, Philip Becker-Ehmck and Patrick van der\n  Smagt", "title": "Beta DVBF: Learning State-Space Models for Control from High Dimensional\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a model of dynamics from high-dimensional images can be a core\ningredient for success in many applications across different domains,\nespecially in sequential decision making. However, currently prevailing methods\nbased on latent-variable models are limited to working with low resolution\nimages only. In this work, we show that some of the issues with using\nhigh-dimensional observations arise from the discrepancy between the\ndimensionality of the latent and observable space, and propose solutions to\novercome them.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:26:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Das", "Neha", ""], ["Karl", "Maximilian", ""], ["Becker-Ehmck", "Philip", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1911.00757", "submitter": "Komlan Atitey", "authors": "Komlan Atitey, Pavel Loskot and Lyudmila Mihaylova", "title": "Variational Bayesian inference of hidden stochastic processes with\n  unknown parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating hidden processes from non-linear noisy observations is\nparticularly difficult when the parameters of these processes are not known.\nThis paper adopts a machine learning approach to devise variational Bayesian\ninference for such scenarios. In particular, a random process generated by the\nautoregressive moving average (ARMA) linear model is inferred from\nnon-linearity noise observations. The posterior distribution of hidden states\nare approximated by a set of weighted particles generated by the sequential\nMonte carlo (SMC) algorithm involving sampling with importance sampling\nresampling (SISR). Numerical efficiency and estimation accuracy of the proposed\ninference method are evaluated by computer simulations. Furthermore, the\nproposed inference method is demonstrated on a practical problem of estimating\nthe missing values in the gene expression time series assuming vector\nautoregressive (VAR) data model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:27:11 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Atitey", "Komlan", ""], ["Loskot", "Pavel", ""], ["Mihaylova", "Lyudmila", ""]]}, {"id": "1911.00765", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Adaptive Statistical Learning with Bayesian Differential Privacy", "comments": "WPES '17 Proceedings of the 2017 on Workshop on Privacy in the\n  Electronic Society, held in conjunction with ACM SIGSAC 25th Annual\n  Conference on Computer and Communications Security (CCS), Dallas, Texas, US,\n  October 2017", "journal-ref": null, "doi": "10.1145/3139550.3139556", "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning, a dataset is often partitioned into two parts: the\ntraining set and the holdout (i.e., testing) set. For instance, the training\nset is used to learn a predictor, and then the holdout set is used for\nestimating the accuracy of the predictor on the true distribution. However,\noften in practice, the holdout dataset is reused and the estimates tested on\nthe holdout dataset are chosen adaptively based on the results of prior\nestimates, leading to that the predictor may become dependent of the holdout\nset. Hence, overfitting may occur, and the learned models may not generalize\nwell to the unseen datasets. Prior studies have established connections between\nthe stability of a learning algorithm and its ability to generalize, but the\ntraditional generalization is not robust to adaptive composition. Recently,\nDwork et al. in NIPS, STOC, and Science 2015 show that the holdout dataset from\ni.i.d. data samples can be reused in adaptive statistical learning, if the\nestimates are perturbed and coordinated using techniques developed for\ndifferential privacy, which is a widely used notion to quantify privacy. Yet,\nthe results of Dwork et al. are applicable to only the case of i.i.d. samples.\nIn contrast, correlations between data samples exist because of various\nbehavioral, social, and genetic relationships between users. Our results in\nadaptive statistical learning generalize the results of Dwork et al. for i.i.d.\ndata samples to arbitrarily correlated data. Specifically, we show that the\nholdout dataset from correlated samples can be reused in adaptive statistical\nlearning, if the estimates are perturbed and coordinated using techniques\ndeveloped for Bayesian differential privacy, which is a privacy notion recently\nintroduced by Yang et al. in SIGMOD 2015 to broaden the application scenarios\nof differential privacy when data records are correlated.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:45:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00776", "submitter": "Changmao Li", "authors": "Changmao Li, Han He, Yunze Hao, Caleb Ziems", "title": "Ten-year Survival Prediction for Breast Cancer Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report assesses different machine learning approaches to 10-year\nsurvival prediction of breast cancer patients.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:53:32 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Changmao", ""], ["He", "Han", ""], ["Hao", "Yunze", ""], ["Ziems", "Caleb", ""]]}, {"id": "1911.00782", "submitter": "Bao Wang", "authors": "Bao Wang, Difan Zou, Quanquan Gu, Stanley Osher", "title": "Laplacian Smoothing Stochastic Gradient Markov Chain Monte Carlo", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important Markov Chain Monte Carlo (MCMC) method, stochastic gradient\nLangevin dynamics (SGLD) algorithm has achieved great success in Bayesian\nlearning and posterior sampling. However, SGLD typically suffers from slow\nconvergence rate due to its large variance caused by the stochastic gradient.\nIn order to alleviate these drawbacks, we leverage the recently developed\nLaplacian Smoothing (LS) technique and propose a Laplacian smoothing stochastic\ngradient Langevin dynamics (LS-SGLD) algorithm. We prove that for sampling from\nboth log-concave and non-log-concave densities, LS-SGLD achieves strictly\nsmaller discretization error in $2$-Wasserstein distance, although its mixing\nrate can be slightly slower. Experiments on both synthetic and real datasets\nverify our theoretical results, and demonstrate the superior performance of\nLS-SGLD on different machine learning tasks including posterior sampling,\nBayesian logistic regression and training Bayesian convolutional neural\nnetworks. The code is available at\n\\url{https://github.com/BaoWangMath/LS-MCMC}.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 20:32:11 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Bao", ""], ["Zou", "Difan", ""], ["Gu", "Quanquan", ""], ["Osher", "Stanley", ""]]}, {"id": "1911.00783", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Hawzhin Raoof Mohammed and Syed Rafay Hasan", "title": "A Stealthy Hardware Trojan Exploiting the Architectural Vulnerability of\n  Deep Learning Architectures: Input Interception Attack (IIA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures (DLA) have shown impressive performance in\ncomputer vision, natural language processing and so on. Many DLA make use of\ncloud computing to achieve classification due to the high computation and\nmemory requirements. Privacy and latency concerns resulting from cloud\ncomputing has inspired the deployment of DLA on embedded hardware accelerators.\nTo achieve short time-to-market and have access to global experts,\nstate-of-the-art techniques of DLA deployment on hardware accelerators are\noutsourced to untrusted third parties. This outsourcing raises security\nconcerns as hardware Trojans can be inserted into the hardware design of the\nmapped DLA of the hardware accelerator. We argue that existing hardware Trojan\nattacks highlighted in literature have no qualitative means how definite they\nare of the triggering of the Trojan. Also, most inserted Trojans show a obvious\nspike in the number of hardware resources utilized on the accelerator at the\ntime of triggering the Trojan or when the payload is active. In this paper, we\nintroduce a hardware Trojan attack called Input Interception Attack (IIA). In\nthis attack, we make use of the statistical properties of layer-by-layer output\nto ensure that asides from being stealthy. Our IIA is able to trigger with some\nmeasure of definiteness. Moreover, this IIA attack is tested on DLA used to\nclassify MNIST and Cifar-10 data sets. The attacked design utilizes\napproximately up to 2% more LUTs respectively compared to the un-compromised\ndesigns. Finally, this paper discusses potential defensive mechanisms that\ncould be used to combat such hardware Trojans based attack in hardware\naccelerators for DLA.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 20:34:16 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 16:07:07 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Mohammed", "Hawzhin Raoof", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.00804", "submitter": "Isabela Maria Carneiro de Albuquerque", "authors": "Isabela Albuquerque, Jo\\~ao Monteiro, Mohammad Darvishi, Tiago H.\n  Falk, and Ioannis Mitliagkas", "title": "Generalizing to unseen domains via distribution matching", "comments": "Major changes to the text and the title. Added experiments on\n  affective state prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning results typically rely on assumptions of i.i.d. data.\nUnfortunately, those assumptions are commonly violated in practice. In this\nwork, we tackle this problem by focusing on domain generalization: a\nformalization where the data generating process at test time may yield samples\nfrom never-before-seen domains (distributions). Our work relies on a simple\nlemma: by minimizing a notion of discrepancy between all pairs from a set of\ngiven domains, we also minimize the discrepancy between any pairs of mixtures\nof domains. Using this result, we derive a generalization bound for our\nsetting. We then show that low risk over unseen domains can be achieved by\nrepresenting the data in a space where (i) the training distributions are\nindistinguishable, and (ii) relevant information for the task at hand is\npreserved. Minimizing the terms in our bound yields an adversarial formulation\nwhich estimates and minimizes pairwise discrepancies. We validate our proposed\nstrategy on standard domain generalization benchmarks, outperforming a number\nof recently introduced methods. Notably, we tackle a real-world application\nwhere the underlying data corresponds to multi-channel electroencephalography\ntime series from different subjects, each considered as a distinct domain.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 01:03:15 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 22:33:52 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 21:04:02 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 17:42:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Albuquerque", "Isabela", ""], ["Monteiro", "Jo\u00e3o", ""], ["Darvishi", "Mohammad", ""], ["Falk", "Tiago H.", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1911.00809", "submitter": "Ruosong Wang", "authors": "Zhiyuan Li, Ruosong Wang, Dingli Yu, Simon S. Du, Wei Hu, Ruslan\n  Salakhutdinov, Sanjeev Arora", "title": "Enhanced Convolutional Neural Tangent Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that for training with $\\ell_2$ loss, convolutional\nneural networks (CNNs) whose width (number of channels in convolutional layers)\ngoes to infinity correspond to regression with respect to the CNN Gaussian\nProcess kernel (CNN-GP) if only the last layer is trained, and correspond to\nregression with respect to the Convolutional Neural Tangent Kernel (CNTK) if\nall layers are trained. An exact algorithm to compute CNTK (Arora et al., 2019)\nyielded the finding that classification accuracy of CNTK on CIFAR-10 is within\n6-7% of that of that of the corresponding CNN architecture (best figure being\naround 78%) which is interesting performance for a fixed kernel. Here we show\nhow to significantly enhance the performance of these kernels using two ideas.\n(1) Modifying the kernel using a new operation called Local Average Pooling\n(LAP) which preserves efficient computability of the kernel and inherits the\nspirit of standard data augmentation using pixel shifts. Earlier papers were\nunable to incorporate naive data augmentation because of the quadratic training\ncost of kernel regression. This idea is inspired by Global Average Pooling\n(GAP), which we show for CNN-GP and CNTK is equivalent to full translation data\naugmentation. (2) Representing the input image using a pre-processing technique\nproposed by Coates et al. (2011), which uses a single convolutional layer\ncomposed of random image patches. On CIFAR-10, the resulting kernel, CNN-GP\nwith LAP and horizontal flip data augmentation, achieves 89% accuracy, matching\nthe performance of AlexNet (Krizhevsky et al., 2012). Note that this is the\nbest such result we know of for a classifier that is not a trained neural\nnetwork. Similar improvements are obtained for Fashion-MNIST.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:24:39 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Zhiyuan", ""], ["Wang", "Ruosong", ""], ["Yu", "Dingli", ""], ["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Salakhutdinov", "Ruslan", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1911.00828", "submitter": "Andrew Cohen", "authors": "Andrew Cohen and Lei Yu and Xingye Qiao and Xiangrong Tong", "title": "Maximum Entropy Diverse Exploration: Disentangling Maximum Entropy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two hitherto disconnected threads of research, diverse exploration (DE) and\nmaximum entropy RL have addressed a wide range of problems facing reinforcement\nlearning algorithms via ostensibly distinct mechanisms. In this work, we\nidentify a connection between these two approaches. First, a\ndiscriminator-based diversity objective is put forward and connected to\ncommonly used divergence measures. We then extend this objective to the maximum\nentropy framework and propose an algorithm Maximum Entropy Diverse Exploration\n(MEDE) which provides a principled method to learn diverse behaviors. A\ntheoretical investigation shows that the set of policies learned by MEDE\ncapture the same modalities as the optimal maximum entropy policy. In effect,\nthe proposed algorithm disentangles the maximum entropy policy into its\ndiverse, constituent policies. Experiments show that MEDE is superior to the\nstate of the art in learning high performing and diverse policies.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 04:25:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cohen", "Andrew", ""], ["Yu", "Lei", ""], ["Qiao", "Xingye", ""], ["Tong", "Xiangrong", ""]]}, {"id": "1911.00847", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Andri Ashfahani and Mohamad Abdul Hady", "title": "Weakly Supervised Deep Learning Approach in Streaming Environments", "comments": "This paper has been accepted for publication in The 2019 IEEE\n  International Conference on Big Data (IEEE BigData 2019), Los Angeles, CA,\n  USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The feasibility of existing data stream algorithms is often hindered by the\nweakly supervised condition of data streams. A self-evolving deep neural\nnetwork, namely Parsimonious Network (ParsNet), is proposed as a solution to\nvarious weakly-supervised data stream problems. A self-labelling strategy with\nhedge (SLASH) is proposed in which its auto-correction mechanism copes with\n\\textit{the accumulation of mistakes} significantly affecting the model's\ngeneralization. ParsNet is developed from a closed-loop configuration of the\nself-evolving generative and discriminative training processes exploiting\nshared parameters in which its structure flexibly grows and shrinks to overcome\nthe issue of concept drift with/without labels. The numerical evaluation has\nbeen performed under two challenging problems, namely sporadic access to ground\ntruth and infinitely delayed access to the ground truth. Our numerical study\nshows the advantage of ParsNet with a substantial margin from its counterparts\nin the high-dimensional data streams and infinite delay simulation protocol. To\nsupport the reproducible research initiative, the source code of ParsNet along\nwith supplementary materials are made available at https://bit.ly/2qNW7p4.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 07:31:25 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 14:40:51 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 12:28:12 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 07:47:19 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Ashfahani", "Andri", ""], ["Hady", "Mohamad Abdul", ""]]}, {"id": "1911.00870", "submitter": "Shai Rozenberg", "authors": "Shai Rozenberg, Gal Elidan, Ran El-Yaniv", "title": "MadNet: Using a MAD Optimization for Defending Against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned with the defense of deep models against adversarial\nattacks. Inspired by the certificate defense approach, we propose a maximal\nadversarial distortion (MAD) optimization method for robustifying deep\nnetworks. MAD captures the idea of increasing separability of class clusters in\nthe embedding space while decreasing the network sensitivity to small\ndistortions. Given a deep neural network (DNN) for a classification problem, an\napplication of MAD optimization results in MadNet, a version of the original\nnetwork, now equipped with an adversarial defense mechanism. MAD optimization\nis intuitive, effective and scalable, and the resulting MadNet can improve the\noriginal accuracy. We present an extensive empirical study demonstrating that\nMadNet improves adversarial robustness performance compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 11:21:35 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 19:05:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rozenberg", "Shai", ""], ["Elidan", "Gal", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1911.00886", "submitter": "Yikai Wang", "authors": "Yikai Wang, Liang Zhang, Quanyu Dai, Fuchun Sun, Bo Zhang, Yang He,\n  Weipeng Yan, Yongjun Bao", "title": "Regularized Adversarial Sampling and Deep Time-aware Attention for\n  Click-Through Rate Prediction", "comments": "CIKM 2019 Long Paper, 10 pages", "journal-ref": null, "doi": "10.1145/3357384.3357936", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the performance of click-through rate (CTR) prediction remains one\nof the core tasks in online advertising systems. With the rise of deep\nlearning, CTR prediction models with deep networks remarkably enhance model\ncapacities. In deep CTR models, exploiting users' historical data is essential\nfor learning users' behaviors and interests. As existing CTR prediction works\nneglect the importance of the temporal signals when embed users' historical\nclicking records, we propose a time-aware attention model which explicitly uses\nabsolute temporal signals for expressing the users' periodic behaviors and\nrelative temporal signals for expressing the temporal relation between items.\nBesides, we propose a regularized adversarial sampling strategy for negative\nsampling which eases the classification imbalance of CTR data and can make use\nof the strong guidance provided by the observed negative CTR samples. The\nadversarial sampling strategy significantly improves the training efficiency,\nand can be co-trained with the time-aware attention model seamlessly.\nExperiments are conducted on real-world CTR datasets from both in-station and\nout-station advertising places.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 13:40:57 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Yikai", ""], ["Zhang", "Liang", ""], ["Dai", "Quanyu", ""], ["Sun", "Fuchun", ""], ["Zhang", "Bo", ""], ["He", "Yang", ""], ["Yan", "Weipeng", ""], ["Bao", "Yongjun", ""]]}, {"id": "1911.00887", "submitter": "Marc Fischer", "authors": "Marc Fischer, Matthew Mirman, Steven Stalder, Martin Vechev", "title": "Online Robustness Training for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep reinforcement learning (RL), adversarial attacks can trick an agent\ninto unwanted states and disrupt training. We propose a system called Robust\nStudent-DQN (RS-DQN), which permits online robustness training alongside Q\nnetworks, while preserving competitive performance. We show that RS-DQN can be\ncombined with (i) state-of-the-art adversarial training and (ii) provably\nrobust training to obtain an agent that is resilient to strong attacks during\ntraining and evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 13:44:42 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 13:09:37 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 07:12:00 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Fischer", "Marc", ""], ["Mirman", "Matthew", ""], ["Stalder", "Steven", ""], ["Vechev", "Martin", ""]]}, {"id": "1911.00888", "submitter": "Mingkui Tan", "authors": "Jiezhang Cao, Langyuan Mo, Yifan Zhang, Kui Jia, Chunhua Shen, Mingkui\n  Tan", "title": "Multi-marginal Wasserstein GAN", "comments": "This paper is accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple marginal matching problem aims at learning mappings to match a\nsource domain to multiple target domains and it has attracted great attention\nin many applications, such as multi-domain image translation. However,\naddressing this problem has two critical challenges: (i) Measuring the\nmulti-marginal distance among different domains is very intractable; (ii) It is\nvery difficult to exploit cross-domain correlations to match the target domain\ndistributions. In this paper, we propose a novel Multi-marginal Wasserstein GAN\n(MWGAN) to minimize Wasserstein distance among domains. Specifically, with the\nhelp of multi-marginal optimal transport theory, we develop a new adversarial\nobjective function with inner- and inter-domain constraints to exploit\ncross-domain correlations. Moreover, we theoretically analyze the\ngeneralization performance of MWGAN, and empirically evaluate it on the\nbalanced and imbalanced translation tasks. Extensive experiments on toy and\nreal-world datasets demonstrate the effectiveness of MWGAN.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 13:47:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cao", "Jiezhang", ""], ["Mo", "Langyuan", ""], ["Zhang", "Yifan", ""], ["Jia", "Kui", ""], ["Shen", "Chunhua", ""], ["Tan", "Mingkui", ""]]}, {"id": "1911.00890", "submitter": "Marylou Gabri\\'e", "authors": "Marylou Gabri\\'e", "title": "Mean-field inference methods for neural networks", "comments": null, "journal-ref": "JPhysA 2020", "doi": "10.1088/1751-8121/ab7f65", "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms relying on deep neural networks recently allowed\na great leap forward in artificial intelligence. Despite the popularity of\ntheir applications, the efficiency of these algorithms remains largely\nunexplained from a theoretical point of view. The mathematical description of\nlearning problems involves very large collections of interacting random\nvariables, difficult to handle analytically as well as numerically. This\ncomplexity is precisely the object of study of statistical physics. Its\nmission, originally pointed towards natural systems, is to understand how\nmacroscopic behaviors arise from microscopic laws. Mean-field methods are one\ntype of approximation strategy developed in this view. We review a selection of\nclassical mean-field methods and recent progress relevant for inference in\nneural networks. In particular, we remind the principles of derivations of\nhigh-temperature expansions, the replica method and message passing algorithms,\nhighlighting their equivalences and complementarities. We also provide\nreferences for past and current directions of research on neural networks\nrelying on mean-field methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:04:57 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 12:13:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Gabri\u00e9", "Marylou", ""]]}, {"id": "1911.00896", "submitter": "Amina Asif", "authors": "Amina Asif and Fayyaz ul Amir Afsar Minhas", "title": "Generalized Learning with Rejection for Classification and Regression\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with rejection (LWR) allows development of machine learning systems\nwith the ability to discard low confidence decisions generated by a prediction\nmodel. That is, just like human experts, LWR allows machine models to abstain\nfrom generating a prediction when reliability of the prediction is expected to\nbe low. Several frameworks for this learning with rejection have been proposed\nin the literature. However, most of them work for classification problems only\nand regression with rejection has not been studied in much detail. In this\nwork, we present a neural framework for LWR based on a generalized meta-loss\nfunction that involves simultaneous training of two neural network models: a\npredictor model for generating predictions and a rejecter model for deciding\nwhether the prediction should be accepted or rejected. The proposed framework\ncan be used for classification as well as regression and other related machine\nlearning tasks. We have demonstrated the applicability and effectiveness of the\nmethod on synthetically generated data as well as benchmark datasets from UCI\nmachine learning repository for both classification and regression problems.\nDespite being simpler in implementation, the proposed scheme for learning with\nrejection has shown to perform at par or better than previously proposed\nmethods. Furthermore, we have applied the method to the problem of hurricane\nintensity prediction from satellite imagery. Significant improvement in\nperformance as compared to conventional supervised methods shows the\neffectiveness of the proposed scheme in real-world regression problems.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:21:04 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Asif", "Amina", ""], ["Minhas", "Fayyaz ul Amir Afsar", ""]]}, {"id": "1911.00922", "submitter": "Yuhao Su", "authors": "Yuhao Su and Jie Ding", "title": "Variable Grouping Based Bayesian Additive Regression Tree", "comments": "5 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using ensemble methods for regression has been a large success in obtaining\nhigh-accuracy prediction. Examples are Bagging, Random forest, Boosting, BART\n(Bayesian additive regression tree), and their variants. In this paper, we\npropose a new perspective named variable grouping to enhance the predictive\nperformance. The main idea is to seek for potential grouping of variables in\nsuch way that there is no nonlinear interaction term between variables of\ndifferent groups. Given a sum-of-learner model, each learner will only be\nresponsible for one group of variables, which would be more efficient in\nmodeling nonlinear interactions. We propose a two-stage method named variable\ngrouping based Bayesian additive regression tree (GBART) with a well-developed\npython package gbart available. The first stage is to search for potential\ninteractions and an appropriate grouping of variables. The second stage is to\nbuild a final model based on the discovered groups. Experiments on synthetic\nand real data show that the proposed method can perform significantly better\nthan classical approaches.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:08:56 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 02:16:02 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Su", "Yuhao", ""], ["Ding", "Jie", ""]]}, {"id": "1911.00926", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Elmar Rueckert, Jan Peters", "title": "Learning Algorithmic Solutions to Symbolic Planning Tasks with a Neural\n  Computer Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of intelligent behavior is the ability to learn abstract\nstrategies that transfer to unfamiliar problems. Therefore, we present a novel\narchitecture, based on memory-augmented networks, that is inspired by the von\nNeumann and Harvard architectures of modern computers. This architecture\nenables the learning of abstract algorithmic solutions via Evolution Strategies\nin a reinforcement learning setting. Applied to Sokoban, sliding block puzzle\nand robotic manipulation tasks, we show that the architecture can learn\nalgorithmic solutions with strong generalization and abstraction: scaling to\narbitrary task configurations and complexities, and being independent of both\nthe data representation and the task domain.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:02:13 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 11:21:39 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""]]}, {"id": "1911.00934", "submitter": "Jun Sun Dr.", "authors": "Jun Sun, Gang Wang, Georgios B. Giannakis, Qinmin Yang, and Zaiyue\n  Yang", "title": "Finite-Sample Analysis of Decentralized Temporal-Difference Learning\n  with Linear Function Approximation", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.SY eess.SY math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the emerging use of multi-agent reinforcement learning (MARL) in\nengineering applications such as networked robotics, swarming drones, and\nsensor networks, we investigate the policy evaluation problem in a fully\ndecentralized setting, using temporal-difference (TD) learning with linear\nfunction approximation to handle large state spaces in practice. The goal of a\ngroup of agents is to collaboratively learn the value function of a given\npolicy from locally private rewards observed in a shared environment, through\nexchanging local estimates with neighbors. Despite their simplicity and\nwidespread use, our theoretical understanding of such decentralized TD learning\nalgorithms remains limited. Existing results were obtained based on i.i.d. data\nsamples, or by imposing an `additional' projection step to control the\n`gradient' bias incurred by the Markovian observations. In this paper, we\nprovide a finite-sample analysis of the fully decentralized TD(0) learning\nunder both i.i.d. as well as Markovian samples, and prove that all local\nestimates converge linearly to a small neighborhood of the optimum. The\nresultant error bounds are the first of its type---in the sense that they hold\nunder the most practical assumptions ---which is made possible by means of a\nnovel multi-step Lyapunov analysis.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:30:07 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:30:10 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Sun", "Jun", ""], ["Wang", "Gang", ""], ["Giannakis", "Georgios B.", ""], ["Yang", "Qinmin", ""], ["Yang", "Zaiyue", ""]]}, {"id": "1911.00936", "submitter": "Daeryong Kim", "authors": "Daeryong Kim and Bongwon Suh", "title": "Enhancing VAEs for Collaborative Filtering: Flexible Priors & Gating\n  Mechanisms", "comments": null, "journal-ref": "In Thirteenth ACM Conference on Recommender Systems (RecSys '19),\n  September 16-20, 2019, Copenhagen, Denmark. ACM, New York, NY, USA, 5 pages", "doi": "10.1145/3298689.3347015", "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based models for collaborative filtering have started to gain\nattention recently. One branch of research is based on using deep generative\nmodels to model user preferences where variational autoencoders were shown to\nproduce state-of-the-art results. However, there are some potentially\nproblematic characteristics of the current variational autoencoder for CF. The\nfirst is the too simplistic prior that VAEs incorporate for learning the latent\nrepresentations of user preference. The other is the model's inability to learn\ndeeper representations with more than one hidden layer for each network. Our\ngoal is to incorporate appropriate techniques to mitigate the aforementioned\nproblems of variational autoencoder CF and further improve the recommendation\nperformance. Our work is the first to apply flexible priors to collaborative\nfiltering and show that simple priors (in original VAEs) may be too restrictive\nto fully model user preferences and setting a more flexible prior gives\nsignificant gains. We experiment with the VampPrior, originally proposed for\nimage generation, to examine the effect of flexible priors in CF. We also show\nthat VampPriors coupled with gating mechanisms outperform SOTA results\nincluding the Variational Autoencoder for Collaborative Filtering by meaningful\nmargins on 2 popular benchmark datasets (MovieLens & Netflix).\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:42:57 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kim", "Daeryong", ""], ["Suh", "Bongwon", ""]]}, {"id": "1911.00937", "submitter": "Qiyang Li", "authors": "Qiyang Li, Saminul Haque, Cem Anil, James Lucas, Roger Grosse,\n  J\\\"orn-Henrik Jacobsen", "title": "Preventing Gradient Attenuation in Lipschitz Constrained Convolutional\n  Networks", "comments": "9 main pages, 31 pages total, 3 figures. Accepted at 33rd Conference\n  on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipschitz constraints under L2 norm on deep neural networks are useful for\nprovable adversarial robustness bounds, stable training, and Wasserstein\ndistance estimation. While heuristic approaches such as the gradient penalty\nhave seen much practical success, it is challenging to achieve similar\npractical performance while provably enforcing a Lipschitz constraint. In\nprinciple, one can design Lipschitz constrained architectures using the\ncomposition property of Lipschitz functions, but Anil et al. recently\nidentified a key obstacle to this approach: gradient norm attenuation. They\nshowed how to circumvent this problem in the case of fully connected networks\nby designing each layer to be gradient norm preserving. We extend their\napproach to train scalable, expressive, provably Lipschitz convolutional\nnetworks. In particular, we present the Block Convolution Orthogonal\nParameterization (BCOP), an expressive parameterization of orthogonal\nconvolution operations. We show that even though the space of orthogonal\nconvolutions is disconnected, the largest connected component of BCOP with 2n\nchannels can represent arbitrary BCOP convolutions over n channels. Our BCOP\nparameterization allows us to train large convolutional networks with provable\nLipschitz bounds. Empirically, we find that it is competitive with existing\napproaches to provable adversarial robustness and Wasserstein distance\nestimation.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:57:10 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 21:22:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Qiyang", ""], ["Haque", "Saminul", ""], ["Anil", "Cem", ""], ["Lucas", "James", ""], ["Grosse", "Roger", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "1911.00941", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Valery Manokhin, and Alex\n  Gammerman", "title": "Computationally efficient versions of conformal predictive distributions", "comments": "31 pages, 14 figures, 1 table. The conference version published in\n  the Proceedings of COPA 2018, and the journal version is to appear in\n  Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conformal predictive systems are a recent modification of conformal\npredictors that output, in regression problems, probability distributions for\nlabels of test observations rather than set predictions. The extra information\nprovided by conformal predictive systems may be useful, e.g., in decision\nmaking problems. Conformal predictive systems inherit the relative\ncomputational inefficiency of conformal predictors. In this paper we discuss\ntwo computationally efficient versions of conformal predictive systems, which\nwe call split conformal predictive systems and cross-conformal predictive\nsystems. The main advantage of split conformal predictive systems is their\nguaranteed validity, whereas for cross-conformal predictive systems validity\nonly holds empirically and in the absence of excessive randomization. The main\nadvantage of cross-conformal predictive systems is their greater predictive\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 18:18:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Vovk", "Vladimir", ""], ["Petej", "Ivan", ""], ["Nouretdinov", "Ilia", ""], ["Manokhin", "Valery", ""], ["Gammerman", "Alex", ""]]}, {"id": "1911.00949", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Xiangnan Kong, Elke Rundensteiner, Jihane Zouaoui,\n  Aditya Arora", "title": "Attributed Sequence Embedding", "comments": "Accepted by IEEE Big Data 2019", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006481", "report-no": null, "categories": "cs.LG cs.CL cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining tasks over sequential data, such as clickstreams and gene sequences,\nrequire a careful design of embeddings usable by learning algorithms. Recent\nresearch in feature learning has been extended to sequential data, where each\ninstance consists of a sequence of heterogeneous items with a variable length.\nHowever, many real-world applications often involve attributed sequences, where\neach instance is composed of both a sequence of categorical items and a set of\nattributes. In this paper, we study this new problem of attributed sequence\nembedding, where the goal is to learn the representations of attributed\nsequences in an unsupervised fashion. This problem is core to many important\ndata mining tasks ranging from user behavior analysis to the clustering of gene\nsequences. This problem is challenging due to the dependencies between\nsequences and their associated attributes. We propose a deep multimodal\nlearning framework, called NAS, to produce embeddings of attributed sequences.\nThe embeddings are task independent and can be used on various mining tasks of\nattributed sequences. We demonstrate the effectiveness of our embeddings of\nattributed sequences in various unsupervised learning tasks on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:16:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Kong", "Xiangnan", ""], ["Rundensteiner", "Elke", ""], ["Zouaoui", "Jihane", ""], ["Arora", "Aditya", ""]]}, {"id": "1911.00954", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Emma Brunskill", "title": "Problem Dependent Reinforcement Learning Bounds Which Can Identify\n  Bandit Structure in MDPs", "comments": null, "journal-ref": "International Conference on Machine Learning, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make good decision under uncertainty an agent must learn from\nobservations. To do so, two of the most common frameworks are Contextual\nBandits and Markov Decision Processes (MDPs). In this paper, we study whether\nthere exist algorithms for the more general framework (MDP) which automatically\nprovide the best performance bounds for the specific problem at hand without\nuser intervention and without modifying the algorithm. In particular, it is\nfound that a very minor variant of a recently proposed reinforcement learning\nalgorithm for MDPs already matches the best possible regret bound $\\tilde O\n(\\sqrt{SAT})$ in the dominant term if deployed on a tabular Contextual Bandit\nproblem despite the agent being agnostic to such setting.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:44:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zanette", "Andrea", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.00958", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "Clustering in Partially Labeled Stochastic Block Models via Total\n  Variation Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main task in data analysis is to organize data points into coherent groups\nor clusters. The stochastic block model is a probabilistic model for the\ncluster structure. This model prescribes different probabilities for the\npresence of edges within a cluster and between different clusters. We assume\nthat the cluster assignments are known for at least one data point in each\ncluster. In such a partially labeled stochastic block model, clustering amounts\nto estimating the cluster assignments of the remaining data points. We study\ntotal variation minimization as a method for this clustering task. We implement\nthe resulting clustering algorithm as a highly scalable message-passing\nprotocol. We also provide a condition on the model parameters such that total\nvariation minimization allows for accurate clustering.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:57:38 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 17:22:33 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1911.00972", "submitter": "Tian Li", "authors": "Tian Li, Zaoxing Liu, Vyas Sekar, Virginia Smith", "title": "Privacy for Free: Communication-Efficient Learning with Differential\n  Privacy Using Sketches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication and privacy are two critical concerns in distributed learning.\nMany existing works treat these concerns separately. In this work, we argue\nthat a natural connection exists between methods for communication reduction\nand privacy preservation in the context of distributed machine learning. In\nparticular, we prove that Count Sketch, a simple method for data stream\nsummarization, has inherent differential privacy properties. Using these\nderived privacy guarantees, we propose a novel sketch-based framework\n(DiffSketch) for distributed learning, where we compress the transmitted\nmessages via sketches to simultaneously achieve communication efficiency and\nprovable privacy benefits. Our evaluation demonstrates that DiffSketch can\nprovide strong differential privacy guarantees (e.g., $\\varepsilon$= 1) and\nreduce communication by 20-50x with only marginal decreases in accuracy.\nCompared to baselines that treat privacy and communication separately,\nDiffSketch improves absolute test accuracy by 5%-50% while offering the same\nprivacy guarantees and communication compression.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:19:13 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 18:35:54 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Li", "Tian", ""], ["Liu", "Zaoxing", ""], ["Sekar", "Vyas", ""], ["Smith", "Virginia", ""]]}, {"id": "1911.00980", "submitter": "Yichong Xu", "authors": "Yichong Xu, Aparna Joshi, Aarti Singh, Artur Dubrawski", "title": "Zeroth Order Non-convex optimization with Dueling-Choice Bandits", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel setting of zeroth order non-convex optimization, where in\naddition to querying the function value at a given point, we can also duel two\npoints and get the point with the larger function value. We refer to this\nsetting as optimization with dueling-choice bandits since both direct queries\nand duels are available for optimization. We give the COMP-GP-UCB algorithm\nbased on GP-UCB (Srinivas et al., 2009), where instead of directly querying the\npoint with the maximum Upper Confidence Bound (UCB), we perform a constrained\noptimization and use comparisons to filter out suboptimal points. COMP-GP-UCB\ncomes with theoretical guarantee of $O(\\frac{\\Phi}{\\sqrt{T}})$ on simple regret\nwhere $T$ is the number of direct queries and $\\Phi$ is an improved information\ngain corresponding to a comparison based constraint set that restricts the\nsearch space for the optimum. In contrast, in the direct query only setting,\n$\\Phi$ depends on the entire domain. Finally, we present experimental results\nto show the efficacy of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:46:17 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Xu", "Yichong", ""], ["Joshi", "Aparna", ""], ["Singh", "Aarti", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1911.00995", "submitter": "Nicholas James", "authors": "Nick James, Max Menzies, Lamiae Azizi, Jennifer Chan", "title": "Novel semi-metrics for multivariate change point analysis and anomaly\n  detection", "comments": "Accepted manuscript. Minor edits since v2. Equal contribution from\n  first two authors", "journal-ref": "Physica D: Nonlinear Phenomena 412 (2020) 132636", "doi": "10.1016/j.physd.2020.132636", "report-no": null, "categories": "cs.LG math.DS stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for determining similarity and anomalies\nbetween time series, most practically effective in large collections of (likely\nrelated) time series, by measuring distances between structural breaks within\nsuch a collection. We introduce a class of \\emph{semi-metric} distance\nmeasures, which we term \\emph{MJ distances}. These semi-metrics provide an\nadvantage over existing options such as the Hausdorff and Wasserstein metrics.\nWe prove they have desirable properties, including better sensitivity to\noutliers, while experiments on simulated data demonstrate that they uncover\nsimilarity within collections of time series more effectively. Semi-metrics\ncarry a potential disadvantage: without the triangle inequality, they may not\nsatisfy a \"transitivity property of closeness.\" We analyse this failure with\nproof and introduce an computational method to investigate, in which we\ndemonstrate that our semi-metrics violate transitivity infrequently and mildly.\nFinally, we apply our methods to cryptocurrency and measles data, introducing a\njudicious application of eigenvalue analysis.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:04:30 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 14:58:46 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 10:44:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["James", "Nick", ""], ["Menzies", "Max", ""], ["Azizi", "Lamiae", ""], ["Chan", "Jennifer", ""]]}, {"id": "1911.00996", "submitter": "Shigang Liu", "authors": "Shigang Liu, Jun Zhang, Yang Xiang, Wanlei Zhou, Dongxi Xiang", "title": "A Study of Data Pre-processing Techniques for Imbalanced Biomedical Data\n  Classification", "comments": "This paper is scheduled for inclusion in V16 N3 2020, International\n  Journal of Bioinformatics Research and Applications (IJBRA)", "journal-ref": "V16 N3, International Journal of Bioinformatics Research and\n  Applications (IJBRA), 2020", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Biomedical data are widely accepted in developing prediction models for\nidentifying a specific tumor, drug discovery and classification of human\ncancers. However, previous studies usually focused on different classifiers,\nand overlook the class imbalance problem in real-world biomedical datasets.\nThere are a lack of studies on evaluation of data pre-processing techniques,\nsuch as resampling and feature selection, on imbalanced biomedical data\nlearning. The relationship between data pre-processing techniques and the data\ndistributions has never been analysed in previous studies. This article mainly\nfocuses on reviewing and evaluating some popular and recently developed\nresampling and feature selection methods for class imbalance learning. We\nanalyse the effectiveness of each technique from data distribution perspective.\nExtensive experiments have been done based on five classifiers, four\nperformance measures, eight learning techniques across twenty real-world\ndatasets. Experimental results show that: (1) resampling and feature selection\ntechniques exhibit better performance using support vector machine (SVM)\nclassifier. However, resampling and Feature Selection techniques perform poorly\nwhen using C4.5 decision tree and Linear discriminant analysis classifiers; (2)\nfor datasets with different distributions, techniques such as Random\nundersampling and Feature Selection perform better than other data\npre-processing methods with T Location-Scale distribution when using SVM and\nKNN (K-nearest neighbours) classifiers. Random oversampling outperforms other\nmethods on Negative Binomial distribution using Random Forest classifier with\nlower level of imbalance ratio; (3) Feature Selection outperforms other data\npre-processing methods in most cases, thus, Feature Selection with SVM\nclassifier is the best choice for imbalanced biomedical data learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:32:32 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Shigang", ""], ["Zhang", "Jun", ""], ["Xiang", "Yang", ""], ["Zhou", "Wanlei", ""], ["Xiang", "Dongxi", ""]]}, {"id": "1911.00997", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang, Ruslan Salakhutdinov", "title": "Multiple Futures Prediction", "comments": "In proceedings of NeurIPS 2019, Vancouver, British Columbia, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal prediction is critical for making intelligent and robust decisions\nin complex dynamic environments. Motion prediction needs to model the\ninherently uncertain future which often contains multiple potential outcomes,\ndue to multi-agent interactions and the latent goals of others. Towards these\ngoals, we introduce a probabilistic framework that efficiently learns latent\nvariables to jointly model the multi-step future motions of agents in a scene.\nOur framework is data-driven and learns semantically meaningful latent\nvariables to represent the multimodal future, without requiring explicit\nlabels. Using a dynamic attention-based state encoder, we learn to encode the\npast as well as the future interactions among agents, efficiently scaling to\nany number of agents. Finally, our model can be used for planning via computing\na conditional probability density over the trajectories of other agents given a\nhypothetical rollout of the 'self' agent. We demonstrate our algorithms by\npredicting vehicle trajectories of both simulated and real data, demonstrating\nthe state-of-the-art results on several vehicle trajectory datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:42:01 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:36:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Tang", "Yichuan Charlie", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1911.01004", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Raed Al Kontar", "title": "Why Non-myopic Bayesian Optimization is Promising and How Far Should We\n  Look-ahead? A Study via Rollout", "comments": "12 pages, 1 figure Accepted by AISTATS 2020", "journal-ref": "Artificial Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lookahead, also known as non-myopic, Bayesian optimization (BO) aims to find\noptimal sampling policies through solving a dynamic programming (DP)\nformulation that maximizes a long-term reward over a rolling horizon. Though\npromising, lookahead BO faces the risk of error propagation through its\nincreased dependence on a possibly mis-specified model. In this work we focus\non the rollout approximation for solving the intractable DP. We first prove the\nimproving nature of rollout in tackling lookahead BO and provide a sufficient\ncondition for the used heuristic to be rollout improving. We then provide both\na theoretical and practical guideline to decide on the rolling horizon\nstagewise. This guideline is built on quantifying the negative effect of a\nmis-specified model. To illustrate our idea, we provide case studies on both\nsingle and multi-information source BO. Empirical results show the advantageous\nproperties of our method over several myopic and non-myopic BO algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:57:40 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 03:02:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yue", "Xubo", ""], ["Kontar", "Raed Al", ""]]}, {"id": "1911.01005", "submitter": "Fan Yang", "authors": "Fan Yang, Zijian Zhang, Haofan Wang, Yuening Li, Xia Hu", "title": "XDeep: An Interpretation Tool for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XDeep is an open-source Python package developed to interpret deep models for\nboth practitioners and researchers. Overall, XDeep takes a trained deep neural\nnetwork (DNN) as the input, and generates relevant interpretations as the\noutput with the post-hoc manner. From the functionality perspective, XDeep\nintegrates a wide range of interpretation algorithms from the\nstate-of-the-arts, covering different types of methodologies, and is capable of\nproviding both local explanation and global explanation for DNN when\ninterpreting model behaviours. With the well-documented API designed in XDeep,\nend-users can easily obtain the interpretations for their deep models at hand\nwith several lines of codes, and compare the results among different\nalgorithms. XDeep is generally compatible with Python 3, and can be installed\nthrough Python Package Index (PyPI). The source codes are available at:\nhttps://github.com/datamllab/xdeep.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:59:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yang", "Fan", ""], ["Zhang", "Zijian", ""], ["Wang", "Haofan", ""], ["Li", "Yuening", ""], ["Hu", "Xia", ""]]}, {"id": "1911.01010", "submitter": "Enzo Busseti", "authors": "Enzo Busseti", "title": "Seasonally-Adjusted Auto-Regression of Vector Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple algorithm to forecast vector time series, that is robust\nagainst missing data, in both training and inference. It models seasonal\nannual, weekly, and daily baselines, and a Gaussian process for the\nseasonally-adjusted residuals. We develop a custom truncated eigendecomposition\nto fit a low-rank plus block-diagonal Gaussian kernel. Inference is performed\nwith the Schur complement, using Tikhonov regularization to prevent overfit,\nand the Woodbury formula to invert sub-matrices of the kernel efficiently.\nInference requires an amount of memory and computation linear in the dimension\nof the time series, and so the model can scale to very large datasets. We also\npropose a simple \"greedy\" grid search for automatic hyper-parameter tuning. The\npaper is accompanied by tsar (i.e., time series auto-regressor), a Python\nlibrary that implements the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 02:28:50 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Busseti", "Enzo", ""]]}, {"id": "1911.01018", "submitter": "Chao Gao", "authors": "Chao Gao and Anderson Y. Zhang", "title": "Iterative Algorithm for Discrete Structure Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general modeling and algorithmic framework for discrete\nstructure recovery that can be applied to a wide range of problems. Under this\nframework, we are able to study the recovery of clustering labels, ranks of\nplayers, signs of regression coefficients, cyclic shifts, and even group\nelements from a unified perspective. A simple iterative algorithm is proposed\nfor discrete structure recovery, which generalizes methods including Lloyd's\nalgorithm and the power method. A linear convergence result for the proposed\nalgorithm is established in this paper under appropriate abstract conditions on\nstochastic errors and initialization. We illustrate our general theory by\napplying it on several representative problems: (1) clustering in Gaussian\nmixture model, (2) approximate ranking, (3) sign recovery in compressed\nsensing, (4) multireference alignment, and (5) group synchronization, and show\nthat minimax rate is achieved in each case.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 03:11:10 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 05:49:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gao", "Chao", ""], ["Zhang", "Anderson Y.", ""]]}, {"id": "1911.01024", "submitter": "Shen Zhang", "authors": "Shen Zhang, Shibo Zhang, Sufei Li, Liang Du, and Thomas G. Habetler", "title": "Visualization of Multi-Objective Switched Reluctance Machine\n  Optimization at Multiple Operating Conditions with t-SNE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of electric machines at multiple operating points is crucial\nfor applications that require frequent changes on speeds and loads, such as the\nelectric vehicles, to strive for the machine optimal performance across the\nentire driving cycle. However, the number of objectives that would need to be\noptimized would significantly increase with the number of operating points\nconsidered in the optimization, thus posting a potential problem in regards to\nthe visualization techniques currently in use, such as in the scatter plots of\nPareto fronts, the parallel coordinates, and in the principal component\nanalysis (PCA), inhibiting their ability to provide machine designers with\nintuitive and informative visualizations of all of the design candidates and\ntheir ability to pick a few for further fine-tuning with performance\nverification. Therefore, this paper proposes the utilization of t-distributed\nstochastic neighbor embedding (t-SNE) to visualize all of the optimization\nobjectives of various electric machines design candidates with various\noperating conditions, which constitute a high-dimensional set of data that\nwould lie on several different, but related, low-dimensional manifolds.\nFinally, two case studies of switched reluctance machines (SRM) are presented\nto illustrate the superiority of then t-SNE when compared to traditional\nvisualization techniques used in electric machine optimizations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:12:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhang", "Shen", ""], ["Zhang", "Shibo", ""], ["Li", "Sufei", ""], ["Du", "Liang", ""], ["Habetler", "Thomas G.", ""]]}, {"id": "1911.01026", "submitter": "Jeremy Wohlwend", "authors": "Jeremy Wohlwend, Ethan R. Elenberg, Samuel Altschul, Shawn Henry, Tao\n  Lei", "title": "Metric Learning for Dynamic Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional text classifiers are limited to predicting over a fixed set of\nlabels. However, in many real-world applications the label set is frequently\nchanging. For example, in intent classification, new intents may be added over\ntime while others are removed. We propose to address the problem of dynamic\ntext classification by replacing the traditional, fixed-size output layer with\na learned, semantically meaningful metric space. Here the distances between\ntextual inputs are optimized to perform nearest-neighbor classification across\noverlapping label sets. Changing the label set does not involve removing\nparameters, but rather simply adding or removing support points in the metric\nspace. Then the learned metric can be fine-tuned with only a few additional\ntraining examples. We demonstrate that this simple strategy is robust to\nchanges in the label space. Furthermore, our results show that learning a\nnon-Euclidean metric can improve performance in the low data regime, suggesting\nthat further work on metric spaces may benefit low-resource research.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:27:29 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wohlwend", "Jeremy", ""], ["Elenberg", "Ethan R.", ""], ["Altschul", "Samuel", ""], ["Henry", "Shawn", ""], ["Lei", "Tao", ""]]}, {"id": "1911.01028", "submitter": "Dibakar Gope", "authors": "Dibakar Gope, Jesse Beu, Urmish Thakker, Matthew Mattina", "title": "Ternary MobileNets via Per-Layer Hybrid Filter Banks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MobileNets family of computer vision neural networks have fueled tremendous\nprogress in the design and organization of resource-efficient architectures in\nrecent years. New applications with stringent real-time requirements on highly\nconstrained devices require further compression of MobileNets-like already\ncompute-efficient networks. Model quantization is a widely used technique to\ncompress and accelerate neural network inference and prior works have quantized\nMobileNets to 4-6 bits albeit with a modest to significant drop in accuracy.\nWhile quantization to sub-byte values (i.e. precision less than or equal to 8\nbits) has been valuable, even further quantization of MobileNets to binary or\nternary values is necessary to realize significant energy savings and possibly\nruntime speedups on specialized hardware, such as ASICs and FPGAs. Under the\nkey observation that convolutional filters at each layer of a deep neural\nnetwork may respond differently to ternary quantization, we propose a novel\nquantization method that generates per-layer hybrid filter banks consisting of\nfull-precision and ternary weight filters for MobileNets. The layer-wise hybrid\nfilter banks essentially combine the strengths of full-precision and ternary\nweight filters to derive a compact, energy-efficient architecture for\nMobileNets. Using this proposed quantization method, we quantized a substantial\nportion of weight filters of MobileNets to ternary values resulting in 27.98%\nsavings in energy, and a 51.07% reduction in the model size, while achieving\ncomparable accuracy and no degradation in throughput on specialized hardware in\ncomparison to the baseline full-precision MobileNets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:32:59 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gope", "Dibakar", ""], ["Beu", "Jesse", ""], ["Thakker", "Urmish", ""], ["Mattina", "Matthew", ""]]}, {"id": "1911.01030", "submitter": "Caihua Shan", "authors": "Caihua Shan, Nikos Mamoulis, Reynold Cheng, Guoliang Li, Xiang Li and\n  Yuqiu Qian", "title": "An End-to-End Deep RL Framework for Task Arrangement in Crowdsourcing\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Deep Reinforcement Learning (RL) framework for\ntask arrangement, which is a critical problem for the success of crowdsourcing\nplatforms. Previous works conduct the personalized recommendation of tasks to\nworkers via supervised learning methods. However, the majority of them only\nconsider the benefit of either workers or requesters independently. In\naddition, they cannot handle the dynamic environment and may produce\nsub-optimal results. To address these issues, we utilize Deep Q-Network (DQN),\nan RL-based method combined with a neural network to estimate the expected\nlong-term return of recommending a task. DQN inherently considers the immediate\nand future reward simultaneously and can be updated in real-time to deal with\nevolving data and dynamic changes. Furthermore, we design two DQNs that capture\nthe benefit of both workers and requesters and maximize the profit of the\nplatform. To learn value functions in DQN effectively, we also propose novel\nstate representations, carefully design the computation of Q values, and\npredict transition probabilities and future states. Experiments on synthetic\nand real datasets demonstrate the superior performance of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:53:11 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shan", "Caihua", ""], ["Mamoulis", "Nikos", ""], ["Cheng", "Reynold", ""], ["Li", "Guoliang", ""], ["Li", "Xiang", ""], ["Qian", "Yuqiu", ""]]}, {"id": "1911.01032", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "On Batch Bayesian Optimization", "comments": "All of Bayesian Nonparametrics workshop, Neural Information\n  Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two algorithms for Bayesian optimization in the batch feedback\nsetting, based on Gaussian process upper confidence bound and Thompson sampling\napproaches, along with frequentist regret guarantees and numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 05:04:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.01040", "submitter": "Adel Javanmard", "authors": "Yash Deshpande, Adel Javanmard, Mohammad Mehrabi", "title": "Online Debiasing for Adaptively Collected High-dimensional Data with\n  Applications to Time Series Analysis", "comments": "66 pages, 2 tables, 11 figures; updated with minor fixes and\n  reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive collection of data is commonplace in applications throughout science\nand engineering. From the point of view of statistical inference however,\nadaptive data collection induces memory and correlation in the samples, and\nposes significant challenge. We consider the high-dimensional linear\nregression, where the samples are collected adaptively, and the sample size $n$\ncan be smaller than $p$, the number of covariates. In this setting, there are\ntwo distinct sources of bias: the first due to regularization imposed for\nconsistent estimation, e.g. using the LASSO, and the second due to adaptivity\nin collecting the samples. We propose \"online debiasing\", a general procedure\nfor estimators such as the LASSO, which addresses both sources of bias. In two\nconcrete contexts $(i)$ time series analysis and $(ii)$ batched data\ncollection, we demonstrate that online debiasing optimally debiases the LASSO\nestimate when the underlying parameter $\\theta_0$ has sparsity of order\n$o(\\sqrt{n}/\\log p)$. In this regime, the debiased estimator can be used to\ncompute $p$-values and confidence intervals of optimal size.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:03:58 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:41:44 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 19:39:33 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Deshpande", "Yash", ""], ["Javanmard", "Adel", ""], ["Mehrabi", "Mohammad", ""]]}, {"id": "1911.01043", "submitter": "Kamil Nar", "authors": "Kamil Nar, S. Shankar Sastry", "title": "Persistency of Excitation for Robustness of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an online learning algorithm is used to estimate the unknown parameters\nof a model, the signals interacting with the parameter estimates should not\ndecay too quickly for the optimal values to be discovered correctly. This\nrequirement is referred to as persistency of excitation, and it arises in\nvarious contexts, such as optimization with stochastic gradient methods,\nexploration for multi-armed bandits, and adaptive control of dynamical systems.\nWhile training a neural network, the iterative optimization algorithm involved\nalso creates an online learning problem, and consequently, correct estimation\nof the optimal parameters requires persistent excitation of the network\nweights. In this work, we analyze the dynamics of the gradient descent\nalgorithm while training a two-layer neural network with two different loss\nfunctions, the squared-error loss and the cross-entropy loss; and we obtain\nconditions to guarantee persistent excitation of the network weights. We then\nshow that these conditions are difficult to satisfy when a multi-layer network\nis trained for a classification task, for the signals in the intermediate\nlayers of the network become low-dimensional during training and fail to remain\npersistently exciting. To provide a remedy, we delve into the classical\nregularization terms used for linear models, reinterpret them as a means to\nensure persistent excitation of the model parameters, and propose an algorithm\nfor neural networks by building an analogy. The results in this work shed some\nlight on why adversarial examples have become a challenging problem for neural\nnetworks, why merely augmenting training data sets will not be an effective\napproach to address them, and why there may not exist a data-independent\nregularization term for neural networks, which involve only the model\nparameters but not the training data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:17:35 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nar", "Kamil", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1911.01046", "submitter": "Shashi Raj Pandey", "authors": "Shashi Raj Pandey, Nguyen H. Tran, Mehdi Bennis, Yan Kyaw Tun, Aunas\n  Manzoor, and Choong Seon Hong", "title": "A Crowdsourcing Framework for On-Device Federated Learning", "comments": "Accepted in IEEE Transactions on Wireless Communications", "journal-ref": null, "doi": "10.1109/TWC.2020.2971981", "report-no": null, "categories": "cs.LG cs.GT cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) rests on the notion of training a global model in a\ndecentralized manner. Under this setting, mobile devices perform computations\non their local data before uploading the required updates to improve the global\nmodel. However, when the participating clients implement an uncoordinated\ncomputation strategy, the difficulty is to handle the communication efficiency\n(i.e., the number of communications per iteration) while exchanging the model\nparameters during aggregation. Therefore, a key challenge in FL is how users\nparticipate to build a high-quality global model with communication efficiency.\nWe tackle this issue by formulating a utility maximization problem, and propose\na novel crowdsourcing framework to leverage FL that considers the communication\nefficiency during parameters exchange. First, we show an incentive-based\ninteraction between the crowdsourcing platform and the participating client's\nindependent strategies for training a global learning model, where each side\nmaximizes its own benefit. We formulate a two-stage Stackelberg game to analyze\nsuch scenario and find the game's equilibria. Second, we formalize an admission\ncontrol scheme for participating clients to ensure a level of local accuracy.\nSimulated results demonstrate the efficacy of our proposed solution with up to\n22% gain in the offered reward.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 06:41:37 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 04:06:40 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Pandey", "Shashi Raj", ""], ["Tran", "Nguyen H.", ""], ["Bennis", "Mehdi", ""], ["Tun", "Yan Kyaw", ""], ["Manzoor", "Aunas", ""], ["Hong", "Choong Seon", ""]]}, {"id": "1911.01058", "submitter": "Sheng Shi", "authors": "Sheng Shi, Xinfeng Zhang and Wei Fan", "title": "Explaining the Predictions of Any Image Classifier via Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite outstanding contribution to the significant progress of Artificial\nIntelligence (AI), deep learning models remain mostly black boxes, which are\nextremely weak in explainability of the reasoning process and prediction\nresults. Explainability is not only a gateway between AI and society but also a\npowerful tool to detect flaws in the model and biases in the data. Local\nInterpretable Model-agnostic Explanation (LIME) is a recent approach that uses\nan interpretable model to form a local explanation for the individual\nprediction result. The current implementation of LIME adopts the linear\nregression as its interpretable function. However, being so restricted and\nusually over-simplifying the relationships, linear models fail in situations\nwhere nonlinear associations and interactions exist among features and\nprediction results. This paper implements a decision Tree-based LIME approach,\nwhich uses a decision tree model to form an interpretable representation that\nis locally faithful to the original model. Tree-LIME approach can capture\nnonlinear interactions among features in the data and creates plausible\nexplanations. Various experiments show that the Tree-LIME explanation of\nmultiple black-box models can achieve more reliable performance in terms of\nunderstandability, fidelity, and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:31:30 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 01:20:25 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shi", "Sheng", ""], ["Zhang", "Xinfeng", ""], ["Fan", "Wei", ""]]}, {"id": "1911.01067", "submitter": "Yunzong Xu", "authors": "David Simchi-Levi, Yunzong Xu, Jinglong Zhao", "title": "Blind Network Revenue Management and Bandits with Knapsacks under\n  Limited Switches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work is motivated by a common business constraint in online markets.\nWhile firms respect the advantages of dynamic pricing and price\nexperimentation, they must limit the number of price changes (i.e., switches)\nto be within some budget due to various practical reasons. We study both the\nclassical price-based network revenue management problem in the\ndistributionally-unknown setup, and the bandits with knapsacks problem. In\nthese problems, a decision-maker (without prior knowledge of the environment)\nhas finite initial inventory of multiple resources to allocate over a finite\ntime horizon. Beyond the classical resource constraints, we introduce an\nadditional switching constraint to these problems, which restricts the total\nnumber of times that the decision-maker makes switches between actions to be\nwithin a fixed switching budget. For such problems, we show matching upper and\nlower bounds on the optimal regret, and propose computationally-efficient\nlimited-switch algorithms that achieve the optimal regret. Our work reveals a\nsurprising result: the optimal regret rate is completely characterized by a\npiecewise-constant function of the switching budget, which further depends on\nthe number of resource constraints -- to the best of our knowledge, this is the\nfirst time the number of resources constraints is shown to play a fundamental\nrole in determining the statistical complexity of online learning problems. We\nconduct computational experiments to examine the performance of our algorithms\non a numerical setup that is widely used in the literature. Compared with\nbenchmark algorithms from the literature, our proposed algorithms achieve\npromising performance with clear advantages on the number of incurred switches.\nPractically, firms can benefit from our study and improve their learning and\ndecision-making performance when they simultaneously face resource and\nswitching constraints.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:58:37 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 00:59:19 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 18:14:13 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 22:19:19 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Simchi-Levi", "David", ""], ["Xu", "Yunzong", ""], ["Zhao", "Jinglong", ""]]}, {"id": "1911.01071", "submitter": "Dino Ienco", "authors": "Dino Ienco, Roberto Interdonato and Raffaele Gaetano", "title": "Supervised level-wise pretraining for recurrent neural network\n  initialization in multi-class classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) can be seriously impacted by the initial\nparameters assignment, which may result in poor generalization performances on\nnew unseen data. With the objective to tackle this crucial issue, in the\ncontext of RNN based classification, we propose a new supervised layer-wise\npretraining strategy to initialize network parameters. The proposed approach\nleverages a data-aware strategy that sets up a taxonomy of classification\nproblems automatically derived by the model behavior. To the best of our\nknowledge, despite the great interest in RNN-based classification, this is the\nfirst data-aware strategy dealing with the initialization of such models. The\nproposed strategy has been tested on four benchmarks coming from two different\ndomains, i.e., Speech Recognition and Remote Sensing. Results underline the\nsignificance of our approach and point out that data-aware strategies\npositively support the initialization of Recurrent Neural Network based\nclassification models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 08:30:01 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ienco", "Dino", ""], ["Interdonato", "Roberto", ""], ["Gaetano", "Raffaele", ""]]}, {"id": "1911.01155", "submitter": "Kushal Satya", "authors": "Jagriti Sikka, Kushal Satya, Yaman Kumar, Shagun Uppal, Rajiv Ratn\n  Shah, Roger Zimmermann", "title": "Learning based Methods for Code Runtime Complexity Prediction", "comments": "14 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the runtime complexity of a programming code is an arduous task.\nIn fact, even for humans, it requires a subtle analysis and comprehensive\nknowledge of algorithms to predict time complexity with high fidelity, given\nany code. As per Turing's Halting problem proof, estimating code complexity is\nmathematically impossible. Nevertheless, an approximate solution to such a task\ncan help developers to get real-time feedback for the efficiency of their code.\nIn this work, we model this problem as a machine learning task and check its\nfeasibility with thorough analysis. Due to the lack of any open source dataset\nfor this task, we propose our own annotated dataset CoRCoD: Code Runtime\nComplexity Dataset, extracted from online judges. We establish baselines using\ntwo different approaches: feature engineering and code embeddings, to achieve\nstate of the art results and compare their performances. Such solutions can be\nwidely useful in potential applications like automatically grading coding\nassignments, IDE-integrated tools for static code analysis, and others.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:26:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sikka", "Jagriti", ""], ["Satya", "Kushal", ""], ["Kumar", "Yaman", ""], ["Uppal", "Shagun", ""], ["Shah", "Rajiv Ratn", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1911.01172", "submitter": "Le Shu", "authors": "Jiazhu Dai, Le Shu", "title": "Fast-UAP: An Algorithm for Speeding up Universal Adversarial\n  Perturbation Generation with Orientation of Perturbation Vectors", "comments": "9 pages, 7 figures, 1 table, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have become one of the most popular\nmachine learning tools and are being applied in various tasks, however, CNN\nmodels are vulnerable to universal perturbations, which are usually\nhuman-imperceptible but can cause natural images to be misclassified with high\nprobability. One of the state-of-the-art algorithms to generate universal\nperturbations is known as UAP. UAP only aggregates the minimal perturbations in\nevery iteration, which will lead to generated universal perturbation whose\nmagnitude cannot rise up efficiently and cause a slow generation. In this\npaper, we proposed an optimized algorithm to improve the performance of\ncrafting universal perturbations based on orientation of perturbation vectors.\nAt each iteration, instead of choosing minimal perturbation vector with respect\nto each image, we aggregate the current instance of universal perturbation with\nthe perturbation which has similar orientation to the former so that the\nmagnitude of the aggregation will rise up as large as possible at every\niteration. The experiment results show that we get universal perturbations in a\nshorter time and with a smaller number of training images. Furthermore, we\nobserve in experiments that universal perturbations generated by our proposed\nalgorithm have an average increment of fooling rate by 9% in white-box attacks\nand black-box attacks comparing with universal perturbations generated by UAP.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:57:17 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 12:00:11 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 10:28:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dai", "Jiazhu", ""], ["Shu", "Le", ""]]}, {"id": "1911.01182", "submitter": "Ville Vestman", "authors": "Alexey Sholokhov, Tomi Kinnunen, Ville Vestman, Kong Aik Lee", "title": "Voice Biometrics Security: Extrapolating False Alarm Rate via\n  Hierarchical Bayesian Modeling of Speaker Verification Scores", "comments": "Accepted to be published in Computer Speech and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How secure automatic speaker verification (ASV) technology is? More\nconcretely, given a specific target speaker, how likely is it to find another\nperson who gets falsely accepted as that target? This question may be addressed\nempirically by studying naturally confusable pairs of speakers within a large\nenough corpus. To this end, one might expect to find at least some speaker\npairs that are indistinguishable from each other in terms of ASV. To a certain\nextent, such aim is mirrored in the standardized ASV evaluation benchmarks.\nHowever, the number of speakers in such evaluation benchmarks represents only a\nsmall fraction of all possible human voices, making it challenging to\nextrapolate performance beyond a given corpus. Furthermore, the impostors used\nin performance evaluation are usually selected randomly. A potentially more\nmeaningful definition of an impostor - at least in the context of\nsecurity-driven ASV applications - would be closest (most confusable) other\nspeaker to a given target.\n  We put forward a novel performance assessment framework to address both the\ninadequacy of the random-impostor evaluation model and the size limitation of\nevaluation corpora by addressing ASV security against closest impostors on\narbitrarily large datasets. The framework allows one to make a prediction of\nthe safety of given ASV technology, in its current state, for arbitrarily large\nspeaker database size consisting of virtual (sampled) speakers. As a\nproof-of-concept, we analyze the performance of two state-of-the-art ASV\nsystems, based on i-vector and x-vector speaker embeddings (as implemented in\nthe popular Kaldi toolkit), on the recent VoxCeleb 1 & 2 corpora. We found that\nneither the i-vector or x-vector system is immune to increased false alarm rate\nat increased impostor database size.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:13:45 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sholokhov", "Alexey", ""], ["Kinnunen", "Tomi", ""], ["Vestman", "Ville", ""], ["Lee", "Kong Aik", ""]]}, {"id": "1911.01196", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaxin Huang, Guangyuan Wang, Chao Zhang, Honglei Zhuang,\n  Lance Kaplan, Jiawei Han", "title": "Spherical Text Embedding", "comments": "NeurIPS 2019. (Code:\n  https://github.com/yumeng5/Spherical-Text-Embedding)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text embedding has shown great power in a wide range of NLP\ntasks. While text embeddings are typically learned in the Euclidean space,\ndirectional similarity is often more effective in tasks such as word similarity\nand document clustering, which creates a gap between the training stage and\nusage stage of text embedding. To close this gap, we propose a spherical\ngenerative model based on which unsupervised word and paragraph embeddings are\njointly learned. To learn text embeddings in the spherical space, we develop an\nefficient optimization algorithm with convergence guarantee based on Riemannian\noptimization. Our model enjoys high efficiency and achieves state-of-the-art\nperformances on various text embedding tasks including word similarity and\ndocument clustering.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:36:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Meng", "Yu", ""], ["Huang", "Jiaxin", ""], ["Wang", "Guangyuan", ""], ["Zhang", "Chao", ""], ["Zhuang", "Honglei", ""], ["Kaplan", "Lance", ""], ["Han", "Jiawei", ""]]}, {"id": "1911.01198", "submitter": "Yanwei Cui", "authors": "Yanwei Cui, Xavier Illy", "title": "Understand customer reviews with less data and in short time: pretrained\n  language representation and active learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address customer review understanding problems by using\nsupervised machine learning approaches, in order to achieve a fully automatic\nreview aspects categorisation and sentiment analysis. In general, such\nsupervised learning algorithms require domain-specific expert knowledge for\ngenerating high quality labeled training data, and the cost of labeling can be\nvery high. To achieve an in-production customer review machine learning enabled\nanalysis tool with only a limited amount of data and within a reasonable\ntraining data collection time, we propose to use pre-trained language\nrepresentation to boost model performance and active learning framework for\naccelerating the iterative training process. The results show that with\nintegration of both components, the fully automatic review analysis can be\nachieved at a much faster pace.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 12:39:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cui", "Yanwei", ""], ["Illy", "Xavier", ""]]}, {"id": "1911.01205", "submitter": "Daniel Tarlow", "authors": "Daniel Tarlow, Subhodeep Moitra, Andrew Rice, Zimin Chen,\n  Pierre-Antoine Manzagol, Charles Sutton, Edward Aftandilian", "title": "Learning to Fix Build Errors with Graph2Diff Neural Networks", "comments": "Submitted for review on Aug 23, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Professional software developers spend a significant amount of time fixing\nbuilds, but this has received little attention as a problem in automatic\nprogram repair. We present a new deep learning architecture, called Graph2Diff,\nfor automatically localizing and fixing build errors. We represent source code,\nbuild configuration files, and compiler diagnostic messages as a graph, and\nthen use a Graph Neural Network model to predict a diff. A diff specifies how\nto modify the code's abstract syntax tree, represented in the neural network as\na sequence of tokens and of pointers to code locations. Our network is an\ninstance of a more general abstraction that we call Graph2Tocopo, which is\npotentially useful in any development tool for predicting source code changes.\nWe evaluate the model on a dataset of over 500k real build errors and their\nresolutions from professional developers. Compared to the approach of DeepDelta\n(Mesbah et al., 2019), our approach tackles the harder task of predicting a\nmore precise diff but still achieves over double the accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:40:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Tarlow", "Daniel", ""], ["Moitra", "Subhodeep", ""], ["Rice", "Andrew", ""], ["Chen", "Zimin", ""], ["Manzagol", "Pierre-Antoine", ""], ["Sutton", "Charles", ""], ["Aftandilian", "Edward", ""]]}, {"id": "1911.01208", "submitter": "Alon Kipnis", "authors": "Alon Kipnis", "title": "Higher Criticism for Discriminating Word-Frequency Tables and Testing\n  Authorship", "comments": "under review (AOAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt the Higher Criticism (HC) goodness-of-fit test to measure closeness\nbetween word-frequency tables. We apply this measure to authorship attribution\nchallenges, where the goal is to identify the author of a document using other\ndocuments whose authorship is known. The method is simple yet performs well\nwithout handcrafting and tuning; reporting accuracy at the state of the art\nlevel in various current challenges. As an inherent side effect, the HC\ncalculation identifies a subset of discriminating words. In practice, the\nidentified words have low variance across documents belonging to a corpus of\nhomogeneous authorship. We conclude that in comparing the similarity of a new\ndocument and a corpus of a single author, HC is mostly affected by words\ncharacteristic of the author and is relatively unaffected by topic structure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:47:25 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 19:41:44 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 20:04:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kipnis", "Alon", ""]]}, {"id": "1911.01212", "submitter": "Tamali Banerjee", "authors": "Tamali Banerjee, Rudra Murthy V, Pushpak Bhattacharyya", "title": "Scrambled Translation Problem: A Problem of Denoising UNMT", "comments": "Accepted by MT Summit 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify an interesting kind of error in the output of\nUnsupervised Neural Machine Translation (UNMT) systems like\n\\textit{Undreamt}(footnote). We refer to this error type as \\textit{Scrambled\nTranslation problem}. We observe that UNMT models which use \\textit{word\nshuffle} noise (as in case of Undreamt) can generate correct words, but fail to\nstitch them together to form phrases. As a result, words of the translated\nsentence look \\textit{scrambled}, resulting in decreased BLEU. We hypothesise\nthat the reason behind \\textit{scrambled translation problem} is 'shuffling\nnoise' which is introduced in every input sentence as a denoising strategy. To\ntest our hypothesis, we experiment by retraining UNMT models with a simple\n\\textit{retraining} strategy. We stop the training of the Denoising UNMT model\nafter a pre-decided number of iterations and resume the training for the\nremaining iterations -- which number is also pre-decided -- using original\nsentence as input without adding any noise. Our proposed solution achieves\nsignificant performance improvement UNMT models that train conventionally. We\ndemonstrate these performance gains on four language pairs, \\textit{viz.},\nEnglish-French, English-German, English-Spanish, Hindi-Punjabi. Our qualitative\nand quantitative analysis shows that the retraining strategy helps achieve\nbetter alignment as observed by attention heatmap and better phrasal\ntranslation, leading to statistically significant improvement in BLEU scores.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:22:37 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 10:57:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Banerjee", "Tamali", ""], ["Murthy", "Rudra", "V"], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1911.01220", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Yinliang Diao, Akimasa Hirata", "title": "Learning-based estimation of dielectric properties and tissue density in\n  head models for personalized radio-frequency dosimetry", "comments": "18 pages, 10 figures, 4 tables", "journal-ref": "Physics in Medicine and Biology 65, pp. 065001, 2020", "doi": "10.1088/1361-6560/ab7308", "report-no": null, "categories": "cs.LG eess.IV physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio-frequency dosimetry is an important process in human safety and for\ncompliance of related products. Recently, computational human models generated\nfrom medical images have often been used for such assessment, especially to\nconsider the inter-variability of subjects. However, the common procedure to\ndevelop personalized models is time consuming because it involves excessive\nsegmentation of several components that represent different biological tissues,\nwhich limits the inter-variability assessment of radiation safety based on\npersonalized dosimetry. Deep learning methods have been shown to be a powerful\napproach for pattern recognition and signal analysis. Convolutional neural\nnetworks with deep architecture are proven robust for feature extraction and\nimage mapping in several biomedical applications. In this study, we develop a\nlearning-based approach for fast and accurate estimation of the dielectric\nproperties and density of tissues directly from magnetic resonance images in a\nsingle shot. The smooth distribution of the dielectric properties in head\nmodels, which is realized using a process without tissue segmentation, improves\nthe smoothness of the specific absorption rate (SAR) distribution compared with\nthat in the commonly used procedure. The estimated SAR distributions, as well\nas that averaged over 10-g of tissue in a cubic shape, are found to be highly\nconsistent with those computed using the conventional methods that employ\nsegmentation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:55:30 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 03:16:33 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 01:07:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Rashed", "Essam A.", ""], ["Diao", "Yinliang", ""], ["Hirata", "Akimasa", ""]]}, {"id": "1911.01225", "submitter": "Fan (Fred) Lin", "authors": "Fred Lin, Keyur Muzumdar, Nikolay Pavlovich Laptev, Mihai-Valentin\n  Curelea, Seunghak Lee, Sriram Sankar", "title": "Fast Dimensional Analysis for Root Cause Investigation in a Large-Scale\n  Service Environment", "comments": "13 pages", "journal-ref": "POMACS 2020", "doi": "10.1145/3392149", "report-no": null, "categories": "cs.DC cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Root cause analysis in a large-scale production environment is challenging\ndue to the complexity of services running across global data centers. Due to\nthe distributed nature of a large-scale system, the various hardware, software,\nand tooling logs are often maintained separately, making it difficult to review\nthe logs jointly for understanding production issues. Another challenge in\nreviewing the logs for identifying issues is the scale - there could easily be\nmillions of entities, each described by hundreds of features. In this paper we\npresent a fast dimensional analysis framework that automates the root cause\nanalysis on structured logs with improved scalability.\n  We first explore item-sets, i.e. combinations of feature values, that could\nidentify groups of samples with sufficient support for the target failures\nusing the Apriori algorithm and a subsequent improvement, FP-Growth. These\nalgorithms were designed for frequent item-set mining and association rule\nlearning over transactional databases. After applying them on structured logs,\nwe select the item-sets that are most unique to the target failures based on\nlift. We propose pre-processing steps with the use of a large-scale real-time\ndatabase and post-processing techniques and parallelism to further speed up the\nanalysis and improve interpretability, and demonstrate that such optimization\nis necessary for handling large-scale production datasets. We have successfully\nrolled out this approach for root cause investigation purposes in a large-scale\ninfrastructure. We also present the setup and results from multiple production\nuse cases in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:03:01 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 19:49:04 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Lin", "Fred", ""], ["Muzumdar", "Keyur", ""], ["Laptev", "Nikolay Pavlovich", ""], ["Curelea", "Mihai-Valentin", ""], ["Lee", "Seunghak", ""], ["Sankar", "Sriram", ""]]}, {"id": "1911.01226", "submitter": "Ruibin Ma", "authors": "Ruibin Ma and Po-Hsuan Cameron Chen and Gang Li and Wei-Hung Weng and\n  Angela Lin and Krishna Gadepalli and Yuannan Cai", "title": "Human-centric Metric for Accelerating Pathology Reports Annotation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathology reports contain useful information such as the main involved organ,\ndiagnosis, etc. These information can be identified from the free text reports\nand used for large-scale statistical analysis or serve as annotation for other\nmodalities such as pathology slides images. However, manual classification for\na huge number of reports on multiple tasks is labor-intensive. In this paper,\nwe have developed an automatic text classifier based on BERT and we propose a\nhuman-centric metric to evaluate the model. According to the model confidence,\nwe identify low-confidence cases that require further expert annotation and\nhigh-confidence cases that are automatically classified. We report the\npercentage of low-confidence cases and the performance of automatically\nclassified cases. On the high-confidence cases, the model achieves\nclassification accuracy comparable to pathologists. This leads a potential of\nreducing 80% to 98% of the manual annotation workload.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:09:19 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 15:12:45 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ma", "Ruibin", ""], ["Chen", "Po-Hsuan Cameron", ""], ["Li", "Gang", ""], ["Weng", "Wei-Hung", ""], ["Lin", "Angela", ""], ["Gadepalli", "Krishna", ""], ["Cai", "Yuannan", ""]]}, {"id": "1911.01257", "submitter": "Xiaoting Du", "authors": "Yuan Zhou, Xiaoting Du, Yeda Zhang, and Sun-Yuan Kung", "title": "Cross-Scale Residual Network for Multiple Tasks:Image Super-resolution,\n  Denoising, and Deblocking", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, image restoration involves mapping from low quality images to\ntheir high-quality counterparts. Such optimal mapping is usually non-linear and\nlearnable by machine learning. Recently, deep convolutional neural networks\nhave proven promising for such learning processing. It is desirable for an\nimage processing network to support well with three vital tasks, namely,\nsuper-resolution, denoising, and deblocking. It is commonly recognized that\nthese tasks have strong correlations. Therefore, it is imperative to harness\nthe inter-task correlations. To this end, we propose the cross-scale residual\nnetwork to exploit scale-related features and the inter-task correlations among\nthe three tasks. The proposed network can extract multiple spatial scale\nfeatures and establish multiple temporal feature reusage. Our experiments show\nthat the proposed approach outperforms state-of-the-art methods in both\nquantitative and qualitative evaluations for multiple image restoration tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 14:51:25 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhou", "Yuan", ""], ["Du", "Xiaoting", ""], ["Zhang", "Yeda", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "1911.01288", "submitter": "Prateek Jaiswal", "authors": "Prateek Jaiswal, Harsha Honnappa and Vinayak A. Rao", "title": "Asymptotic Consistency of Loss-Calibrated Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the asymptotic consistency of the {\\it loss-calibrated\nvariational Bayes} (LCVB) method. LCVB was proposed in~\\cite{LaSiGh2011} as a\nmethod for approximately computing Bayesian posteriors in a `loss aware'\nmanner. This methodology is also highly relevant in general data-driven\ndecision-making contexts. Here, we not only establish the asymptotic\nconsistency of the calibrated approximate posterior, but also the asymptotic\nconsistency of decision rules. We also establish the asymptotic consistency of\ndecision rules obtained from a `naive' variational Bayesian procedure.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:43:50 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Jaiswal", "Prateek", ""], ["Honnappa", "Harsha", ""], ["Rao", "Vinayak A.", ""]]}, {"id": "1911.01291", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross, Weiwei Pan, Leo Anthony Celi, Finale Doshi-Velez", "title": "Ensembles of Locally Independent Prediction Models", "comments": "This is an expansion of arXiv:1806.08716 with different applications\n  and focus, accepted to AAAI 2020. Latest update clarifies a derivation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles depend on diversity for improved performance. Many ensemble\ntraining methods, therefore, attempt to optimize for diversity, which they\nalmost always define in terms of differences in training set predictions. In\nthis paper, however, we demonstrate the diversity of predictions on the\ntraining set does not necessarily imply diversity under mild covariate shift,\nwhich can harm generalization in practical settings. To address this issue, we\nintroduce a new diversity metric and associated method of training ensembles of\nmodels that extrapolate differently on local patches of the data manifold.\nAcross a variety of synthetic and real-world tasks, we find that our method\nimproves generalization and diversity in qualitatively novel ways, especially\nunder data limits and covariate shift.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:46:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 14:27:03 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 17:03:50 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Pan", "Weiwei", ""], ["Celi", "Leo Anthony", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1911.01366", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej and Tanya Berger-Wolf", "title": "Framework for Inferring Following Strategies from Time Series of\n  Movement Data", "comments": "This is the revised version of the preprint entitled \"Inferring\n  Coordination Strategies from Time Series of Movement Data\" following\n  reviewers' suggestions", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 14(3),\n  35 (2020)", "doi": "10.1145/3385730", "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.MA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do groups of individuals achieve consensus in movement decisions? Do\nindividuals follow their friends, the one predetermined leader, or whomever\njust happens to be nearby? To address these questions computationally, we\nformalize \"Coordination Strategy Inference Problem\". In this setting, a group\nof multiple individuals moves in a coordinated manner towards a target path.\nEach individual uses a specific strategy to follow others (e.g. nearest\nneighbors, pre-defined leaders, preferred friends). Given a set of time series\nthat includes coordinated movement and a set of candidate strategies as inputs,\nwe provide the first methodology (to the best of our knowledge) to infer\nwhether each individual uses local-agreement-system or dictatorship-like\nstrategy to achieve movement coordination at the group level. We evaluate and\ndemonstrate the performance of the proposed framework by predicting the\ndirection of movement of an individual in a group in both simulated datasets as\nwell as two real-world datasets: a school of fish and a troop of baboons.\nMoreover, since there is no prior methodology for inferring individual-level\nstrategies, we compare our framework with the state-of-the-art approach for the\ntask of classification of group-level-coordination models. The results show\nthat our approach is highly accurate in inferring the correct strategy in\nsimulated datasets even in complicated mixed strategy settings, which no\nexisting method can infer. In the task of classification of\ngroup-level-coordination models, our framework performs better than the\nstate-of-the-art approach in all datasets. Animal data experiments show that\nfish, as expected, follow their neighbors, while baboons have a preference to\nfollow specific individuals. Our methodology generalizes to arbitrary time\nseries data of real numbers, beyond movement data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:51:23 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 09:46:22 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1911.01373", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Petros Dellaportas", "title": "Gradient-based Adaptive Markov Chain Monte Carlo", "comments": "17 pages, 7 Figures, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a gradient-based learning method to automatically adapt Markov\nchain Monte Carlo (MCMC) proposal distributions to intractable targets. We\ndefine a maximum entropy regularised objective function, referred to as\ngeneralised speed measure, which can be robustly optimised over the parameters\nof the proposal distribution by applying stochastic gradient optimisation. An\nadvantage of our method compared to traditional adaptive MCMC methods is that\nthe adaptation occurs even when candidate state values are rejected. This is a\nhighly desirable property of any adaptation strategy because the adaptation\nstarts in early iterations even if the initial proposal distribution is far\nfrom optimum. We apply the framework for learning multivariate random walk\nMetropolis and Metropolis-adjusted Langevin proposals with full covariance\nmatrices, and provide empirical evidence that our method can outperform other\nMCMC algorithms, including Hamiltonian Monte Carlo schemes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:03:06 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 15:00:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Dellaportas", "Petros", ""]]}, {"id": "1911.01382", "submitter": "Hao Wu", "authors": "Hao Wu, Heiko Zimmermann, Eli Sennesh, Tuan Anh Le, and Jan-Willem van\n  de Meent", "title": "Amortized Population Gibbs Samplers with Neural Sufficient Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop amortized population Gibbs (APG) samplers, a class of scalable\nmethods that frames structured variational inference as adaptive importance\nsampling. APG samplers construct high-dimensional proposals by iterating over\nupdates to lower-dimensional blocks of variables. We train each conditional\nproposal by minimizing the inclusive KL divergence with respect to the\nconditional posterior. To appropriately account for the size of the input data,\nwe develop a new parameterization in terms of neural sufficient statistics.\nExperiments show that APG samplers can train highly structured deep generative\nmodels in an unsupervised manner, and achieve substantial improvements in\ninference accuracy relative to standard autoencoding variational methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:10:11 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 17:46:09 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 18:59:36 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Wu", "Hao", ""], ["Zimmermann", "Heiko", ""], ["Sennesh", "Eli", ""], ["Le", "Tuan Anh", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1911.01413", "submitter": "Tian Ding", "authors": "Tian Ding, Dawei Li, Ruoyu Sun", "title": "Sub-Optimal Local Minima Exist for Neural Networks with Almost All\n  Non-Linear Activations", "comments": "58 pages. The main theorem is strengthened. An early version was\n  submitted to Optimization Online on October 4, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does over-parameterization eliminate sub-optimal local minima for neural\nnetworks? An affirmative answer was given by a classical result in [59] for\n1-hidden-layer wide neural networks. A few recent works have extended the\nsetting to multi-layer neural networks, but none of them has proved every local\nminimum is global. Why is this result never extended to deep networks?\n  In this paper, we show that the task is impossible because the original\nresult for 1-hidden-layer network in [59] can not hold. More specifically, we\nprove that for any multi-layer network with generic input data and non-linear\nactivation functions, sub-optimal local minima can exist, no matter how wide\nthe network is (as long as the last hidden layer has at least two neurons).\nWhile the result of [59] assumes sigmoid activation, our counter-example covers\na large set of activation functions (dense in the set of continuous functions),\nindicating that the limitation is not due to the specific activation. Our\nresult indicates that \"no bad local-min\" may be unable to explain the benefit\nof over-parameterization for training neural nets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:56:58 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:33:55 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 17:05:52 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ding", "Tian", ""], ["Li", "Dawei", ""], ["Sun", "Ruoyu", ""]]}, {"id": "1911.01419", "submitter": "Loren Anderson", "authors": "Loren Anderson and Sahitya Senapathy", "title": "On Solving the 2-Dimensional Greedy Shooter Problem for UAVs", "comments": "7 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs), autonomously-guided aircraft, are widely\nused for tasks involving surveillance and reconnaissance. A version of the\npursuit-evasion problems centered around UAVs and its variants has been\nextensively studied in recent years due to numerous breakthroughs in AI. We\npresent an approach to UAV pursuit-evasion in a 2D aerial-engagement\nenvironment using reinforcement learning (RL), a machine learning paradigm\nconcerned with goal-oriented algorithms. In this work, a UAV wielding the\ngreedy shooter strategy engages with a UAV trained using deep Q-learning\ntechniques. Simulated results show that the latter UAV wins every engagement in\nwhich the UAVs are suffciently separated during initialization. This approach\nhighlights an exhaustive and robust application of reinforcement learning to\npursuit-evasion that provides insight into effective strategies for UAV flight\nand interaction.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 21:55:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Anderson", "Loren", ""], ["Senapathy", "Sahitya", ""]]}, {"id": "1911.01425", "submitter": "Pablo S\\'anchez Mart\\'in", "authors": "Pablo S\\'anchez-Mart\\'in, Pablo M. Olmos and Fernando Perez-Cruz", "title": "Improved BiGAN training with marginal likelihood equalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel training procedure for improving the performance of\ngenerative adversarial networks (GANs), especially to bidirectional GANs.\nFirst, we enforce that the empirical distribution of the inverse inference\nnetwork matches the prior distribution, which favors the generator network\nreproducibility on the seen samples. Second, we have found that the marginal\nlog-likelihood of the samples shows a severe overrepresentation of a certain\ntype of samples. To address this issue, we propose to train the bidirectional\nGAN using a non-uniform sampling for the mini-batch selection, resulting in\nimproved quality and variety in generated samples measured quantitatively and\nby visual inspection. We illustrate our new procedure with the well-known\nCIFAR10, Fashion MNIST and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:02:20 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 10:38:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["S\u00e1nchez-Mart\u00edn", "Pablo", ""], ["Olmos", "Pablo M.", ""], ["Perez-Cruz", "Fernando", ""]]}, {"id": "1911.01429", "submitter": "Johann Brehmer Mr", "authors": "Kyle Cranmer, Johann Brehmer, Gilles Louppe", "title": "The frontier of simulation-based inference", "comments": "10 pages, 3 figures, proceedings for the Sackler Colloquia at the US\n  National Academy of Sciences. v2: fixed typos. v3: clarified text, added\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many domains of science have developed complex simulations to describe\nphenomena of interest. While these simulations provide high-fidelity models,\nthey are poorly suited for inference and lead to challenging inverse problems.\nWe review the rapidly developing field of simulation-based inference and\nidentify the forces giving new momentum to the field. Finally, we describe how\nthe frontier is expanding so that a broad audience can appreciate the profound\nchange these developments may have on science.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:00:00 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 20:16:42 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 14:08:04 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Cranmer", "Kyle", ""], ["Brehmer", "Johann", ""], ["Louppe", "Gilles", ""]]}, {"id": "1911.01458", "submitter": "Roberto Souza", "authors": "Roberto Souza, Mariana Bento, Nikita Nogovitsyn, Kevin J. Chung, R.\n  Marc Lebel and Richard Frayne", "title": "Dual-domain Cascade of U-nets for Multi-channel Magnetic Resonance Image\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U-net is a deep-learning network model that has been used to solve a\nnumber of inverse problems. In this work, the concatenation of two-element\nU-nets, termed the W-net, operating in k-space (K) and image (I) domains, were\nevaluated for multi-channel magnetic resonance (MR) image reconstruction. The\ntwo element network combinations were evaluated for the four possible\nimage-k-space domain configurations: a) W-net II, b) W-net KK, c) W-net IK, and\nd) W-net KI were evaluated. Selected promising four element networks (WW-nets)\nwere also examined. Two configurations of each network were compared: 1) Each\ncoil channel processed independently, and 2) all channels processed\nsimultaneously. One hundred and eleven volumetric, T1-weighted, 12-channel coil\nk-space datasets were used in the experiments. Normalized root mean squared\nerror, peak signal to noise ratio, visual information fidelity and visual\ninspection were used to assess the reconstructed images against the fully\nsampled reference images. Our results indicated that networks that operate\nsolely in the image domain are better suited when processing individual\nchannels of multi-channel data independently. Dual domain methods are more\nadvantageous when simultaneously reconstructing all channels of multi-channel\ndata. Also, the appropriate cascade of U-nets compared favorably (p < 0.01) to\nthe previously published, state-of-the-art Deep Cascade model in in three out\nof four experiments.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:23:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Souza", "Roberto", ""], ["Bento", "Mariana", ""], ["Nogovitsyn", "Nikita", ""], ["Chung", "Kevin J.", ""], ["Lebel", "R. Marc", ""], ["Frayne", "Richard", ""]]}, {"id": "1911.01462", "submitter": "Surbhi Goel", "authors": "Surbhi Goel, Sushrut Karmalkar, Adam Klivans", "title": "Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian\n  Marginals", "comments": "To appear in NeurIPS 2019 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the best-fitting ReLU with respect to\nsquare-loss on a training set when the examples have been drawn according to a\nspherical Gaussian distribution (the labels can be arbitrary). Let\n$\\mathsf{opt} < 1$ be the population loss of the best-fitting ReLU. We prove:\n  1. Finding a ReLU with square-loss $\\mathsf{opt} + \\epsilon$ is as hard as\nthe problem of learning sparse parities with noise, widely thought to be\ncomputationally intractable. This is the first hardness result for learning a\nReLU with respect to Gaussian marginals, and our results imply -{\\emph\nunconditionally}- that gradient descent cannot converge to the global minimum\nin polynomial time.\n  2. There exists an efficient approximation algorithm for finding the\nbest-fitting ReLU that achieves error $O(\\mathsf{opt}^{2/3})$. The algorithm\nuses a novel reduction to noisy halfspace learning with respect to $0/1$ loss.\n  Prior work due to Soltanolkotabi [Sol17] showed that gradient descent can\nfind the best-fitting ReLU with respect to Gaussian marginals, if the training\nset is exactly labeled by a ReLU.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:35:49 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Goel", "Surbhi", ""], ["Karmalkar", "Sushrut", ""], ["Klivans", "Adam", ""]]}, {"id": "1911.01468", "submitter": "Viktoriia Oliinyk", "authors": "Giulio Morina, Viktoriia Oliinyk, Julian Waton, Ines Marusic and\n  Konstantinos Georgatzis", "title": "Auditing and Achieving Intersectional Fairness in Classification\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are extensively used to make increasingly more\nconsequential decisions about people, so achieving optimal predictive\nperformance can no longer be the only focus. A particularly important\nconsideration is fairness with respect to race, gender, or any other sensitive\nattribute. This paper studies intersectional fairness, where intersections of\nmultiple sensitive attributes are considered. Prior research has mainly focused\non fairness with respect to a single sensitive attribute, with intersectional\nfairness being comparatively less studied despite its critical importance for\nthe safety of modern machine learning systems. We present a comprehensive\nframework for auditing and achieving intersectional fairness in classification\nproblems: we define a suite of metrics to assess intersectional fairness in the\ndata or model outputs by extending known single-attribute fairness metrics, and\npropose methods for robustly estimating them even when some intersectional\nsubgroups are underrepresented. Furthermore, we develop post-processing\ntechniques to mitigate any detected intersectional bias in a classification\nmodel. Our techniques do not rely on any assumptions regarding the underlying\nmodel and preserve predictive performance at a guaranteed level of fairness.\nFinally, we give guidance on a practical implementation, showing how the\nproposed methods perform on a real-world dataset.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:55:23 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:41:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Morina", "Giulio", ""], ["Oliinyk", "Viktoriia", ""], ["Waton", "Julian", ""], ["Marusic", "Ines", ""], ["Georgatzis", "Konstantinos", ""]]}, {"id": "1911.01469", "submitter": "Andre Wibisono", "authors": "Andre Wibisono", "title": "Proximal Langevin Algorithm: Rapid Convergence Under Isoperimetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Proximal Langevin Algorithm (PLA) for sampling from a\nprobability distribution $\\nu = e^{-f}$ on $\\mathbb{R}^n$ under isoperimetry.\nWe prove a convergence guarantee for PLA in Kullback-Leibler (KL) divergence\nwhen $\\nu$ satisfies log-Sobolev inequality (LSI) and $f$ has bounded second\nand third derivatives. This improves on the result for the Unadjusted Langevin\nAlgorithm (ULA), and matches the fastest known rate for sampling under LSI\n(without Metropolis filter) with a better dependence on the LSI constant. We\nalso prove convergence guarantees for PLA in R\\'enyi divergence of order $q >\n1$ when the biased limit satisfies either LSI or Poincar\\'e inequality.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:57:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wibisono", "Andre", ""]]}, {"id": "1911.01483", "submitter": "Yi Zhu", "authors": "Yi Zhu, Jing Dong", "title": "On Constructing Confidence Region for Model Parameters in Stochastic\n  Gradient Descent via Batch Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a simple algorithm to construct asymptotically valid\nconfidence regions for model parameters using the batch means method. The main\nidea is to cancel out the covariance matrix which is hard/costly to estimate.\nIn the process of developing the algorithm, we establish process-level\nfunctional central limit theorem for Polyak-Ruppert averaging based stochastic\ngradient descent estimators. We also extend the batch means method to\naccommodate more general batch size specifications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:48:30 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 15:13:19 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhu", "Yi", ""], ["Dong", "Jing", ""]]}, {"id": "1911.01484", "submitter": "Brandon Foggo", "authors": "Brandon Foggo, Nanpeng Yu", "title": "Improving Supervised Phase Identification Through the Theory of\n  Information Losses", "comments": "To be published in IEEE Transactions on Smart Grid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of Phase Identification in power\ndistribution systems. In particular, it focuses on improving supervised\nlearning accuracies by focusing on exploiting some of the problem's information\ntheoretic properties. This focus, along with recent advances in Information\nTheoretic Machine Learning (ITML), helps us to create two new techniques. The\nfirst transforms a bound on information losses into a data selection technique.\nThis is important because phase identification data labels are difficult to\nobtain in practice. The second interprets the properties of distribution\nsystems in the terms of ITML. This allows us to obtain an improvement in the\nrepresentation learned by any classifier applied to the problem. We tested\nthese two techniques experimentally on real datasets and have found that they\nyield phenomenal performance in every case. In the most extreme case, they\nimprove phase identification accuracy from $51.7\\%$ to $97.3\\%$. Furthermore,\nsince many problems share the physical properties of phase identification\nexploited in this paper, the techniques can be applied to a wide range of\nsimilar problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:51:26 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Foggo", "Brandon", ""], ["Yu", "Nanpeng", ""]]}, {"id": "1911.01485", "submitter": "Yi Chern Tan", "authors": "Yi Chern Tan, L. Elisa Celis", "title": "Assessing Social and Intersectional Biases in Contextualized Word\n  Representations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bias in machine learning has drawn significant attention, with work\nranging from demonstrations of bias in a multitude of applications, curating\ndefinitions of fairness for different contexts, to developing algorithms to\nmitigate bias. In natural language processing, gender bias has been shown to\nexist in context-free word embeddings. Recently, contextual word\nrepresentations have outperformed word embeddings in several downstream NLP\ntasks. These word representations are conditioned on their context within a\nsentence, and can also be used to encode the entire sentence. In this paper, we\nanalyze the extent to which state-of-the-art models for contextual word\nrepresentations, such as BERT and GPT-2, encode biases with respect to gender,\nrace, and intersectional identities. Towards this, we propose assessing bias at\nthe contextual word level. This novel approach captures the contextual effects\nof bias missing in context-free word embeddings, yet avoids confounding effects\nthat underestimate bias at the sentence encoding level. We demonstrate evidence\nof bias at the corpus level, find varying evidence of bias in embedding\nassociation tests, show in particular that racial bias is strongly encoded in\ncontextual word models, and observe that bias effects for intersectional\nminorities are exacerbated beyond their constituent minority identities.\nFurther, evaluating bias effects at the contextual word level captures biases\nthat are not captured at the sentence level, confirming the need for our novel\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:57:54 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tan", "Yi Chern", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1911.01486", "submitter": "Xavier Gitiaux", "authors": "Xavier Gitiaux, Shane A. Maloney, Anna Jungbluth, Carl Shneider, Paul\n  J. Wright, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Michel Deudon, Yarin Gal, Alfredo\n  Kalaitzis, Andr\\'es Mu\\~noz-Jaramillo", "title": "Probabilistic Super-Resolution of Solar Magnetograms: Generating Many\n  Explanations and Measuring Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.SR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been successfully applied to\nsuper-resolution tasks on natural images where visually pleasing results are\nsufficient. However in many scientific domains this is not adequate and\nestimations of errors and uncertainties are crucial. To address this issue we\npropose a Bayesian framework that decomposes uncertainties into epistemic and\naleatoric uncertainties. We test the validity of our approach by\nsuper-resolving images of the Sun's magnetic field and by generating maps\nmeasuring the range of possible high resolution explanations compatible with a\ngiven low resolution magnetogram.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:58:32 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Gitiaux", "Xavier", ""], ["Maloney", "Shane A.", ""], ["Jungbluth", "Anna", ""], ["Shneider", "Carl", ""], ["Wright", "Paul J.", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Deudon", "Michel", ""], ["Gal", "Yarin", ""], ["Kalaitzis", "Alfredo", ""], ["Mu\u00f1oz-Jaramillo", "Andr\u00e9s", ""]]}, {"id": "1911.01496", "submitter": "Le\\\"ila Haegel", "authors": "Le\\\"ila Haegel, Sascha Husa", "title": "Predicting the properties of black holes merger remnants with Deep\n  Neural Networks", "comments": "16 pages, 5 figures", "journal-ref": "Classical and Quantum Gravity (2020)", "doi": "10.1088/1361-6382/ab905c", "report-no": null, "categories": "gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first estimation of the mass and spin magnitude of Kerr black\nholes resulting from the coalescence of binary black holes using a deep neural\nnetwork. The network is trained on a dataset containing 80\\% of the full\npublicly available catalog of numerical simulations of gravitational waves\nemission by binary black hole systems, including full precession effects for\nspinning binaries. The network predicts the remnant black holes mass and spin\nwith an error less than 0.04\\% and 0.3\\% respectively for 90\\% of the values in\nthe non-precessing test dataset, it is 0.1\\% and 0.3\\% respectively in the\nprecessing test dataset. When compared to existing fits in the LIGO algorithm\nsoftware library, the network enables to reduce the remnant mass root mean\nsquare error to one half in the non-precessing case. In the precessing case,\nboth remnant mass and spin mean square errors are decreased to one half, and\nthe network corrects the bias observed in available fits.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 21:30:17 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:09:18 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Haegel", "Le\u00efla", ""], ["Husa", "Sascha", ""]]}, {"id": "1911.01509", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Moninder Singh and Karthikeyan Natesan Ramamurthy", "title": "Understanding racial bias in health using the Medical Expenditure Panel\n  Survey data", "comments": "8 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, several studies have demonstrated that there exist\nsignificant disparities in health indicators in the United States population\nacross various groups. Healthcare expense is used as a proxy for health in\nalgorithms that drive healthcare systems and this exacerbates the existing\nbias. In this work, we focus on the presence of racial bias in health\nindicators in the publicly available, and nationally representative Medical\nExpenditure Panel Survey (MEPS) data. We show that predictive models for care\nmanagement trained using this data inherit this bias. Finally, we demonstrate\nthat this inherited bias can be reduced significantly using simple mitigation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 22:14:52 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Singh", "Moninder", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1911.01522", "submitter": "Cesar A. Uribe", "authors": "Pavel Dvurechensky, Mathias Staudigl, C\\'esar A. Uribe", "title": "Generalized Self-concordant Hessian-barrier algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in statistical learning, imaging, and computer vision involve\nthe optimization of a non-convex objective function with singularities at the\nboundary of the feasible set. For such challenging instances, we develop a new\ninterior-point technique building on the Hessian-barrier algorithm recently\nintroduced in Bomze, Mertikopoulos, Schachinger and Staudigl, [SIAM J. Opt.\n2019 29(3), pp. 2100-2127], where the Riemannian metric is induced by a\ngeneralized self-concordant function. This class of functions is sufficiently\ngeneral to include most of the commonly used barrier functions in the\nliterature of interior point methods. We prove global convergence to an\napproximate stationary point of the method, and in cases where the feasible set\nadmits an easily computable self-concordant barrier, we verify worst-case\noptimal iteration complexity of the method. Applications in non-convex\nstatistical estimation and $L^{p}$-minimization are discussed to given the\nefficiency of the method.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 22:58:01 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 05:22:03 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Dvurechensky", "Pavel", ""], ["Staudigl", "Mathias", ""], ["Uribe", "C\u00e9sar A.", ""]]}, {"id": "1911.01525", "submitter": "Wei Han", "authors": "Wei Han, Yun Yang", "title": "Statistical Inference in Mean-Field Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct non-asymptotic analysis on the mean-field variational inference\nfor approximating posterior distributions in complex Bayesian models that may\ninvolve latent variables. We show that the mean-field approximation to the\nposterior can be well-approximated relative to the Kullback-Leibler divergence\ndiscrepancy measure by a normal distribution whose center is the maximum\nlikelihood estimator (MLE). In particular, our results imply that the center of\nthe mean-field approximation matches the MLE up to higher-order terms and there\nis essentially no loss of efficiency in using it as a point estimator for the\nparameter in any regular parametric model with latent variables. We also\npropose a new class of variational weighted likelihood bootstrap (VWLB) methods\nfor quantifying the uncertainty in the mean-field variational inference. The\nproposed VWLB can be viewed as a new sampling scheme that produces independent\nsamples for approximating the posterior. Comparing with traditional sampling\nalgorithms such Markov Chain Monte Carlo, VWLB can be implemented in parallel\nand is free of tuning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:08:49 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Han", "Wei", ""], ["Yang", "Yun", ""]]}, {"id": "1911.01531", "submitter": "Yiyang Wang", "authors": "Yiyang Wang, Neda Masoud, Anahita Khojandi", "title": "Real-Time Sensor Anomaly Detection and Recovery in Connected Automated\n  Vehicle Sensors", "comments": "Accepted to be Published in: IEEE Transactions on Intelligent\n  Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.2970295", "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel observer-based method to improve the safety\nand security of connected and automated vehicle (CAV) transportation. The\nproposed method combines model-based signal filtering and anomaly detection\nmethods. Specifically, we use adaptive extended Kalman filter (AEKF) to smooth\nsensor readings of a CAV based on a nonlinear car-following motion model. Under\nthe assumption of a car-following model, the subject vehicle utilizes its\nleading vehicle's information to detect sensor anomalies by employing\npreviously-trained One Class Support Vector Machine (OCSVM) models. This\napproach allows the AEKF to estimate the state of a vehicle not only based on\nthe vehicle's location and speed, but also by taking into account the state of\nthe surrounding traffic. A communication time delay factor is considered in the\ncar-following model to make it more suitable for real-world applications. Our\nexperiments show that compared with the AEKF with a traditional\n$\\chi^2$-detector, our proposed method achieves a better anomaly detection\nperformance. We also demonstrate that a larger time delay factor has a negative\nimpact on the overall detection performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:22:25 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:22:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Wang", "Yiyang", ""], ["Masoud", "Neda", ""], ["Khojandi", "Anahita", ""]]}, {"id": "1911.01535", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott Anthony Sisson, Caoyuan Li, Ling Chen", "title": "Scalable Deep Generative Relational Models with High-Order Node\n  Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic framework for modelling and exploring the latent\nstructure of relational data. Given feature information for the nodes in a\nnetwork, the scalable deep generative relational model (SDREM) builds a deep\nnetwork architecture that can approximate potential nonlinear mappings between\nnodes' feature information and the nodes' latent representations. Our\ncontribution is two-fold: (1) We incorporate high-order neighbourhood structure\ninformation to generate the latent representations at each node, which vary\nsmoothly over the network. (2) Due to the Dirichlet random variable structure\nof the latent representations, we introduce a novel data augmentation trick\nwhich permits efficient Gibbs sampling. The SDREM can be used for large sparse\nnetworks as its computational cost scales with the number of positive links. We\ndemonstrate its competitive performance through improved link prediction\nperformance on a range of real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:36:09 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott Anthony", ""], ["Li", "Caoyuan", ""], ["Chen", "Ling", ""]]}, {"id": "1911.01544", "submitter": "Andrea Montanari", "authors": "Andrea Montanari and Feng Ruan and Youngtak Sohn and Jun Yan", "title": "The generalization error of max-margin linear classifiers:\n  High-dimensional asymptotics in the overparametrized regime", "comments": "73 pages; 12 pdf figures (Added formulas for wide asymptotics, and\n  distribution of the coordinates of the estimator)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models are often so complex that they achieve\nvanishing classification error on the training set. Max-margin linear\nclassifiers are among the simplest classification methods that have zero\ntraining error (with linearly separable data). Despite their simplicity, their\nhigh-dimensional behavior is not yet completely understood. We assume to be\ngiven i.i.d. data $(y_i,{\\boldsymbol x}_i)$, $i\\le n$ with ${\\boldsymbol\nx}_i\\sim {\\sf N}(0,{\\boldsymbol \\Sigma})$ a $p$-dimensional feature vector, and\n$y_i \\in\\{+1,-1\\}$ a label whose distribution depends on a linear combination\nof the covariates $\\langle{\\boldsymbol\\theta}_*,{\\boldsymbol x}_i\\rangle$. We\nconsider the proportional asymptotics $n,p\\to\\infty$ with $p/n\\to \\psi$, and\nderive exact expressions for the limiting prediction error. Our asymptotic\nresults match simulations already when $n,p$ are of the order of a few\nhundreds.\n  We explore several choices for $({\\boldsymbol \\theta}_*,{\\boldsymbol\n\\Sigma})$, and show that the resulting generalization curve (test error error\nas a function of the overparametrization $\\psi=p/n$) is qualitatively\ndifferent, depending on this choice. In particular we consider a specific\nstructure of $({\\boldsymbol \\theta}_*,{\\boldsymbol\\Sigma})$ that captures the\nbehavior of nonlinear random feature models or, equivalently, two-layers neural\nnetworks with random first layer weights. In this case, we aim at classifying\ndata $(y_i,{\\boldsymbol x}_i)$ with ${\\boldsymbol x}_i\\in{\\mathbb R}^d$ but we\ndo so by first embedding them a $p$ dimensional feature space via ${\\boldsymbol\nx}_i\\mapsto\\sigma({\\boldsymbol W}{\\boldsymbol x}_i)$ and then finding a\nmax-margin classifier in this space. We derive exact formulas in the\nproportional asymptotics $p,n,d\\to\\infty$ with $p/d\\to\\psi_1$, $n/d\\to\\psi_2$\nand observe that the test error is minimized in the highly overparametrized\nregime $\\psi_1\\gg 0$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:15:27 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:29:50 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Montanari", "Andrea", ""], ["Ruan", "Feng", ""], ["Sohn", "Youngtak", ""], ["Yan", "Jun", ""]]}, {"id": "1911.01545", "submitter": "Forough Arabshahi", "authors": "Forough Arabshahi, Zhichu Lu, Pranay Mundra, Sameer Singh, Animashree\n  Anandkumar", "title": "Compositional Generalization with Tree Stack Memory Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study compositional generalization, viz., the problem of zero-shot\ngeneralization to novel compositions of concepts in a domain. Standard neural\nnetworks fail to a large extent on compositional learning. We propose Tree\nStack Memory Units (Tree-SMU) to enable strong compositional generalization.\nTree-SMU is a recursive neural network with Stack Memory Units (\\SMU s), a\nnovel memory augmented neural network whose memory has a differentiable stack\nstructure. Each SMU in the tree architecture learns to read from its stack and\nto write to it by combining the stacks and states of its children through\ngating. The stack helps capture long-range dependencies in the problem domain,\nthereby enabling compositional generalization. Additionally, the stack also\npreserves the ordering of each node's descendants, thereby retaining locality\non the tree. We demonstrate strong empirical results on two mathematical\nreasoning benchmarks. We use four compositionality tests to assess the\ngeneralization performance of Tree-SMU and show that it enables accurate\ncompositional generalization compared to strong baselines such as Transformers\nand Tree-LSTMs.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:27:03 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 16:17:52 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 04:19:53 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 16:50:58 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 00:24:06 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Arabshahi", "Forough", ""], ["Lu", "Zhichu", ""], ["Mundra", "Pranay", ""], ["Singh", "Sameer", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1911.01559", "submitter": "Ren Pang", "authors": "Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik,\n  Xiapu Luo, Alex Liu, Ting Wang", "title": "A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models", "comments": "Accepted as a full paper at ACM CCS 2020", "journal-ref": null, "doi": "10.1145/3372297.3417253", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their tremendous success in a range of domains, deep learning systems\nare inherently susceptible to two types of manipulations: adversarial inputs --\nmaliciously crafted samples that deceive target deep neural network (DNN)\nmodels, and poisoned models -- adversely forged DNNs that misbehave on\npre-defined inputs. While prior work has intensively studied the two attack\nvectors in parallel, there is still a lack of understanding about their\nfundamental connections: what are the dynamic interactions between the two\nattack vectors? what are the implications of such interactions for optimizing\nexisting attacks? what are the potential countermeasures against the enhanced\nattacks? Answering these key questions is crucial for assessing and mitigating\nthe holistic vulnerabilities of DNNs deployed in realistic settings.\n  Here we take a solid step towards this goal by conducting the first\nsystematic study of the two attack vectors within a unified framework.\nSpecifically, (i) we develop a new attack model that jointly optimizes\nadversarial inputs and poisoned models; (ii) with both analytical and empirical\nevidence, we reveal that there exist intriguing \"mutual reinforcement\" effects\nbetween the two attack vectors -- leveraging one vector significantly amplifies\nthe effectiveness of the other; (iii) we demonstrate that such effects enable a\nlarge design spectrum for the adversary to enhance the existing attacks that\nexploit both vectors (e.g., backdoor attacks), such as maximizing the attack\nevasiveness with respect to various detection methods; (iv) finally, we discuss\npotential countermeasures against such optimized attacks and their technical\nchallenges, pointing to several promising research directions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:32:57 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 22:14:26 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 04:54:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pang", "Ren", ""], ["Shen", "Hua", ""], ["Zhang", "Xinyang", ""], ["Ji", "Shouling", ""], ["Vorobeychik", "Yevgeniy", ""], ["Luo", "Xiapu", ""], ["Liu", "Alex", ""], ["Wang", "Ting", ""]]}, {"id": "1911.01575", "submitter": "Anant Raj", "authors": "Anant Raj, Cameron Musco and Lester Mackey", "title": "Importance Sampling via Local Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a loss function $F:\\mathcal{X} \\rightarrow \\R^+$ that can be written as\nthe sum of losses over a large set of inputs $a_1,\\ldots, a_n$, it is often\ndesirable to approximate $F$ by subsampling the input points. Strong\ntheoretical guarantees require taking into account the importance of each\npoint, measured by how much its individual loss contributes to $F(x)$.\nMaximizing this importance over all $x \\in \\mathcal{X}$ yields the\n\\emph{sensitivity score} of $a_i$. Sampling with probabilities proportional to\nthese scores gives strong guarantees, allowing one to approximately minimize of\n$F$ using just the subsampled points.\n  Unfortunately, sensitivity sampling is difficult to apply since (1) it is\nunclear how to efficiently compute the sensitivity scores and (2) the sample\nsize required is often impractically large. To overcome both obstacles we\nintroduce \\emph{local sensitivity}, which measures data point importance in a\nball around some center $x_0$. We show that the local sensitivity can be\nefficiently estimated using the \\emph{leverage scores} of a quadratic\napproximation to $F$ and that the sample size required to approximate $F$\naround $x_0$ can be bounded. We propose employing local sensitivity sampling in\nan iterative optimization method and analyze its convergence when $F$ is smooth\nand convex.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 03:59:58 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 13:53:48 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Raj", "Anant", ""], ["Musco", "Cameron", ""], ["Mackey", "Lester", ""]]}, {"id": "1911.01641", "submitter": "Vladimir Kobzar", "authors": "Vladimir A. Kobzar, Robert V. Kohn, Zhilei Wang", "title": "New Potential-Based Bounds for Prediction with Expert Advice", "comments": "To appear in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.AP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the classic machine learning problem of online prediction\nwith expert advice. We consider the finite-horizon version of this zero-sum,\ntwo-person game. Using verification arguments from optimal control theory, we\nview the task of finding better lower and upper bounds on the value of the game\n(regret) as the problem of finding better sub- and supersolutions of certain\npartial differential equations (PDEs). These sub- and supersolutions serve as\nthe potentials for player and adversary strategies, which lead to the\ncorresponding bounds. To get explicit bounds, we use closed-form solutions of\nspecific PDEs. Our bounds hold for any given number of experts and horizon; in\ncertain regimes (which we identify) they improve upon the previous state of the\nart. For two and three experts, our bounds provide the optimal leading order\nterm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 06:43:21 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 00:52:20 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 16:53:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kobzar", "Vladimir A.", ""], ["Kohn", "Robert V.", ""], ["Wang", "Zhilei", ""]]}, {"id": "1911.01649", "submitter": "Chuang Wang", "authors": "Wei Wang, Chuang Wang, Tao Cui, Yue Li", "title": "Study of Constrained Network Structures for WGANs on Numeric Data\n  Generation", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.2993839", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some recent studies have suggested using GANs for numeric data generation\nsuch as to generate data for completing the imbalanced numeric data.\nConsidering the significant difference between the dimensions of the numeric\ndata and images, as well as the strong correlations between features of numeric\ndata, the conventional GANs normally face an overfitting problem, consequently\nleads to an ill-conditioning problem in generating numeric and structured data.\nThis paper studies the constrained network structures between generator G and\ndiscriminator D in WGAN, designs several structures including isomorphic,\nmirror and self-symmetric structures. We evaluates the performances of the\nconstrained WGANs in data augmentations, taking the non-constrained GANs and\nWGANs as the baselines. Experiments prove the constrained structures have been\nimproved in 17/20 groups of experiments. In twenty experiments on four UCI\nMachine Learning Repository datasets, Australian Credit Approval data, German\nCredit data, Pima Indians Diabetes data and SPECT heart data facing five\nconventional classifiers. Especially, Isomorphic WGAN is the best in 15/20\nexperiments. Finally, we theoretically proves that the effectiveness of\nconstrained structures by the directed graphic model (DGM) analysis.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 07:27:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Wei", ""], ["Wang", "Chuang", ""], ["Cui", "Tao", ""], ["Li", "Yue", ""]]}, {"id": "1911.01654", "submitter": "Kasra Babaei", "authors": "Kasra Babaei, ZhiYuan Chen, Tomas Maul", "title": "Detecting Point Outliers Using Prune-based Outlier Factor (PLOF)", "comments": "Accepted by \"The 4th International Conference on Computing,\n  Mathematics and Statistics 2019 (iCMS2019)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Outlier detection (also known as anomaly detection or deviation detection) is\na process of detecting data points in which their patterns deviate\nsignificantly from others. It is common to have outliers in industry\napplications, which could be generated by different causes such as human error,\nfraudulent activities, or system failure. Recently, density-based methods have\nshown promising results, particularly among which Local Outlier Factor (LOF) is\narguably dominating. However, one of the major drawbacks of LOF is that it is\ncomputationally expensive. Motivated by the mentioned problem, this research\npresents a novel pruning-based procedure in which the execution time of LOF is\nreduced while the performance is maintained. A novel Prune-based Local Outlier\nFactor (PLOF) approach is proposed, in which prior to employing LOF,\noutlierness of each data instance is measured. Next, based on a threshold, data\ninstances that require further investigation are separated and LOF score is\nonly computed for these points. Extensive experiments have been conducted and\nresults are promising. Comparison experiments with the original LOF and two\nstate-of-the-art variants of LOF have shown that PLOF produces higher accuracy\nand precision while reducing execution time.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 07:42:42 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Babaei", "Kasra", ""], ["Chen", "ZhiYuan", ""], ["Maul", "Tomas", ""]]}, {"id": "1911.01658", "submitter": "Guoqiang Wu", "authors": "Guoqiang Wu, Ruobing Zheng, Yingjie Tian, Dalian Liu", "title": "Joint Ranking SVM and Binary Relevance with Robust Low-Rank Learning for\n  Multi-Label Classification", "comments": "57 pages, 5 figures, to be published in the journal of Neural\n  Networks", "journal-ref": "Neural Networks, 2020, 122: 24-39", "doi": "10.1016/j.neunet.2019.10.002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification studies the task where each example belongs to\nmultiple labels simultaneously. As a representative method, Ranking Support\nVector Machine (Rank-SVM) aims to minimize the Ranking Loss and can also\nmitigate the negative influence of the class-imbalance issue. However, due to\nits stacking-style way for thresholding, it may suffer error accumulation and\nthus reduces the final classification performance. Binary Relevance (BR) is\nanother typical method, which aims to minimize the Hamming Loss and only needs\none-step learning. Nevertheless, it might have the class-imbalance issue and\ndoes not take into account label correlations. To address the above issues, we\npropose a novel multi-label classification model, which joints Ranking support\nvector machine and Binary Relevance with robust Low-rank learning (RBRL). RBRL\ninherits the ranking loss minimization advantages of Rank-SVM, and thus\novercomes the disadvantages of BR suffering the class-imbalance issue and\nignoring the label correlations. Meanwhile, it utilizes the hamming loss\nminimization and one-step learning advantages of BR, and thus tackles the\ndisadvantages of Rank-SVM including another thresholding learning step.\nBesides, a low-rank constraint is utilized to further exploit high-order label\ncorrelations under the assumption of low dimensional label space. Furthermore,\nto achieve nonlinear multi-label classifiers, we derive the kernelization RBRL.\nTwo accelerated proximal gradient methods (APG) are used to solve the\noptimization problems efficiently. Extensive comparative experiments with\nseveral state-of-the-art methods illustrate a highly competitive or superior\nperformance of our method RBRL.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 07:50:36 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wu", "Guoqiang", ""], ["Zheng", "Ruobing", ""], ["Tian", "Yingjie", ""], ["Liu", "Dalian", ""]]}, {"id": "1911.01679", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Alon Cohen, Haim Kaplan and Yishay Mansour", "title": "Apprenticeship Learning via Frank-Wolfe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the applications of the Frank-Wolfe (FW) algorithm for\nApprenticeship Learning (AL). In this setting, we are given a Markov Decision\nProcess (MDP) without an explicit reward function. Instead, we observe an\nexpert that acts according to some policy, and the goal is to find a policy\nwhose feature expectations are closest to those of the expert policy. We\nformulate this problem as finding the projection of the feature expectations of\nthe expert on the feature expectations polytope -- the convex hull of the\nfeature expectations of all the deterministic policies in the MDP. We show that\nthis formulation is equivalent to the AL objective and that solving this\nproblem using the FW algorithm is equivalent well-known Projection method of\nAbbeel and Ng (2004). This insight allows us to analyze AL with tools from\nconvex optimization literature and derive tighter convergence bounds on AL.\nSpecifically, we show that a variation of the FW method that is based on taking\n\"away steps\" achieves a linear rate of convergence when applied to AL and that\na stochastic version of the FW algorithm can be used to avoid precise\nestimation of feature expectations. We also experimentally show that this\nversion outperforms the FW baseline. To the best of our knowledge, this is the\nfirst work that shows linear convergence rates for AL.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:26:06 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 14:50:44 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zahavy", "Tom", ""], ["Cohen", "Alon", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1911.01694", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty and George Haddad and Catherine A. Haddad-Zaknoon", "title": "Bounds for the Number of Tests in Non-Adaptive Randomized Algorithms for\n  Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the group testing problem with non-adaptive randomized algorithms.\nSeveral models have been discussed in the literature to determine how to\nrandomly choose the tests. For a model ${\\cal M}$, let $m_{\\cal M}(n,d)$ be the\nminimum number of tests required to detect at most $d$ defectives within $n$\nitems, with success probability at least $1-\\delta$, for some constant\n$\\delta$. In this paper, we study the measures $$c_{\\cal M}(d)=\\lim_{n\\to\n\\infty} \\frac{m_{\\cal M}(n,d)}{\\ln n} \\mbox{ and } c_{\\cal M}=\\lim_{d\\to\n\\infty} \\frac{c_{\\cal M}(d)}{d}.$$\n  In the literature, the analyses of such models only give upper bounds for\n$c_{\\cal M}(d)$ and $c_{\\cal M}$, and for some of them, the bounds are not\ntight. We give new analyses that yield tight bounds for $c_{\\cal M}(d)$ and\n$c_{\\cal M}$ for all the known models~${\\cal M}$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:09:28 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bshouty", "Nader H.", ""], ["Haddad", "George", ""], ["Haddad-Zaknoon", "Catherine A.", ""]]}, {"id": "1911.01695", "submitter": "Mohammadi Zaki", "authors": "Mohammadi Zaki, Avinash Mohan and Aditya Gopalan", "title": "Towards Optimal and Efficient Best Arm Identification in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for best arm identification in linearly parameterised\nbandits in the fixed confidence setting. The algorithm generalises the\nwell-known LUCB algorithm of Kalyanakrishnan et al. (2012) by playing an arm\nwhich minimises a suitable notion of geometric overlap of the statistical\nconfidence set for the unknown parameter, and is fully adaptive and\ncomputationally efficient as compared to several state-of-the methods. We\ntheoretically analyse the sample complexity of the algorithm for problems with\ntwo and three arms, showing optimality in many cases. Numerical results\nindicate favourable performance over other algorithms with which we compare.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:11:49 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 07:20:35 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zaki", "Mohammadi", ""], ["Mohan", "Avinash", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.01700", "submitter": "Magnus Wiese", "authors": "Magnus Wiese, Lianjun Bai, Ben Wood, Hans Buehler", "title": "Deep Hedging: Learning to Simulate Equity Option Markets", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness, and Privacy", "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.MF q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct realistic equity option market simulators based on generative\nadversarial networks (GANs). We consider recurrent and temporal convolutional\narchitectures, and assess the impact of state compression. Option market\nsimulators are highly relevant because they allow us to extend the limited\nreal-world data sets available for the training and evaluation of option\ntrading strategies. We show that network-based generators outperform classical\nmethods on a range of benchmark metrics, and adversarial training achieves the\nbest performance. Our work demonstrates for the first time that GANs can be\nsuccessfully applied to the task of generating multivariate financial time\nseries.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:23:39 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wiese", "Magnus", ""], ["Bai", "Lianjun", ""], ["Wood", "Ben", ""], ["Buehler", "Hans", ""]]}, {"id": "1911.01702", "submitter": "Johannes Rausch", "authors": "Johannes Rausch, Octavio Martinez, Fabian Bissig, Ce Zhang, Stefan\n  Feuerriegel", "title": "DocParser: Hierarchical Structure Parsing of Document Renderings", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating renderings (e. g. PDFs, scans) into hierarchical document\nstructures is extensively demanded in the daily routines of many real-world\napplications. However, a holistic, principled approach to inferring the\ncomplete hierarchical structure of documents is missing. As a remedy, we\ndeveloped \"DocParser\": an end-to-end system for parsing the complete document\nstructure - including all text elements, nested figures, tables, and table cell\nstructures. Our second contribution is to provide a dataset for evaluating\nhierarchical document structure parsing. Our third contribution is to propose a\nscalable learning framework for settings where domain-specific data are scarce,\nwhich we address by a novel approach to weak supervision that significantly\nimproves the document structure parsing performance. Our experiments confirm\nthe effectiveness of our proposed weak supervision: Compared to the baseline\nwithout weak supervision, it improves the mean average precision for detecting\ndocument entities by 39.1 % and improves the F1 score of classifying\nhierarchical relations by 35.8 %.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:42:08 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 11:54:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Rausch", "Johannes", ""], ["Martinez", "Octavio", ""], ["Bissig", "Fabian", ""], ["Zhang", "Ce", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1911.01705", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Liu Yang and Rudrasis Chakraborty", "title": "A GMM based algorithm to generate point-cloud and its application to\n  neuroimaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence of 3D medical imaging techniques\nwith the development of 3D sensors and technology. Due to the presence of noise\nin image acquisition, registration researchers focused on an alternative way to\nrepresent medical images. An alternative way to analyze medical imaging is by\nunderstanding the 3D shapes represented in terms of point-cloud. Though in the\nmedical imaging community, 3D point-cloud processing is not a ``go-to'' choice,\nit is a ``natural'' way to capture 3D shapes. However, as the number of samples\nfor medical images are small, researchers have used pre-trained models to\nfine-tune on medical images. Furthermore, due to different modality in medical\nimages, standard generative models can not be used to generate new samples of\nmedical images. In this work, we use the advantage of point-cloud\nrepresentation of 3D structures of medical images and propose a Gaussian\nmixture model-based generation scheme. Our proposed method is robust to\noutliers. Experimental validation has been performed to show that the proposed\nscheme can generate new 3D structures using interpolation techniques, i.e.,\ngiven two 3D structures represented as point-clouds, we can generate\npoint-clouds in between. We have also generated new point-clouds for subjects\nwith and without dementia and show that the generated samples are indeed\nclosely matched to the respective training samples from the same class.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:54:53 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yang", "Liu", ""], ["Chakraborty", "Rudrasis", ""]]}, {"id": "1911.01731", "submitter": "Yanqiao Zhu", "authors": "Fenyu Hu, Yanqiao Zhu, Shu Wu, Weiran Huang, Liang Wang, Tieniu Tan", "title": "GraphAIR: Graph Representation Learning with Neighborhood Aggregation\n  and Interaction", "comments": "12 pages, accepted to Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107745", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is of paramount importance for a variety of\ngraph analytical tasks, ranging from node classification to community\ndetection. Recently, graph convolutional networks (GCNs) have been successfully\napplied for graph representation learning. These GCNs generate node\nrepresentation by aggregating features from the neighborhoods, which follows\nthe \"neighborhood aggregation\" scheme. In spite of having achieved promising\nperformance on various tasks, existing GCN-based models have difficulty in well\ncapturing complicated non-linearity of graph data. In this paper, we first\ntheoretically prove that coefficients of the neighborhood interacting terms are\nrelatively small in current models, which explains why GCNs barely outperforms\nlinear models. Then, in order to better capture the complicated non-linearity\nof graph data, we present a novel GraphAIR framework which models the\nneighborhood interaction in addition to neighborhood aggregation. Comprehensive\nexperiments conducted on benchmark tasks including node classification and link\nprediction using public datasets demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 11:47:58 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 12:21:06 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 16:11:49 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hu", "Fenyu", ""], ["Zhu", "Yanqiao", ""], ["Wu", "Shu", ""], ["Huang", "Weiran", ""], ["Wang", "Liang", ""], ["Tan", "Tieniu", ""]]}, {"id": "1911.01738", "submitter": "Sergey Pavlov", "authors": "Sergey Pavlov, Alexey Artemov, Maksim Sharaev, Alexander Bernstein,\n  Evgeny Burnaev", "title": "Weakly Supervised Fine Tuning Approach for Brain Tumor Segmentation\n  Problem", "comments": "Accepted to IEEE International Conference on Machine Learning and\n  Applications (ICMLA 2019). Typos corrected, images updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of tumors in brain MRI images is a challenging task, where most\nrecent methods demand large volumes of data with pixel-level annotations, which\nare generally costly to obtain. In contrast, image-level annotations, where\nonly the presence of lesion is marked, are generally cheap, generated in far\nlarger volumes compared to pixel-level labels, and contain less labeling noise.\nIn the context of brain tumor segmentation, both pixel-level and image-level\nannotations are commonly available; thus, a natural question arises whether a\nsegmentation procedure could take advantage of both. In the present work we: 1)\npropose a learning-based framework that allows simultaneous usage of both\npixel- and image-level annotations in MRI images to learn a segmentation model\nfor brain tumor; 2) study the influence of comparative amounts of pixel- and\nimage-level annotations on the quality of brain tumor segmentation; 3) compare\nour approach to the traditional fully-supervised approach and show that the\nperformance of our method in terms of segmentation quality may be competitive.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 12:14:40 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 07:48:01 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Pavlov", "Sergey", ""], ["Artemov", "Alexey", ""], ["Sharaev", "Maksim", ""], ["Bernstein", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1911.01812", "submitter": "Zaoxing Liu", "authors": "Zaoxing Liu, Tian Li, Virginia Smith, Vyas Sekar", "title": "Enhancing the Privacy of Federated Learning with Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to growing concerns about user privacy, federated learning has\nemerged as a promising tool to train statistical models over networks of\ndevices while keeping data localized. Federated learning methods run training\ntasks directly on user devices and do not share the raw user data with third\nparties. However, current methods still share model updates, which may contain\nprivate information (e.g., one's weight and height), during the training\nprocess. Existing efforts that aim to improve the privacy of federated learning\nmake compromises in one or more of the following key areas: performance\n(particularly communication cost), accuracy, or privacy. To better optimize\nthese trade-offs, we propose that \\textit{sketching algorithms} have a unique\nadvantage in that they can provide both privacy and performance benefits while\nmaintaining accuracy. We evaluate the feasibility of sketching-based federated\nlearning with a prototype on three representative learning models. Our initial\nfindings show that it is possible to provide strong privacy guarantees for\nfederated learning without sacrificing performance or accuracy. Our work\nhighlights that there exists a fundamental connection between privacy and\ncommunication in distributed settings, and suggests important open problems\nsurrounding the theoretical understanding, methodology, and system design of\npractical, private federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:38:18 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Zaoxing", ""], ["Li", "Tian", ""], ["Smith", "Virginia", ""], ["Sekar", "Vyas", ""]]}, {"id": "1911.01861", "submitter": "Massih-Reza Amini", "authors": "Anastasiia Doinychko and Massih-Reza Amini", "title": "Biconditional Generative Adversarial Networks for Multiview Learning\n  with Missing Views", "comments": "15 pages, 3 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a conditional GAN with two generators and a common\ndiscriminator for multiview learning problems where observations have two\nviews, but one of them may be missing for some of the training samples. This is\nfor example the case for multilingual collections where documents are not\navailable in all languages. Some studies tackled this problem by assuming the\nexistence of view generation functions to approximately complete the missing\nviews; for example Machine Translation to translate documents into the missing\nlanguages. These functions generally require an external resource to be set and\ntheir quality has a direct impact on the performance of the learned multiview\nclassifier over the completed training set. Our proposed approach addresses\nthis problem by jointly learning the missing views and the multiview classifier\nusing a tripartite game with two generators and a discriminator. Each of the\ngenerators is associated to one of the views and tries to fool the\ndiscriminator by generating the other missing view conditionally on the\ncorresponding observed view. The discriminator then tries to identify if for an\nobservation, one of its views is completed by one of the generators or if both\nviews are completed along with its class. Our results on a subset of Reuters\nRCV1/RCV2 collections show that the discriminator achieves significant\nclassification performance; and that the generators learn the missing views\nwith high quality without the need of any consequent external resource.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:20:06 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 08:37:45 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Doinychko", "Anastasiia", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1911.01871", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "On Online Learning in Kernelized Markov Decision Processes", "comments": "arXiv admin note: text overlap with arXiv:1805.08052", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop algorithms with low regret for learning episodic Markov decision\nprocesses based on kernel approximation techniques. The algorithms are based on\nboth the Upper Confidence Bound (UCB) as well as Posterior or Thompson Sampling\n(PSRL) philosophies, and work in the general setting of continuous state and\naction spaces when the true unknown transition dynamics are assumed to have\nsmoothness induced by an appropriate Reproducing Kernel Hilbert Space (RKHS).\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 05:17:28 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.01872", "submitter": "Taoli Cheng", "authors": "Taoli Cheng", "title": "Interpretability Study on Deep Learning for Jet Physics at the Large\n  Hadron Collider", "comments": "Version for Machine Learning and the Physical Sciences workshop\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using deep neural networks for identifying physics objects at the Large\nHadron Collider (LHC) has become a powerful alternative approach in recent\nyears. After successful training of deep neural networks, examining the trained\nnetworks not only helps us understand the behaviour of neural networks, but\nalso helps improve the performance of deep learning models through proper\ninterpretation. We take jet tagging problem at the LHC as an example, using\nrecursive neural networks as a starting point, aim at a thorough understanding\nof the behaviour of the physics-oriented DNNs and the information encoded in\nthe embedding space. We make a comparative study on a series of different jet\ntagging tasks dominated by different underlying physics. Interesting\nobservations on the latent space are obtained.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:27:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Cheng", "Taoli", ""]]}, {"id": "1911.01877", "submitter": "Tim J. Adler", "authors": "Tim J. Adler, Leonardo Ayala, Lynton Ardizzone, Hannes G. Kenngott,\n  Anant Vemuri, Beat P. M\\\"uller-Stich, Carsten Rother, Ullrich K\\\"othe, and\n  Lena Maier-Hein", "title": "Out of distribution detection for intra-operative functional imaging", "comments": "The final authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-32689-0_8", "journal-ref": "Proceedings of the First International Workshop on Uncertainty for\n  Safe Utilization of Machine Learning in Medical Imaging, UNSURE 2019, and the\n  8th International Workshop on Clinical Image-Based Procedures, CLIP 2019", "doi": "10.1007/978-3-030-32689-0_8", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multispectral optical imaging is becoming a key tool in the operating room.\nRecent research has shown that machine learning algorithms can be used to\nconvert pixel-wise reflectance measurements to tissue parameters, such as\noxygenation. However, the accuracy of these algorithms can only be guaranteed\nif the spectra acquired during surgery match the ones seen during training. It\nis therefore of great interest to detect so-called out of distribution (OoD)\nspectra to prevent the algorithm from presenting spurious results. In this\npaper we present an information theory based approach to OoD detection based on\nthe widely applicable information criterion (WAIC). Our work builds upon recent\nmethodology related to invertible neural networks (INN). Specifically, we make\nuse of an ensemble of INNs as we need their tractable Jacobians in order to\ncompute the WAIC. Comprehensive experiments with in silico, and in vivo\nmultispectral imaging data indicate that our approach is well-suited for OoD\ndetection. Our method could thus be an important step towards reliable\nfunctional imaging in the operating room.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:31:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Adler", "Tim J.", ""], ["Ayala", "Leonardo", ""], ["Ardizzone", "Lynton", ""], ["Kenngott", "Hannes G.", ""], ["Vemuri", "Anant", ""], ["M\u00fcller-Stich", "Beat P.", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""], ["Maier-Hein", "Lena", ""]]}, {"id": "1911.01894", "submitter": "Tomas Geffner", "authors": "Tomas Geffner and Justin Domke", "title": "A Rule for Gradient Estimator Selection, with an Application to\n  Variational Inference", "comments": "18 pages, preliminary work. International Conference on Artificial\n  Intelligence and Statistics. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is the workhorse of modern machine\nlearning. Sometimes, there are many different potential gradient estimators\nthat can be used. When so, choosing the one with the best tradeoff between cost\nand variance is important. This paper analyzes the convergence rates of SGD as\na function of time, rather than iterations. This results in a simple rule to\nselect the estimator that leads to the best optimization convergence guarantee.\nThis choice is the same for different variants of SGD, and with different\nassumptions about the objective (e.g. convexity or smoothness). Inspired by\nthis principle, we propose a technique to automatically select an estimator\nwhen a finite pool of estimators is given. Then, we extend to infinite pools of\nestimators, where each one is indexed by control variate weights. This is\nenabled by a reduction to a mixed-integer quadratic program. Empirically,\nautomatically choosing an estimator performs comparably to the best estimator\nchosen with hindsight.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:57:19 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "1911.01914", "submitter": "Gonzalo Mart\\'inez-Mu\\~noz", "authors": "Candice Bent\\'ejac and Anna Cs\\\"org\\H{o} and Gonzalo\n  Mart\\'inez-Mu\\~noz", "title": "A Comparative Analysis of XGBoost", "comments": null, "journal-ref": null, "doi": "10.1007/s10462-020-09896-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XGBoost is a scalable ensemble technique based on gradient boosting that has\ndemonstrated to be a reliable and efficient machine learning challenge solver.\nThis work proposes a practical analysis of how this novel technique works in\nterms of training speed, generalization performance and parameter setup. In\naddition, a comprehensive comparison between XGBoost, random forests and\ngradient boosting has been performed using carefully tuned models as well as\nusing the default settings. The results of this comparison may indicate that\nXGBoost is not necessarily the best choice under all circumstances. Finally an\nextensive analysis of XGBoost parametrization tuning process is carried out.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:18:29 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bent\u00e9jac", "Candice", ""], ["Cs\u00f6rg\u0151", "Anna", ""], ["Mart\u00ednez-Mu\u00f1oz", "Gonzalo", ""]]}, {"id": "1911.01915", "submitter": "Pablo Morales-\\'Alvarez", "authors": "Pablo Morales-\\'Alvarez and Pablo Ruiz and Scott Coughlin and Rafael\n  Molina and Aggelos K. Katsaggelos", "title": "Scalable Variational Gaussian Processes for Crowdsourcing: Glitch\n  Detection in LIGO", "comments": "16 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, crowdsourcing is transforming the way classification\ntraining sets are obtained. Instead of relying on a single expert annotator,\ncrowdsourcing shares the labelling effort among a large number of\ncollaborators. For instance, this is being applied to the data acquired by the\nlaureate Laser Interferometer Gravitational Waves Observatory (LIGO), in order\nto detect glitches which might hinder the identification of true\ngravitational-waves. The crowdsourcing scenario poses new challenging\ndifficulties, as it deals with different opinions from a heterogeneous group of\nannotators with unknown degrees of expertise. Probabilistic methods, such as\nGaussian Processes (GP), have proven successful in modeling this setting.\nHowever, GPs do not scale well to large data sets, which hampers their broad\nadoption in real practice (in particular at LIGO). This has led to the recent\nintroduction of deep learning based crowdsourcing methods, which have become\nthe state-of-the-art. However, the accurate uncertainty quantification of GPs\nhas been partially sacrificed. This is an important aspect for astrophysicists\nin LIGO, since a glitch detection system should provide very accurate\nprobability distributions of its predictions. In this work, we leverage the\nmost popular sparse GP approximation to develop a novel GP based crowdsourcing\nmethod that factorizes into mini-batches. This makes it able to cope with\npreviously-prohibitive data sets. The approach, which we refer to as Scalable\nVariational Gaussian Processes for Crowdsourcing (SVGPCR), brings back GP-based\nmethods to the state-of-the-art, and excels at uncertainty quantification.\nSVGPCR is shown to outperform deep learning based methods and previous\nprobabilistic approaches when applied to the LIGO data. Moreover, its behavior\nand main properties are carefully analyzed in a controlled experiment based on\nthe MNIST data set.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:20:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Morales-\u00c1lvarez", "Pablo", ""], ["Ruiz", "Pablo", ""], ["Coughlin", "Scott", ""], ["Molina", "Rafael", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "1911.01916", "submitter": "Xuezhi Wang", "authors": "Xuezhi Wang, Nithum Thain, Anu Sinha, Flavien Prost, Ed H. Chi, Jilin\n  Chen, Alex Beutel", "title": "Practical Compositional Fairness: Understanding Fairness in\n  Multi-Component Recommender Systems", "comments": "WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we build recommender systems to take into account fairness?\nReal-world recommender systems are often composed of multiple models, built by\nmultiple teams. However, most research on fairness focuses on improving\nfairness in a single model. Further, recent research on classification fairness\nhas shown that combining multiple \"fair\" classifiers can still result in an\n\"unfair\" classification system. This presents a significant challenge: how do\nwe understand and improve fairness in recommender systems composed of multiple\ncomponents?\n  In this paper, we study the compositionality of recommender fairness. We\nconsider two recently proposed fairness ranking metrics: equality of exposure\nand pairwise ranking accuracy. While we show that fairness in recommendation is\nnot guaranteed to compose, we provide theory for a set of conditions under\nwhich fairness of individual models does compose. We then present an analytical\nframework for both understanding whether a real system's signals can achieve\ncompositional fairness, and improving which component would have the greatest\nimpact on the fairness of the overall system. In addition to the theoretical\nresults, we find on multiple datasets -- including a large-scale real-world\nrecommender system -- that the overall system's end-to-end fairness is largely\nachievable by improving fairness in individual components.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:22:25 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:44:40 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 05:44:06 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 21:43:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wang", "Xuezhi", ""], ["Thain", "Nithum", ""], ["Sinha", "Anu", ""], ["Prost", "Flavien", ""], ["Chi", "Ed H.", ""], ["Chen", "Jilin", ""], ["Beutel", "Alex", ""]]}, {"id": "1911.01919", "submitter": "Shaoming Xie", "authors": "Shao-Ming Xie", "title": "Neural Network Based Parameter Estimation Method for the Pareto/NBD\n  Model", "comments": "35 pages, 6 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether stochastic or parametric, the Pareto/NBD model can only be utilized\nfor an in-sample prediction rather than an out-of-sample prediction. This\nresearch thus provides a neural network based extension of the Pareto/NBD model\nto estimate the out-of-sample parameters, which overrides the estimation burden\nand the application dilemma of the Pareto/NBD approach. The empirical results\nindicate that the Pareto/NBD model and neural network algorithms have similar\npredictability for identifying inactive customers. Even with a strong trend\nfitting on the customer count of each repeat purchase point, the Pareto/NBD\nmodel underestimates repeat purchases at both the individual and aggregate\nlevels. Nonetheless, when embedding the likelihood function of the Pareto/NBD\nmodel into the loss function, the proposed parameter estimation method shows\nextraordinary predictability on repeat purchases at these two levels.\nFurthermore, the proposed neural network based method is highly efficient and\nresource-friendly and can be deployed in cloud computing to handle with big\ndata analysis.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:27:41 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Xie", "Shao-Ming", ""]]}, {"id": "1911.01929", "submitter": "Pavel Berkovich", "authors": "Pavel Berkovich, Eric Perim, Wessel Bruinsma", "title": "GP-ALPS: Automatic Latent Process Selection for Multi-Output Gaussian\n  Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple and widely adopted approach to extend Gaussian processes (GPs) to\nmultiple outputs is to model each output as a linear combination of a\ncollection of shared, unobserved latent GPs. An issue with this approach is\nchoosing the number of latent processes and their kernels. These choices are\ntypically done manually, which can be time consuming and prone to human biases.\nWe propose Gaussian Process Automatic Latent Process Selection (GP-ALPS), which\nautomatically chooses the latent processes by turning off those that do not\nmeaningfully contribute to explaining the data. We develop a variational\ninference scheme, assess the quality of the variational posterior by comparing\nit against the gold standard MCMC, and demonstrate the suitability of GP-ALPS\nin a set of preliminary experiments.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:46:37 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 12:02:55 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Berkovich", "Pavel", ""], ["Perim", "Eric", ""], ["Bruinsma", "Wessel", ""]]}, {"id": "1911.01931", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Deanna Needell, and Laura Balzano", "title": "Online matrix factorization for Markovian data and applications to\n  Network Dictionary Learning", "comments": "39 pages, 13 figures", "journal-ref": "Journal of Machine Learning Research 21 (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Matrix Factorization (OMF) is a fundamental tool for dictionary\nlearning problems, giving an approximate representation of complex data sets in\nterms of a reduced number of extracted features. Convergence guarantees for\nmost of the OMF algorithms in the literature assume independence between data\nmatrices, and the case of dependent data streams remains largely unexplored. In\nthis paper, we show that a non-convex generalization of the well-known OMF\nalgorithm for i.i.d. stream of data in \\citep{mairal2010online} converges\nalmost surely to the set of critical points of the expected loss function, even\nwhen the data matrices are functions of some underlying Markov chain satisfying\na mild mixing condition. This allows one to extract features more efficiently\nfrom dependent data streams, as there is no need to subsample the data sequence\nto approximately satisfy the independence assumption. As the main application,\nby combining online non-negative matrix factorization and a recent MCMC\nalgorithm for sampling motifs from networks, we propose a novel framework of\nNetwork Dictionary Learning, which extracts ``network dictionary patches' from\na given network in an online manner that encodes main features of the network.\nWe demonstrate this technique and its application to network denoising problems\non real-world network data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:47:28 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:32:44 GMT"}, {"version": "v3", "created": "Sat, 9 Nov 2019 05:52:03 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 01:01:38 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 03:27:15 GMT"}, {"version": "v6", "created": "Sat, 7 Nov 2020 22:41:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Needell", "Deanna", ""], ["Balzano", "Laura", ""]]}, {"id": "1911.01933", "submitter": "Amelia Drew", "authors": "Amelia Drew and Alexander Heinecke", "title": "Training Neural Machine Translation (NMT) Models using Tensor Train\n  Decomposition on TensorFlow (T3F)", "comments": "10 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a Tensor Train layer in the TensorFlow Neural Machine\nTranslation (NMT) model using the t3f library. We perform training runs on the\nIWSLT English-Vietnamese '15 and WMT German-English '16 datasets with learning\nrates $\\in \\{0.0004,0.0008,0.0012\\}$, maximum ranks $\\in \\{2,4,8,16\\}$ and a\nrange of core dimensions. We compare against a target BLEU test score of 24.0,\nobtained by our benchmark run. For the IWSLT English-Vietnamese training, we\nobtain BLEU test/dev scores of 24.0/21.9 and 24.2/21.9 using core dimensions\n$(2, 2, 256) \\times (2, 2, 512)$ with learning rate 0.0012 and rank\ndistributions $(1,4,4,1)$ and $(1,4,16,1)$ respectively. These runs use 113\\%\nand 397\\% of the flops of the benchmark run respectively. We find that, of the\nparameters surveyed, a higher learning rate and more `rectangular' core\ndimensions generally produce higher BLEU scores. For the WMT German-English\ndataset, we obtain BLEU scores of 24.0/23.8 using core dimensions $(4, 4, 128)\n\\times (4, 4, 256)$ with learning rate 0.0012 and rank distribution\n$(1,2,2,1)$. We discuss the potential for future optimization and application\nof Tensor Train decomposition to other NMT models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:48:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Drew", "Amelia", ""], ["Heinecke", "Alexander", ""]]}, {"id": "1911.01944", "submitter": "Yaniv Shulman", "authors": "Yaniv Shulman", "title": "Dynamic Time Warp Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where dealing with temporal sequences it is fair to assume that the same kind\nof deformations that motivated the development of the Dynamic Time Warp\nalgorithm could be relevant also in the calculation of the dot product\n(\"convolution\") in a 1-D convolution layer. In this work a method is proposed\nfor aligning the convolution filter and the input where they are locally out of\nphase utilising an algorithm similar to the Dynamic Time Warp. The proposed\nmethod enables embedding a non-parametric warping of temporal sequences for\nincreasing similarity directly in deep networks and can expand on the\ngeneralisation capabilities and the capacity of standard 1-D convolution layer\nwhere local sequential deformations are present in the input. Experimental\nresults demonstrate the proposed method exceeds or matches the standard 1-D\nconvolution layer in terms of the maximum accuracy achieved on a number of time\nseries classification tasks. In addition the impact of different\nhyperparameters settings is investigated given different datasets and the\nresults support the conclusions of previous work done in relation to the choice\nof DTW parameter values. The proposed layer can be freely integrated with other\ntypical layers to compose deep artificial neural networks of an arbitrary\narchitecture that are trained using standard stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:08:02 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shulman", "Yaniv", ""]]}, {"id": "1911.02007", "submitter": "Hongjia Li", "authors": "Hongjia Li, Sheng Lin, Ning Liu, Caiwen Ding, and Yanzhi Wang", "title": "Deep Compressed Pneumonia Detection for Low-Power Embedded Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been expanded into medical fields and\ntriggered the revolution of some medical applications by extracting complex\nfeatures and achieving high accuracy and performance, etc. On the contrast, the\nlarge-scale network brings high requirements of both memory storage and\ncomputation resource, especially for portable medical devices and other\nembedded systems. In this work, we first train a DNN for pneumonia detection\nusing the dataset provided by RSNA Pneumonia Detection Challenge. To overcome\nhardware limitation for implementing large-scale networks, we develop a\nsystematic structured weight pruning method with filter sparsity, column\nsparsity and combined sparsity. Experiments show that we can achieve up to 36x\ncompression ratio compared to the original model with 106 layers, while\nmaintaining no accuracy degradation. We evaluate the proposed methods on an\nembedded low-power device, Jetson TX2, and achieve low power usage and high\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:05:40 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Li", "Hongjia", ""], ["Lin", "Sheng", ""], ["Liu", "Ning", ""], ["Ding", "Caiwen", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1911.02008", "submitter": "Yang-Hui He", "authors": "Laura Alessandretti, Andrea Baronchelli, Yang-Hui He", "title": "Machine Learning meets Number Theory: The Data Science of\n  Birch-Swinnerton-Dyer", "comments": "40 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical analysis is often the first step towards the birth of a conjecture.\nThis is the case of the Birch-Swinnerton-Dyer (BSD) Conjecture describing the\nrational points on an elliptic curve, one of the most celebrated unsolved\nproblems in mathematics. Here we extend the original empirical approach, to the\nanalysis of the Cremona database of quantities relevant to BSD, inspecting more\nthan 2.5 million elliptic curves by means of the latest techniques in data\nscience, machine-learning and topological data analysis. Key quantities such as\nrank, Weierstrass coefficients, period, conductor, Tamagawa number, regulator\nand order of the Tate-Shafarevich group give rise to a high-dimensional\npoint-cloud whose statistical properties we investigate. We reveal patterns and\ndistributions in the rank versus Weierstrass coefficients, as well as the Beta\ndistribution of the BSD ratio of the quantities. Via gradient boosted trees,\nmachine learning is applied in finding inter-correlation amongst the various\nquantities. We anticipate that our approach will spark further research on the\nstatistical properties of large datasets in Number Theory and more in general\nin pure Mathematics.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 21:52:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Alessandretti", "Laura", ""], ["Baronchelli", "Andrea", ""], ["He", "Yang-Hui", ""]]}, {"id": "1911.02010", "submitter": "Ping Li", "authors": "Fan Zhou and Ping Li", "title": "A Fourier Analytical Approach to Estimation of Smooth Functions in\n  Gaussian Shift Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathbf{x}_j = \\mathbf{\\theta} + \\mathbf{\\epsilon}_j$, $j=1,\\dots,n$ be\ni.i.d. copies of a Gaussian random vector\n$\\mathbf{x}\\sim\\mathcal{N}(\\mathbf{\\theta},\\mathbf{\\Sigma})$ with unknown mean\n$\\mathbf{\\theta} \\in \\mathbb{R}^d$ and unknown covariance matrix\n$\\mathbf{\\Sigma}\\in \\mathbb{R}^{d\\times d}$. The goal of this article is to\nstudy the estimation of $f(\\mathbf{\\theta})$ where $f$ is a given smooth\nfunction of which smoothness is characterized by a Besov-type norm. The problem\nof interest resides in the high dimensional regime where the intrinsic\ndimension can grow with the sample size $n$. Inspired by the classical work of\nA. N. Kolmogorov on unbiased estimation and Littlewood-Paley theory, we develop\na new estimator based on a Fourier analytical approach that achieves effective\nbias reduction. Asymptotic normality and efficiency are proved when the\nsmoothness index of $f$ is above certain threshold which was discovered\nrecently by Koltchinskii et. al. (2018) for a H\\\"{o}lder type class. Numerical\nsimulations are presented to validate our analysis. The simplicity of\nimplementation and its superiority over the plug-in approach indicate the new\nestimator can be applied to a broad range of real world applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:16:24 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 05:50:56 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Zhou", "Fan", ""], ["Li", "Ping", ""]]}, {"id": "1911.02014", "submitter": "Zhanghexuan Ji", "authors": "Zhanghexuan Ji, Yan Shen, Chunwei Ma, Mingchen Gao", "title": "Scribble-based Hierarchical Weakly Supervised Learning for Brain Tumor\n  Segmentation", "comments": "22nd International Conference on Medical Image Computing and Computer\n  Assisted Intervention (MICCAI 2019) Accept", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent state-of-the-art deep learning methods have significantly improved\nbrain tumor segmentation. However, fully supervised training requires a large\namount of manually labeled masks, which is highly time-consuming and needs\ndomain expertise. Weakly supervised learning with scribbles provides a good\ntrade-off between model accuracy and the effort of manual labeling. However,\nfor segmenting the hierarchical brain tumor structures, manually labeling\nscribbles for each substructure could still be demanding. In this paper, we use\nonly two kinds of weak labels, i.e., scribbles on whole tumor and healthy brain\ntissue, and global labels for the presence of each substructure, to train a\ndeep learning model to segment all the sub-regions. Specifically, we train two\nnetworks in two phases: first, we only use whole tumor scribbles to train a\nwhole tumor (WT) segmentation network, which roughly recovers the WT mask of\ntraining data; then we cluster the WT region with the guide of global labels.\nThe rough substructure segmentation from clustering is used as weak labels to\ntrain the second network. The dense CRF loss is used to refine the weakly\nsupervised segmentation. We evaluate our approach on the BraTS2017 dataset and\nachieve competitive WT dice score as well as comparable scores on substructure\nsegmentation compared to an upper bound when trained with fully annotated\nmasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:56:35 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ji", "Zhanghexuan", ""], ["Shen", "Yan", ""], ["Ma", "Chunwei", ""], ["Gao", "Mingchen", ""]]}, {"id": "1911.02029", "submitter": "Yifan Cui", "authors": "Yifan Cui and Eric Tchetgen Tchetgen", "title": "Selective machine learning of doubly robust functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While model selection is a well-studied topic in parametric and nonparametric\nregression or density estimation, selection of possibly high-dimensional\nnuisance parameters in semiparametric problems is far less developed. In this\npaper, we propose a selective machine learning framework for making inferences\nabout a finite-dimensional functional defined on a semiparametric model, when\nthe latter admits a doubly robust estimating function and several candidate\nmachine learning algorithms are available for estimating the nuisance\nparameters. We introduce two new selection criteria for bias reduction in\nestimating the functional of interest, each based on a novel definition of\npseudo-risk for the functional that embodies the double robustness property and\nthus is used to select the pair of learners that is nearest to fulfilling this\nproperty. We establish an oracle property for a multi-fold cross-validation\nversion of the new selection criteria which states that our empirical criteria\nperform nearly as well as an oracle with a priori knowledge of the pseudo-risk\nfor each pair of candidate learners. We also describe a smooth approximation to\nthe selection criteria which allows for valid post-selection inference.\nFinally, we apply the approach to model selection of a semiparametric estimator\nof average treatment effect given an ensemble of candidate machine learners to\naccount for confounding in an observational study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:00:03 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 03:35:30 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 17:49:49 GMT"}, {"version": "v4", "created": "Mon, 3 Aug 2020 18:43:09 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 17:10:30 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Cui", "Yifan", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "1911.02035", "submitter": "Sitan Chen", "authors": "Sitan Chen, Jerry Li, Ankur Moitra", "title": "Efficiently Learning Structured Distributions from Untrusted Batches", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem, introduced by Qiao and Valiant, of learning from\nuntrusted batches. Here, we assume $m$ users, all of whom have samples from\nsome underlying distribution $p$ over $1, \\ldots, n$. Each user sends a batch\nof $k$ i.i.d. samples from this distribution; however an $\\epsilon$-fraction of\nusers are untrustworthy and can send adversarially chosen responses. The goal\nis then to learn $p$ in total variation distance. When $k = 1$ this is the\nstandard robust univariate density estimation setting and it is well-understood\nthat $\\Omega (\\epsilon)$ error is unavoidable. Suprisingly, Qiao and Valiant\ngave an estimator which improves upon this rate when $k$ is large.\nUnfortunately, their algorithms run in time exponential in either $n$ or $k$.\n  We first give a sequence of polynomial time algorithms whose estimation error\napproaches the information-theoretically optimal bound for this problem. Our\napproach is based on recent algorithms derived from the sum-of-squares\nhierarchy, in the context of high-dimensional robust estimation. We show that\nalgorithms for learning from untrusted batches can also be cast in this\nframework, but by working with a more complicated set of test functions.\n  It turns out this abstraction is quite powerful and can be generalized to\nincorporate additional problem specific constraints. Our second and main result\nis to show that this technology can be leveraged to build in prior knowledge\nabout the shape of the distribution. Crucially, this allows us to reduce the\nsample complexity of learning from untrusted batches to polylogarithmic in $n$\nfor most natural classes of distributions, which is important in many\napplications. To do so, we demonstrate that these sum-of-squares algorithms for\nrobust mean estimation can be made to handle complex combinatorial constraints\n(e.g. those arising from VC theory), which may be of independent technical\ninterest.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:01:46 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Jerry", ""], ["Moitra", "Ankur", ""]]}, {"id": "1911.02042", "submitter": "Thai Le", "authors": "Thai Le, Suhang Wang, Dongwon Lee", "title": "GRACE: Generating Concise and Informative Contrastive Sample to Explain\n  Neural Network Model's Prediction", "comments": "Accepted at the 26th SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent development in the topic of explainable AI/ML for image\nand text data, the majority of current solutions are not suitable to explain\nthe prediction of neural network models when the datasets are tabular and their\nfeatures are in high-dimensional vectorized formats. To mitigate this\nlimitation, therefore, we borrow two notable ideas (i.e., \"explanation by\nintervention\" from causality and \"explanation are contrastive\" from philosophy)\nand propose a novel solution, named as GRACE, that better explains neural\nnetwork models' predictions for tabular datasets. In particular, given a\nmodel's prediction as label X, GRACE intervenes and generates a\nminimally-modified contrastive sample to be classified as Y, with an intuitive\ntextual explanation, answering the question of \"Why X rather than Y?\" We carry\nout comprehensive experiments using eleven public datasets of different scales\nand domains (e.g., # of features ranges from 5 to 216) and compare GRACE with\ncompeting baselines on different measures: fidelity, conciseness, info-gain,\nand influence. The user-studies show that our generated explanation is not only\nmore intuitive and easy-to-understand but also facilitates end-users to make as\nmuch as 60% more accurate post-explanation decisions than that of Lime.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:06:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 15:08:19 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 17:49:01 GMT"}, {"version": "v4", "created": "Sun, 27 Sep 2020 10:17:36 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 11:43:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Le", "Thai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""]]}, {"id": "1911.02048", "submitter": "Pavel Sulimov Mr", "authors": "Pavel Sulimov, Elena Sukmanova, Roman Chereshnev, and Attila\n  Kertesz-Farkas", "title": "Guided Layer-wise Learning for Deep Models using Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of deep models for classification tasks is hindered by local minima\nproblems and vanishing gradients, while unsupervised layer-wise pretraining\ndoes not exploit information from class labels. Here, we propose a new\nregularization technique, called diversifying regularization (DR), which\napplies a penalty on hidden units at any layer if they obtain similar features\nfor different types of data. For generative models, DR is defined as divergence\nover the variational posteriori distributions and included in the maximum\nlikelihood estimation as a prior. Thus, DR includes class label information for\ngreedy pretraining of deep belief networks which result in a better weight\ninitialization for fine-tuning methods. On the other hand, for discriminative\ntraining of deep neural networks, DR is defined as a distance over the features\nand included in the learning objective. With our experimental tests, we show\nthat DR can help the backpropagation to cope with vanishing gradient problems\nand to provide faster convergence and smaller generalization errors.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:27:16 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Sulimov", "Pavel", ""], ["Sukmanova", "Elena", ""], ["Chereshnev", "Roman", ""], ["Kertesz-Farkas", "Attila", ""]]}, {"id": "1911.02052", "submitter": "Zhisheng Xiao", "authors": "Zhisheng Xiao, Qing Yan, Yali Amit", "title": "A Method to Model Conditional Distributions with Normalizing Flows", "comments": "10 pages. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the use of normalizing flows to model\nconditional distributions. In particular, we use our proposed method to analyze\ninverse problems with invertible neural networks by maximizing the posterior\nlikelihood. Our method uses only a single loss and is easy to train. This is an\nimprovement on the previous method that solves similar inverse problems with\ninvertible neural networks but which involves a combination of several loss\nterms with ad-hoc weighting. In addition, our method provides a natural\nframework to incorporate conditioning in normalizing flows, and therefore, we\ncan train an invertible network to perform conditional generation. We analyze\nour method and perform a careful comparison with previous approaches. Simple\nexperiments show the effectiveness of our method, and more comprehensive\nexperimental evaluations are undergoing.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:37:37 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Xiao", "Zhisheng", ""], ["Yan", "Qing", ""], ["Amit", "Yali", ""]]}, {"id": "1911.02053", "submitter": "Sebastian Claici", "authors": "Pierre Monteiller, Sebastian Claici, Edward Chien, Farzaneh\n  Mirzazadeh, Justin Solomon, Mikhail Yurochkin", "title": "Alleviating Label Switching with Optimal Transport", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label switching is a phenomenon arising in mixture model posterior inference\nthat prevents one from meaningfully assessing posterior statistics using\nstandard Monte Carlo procedures. This issue arises due to invariance of the\nposterior under actions of a group; for example, permuting the ordering of\nmixture components has no effect on the likelihood. We propose a resolution to\nlabel switching that leverages machinery from optimal transport. Our algorithm\nefficiently computes posterior statistics in the quotient space of the symmetry\ngroup. We give conditions under which there is a meaningful solution to label\nswitching and demonstrate advantages over alternative approaches on simulated\nand real data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:40:27 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 20:34:57 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Monteiller", "Pierre", ""], ["Claici", "Sebastian", ""], ["Chien", "Edward", ""], ["Mirzazadeh", "Farzaneh", ""], ["Solomon", "Justin", ""], ["Yurochkin", "Mikhail", ""]]}, {"id": "1911.02067", "submitter": "Humoud Alsabah", "authors": "Humoud Alsabah, Agostino Capponi, Octavio Ruiz Lacedelli, and Matt\n  Stern", "title": "Robo-advising: Learning Investors' Risk Preferences via Portfolio\n  Choices", "comments": null, "journal-ref": null, "doi": "10.1093/jjfinec/nbz040", "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a reinforcement learning framework for retail robo-advising. The\nrobo-advisor does not know the investor's risk preference, but learns it over\ntime by observing her portfolio choices in different market environments. We\ndevelop an exploration-exploitation algorithm which trades off costly\nsolicitations of portfolio choices by the investor with autonomous trading\ndecisions based on stale estimates of investor's risk aversion. We show that\nthe algorithm's value function converges to the optimal value function of an\nomniscient robo-advisor over a number of periods that is polynomial in the\nstate and action space. By correcting for the investor's mistakes, the\nrobo-advisor may outperform a stand-alone investor, regardless of the\ninvestor's opportunity cost for making portfolio decisions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:08:43 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 16:56:03 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Alsabah", "Humoud", ""], ["Capponi", "Agostino", ""], ["Lacedelli", "Octavio Ruiz", ""], ["Stern", "Matt", ""]]}, {"id": "1911.02069", "submitter": "Alper Ahmeto\\u{g}lu", "authors": "Alper Ahmeto\\u{g}lu and Ethem Alpayd{\\i}n", "title": "Hierarchical Mixtures of Generators for Adversarial Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9413249", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are deep neural networks that allow us\nto sample from an arbitrary probability distribution without explicitly\nestimating the distribution. There is a generator that takes a latent vector as\ninput and transforms it into a valid sample from the distribution. There is\nalso a discriminator that is trained to discriminate such fake samples from\ntrue samples of the distribution; at the same time, the generator is trained to\ngenerate fakes that the discriminator cannot tell apart from the true samples.\nInstead of learning a global generator, a recent approach involves training\nmultiple generators each responsible from one part of the distribution. In this\nwork, we review such approaches and propose the hierarchical mixture of\ngenerators, inspired from the hierarchical mixture of experts model, that\nlearns a tree structure implementing a hierarchical clustering with soft splits\nin the decision nodes and local generators in the leaves. Since the generators\nare combined softly, the whole model is continuous and can be trained using\ngradient-based optimization, just like the original GAN model. Our experiments\non five image data sets, namely, MNIST, FashionMNIST, UTZap50K, Oxford Flowers,\nand CelebA, show that our proposed model generates samples of high quality and\ndiversity in terms of popular GAN evaluation metrics. The learned hierarchical\nstructure also leads to knowledge extraction.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:13:31 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ahmeto\u011flu", "Alper", ""], ["Alpayd\u0131n", "Ethem", ""]]}, {"id": "1911.02074", "submitter": "Kunal Talwar", "authors": "Kunal Talwar", "title": "Computational Separations between Sampling and Optimization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two commonly arising computational tasks in Bayesian learning are\nOptimization (Maximum A Posteriori estimation) and Sampling (from the posterior\ndistribution). In the convex case these two problems are efficiently reducible\nto each other. Recent work (Ma et al. 2019) shows that in the non-convex case,\nsampling can sometimes be provably faster. We present a simpler and stronger\nseparation. We then compare sampling and optimization in more detail and show\nthat they are provably incomparable: there are families of continuous functions\nfor which optimization is easy but sampling is NP-hard, and vice versa.\nFurther, we show function families that exhibit a sharp phase transition in the\ncomputational complexity of sampling, as one varies the natural temperature\nparameter. Our results draw on a connection to analogous separations in the\ndiscrete setting which are well-studied.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:29:20 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Talwar", "Kunal", ""]]}, {"id": "1911.02079", "submitter": "Hui Guan", "authors": "Hui Guan, Andrey Malevich, Jiyan Yang, Jongsoo Park, Hector Yuen", "title": "Post-Training 4-bit Quantization on Embedding Tables", "comments": "Accepted in MLSys@NeurIPS'19 (http://learningsys.org/neurips19/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous representations have been widely adopted in recommender systems\nwhere a large number of entities are represented using embedding vectors. As\nthe cardinality of the entities increases, the embedding components can easily\ncontain millions of parameters and become the bottleneck in both storage and\ninference due to large memory consumption. This work focuses on post-training\n4-bit quantization on the continuous embeddings. We propose row-wise uniform\nquantization with greedy search and codebook-based quantization that\nconsistently outperforms state-of-the-art quantization approaches on reducing\naccuracy degradation. We deploy our uniform quantization technique on a\nproduction model in Facebook and demonstrate that it can reduce the model size\nto only 13.89% of the single-precision version while the model quality stays\nneutral.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:43:51 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guan", "Hui", ""], ["Malevich", "Andrey", ""], ["Yang", "Jiyan", ""], ["Park", "Jongsoo", ""], ["Yuen", "Hector", ""]]}, {"id": "1911.02088", "submitter": "Gregory Meyer", "authors": "Gregory P. Meyer", "title": "An Alternative Probabilistic Interpretation of the Huber Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Huber loss is a robust loss function used for a wide range of regression\ntasks. To utilize the Huber loss, a parameter that controls the transitions\nfrom a quadratic function to an absolute value function needs to be selected.\nWe believe the standard probabilistic interpretation that relates the Huber\nloss to the Huber density fails to provide adequate intuition for identifying\nthe transition point. As a result, a hyper-parameter search is often necessary\nto determine an appropriate value. In this work, we propose an alternative\nprobabilistic interpretation of the Huber loss, which relates minimizing the\nloss to minimizing an upper-bound on the Kullback-Leibler divergence between\nLaplace distributions, where one distribution represents the noise in the\nground-truth and the other represents the noise in the prediction. In addition,\nwe show that the parameters of the Laplace distributions are directly related\nto the transition point of the Huber loss. We demonstrate, through a toy\nproblem, that the optimal transition point of the Huber loss is closely related\nto the distribution of the noise in the ground-truth data. As a result, our\ninterpretation provides an intuitive way to identify well-suited\nhyper-parameters by approximating the amount of noise in the data, which we\ndemonstrate through a case study and experimentation on the Faster R-CNN and\nRetinaNet object detectors.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:15:19 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 19:23:10 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 19:27:22 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Meyer", "Gregory P.", ""]]}, {"id": "1911.02098", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Ogheneuriri Oderhohwo and Syed Rafay Hasan", "title": "A Scalable Multilabel Classification to Deploy Deep Learning\n  Architectures For Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Networks (CNN) have performed well in many applications\nsuch as object detection, pattern recognition, video surveillance and so on.\nCNN carryout feature extraction on labelled data to perform classification.\nMulti-label classification assigns more than one label to a particular data\nsample in a data set. In multi-label classification, properties of a data point\nthat are considered to be mutually exclusive are classified. However, existing\nmulti-label classification requires some form of data pre-processing that\ninvolves image training data cropping or image tiling. The computation and\nmemory requirement of these multi-label CNN models makes their deployment on\nedge devices challenging. In this paper, we propose a methodology that solves\nthis problem by extending the capability of existing multi-label classification\nand provide models with lower latency that requires smaller memory size when\ndeployed on edge devices. We make use of a single CNN model designed with\nmultiple loss layers and multiple accuracy layers. This methodology is tested\non state-of-the-art deep learning algorithms such as AlexNet, GoogleNet and\nSqueezeNet using the Stanford Cars Dataset and deployed on Raspberry Pi3. From\nthe results the proposed methodology achieves comparable accuracy with 1.8x\nless MACC operation, 0.97x reduction in latency and 0.5x, 0.84x and 0.97x\nreduction in size for the generated AlexNet, GoogleNet and SqueezeNet CNN\nmodels respectively when compared to conventional ways of achieving multi-label\nclassification like hard-coding multi-label instances into single labels. The\nmethodology also yields CNN models that achieve 50\\% less MACC operations, 50%\nreduction in latency and size of generated versions of AlexNet, GoogleNet and\nSqueezeNet respectively when compared to conventional ways using 2 different\nsingle-labelled models to achieve multi-label classification.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:45:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 04:35:51 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 15:14:13 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Oderhohwo", "Ogheneuriri", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.02106", "submitter": "Peter Tonner", "authors": "Peter D. Tonner, Daniel V. Samarov, A. Gilad Kusne", "title": "Designing over uncertain outcomes with stochastic sampling Bayesian\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is becoming increasingly common in scientific and engineering\ndomains. Oftentimes, these problems involve various levels of stochasticity or\nuncertainty in generating proposed solutions. Therefore, optimization in these\nscenarios must consider this stochasticity to properly guide the design of\nfuture experiments. Here, we adapt Bayesian optimization to handle uncertain\noutcomes, proposing a new framework called stochastic sampling Bayesian\noptimization (SSBO). We show that the bounds on expected regret for an upper\nconfidence bound search in SSBO resemble those of earlier Bayesian optimization\napproaches, with added penalties due to the stochastic generation of inputs.\nAdditionally, we adapt existing batch optimization techniques to properly limit\nthe myopic decision making that can arise when selecting multiple instances\nbefore feedback. Finally, we show that SSBO techniques properly optimize a set\nof standard optimization problems as well as an applied problem inspired by\nbioengineering.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:21:07 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 21:55:42 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Tonner", "Peter D.", ""], ["Samarov", "Daniel V.", ""], ["Kusne", "A. Gilad", ""]]}, {"id": "1911.02109", "submitter": "Jingshuang Chen", "authors": "Zhiqiang Cai, Jingshuang Chen, Min Liu, Xinyu Liu", "title": "Deep least-squares methods: an unsupervised learning-based numerical\n  method for solving elliptic PDEs", "comments": "15 pages, 6 figures, 5 tables, accepted by Journal of Computational\n  Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109707", "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an unsupervised deep learning-based numerical approach for\nsolving partial differential equations (PDEs). The approach makes use of the\ndeep neural network to approximate solutions of PDEs through the compositional\nconstruction and employs least-squares functionals as loss functions to\ndetermine parameters of the deep neural network. There are various\nleast-squares functionals for a partial differential equation. This paper\nfocuses on the so-called first-order system least-squares (FOSLS) functional\nstudied in [3], which is based on a first-order system of scalar second-order\nelliptic PDEs. Numerical results for second-order elliptic PDEs in one\ndimension are presented.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:24:06 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 18:42:28 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 16:56:33 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Cai", "Zhiqiang", ""], ["Chen", "Jingshuang", ""], ["Liu", "Min", ""], ["Liu", "Xinyu", ""]]}, {"id": "1911.02121", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Teresa Tsang, Purang Abolmaesumi", "title": "GAN-enhanced Conditional Echocardiogram Generation", "comments": "Workshop of Medical Imaging Meets NeurIPS, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echocardiography (echo) is a common means of evaluating cardiac conditions.\nDue to the label scarcity, semi-supervised paradigms in automated echo analysis\nare getting traction. One of the most sought-after problems in echo is the\nsegmentation of cardiac structures (e.g. chambers). Accordingly, we propose an\nechocardiogram generation approach using generative adversarial networks with a\nconditional patch-based discriminator. In this work, we validate the\nfeasibility of GAN-enhanced echo generation with different conditions\n(segmentation masks), namely, the left ventricle, ventricular myocardium, and\natrium. Results show that the proposed adversarial algorithm can generate\nhigh-quality echo frames whose cardiac structures match the given segmentation\nmasks. This method is expected to facilitate the training of other machine\nlearning models in a semi-supervised fashion as suggested in similar\nresearches.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:49:25 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 21:37:19 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Abdi", "Amir H.", ""], ["Tsang", "Teresa", ""], ["Abolmaesumi", "Purang", ""]]}, {"id": "1911.02140", "submitter": "Derek Yang", "authors": "Derek Yang, Li Zhao, Zichuan Lin, Tao Qin, Jiang Bian, Tieyan Liu", "title": "Fully Parameterized Quantile Function for Distributional Reinforcement\n  Learning", "comments": "NeurIPS 2019. Code at https://github.com/microsoft/FQF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional Reinforcement Learning (RL) differs from traditional RL in\nthat, rather than the expectation of total returns, it estimates distributions\nand has achieved state-of-the-art performance on Atari Games. The key challenge\nin practical distributional RL algorithms lies in how to parameterize estimated\ndistributions so as to better approximate the true continuous distribution.\nExisting distributional RL algorithms parameterize either the probability side\nor the return value side of the distribution function, leaving the other side\nuniformly fixed as in C51, QR-DQN or randomly sampled as in IQN. In this paper,\nwe propose fully parameterized quantile function that parameterizes both the\nquantile fraction axis (i.e., the x-axis) and the value axis (i.e., y-axis) for\ndistributional RL. Our algorithm contains a fraction proposal network that\ngenerates a discrete set of quantile fractions and a quantile value network\nthat gives corresponding quantile values. The two networks are jointly trained\nto find the best approximation of the true distribution. Experiments on 55\nAtari Games show that our algorithm significantly outperforms existing\ndistributional RL algorithms and creates a new record for the Atari Learning\nEnvironment for non-distributed agents.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:38:57 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:48:25 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 09:13:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Derek", ""], ["Zhao", "Li", ""], ["Lin", "Zichuan", ""], ["Qin", "Tao", ""], ["Bian", "Jiang", ""], ["Liu", "Tieyan", ""]]}, {"id": "1911.02151", "submitter": "Mahdi Haghifam", "authors": "Jeffrey Negrea, Mahdi Haghifam, Gintare Karolina Dziugaite, Ashish\n  Khisti, Daniel M. Roy", "title": "Information-Theoretic Generalization Bounds for SGLD via Data-Dependent\n  Estimates", "comments": "23 pages, 1 figure. To appear in, Advances in Neural Information\n  Processing Systems (33), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we improve upon the stepwise analysis of noisy iterative\nlearning algorithms initiated by Pensia, Jog, and Loh (2018) and recently\nextended by Bu, Zou, and Veeravalli (2019). Our main contributions are\nsignificantly improved mutual information bounds for Stochastic Gradient\nLangevin Dynamics via data-dependent estimates. Our approach is based on the\nvariational characterization of mutual information and the use of\ndata-dependent priors that forecast the mini-batch gradient based on a subset\nof the training samples. Our approach is broadly applicable within the\ninformation-theoretic framework of Russo and Zou (2015) and Xu and Raginsky\n(2017). Our bound can be tied to a measure of flatness of the empirical risk\nsurface. As compared with other bounds that depend on the squared norms of\ngradients, empirical investigations show that the terms in our bounds are\norders of magnitude smaller.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:28:33 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:01:39 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 20:43:31 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Negrea", "Jeffrey", ""], ["Haghifam", "Mahdi", ""], ["Dziugaite", "Gintare Karolina", ""], ["Khisti", "Ashish", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1911.02155", "submitter": "James Murphy", "authors": "James M. Murphy", "title": "Spatially regularized active diffusion learning for high-dimensional\n  images", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active learning algorithm for the classification of high-dimensional\nimages is proposed in which spatially-regularized nonlinear diffusion geometry\nis used to characterize cluster cores. The proposed method samples from\nestimated cluster cores in order to generate a small but potent set of training\nlabels which propagate to the remainder of the dataset via the underlying\ndiffusion process. By spatially regularizing the rich, high-dimensional\nspectral information of the image to efficiently estimate the most significant\nand influential points in the data, our approach avoids redundancy in the\ntraining dataset. This allows it to produce high-accuracy labelings with a very\nsmall number of training labels. The proposed algorithm admits an efficient\nnumerical implementation that scales essentially linearly in the number of data\npoints under a suitable data model and enjoys state-of-the-art performance on\nreal hyperspectral images.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:58:24 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Murphy", "James M.", ""]]}, {"id": "1911.02156", "submitter": "Ahmadreza Moradipari", "authors": "Ahmadreza Moradipari, Sanae Amani, Mahnoosh Alizadeh, Christos\n  Thrampoulidis", "title": "Safe Linear Thompson Sampling with Side Information", "comments": "Comparing with safe versions of linear UCB algorithms, Providing more\n  intuition for proof sketch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and performance analysis of bandit algorithms in the presence of\nstage-wise safety or reliability constraints has recently garnered significant\ninterest. In this work, we consider the linear stochastic bandit problem under\nadditional \\textit{linear safety constraints} that need to be satisfied at each\nround. We provide a new safe algorithm based on linear Thompson Sampling (TS)\nfor this problem and show a frequentist regret of order $\\mathcal{O}\n(d^{3/2}\\log^{1/2}d \\cdot T^{1/2}\\log^{3/2}T)$, which remarkably matches the\nresults provided by (Abeille et al., 2017) for the standard linear TS algorithm\nin the absence of safety constraints. We compare the performance of our\nalgorithm with UCB-based safe algorithms and highlight how the inherently\nrandomized nature of TS leads to a superior performance in expanding the set of\nsafe actions the algorithm has access to at each round.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:59:20 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:13:37 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Moradipari", "Ahmadreza", ""], ["Amani", "Sanae", ""], ["Alizadeh", "Mahnoosh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1911.02161", "submitter": "Chuyang Ke", "authors": "Chuyang Ke, Jean Honorio", "title": "Exact Partitioning of High-order Models with a Novel Convex Tensor Cone\n  Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm for exact partitioning of high-order\nmodels. We define a general class of $m$-degree Homogeneous Polynomial Models,\nwhich subsumes several examples motivated from prior literature. Exact\npartitioning can be formulated as a tensor optimization problem. We relax this\nhigh-order combinatorial problem to a convex conic form problem. To this end,\nwe carefully define the Carath\\'eodory symmetric tensor cone, and show its\nconvexity, and the convexity of its dual cone. This allows us to construct a\nprimal-dual certificate to show that the solution of the convex relaxation is\ncorrect (equal to the unobserved true group assignment) and to analyze the\nstatistical upper bound of exact partitioning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 01:52:05 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 17:21:46 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "1911.02171", "submitter": "Xin Xing", "authors": "Xin Xing, Zuofeng Shang, Pang Du, Ping Ma, Wenxuan Zhong and Jun S.\n  Liu", "title": "Minimax Nonparametric Two-sample Test under Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of comparing probability densities between two\ngroups. A new probabilistic tensor product smoothing spline framework is\ndeveloped to model the joint density of two variables. Under such a framework,\nthe probability density comparison is equivalent to testing the\npresence/absence of interactions. We propose a penalized likelihood ratio test\nfor such interaction testing and show that the test statistic is asymptotically\nchi-square distributed under the null hypothesis. Furthermore, we derive a\nsharp minimax testing rate based on the Bernstein width for nonparametric\ntwo-sample tests and show that our proposed test statistics is minimax optimal.\nIn addition, a data-adaptive tuning criterion is developed to choose the\npenalty parameter. Simulations and real applications demonstrate that the\nproposed test outperforms the conventional approaches under various scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:40:35 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 23:05:21 GMT"}, {"version": "v3", "created": "Sun, 5 Jan 2020 19:57:41 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 19:34:53 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Xing", "Xin", ""], ["Shang", "Zuofeng", ""], ["Du", "Pang", ""], ["Ma", "Ping", ""], ["Zhong", "Wenxuan", ""], ["Liu", "Jun S.", ""]]}, {"id": "1911.02175", "submitter": "Robert Osazuwa Ness", "authors": "Robert Osazuwa Ness, Kaushal Paneri, and Olga Vitek", "title": "Integrating Markov processes with structural causal modeling enables\n  counterfactual inference in complex systems", "comments": "Accepted to Thirty-third Conference on Neural Information Processing\n  Systems (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.MN stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This manuscript contributes a general and practical framework for casting a\nMarkov process model of a system at equilibrium as a structural causal model,\nand carrying out counterfactual inference. Markov processes mathematically\ndescribe the mechanisms in the system, and predict the system's equilibrium\nbehavior upon intervention, but do not support counterfactual inference. In\ncontrast, structural causal models support counterfactual inference, but do not\nidentify the mechanisms. This manuscript leverages the benefits of both\napproaches. We define the structural causal models in terms of the parameters\nand the equilibrium dynamics of the Markov process models, and counterfactual\ninference flows from these settings. The proposed approach alleviates the\nidentifiability drawback of the structural causal models, in that the\ncounterfactual inference is consistent with the counterfactual trajectories\nsimulated from the Markov process model. We showcase the benefits of this\nframework in case studies of complex biomolecular systems with nonlinear\ndynamics. We illustrate that, in presence of Markov process model\nmisspecification, counterfactual inference leverages prior data, and therefore\nestimates the outcome of an intervention more accurately than a direct\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:01:45 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ness", "Robert Osazuwa", ""], ["Paneri", "Kaushal", ""], ["Vitek", "Olga", ""]]}, {"id": "1911.02182", "submitter": "Gordon Wichern", "authors": "Fatemeh Pishdadian, Gordon Wichern, Jonathan Le Roux", "title": "Finding Strength in Weakness: Learning to Separate Sounds with Weak\n  Supervision", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing vol\n  28 (2020) 2386-2399", "doi": "10.1109/TASLP.2020.3013105", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been much recent progress using deep learning techniques to\nseparate speech and music audio signals, these systems typically require large\ncollections of isolated sources during the training process. When extending\naudio source separation algorithms to more general domains such as\nenvironmental monitoring, it may not be possible to obtain isolated signals for\ntraining. Here, we propose objective functions and network architectures that\nenable training a source separation system with weak labels. In this scenario,\nweak labels are defined in contrast with strong time-frequency (TF) labels such\nas those obtained from isolated sources, and refer either to frame-level weak\nlabels where one only has access to the time periods when different sources are\nactive in an audio mixture, or to clip-level weak labels that only indicate the\npresence or absence of sounds in an entire audio clip. We train a separator\nthat estimates a TF mask for each type of sound event, using a sound event\nclassifier as an assessor of the separator's performance to bridge the gap\nbetween the TF-level separation and the ground truth weak labels only available\nat the frame or clip level. Our objective function requires the classifier\napplied to a separated source to assign high probability to the class\ncorresponding to that source and low probability to all other classes. The\nobjective function also enforces that the separated sources sum up to the\nmixture. We benchmark the performance of our algorithm using synthetic mixtures\nof overlapping events created from a database of sounds recorded in urban\nenvironments. Compared to training a network using isolated sources, our model\nachieves somewhat lower but still significant SI-SDR improvement, even in\nscenarios with significant sound event overlap.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:36:55 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:53:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pishdadian", "Fatemeh", ""], ["Wichern", "Gordon", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "1911.02210", "submitter": "Sayandev Mukherjee", "authors": "Sayandev Mukherjee", "title": "Machine Learning using the Variational Predictive Information Bottleneck\n  with a Validation Set", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zellner (1988) modeled statistical inference in terms of information\nprocessing and postulated the Information Conservation Principle (ICP) between\nthe input and output of the information processing block, showing that this\nyielded Bayesian inference as the optimum information processing rule.\nRecently, Alemi (2019) reviewed Zellner's work in the context of machine\nlearning and showed that the ICP could be seen as a special case of a more\ngeneral optimum information processing criterion, namely the Predictive\nInformation Bottleneck Objective. However, Alemi modeled the model training\nstep in machine learning as using training and test data sets only, and did not\naccount for the use of a validation data set during training. The present note\nis an attempt to extend Alemi's information processing formulation of machine\nlearning, and the predictive information bottleneck objective for model\ntraining, to the widely-used scenario where training utilizes not only a\ntraining but also a validation data set.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 05:31:59 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 02:25:37 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Mukherjee", "Sayandev", ""]]}, {"id": "1911.02212", "submitter": "Max Simchowitz", "authors": "Mark Braverman, Elad Hazan, Max Simchowitz, Blake Woodworth", "title": "The gradient complexity of linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational complexity of several basic linear algebra\nprimitives, including largest eigenvector computation and linear regression, in\nthe computational model that allows access to the data via a matrix-vector\nproduct oracle. We show that for polynomial accuracy, $\\Theta(d)$ calls to the\noracle are necessary and sufficient even for a randomized algorithm.\n  Our lower bound is based on a reduction to estimating the least eigenvalue of\na random Wishart matrix. This simple distribution enables a concise proof,\nleveraging a few key properties of the random Wishart ensemble.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 05:45:05 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 01:06:45 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 05:12:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Braverman", "Mark", ""], ["Hazan", "Elad", ""], ["Simchowitz", "Max", ""], ["Woodworth", "Blake", ""]]}, {"id": "1911.02247", "submitter": "Arthur Bra\\v{z}inskas", "authors": "Arthur Bra\\v{z}inskas, Mirella Lapata and Ivan Titov", "title": "Unsupervised Opinion Summarization as Copycat-Review Generation", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization is the task of automatically creating summaries that\nreflect subjective information expressed in multiple documents, such as product\nreviews. While the majority of previous work has focused on the extractive\nsetting, i.e., selecting fragments from input reviews to produce a summary, we\nlet the model generate novel sentences and hence produce abstractive summaries.\nRecent progress in summarization has seen the development of supervised models\nwhich rely on large quantities of document-summary pairs. Since such training\ndata is expensive to acquire, we instead consider the unsupervised setting, in\nother words, we do not use any summaries in training. We define a generative\nmodel for a review collection which capitalizes on the intuition that when\ngenerating a new review given a set of other reviews of a product, we should be\nable to control the \"amount of novelty\" going into the new review or,\nequivalently, vary the extent to which it deviates from the input. At test\ntime, when generating summaries, we force the novelty to be minimal, and\nproduce a text reflecting consensus opinions. We capture this intuition by\ndefining a hierarchical variational autoencoder model. Both individual reviews\nand the products they correspond to are associated with stochastic latent\ncodes, and the review generator (\"decoder\") has direct access to the text of\ninput reviews through the pointer-generator mechanism. Experiments on Amazon\nand Yelp datasets, show that setting at test time the review's latent code to\nits mean, allows the model to produce fluent and coherent summaries reflecting\ncommon opinions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:20:13 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 15:49:31 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Lapata", "Mirella", ""], ["Titov", "Ivan", ""]]}, {"id": "1911.02254", "submitter": "Chaoyue Niu", "authors": "Chaoyue Niu, Fan Wu, Shaojie Tang, Lifeng Hua, Rongfei Jia, Chengfei\n  Lv, Zhihua Wu, and Guihai Chen", "title": "Secure Federated Submodel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning was proposed with an intriguing vision of achieving\ncollaborative machine learning among numerous clients without uploading their\nprivate data to a cloud server. However, the conventional framework requires\neach client to leverage the full model for learning, which can be prohibitively\ninefficient for resource-constrained clients and large-scale deep learning\ntasks. We thus propose a new framework, called federated submodel learning,\nwhere clients download only the needed parts of the full model, namely\nsubmodels, and then upload the submodel updates. Nevertheless, the \"position\"\nof a client's truly required submodel corresponds to her private data, and its\ndisclosure to the cloud server during interactions inevitably breaks the tenet\nof federated learning. To integrate efficiency and privacy, we have designed a\nsecure federated submodel learning scheme coupled with a private set union\nprotocol as a cornerstone. Our secure scheme features the properties of\nrandomized response, secure aggregation, and Bloom filter, and endows each\nclient with a customized plausible deniability, in terms of local differential\nprivacy, against the position of her desired submodel, thus protecting her\nprivate data. We further instantiated our scheme with the e-commerce\nrecommendation scenario in Alibaba, implemented a prototype system, and\nextensively evaluated its performance over 30-day Taobao user data. The\nanalysis and evaluation results demonstrate the feasibility and scalability of\nour scheme from model accuracy and convergency, practical communication,\ncomputation, and storage overheads, as well as manifest its remarkable\nadvantages over the conventional federated learning framework.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:49:23 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:07:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Niu", "Chaoyue", ""], ["Wu", "Fan", ""], ["Tang", "Shaojie", ""], ["Hua", "Lifeng", ""], ["Jia", "Rongfei", ""], ["Lv", "Chengfei", ""], ["Wu", "Zhihua", ""], ["Chen", "Guihai", ""]]}, {"id": "1911.02256", "submitter": "Seyed Kamyar Seyed Ghasemipour", "authors": "Seyed Kamyar Seyed Ghasemipour, Richard Zemel, Shixiang Gu", "title": "A Divergence Minimization Perspective on Imitation Learning Methods", "comments": "Published at Conference on Robot Learning (CoRL) 2019. For datasets\n  and reproducing results please refer to\n  https://github.com/KamyarGh/rl_swiss/blob/master/reproducing/fmax_paper.md", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, it is desirable to learn decision-making and control\npolicies through learning or bootstrapping from expert demonstrations. The most\ncommon approaches under this Imitation Learning (IL) framework are Behavioural\nCloning (BC), and Inverse Reinforcement Learning (IRL). Recent methods for IRL\nhave demonstrated the capacity to learn effective policies with access to a\nvery limited set of demonstrations, a scenario in which BC methods often fail.\nUnfortunately, due to multiple factors of variation, directly comparing these\nmethods does not provide adequate intuition for understanding this difference\nin performance. In this work, we present a unified probabilistic perspective on\nIL algorithms based on divergence minimization. We present $f$-MAX, an\n$f$-divergence generalization of AIRL [Fu et al., 2018], a state-of-the-art IRL\nmethod. $f$-MAX enables us to relate prior IRL methods such as GAIL [Ho &\nErmon, 2016] and AIRL [Fu et al., 2018], and understand their algorithmic\nproperties. Through the lens of divergence minimization we tease apart the\ndifferences between BC and successful IRL approaches, and empirically evaluate\nthese nuances on simulated high-dimensional continuous control domains. Our\nfindings conclusively identify that IRL's state-marginal matching objective\ncontributes most to its superior performance. Lastly, we apply our new\nunderstanding of IL methods to the problem of state-marginal matching, where we\ndemonstrate that in simulated arm pushing environments we can teach agents a\ndiverse range of behaviours using simply hand-specified state distributions and\nno reward functions or expert demonstrations. For datasets and reproducing\nresults please refer to\nhttps://github.com/KamyarGh/rl_swiss/blob/master/reproducing/fmax_paper.md .\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:50:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ghasemipour", "Seyed Kamyar Seyed", ""], ["Zemel", "Richard", ""], ["Gu", "Shixiang", ""]]}, {"id": "1911.02306", "submitter": "Quentin Klopfenstein", "authors": "Quentin Klopfenstein (IMB), Samuel Vaiter (CNRS, IMB)", "title": "Linear Support Vector Regression with Linear Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the addition of linear constraints to the Support Vector\nRegression (SVR) when the kernel is linear. Adding those constraints into the\nproblem allows to add prior knowledge on the estimator obtained, such as\nfinding probability vector or monotone data. We propose a generalization of the\nSequential Minimal Optimization (SMO) algorithm for solving the optimization\nproblem with linear constraints and prove its convergence. Then, practical\nperformances of this estimator are shown on simulated and real datasets with\ndifferent settings: non negative regression, regression onto the simplex for\nbiomedical data and isotonic regression for weather forecast.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 10:57:29 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Klopfenstein", "Quentin", "", "IMB"], ["Vaiter", "Samuel", "", "CNRS, IMB"]]}, {"id": "1911.02319", "submitter": "Othmane Mounjid", "authors": "Othmane Mounjid and Charles-Albert Lehalle", "title": "Improving reinforcement learning algorithms: towards optimal learning\n  rate policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates to what extent one can improve reinforcement learning\nalgorithms. Our study is split in three parts. First, our analysis shows that\nthe classical asymptotic convergence rate $O(1/\\sqrt{N})$ is pessimistic and\ncan be replaced by $O((\\log(N)/N)^{\\beta})$ with $\\frac{1}{2}\\leq \\beta \\leq 1$\nand $N$ the number of iterations. Second, we propose a dynamic optimal policy\nfor the choice of the learning rate $(\\gamma_k)_{k\\geq 0}$ used in stochastic\napproximation (SA). We decompose our policy into two interacting levels: the\ninner and the outer level. In the inner level, we present the\n\\nameref{Alg:v_4_s} algorithm (for \"PAst Sign Search\") which, based on a\npredefined sequence $(\\gamma^o_k)_{k\\geq 0}$, constructs a new sequence\n$(\\gamma^i_k)_{k\\geq 0}$ whose error decreases faster. In the outer level, we\npropose an optimal methodology for the selection of the predefined sequence\n$(\\gamma^o_k)_{k\\geq 0}$. Third, we show empirically that our selection\nmethodology of the learning rate outperforms significantly standard algorithms\nused in reinforcement learning (RL) in the three following applications: the\nestimation of a drift, the optimal placement of limit orders and the optimal\nexecution of large number of shares.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:17:53 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 19:05:39 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 21:12:12 GMT"}, {"version": "v4", "created": "Tue, 21 Apr 2020 18:04:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mounjid", "Othmane", ""], ["Lehalle", "Charles-Albert", ""]]}, {"id": "1911.02347", "submitter": "Nicolas Couellan", "authors": "Evgenii Munin, Antoine Blais, Nicolas Couellan", "title": "Convolutional Neural Network for Multipath Detection in GNSS Receivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Navigation Satellite System (GNSS) signals are subject to different\nkinds of events causing significant errors in positioning. This work explores\nthe application of Machine Learning (ML) methods of anomaly detection applied\nto GNSS receiver signals. More specifically, our study focuses on multipath\ncontamination, using samples of the correlator output signal. The GPS L1 C/A\nsignal data is used and sourced directly from the correlator output. To extract\nthe important features and patterns from such data, we use deep convolutional\nneural networks (CNN), which have proven to be efficient in image analysis in\nparticular. To take advantage of CNN, the correlator output signal is mapped as\na 2D input image and fed to the convolutional layers of a neural network. The\nnetwork automatically extracts the relevant features from the input samples and\nproceeds with the multipath detection. We train the CNN using synthetic\nsignals. To optimize the model architecture with respect to the GNSS correlator\ncomplexity, the evaluation of the CNN performance is done as a function of the\nnumber of correlator output points.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:55:02 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Munin", "Evgenii", ""], ["Blais", "Antoine", ""], ["Couellan", "Nicolas", ""]]}, {"id": "1911.02361", "submitter": "Jarek Duda dr", "authors": "Jaros{\\l}aw Duda, Robert Syrek, Henryk Gurgul", "title": "Modelling bid-ask spread conditional distributions using hierarchical\n  correlation reconstruction", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While we would like to predict exact values, available incomplete information\nis rarely sufficient - usually allowing only to predict conditional probability\ndistributions. This article discusses hierarchical correlation reconstruction\n(HCR) methodology for such prediction on example of usually unavailable bid-ask\nspreads, predicted from more accessible data like closing price, volume,\nhigh/low price, returns. In HCR methodology we first normalize marginal\ndistributions to nearly uniform like in copula theory. Then we model (joint)\ndensities as linear combinations of orthonormal polynomials, getting its\ndecomposition into (mixed) moments. Then here we model each moment (separately)\nof predicted variable as a linear combination of mixed moments of known\nvariables using least squares linear regression - getting accurate description\nwith interpretable coefficients describing linear relations between moments.\nCombining such predicted moments we get predicted density as a polynomial, for\nwhich we can e.g. calculate expected value, but also variance to evaluate\nuncertainty of such prediction, or we can use the entire distribution e.g. for\nmore accurate further calculations or generating random values. There were\nperformed 10-fold cross-validation log-likelihood tests for 22 DAX companies,\nleading to very accurate predictions, especially when using individual models\nfor each company as there were found large differences between their behaviors.\nAdditional advantage of the discussed methodology is being computationally\ninexpensive, finding and evaluation a model with hundreds of parameters and\nthousands of data points takes a second on a laptop.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 09:57:27 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Duda", "Jaros\u0142aw", ""], ["Syrek", "Robert", ""], ["Gurgul", "Henryk", ""]]}, {"id": "1911.02369", "submitter": "Abhishek .", "authors": "Abhishek Abhishek (1 and 2) and Wojciech Fedorko (2) and Patrick de\n  Perio (2) and Nicholas Prouse (2) and Julian Z. Ding (2 and 3) ((1)\n  University of Manitoba, (2) TRIUMF, (3) University of British Columbia)", "title": "Variational Autoencoders for Generative Modelling of Water Cherenkov\n  Detectors", "comments": "6 pages, 4 figures, 1 table, submitted to Machine Learning and the\n  Physical Sciences Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matter-antimatter asymmetry is one of the major unsolved problems in physics\nthat can be probed through precision measurements of charge-parity symmetry\nviolation at current and next-generation neutrino oscillation experiments. In\nthis work, we demonstrate the capability of variational autoencoders and\nnormalizing flows to approximate the generative distribution of simulated data\nfor water Cherenkov detectors commonly used in these experiments. We study the\nperformance of these methods and their applicability for semi-supervised\nlearning and synthetic data generation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 22:16:03 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Abhishek", "Abhishek", "", "1 and 2"], ["Fedorko", "Wojciech", "", "2 and 3"], ["de Perio", "Patrick", "", "2 and 3"], ["Prouse", "Nicholas", "", "2 and 3"], ["Ding", "Julian Z.", "", "2 and 3"]]}, {"id": "1911.02377", "submitter": "Quanming Yao", "authors": "Quanming Yao, Hansi Yang, Bo Han, Gang Niu, James Kwok", "title": "Searching to Exploit Memorization Effect in Learning from Corrupted\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample selection approaches are popular in robust learning from noisy labels.\nHowever, how to properly control the selection process so that deep networks\ncan benefit from the memorization effect is a hard problem. In this paper,\nmotivated by the success of automated machine learning (AutoML), we model this\nissue as a function approximation problem. Specifically, we design a\ndomain-specific search space based on general patterns of the memorization\neffect and propose a novel Newton algorithm to solve the bi-level optimization\nproblem efficiently. We further provide theoretical analysis of the algorithm,\nwhich ensures a good approximation to critical points. Experiments are\nperformed on benchmark data sets. Results demonstrate that the proposed method\nis much better than the state-of-the-art noisy-label-learning approaches, and\nalso much more efficient than existing AutoML algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:36:04 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 08:22:25 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 16:46:01 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 20:00:08 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 16:14:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yao", "Quanming", ""], ["Yang", "Hansi", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Kwok", "James", ""]]}, {"id": "1911.02417", "submitter": "Zhaohui Yang", "authors": "Zhaohui Yang and Mingzhe Chen and Walid Saad and Choong Seon Hong and\n  Mohammad Shikh-Bahaei", "title": "Energy Efficient Federated Learning Over Wireless Communication Networks", "comments": "In IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, the problem of energy efficient transmission and computation\nresource allocation for federated learning (FL) over wireless communication\nnetworks is investigated. In the considered model, each user exploits limited\nlocal computational resources to train a local FL model with its collected data\nand, then, sends the trained FL model to a base station (BS) which aggregates\nthe local FL model and broadcasts it back to all of the users. Since FL\ninvolves an exchange of a learning model between users and the BS, both\ncomputation and communication latencies are determined by the learning accuracy\nlevel. Meanwhile, due to the limited energy budget of the wireless users, both\nlocal computation energy and transmission energy must be considered during the\nFL process. This joint learning and communication problem is formulated as an\noptimization problem whose goal is to minimize the total energy consumption of\nthe system under a latency constraint. To solve this problem, an iterative\nalgorithm is proposed where, at every step, closed-form solutions for time\nallocation, bandwidth allocation, power control, computation frequency, and\nlearning accuracy are derived. Since the iterative algorithm requires an\ninitial feasible solution, we construct the completion time minimization\nproblem and a bisection-based algorithm is proposed to obtain the optimal\nsolution, which is a feasible solution to the original energy minimization\nproblem. Numerical results show that the proposed algorithms can reduce up to\n59.5% energy consumption compared to the conventional FL method.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 14:51:49 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 03:17:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yang", "Zhaohui", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""], ["Shikh-Bahaei", "Mohammad", ""]]}, {"id": "1911.02455", "submitter": "Agathe Balayn", "authors": "Agathe Balayn, Alessandro Bozzon, Zoltan Szlavik", "title": "Unfairness towards subjective opinions in Machine Learning", "comments": "Human-Centered Machine Learning Perspectives (HCML) workshop at the\n  CHI conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the high interest for Machine Learning (ML) in academia and industry,\nmany issues related to the application of ML to real-life problems are yet to\nbe addressed. Here we put forward one limitation which arises from a lack of\nadaptation of ML models and datasets to specific applications. We formalise a\nnew notion of unfairness as exclusion of opinions. We propose ways to quantify\nthis unfairness, and aid understanding its causes through visualisation. These\ninsights into the functioning of ML-based systems hint at methods to mitigate\nunfairness.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:11:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Balayn", "Agathe", ""], ["Bozzon", "Alessandro", ""], ["Szlavik", "Zoltan", ""]]}, {"id": "1911.02457", "submitter": "Hadis Anahideh", "authors": "Hadis Anahideh, Jay Rosenberger, Victoria Chen", "title": "High-dimensional Black-box Optimization Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing expensive black-box systems with limited data is an extremely\nchallenging problem. As a resolution, we present a new surrogate optimization\napproach by addressing two gaps in prior research -- unimportant input\nvariables and inefficient treatment of uncertainty associated with the\nblack-box output. We first design a new flexible non-interpolating parsimonious\nsurrogate model using a partitioning-based multivariate adaptive regression\nsplines approach, Tree Knot MARS (TK-MARS). The proposed model is specifically\ndesigned for optimization by capturing the structure of the function, bending\nat near-optimal locations, and is capable of screening unimportant input\nvariables. Furthermore, we develop a novel replication approach called\nSmart-Replication, to overcome the uncertainty associated with the black-box\noutput. The Smart-Replication approach identifies promising input points to\nreplicate and avoids unnecessary evaluations of other data points.\nSmart-Replication is agnostic to the choice of a surrogate and can adapt itself\nto an unknown noise level. Finally to demonstrate the effectiveness of our\nproposed approaches we consider different complex global optimization test\nfunctions from the surrogate optimization literature. The results indicate that\nTK-MARS outperforms original MARS within a surrogate optimization algorithm and\nsuccessfully detects important variables. The results also show that although\nnon-interpolating surrogates can mitigate uncertainty, replication is still\nbeneficial for optimizing highly complex black-box functions. The robustness\nand the quality of the final optimum solution found through Smart-Replication\nare competitive with that using no replications in environments with low levels\nof noise and using a fixed number of replications in highly noisy environments.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:13:36 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 03:47:27 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 17:01:46 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 15:55:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Anahideh", "Hadis", ""], ["Rosenberger", "Jay", ""], ["Chen", "Victoria", ""]]}, {"id": "1911.02469", "submitter": "James Lucas", "authors": "James Lucas, George Tucker, Roger Grosse, Mohammad Norouzi", "title": "Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse", "comments": "11 main pages, 10 appendix pages. 13 figures total. Accepted at 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior collapse in Variational Autoencoders (VAEs) arises when the\nvariational posterior distribution closely matches the prior for a subset of\nlatent variables. This paper presents a simple and intuitive explanation for\nposterior collapse through the analysis of linear VAEs and their direct\ncorrespondence with Probabilistic PCA (pPCA). We explain how posterior collapse\nmay occur in pPCA due to local maxima in the log marginal likelihood.\nUnexpectedly, we prove that the ELBO objective for the linear VAE does not\nintroduce additional spurious local maxima relative to log marginal likelihood.\nWe show further that training a linear VAE with exact variational inference\nrecovers an identifiable global maximum corresponding to the principal\ncomponent directions. Empirically, we find that our linear analysis is\npredictive even for high-capacity, non-linear VAEs and helps explain the\nrelationship between the observation noise, local maxima, and posterior\ncollapse in deep Gaussian VAEs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:34:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lucas", "James", ""], ["Tucker", "George", ""], ["Grosse", "Roger", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1911.02471", "submitter": "Agathe Balayn", "authors": "Agathe Balayn, Alessandro Bozzon", "title": "Designing Evaluations of Machine Learning Models for Subjective\n  Inference: The Case of Sentence Toxicity", "comments": "presented at the Rigorous Evaluation of Artificial Intelligence\n  Systems (REAIS) workshop co-located with HCOMP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is increasingly applied in real-life scenarios, raising\nconcerns about bias in automatic decision making. We focus on bias as a notion\nof opinion exclusion, that stems from the direct application of traditional ML\npipelines to infer subjective properties. We argue that such ML systems should\nbe evaluated with subjectivity and bias in mind. Considering the lack of\nevaluation standards yet to create evaluation benchmarks, we propose an initial\nlist of specifications to define prior to creating evaluation datasets, in\norder to later accurately evaluate the biases. With the example of a sentence\ntoxicity inference system, we illustrate how the specifications support the\nanalysis of biases related to subjectivity. We highlight difficulties in\ninstantiating these specifications and list future work for the crowdsourcing\ncommunity to help the creation of appropriate evaluation datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:38:19 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Balayn", "Agathe", ""], ["Bozzon", "Alessandro", ""]]}, {"id": "1911.02490", "submitter": "Joaquin Vanschoren", "authors": "Matthias Feurer, Jan N. van Rijn, Arlind Kadra, Pieter Gijsbers,\n  Neeratyoy Mallik, Sahithya Ravi, Andreas M\\\"uller, Joaquin Vanschoren, Frank\n  Hutter", "title": "OpenML-Python: an extensible Python API for OpenML", "comments": null, "journal-ref": "Journal of Machine Learning Research 22(100), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenML is an online platform for open science collaboration in machine\nlearning, used to share datasets and results of machine learning experiments.\nIn this paper we introduce OpenML-Python, a client API for Python, opening up\nthe OpenML platform for a wide range of Python-based tools. It provides easy\naccess to all datasets, tasks and experiments on OpenML from within Python. It\nalso provides functionality to conduct machine learning experiments, upload the\nresults to OpenML, and reproduce results which are stored on OpenML.\nFurthermore, it comes with a scikit-learn plugin and a plugin mechanism to\neasily integrate other machine learning libraries written in Python into the\nOpenML ecosystem. Source code and documentation is available at\nhttps://github.com/openml/openml-python/.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:59:30 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:04:39 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feurer", "Matthias", ""], ["van Rijn", "Jan N.", ""], ["Kadra", "Arlind", ""], ["Gijsbers", "Pieter", ""], ["Mallik", "Neeratyoy", ""], ["Ravi", "Sahithya", ""], ["M\u00fcller", "Andreas", ""], ["Vanschoren", "Joaquin", ""], ["Hutter", "Frank", ""]]}, {"id": "1911.02497", "submitter": "Vinu Joseph", "authors": "Vinu Joseph, Saurav Muralidharan, Animesh Garg, Michael Garland,\n  Ganesh Gopalakrishnan", "title": "A Programmable Approach to Neural Network Compression", "comments": "This is an updated version of a paper published in IEEE Micro, vol.\n  40, no. 5, pp. 17-25, Sept.-Oct. 2020 at\n  https://ieeexplore.ieee.org/document/9151283", "journal-ref": "IEEE Micro, Volume: 40, Issue: 5, Sept.-Oct. 2020, pp. 17-25", "doi": "10.1109/MM.2020.3012391", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) frequently contain far more weights, represented\nat a higher precision, than are required for the specific task which they are\ntrained to perform. Consequently, they can often be compressed using techniques\nsuch as weight pruning and quantization that reduce both the model size and\ninference time without appreciable loss in accuracy. However, finding the best\ncompression strategy and corresponding target sparsity for a given DNN,\nhardware platform, and optimization objective currently requires expensive,\nfrequently manual, trial-and-error experimentation. In this paper, we introduce\na programmable system for model compression called Condensa. Users\nprogrammatically compose simple operators, in Python, to build more complex and\npractically interesting compression strategies. Given a strategy and\nuser-provided objective (such as minimization of running time), Condensa uses a\nnovel Bayesian optimization-based algorithm to automatically infer desirable\nsparsities. Our experiments on four real-world DNNs demonstrate memory\nfootprint and hardware runtime throughput improvements of 188x and 2.59x,\nrespectively, using at most ten samples per search. We have released a\nreference implementation of Condensa at https://github.com/NVlabs/condensa.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:14:32 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 22:55:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Joseph", "Vinu", ""], ["Muralidharan", "Saurav", ""], ["Garg", "Animesh", ""], ["Garland", "Michael", ""], ["Gopalakrishnan", "Ganesh", ""]]}, {"id": "1911.02508", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu\n  Lakkaraju", "title": "Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning black boxes are increasingly being deployed in domains\nsuch as healthcare and criminal justice, there is growing emphasis on building\ntools and techniques for explaining these black boxes in an interpretable\nmanner. Such explanations are being leveraged by domain experts to diagnose\nsystematic errors and underlying biases of black boxes. In this paper, we\ndemonstrate that post hoc explanations techniques that rely on input\nperturbations, such as LIME and SHAP, are not reliable. Specifically, we\npropose a novel scaffolding technique that effectively hides the biases of any\ngiven classifier by allowing an adversarial entity to craft an arbitrary\ndesired explanation. Our approach can be used to scaffold any biased classifier\nin such a way that its predictions on the input data distribution still remain\nbiased, but the post hoc explanations of the scaffolded classifier look\ninnocuous. Using extensive evaluation with multiple real-world datasets\n(including COMPAS), we demonstrate how extremely biased (racist) classifiers\ncrafted by our framework can easily fool popular explanation techniques such as\nLIME and SHAP into generating innocuous explanations which do not reflect the\nunderlying biases.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:52:20 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 18:53:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Slack", "Dylan", ""], ["Hilgard", "Sophie", ""], ["Jia", "Emily", ""], ["Singh", "Sameer", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "1911.02516", "submitter": "Alessandro Rigazzi", "authors": "Alessandro Rigazzi", "title": "DC-S3GD: Delay-Compensated Stale-Synchronous SGD for Large-Scale\n  Decentralized Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallelism has become the de facto standard for training Deep Neural\nNetwork on multiple processing units. In this work we propose DC-S3GD, a\ndecentralized (without Parameter Server) stale-synchronous version of the\nDelay-Compensated Asynchronous Stochastic Gradient Descent (DC-ASGD) algorithm.\nIn our approach, we allow for the overlap of computation and communication, and\ncompensate the inherent error with a first-order correction of the gradients.\nWe prove the effectiveness of our approach by training Convolutional Neural\nNetwork with large batches and achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:54:56 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Rigazzi", "Alessandro", ""]]}, {"id": "1911.02522", "submitter": "Jiayi Liu", "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah", "title": "Auptimizer -- an Extensible, Open-Source Framework for Hyperparameter\n  Tuning", "comments": "Accepted at IEEE Big Data 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning machine learning models at scale, especially finding the right\nhyperparameter values, can be difficult and time-consuming. In addition to the\ncomputational effort required, this process also requires some ancillary\nefforts including engineering tasks (e.g., job scheduling) as well as more\nmundane tasks (e.g., keeping track of the various parameters and associated\nresults). We present Auptimizer, a general Hyperparameter Optimization (HPO)\nframework to help data scientists speed up model tuning and bookkeeping. With\nAuptimizer, users can use all available computing resources in distributed\nsettings for model training. The user-friendly system design simplifies\ncreating, controlling, and tracking of a typical machine learning project. The\ndesign also allows researchers to integrate new HPO algorithms. To demonstrate\nits flexibility, we show how Auptimizer integrates a few major HPO techniques\n(from random search to neural architecture search). The code is available at\nhttps://github.com/LGE-ARC-AdvancedAI/auptimizer.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:00:31 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1911.02536", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Youssef Mroueh, Tommi S. Jaakkola", "title": "Unsupervised Hierarchy Matching with Optimal Transport over Hyperbolic\n  Spaces", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of unsupervised alignment of hierarchical\ndata such as ontologies or lexical databases. This is a problem that appears\nacross areas, from natural language processing to bioinformatics, and is\ntypically solved by appeal to outside knowledge bases and label-textual\nsimilarity. In contrast, we approach the problem from a purely geometric\nperspective: given only a vector-space representation of the items in the two\nhierarchies, we seek to infer correspondences across them. Our work derives\nfrom and interweaves hyperbolic-space representations for hierarchical data, on\none hand, and unsupervised word-alignment methods, on the other. We first\nprovide a set of negative results showing how and why Euclidean methods fail in\nthis hyperbolic setting. We then propose a novel approach based on optimal\ntransport over hyperbolic spaces, and show that it outperforms standard\nembedding alignment techniques in various experiments on cross-lingual WordNet\nalignment and ontology matching tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:20:35 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 01:52:26 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Mroueh", "Youssef", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1911.02549", "submitter": "Cody Coleman", "authors": "Vijay Janapa Reddi, Christine Cheng, David Kanter, Peter Mattson,\n  Guenther Schmuelling, Carole-Jean Wu, Brian Anderson, Maximilien Breughe,\n  Mark Charlebois, William Chou, Ramesh Chukka, Cody Coleman, Sam Davis, Pan\n  Deng, Greg Diamos, Jared Duke, Dave Fick, J. Scott Gardner, Itay Hubara,\n  Sachin Idgunji, Thomas B. Jablin, Jeff Jiao, Tom St. John, Pankaj Kanwar,\n  David Lee, Jeffery Liao, Anton Lokhmotov, Francisco Massa, Peng Meng, Paulius\n  Micikevicius, Colin Osborne, Gennady Pekhimenko, Arun Tejusve Raghunath\n  Rajan, Dilip Sequeira, Ashish Sirasao, Fei Sun, Hanlin Tang, Michael Thomson,\n  Frank Wei, Ephrem Wu, Lingjie Xu, Koichi Yamada, Bing Yu, George Yuan, Aaron\n  Zhong, Peizhao Zhang, Yuchen Zhou", "title": "MLPerf Inference Benchmark", "comments": "ISCA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning (ML) hardware and software system demand is burgeoning.\nDriven by ML applications, the number of different ML inference systems has\nexploded. Over 100 organizations are building ML inference chips, and the\nsystems that incorporate existing models span at least three orders of\nmagnitude in power consumption and five orders of magnitude in performance;\nthey range from embedded devices to data-center solutions. Fueling the hardware\nare a dozen or more software frameworks and libraries. The myriad combinations\nof ML hardware and ML software make assessing ML-system performance in an\narchitecture-neutral, representative, and reproducible manner challenging.\nThere is a clear need for industry-wide standard ML benchmarking and evaluation\ncriteria. MLPerf Inference answers that call. In this paper, we present our\nbenchmarking method for evaluating ML inference systems. Driven by more than 30\norganizations as well as more than 200 ML engineers and practitioners, MLPerf\nprescribes a set of rules and best practices to ensure comparability across\nsystems with wildly differing architectures. The first call for submissions\ngarnered more than 600 reproducible inference-performance measurements from 14\norganizations, representing over 30 systems that showcase a wide range of\ncapabilities. The submissions attest to the benchmark's flexibility and\nadaptability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:43:10 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 23:40:20 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Reddi", "Vijay Janapa", ""], ["Cheng", "Christine", ""], ["Kanter", "David", ""], ["Mattson", "Peter", ""], ["Schmuelling", "Guenther", ""], ["Wu", "Carole-Jean", ""], ["Anderson", "Brian", ""], ["Breughe", "Maximilien", ""], ["Charlebois", "Mark", ""], ["Chou", "William", ""], ["Chukka", "Ramesh", ""], ["Coleman", "Cody", ""], ["Davis", "Sam", ""], ["Deng", "Pan", ""], ["Diamos", "Greg", ""], ["Duke", "Jared", ""], ["Fick", "Dave", ""], ["Gardner", "J. Scott", ""], ["Hubara", "Itay", ""], ["Idgunji", "Sachin", ""], ["Jablin", "Thomas B.", ""], ["Jiao", "Jeff", ""], ["John", "Tom St.", ""], ["Kanwar", "Pankaj", ""], ["Lee", "David", ""], ["Liao", "Jeffery", ""], ["Lokhmotov", "Anton", ""], ["Massa", "Francisco", ""], ["Meng", "Peng", ""], ["Micikevicius", "Paulius", ""], ["Osborne", "Colin", ""], ["Pekhimenko", "Gennady", ""], ["Rajan", "Arun Tejusve Raghunath", ""], ["Sequeira", "Dilip", ""], ["Sirasao", "Ashish", ""], ["Sun", "Fei", ""], ["Tang", "Hanlin", ""], ["Thomson", "Michael", ""], ["Wei", "Frank", ""], ["Wu", "Ephrem", ""], ["Xu", "Lingjie", ""], ["Yamada", "Koichi", ""], ["Yu", "Bing", ""], ["Yuan", "George", ""], ["Zhong", "Aaron", ""], ["Zhang", "Peizhao", ""], ["Zhou", "Yuchen", ""]]}, {"id": "1911.02590", "submitter": "Jonathan Lorraine", "authors": "Jonathan Lorraine, Paul Vicol, David Duvenaud", "title": "Optimizing Millions of Hyperparameters by Implicit Differentiation", "comments": "Submitted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for inexpensive gradient-based hyperparameter\noptimization that combines the implicit function theorem (IFT) with efficient\ninverse Hessian approximations. We present results about the relationship\nbetween the IFT and differentiating through optimization, motivating our\nalgorithm. We use the proposed approach to train modern network architectures\nwith millions of weights and millions of hyper-parameters. For example, we\nlearn a data-augmentation network - where every weight is a hyperparameter\ntuned for validation performance - outputting augmented training examples.\nJointly tuning weights and hyperparameters with our approach is only a few\ntimes more costly in memory and compute than standard training.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 19:04:16 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lorraine", "Jonathan", ""], ["Vicol", "Paul", ""], ["Duvenaud", "David", ""]]}, {"id": "1911.02613", "submitter": "Ruochi Zhang", "authors": "Ruochi Zhang, Yuesong Zou, Jian Ma", "title": "Hyper-SAGNN: a self-attention based graph neural network for hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning for hypergraphs can be used to extract patterns\namong higher-order interactions that are critically important in many real\nworld problems. Current approaches designed for hypergraphs, however, are\nunable to handle different types of hypergraphs and are typically not generic\nfor various learning tasks. Indeed, models that can predict variable-sized\nheterogeneous hyperedges have not been available. Here we develop a new\nself-attention based graph neural network called Hyper-SAGNN applicable to\nhomogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We\nperform extensive evaluations on multiple datasets, including four benchmark\nnetwork datasets and two single-cell Hi-C datasets in genomics. We demonstrate\nthat Hyper-SAGNN significantly outperforms the state-of-the-art methods on\ntraditional tasks while also achieving great performance on a new task called\noutsider identification. Hyper-SAGNN will be useful for graph representation\nlearning to uncover complex higher-order interactions in different\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:10:24 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Ruochi", ""], ["Zou", "Yuesong", ""], ["Ma", "Jian", ""]]}, {"id": "1911.02623", "submitter": "Soumi Das", "authors": "Soumi Das, Rajath Nandan Kalava, Kolli Kiran Kumar, Akhil Kandregula,\n  Kalpam Suhaas, Sourangshu Bhattacharya, Niloy Ganguly", "title": "Map Enhanced Route Travel Time Prediction using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time estimation is a fundamental problem in transportation science\nwith extensive literature. The study of these techniques has intensified due to\navailability of many publicly available large trip datasets. Recently developed\ndeep learning based models have improved the generality and performance and\nhave focused on estimating times for individual sub-trajectories and\naggregating them to predict the travel time of the entire trajectory. However,\nthese techniques ignore the road network information. In this work, we propose\nand study techniques for incorporating road networks along with historical\ntrips' data into travel time prediction. We incorporate both node embeddings as\nwell as road distance into the existing model. Experiments on large real-world\nbenchmark datasets suggest improved performance, especially when the train data\nis small. As expected, the proposed method performs better than the baseline\nwhen there is a larger difference between road distance and Vincenty distance\nbetween start and end points.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:52:02 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Das", "Soumi", ""], ["Kalava", "Rajath Nandan", ""], ["Kumar", "Kolli Kiran", ""], ["Kandregula", "Akhil", ""], ["Suhaas", "Kalpam", ""], ["Bhattacharya", "Sourangshu", ""], ["Ganguly", "Niloy", ""]]}, {"id": "1911.02624", "submitter": "Nathana\\\"el Fijalkow", "authors": "Judith Clymo, Haik Manukian, Nathana\\\"el Fijalkow, Adri\\`a Gasc\\'on,\n  Brooks Paige", "title": "Data Generation for Neural Programming by Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming by example is the problem of synthesizing a program from a small\nset of input / output pairs. Recent works applying machine learning methods to\nthis task show promise, but are typically reliant on generating synthetic\nexamples for training. A particular challenge lies in generating meaningful\nsets of inputs and outputs, which well-characterize a given program and\naccurately demonstrate its behavior. Where examples used for testing are\ngenerated by the same method as training data then the performance of a model\nmay be partly reliant on this similarity. In this paper we introduce a novel\napproach using an SMT solver to synthesize inputs which cover a diverse set of\nbehaviors for a given program. We carry out a case study comparing this method\nto existing synthetic data generation procedures in the literature, and find\nthat data generated using our approach improves both the discriminatory power\nof example sets and the ability of trained machine learning models to\ngeneralize to unfamiliar data.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:57:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Clymo", "Judith", ""], ["Manukian", "Haik", ""], ["Fijalkow", "Nathana\u00ebl", ""], ["Gasc\u00f3n", "Adri\u00e0", ""], ["Paige", "Brooks", ""]]}, {"id": "1911.02656", "submitter": "Karthik Bharath", "authors": "Rachel Carrington, Karthik Bharath and Simon Preston", "title": "Invariance and identifiability issues for word embeddings", "comments": "NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are commonly obtained as optimizers of a criterion function\n$f$ of a text corpus, but assessed on word-task performance using a different\nevaluation function $g$ of the test data. We contend that a possible source of\ndisparity in performance on tasks is the incompatibility between classes of\ntransformations that leave $f$ and $g$ invariant. In particular, word\nembeddings defined by $f$ are not unique; they are defined only up to a class\nof transformations to which $f$ is invariant, and this class is larger than the\nclass to which $g$ is invariant. One implication of this is that the apparent\nsuperiority of one word embedding over another, as measured by word task\nperformance, may largely be a consequence of the arbitrary elements selected\nfrom the respective solution sets. We provide a formal treatment of the above\nidentifiability issue, present some numerical examples, and discuss possible\nresolutions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:41:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Carrington", "Rachel", ""], ["Bharath", "Karthik", ""], ["Preston", "Simon", ""]]}, {"id": "1911.02660", "submitter": "Weilin Fu", "authors": "Weilin Fu and Katharina Breininger and Zhaoya Pan and Andreas Maier", "title": "What Do We Really Need? Degenerating U-Net on Retinal Vessel\n  Segmentation", "comments": "7 pages, 2 figures, submitted in BVM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retinal vessel segmentation is an essential step for fundus image analysis.\nWith the recent advances of deep learning technologies, many convolutional\nneural networks have been applied in this field, including the successful\nU-Net. In this work, we firstly modify the U-Net with functional blocks aiming\nto pursue higher performance. The absence of the expected performance boost\nthen lead us to dig into the opposite direction of shrinking the U-Net and\nexploring the extreme conditions such that its segmentation performance is\nmaintained. Experiment series to simplify the network structure, reduce the\nnetwork size and restrict the training conditions are designed. Results show\nthat for retinal vessel segmentation on DRIVE database, U-Net does not\ndegenerate until surprisingly acute conditions: one level, one filter in\nconvolutional layers, and one training sample. This experimental discovery is\nboth counter-intuitive and worthwhile. Not only are the extremes of the U-Net\nexplored on a well-studied application, but also one intriguing warning is\nraised for the research methodology which seeks for marginal performance\nenhancement regardless of the resource cost.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:49:55 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fu", "Weilin", ""], ["Breininger", "Katharina", ""], ["Pan", "Zhaoya", ""], ["Maier", "Andreas", ""]]}, {"id": "1911.02673", "submitter": "Emily Aiken", "authors": "Emily L. Aiken, Andre T. Nguyen, Mauricio Santillana", "title": "Towards the Use of Neural Networks for Influenza Prediction at Multiple\n  Spatial Resolutions", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract; Added Footer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of a Gated Recurrent Unit (GRU) for influenza prediction\nat the state- and city-level in the US, and experiment with the inclusion of\nreal-time flu-related Internet search data. We find that a GRU has lower\nprediction error than current state-of-the-art methods for data-driven\ninfluenza prediction at time horizons of over two weeks. In contrast with other\nmachine learning approaches, the inclusion of real-time Internet search data\ndoes not improve GRU predictions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:14:53 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 05:10:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Aiken", "Emily L.", ""], ["Nguyen", "Andre T.", ""], ["Santillana", "Mauricio", ""]]}, {"id": "1911.02681", "submitter": "Anbang Wu", "authors": "Anbang Wu, Shuangxi Chen, Chunming Wu", "title": "Generalized Transformation-based Gradient", "comments": "There is some errors in the proof to the conclusion, therefore\n  leading to untrusted conclusion, so I want to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reparameterization trick has become one of the most useful tools in the\nfield of variational inference. However, the reparameterization trick is based\non the standardization transformation which restricts the scope of application\nof this method to distributions that have tractable inverse cumulative\ndistribution functions or are expressible as deterministic transformations of\nsuch distributions. In this paper, we generalized the reparameterization trick\nby allowing a general transformation. We discover that the proposed model is a\nspecial case of control variate indicating that the proposed model can combine\nthe advantages of CV and generalized reparameterization.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:40:12 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 01:30:21 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 10:38:09 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wu", "Anbang", ""], ["Chen", "Shuangxi", ""], ["Wu", "Chunming", ""]]}, {"id": "1911.02682", "submitter": "Arka Daw", "authors": "Arka Daw, R. Quinn Thomas, Cayelan C. Carey, Jordan S. Read, Alison P.\n  Appling, Anuj Karpatne", "title": "Physics-Guided Architecture (PGA) of Neural Networks for Quantifying\n  Uncertainty in Lake Temperature Modeling", "comments": "11 pages, 15 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To simultaneously address the rising need of expressing uncertainties in deep\nlearning models along with producing model outputs which are consistent with\nthe known scientific knowledge, we propose a novel physics-guided architecture\n(PGA) of neural networks in the context of lake temperature modeling where the\nphysical constraints are hard coded in the neural network architecture. This\nallows us to integrate such models with state of the art uncertainty estimation\napproaches such as Monte Carlo (MC) Dropout without sacrificing the physical\nconsistency of our results. We demonstrate the effectiveness of our approach in\nensuring better generalizability as well as physical consistency in MC\nestimates over data collected from Lake Mendota in Wisconsin and Falling Creek\nReservoir in Virginia, even with limited training data. We further show that\nour MC estimates correctly match the distribution of ground-truth observations,\nthus making the PGA paradigm amenable to physically grounded uncertainty\nquantification.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:47:14 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Daw", "Arka", ""], ["Thomas", "R. Quinn", ""], ["Carey", "Cayelan C.", ""], ["Read", "Jordan S.", ""], ["Appling", "Alison P.", ""], ["Karpatne", "Anuj", ""]]}, {"id": "1911.02685", "submitter": "Fuzhen Zhuang", "authors": "Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu\n  Zhu, Hui Xiong, Qing He", "title": "A Comprehensive Survey on Transfer Learning", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims at improving the performance of target learners on\ntarget domains by transferring the knowledge contained in different but related\nsource domains. In this way, the dependence on a large number of target domain\ndata can be reduced for constructing target learners. Due to the wide\napplication prospects, transfer learning has become a popular and promising\narea in machine learning. Although there are already some valuable and\nimpressive surveys on transfer learning, these surveys introduce approaches in\na relatively isolated way and lack the recent advances in transfer learning.\nDue to the rapid expansion of the transfer learning area, it is both necessary\nand challenging to comprehensively review the relevant studies. This survey\nattempts to connect and systematize the existing transfer learning researches,\nas well as to summarize and interpret the mechanisms and the strategies of\ntransfer learning in a comprehensive way, which may help readers have a better\nunderstanding of the current research status and ideas. Unlike previous\nsurveys, this survey paper reviews more than forty representative transfer\nlearning approaches, especially homogeneous transfer learning approaches, from\nthe perspectives of data and model. The applications of transfer learning are\nalso briefly introduced. In order to show the performance of different transfer\nlearning models, over twenty representative transfer learning models are used\nfor experiments. The models are performed on three different datasets, i.e.,\nAmazon Reviews, Reuters-21578, and Office-31. And the experimental results\ndemonstrate the importance of selecting appropriate transfer learning models\nfor different applications in practice.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:15:02 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 02:20:48 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 15:52:46 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhuang", "Fuzhen", ""], ["Qi", "Zhiyuan", ""], ["Duan", "Keyu", ""], ["Xi", "Dongbo", ""], ["Zhu", "Yongchun", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["He", "Qing", ""]]}, {"id": "1911.02688", "submitter": "Daniel Jacob", "authors": "Daniel Jacob", "title": "Group Average Treatment Effects for Observational Studies", "comments": "Draft version", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper proposes an estimator to make inference of heterogeneous treatment\neffects sorted by impact groups (GATES) for non-randomised experiments. The\ngroups can be understood as a broader aggregation of the conditional average\ntreatment effect (CATE) where the number of groups is set in advance. In\neconomics, this approach is similar to pre-analysis plans. Observational\nstudies are standard in policy evaluation from labour markets, educational\nsurveys and other empirical studies. To control for a potential selection-bias,\nwe implement a doubly-robust estimator in the first stage. We use machine\nlearning methods to learn the conditional mean functions as well as the\npropensity score. The group average treatment effect is then estimated via a\nlinear projection model. The linear model is easy to interpret, provides\np-values and confidence intervals, and limits the danger of finding spurious\nheterogeneity due to small subgroups in the CATE. To control for confounding in\nthe linear model, we use Neyman-orthogonal moments to partial out the effect\nthat covariates have on both, the treatment assignment and the outcome. The\nresult is a best linear predictor for effect heterogeneity based on impact\ngroups. We find that our proposed method has lower absolute errors as well as\nsmaller bias than the benchmark doubly-robust estimator. We further introduce a\nbagging type averaging for the CATE function for each observation to avoid\nbiases through sample splitting. The advantage of the proposed method is a\nrobust linear estimation of heterogeneous group treatment effects in\nobservational studies.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:42:16 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 02:25:09 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 14:56:50 GMT"}, {"version": "v4", "created": "Fri, 20 Dec 2019 18:01:23 GMT"}, {"version": "v5", "created": "Fri, 27 Mar 2020 12:43:13 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Jacob", "Daniel", ""]]}, {"id": "1911.02700", "submitter": "David Wolpert", "authors": "David H. Wolpert", "title": "Uncertainty relations and fluctuation theorems for Bayes nets", "comments": "5 pages main text, 10 pages appendices, 1 figure - typos fixed from\n  earlier version", "journal-ref": "Phys. Rev. Lett. 125, 200602 (2020)", "doi": "10.1103/PhysRevLett.125.200602", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has considered the stochastic thermodynamics of multiple\ninteracting systems, representing the overall system as a Bayes net. I derive\nfluctuation theorems governing the entropy production (EP)of arbitrary sets of\nthe systems in such a Bayes net. I also derive ``conditional'' fluctuation\ntheorems, governing the distribution of EP in one set of systems conditioned on\nthe EP of a different set of systems. I then derive thermodynamic uncertainty\nrelations relating the EP of the overall system to the precisions of\nprobability currents within the individual systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:17:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 16:40:58 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 23:06:57 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 18:51:40 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 21:59:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wolpert", "David H.", ""]]}, {"id": "1911.02710", "submitter": "Craig Gin", "authors": "Craig Gin, Bethany Lusch, Steven L. Brunton, J. Nathan Kutz", "title": "Deep Learning Models for Global Coordinate Transformations that\n  Linearize PDEs", "comments": "23 pages, 18 figures", "journal-ref": null, "doi": "10.1017/S0956792520000327", "report-no": null, "categories": "math.DS cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a deep autoencoder architecture that can be used to find a\ncoordinate transformation which turns a nonlinear PDE into a linear PDE. Our\narchitecture is motivated by the linearizing transformations provided by the\nCole-Hopf transform for Burgers equation and the inverse scattering transform\nfor completely integrable PDEs. By leveraging a residual network architecture,\na near-identity transformation can be exploited to encode intrinsic coordinates\nin which the dynamics are linear. The resulting dynamics are given by a Koopman\noperator matrix $\\mathbf{K}$. The decoder allows us to transform back to the\noriginal coordinates as well. Multiple time step prediction can be performed by\nrepeated multiplication by the matrix $\\mathbf{K}$ in the intrinsic\ncoordinates. We demonstrate our method on a number of examples, including the\nheat equation and Burgers equation, as well as the substantially more\nchallenging Kuramoto-Sivashinsky equation, showing that our method provides a\nrobust architecture for discovering interpretable, linearizing transforms for\nnonlinear PDEs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:46:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gin", "Craig", ""], ["Lusch", "Bethany", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1911.02714", "submitter": "Benjamin Caulfield", "authors": "Benjamin Caulfield, Sanjit A. Seshia", "title": "Modularity in Query-Based Concept Learning", "comments": "17 pages, 4 figures, submitted to TACAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define and study the problem of modular concept learning, that is,\nlearning a concept that is a cross product of component concepts. If an\nelement's membership in a concept depends solely on it's membership in the\ncomponents, learning the concept as a whole can be reduced to learning the\ncomponents. We analyze this problem with respect to different types of oracle\ninterfaces, defining different sets of queries. If a given oracle interface\ncannot answer questions about the components, learning can be difficult, even\nwhen the components are easy to learn with the same type of oracle queries.\nWhile learning from superset queries is easy, learning from membership,\nequivalence, or subset queries is harder. However, we show that these problems\nbecome tractable when oracles are given a positive example and are allowed to\nask membership queries.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:05:25 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Caulfield", "Benjamin", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1911.02723", "submitter": "Rakhoon Hwang", "authors": "Rakhoon Hwang, Hanjin Lee, Hyung Ju Hwang", "title": "Option Compatible Reward Inverse Reinforcement Learning", "comments": "This paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in complex environments is a challenging problem. In\nparticular, the success of reinforcement learning algorithms depends on a\nwell-designed reward function. Inverse reinforcement learning (IRL) solves the\nproblem of recovering reward functions from expert demonstrations. In this\npaper, we solve a hierarchical inverse reinforcement learning problem within\nthe options framework, which allows us to utilize intrinsic motivation of the\nexpert demonstrations. A gradient method for parametrized options is used to\ndeduce a defining equation for the Q-feature space, which leads to a reward\nfeature space. Using a second-order optimality condition for option parameters,\nan optimal reward function is selected. Experimental results in both discrete\nand continuous domains confirm that our recovered rewards provide a solution to\nthe IRL problem using temporal abstraction, which in turn are effective in\naccelerating transfer learning tasks. We also show that our method is robust to\nnoises contained in expert demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:29:58 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 04:14:35 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Hwang", "Rakhoon", ""], ["Lee", "Hanjin", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "1911.02728", "submitter": "Meimei Liu", "authors": "Meimei Liu, Zhengwu Zhang and David B. Dunson", "title": "Auto-encoding brain networks with applications to analyzing large-scale\n  brain imaging datasets", "comments": "31 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been huge interest in studying human brain connectomes inferred\nfrom different imaging modalities and exploring their relationship with human\ntraits, such as cognition. Brain connectomes are usually represented as\nnetworks, with nodes corresponding to different regions of interest (ROIs) and\nedges to connection strengths between ROIs. Due to the high-dimensionality and\nnon-Euclidean nature of networks, it is challenging to depict their population\ndistribution and relate them to human traits. Current approaches focus on\nsummarizing the network using either pre-specified topological features or\nprincipal components analysis (PCA). In this paper, building on recent advances\nin deep learning, we develop a nonlinear latent factor model to characterize\nthe population distribution of brain graphs and infer the relationships between\nbrain structural connectomes and human traits. We refer to our method as Graph\nAuTo-Encoding (GATE). We applied GATE to two large-scale brain imaging\ndatasets, the Adolescent Brain Cognitive Development (ABCD) study and the Human\nConnectome Project (HCP) for adults, to understand the structural brain\nconnectome and its relationship with cognition. Numerical results demonstrate\nhuge advantages of GATE over competitors in terms of prediction accuracy,\nstatistical inference and computing efficiency. We found that structural\nconnectomes have a stronger association with a wide range of human cognitive\ntraits than was apparent using previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:51:35 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 18:38:28 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Liu", "Meimei", ""], ["Zhang", "Zhengwu", ""], ["Dunson", "David B.", ""]]}, {"id": "1911.02743", "submitter": "Ishan D Khurjekar", "authors": "Ishan D. Khurjekar and Joel B. Harley", "title": "Accounting for Physics Uncertainty in Ultrasonic Wave Propagation using\n  Deep Learning", "comments": "Second Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasonic guided waves are commonly used to localize structural damage in\ninfrastructures such as buildings, airplanes, bridges. Damage localization can\nbe viewed as an inverse problem. Physical model based techniques are popular\nfor guided wave based damage localization. The performance of these techniques\ndepend on the degree of faithfulness with which the physical model describes\nwave propagation. External factors such as environmental variations and random\nnoise are a source of uncertainty in wave propagation. The physical modeling of\nuncertainty in an inverse problem is still a challenging problem. In this work,\nwe propose a deep learning based model for robust damage localization in\npresence of uncertainty. Wave data with uncertainty is simulated to reflect\nvariations due to external factors and Gaussian noise is added to reflect\nrandom noise in the environment. After evaluating the localization error on\ntest data with uncertainty, we observe that the deep learning model trained\nwith uncertainty can learn robust representations. The approach shows potential\nfor dealing with uncertainty in physical science problems using deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:44:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Khurjekar", "Ishan D.", ""], ["Harley", "Joel B.", ""]]}, {"id": "1911.02752", "submitter": "Rocky Chen", "authors": "Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen, Wen-Chih Peng, Xue Li,\n  Xiaofang Zhou", "title": "Sequence-Aware Factorization Machines for Temporal Predictive Analytics", "comments": "To appear in ICDE'20, Dallas, Texas, USA. Code link updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various web applications like targeted advertising and recommender\nsystems, the available categorical features (e.g., product type) are often of\ngreat importance but sparse. As a widely adopted solution, models based on\nFactorization Machines (FMs) are capable of modelling high-order interactions\namong features for effective sparse predictive analytics. As the volume of\nweb-scale data grows exponentially over time, sparse predictive analytics\ninevitably involves dynamic and sequential features. However, existing FM-based\nmodels assume no temporal orders in the data, and are unable to capture the\nsequential dependencies or patterns within the dynamic features, impeding the\nperformance and adaptivity of these methods. Hence, in this paper, we propose a\nnovel Sequence-Aware Factorization Machine (SeqFM) for temporal predictive\nanalytics, which models feature interactions by fully investigating the effect\nof sequential dependencies. As static features (e.g., user gender) and dynamic\nfeatures (e.g., user interacted items) express different semantics, we\ninnovatively devise a multi-view self-attention scheme that separately models\nthe effect of static features, dynamic features and the mutual interactions\nbetween static and dynamic features in three different views. In SeqFM, we\nfurther map the learned representations of feature interactions to the desired\noutput with a shared residual network. To showcase the versatility and\ngeneralizability of SeqFM, we test SeqFM in three popular application scenarios\nfor FM-based models, namely ranking, classification and regression tasks.\nExtensive experimental results on six large-scale datasets demonstrate the\nsuperior effectiveness and efficiency of SeqFM.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 04:29:53 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 01:44:19 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Tong", ""], ["Yin", "Hongzhi", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Peng", "Wen-Chih", ""], ["Li", "Xue", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "1911.02768", "submitter": "Vitor Hadad", "authors": "Vitor Hadad, David A. Hirshberg, Ruohan Zhan, Stefan Wager, Susan\n  Athey", "title": "Confidence Intervals for Policy Evaluation in Adaptive Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive experiment designs can dramatically improve statistical efficiency\nin randomized trials, but they also complicate statistical inference. For\nexample, it is now well known that the sample mean is biased in adaptive\ntrials. Inferential challenges are exacerbated when our parameter of interest\ndiffers from the parameter the trial was designed to target, such as when we\nare interested in estimating the value of a sub-optimal treatment after running\na trial to determine the optimal treatment using a stochastic bandit design. In\nthis context, typical estimators that use inverse propensity weighting to\neliminate sampling bias can be problematic: their distributions become skewed\nand heavy-tailed as the propensity scores decay to zero. In this paper, we\npresent a class of estimators that overcome these issues. Our approach is to\nadaptively reweight the terms of an augmented inverse propensity weighting\nestimator to control the contribution of each term to the estimator's variance.\nThis adaptive weighting scheme prevents estimates from becoming heavy-tailed,\nensuring asymptotically correct coverage. It also reduces variance, allowing us\nto test hypotheses with greater power - especially hypotheses that were not\ntargeted by the experimental design. We validate the accuracy of the resulting\nestimates and their confidence intervals in numerical experiments and show our\nmethods compare favorably to existing alternatives in terms of RMSE and\ncoverage.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 06:15:52 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 17:44:37 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 18:09:03 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 20:03:50 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hadad", "Vitor", ""], ["Hirshberg", "David A.", ""], ["Zhan", "Ruohan", ""], ["Wager", "Stefan", ""], ["Athey", "Susan", ""]]}, {"id": "1911.02883", "submitter": "Elif Vural", "authors": "Yusuf Yigit Pilavci, Eylem Tugce Guneyi, Cemil Cengiz and Elif Vural", "title": "Graph Domain Adaptation with Localized Graph Signal Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a domain adaptation algorithm designed for graph\ndomains. Given a source graph with many labeled nodes and a target graph with\nfew or no labeled nodes, we aim to estimate the target labels by making use of\nthe similarity between the characteristics of the variation of the label\nfunctions on the two graphs. Our assumption about the source and the target\ndomains is that the local behaviour of the label function, such as its spread\nand speed of variation on the graph, bears resemblance between the two graphs.\nWe estimate the unknown target labels by solving an optimization problem where\nthe label information is transferred from the source graph to the target graph\nbased on the prior that the projections of the label functions onto localized\ngraph bases be similar between the source and the target graphs. In order to\nefficiently capture the local variation of the label functions on the graphs,\nspectral graph wavelets are used as the graph bases. Experimentation on various\ndata sets shows that the proposed method yields quite satisfactory\nclassification accuracy compared to reference domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:05:52 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:31:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pilavci", "Yusuf Yigit", ""], ["Guneyi", "Eylem Tugce", ""], ["Cengiz", "Cemil", ""], ["Vural", "Elif", ""]]}, {"id": "1911.02903", "submitter": "Jakob Heiss", "authors": "Jakob Heiss, Josef Teichmann, Hanna Wutte", "title": "How Implicit Regularization of ReLU Neural Networks Characterizes the\n  Learned Function -- Part I: the 1-D Case of Two Layers with Random First\n  Layer", "comments": "further generalizing training loss L, fixing typos, improving\n  formulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, various forms of neural networks are trained to perform approximation\ntasks in many fields. However, the estimates obtained are not fully understood\non function space. Empirical results suggest that typical training algorithms\nfavor regularized solutions. These observations motivate us to analyze\nproperties of the neural networks found by gradient descent initialized close\nto zero, that is frequently employed to perform the training task. As a\nstarting point, we consider one dimensional (shallow) ReLU neural networks in\nwhich weights are chosen randomly and only the terminal layer is trained.\nFirst, we rigorously show that for such networks ridge regularized regression\ncorresponds in function space to regularizing the estimate's second derivative\nfor fairly general loss functionals. For least squares regression, we show that\nthe trained network converges to the smooth spline interpolation of the\ntraining data as the number of hidden nodes tends to infinity. Moreover, we\nderive a correspondence between the early stopped gradient descent and the\nsmoothing spline regression. Our analysis might give valuable insight on the\nproperties of the solutions obtained using gradient descent methods in general\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:48:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 19:31:46 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 19:54:00 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Heiss", "Jakob", ""], ["Teichmann", "Josef", ""], ["Wutte", "Hanna", ""]]}, {"id": "1911.02922", "submitter": "Luciano Melodia", "authors": "Luciano Melodia, Richard Lenz", "title": "Persistent Homology as Stopping-Criterion for Voronoi Interpolation", "comments": "Former title: \"Persistent Homology as Stopping-Criterion for Natural\n  Neighbor Interpolation\"", "journal-ref": "Int.Worksh.Comb.Img.Ana 2020 (29-44)", "doi": "10.1007/978-3-030-51002-2_3", "report-no": null, "categories": "cs.CG cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study the Voronoi interpolation is used to interpolate a set of\npoints drawn from a topological space with higher homology groups on its\nfiltration. The technique is based on Voronoi tessellation, which induces a\nnatural dual map to the Delaunay triangulation. Advantage is taken from this\nfact calculating the persistent homology on it after each iteration to capture\nthe changing topology of the data. The boundary points are identified as\ncritical. The Bottleneck and Wasserstein distance serve as a measure of quality\nbetween the original point set and the interpolation. If the norm of two\ndistances exceeds a heuristically determined threshold, the algorithm\nterminates. We give the theoretical basis for this approach and justify its\nvalidity with numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:46:30 GMT"}, {"version": "v10", "created": "Fri, 24 Jan 2020 15:36:53 GMT"}, {"version": "v11", "created": "Thu, 5 Mar 2020 15:23:36 GMT"}, {"version": "v12", "created": "Wed, 1 Apr 2020 08:16:04 GMT"}, {"version": "v13", "created": "Mon, 8 Jun 2020 14:11:42 GMT"}, {"version": "v14", "created": "Fri, 4 Dec 2020 12:40:47 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:25:10 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 19:33:17 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 08:52:31 GMT"}, {"version": "v5", "created": "Fri, 6 Dec 2019 09:42:25 GMT"}, {"version": "v6", "created": "Tue, 10 Dec 2019 17:48:50 GMT"}, {"version": "v7", "created": "Fri, 13 Dec 2019 15:28:36 GMT"}, {"version": "v8", "created": "Fri, 27 Dec 2019 12:11:29 GMT"}, {"version": "v9", "created": "Tue, 14 Jan 2020 13:19:46 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Melodia", "Luciano", ""], ["Lenz", "Richard", ""]]}, {"id": "1911.02924", "submitter": "S. Ashwin Renganathan", "authors": "S. Ashwin Renganathan, Kohei Harada and Dimitri N. Mavris", "title": "Aerodynamic Data Fusion Towards the Digital Twin Paradigm", "comments": "33 pages, 19 figures", "journal-ref": "AIAA Journal 2020", "doi": "10.2514/1.J059203", "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the fusion of two aerodynamic data sets originating from\ndiffering fidelity physical or computer experiments. We specifically address\nthe fusion of: 1) noisy and in-complete fields from wind tunnel measurements\nand 2) deterministic but biased fields from numerical simulations. These two\ndata sources are fused in order to estimate the \\emph{true} field that best\nmatches measured quantities that serves as the ground truth. For example, two\nsources of pressure fields about an aircraft are fused based on measured forces\nand moments from a wind-tunnel experiment. A fundamental challenge in this\nproblem is that the true field is unknown and can not be estimated with 100\\%\ncertainty. We employ a Bayesian framework to infer the true fields conditioned\non measured quantities of interest; essentially we perform a \\emph{statistical\ncorrection} to the data. The fused data may then be used to construct more\naccurate surrogate models suitable for early stages of aerospace design. We\nalso introduce an extension of the Proper Orthogonal Decomposition with\nconstraints to solve the same problem. Both methods are demonstrated on fusing\nthe pressure distributions for flow past the RAE2822 airfoil and the Common\nResearch Model wing at transonic conditions. Comparison of both methods reveal\nthat the Bayesian method is more robust when data is scarce while capable of\nalso accounting for uncertainties in the data. Furthermore, given adequate\ndata, the POD based and Bayesian approaches lead to \\emph{similar} results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 02:38:48 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Renganathan", "S. Ashwin", ""], ["Harada", "Kohei", ""], ["Mavris", "Dimitri N.", ""]]}, {"id": "1911.02928", "submitter": "Mustafa Coskun", "authors": "Mustafa Coskun", "title": "Graph Convolutional Networks Meet with High Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Graph Convolutional Networks (GCNs) and their variants have been\nreceiving many research interests for learning graph-related tasks. While the\nGCNs have been successfully applied to this problem, some caveats inherited\nfrom classical deep learning still remain as open research topics in the\ncontext of the node classification problem. One such inherited caveat is that\nGCNs only consider the nodes that are a few propagations away from the labeled\nnodes to classify them. However, taking only a few propagation steps away nodes\ninto account defeats the purpose of using the graph topological information in\nthe GCNs. To remedy this problem, the-state-of-the-art methods leverage the\nnetwork diffusion approaches, namely personalized page rank and its variants,\nto fully account for the graph topology, {\\em after} they use the Neural\nNetworks in the GCNs. However, these approaches overlook the fact that the\nnetwork diffusion methods favour high degree nodes in the graph, resulting in\nthe propagation of labels to unlabeled centralized, hub, nodes. To address this\nbiasing hub nodes problem, in this paper, we propose to utilize a\ndimensionality reduction technique conjugate with personalized page rank so\nthat we can both take advantage from graph topology and resolve the hub node\nfavouring problem for GCNs. Here, our approach opens a new holistic road for\nmessage passing phase of GCNs by suggesting the usage of other proximity\nmatrices instead of well-known Laplacian. Testing on two real-world networks\nthat are commonly used in benchmarking GCNs' performance for the node\nclassification context, we systematically evaluate the performance of the\nproposed methodology and show that our approach outperforms existing methods\nfor wide ranges of parameter values with very limited deep learning training\n{\\em epochs}.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:22:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Coskun", "Mustafa", ""]]}, {"id": "1911.02933", "submitter": "Mohammad Kassem Zein", "authors": "Rema Daher, Mohammad Kassem Zein, Julia El Zini, Mariette Awad, and\n  Daniel Asmar", "title": "Change your singer: a transfer learning generative adversarial framework\n  for song to song conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Have you ever wondered how a song might sound if performed by a different\nartist? In this work, we propose SCM-GAN, an end-to-end non-parallel song\nconversion system powered by generative adversarial and transfer learning that\nallows users to listen to a selected target singer singing any song. SCM-GAN\nfirst separates songs into vocals and instrumental music using a U-Net network,\nthen converts the vocal segments to the target singer using advanced\nCycleGAN-VC, before merging the converted vocals with their corresponding\nbackground music. SCM-GAN is first initialized with feature representations\nlearned from a state-of-the-art voice-to-voice conversion and then trained on a\ndataset of non-parallel songs. Furthermore, SCM-GAN is evaluated against a set\nof metrics including global variance GV and modulation spectra MS on the 24\nMel-cepstral coefficients (MCEPs). Transfer learning improves the GV by 35% and\nthe MS by 13% on average. A subjective comparison is conducted to test the user\nsatisfaction with the quality and the naturalness of the conversion. Results\nshow above par similarity between SCM-GAN's output and the target (70\\% on\naverage) as well as great naturalness of the converted songs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:32:43 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:03:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Daher", "Rema", ""], ["Zein", "Mohammad Kassem", ""], ["Zini", "Julia El", ""], ["Awad", "Mariette", ""], ["Asmar", "Daniel", ""]]}, {"id": "1911.02961", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Yasir Latif, Ravi Garg, Vincent Gripon, Ian Reid", "title": "Improved Visual Localization via Graph Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision based localization is the problem of inferring the pose of the camera\ngiven a single image. One solution to this problem is to learn a deep neural\nnetwork to infer the pose of a query image after learning on a dataset of\nimages with known poses. Another more commonly used approach rely on image\nretrieval where the query image is compared against the database of images and\nits pose is inferred with the help of the retrieved images. The latter approach\nassumes that images taken from the same places consists of the same landmarks\nand, thus would have similar feature representations. These representation can\nbe learned using full supervision to be robust to different variations in\ncapture conditions like time of the day and weather. In this work, we introduce\na framework to enhance the performance of these retrieval based localization\nmethods by taking into account the additional information including GPS\ncoordinates and temporal neighbourhood of the images provided by the\nacquisition process in addition to the descriptor similarity of pairs of images\nin the reference or query database which is used traditionally for\nlocalization. Our method constructs a graph based on this additional\ninformation and use it for robust retrieval by smoothing the feature\nrepresentation of reference and/or query images. We show that the proposed\nmethod is able to significantly improve the localization accuracy on two large\nscale datasets over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 15:15:24 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lassance", "Carlos", ""], ["Latif", "Yasir", ""], ["Garg", "Ravi", ""], ["Gripon", "Vincent", ""], ["Reid", "Ian", ""]]}, {"id": "1911.02966", "submitter": "Vishal Anand", "authors": "Vishal Anand, S.R. Sreeja, Debasis Samanta", "title": "An automated approach for task evaluation using EEG signals", "comments": "19 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical task and cognition-based environments, such as in military and\ndefense operations, aviation user-technology interaction evaluation on UI,\nunderstanding intuitiveness of a hardware model or software toolkit, etc.\nrequire an assessment of how much a particular task is generating mental\nworkload on a user. This is necessary for understanding how those tasks,\noperations, and activities can be improvised and made better suited for the\nusers so that they reduce the mental workload on the individual and the\noperators can use them with ease and less difficulty. However, a particular\ntask can be gauged by a user as simple while for others it may be difficult.\nUnderstanding the complexity of a particular task can only be done on user\nlevel and we propose to do this by understanding the mental workload (MWL)\ngenerated on an operator while performing a task which requires processing a\nlot of information to get the task done. In this work, we have proposed an\nexperimental setup which replicates modern day workload on doing regular day\njob tasks. We propose an approach to automatically evaluate the task complexity\nperceived by an individual by using electroencephalogram (EEG) data of a user\nduring operation. Few crucial steps that are addressed in this work include\nextraction and optimization of different features and selection of relevant\nfeatures for dimensionality reduction and using supervised machine learning\ntechniques. In addition to this, performance results of the classifiers are\ncompared using all features and also using only the selected features. From the\nresults, it can be inferred that machine learning algorithms perform better as\ncompared to traditional approaches for mental workload estimation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 15:37:40 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 16:36:27 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Anand", "Vishal", ""], ["Sreeja", "S. R.", ""], ["Samanta", "Debasis", ""]]}, {"id": "1911.02970", "submitter": "Liang Ma", "authors": "Swati Rallapalli, Liang Ma, Mudhakar Srivatsa, Ananthram Swami,\n  Heesung Kwon, Graham Bent, Christopher Simpkin", "title": "SENSE: Semantically Enhanced Node Sequence Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively capturing graph node sequences in the form of vector embeddings\nis critical to many applications. We achieve this by (i) first learning vector\nembeddings of single graph nodes and (ii) then composing them to compactly\nrepresent node sequences. Specifically, we propose SENSE-S (Semantically\nEnhanced Node Sequence Embedding - for Single nodes), a skip-gram based novel\nembedding mechanism, for single graph nodes that co-learns graph structure as\nwell as their textual descriptions. We demonstrate that SENSE-S vectors\nincrease the accuracy of multi-label classification tasks by up to 50% and\nlink-prediction tasks by up to 78% under a variety of scenarios using real\ndatasets. Based on SENSE-S, we next propose generic SENSE to compute composite\nvectors that represent a sequence of nodes, where preserving the node order is\nimportant. We prove that this approach is efficient in embedding node\nsequences, and our experiments on real data confirm its high accuracy in node\norder decoding.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:21:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Rallapalli", "Swati", ""], ["Ma", "Liang", ""], ["Srivatsa", "Mudhakar", ""], ["Swami", "Ananthram", ""], ["Kwon", "Heesung", ""], ["Bent", "Graham", ""], ["Simpkin", "Christopher", ""]]}, {"id": "1911.02982", "submitter": "Max Westphal", "authors": "Max Westphal, Antonia Zapf, Werner Brannath", "title": "A multiple testing framework for diagnostic accuracy studies with\n  co-primary endpoints", "comments": "32 pages, 5 figures; v2: minor linguistic revision, no\n  content-related changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major advances have been made regarding the utilization of artificial\nintelligence in health care. In particular, deep learning approaches have been\nsuccessfully applied for automated and assisted disease diagnosis and prognosis\nbased on complex and high-dimensional data. However, despite all justified\nenthusiasm, overoptimistic assessments of predictive performance are still\ncommon. Automated medical testing devices based on machine-learned prediction\nmodels should thus undergo a throughout evaluation before being implemented\ninto clinical practice. In this work, we propose a multiple testing framework\nfor (comparative) phase III diagnostic accuracy studies with sensitivity and\nspecificity as co-primary endpoints. Our approach challenges the frequent\nrecommendation to strictly separate model selection and evaluation, i.e. to\nonly assess a single diagnostic model in the evaluation study. We show that our\nparametric simultaneous test procedure asymptotically allows strong control of\nthe family-wise error rate. Moreover, we demonstrate in extensive simulation\nstudies that our multiple testing strategy on average leads to a better final\ndiagnostic model and increased statistical power. To plan such studies, we\npropose a Bayesian approach to determine the optimal number of models to\nevaluate. For this purpose, our algorithm optimizes the expected final model\nperformance given previous (hold-out) data from the model development phase. We\nconclude that an assessment of multiple promising diagnostic models in the same\nevaluation study has several advantages when suitable adjustments for multiple\ncomparisons are implemented.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 01:58:54 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 22:38:32 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Westphal", "Max", ""], ["Zapf", "Antonia", ""], ["Brannath", "Werner", ""]]}, {"id": "1911.02991", "submitter": "Joy Bose", "authors": "Joy Bose, Sumanta Mukherjee", "title": "Semi-Supervised Method using Gaussian Random Fields for Boilerplate\n  Removal in Web Browsers", "comments": "4 pages, 1 figure, IEEE INDICON conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boilerplate removal refers to the problem of removing noisy content from a\nwebpage such as ads and extracting relevant content that can be used by various\nservices. This can be useful in several features in web browsers such as ad\nblocking, accessibility tools such as read out loud, translation, summarization\netc. In order to create a training dataset to train a model for boilerplate\ndetection and removal, labeling or tagging webpage data manually can be tedious\nand time consuming. Hence, a semi-supervised model, in which some of the\nwebpage elements are labeled manually and labels for others are inferred based\non some parameters, can be useful. In this paper we present a solution for\nextraction of relevant content from a webpage that relies on semi-supervised\nlearning using Gaussian Random Fields. We first represent the webpage as a\ngraph, with text elements as nodes and the edge weights representing similarity\nbetween nodes. After this, we label a few nodes in the graph using heuristics\nand label the remaining nodes by a weighted measure of similarity to the\nalready labeled nodes. We describe the system architecture and a few\npreliminary results on a dataset of webpages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:23:33 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bose", "Joy", ""], ["Mukherjee", "Sumanta", ""]]}, {"id": "1911.02996", "submitter": "Elijah Bolluyt", "authors": "Elijah D. Bolluyt, Cristina Comaniciu", "title": "Collapse Resistant Deep Convolutional GAN for Multi-Object Image\n  Generation", "comments": "Accepted to IEEE International Conference on Machine Learning and\n  Applications 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel system for the generation of images that contain\nmultiple classes of objects. Recent work in Generative Adversarial Networks\nhave produced high quality images, but many focus on generating images of a\nsingle object or set of objects. Our system addresses the task of image\ngeneration conditioned on a list of desired classes to be included in a single\nimage. This enables our system to generate images with any given combination of\nobjects, all composed into a visually realistic natural image. The system\nlearns the interrelationships of all classes represented in a dataset, and can\ngenerate diverse samples including a set of these classes. It displays the\nability to arrange these objects together, accounting for occlusions and\ninter-object spatial relations that characterize complex natural images. To\naccomplish this, we introduce a novel architecture based on Conditional Deep\nConvolutional GANs that is stabilized against collapse relative to both mode\nand condition. The system learns to rectify mode collapse during training,\nself-correcting to avoid suboptimal generation modes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:27:23 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bolluyt", "Elijah D.", ""], ["Comaniciu", "Cristina", ""]]}, {"id": "1911.03011", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zeyi Wen, Bingsheng He", "title": "Adaptive Kernel Value Caching for SVM Training", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "journal-ref": null, "doi": "10.1109/TNNLS.2019.2944562", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines (SVMs) can solve structured multi-output learning\nproblems such as multi-label classification, multiclass classification and\nvector regression. SVM training is expensive especially for large and high\ndimensional datasets. The bottleneck of the SVM training often lies in the\nkernel value computation. In many real-world problems, the same kernel values\nare used in many iterations during the training, which makes the caching of\nkernel values potentially useful. The majority of the existing studies simply\nadopt the LRU (least recently used) replacement strategy for caching kernel\nvalues. However, as we analyze in this paper, the LRU strategy generally\nachieves high hit ratio near the final stage of the training, but does not work\nwell in the whole training process. Therefore, we propose a new caching\nstrategy called EFU (less frequently used) which replaces the less frequently\nused kernel values that enhances LFU (least frequently used). Our experimental\nresults show that EFU often has 20\\% higher hit ratio than LRU in the training\nwith the Gaussian kernel. To further optimize the strategy, we propose a\ncaching strategy called HCST (hybrid caching for the SVM training), which has a\nnovel mechanism to automatically adapt the better caching strategy in the\ndifferent stages of the training. We have integrated the caching strategy into\nThunderSVM, a recent SVM library on many-core processors. Our experiments show\nthat HCST adaptively achieves high hit ratios with little runtime overhead\namong different problems including multi-label classification, multiclass\nclassification and regression problems. Compared with other existing caching\nstrategies, HCST achieves 20\\% more reduction in training time on average.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:06:42 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Li", "Qinbin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.03030", "submitter": "Chuan Guo", "authors": "Chuan Guo, Tom Goldstein, Awni Hannun, Laurens van der Maaten", "title": "Certified Data Removal from Machine Learning Models", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Good data stewardship requires removal of data at the request of the data's\nowner. This raises the question if and how a trained machine-learning model,\nwhich implicitly stores information about its training data, should be affected\nby such a removal request. Is it possible to \"remove\" data from a\nmachine-learning model? We study this problem by defining certified removal: a\nvery strong theoretical guarantee that a model from which data is removed\ncannot be distinguished from a model that never observed the data to begin\nwith. We develop a certified-removal mechanism for linear classifiers and\nempirically study learning settings in which this mechanism is practical.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:57:41 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 06:41:24 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 19:46:46 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 00:01:30 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 20:57:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Guo", "Chuan", ""], ["Goldstein", "Tom", ""], ["Hannun", "Awni", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1911.03034", "submitter": "Shuo Yang", "authors": "Shuo Yang, Yanyao Shen, Sujay Sanghavi", "title": "Interaction Hard Thresholding: Consistent Sparse Quadratic Regression in\n  Sub-quadratic Time and Space", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic regression involves modeling the response as a (generalized) linear\nfunction of not only the features $x^{j_1}$ but also of quadratic terms\n$x^{j_1}x^{j_2}$. The inclusion of such higher-order \"interaction terms\" in\nregression often provides an easy way to increase accuracy in\nalready-high-dimensional problems. However, this explodes the problem dimension\nfrom linear $O(p)$ to quadratic $O(p^2)$, and it is common to look for sparse\ninteractions (typically via heuristics). In this paper, we provide a new\nalgorithm - Interaction Hard Thresholding (IntHT) which is the first one to\nprovably accurately solve this problem in sub-quadratic time and space. It is a\nvariant of Iterative Hard Thresholding; one that uses the special quadratic\nstructure to devise a new way to (approx.) extract the top elements of a $p^2$\nsize gradient in sub-$p^2$ time and space. Our main result is to theoretically\nprove that, in spite of the many speedup-related approximations, IntHT linearly\nconverges to a consistent estimate under standard high-dimensional sparse\nrecovery assumptions. We also demonstrate its value via synthetic experiments.\nMoreover, we numerically show that IntHT can be extended to higher-order\nregression problems, and also theoretically analyze an SVRG variant of IntHT.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:02:38 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Yang", "Shuo", ""], ["Shen", "Yanyao", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1911.03043", "submitter": "Holden Lee", "authors": "Rong Ge, Holden Lee, Jianfeng Lu", "title": "Estimating Normalizing Constants for Log-Concave Distributions:\n  Algorithms and Lower Bounds", "comments": "46 pages", "journal-ref": "Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of\n  Computing. 2020. p. 579-586", "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the normalizing constant of an unnormalized probability\ndistribution has important applications in computer science, statistical\nphysics, machine learning, and statistics. In this work, we consider the\nproblem of estimating the normalizing constant $Z=\\int_{\\mathbb{R}^d}\ne^{-f(x)}\\,\\mathrm{d}x$ to within a multiplication factor of $1 \\pm\n\\varepsilon$ for a $\\mu$-strongly convex and $L$-smooth function $f$, given\nquery access to $f(x)$ and $\\nabla f(x)$. We give both algorithms and\nlowerbounds for this problem. Using an annealing algorithm combined with a\nmultilevel Monte Carlo method based on underdamped Langevin dynamics, we show\nthat $\\widetilde{\\mathcal{O}}\\Bigl(\\frac{d^{4/3}\\kappa +\nd^{7/6}\\kappa^{7/6}}{\\varepsilon^2}\\Bigr)$ queries to $\\nabla f$ are\nsufficient, where $\\kappa= L / \\mu$ is the condition number. Moreover, we\nprovide an information theoretic lowerbound, showing that at least\n$\\frac{d^{1-o(1)}}{\\varepsilon^{2-o(1)}}$ queries are necessary. This provides\na first nontrivial lowerbound for the problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:32:11 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 19:22:32 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Holden", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1911.03053", "submitter": "Michael Rotman", "authors": "Michael Rotman, Lior Wolf", "title": "Electric Analog Circuit Design with Hypernetworks and a Differential\n  Simulator", "comments": "The paper will be presented at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual design of analog circuits is a tedious task of parameter tuning\nthat requires hours of work by human experts. In this work, we make a\nsignificant step towards a fully automatic design method that is based on deep\nlearning. The method selects the components and their configuration, as well as\ntheir numerical parameters. By contrast, the current literature methods are\nlimited to the parameter fitting part only. A two-stage network is used, which\nfirst generates a chain of circuit components and then predicts their\nparameters. A hypernetwork scheme is used in which a weight generating network,\nwhich is conditioned on the circuit's power spectrum, produces the parameters\nof a primal RNN network that places the components. A differential simulator is\nused for refining the numerical values of the components. We show that our\nmodel provides an efficient design solution, and is superior to alternative\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:13:05 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 13:36:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Rotman", "Michael", ""], ["Wolf", "Lior", ""]]}, {"id": "1911.03054", "submitter": "Suryabhan Singh Hada", "authors": "Arman Zharmagambetov and Suryabhan Singh Hada and Miguel \\'A.\n  Carreira-Perpi\\~n\\'an and Magzhan Gabidolla", "title": "An Experimental Comparison of Old and New Decision Tree Algorithms", "comments": "12 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a detailed comparison of a recently proposed algorithm\nfor optimizing decision trees, tree alternating optimization (TAO), with other\npopular, established algorithms. We compare their performance on a number of\nclassification and regression datasets of various complexity, different size\nand dimensionality, across different performance factors: accuracy and tree\nsize (in terms of the number of leaves or the depth of the tree). We find that\nTAO achieves higher accuracy in nearly all datasets, often by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:14:48 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 01:21:47 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zharmagambetov", "Arman", ""], ["Hada", "Suryabhan Singh", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Gabidolla", "Magzhan", ""]]}, {"id": "1911.03063", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Jie Ding, Yuhong Yang", "title": "A Binary Regression Adaptive Goodness-of-fit Test (BAGofT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pearson's $\\chi^2$ test and residual deviance test are two classical\ngoodness-of-fit tests for binary regression models such as logistic regression.\nThese two tests cannot be applied when we have one or more continuous\ncovariates in the data, a quite common situation in practice. In that case, the\nmost widely used approach is the Hosmer-Lemeshow test, which partitions the\ncovariate space into groups according to quantiles of the fitted probabilities\nfrom all the observations. However, its grouping scheme is not flexible enough\nto explore how to adversarially partition the data space in order to enhance\nthe power. In this work, we propose a new methodology, named binary regression\nadaptive grouping goodness-of-fit test (BAGofT), to address the above concern.\nIt is a two-stage solution where the first stage adaptively selects candidate\npartitions using \"training\" data, and the second stage performs $\\chi^2$ tests\nwith necessary corrections based on \"test\" data. A proper data splitting\nensures that the test has desirable size and power properties. From our\nexperimental results, BAGofT performs much better than Hosmer-Lemeshow test in\nmany situations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:55:05 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Jiawei", ""], ["Ding", "Jie", ""], ["Yang", "Yuhong", ""]]}, {"id": "1911.03080", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Myriam Bontonou, Ghouthi Boukli Hacene, Vincent\n  Gripon, Jian Tang, Antonio Ortega", "title": "Deep geometric knowledge distillation with graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most cases deep learning architectures are trained disregarding the amount\nof operations and energy consumption. However, some applications, like embedded\nsystems, can be resource-constrained during inference. A popular approach to\nreduce the size of a deep learning architecture consists in distilling\nknowledge from a bigger network (teacher) to a smaller one (student). Directly\ntraining the student to mimic the teacher representation can be effective, but\nit requires that both share the same latent space dimensions. In this work, we\nfocus instead on relative knowledge distillation (RKD), which considers the\ngeometry of the respective latent spaces, allowing for dimension-agnostic\ntransfer of knowledge. Specifically we introduce a graph-based RKD method, in\nwhich graphs are used to capture the geometry of latent spaces. Using classical\ncomputer vision benchmarks, we demonstrate the ability of the proposed method\nto efficiently distillate knowledge from the teacher to the student, leading to\nbetter accuracy for the same budget as compared to existing RKD alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:42:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lassance", "Carlos", ""], ["Bontonou", "Myriam", ""], ["Hacene", "Ghouthi Boukli", ""], ["Gripon", "Vincent", ""], ["Tang", "Jian", ""], ["Ortega", "Antonio", ""]]}, {"id": "1911.03082", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, Partha Talukdar", "title": "Composition-based Multi-Relational Graph Convolutional Networks", "comments": "In Proceedings of ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have recently been shown to be quite\nsuccessful in modeling graph-structured data. However, the primary focus has\nbeen on handling simple undirected graphs. Multi-relational graphs are a more\ngeneral and prevalent form of graphs where each edge has a label and direction\nassociated with it. Most of the existing approaches to handle such graphs\nsuffer from over-parameterization and are restricted to learning\nrepresentations of nodes only. In this paper, we propose CompGCN, a novel Graph\nConvolutional framework which jointly embeds both nodes and relations in a\nrelational graph. CompGCN leverages a variety of entity-relation composition\noperations from Knowledge Graph Embedding techniques and scales with the number\nof relations. It also generalizes several of the existing multi-relational GCN\nmethods. We evaluate our proposed method on multiple tasks such as node\nclassification, link prediction, and graph classification, and achieve\ndemonstrably superior results. We make the source code of CompGCN available to\nfoster reproducible research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:48:40 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 22:50:01 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Sanyal", "Soumya", ""], ["Nitin", "Vikram", ""], ["Talukdar", "Partha", ""]]}, {"id": "1911.03105", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Unified Sample-Optimal Property Estimation in Near-Linear Time", "comments": "Appeared at NeurIPS 2019. Fixed a few typos and minor issues in\n  corner cases", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental learning problem of estimating properties of\ndistributions over large domains. Using a novel piecewise-polynomial\napproximation technique, we derive the first unified methodology for\nconstructing sample- and time-efficient estimators for all sufficiently smooth,\nsymmetric and non-symmetric, additive properties. This technique yields\nnear-linear-time computable estimators whose approximation values are\nasymptotically optimal and highly-concentrated, resulting in the first: 1)\nestimators achieving the $\\mathcal{O}(k/(\\varepsilon^2\\log k))$ min-max\n$\\varepsilon$-error sample complexity for all $k$-symbol Lipschitz properties;\n2) unified near-optimal differentially private estimators for a variety of\nproperties; 3) unified estimator achieving optimal bias and near-optimal\nvariance for five important properties; 4) near-optimal sample-complexity\nestimators for several important symmetric properties over both domain sizes\nand confidence levels. In addition, we establish a McDiarmid's inequality under\nPoisson sampling, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:46:47 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 17:43:02 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1911.03117", "submitter": "Matthieu Heitz", "authors": "Matthieu Heitz, Nicolas Bonneel, David Coeurjolly, Marco Cuturi,\n  Gabriel Peyr\\'e", "title": "Ground Metric Learning on Graphs", "comments": "Fixed sign of gradient", "journal-ref": "Journal of Mathematical Imaging and Vision (2020): 1-19", "doi": "10.1007/s10851-020-00996-z", "report-no": null, "categories": "stat.ML cs.GR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) distances between probability distributions are\nparameterized by the ground metric they use between observations. Their\nrelevance for real-life applications strongly hinges on whether that ground\nmetric parameter is suitably chosen. Selecting it adaptively and\nalgorithmically from prior knowledge, the so-called ground metric learning GML)\nproblem, has therefore appeared in various settings. We consider it in this\npaper when the learned metric is constrained to be a geodesic distance on a\ngraph that supports the measures of interest. This imposes a rich structure for\ncandidate metrics, but also enables far more efficient learning procedures when\ncompared to a direct optimization over the space of all metric matrices. We use\nthis setting to tackle an inverse problem stemming from the observation of a\ndensity evolving with time: we seek a graph ground metric such that the OT\ninterpolation between the starting and ending densities that result from that\nground metric agrees with the observed evolution. This OT dynamic framework is\nrelevant to model natural phenomena exhibiting displacements of mass, such as\nfor instance the evolution of the color palette induced by the modification of\nlighting and materials.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:27:19 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 12:14:11 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 15:17:39 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Heitz", "Matthieu", ""], ["Bonneel", "Nicolas", ""], ["Coeurjolly", "David", ""], ["Cuturi", "Marco", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1911.03183", "submitter": "Erik-Jan van Kesteren", "authors": "Erik-Jan van Kesteren, Chang Sun, Daniel L. Oberski, Michel Dumontier,\n  Lianne Ippel", "title": "Privacy-Preserving Generalized Linear Models using Distributed Block\n  Coordinate Descent", "comments": "Fully reproducible code for all results and images can be found at\n  https://github.com/vankesteren/privacy-preserving-glm, and the software\n  package can be found at https://github.com/vankesteren/privreg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining data from varied sources has considerable potential for knowledge\ndiscovery: collaborating data parties can mine data in an expanded feature\nspace, allowing them to explore a larger range of scientific questions.\nHowever, data sharing among different parties is highly restricted by legal\nconditions, ethical concerns, and / or data volume. Fueled by these concerns,\nthe fields of cryptography and distributed learning have made great progress\ntowards privacy-preserving and distributed data mining. However, practical\nimplementations have been hampered by the limited scope or computational\ncomplexity of these methods. In this paper, we greatly extend the range of\nanalyses available for vertically partitioned data, i.e., data collected by\nseparate parties with different features on the same subjects. To this end, we\npresent a novel approach for privacy-preserving generalized linear models, a\nfundamental and powerful framework underlying many prediction and\nclassification procedures. We base our method on a distributed block coordinate\ndescent algorithm to obtain parameter estimates, and we develop an extension to\ncompute accurate standard errors without additional communication cost. We\ncritically evaluate the information transfer for semi-honest collaborators and\nshow that our protocol is secure against data reconstruction. Through both\nsimulated and real-world examples we illustrate the functionality of our\nproposed algorithm. Without leaking information, our method performs as well on\nvertically partitioned data as existing methods on combined data -- all within\nmere minutes of computation time. We conclude that our method is a viable\napproach for vertically partitioned data analysis with a wide range of\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 11:07:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["van Kesteren", "Erik-Jan", ""], ["Sun", "Chang", ""], ["Oberski", "Daniel L.", ""], ["Dumontier", "Michel", ""], ["Ippel", "Lianne", ""]]}, {"id": "1911.03219", "submitter": "Nicolas Lair", "authors": "Nicolas Lair, C\\'edric Colas, R\\'emy Portelas, Jean-Michel Dussoux,\n  Peter Ford Dominey, Pierre-Yves Oudeyer", "title": "Language Grounding through Social Interactions and Curiosity-Driven\n  Multi-Goal Learning", "comments": "NeurIPS 2019 Workshop ViGIL : Visually Grounded Interaction and\n  Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous reinforcement learning agents, like children, do not have access\nto predefined goals and reward functions. They must discover potential goals,\nlearn their own reward functions and engage in their own learning trajectory.\nChildren, however, benefit from exposure to language, helping to organize and\nmediate their thought. We propose LE2 (Language Enhanced Exploration), a\nlearning algorithm leveraging intrinsic motivations and natural language (NL)\ninteractions with a descriptive social partner (SP). Using NL descriptions from\nthe SP, it can learn an NL-conditioned reward function to formulate goals for\nintrinsically motivated goal exploration and learn a goal-conditioned policy.\nBy exploring, collecting descriptions from the SP and jointly learning the\nreward function and the policy, the agent grounds NL descriptions into real\nbehavioral goals. From simple goals discovered early to more complex goals\ndiscovered by experimenting on simpler ones, our agent autonomously builds its\nown behavioral repertoire. This naturally occurring curriculum is supplemented\nby an active learning curriculum resulting from the agent's intrinsic\nmotivations. Experiments are presented with a simulated robotic arm that\ninteracts with several objects including tools.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:42:22 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lair", "Nicolas", ""], ["Colas", "C\u00e9dric", ""], ["Portelas", "R\u00e9my", ""], ["Dussoux", "Jean-Michel", ""], ["Dominey", "Peter Ford", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1911.03221", "submitter": "Valentin Thorey", "authors": "Antoine Guillot, Fabien Sauvet, Emmanuel H During and Valentin Thorey", "title": "Dreem Open Datasets: Multi-Scored Sleep Datasets to compare Human and\n  Automated sleep staging", "comments": "10 pages, journal submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep stage classification constitutes an important element of sleep disorder\ndiagnosis. It relies on the visual inspection of polysomnography records by\ntrained sleep technologists. Automated approaches have been designed to\nalleviate this resource-intensive task. However, such approaches are usually\ncompared to a single human scorer annotation despite an inter-rater agreement\nof about 85 % only. The present study introduces two publicly-available\ndatasets, DOD-H including 25 healthy volunteers and DOD-O including 55 patients\nsuffering from obstructive sleep apnea (OSA). Both datasets have been scored by\n5 sleep technologists from different sleep centers. We developed a framework to\ncompare automated approaches to a consensus of multiple human scorers. Using\nthis framework, we benchmarked and compared the main literature approaches. We\nalso developed and benchmarked a new deep learning method, SimpleSleepNet,\ninspired by current state-of-the-art. We demonstrated that many methods can\nreach human-level performance on both datasets. SimpleSleepNet achieved an F1\nof 89.9 % vs 86.8 % on average for human scorers on DOD-H, and an F1 of 88.3 %\nvs 84.8 % on DOD-O. Our study highlights that using state-of-the-art automated\nsleep staging outperforms human scorers performance for healthy volunteers and\npatients suffering from OSA. Consideration could be made to use automated\napproaches in the clinical setting.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:12:43 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 17:21:23 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 16:53:12 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 09:45:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Guillot", "Antoine", ""], ["Sauvet", "Fabien", ""], ["During", "Emmanuel H", ""], ["Thorey", "Valentin", ""]]}, {"id": "1911.03222", "submitter": "Valentin Vielzeuf", "authors": "Valentin Vielzeuf, Alexis Lechervy, St\\'ephane Pateux, Fr\\'ed\\'eric\n  Jurie", "title": "Towards a General Model of Knowledge for Facial Analysis by Multi-Source\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a step toward obtaining general models of knowledge for\nfacial analysis, by addressing the question of multi-source transfer learning.\nMore precisely, the proposed approach consists in two successive training\nsteps: the first one consists in applying a combination operator to define a\ncommon embedding for the multiple sources materialized by different existing\ntrained models. The proposed operator relies on an auto-encoder, trained on a\nlarge dataset, efficient both in terms of compression ratio and transfer\nlearning performance. In a second step we exploit a distillation approach to\nobtain a lightweight student model mimicking the collection of the fused\nexisting models. This model outperforms its teacher on novel tasks, achieving\nresults on par with state-of-the-art methods on 15 facial analysis tasks (and\ndomains), at an affordable training cost. Moreover, this student has 75 times\nless parameters than the original teacher and can be applied to a variety of\nnovel face-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:47:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Vielzeuf", "Valentin", ""], ["Lechervy", "Alexis", ""], ["Pateux", "St\u00e9phane", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1911.03224", "submitter": "Zachary del Rosario", "authors": "Zachary del Rosario and Matthias Rupp and Yoolhee Kim and Erin Antono\n  and Julia Ling", "title": "Assessing the Frontier: Active Learning, Model Accuracy, and\n  Multi-objective Materials Discovery and Optimization", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering novel materials can be greatly accelerated by iterative machine\nlearning-informed proposal of candidates---active learning. However, standard\n\\emph{global-scope error} metrics for model quality are not predictive of\ndiscovery performance, and can be misleading. We introduce the notion of\n\\emph{Pareto shell-scope error} to help judge the suitability of a model for\nproposing material candidates. Further, through synthetic cases and a\nthermoelectric dataset, we probe the relation between acquisition function\nfidelity and active learning performance. Results suggest novel diagnostic\ntools, as well as new insights for acquisition function design.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:24:35 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 22:42:41 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 18:06:43 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["del Rosario", "Zachary", ""], ["Rupp", "Matthias", ""], ["Kim", "Yoolhee", ""], ["Antono", "Erin", ""], ["Ling", "Julia", ""]]}, {"id": "1911.03249", "submitter": "Tomas Kliegr", "authors": "Tom\\'a\\v{s} Kliegr, \\v{S}t\\v{e}p\\'an Bahn\\'ik, Johannes F\\\"urnkranz", "title": "Advances in Machine Learning for the Behavioral Sciences", "comments": null, "journal-ref": "American Behavioral Scientist 64.2 (2020): 145-175", "doi": "10.1177/0002764219859639", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The areas of machine learning and knowledge discovery in databases have\nconsiderably matured in recent years. In this article, we briefly review recent\ndevelopments as well as classical algorithms that stood the test of time. Our\ngoal is to provide a general introduction into different tasks such as learning\nfrom tabular data, behavioral data, or textual data, with a particular focus on\nactual and potential applications in behavioral sciences. The supplemental\nappendix to the article also provides practical guidance for using the methods\nby pointing the reader to proven software implementations. The focus is on R,\nbut we also cover some libraries in other programming languages as well as\nsystems with easy-to-use graphical interfaces.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:30:21 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kliegr", "Tom\u00e1\u0161", ""], ["Bahn\u00edk", "\u0160t\u011bp\u00e1n", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1911.03264", "submitter": "Ali Taleb Zadeh Kasgari", "authors": "Ali Taleb Zadeh Kasgari, Walid Saad, Mohammad Mozaffari, H. Vincent\n  Poor", "title": "Experienced Deep Reinforcement Learning with Generative Adversarial\n  Networks (GANs) for Model-Free Ultra Reliable Low Latency Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel experienced deep reinforcement learning (deep-RL)\nframework is proposed to provide model-free resource allocation for ultra\nreliable low latency communication (URLLC). The proposed, experienced deep-RL\nframework can guarantee high end-to-end reliability and low end-to-end latency,\nunder explicit data rate constraints, for each wireless without any models of\nor assumptions on the users' traffic. In particular, in order to enable the\ndeep-RL framework to account for extreme network conditions and operate in\nhighly reliable systems, a new approach based on generative adversarial\nnetworks (GANs) is proposed. This GAN approach is used to pre-train the deep-RL\nframework using a mix of real and synthetic data, thus creating an experienced\ndeep-RL framework that has been exposed to a broad range of network conditions.\nFormally, the URLLC resource allocation problem is posed as a power\nminimization problem under reliability, latency, and rate constraints. To solve\nthis problem using experienced deep-RL, first, the rate of each user is\ndetermined. Then, these rates are mapped to the resource block and power\nallocation vectors of the studied wireless system. Finally, the end-to-end\nreliability and latency of each user are used as feedback to the deep-RL\nframework. It is then shown that at the fixed-point of the deep-RL algorithm,\nthe reliability and latency of the users are near-optimal. Moreover, for the\nproposed GAN approach, a theoretical limit for the generator output is\nanalytically derived. Simulation results show how the proposed approach can\nachieve near-optimal performance within the rate-reliability-latency region,\ndepending on the network and service requirements. The results also show that\nthe proposed experienced deep-RL framework is able to remove the transient\ntraining time that makes conventional deep-RL methods unsuitable for URLLC.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:50:48 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 01:23:10 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Kasgari", "Ali Taleb Zadeh", ""], ["Saad", "Walid", ""], ["Mozaffari", "Mohammad", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1911.03274", "submitter": "Xavier Renard", "authors": "Vincent Ballet, Xavier Renard, Jonathan Aigrain, Thibault Laugel,\n  Pascal Frossard, Marcin Detyniecki", "title": "Imperceptible Adversarial Attacks on Tabular Data", "comments": "presented at NeurIPS 2019 Workshop on Robust AI in Financial\n  Services: Data, Fairness, Explainability, Trustworthiness, and Privacy\n  (Robust AI in FS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of machine learning models is a concern as they may face adversarial\nattacks for unwarranted advantageous decisions. While research on the topic has\nmainly been focusing on the image domain, numerous industrial applications, in\nparticular in finance, rely on standard tabular data. In this paper, we discuss\nthe notion of adversarial examples in the tabular domain. We propose a\nformalization based on the imperceptibility of attacks in the tabular domain\nleading to an approach to generate imperceptible adversarial examples.\nExperiments show that we can generate imperceptible adversarial examples with a\nhigh fooling rate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:14:11 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 11:15:29 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ballet", "Vincent", ""], ["Renard", "Xavier", ""], ["Aigrain", "Jonathan", ""], ["Laugel", "Thibault", ""], ["Frossard", "Pascal", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.03295", "submitter": "Mohammad Taha Bahadori", "authors": "Mohammad Taha Bahadori and Layne C. Price", "title": "Discovering Invariances in Healthcare Neural Networks", "comments": "The extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the invariance characteristics of pre-trained predictive models by\nempirically learning transformations on the input that leave the prediction\nfunction approximately unchanged. To learn invariant transformations, we\nminimize the Wasserstein distance between the predictive distribution\nconditioned on the data instances and the predictive distribution conditioned\non the transformed data instances. To avoid finding degenerate or perturbative\ntransformations, we add a similarity regularization to discourage similarity\nbetween the data and its transformed values. We theoretically analyze the\ncorrectness of the algorithm and the structure of the solutions. Applying the\nproposed technique to clinical time series data, we discover variables that\ncommonly-used LSTM models do not rely on for their prediction, especially when\nthe LSTM is trained to be adversarially robust. We also analyze the invariances\nof BioBERT on clinical notes and discover words that it is invariant to.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:48:05 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:40:38 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 18:00:06 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Bahadori", "Mohammad Taha", ""], ["Price", "Layne C.", ""]]}, {"id": "1911.03299", "submitter": "Hankui Peng", "authors": "Hankui Peng, Nicos G. Pavlidis", "title": "Subspace Clustering with Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is a growing field of unsupervised learning that has\ngained much popularity in the computer vision community. Applications can be\nfound in areas such as motion segmentation and face clustering. It assumes that\ndata originate from a union of subspaces, and clusters the data depending on\nthe corresponding subspace. In practice, it is reasonable to assume that a\nlimited amount of labels can be obtained, potentially at a cost. Therefore,\nalgorithms that can effectively and efficiently incorporate this information to\nimprove the clustering model are desirable. In this paper, we propose an active\nlearning framework for subspace clustering that sequentially queries\ninformative points and updates the subspace model. The query stage of the\nproposed framework relies on results from the perturbation theory of principal\ncomponent analysis, to identify influential and potentially misclassified\npoints. A constrained subspace clustering algorithm is proposed that\nmonotonically decreases the objective function subject to the constraints\nimposed by the labelled data. We show that our proposed framework is suitable\nfor subspace clustering algorithms including iterative methods and spectral\nmethods. Experiments on synthetic data sets, motion segmentation data sets, and\nYale Faces data sets demonstrate the advantage of our proposed active strategy\nover state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:54:45 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:00:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Peng", "Hankui", ""], ["Pavlidis", "Nicos G.", ""]]}, {"id": "1911.03306", "submitter": "Bahram Mohammadi", "authors": "Mohammed Gharib, Bahram Mohammadi, Shadi Hejareh Dastgerdi, Mohammad\n  Sabokrou", "title": "AutoIDS: Auto-encoder Based Method for Intrusion Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion Detection System (IDS) is one of the most effective solutions for\nproviding primary security services. IDSs are generally working based on attack\nsignatures or by detecting anomalies. In this paper, we have presented AutoIDS,\na novel yet efficient solution for IDS, based on a semi-supervised machine\nlearning technique. AutoIDS can distinguish abnormal packet flows from normal\nones by taking advantage of cascading two efficient detectors. These detectors\nare two encoder-decoder neural networks that are forced to provide a compressed\nand a sparse representation from the normal flows. In the test phase, failing\nthese neural networks on providing compressed or sparse representation from an\nincoming packet flow, means such flow does not comply with the normal traffic\nand thus it is considered as an intrusion. For lowering the computational cost\nalong with preserving the accuracy, a large number of flows are just processed\nby the first detector. In fact, the second detector is only used for difficult\nsamples which the first detector is not confident about them. We have evaluated\nAutoIDS on the NSL-KDD benchmark as a widely-used and well-known dataset. The\naccuracy of AutoIDS is 90.17\\% showing its superiority compared to the other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:03:31 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gharib", "Mohammed", ""], ["Mohammadi", "Bahram", ""], ["Dastgerdi", "Shadi Hejareh", ""], ["Sabokrou", "Mohammad", ""]]}, {"id": "1911.03308", "submitter": "Matt Benatan", "authors": "Matt Benatan and Edward O. Pyzer-Knapp", "title": "Fully Bayesian Recurrent Neural Networks for Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has demonstrated state-of-the-art results in a\nnumber of autonomous system applications, however many of the underlying\nalgorithms rely on black-box predictions. This results in poor explainability\nof the behaviour of these systems, raising concerns as to their use in\nsafety-critical applications. Recent work has demonstrated that\nuncertainty-aware models exhibit more cautious behaviours through the\nincorporation of model uncertainty estimates. In this work, we build on\nProbabilistic Backpropagation to introduce a fully Bayesian Recurrent Neural\nNetwork architecture. We apply this within a Safe RL scenario, and demonstrate\nthat the proposed method significantly outperforms a popular approach for\nobtaining model uncertainties in collision avoidance tasks. Furthermore, we\ndemonstrate that the proposed approach requires less training and is far more\nefficient than the current leading method, both in terms of compute resource\nand memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:08:51 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 11:36:03 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Benatan", "Matt", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "1911.03314", "submitter": "Xiaying Wang", "authors": "Xiaying Wang, Michele Magno, Lukas Cavigelli and Luca Benini", "title": "FANN-on-MCU: An Open-Source Toolkit for Energy-Efficient Neural Network\n  Inference at the Edge of the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing number of low-power smart devices in the Internet of Things is\ncoupled with the concept of \"Edge Computing\", that is moving some of the\nintelligence, especially machine learning, towards the edge of the network.\nEnabling machine learning algorithms to run on resource-constrained hardware,\ntypically on low-power smart devices, is challenging in terms of hardware\n(optimized and energy-efficient integrated circuits), algorithmic and firmware\nimplementations. This paper presents FANN-on-MCU, an open-source toolkit built\nupon the Fast Artificial Neural Network (FANN) library to run lightweight and\nenergy-efficient neural networks on microcontrollers based on both the ARM\nCortex-M series and the novel RISC-V-based Parallel Ultra-Low-Power (PULP)\nplatform. The toolkit takes multi-layer perceptrons trained with FANN and\ngenerates code targeted at execution on low-power microcontrollers either with\na floating-point unit (i.e., ARM Cortex-M4F and M7F) or without (i.e., ARM\nCortex M0-M3 or PULP-based processors). This paper also provides an\narchitectural performance evaluation of neural networks on the most popular ARM\nCortex-M family and the parallel RISC-V processor called Mr. Wolf. The\nevaluation includes experimental results for three different applications using\na self-sustainable wearable multi-sensor bracelet. Experimental results show a\nmeasured latency in the order of only a few microseconds and a power\nconsumption of few milliwatts while keeping the memory requirements below the\nlimitations of the targeted microcontrollers. In particular, the parallel\nimplementation on the octa-core RISC-V platform reaches a speedup of 22x and a\n69% reduction in energy consumption with respect to a single-core\nimplementation on Cortex-M4 for continuous real-time classification.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:14:50 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 19:01:22 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wang", "Xiaying", ""], ["Magno", "Michele", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1911.03318", "submitter": "Zhanhong Jiang", "authors": "Zhanhong Jiang and Young M. Lee", "title": "Deep Transfer Learning for Thermal Dynamics Modeling in Smart Buildings", "comments": "5 pages, 2 figures; Accepted at 2019 IEEE International Conference on\n  Big Data (IEEE BigData 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal dynamics modeling has been a critical issue in building heating,\nventilation, and air-conditioning (HVAC) systems, which can significantly\naffect the control and maintenance strategies. Due to the uniqueness of each\nspecific building, traditional thermal dynamics modeling approaches heavily\ndepending on physics knowledge cannot generalize well. This study proposes a\ndeep supervised domain adaptation (DSDA) method for thermal dynamics modeling\nof building indoor temperature evolution and energy consumption. A long short\nterm memory network based Sequence to Sequence scheme is pre-trained based on a\nlarge amount of data collected from a building and then adapted to another\nbuilding which has a limited amount of data by applying the model fine-tuning.\nWe use four publicly available datasets: SML and AHU for temperature evolution,\nlong-term datasets from two different commercial buildings, termed as Building\n1 and Building 2 for energy consumption. We show that the deep supervised\ndomain adaptation is effective to adapt the pre-trained model from one building\nto another building and has better predictive performance than learning from\nscratch with only a limited amount of data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:19:33 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Zhanhong", ""], ["Lee", "Young M.", ""]]}, {"id": "1911.03336", "submitter": "Carlos Ruiz", "authors": "Andr\\'es M. Alonso, F. Javier Nogales and Carlos Ruiz", "title": "Hierarchical Clustering for Smart Meter Electricity Loads based on\n  Quantile Autocovariances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to improve the efficiency and sustainability of electricity systems,\nmost countries worldwide are deploying advanced metering infrastructures, and\nin particular household smart meters, in the residential sector. This\ntechnology is able to record electricity load time series at a very high\nfrequency rates, information that can be exploited to develop new clustering\nmodels to group individual households by similar consumptions patterns. To this\nend, in this work we propose three hierarchical clustering methodologies that\nallow capturing different characteristics of the time series. These are based\non a set of \"dissimilarity\" measures computed over different features: quantile\nauto-covariances, and simple and partial autocorrelations. The main advantage\nis that they allow summarizing each time series in a few representative\nfeatures so that they are computationally efficient, robust against outliers,\neasy to automatize, and scalable to hundreds of thousands of smart meters\nseries. We evaluate the performance of each clustering model in a real-world\nsmart meter dataset with thousands of half-hourly time series. The results show\nhow the obtained clusters identify relevant consumption behaviors of households\nand capture part of their geo-demographic segmentation. Moreover, we apply a\nsupervised classification procedure to explore which features are more relevant\nto define each cluster.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:47:34 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Alonso", "Andr\u00e9s M.", ""], ["Nogales", "F. Javier", ""], ["Ruiz", "Carlos", ""]]}, {"id": "1911.03347", "submitter": "Juri Opitz", "authors": "Juri Opitz and Sebastian Burst", "title": "Macro F1 and Macro F1", "comments": "6 pages (+ appendix), 6 figures, fixed typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'macro F1' metric is frequently used to evaluate binary, multi-class and\nmulti-label classification problems. Yet, we find that there exist two\ndifferent formulas to calculate this quantity. In this note, we show that only\nunder rare circumstances the two computations can be considered equivalent.\nMore specifically, one formula well 'rewards' classifiers which produce a\nskewed error type distribution. In fact, the difference in outcome of the two\ncomputations can be as high as 0.5. The two computations may not only diverge\nin their scalar result but can also lead to different classifier rankings.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:13:54 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 09:24:02 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 18:20:55 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Opitz", "Juri", ""], ["Burst", "Sebastian", ""]]}, {"id": "1911.03362", "submitter": "Nikolay Bogoychev Dr", "authors": "Nikolay Bogoychev and Rico Sennrich", "title": "Domain, Translationese and Noise in Synthetic Data for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of neural machine translation can be improved by leveraging\nadditional monolingual resources to create synthetic training data. Source-side\nmonolingual data can be (forward-)translated into the target language for\nself-training; target-side monolingual data can be back-translated. It has been\nwidely reported that back-translation delivers superior results, but could this\nbe due to artefacts in the test sets? We perform a case study using\nFrench-English news translation task and separate test sets based on their\noriginal languages. We show that forward translation delivers superior gains in\nterms of BLEU on sentences that were originally in the source language,\ncomplementing previous studies which show large improvements with\nback-translation on sentences that were originally in the target language. To\nbetter understand when and why forward and back-translation are effective, we\nstudy the role of domains, translationese, and noise. While translationese\neffects are well known to influence MT evaluation, we also find evidence that\nnews data from different languages shows subtle domain differences, which is\nanother explanation for varying performance on different portions of the test\nset. We perform additional low-resource experiments which demonstrate that\nforward translation is more sensitive to the quality of the initial translation\nsystem than back-translation, and tends to perform worse in low-resource\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:30:57 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 17:14:02 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bogoychev", "Nikolay", ""], ["Sennrich", "Rico", ""]]}, {"id": "1911.03366", "submitter": "Ankita Tondwalkar", "authors": "Ankita Tondwalkar and Dr Andres Kwasinski", "title": "Deep Reinforcement Learning for Distributed Uncoordinated Cognitive\n  Radios Resource Allocation", "comments": "This paper has been submitted in the 21st IEEE International Workshop\n  On Signal Processing Advances In Wireless Communications (SPAWC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep reinforcement learning-based resource\nallocation technique for the multi-agent environment presented by a cognitive\nradio network that coexists through underlay dynamic spectrum access (DSA) with\na primary network. The resource allocation technique presented in this work is\ndistributed, not requiring coordination with other agents. The presented\nalgorithm is the first deep reinforcement learning technique for which\nconvergence to equilibrium policies can be shown in the non-stationary\nmulti-agent environment that results from the uncoordinated dynamic interaction\nbetween radios through the shared wireless environment. Moreover, simulation\nresults show that in a finite learning time the presented technique is able to\nfind policies that yield performance within 3 % of an exhaustive search\nsolution, finding the optimal policy in nearly 70 % of cases. Moreover, it is\nshown that standard single-agent deep reinforcement learning may not achieve\nconvergence when used in a non-coordinated, coupled multi-radio scenario.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 20:19:37 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 16:54:41 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Tondwalkar", "Ankita", ""], ["Kwasinski", "Dr Andres", ""]]}, {"id": "1911.03393", "submitter": "Yuge Shi", "authors": "Yuge Shi, N. Siddharth, Brooks Paige, Philip H.S. Torr", "title": "Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning generative models that span multiple data modalities, such as vision\nand language, is often motivated by the desire to learn more useful,\ngeneralisable representations that faithfully capture common underlying factors\nbetween the modalities. In this work, we characterise successful learning of\nsuch models as the fulfillment of four criteria: i) implicit latent\ndecomposition into shared and private subspaces, ii) coherent joint generation\nover all modalities, iii) coherent cross-generation across individual\nmodalities, and iv) improved model learning for individual modalities through\nmulti-modal integration. Here, we propose a mixture-of-experts multimodal\nvariational autoencoder (MMVAE) to learn generative models on different sets of\nmodalities, including a challenging image-language dataset, and demonstrate its\nability to satisfy all four criteria, both qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:18:57 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Shi", "Yuge", ""], ["Siddharth", "N.", ""], ["Paige", "Brooks", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1911.03405", "submitter": "Mario Diaz", "authors": "Mario Diaz and Peter Kairouz and Jiachun Liao and Lalitha Sankar", "title": "Theoretical Guarantees for Model Auditing with Finite Adversaries", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns have led to the development of privacy-preserving approaches\nfor learning models from sensitive data. Yet, in practice, even models learned\nwith privacy guarantees can inadvertently memorize unique training examples or\nleak sensitive features. To identify such privacy violations, existing model\nauditing techniques use finite adversaries defined as machine learning models\nwith (a) access to some finite side information (e.g., a small auditing\ndataset), and (b) finite capacity (e.g., a fixed neural network architecture).\nOur work investigates the requirements under which an unsuccessful attempt to\nidentify privacy violations by a finite adversary implies that no stronger\nadversary can succeed at such a task. We do so via parameters that quantify the\ncapabilities of the finite adversary, including the size of the neural network\nemployed by such an adversary and the amount of side information it has access\nto as well as the regularity of the (perhaps privacy-guaranteeing) audited\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:39:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Diaz", "Mario", ""], ["Kairouz", "Peter", ""], ["Liao", "Jiachun", ""], ["Sankar", "Lalitha", ""]]}, {"id": "1911.03409", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Sundeep Rangan, Philip\n  Schniter, Alyson K. Fletcher", "title": "Inference with Deep Generative Priors in High Dimensions", "comments": "50 pages, double-spaced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative priors offer powerful models for complex-structured data,\nsuch as images, audio, and text. Using these priors in inverse problems\ntypically requires estimating the input and/or hidden signals in a multi-layer\ndeep neural network from observation of its output. While these approaches have\nbeen successful in practice, rigorous performance analysis is complicated by\nthe non-convex nature of the underlying optimization problems. This paper\npresents a novel algorithm, Multi-Layer Vector Approximate Message Passing\n(ML-VAMP), for inference in multi-layer stochastic neural networks. ML-VAMP can\nbe configured to compute maximum a priori (MAP) or approximate minimum\nmean-squared error (MMSE) estimates for these networks. We show that the\nperformance of ML-VAMP can be exactly predicted in a certain high-dimensional\nrandom limit. Furthermore, under certain conditions, ML-VAMP yields estimates\nthat achieve the minimum (i.e., Bayes-optimal) MSE as predicted by the replica\nmethod. In this way, ML-VAMP provides a computationally efficient method for\nmulti-layer inference with an exact performance characterization and testable\nconditions for optimality in the large-system limit.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:54:10 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Rangan", "Sundeep", ""], ["Schniter", "Philip", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "1911.03417", "submitter": "Claire Donnat", "authors": "Claire Donnat, Susan Holmes", "title": "Convex Hierarchical Clustering for Graph-Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex clustering is a recent stable alternative to hierarchical clustering.\nIt formulates the recovery of progressively coalescing clusters as a\nregularized convex problem. While convex clustering was originally designed for\nhandling Euclidean distances between data points, in a growing number of\napplications, the data is directly characterized by a similarity matrix or\nweighted graph. In this paper, we extend the robust hierarchical clustering\napproach to these broader classes of similarities. Having defined an\nappropriate convex objective, the crux of this adaptation lies in our ability\nto provide: (a) an efficient recovery of the regularization path and (b) an\nempirical demonstration of the use of our method. We address the first\nchallenge through a proximal dual algorithm, for which we characterize both the\ntheoretical efficiency as well as the empirical performance on a set of\nexperiments. Finally, we highlight the potential of our method by showing its\napplication to several real-life datasets, thus providing a natural extension\nto the current scope of applications of convex clustering.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:08:21 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 00:00:38 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Donnat", "Claire", ""], ["Holmes", "Susan", ""]]}, {"id": "1911.03432", "submitter": "Akshay Mehra", "authors": "Akshay Mehra and Jihun Hamm", "title": "Penalty Method for Inversion-Free Deep Bilevel Optimization", "comments": "22 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization problems are at the center of several important machine\nlearning problems such as hyperparameter tuning, data denoising, meta- and\nfew-shot learning, and training-data poisoning. Different from simultaneous or\nmulti-objective optimization, the steepest descent direction for minimizing the\nupper-level cost requires the inverse of the Hessian of the lower-level cost.\nIn this paper, we propose a new method for solving bilevel optimization\nproblems using the classical penalty function approach which avoids computing\nthe inverse and can also handle additional constraints easily. We prove the\nconvergence of the method under mild conditions and show that the exact\nhypergradient is obtained asymptotically. Our method's simplicity and small\nspace and time complexities enable us to effectively solve large-scale bilevel\nproblems involving deep neural networks. We present results on data denoising,\nfew-shot learning, and training-data poisoning problems in a large scale\nsetting and show that our method outperforms or is comparable to previously\nproposed methods based on automatic differentiation and approximate inversion\nin terms of accuracy, run-time and convergence speed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:33:29 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 05:29:39 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 14:34:59 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 18:42:21 GMT"}, {"version": "v5", "created": "Sun, 28 Jun 2020 17:45:39 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mehra", "Akshay", ""], ["Hamm", "Jihun", ""]]}, {"id": "1911.03443", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Liu Yang and Rudrasis Chakraborty", "title": "An \"augmentation-free\" rotation invariant classification scheme on\n  point-cloud and its application to neuroimaging", "comments": "arXiv admin note: text overlap with arXiv:1910.13050 and\n  arXiv:1911.01705", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence and increasing popularity of 3D\nmedical imaging techniques with the development of 3D sensors and technology.\nHowever, achieving geometric invariance in the processing of 3D medical images\nis computationally expensive but nonetheless essential due to the presence of\npossible errors caused by rigid registration techniques. An alternative way to\nanalyze medical imaging is by understanding the 3D shapes represented in terms\nof point-cloud. Though in the medical imaging community, 3D point-cloud\nprocessing is not a \"go-to\" choice, it is a canonical way to preserve rotation\ninvariance. Unfortunately, due to the presence of discrete topology, one can\nnot use the standard convolution operator on point-cloud. To the best of our\nknowledge, the existing ways to do \"convolution\" can not preserve the rotation\ninvariance without explicit data augmentation. Therefore, we propose a rotation\ninvariant convolution operator by inducing topology from hypersphere.\nExperimental validation has been performed on publicly available OASIS dataset\nin terms of classification accuracy between subjects with (without) dementia,\ndemonstrating the usefulness of our proposed method in terms of model\ncomplexity, classification accuracy, and last but most important invariance to\nrotations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:45:56 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Yang", "Liu", ""], ["Chakraborty", "Rudrasis", ""]]}, {"id": "1911.03459", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo and Byoung-Tak Zhang", "title": "Ruminating Word Representations with Random Noised Masker", "comments": "AAAI ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a training method for both better word representation and\nperformance, which we call GROVER (Gradual Rumination On the Vector with\nmaskERs). The method is to gradually and iteratively add random noises to word\nembeddings while training a model. GROVER first starts from conventional\ntraining process, and then extracts the fine-tuned representations. Next, we\ngradually add random noises to the word representations and repeat the training\nprocess from scratch, but initialize with the noised word representations.\nThrough the re-training process, we can mitigate some noises to be compensated\nand utilize other noises to learn better representations. As a result, we can\nget word representations further fine-tuned and specialized on the task. When\nwe experiment with our method on 5 text classification datasets, our method\nimproves model performances on most of the datasets. Moreover, we show that our\nmethod can be combined with other regularization techniques, further improving\nthe model performance.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:23:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jo", "Hwiyeol", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1911.03508", "submitter": "Jason Cheuk Nam Liang", "authors": "Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang", "title": "Incentive-aware Contextual Pricing with Non-parametric Market Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a dynamic pricing problem for repeated contextual second-price\nauctions with strategic buyers whose goals are to maximize their long-term time\ndiscounted utility. The seller has very limited information about buyers'\noverall demand curves, which depends on $d$-dimensional context vectors\ncharacterizing auctioned items, and a non-parametric market noise distribution\nthat captures buyers' idiosyncratic tastes. The noise distribution and the\nrelationship between the context vectors and buyers' demand curves are both\nunknown to the seller. We focus on designing the seller's learning policy to\nset contextual reserve prices where the seller's goal is to minimize his regret\nfor revenue. We first propose a pricing policy when buyers are truthful and\nshow that it achieves a $T$-period regret bound of\n$\\tilde{\\mathcal{O}}(\\sqrt{dT})$ against a clairvoyant policy that has full\ninformation of the buyers' demand. Next, under the setting where buyers bid\nstrategically to maximize their long-term discounted utility, we develop a\nvariant of our first policy that is robust to strategic (corrupted) bids. This\npolicy incorporates randomized \"isolation\" periods, during which a buyer is\nrandomly chosen to solely participate in the auction. We show that this design\nallows the seller to control the number of periods in which buyers\nsignificantly corrupt their bids. Because of this nice property, our robust\npolicy enjoys a $T$-period regret of $\\tilde{\\mathcal{O}}(\\sqrt{dT})$, matching\nthat under the truthful setting up to a constant factor that depends on the\nutility discount factor.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:20:36 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 02:28:33 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Golrezaei", "Negin", ""], ["Jaillet", "Patrick", ""], ["Liang", "Jason Cheuk Nam", ""]]}, {"id": "1911.03522", "submitter": "Ignacio Peis", "authors": "Ignacio Peis, Pablo M. Olmos, Constanza Vera-Varela, Mar\\'ia Luisa\n  Barrig\\'on, Philippe Courtet, Enrique Baca-Garc\\'ia and Antonio\n  Art\\'es-Rodr\\'iguez", "title": "Deep Sequential Models for Suicidal Ideation from Multiple Source Data", "comments": "Accepted for publication in IEEE Journal of Biomedical and Health\n  Informatics (JBHI)", "journal-ref": "Journal of Biomedical and Health Informatics, vol.23, no. 6, 2019", "doi": "10.1109/JBHI.2019.2919270", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article presents a novel method for predicting suicidal ideation from\nElectronic Health Records (EHR) and Ecological Momentary Assessment (EMA) data\nusing deep sequential models. Both EHR longitudinal data and EMA question forms\nare defined by asynchronous, variable length, randomly-sampled data sequences.\nIn our method, we model each of them with a Recurrent Neural Network (RNN), and\nboth sequences are aligned by concatenating the hidden state of each of them\nusing temporal marks. Furthermore, we incorporate attention schemes to improve\nperformance in long sequences and time-independent pre-trained schemes to cope\nwith very short sequences. Using a database of 1023 patients, our experimental\nresults show that the addition of EMA records boosts the system recall to\npredict the suicidal ideation diagnosis from 48.13% obtained exclusively from\nEHR-based state-of-the-art methods to 67.78%. Additionally, our method provides\ninterpretability through the t-SNE representation of the latent space. Further,\nthe most relevant input features are identified and interpreted medically.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:55:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Peis", "Ignacio", ""], ["Olmos", "Pablo M.", ""], ["Vera-Varela", "Constanza", ""], ["Barrig\u00f3n", "Mar\u00eda Luisa", ""], ["Courtet", "Philippe", ""], ["Baca-Garc\u00eda", "Enrique", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "1911.03539", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Viet Anh Nguyen and Soroosh Shafieezadeh-Abadeh and Daniel Kuhn and\n  Peyman Mohajerin Esfahani", "title": "Bridging Bayesian and Minimax Mean Square Error Estimation via\n  Wasserstein Distributionally Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a distributionally robust minimium mean square error estimation\nmodel with a Wasserstein ambiguity set to recover an unknown signal from a\nnoisy observation. The proposed model can be viewed as a zero-sum game between\na statistician choosing an estimator -- that is, a measurable function of the\nobservation -- and a fictitious adversary choosing a prior -- that is, a pair\nof signal and noise distributions ranging over independent Wasserstein balls --\nwith the goal to minimize and maximize the expected squared estimation error,\nrespectively. We show that if the Wasserstein balls are centered at normal\ndistributions, then the zero-sum game admits a Nash equilibrium, where the\nplayers' optimal strategies are given by an {\\em affine} estimator and a {\\em\nnormal} prior, respectively. We further prove that this Nash equilibrium can be\ncomputed by solving a tractable convex program. Finally, we develop a\nFrank-Wolfe algorithm that can solve this convex program orders of magnitude\nfaster than state-of-the-art general purpose solvers. We show that this\nalgorithm enjoys a linear convergence rate and that its direction-finding\nsubproblems can be solved in quasi-closed form.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 21:10:25 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 10:00:16 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""], ["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "1911.03548", "submitter": "Dushyant Sahoo", "authors": "Soham Dan and Dushyant Sahoo", "title": "Variance Reduced Stochastic Proximal Algorithm for AUC Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent has been widely studied with classification\naccuracy as a performance measure. However, these stochastic algorithms cannot\nbe directly used when non-decomposable pairwise performance measures are used\nsuch as Area under the ROC curve (AUC) which is a common performance metric\nwhen the classes are imbalanced. There have been several algorithms proposed\nfor optimizing AUC as a performance metric, and one of the recent being a\nstochastic proximal gradient algorithm (SPAM). But the downside of the\nstochastic methods is that they suffer from high variance leading to slower\nconvergence. To combat this issue, several variance reduced methods have been\nproposed with faster convergence guarantees than vanilla stochastic gradient\ndescent. Again, these variance reduced methods are not directly applicable when\nnon-decomposable performance measures are used. In this paper, we develop a\nVariance Reduced Stochastic Proximal algorithm for AUC Maximization\n(\\textsc{VRSPAM}) and perform a theoretical analysis as well as empirical\nanalysis to show that our algorithm converges faster than SPAM which is the\nprevious state-of-the-art for the AUC maximization problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 21:23:20 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 16:45:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Dan", "Soham", ""], ["Sahoo", "Dushyant", ""]]}, {"id": "1911.03572", "submitter": "Mohit Goyal", "authors": "Mohit Goyal, Kedar Tatwawadi, Shubham Chandak, Idoia Ochoa", "title": "DZip: improved general-purpose lossless compression based on novel\n  neural network modeling", "comments": "Updated manuscript and an efficient implementation added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider lossless compression based on statistical data modeling followed\nby prediction-based encoding, where an accurate statistical model for the input\ndata leads to substantial improvements in compression. We propose DZip, a\ngeneral-purpose compressor for sequential data that exploits the well-known\nmodeling capabilities of neural networks (NNs) for prediction, followed by\narithmetic coding. Dzip uses a novel hybrid architecture based on adaptive and\nsemi-adaptive training. Unlike most NN based compressors, DZip does not require\nadditional training data and is not restricted to specific data types, only\nneeding the alphabet size of the input data. The proposed compressor\noutperforms general-purpose compressors such as Gzip (on average 26% reduction)\non a variety of real datasets, achieves near-optimal compression on synthetic\ndatasets, and performs close to specialized compressors for large sequence\nlengths, without any human input. The main limitation of DZip in its current\nimplementation is the encoding/decoding time, which limits its practicality.\nNevertheless, the results showcase the potential of developing improved\ngeneral-purpose compressors based on neural networks and hybrid modeling.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:50:02 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 17:58:10 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Goyal", "Mohit", ""], ["Tatwawadi", "Kedar", ""], ["Chandak", "Shubham", ""], ["Ochoa", "Idoia", ""]]}, {"id": "1911.03577", "submitter": "Gabriel Peyr\\'e", "authors": "Clarice Poon and Gabriel Peyr\\'e", "title": "Degrees of freedom for off-the-grid sparse estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question in modern machine learning and imaging sciences is to\nquantify the number of effective parameters of vastly over-parameterized\nmodels. The degrees of freedom is a mathematically convenient way to define\nthis number of parameters. Its computation and properties are well understood\nwhen dealing with discretized linear models, possibly regularized using\nsparsity. In this paper, we argue that this way of thinking is plagued when\ndealing with models having very large parameter spaces. In this case it makes\nmore sense to consider \"off-the-grid\" approaches, using a continuous parameter\nspace. This type of approach is the one favoured when training multi-layer\nperceptrons, and is also becoming popular to solve super-resolution problems in\nimaging. Training these off-the-grid models with a sparsity inducing prior can\nbe achieved by solving a convex optimization problem over the space of\nmeasures, which is often called the Beurling Lasso (Blasso), and is the\ncontinuous counterpart of the celebrated Lasso parameter selection method. In\nprevious works, the degrees of freedom for the Lasso was shown to coincide with\nthe size of the smallest solution support. Our main contribution is a proof of\na continuous counterpart to this result for the Blasso. Our findings suggest\nthat discretized methods actually vastly over-estimate the number of intrinsic\ncontinuous degrees of freedom. Our second contribution is a detailed study of\nthe case of sampling Fourier coefficients in 1D, which corresponds to a\nsuper-resolution problem. We show that our formula for the degrees of freedom\nis valid outside of a set of measure zero of observations, which in turn\njustifies its use to compute an unbiased estimator of the prediction risk using\nthe Stein Unbiased Risk Estimator (SURE).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:29:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Poon", "Clarice", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1911.03583", "submitter": "Guixiang Ma", "authors": "Jiahao Liu, Guixiang Ma, Fei Jiang, Chun-Ta Lu, Philip S. Yu, Ann B.\n  Ragin", "title": "Community-preserving Graph Convolutions for Structural and Functional\n  Joint Embedding of Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain networks have received considerable attention given the critical\nsignificance for understanding human brain organization, for investigating\nneurological disorders and for clinical diagnostic applications. Structural\nbrain network (e.g. DTI) and functional brain network (e.g. fMRI) are the\nprimary networks of interest. Most existing works in brain network analysis\nfocus on either structural or functional connectivity, which cannot leverage\nthe complementary information from each other. Although multi-view learning\nmethods have been proposed to learn from both networks (or views), these\nmethods aim to reach a consensus among multiple views, and thus distinct\nintrinsic properties of each view may be ignored. How to jointly learn\nrepresentations from structural and functional brain networks while preserving\ntheir inherent properties is a critical problem. In this paper, we propose a\nframework of Siamese community-preserving graph convolutional network (SCP-GCN)\nto learn the structural and functional joint embedding of brain networks.\nSpecifically, we use graph convolutions to learn the structural and functional\njoint embedding, where the graph structure is defined with structural\nconnectivity and node features are from the functional connectivity. Moreover,\nwe propose to preserve the community structure of brain networks in the graph\nconvolutions by considering the intra-community and inter-community properties\nin the learning process. Furthermore, we use Siamese architecture which models\nthe pair-wise similarity learning to guide the learning process. To evaluate\nthe proposed approach, we conduct extensive experiments on two real brain\nnetwork datasets. The experimental results demonstrate the superior performance\nof the proposed approach in structural and functional joint embedding for\nneurological disorder analysis, indicating its promising value for clinical\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:47:34 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Jiahao", ""], ["Ma", "Guixiang", ""], ["Jiang", "Fei", ""], ["Lu", "Chun-Ta", ""], ["Yu", "Philip S.", ""], ["Ragin", "Ann B.", ""]]}, {"id": "1911.03584", "submitter": "Jean-Baptiste Cordonnier", "authors": "Jean-Baptiste Cordonnier, Andreas Loukas, Martin Jaggi", "title": "On the Relationship between Self-Attention and Convolutional Layers", "comments": "To appear at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent trends of incorporating attention mechanisms in vision have led\nresearchers to reconsider the supremacy of convolutional layers as a primary\nbuilding block. Beyond helping CNNs to handle long-range dependencies,\nRamachandran et al. (2019) showed that attention can completely replace\nconvolution and achieve state-of-the-art performance on vision tasks. This\nraises the question: do learned attention layers operate similarly to\nconvolutional layers? This work provides evidence that attention layers can\nperform convolution and, indeed, they often learn to do so in practice.\nSpecifically, we prove that a multi-head self-attention layer with sufficient\nnumber of heads is at least as expressive as any convolutional layer. Our\nnumerical experiments then show that self-attention layers attend to pixel-grid\npatterns similarly to CNN layers, corroborating our analysis. Our code is\npublicly available.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:48:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:06:09 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Loukas", "Andreas", ""], ["Jaggi", "Martin", ""]]}, {"id": "1911.03594", "submitter": "Florian Golemo", "authors": "Maxime Chevalier-Boisvert, Guillaume Alain, Florian Golemo, Derek\n  Nowrouzezahrai", "title": "Robo-PlaNet: Learning to Poke in a Day", "comments": "4 pages, 3 figures. Version 2: added reference and acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Deep Planning Network (PlaNet) approach was introduced as a\nmodel-based reinforcement learning method that learns environment dynamics\ndirectly from pixel observations. This architecture is useful for learning\ntasks in which either the agent does not have access to meaningful states (like\nposition/velocity of robotic joints) or where the observed states significantly\ndeviate from the physical state of the agent (which is commonly the case in\nlow-cost robots in the form of backlash or noisy joint readings). PlaNet, by\ndesign, interleaves phases of training the dynamics model with phases of\ncollecting more data on the target environment, leading to long training times.\nIn this work, we introduce Robo-PlaNet, an asynchronous version of PlaNet. This\nalgorithm consistently reaches higher performance in the same amount of time,\nwhich we demonstrate in both a simulated and a real robotic experiment.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 02:05:18 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 23:12:39 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chevalier-Boisvert", "Maxime", ""], ["Alain", "Guillaume", ""], ["Golemo", "Florian", ""], ["Nowrouzezahrai", "Derek", ""]]}, {"id": "1911.03605", "submitter": "Justin Chen", "authors": "Justin Y. Chen, Gregory Valiant, Paul Valiant", "title": "Worst-Case Analysis for Randomly Collected Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for statistical estimation that leverages knowledge\nof how samples are collected but makes no distributional assumptions on the\ndata values. Specifically, we consider a population of elements\n$[n]={1,\\ldots,n}$ with corresponding data values $x_1,\\ldots,x_n$. We observe\nthe values for a \"sample\" set $A \\subset [n]$ and wish to estimate some\nstatistic of the values for a \"target\" set $B \\subset [n]$ where $B$ could be\nthe entire set. Crucially, we assume that the sets $A$ and $B$ are drawn\naccording to some known distribution $P$ over pairs of subsets of $[n]$. A\ngiven estimation algorithm is evaluated based on its \"worst-case, expected\nerror\" where the expectation is with respect to the distribution $P$ from which\nthe sample $A$ and target sets $B$ are drawn, and the worst-case is with\nrespect to the data values $x_1,\\ldots,x_n$. Within this framework, we give an\nefficient algorithm for estimating the target mean that returns a weighted\ncombination of the sample values--where the weights are functions of the\ndistribution $P$ and the sample and target sets $A$, $B$--and show that the\nworst-case expected error achieved by this algorithm is at most a\nmultiplicative $\\pi/2$ factor worse than the optimal of such algorithms. The\nalgorithm and proof leverage a surprising connection to the Grothendieck\nproblem. This framework, which makes no distributional assumptions on the data\nvalues but rather relies on knowledge of the data collection process, is a\nsignificant departure from typical estimation and introduces a uniform\nalgorithmic analysis for the many natural settings where membership in a sample\nmay be correlated with data values, such as when sampling probabilities vary as\nin \"importance sampling\", when individuals are recruited into a sample via a\nsocial network as in \"snowball sampling\", or when samples have chronological\nstructure as in \"selective prediction\".\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 03:35:14 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:05:01 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chen", "Justin Y.", ""], ["Valiant", "Gregory", ""], ["Valiant", "Paul", ""]]}, {"id": "1911.03620", "submitter": "Hossein Esfandiari", "authors": "Hossein Esfandiari, Amin Karbasi, Vahab Mirrokni", "title": "Adaptivity in Adaptive Submodularity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive sequential decision making is one of the central challenges in\nmachine learning and artificial intelligence. In such problems, the goal is to\ndesign an interactive policy that plans for an action to take, from a finite\nset of $n$ actions, given some partial observations. It has been shown that in\nmany applications such as active learning, robotics, sequential experimental\ndesign, and active detection, the utility function satisfies adaptive\nsubmodularity, a notion that generalizes the notion of diminishing returns to\npolicies. In this paper, we revisit the power of adaptivity in maximizing an\nadaptive monotone submodular function. We propose an efficient semi adaptive\npolicy that with $O(\\log n \\times\\log k)$ adaptive rounds of observations can\nachieve an almost tight $1-1/e-\\epsilon$ approximation guarantee with respect\nto an optimal policy that carries out $k$ actions in a fully sequential manner.\nTo complement our results, we also show that it is impossible to achieve a\nconstant factor approximation with $o(\\log n)$ adaptive rounds. We also extend\nour result to the case of adaptive stochastic minimum cost coverage where the\ngoal is to reach a desired utility $Q$ with the cheapest policy. We first prove\nthe conjecture of the celebrated work of Golovin and Krause by showing that the\ngreedy policy achieves the asymptotically tight logarithmic approximation\nguarantee without resorting to stronger notions of adaptivity. We then propose\na semi adaptive policy that provides the same guarantee in polylogarithmic\nadaptive rounds through a similar information-parallelism scheme. Our results\nshrink the adaptivity gap in adaptive submodular maximization by an exponential\nfactor.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:31:14 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 06:32:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Esfandiari", "Hossein", ""], ["Karbasi", "Amin", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1911.03642", "submitter": "Andrew Gaut", "authors": "Andrew Gaut, Tony Sun, Shirlyn Tang, Yuxin Huang, Jing Qian, Mai\n  ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, William\n  Yang Wang", "title": "Towards Understanding Gender Bias in Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Neural Relation Extraction (NRE) have made significant\nstrides towards Automated Knowledge Base Construction (AKBC). While much\nattention has been dedicated towards improvements in accuracy, there have been\nno attempts in the literature to our knowledge to evaluate social biases in NRE\nsystems. We create WikiGenderBias, a distantly supervised dataset with a human\nannotated test set. WikiGenderBias has sentences specifically curated to\nanalyze gender bias in relation extraction systems. We use WikiGenderBias to\nevaluate systems for bias and find that NRE systems exhibit gender biased\npredictions and lay groundwork for future evaluation of bias in NRE. We also\nanalyze how name anonymization, hard debiasing for word embeddings, and\ncounterfactual data augmentation affect gender bias in predictions and\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 08:43:02 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 22:38:12 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 23:59:54 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gaut", "Andrew", ""], ["Sun", "Tony", ""], ["Tang", "Shirlyn", ""], ["Huang", "Yuxin", ""], ["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Zhao", "Jieyu", ""], ["Mirza", "Diba", ""], ["Belding", "Elizabeth", ""], ["Chang", "Kai-Wei", ""], ["Wang", "William Yang", ""]]}, {"id": "1911.03645", "submitter": "Ondrej \\v{S}uch", "authors": "Ondrej \\v{S}uch, Peter Tar\\'abek, Katar\\'ina Bachrat\\'a, Andrea\n  Tinajov\\'a", "title": "Pairwise coupling of convolutional neural networks for better\n  explicability of classification systems", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine several aspects of explicability of a classification system built\nfrom neural networks. The first aspect is the pairwise explicability, which is\nthe ability to provide the most accurate prediction when the range of\npossibilities is narrowed to just two. Next we consider explicability in\ndevelopment, which means ability to make incremental improvement in prediction\naccuracy based on observed deficiency of the system. Inherent stochasticity of\nneural network based classifiers can be interpreted using likelihood randomness\nexplicability. Finally, sureness explicability indicates confidence of the\nclassifying system to make any prediction at all.\n  These concepts are examined in the framework of pairwise coupling, which is a\nnon-trainable metamodel that originated during development of support vector\nmachines. Several methodologies are evaluated, of which the key one is shown to\nbe the choice of the pairwise coupling method. We compare two methods: the\nestablished Wu-Lin-Weng method with the recently proposed Bayes covariant\nmethod. Our experiments indicate that the Wu-Lin-Weng method gives more weight\nto a single pairwise classifier, whereas the latter tries to balance\ninformation from the whole matrix of pairwise likelihoods. This translates into\nhigher accuracy, and better sureness predictions for the Bayes covariant\nmethod.\n  Pairwise coupling methodology has its costs, especially in terms of the\nnumber of parameters (but not necessarily in terms of training costs). However,\nwhen additional explicability aspects beyond accuracy are desired in an\napplication, the pairwise coupling models are a promising alternative to the\nestablished methodology.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 09:28:10 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["\u0160uch", "Ondrej", ""], ["Tar\u00e1bek", "Peter", ""], ["Bachrat\u00e1", "Katar\u00edna", ""], ["Tinajov\u00e1", "Andrea", ""]]}, {"id": "1911.03653", "submitter": "Alberto Redondo", "authors": "Alberto Redondo and David Rios Insua", "title": "Protecting from Malware Obfuscation Attacks through Adversarial Risk\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware constitutes a major global risk affecting millions of users each\nyear. Standard algorithms in detection systems perform insufficiently when\ndealing with malware passed through obfuscation tools. We illustrate this\nstudying in detail an open source metamorphic software, making use of a hybrid\nframework to obtain the relevant features from binaries. We then provide an\nimproved alternative solution based on adversarial risk analysis which we\nillustrate describe with an example.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:02:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Redondo", "Alberto", ""], ["Insua", "David Rios", ""]]}, {"id": "1911.03654", "submitter": "Anis Elgabli", "authors": "Anis Elgabli, Jihong Park, Sabbir Ahmed, and Mehdi Bennis", "title": "L-FGADMM: Layer-Wise Federated Group ADMM for Communication Efficient\n  Decentralized Deep Learning", "comments": "6 pages; 4 figures; presented at IEEE WCNC'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a communication-efficient decentralized deep learning\nalgorithm, coined layer-wise federated group ADMM (L-FGADMM). To minimize an\nempirical risk, every worker in L-FGADMM periodically communicates with two\nneighbors, in which the periods are separately adjusted for different layers of\nits deep neural network. A constrained optimization problem for this setting is\nformulated and solved using the stochastic version of GADMM proposed in our\nprior work. Numerical evaluations show that by less frequently exchanging the\nlargest layer, L-FGADMM can significantly reduce the communication cost,\nwithout compromising the convergence speed. Surprisingly, despite less\nexchanged information and decentralized operations, intermittently skipping the\nlargest layer consensus in L-FGADMM creates a regularizing effect, thereby\nachieving the test accuracy as high as federated learning (FL), a baseline\nmethod with the entire layer consensus by the aid of a central entity.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:03:21 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 09:33:25 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Ahmed", "Sabbir", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1911.03658", "submitter": "Magda Friedjungov\\'a", "authors": "Magda Friedjungov\\'a, Daniel Va\\v{s}ata, Marcel Ji\\v{r}ina", "title": "Missing Features Reconstruction and Its Impact on Classification\n  Accuracy", "comments": "Preprint of the conference paper (ICCS 2019), part of the Lecture\n  Notes in Computer Science", "journal-ref": "Computational Science - ICCS 2019. ICCS 2019. Lecture Notes in\n  Computer Science 11538 (2019) 207-220", "doi": "10.1007/978-3-030-22744-9_16", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, we can encounter situations when a well-trained\nmodel has to be used to predict from a damaged dataset. The damage caused by\nmissing or corrupted values can be either on the level of individual instances\nor on the level of entire features. Both situations have a negative impact on\nthe usability of the model on such a dataset. This paper focuses on the\nscenario where entire features are missing which can be understood as a\nspecific case of transfer learning. Our aim is to experimentally research the\ninfluence of various imputation methods on the performance of several\nclassification models. The imputation impact is researched on a combination of\ntraditional methods such as k-NN, linear regression, and MICE compared to\nmodern imputation methods such as multi-layer perceptron (MLP) and gradient\nboosted trees (XGBT). For linear regression, MLP, and XGBT we also propose two\napproaches to using them for multiple features imputation. The experiments were\nperformed on both real world and artificial datasets with continuous features\nwhere different numbers of features, varying from one feature to 50%, were\nmissing. The results show that MICE and linear regression are generally good\nimputers regardless of the conditions. On the other hand, the performance of\nMLP and XGBT is strongly dataset dependent. Their performance is the best in\nsome cases, but more often they perform worse than MICE or linear regression.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:37:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Friedjungov\u00e1", "Magda", ""], ["Va\u0161ata", "Daniel", ""], ["Ji\u0159ina", "Marcel", ""]]}, {"id": "1911.03667", "submitter": "Satyajit Neogi", "authors": "Satyajit Neogi, Justin Dauwels", "title": "Factored Latent-Dynamic Conditional Random Fields for Single and\n  Multi-label Sequence Modeling", "comments": "To be submitted to Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Random Fields (CRF) are frequently applied for labeling and\nsegmenting sequence data. Morency et al. (2007) introduced hidden state\nvariables in a labeled CRF structure in order to model the latent dynamics\nwithin class labels, thus improving the labeling performance. Such a model is\nknown as Latent-Dynamic CRF (LDCRF). We present Factored LDCRF (FLDCRF), a\nstructure that allows multiple latent dynamics of the class labels to interact\nwith each other. Including such latent-dynamic interactions leads to improved\nlabeling performance on single-label and multi-label sequence modeling tasks.\nWe apply our FLDCRF models on two single-label (one nested cross-validation)\nand one multi-label sequence tagging (nested cross-validation) experiments\nacross two different datasets - UCI gesture phase data and UCI opportunity\ndata. FLDCRF outperforms all state-of-the-art sequence models, i.e., CRF,\nLDCRF, LSTM, LSTM-CRF, Factorial CRF, Coupled CRF and a multi-label LSTM model\nin all our experiments. In addition, LSTM based models display inconsistent\nperformance across validation and test data, and pose diffculty to select\nmodels on validation data during our experiments. FLDCRF offers easier model\nselection, consistency across validation and test performance and lucid model\nintuition. FLDCRF is also much faster to train compared to LSTM, even without a\nGPU. FLDCRF outshines the best LSTM model by ~4% on a single-label task on UCI\ngesture phase data and outperforms LSTM performance by ~2% on average across\nnested cross-validation test sets on the multi-label sequence tagging\nexperiment on UCI opportunity data. The idea of FLDCRF can be extended to joint\n(multi-agent interactions) and heterogeneous (discrete and continuous) state\nspace models.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 11:16:42 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:56:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Neogi", "Satyajit", ""], ["Dauwels", "Justin", ""]]}, {"id": "1911.03671", "submitter": "Kota Matsui", "authors": "Kota Matsui, Shunya Kusakawa, Keisuke Ando, Kentaro Kutsukake, Toru\n  Ujihara, Ichiro Takeuchi", "title": "Bayesian Active Learning for Structured Output Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an active learning method for an inverse problem\nthat aims to find an input that achieves a desired structured-output. The\nproposed method provides new acquisition functions for minimizing the error\nbetween the desired structured-output and the prediction of a Gaussian process\nmodel, by effectively incorporating the correlation between multiple outputs of\nthe underlying multi-valued black box output functions. The effectiveness of\nthe proposed method is verified by applying it to two synthetic shape search\nproblem and real data. In the real data experiment, we tackle the input\nparameter search which achieves the desired crystal growth rate in silicon\ncarbide (SiC) crystal growth modeling, that is a problem of materials\ninformatics.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 11:39:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Matsui", "Kota", ""], ["Kusakawa", "Shunya", ""], ["Ando", "Keisuke", ""], ["Kutsukake", "Kentaro", ""], ["Ujihara", "Toru", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1911.03674", "submitter": "Kommy Weldemariam Dr", "authors": "Samuel C. Maina, Reginald E. Bryant, William O. Goal, Robert-Florian\n  Samoilescu, Kush R. Varshney, Komminist Weldemariam", "title": "Preservation of Anomalous Subgroups On Machine Learning Transformed Data", "comments": "5 pages, 3 figures, 2 tables, submitted to icassp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the effect of machine learning based\nanonymization on anomalous subgroup preservation. In particular, we train a\nbinary classifier to discover the most anomalous subgroup in a dataset by\nmaximizing the bias between the group's predicted odds ratio from the model and\nobserved odds ratio from the data. We then perform anonymization using a\nvariational autoencoder (VAE) to synthesize an entirely new dataset that would\nideally be drawn from the distribution of the original data. We repeat the\nanomalous subgroup discovery task on the new data and compare it to what was\nidentified pre-anonymization. We evaluated our approach using publicly\navailable datasets from the financial industry. Our evaluation confirmed that\nthe approach was able to produce synthetic datasets that preserved a high level\nof subgroup differentiation as identified initially in the original dataset.\nSuch a distinction was maintained while having distinctly different records\nbetween the synthetic and original dataset. Finally, we packed the above end to\nend process into what we call Utility Guaranteed Deep Privacy (UGDP) system.\nUGDP can be easily extended to onboard alternative generative approaches such\nas GANs to synthesize tabular data.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:09:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Maina", "Samuel C.", ""], ["Bryant", "Reginald E.", ""], ["Goal", "William O.", ""], ["Samoilescu", "Robert-Florian", ""], ["Varshney", "Kush R.", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "1911.03698", "submitter": "Alice Coucke", "authors": "St\\'ephane d'Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre\n  Caulier, Marc Lelarge", "title": "Conditioned Query Generation for Task-Oriented Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of training data for task-oriented dialogue systems is a well known\nproblem that is usually tackled with costly and time-consuming manual data\nannotation. An alternative solution is to rely on automatic text generation\nwhich, although less accurate than human supervision, has the advantage of\nbeing cheap and fast. In this paper we propose a novel controlled data\ngeneration method that could be used as a training augmentation framework for\nclosed-domain dialogue. Our contribution is twofold. First we show how to\noptimally train and control the generation of intent-specific sentences using a\nconditional variational autoencoder. Then we introduce a novel protocol called\nquery transfer that allows to leverage a broad, unlabelled dataset to extract\nrelevant information. Comparison with two different baselines shows that our\nmethod, in the appropriate regime, consistently improves the diversity of the\ngenerated queries without compromising their quality.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 14:22:57 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Coucke", "Alice", ""], ["Caltagirone", "Francesco", ""], ["Caulier", "Alexandre", ""], ["Lelarge", "Marc", ""]]}, {"id": "1911.03722", "submitter": "Junjie Li", "authors": "Junjie Li, Ding Liu", "title": "Information Bottleneck Theory on Convolutional Neural Networks", "comments": "7 pages,28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years, many researches attempt to open the black box of deep neural\nnetworks and propose a various of theories to understand it. Among them,\nInformation Bottleneck (IB) theory claims that there are two distinct phases\nconsisting of fitting phase and compression phase in the course of training.\nThis statement attracts many attentions since its success in explaining the\ninner behavior of feedforward neural networks. In this paper, we employ IB\ntheory to understand the dynamic behavior of convolutional neural networks\n(CNNs) and investigate how the fundamental features such as convolutional layer\nwidth, kernel size, network depth, pooling layers and multi-fully connected\nlayer have impact on the performance of CNNs. In particular, through a series\nof experimental analysis on benchmark of MNIST and Fashion-MNIST, we\ndemonstrate that the compression phase is not observed in all these cases. This\nshows us the CNNs have a rather complicated behavior than feedforward neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 15:55:54 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 12:12:10 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Li", "Junjie", ""], ["Liu", "Ding", ""]]}, {"id": "1911.03725", "submitter": "Waheed Bajwa", "authors": "Talal Ahmed, Haroon Raja, and Waheed U. Bajwa", "title": "Tensor Regression Using Low-rank and Sparse Tucker Decompositions", "comments": "28 pages, 5 figures, 2 tables; preprint of a journal paper published\n  in SIAM Journal on Mathematics of Data Science", "journal-ref": "SIAM J. Math. Data Science, vol. 2, no. 4, pp. 944-966, 2020", "doi": "10.1137/19M1299335", "report-no": null, "categories": "cs.LG eess.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a tensor-structured linear regression model with a scalar\nresponse variable and tensor-structured predictors, such that the regression\nparameters form a tensor of order $d$ (i.e., a $d$-fold multiway array) in\n$\\mathbb{R}^{n_1 \\times n_2 \\times \\cdots \\times n_d}$. It focuses on the task\nof estimating the regression tensor from $m$ realizations of the response\nvariable and the predictors where $m\\ll n = \\prod \\nolimits_{i} n_i$. Despite\nthe seeming ill-posedness of this problem, it can still be solved if the\nparameter tensor belongs to the space of sparse, low Tucker-rank tensors.\nAccordingly, the estimation procedure is posed as a non-convex optimization\nprogram over the space of sparse, low Tucker-rank tensors, and a tensor variant\nof projected gradient descent is proposed to solve the resulting non-convex\nproblem. In addition, mathematical guarantees are provided that establish the\nproposed method linearly converges to an appropriate solution under a certain\nset of conditions. Further, an upper bound on sample complexity of tensor\nparameter estimation for the model under consideration is characterized for the\nspecial case when the individual (scalar) predictors independently draw values\nfrom a sub-Gaussian distribution. The sample complexity bound is shown to have\na polylogarithmic dependence on $\\bar{n} = \\max \\big\\{n_i: i\\in \\{1,2,\\ldots,d\n\\} \\big\\}$ and, orderwise, it matches the bound one can obtain from a heuristic\nparameter counting argument. Finally, numerical experiments demonstrate the\nefficacy of the proposed tensor model and estimation method on a synthetic\ndataset and a collection of neuroimaging datasets pertaining to attention\ndeficit hyperactivity disorder. Specifically, the proposed method exhibits\nbetter sample complexities on both synthetic and real datasets, demonstrating\nthe usefulness of the model and the method in settings where $n \\gg m$.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:00:38 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 03:44:59 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ahmed", "Talal", ""], ["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1911.03731", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Internal Representations (PhD Thesis)", "comments": "Phd Thesis, Jonathan Baxter, 1994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning theory and practice is concerned with learning a single\ntask. In this thesis it is argued that in general there is insufficient\ninformation in a single task for a learner to generalise well and that what is\nrequired for good generalisation is information about many similar learning\ntasks. Similar learning tasks form a body of prior information that can be used\nto constrain the learner and make it generalise better. Examples of learning\nscenarios in which there are many similar tasks are handwritten character\nrecognition and spoken word recognition.\n  The concept of the environment of a learner is introduced as a probability\nmeasure over the set of learning problems the learner might be expected to\nlearn. It is shown how a sample from the environment may be used to learn a\nrepresentation, or recoding of the input space that is appropriate for the\nenvironment. Learning a representation can equivalently be thought of as\nlearning the appropriate features of the environment. Bounds are derived on the\nsample size required to ensure good generalisation from a representation\nlearning process. These bounds show that under certain circumstances learning a\nrepresentation appropriate for $n$ tasks reduces the number of examples\nrequired of each task by a factor of $n$.\n  Once a representation is learnt it can be used to learn novel tasks from the\nsame environment, with the result that far fewer examples are required of the\nnew tasks to ensure good generalisation. Bounds are given on the number of\ntasks and the number of samples from each task required to ensure that a\nrepresentation will be a good one for learning novel tasks.\n  The results on representation learning are generalised to cover any form of\nautomated hypothesis space bias.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:25:33 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 15:20:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.03740", "submitter": "Sheng Liu", "authors": "Sheng Liu, Chhavi Yadav, Carlos Fernandez-Granda, Narges Razavian", "title": "On the design of convolutional neural networks for automatic detection\n  of Alzheimer's disease", "comments": "Machine Learning for Health Workshop, NeurIPS2019. Authors\n  Fernandez-Granda and Razavian are joint last authors", "journal-ref": "Proceedings of Machine Learning Research, 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection is a crucial goal in the study of Alzheimer's Disease (AD).\nIn this work, we describe several techniques to boost the performance of 3D\ndeep convolutional neural networks (CNNs) trained to detect AD using structural\nbrain MRI scans. Specifically, we provide evidence that (1) instance\nnormalization outperforms batch normalization, (2) early spatial downsampling\nnegatively affects performance, (3) widening the model brings consistent gains\nwhile increasing the depth does not, and (4) incorporating age information\nyields moderate improvement. Together, these insights yield an increment of\napproximately 14% in test accuracy over existing models when distinguishing\nbetween patients with AD, mild cognitive impairment, and controls in the ADNI\ndataset. Similar performance is achieved on an independent dataset.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:08:34 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 18:18:06 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 01:47:59 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Liu", "Sheng", ""], ["Yadav", "Chhavi", ""], ["Fernandez-Granda", "Carlos", ""], ["Razavian", "Narges", ""]]}, {"id": "1911.03764", "submitter": "Ruoxuan Xiong", "authors": "Ruoxuan Xiong, Susan Athey, Mohsen Bayati, Guido Imbens", "title": "Optimal Experimental Design for Staggered Rollouts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimentation has become an increasingly prevalent tool for guiding\ndecision-making and policy choices. A common hurdle in designing experiments is\nthe lack of statistical power. In this paper, we study the optimal multi-period\nexperimental design under the constraint that the treatment cannot be easily\nremoved once implemented; for example, a government might implement a public\nhealth intervention in different geographies at different times, where the\ntreatment cannot be easily removed due to practical constraints. The treatment\ndesign problem is to select which geographies (referred by units) to treat at\nwhich time, intending to test hypotheses about the effect of the treatment.\nWhen the potential outcome is a linear function of unit and time effects, and\ndiscrete observed/latent covariates, we provide an analytically feasible\nsolution to the optimal treatment design problem where the variance of the\ntreatment effect estimator is at most 1+O(1/N^2) times the variance using the\noptimal treatment design, where N is the number of units. This solution assigns\nunits in a staggered treatment adoption pattern - if the treatment only affects\none period, the optimal fraction of treated units in each period increases\nlinearly in time; if the treatment affects multiple periods, the optimal\nfraction increases non-linearly in time, smaller at the beginning and larger at\nthe end. In the general setting where outcomes depend on latent covariates, we\nshow that historical data can be utilized in designing experiments. We propose\na data-driven local search algorithm to assign units to treatment times. We\ndemonstrate that our approach improves upon benchmark experimental designs via\nsynthetic interventions on the influenza occurrence rate and synthetic\nexperiments on interventions for in-home medical services and grocery\nexpenditure.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:46:29 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 02:19:05 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xiong", "Ruoxuan", ""], ["Athey", "Susan", ""], ["Bayati", "Mohsen", ""], ["Imbens", "Guido", ""]]}, {"id": "1911.03779", "submitter": "Joseph Chow", "authors": "Susan Jia Xu, Qian Xie, Joseph Y. J. Chow, Xintao Liu", "title": "Empirical validation of network learning with taxi GPS data from Wuhan,\n  China", "comments": null, "journal-ref": "IEEE Intelligent Transportation Systems Magazine 13(1) (2021)\n  42-58", "doi": "10.1109/MITS.2020.3037324", "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In prior research, a statistically cheap method was developed to monitor\ntransportation network performance by using only a few groups of agents without\nhaving to forecast the population flows. The current study validates this\n\"multi-agent inverse optimization\" method using taxi GPS probe data from the\ncity of Wuhan, China. Using a controlled 2062-link network environment and\ndifferent GPS data processing algorithms, an online monitoring environment is\nsimulated using the real data over a 4-hour period. Results show that using\nonly samples from one OD pair, the multi-agent inverse optimization method can\nlearn network parameters such that forecasted travel times have a 0.23\ncorrelation with the observed travel times. By increasing to monitoring from\njust two OD pairs, the correlation improves further to 0.56.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:18:22 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:49:44 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xu", "Susan Jia", ""], ["Xie", "Qian", ""], ["Chow", "Joseph Y. J.", ""], ["Liu", "Xintao", ""]]}, {"id": "1911.03784", "submitter": "Marc Khoury", "authors": "Marc Khoury", "title": "Adaptive versus Standard Descent Methods and Robustness Against\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a pervasive phenomenon of machine learning models\nwhere seemingly imperceptible perturbations to the input lead to\nmisclassifications for otherwise statistically accurate models. In this paper\nwe study how the choice of optimization algorithm influences the robustness of\nthe resulting classifier to adversarial examples. Specifically we show an\nexample of a learning problem for which the solution found by adaptive\noptimization algorithms exhibits qualitatively worse robustness properties\nagainst both $L_{2}$- and $L_{\\infty}$-adversaries than the solution found by\nnon-adaptive algorithms. Then we fully characterize the geometry of the loss\nlandscape of $L_{2}$-adversarial training in least-squares linear regression.\nThe geometry of the loss landscape is subtle and has important consequences for\noptimization algorithms. Finally we provide experimental evidence which\nsuggests that non-adaptive methods consistently produce more robust models than\nadaptive methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:54:53 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 19:09:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Khoury", "Marc", ""]]}, {"id": "1911.03787", "submitter": "Yue Cao", "authors": "Yue Cao, Tianlong Chen, Zhangyang Wang, Yang Shen", "title": "Learning to Optimize in Swarms", "comments": "Accepted to Neural Information Processing Systems (NeurIPS2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to optimize has emerged as a powerful framework for various\noptimization and machine learning tasks. Current such \"meta-optimizers\" often\nlearn in the space of continuous optimization algorithms that are point-based\nand uncertainty-unaware. To overcome the limitations, we propose a\nmeta-optimizer that learns in the algorithmic space of both point-based and\npopulation-based optimization algorithms. The meta-optimizer targets at a\nmeta-loss function consisting of both cumulative regret and entropy.\nSpecifically, we learn and interpret the update formula through a population of\nLSTMs embedded with sample- and feature-level attentions. Meanwhile, we\nestimate the posterior directly over the global optimum and use an uncertainty\nmeasure to help guide the learning process. Empirical results over non-convex\ntest functions and the protein-docking application demonstrate that this new\nmeta-optimizer outperforms existing competitors.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 22:25:05 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 19:16:42 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cao", "Yue", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""], ["Shen", "Yang", ""]]}, {"id": "1911.03803", "submitter": "Arash Mohammadi", "authors": "Elahe Rahimian, Soheil Zabihi, Seyed Farokh Atashzar, Amir Asif, and\n  Arash Mohammadi", "title": "XceptionTime: A Novel Deep Architecture based on Depthwise Separable\n  Convolutions for Hand Gesture Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capitalizing on the need for addressing the existing challenges associated\nwith gesture recognition via sparse multichannel surface Electromyography\n(sEMG) signals, the paper proposes a novel deep learning model, referred to as\nthe XceptionTime architecture. The proposed innovative XceptionTime is designed\nby integration of depthwise separable convolutions, adaptive average pooling,\nand a novel non-linear normalization technique. At the heart of the proposed\narchitecture is several XceptionTime modules concatenated in series fashion\ndesigned to capture both temporal and spatial information-bearing contents of\nthe sparse multichannel sEMG signals without the need for data augmentation\nand/or manual design of feature extraction. In addition, through integration of\nadaptive average pooling, Conv1D, and the non-linear normalization approach,\nXceptionTime is less prone to overfitting, more robust to temporal translation\nof the input, and more importantly is independent from the input window size.\nFinally, by utilizing the depthwise separable convolutions, the XceptionTime\nnetwork has far fewer parameters resulting in a less complex network. The\nperformance of XceptionTime is tested on a sub Ninapro dataset, DB1, and the\nresults showed a superior performance in comparison to any existing\ncounterparts. In this regard, 5:71% accuracy improvement, on a window size\n200ms, is reported in this paper, for the first time.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:34:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rahimian", "Elahe", ""], ["Zabihi", "Soheil", ""], ["Atashzar", "Seyed Farokh", ""], ["Asif", "Amir", ""], ["Mohammadi", "Arash", ""]]}, {"id": "1911.03804", "submitter": "Anru Zhang", "authors": "Anru Zhang, Yuetian Luo, Garvesh Raskutti, Ming Yuan", "title": "ISLET: Fast and Optimal Low-rank Tensor Regression via Importance\n  Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we develop a novel procedure for low-rank tensor regression,\nnamely \\emph{\\underline{I}mportance \\underline{S}ketching \\underline{L}ow-rank\n\\underline{E}stimation for \\underline{T}ensors} (ISLET). The central idea\nbehind ISLET is \\emph{importance sketching}, i.e., carefully designed sketches\nbased on both the responses and low-dimensional structure of the parameter of\ninterest. We show that the proposed method is sharply minimax optimal in terms\nof the mean-squared error under low-rank Tucker assumptions and under\nrandomized Gaussian ensemble design. In addition, if a tensor is low-rank with\ngroup sparsity, our procedure also achieves minimax optimality. Further, we\nshow through numerical study that ISLET achieves comparable or better\nmean-squared error performance to existing state-of-the-art methods while\nhaving substantial storage and run-time advantages including capabilities for\nparallel and distributed computing. In particular, our procedure performs\nreliable estimation with tensors of dimension $p = O(10^8)$ and is $1$ or $2$\norders of magnitude faster than baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:36:13 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 05:36:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhang", "Anru", ""], ["Luo", "Yuetian", ""], ["Raskutti", "Garvesh", ""], ["Yuan", "Ming", ""]]}, {"id": "1911.03809", "submitter": "Guoqing Zheng", "authors": "Guoqing Zheng, Ahmed Hassan Awadallah, Susan Dumais", "title": "Meta Label Correction for Learning with Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging weak or noisy supervision for building effective machine learning\nmodels has long been an important research problem. The growing need for\nlarge-scale datasets to train deep learning models has increased its\nimportance. Weak or noisy supervision could originate from multiple sources\nincluding non-expert annotators or automatic labeling based on heuristics or\nuser interaction signals. Previous work on modeling and correcting weak labels\nhave been focused on various aspects, including loss correction, training\ninstance re-weighting, etc. In this paper, we approach this problem from a\nnovel perspective based on meta-learning. We view the label correction\nprocedure as a meta-process and propose a new meta-learning based framework\ntermed MLC for learning with weak supervision. Experiments with different label\nnoise levels on multiple datasets show that MLC can achieve large improvement\nover previous methods incorporating weak labels for learning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 00:24:08 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zheng", "Guoqing", ""], ["Awadallah", "Ahmed Hassan", ""], ["Dumais", "Susan", ""]]}, {"id": "1911.03827", "submitter": "Yiheng Lin", "authors": "Yiheng Lin, Gautam Goel, Adam Wierman", "title": "Online Optimization with Predictions and Non-convex Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online optimization in a setting where an online learner seeks to\noptimize a per-round hitting cost, which may be non-convex, while incurring a\nmovement cost when changing actions between rounds. We ask: \\textit{under what\ngeneral conditions is it possible for an online learner to leverage predictions\nof future cost functions in order to achieve near-optimal costs?} Prior work\nhas provided near-optimal online algorithms for specific combinations of\nassumptions about hitting and switching costs, but no general results are\nknown. In this work, we give two general sufficient conditions that specify a\nrelationship between the hitting and movement costs which guarantees that a new\nalgorithm, Synchronized Fixed Horizon Control (SFHC), provides a $1+O(1/w)$\ncompetitive ratio, where $w$ is the number of predictions available to the\nlearner. Our conditions do not require the cost functions to be convex, and we\nalso derive competitive ratio results for non-convex hitting and movement\ncosts. Our results provide the first constant, dimension-free competitive ratio\nfor online non-convex optimization with movement costs. Further, we give an\nexample of a natural instance, Convex Body Chasing (CBC), where the sufficient\nconditions are not satisfied and we can prove that no online algorithm can have\na competitive ratio that converges to 1.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:01:20 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 00:39:02 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Lin", "Yiheng", ""], ["Goel", "Gautam", ""], ["Wierman", "Adam", ""]]}, {"id": "1911.03831", "submitter": "He Lyu", "authors": "He Lyu, Ningyu Sha, Shuyang Qin, Ming Yan, Yuying Xie, Rongrong Wang", "title": "Manifold Denoising by Nonlinear Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends robust principal component analysis (RPCA) to nonlinear\nmanifolds. Suppose that the observed data matrix is the sum of a sparse\ncomponent and a component drawn from some low dimensional manifold. Is it\npossible to separate them by using similar ideas as RPCA? Is there any benefit\nin treating the manifold as a whole as opposed to treating each local region\nindependently? We answer these two questions affirmatively by proposing and\nanalyzing an optimization framework that separates the sparse component from\nthe manifold under noisy data. Theoretical error bounds are provided when the\ntangent spaces of the manifold satisfy certain incoherence conditions. We also\nprovide a near optimal choice of the tuning parameters for the proposed\noptimization formulation with the help of a new curvature estimation method.\nThe efficacy of our method is demonstrated on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:16:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Lyu", "He", ""], ["Sha", "Ningyu", ""], ["Qin", "Shuyang", ""], ["Yan", "Ming", ""], ["Xie", "Yuying", ""], ["Wang", "Rongrong", ""]]}, {"id": "1911.03839", "submitter": "Dongrui Wu", "authors": "Bo Zhang and Yuqi Cui and Meng Wang and Jingjing Li and Lei Jin and\n  Dongrui Wu", "title": "In Vitro Fertilization (IVF) Cumulative Pregnancy Rate Prediction from\n  Basic Patient Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tens of millions of women suffer from infertility worldwide each year. In\nvitro fertilization (IVF) is the best choice for many such patients. However,\nIVF is expensive, time-consuming, and both physically and emotionally\ndemanding. The first question that a patient usually asks before the IVF is how\nlikely she will conceive, given her basic medical examination information. This\npaper proposes three approaches to predict the cumulative pregnancy rate after\nmultiple oocyte pickup cycles. Experiments on 11,190 patients showed that first\nclustering the patients into different groups and then building a support\nvector machine model for each group can achieve the best overall performance.\nOur model could be a quick and economic approach for reliably estimating the\ncumulative pregnancy rate for a patient, given only her basic medical\nexamination information, well before starting the actual IVF procedure. The\npredictions can help the patient make optimal decisions on whether to use her\nown oocyte or donor oocyte, how many oocyte pickup cycles she may need, whether\nto use embryo frozen, etc. They will also reduce the patient's cost and time to\npregnancy, and improve her quality of life.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 03:00:07 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Bo", ""], ["Cui", "Yuqi", ""], ["Wang", "Meng", ""], ["Li", "Jingjing", ""], ["Jin", "Lei", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.03845", "submitter": "Xueying Bai", "authors": "Xueying Bai, Jian Guan, Hongning Wang", "title": "Model-Based Reinforcement Learning with Adversarial Training for Online\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is well suited for optimizing policies of recommender\nsystems. Current solutions mostly focus on model-free approaches, which require\nfrequent interactions with the real environment, and thus are expensive in\nmodel learning. Offline evaluation methods, such as importance sampling, can\nalleviate such limitations, but usually request a large amount of logged data\nand do not work well when the action space is large. In this work, we propose a\nmodel-based reinforcement learning solution which models user-agent interaction\nfor offline policy learning via a generative adversarial network. To reduce\nbias in the learned model and policy, we use a discriminator to evaluate the\nquality of generated data and scale the generated rewards. Our theoretical\nanalysis and empirical evaluations demonstrate the effectiveness of our\nsolution in learning policies from the offline and generated data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:24:04 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 01:40:22 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 20:47:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bai", "Xueying", ""], ["Guan", "Jian", ""], ["Wang", "Hongning", ""]]}, {"id": "1911.03849", "submitter": "Xinghua Qu", "authors": "Xinghua Qu, Zhu Sun, Yew-Soon Ong, Abhishek Gupta, Pengfei Wei", "title": "Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement\n  Learning Policy", "comments": "Accepted by IEEE Transactions on Cognitive and Developmental System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have revealed that neural network-based policies can be easily\nfooled by adversarial examples. However, while most prior works analyze the\neffects of perturbing every pixel of every frame assuming white-box policy\naccess, in this paper we take a more restrictive view towards adversary\ngeneration - with the goal of unveiling the limits of a model's vulnerability.\nIn particular, we explore minimalistic attacks by defining three key settings:\n(1) black-box policy access: where the attacker only has access to the input\n(state) and output (action probability) of an RL policy; (2) fractional-state\nadversary: where only several pixels are perturbed, with the extreme case being\na single-pixel adversary; and (3) tactically-chanced attack: where only\nsignificant frames are tactically chosen to be attacked. We formulate the\nadversarial attack by accommodating the three key settings and explore their\npotency on six Atari games by examining four fully trained state-of-the-art\npolicies. In Breakout, for example, we surprisingly find that: (i) all policies\nshowcase significant performance degradation by merely modifying 0.01% of the\ninput state, and (ii) the policy trained by DQN is totally deceived by\nperturbation to only 1% frames.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:39:56 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 08:28:44 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 00:51:06 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 01:46:01 GMT"}, {"version": "v5", "created": "Thu, 29 Oct 2020 13:40:22 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qu", "Xinghua", ""], ["Sun", "Zhu", ""], ["Ong", "Yew-Soon", ""], ["Gupta", "Abhishek", ""], ["Wei", "Pengfei", ""]]}, {"id": "1911.03853", "submitter": "Rakesh Bal", "authors": "Rakesh Bal and Sayan Sinha", "title": "Modelling Bahdanau Attention using Election methods aided by Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation has lately gained a lot of \"attention\" with the\nadvent of more and more sophisticated but drastically improved models.\nAttention mechanism has proved to be a boon in this direction by providing\nweights to the input words, making it easy for the decoder to identify words\nrepresenting the present context. But by and by, as newer attention models with\nmore complexity came into development, they involved large computation, making\ninference slow. In this paper, we have modelled the attention network using\ntechniques resonating with social choice theory. Along with that, the attention\nmechanism, being a Markov Decision Process, has been represented by\nreinforcement learning techniques. Thus, we propose to use an election method\n($k$-Borda), fine-tuned using Q-learning, as a replacement for attention\nnetworks. The inference time for this network is less than a standard Bahdanau\ntranslator, and the results of the translation are comparable. This not only\nexperimentally verifies the claims stated above but also helped provide a\nfaster inference.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:55:46 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:46:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bal", "Rakesh", ""], ["Sinha", "Sayan", ""]]}, {"id": "1911.03872", "submitter": "Yann Dubois", "authors": "Yann Dubois, Gautier Dagan, Dieuwke Hupkes, Elia Bruni", "title": "Location Attention for Extrapolation to Longer Sequences", "comments": "11 pages, 9 figures, Accepted for publication at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are surprisingly good at interpolating and perform remarkably\nwell when the training set examples resemble those in the test set. However,\nthey are often unable to extrapolate patterns beyond the seen data, even when\nthe abstractions required for such patterns are simple. In this paper, we first\nreview the notion of extrapolation, why it is important and how one could hope\nto tackle it. We then focus on a specific type of extrapolation which is\nespecially useful for natural language processing: generalization to sequences\nthat are longer than the training ones. We hypothesize that models with a\nseparate content- and location-based attention are more likely to extrapolate\nthan those with common attention mechanisms. We empirically support our claim\nfor recurrent seq2seq models with our proposed attention on variants of the\nLookup Table task. This sheds light on some striking failures of neural models\nfor sequences and on possible methods to approaching such issues.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 07:39:42 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 21:46:40 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Dubois", "Yann", ""], ["Dagan", "Gautier", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "1911.03882", "submitter": "Canwen Xu", "authors": "Yu Duan, Canwen Xu, Jiaxin Pei, Jialong Han, Chenliang Li", "title": "Pre-train and Plug-in: Flexible Conditional Text Generation with\n  Variational Auto-Encoders", "comments": "Accepted as a long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Text Generation has drawn much attention as a topic of Natural\nLanguage Generation (NLG) which provides the possibility for humans to control\nthe properties of generated contents. Current conditional generation models\ncannot handle emerging conditions due to their joint end-to-end learning\nfashion. When a new condition added, these techniques require full retraining.\nIn this paper, we present a new framework named Pre-train and Plug-in\nVariational Auto-Encoder (PPVAE) towards flexible conditional text generation.\nPPVAE decouples the text generation module from the condition representation\nmodule to allow \"one-to-many\" conditional generation. When a fresh condition\nemerges, only a lightweight network needs to be trained and works as a plug-in\nfor PPVAE, which is efficient and desirable for real-world applications.\nExtensive experiments demonstrate the superiority of PPVAE against the existing\nalternatives with better conditionality and diversity but less training effort.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:23:42 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 15:34:10 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 07:44:11 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 06:28:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Duan", "Yu", ""], ["Xu", "Canwen", ""], ["Pei", "Jiaxin", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""]]}, {"id": "1911.03887", "submitter": "Liang Wang", "authors": "Liang Wang, Kezhi Wang, Cunhua Pan, Wei Xu, Nauman Aslam, Arumugam\n  Nallanathan", "title": "Deep Reinforcement Learning Based Dynamic Trajectory Control for\n  UAV-assisted Mobile Edge Computing", "comments": "Accepted by IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a platform of flying mobile edge computing\n(F-MEC), where unmanned aerial vehicles (UAVs) serve as equipment providing\ncomputation resource, and they enable task offloading from user equipment (UE).\nWe aim to minimize energy consumption of all the UEs via optimizing the user\nassociation, resource allocation and the trajectory of UAVs. To this end, we\nfirst propose a Convex optimizAtion based Trajectory control algorithm (CAT),\nwhich solves the problem in an iterative way by using block coordinate descent\n(BCD) method. Then, to make the real-time decision while taking into account\nthe dynamics of the environment (i.e., UAV may take off from different\nlocations), we propose a deep Reinforcement leArning based Trajectory control\nalgorithm (RAT). In RAT, we apply the Prioritized Experience Replay (PER) to\nimprove the convergence of the training procedure. Different from the convex\noptimization based algorithm which may be susceptible to the initial points and\nrequires iterations, RAT can be adapted to any taking off points of the UAVs\nand can obtain the solution more rapidly than CAT once training process has\nbeen completed. Simulation results show that the proposed CAT and RAT achieve\nthe similar performance and both outperform traditional algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:24:04 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 15:42:03 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Liang", ""], ["Wang", "Kezhi", ""], ["Pan", "Cunhua", ""], ["Xu", "Wei", ""], ["Aslam", "Nauman", ""], ["Nallanathan", "Arumugam", ""]]}, {"id": "1911.03904", "submitter": "Deli Chen", "authors": "Deli Chen, Xiaoqian Liu, Yankai Lin, Peng Li, Jie Zhou, Qi Su, Xu Sun", "title": "HighwayGraph: Modelling Long-distance Node Relations for Improving\n  General Graph Neural Network", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are efficient approaches to process\ngraph-structured data. Modelling long-distance node relations is essential for\nGNN training and applications. However, conventional GNNs suffer from bad\nperformance in modelling long-distance node relations due to limited-layer\ninformation propagation. Existing studies focus on building deep GNN\narchitectures, which face the over-smoothing issue and cannot model node\nrelations in particularly long distance. To address this issue, we propose to\nmodel long-distance node relations by simply relying on shallow GNN\narchitectures with two solutions: (1) Implicitly modelling by learning to\npredict node pair relations (2) Explicitly modelling by adding edges between\nnodes that potentially have the same label. To combine our two solutions, we\npropose a model-agnostic training framework named HighwayGraph, which overcomes\nthe challenge of insufficient labeled nodes by sampling node pairs from the\ntraining set and adopting the self-training method. Extensive experimental\nresults show that our HighwayGraph achieves consistent and significant\nimprovements over four representative GNNs on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:23:37 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 05:18:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Deli", ""], ["Liu", "Xiaoqian", ""], ["Lin", "Yankai", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1911.03923", "submitter": "Sara Masoud", "authors": "Sara Masoud, Bijoy Chowdhury, Young-Jun Son, Chieri Kubota, Russell\n  Tronstad", "title": "A Dynamic Modelling Framework for Human Hand Gesture Task Recognition", "comments": "6 pages, 5 figures, 2 tables, conference proceedings", "journal-ref": "(2018). A dynamic modelling framework for human hand gesture task\n  recognition. 563-568. Paper presented at 2018 Institute of Industrial and\n  Systems Engineers Annual Conference and Expo, IISE 2018, Orlando, United\n  States", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gesture recognition and hand motion tracking are important tasks in advanced\ngesture based interaction systems. In this paper, we propose to apply a sliding\nwindows filtering approach to sample the incoming streams of data from data\ngloves and a decision tree model to recognize the gestures in real time for a\nmanual grafting operation of a vegetable seedling propagation facility. The\nsequence of these recognized gestures defines the tasks that are taking place,\nwhich helps to evaluate individuals' performances and to identify any\nbottlenecks in real time. In this work, two pairs of data gloves are utilized,\nwhich reports the location of the fingers, hands, and wrists wirelessly (i.e.,\nvia Bluetooth). To evaluate the performance of the proposed framework, a\npreliminary experiment was conducted in multiple lab settings of tomato\ngrafting operations, where multiple subjects wear the data gloves while\nperforming different tasks. Our results show an accuracy of 91% on average, in\nterms of gesture recognition in real time by employing our proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:06:48 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 05:01:22 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Masoud", "Sara", ""], ["Chowdhury", "Bijoy", ""], ["Son", "Young-Jun", ""], ["Kubota", "Chieri", ""], ["Tronstad", "Russell", ""]]}, {"id": "1911.03925", "submitter": "Chao Yu", "authors": "Chao Yu, Zhiguo Su", "title": "Symmetrical Gaussian Error Linear Units (SGELUs)", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel neural network activation function, called Symmetrical\nGaussian Error Linear Unit (SGELU), is proposed to obtain high performance. It\nis achieved by effectively integrating the property of the stochastic\nregularizer in the Gaussian Error Linear Unit (GELU) with the symmetrical\ncharacteristics. Combining with these two merits, the proposed unit introduces\nthe capability of the bidirection convergence to successfully optimize the\nnetwork without the gradient diminishing problem. The evaluations of SGELU\nagainst GELU and Linearly Scaled Hyperbolic Tangent (LiSHT) have been carried\nout on MNIST classification and MNIST auto-encoder, which provide great\nvalidations in terms of the performance, the convergence rate among these\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:14:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Yu", "Chao", ""], ["Su", "Zhiguo", ""]]}, {"id": "1911.03941", "submitter": "Frederik Kratzert", "authors": "Frederik Kratzert, Daniel Klotz, Johannes Brandstetter, Pieter-Jan\n  Hoedt, Grey Nearing, Sepp Hochreiter", "title": "Using LSTMs for climate change assessment studies on droughts and floods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate change affects occurrences of floods and droughts worldwide. However,\npredicting climate impacts over individual watersheds is difficult, primarily\nbecause accurate hydrological forecasts require models that are calibrated to\npast data. In this work we present a large-scale LSTM-based modeling approach\nthat -- by training on large data sets -- learns a diversity of hydrological\nbehaviors. Previous work shows that this model is more accurate than current\nstate-of-the-art models, even when the LSTM-based approach operates\nout-of-sample and the latter in-sample. In this work, we show how this model\ncan assess the sensitivity of the underlying systems with regard to extreme\n(high and low) flows in individual watersheds over the continental US.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 14:50:48 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 09:36:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kratzert", "Frederik", ""], ["Klotz", "Daniel", ""], ["Brandstetter", "Johannes", ""], ["Hoedt", "Pieter-Jan", ""], ["Nearing", "Grey", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1911.03949", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Interpretable Multiple-Kernel Prototype Learning for Discriminative\n  Representation and Feature Selection", "comments": "CIKM 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototype-based methods are of the particular interest for domain specialists\nand practitioners as they summarize a dataset by a small set of\nrepresentatives. Therefore, in a classification setting, interpretability of\nthe prototypes is as significant as the prediction accuracy of the algorithm.\nNevertheless, the state-of-the-art methods make inefficient trade-offs between\nthese concerns by sacrificing one in favor of the other, especially if the\ngiven data has a kernel-based representation. In this paper, we propose a novel\ninterpretable multiple-kernel prototype learning (IMKPL) to construct highly\ninterpretable prototypes in the feature space, which are also efficient for the\ndiscriminative representation of the data. Our method focuses on the local\ndiscrimination of the classes in the feature space and shaping the prototypes\nbased on condensed class-homogeneous neighborhoods of data. Besides, IMKPL\nlearns a combined embedding in the feature space in which the above objectives\nare better fulfilled. When the base kernels coincide with the data dimensions,\nthis embedding results in a discriminative features selection. We evaluate\nIMKPL on several benchmarks from different domains which demonstrate its\nsuperiority to the related state-of-the-art methods regarding both\ninterpretability and discriminative representation.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 15:53:06 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.03951", "submitter": "Eyke H\\\"ullermeier", "authors": "Ammar Shaker and Eyke H\\\"ullermeier", "title": "TSK-Streams: Learning TSK Fuzzy Systems on Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adaptive learning from evolving and possibly non-stationary\ndata streams has attracted a lot of interest in machine learning in the recent\npast, and also stimulated research in related fields, such as computational\nintelligence and fuzzy systems. In particular, several rule-based methods for\nthe incremental induction of regression models have been proposed. In this\npaper, we develop a method that combines the strengths of two existing\napproaches rooted in different learning paradigms. More concretely, our method\nadopts basic principles of the state-of-the-art learning algorithm AMRules and\nenriches them by the representational advantages of fuzzy rules. In a\ncomprehensive experimental study, TSK-Streams is shown to be highly competitive\nin terms of performance.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 16:04:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Shaker", "Ammar", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1911.03959", "submitter": "Samarth Gupta", "authors": "Samarth Gupta, Shreyas Chaudhari, Gauri Joshi and Osman Ya\\u{g}an", "title": "Multi-Armed Bandits with Correlated Arms", "comments": "A special case of the model studied in this paper is presented in\n  arXiv:1808.05904", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-armed bandit framework where the rewards obtained by\npulling different arms are correlated. We develop a unified approach to\nleverage these reward correlations and present fundamental generalizations of\nclassic bandit algorithms to the correlated setting. We present a unified proof\ntechnique to analyze the proposed algorithms. Rigorous analysis of C-UCB and\nC-TS (the correlated bandit versions of Upper-confidence-bound and Thompson\nsampling) reveals that the algorithms end up pulling certain sub-optimal arms,\ntermed as non-competitive, only O(1) times, as opposed to the O(log T) pulls\nrequired by classic bandit algorithms such as UCB, TS etc. We present\nregret-lower bound and show that when arms are correlated through a latent\nrandom source, our algorithms obtain order-optimal regret. We validate the\nproposed algorithms via experiments on the MovieLens and Goodreads datasets,\nand show significant improvement over classical bandit algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:56:46 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 23:29:49 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 18:05:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Gupta", "Samarth", ""], ["Chaudhari", "Shreyas", ""], ["Joshi", "Gauri", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1911.03966", "submitter": "Youzuo Lin", "authors": "Tiantong Wang, Daniel Trugman, and Youzuo Lin", "title": "SeismoGen: Seismic Waveform Synthesis Using Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting earthquake events from seismic time series has proved itself a\nchallenging task. Manual detection can be expensive and tedious due to the\nintensive labor and large scale data set. In recent years, automatic detection\nmethods based on machine learning have been developed to improve accuracy and\nefficiency. However, the accuracy of those methods relies on a sufficient\namount of high-quality training data, which itself can be expensive to obtain\ndue to the requirement of domain knowledge and subject matter expertise. This\npaper is to resolve this dilemma by answering two questions: (1) provided with\na limited number of reliable labels, can we use them to generate more synthetic\nlabels; (2) Can we use those synthetic labels to improve the detectability?\nAmong all the existing generative models, the generative adversarial network\n(GAN) shows its supreme capability in generating high-quality synthetic samples\nin multiple domains. We designed our model based on GAN. In particular, we\nstudied several different network structures. By comparing the generated\nresults, our GAN-based generative model yields the highest quality. We further\ncombine the dataset with synthetic samples generated by our generative model\nand show that the detectability of our earthquake classification model is\nsignificantly improved than the one trained without augmenting the training\nset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 17:32:09 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 21:46:21 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Tiantong", ""], ["Trugman", "Daniel", ""], ["Lin", "Youzuo", ""]]}, {"id": "1911.03972", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari, Md. Aminur Rab Ratul, Won-Sook Lee", "title": "IrisNet: Deep Learning for Automatic and Real-time Tongue Contour\n  Tracking in Ultrasound Video Data using Peripheral Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The progress of deep convolutional neural networks has been successfully\nexploited in various real-time computer vision tasks such as image\nclassification and segmentation. Owing to the development of computational\nunits, availability of digital datasets, and improved performance of deep\nlearning models, fully automatic and accurate tracking of tongue contours in\nreal-time ultrasound data became practical only in recent years. Recent studies\nhave shown that the performance of deep learning techniques is significant in\nthe tracking of ultrasound tongue contours in real-time applications such as\npronunciation training using multimodal ultrasound-enhanced approaches. Due to\nthe high correlation between ultrasound tongue datasets, it is feasible to have\na general model that accomplishes automatic tongue tracking for almost all\ndatasets. In this paper, we proposed a deep learning model comprises of a\nconvolutional module mimicking the peripheral vision ability of the human eye\nto handle real-time, accurate, and fully automatic tongue contour tracking\ntasks, applicable for almost all primary ultrasound tongue datasets.\nQualitative and quantitative assessment of IrisNet on different ultrasound\ntongue datasets and PASCAL VOC2012 revealed its outstanding generalization\nachievement in compare with similar techniques.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 17:59:28 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 20:01:29 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Ratul", "Md. Aminur Rab", ""], ["Lee", "Won-Sook", ""]]}, {"id": "1911.03976", "submitter": "Teng Long", "authors": "Teng Long, Yanshuai Cao, Jackie Chi Kit Cheung", "title": "On Posterior Collapse and Encoder Feature Dispersion in Sequence VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) hold great potential for modelling text, as\nthey could in theory separate high-level semantic and syntactic properties from\nlocal regularities of natural language. Practically, however, VAEs with\nautoregressive decoders often suffer from posterior collapse, a phenomenon\nwhere the model learns to ignore the latent variables, causing the sequence VAE\nto degenerate into a language model. In this paper, we argue that posterior\ncollapse is in part caused by the lack of dispersion in encoder features. We\nprovide empirical evidence to verify this hypothesis, and propose a\nstraightforward fix using pooling. This simple technique effectively prevents\nposterior collapse, allowing model to achieve significantly better data\nlog-likelihood than standard sequence VAEs. Comparing to existing work, our\nproposed method is able to achieve comparable or superior performances while\nbeing more computationally efficient.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 18:50:46 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:38:27 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Long", "Teng", ""], ["Cao", "Yanshuai", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1911.03988", "submitter": "Dionysios Kalogerias", "authors": "Dionysios S. Kalogerias, Mark Eisen, George J. Pappas, Alejandro\n  Ribeiro", "title": "Model-Free Learning of Optimal Ergodic Policies in Wireless Systems", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": "10.1109/TSP.2020.3030073", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal resource allocation policies in wireless systems can be\neffectively achieved by formulating finite dimensional constrained programs\nwhich depend on system configuration, as well as the adopted learning\nparameterization. The interest here is in cases where system models are\nunavailable, prompting methods that probe the wireless system with candidate\npolicies, and then use observed performance to determine better policies. This\ngeneric procedure is difficult because of the need to cull accurate gradient\nestimates out of these limited system queries. This paper constructs and\nexploits smoothed surrogates of constrained ergodic resource allocation\nproblems, the gradients of the former being representable exactly as averages\nof finite differences that can be obtained through limited system probing.\nLeveraging this unique property, we develop a new model-free primal-dual\nalgorithm for learning optimal ergodic resource allocations, while we\nrigorously analyze the relationships between original policy search problems\nand their surrogates, in both primal and dual domains. First, we show that both\nprimal and dual domain surrogates are uniformly consistent approximations of\ntheir corresponding original finite dimensional counterparts. Upon further\nassuming the use of near-universal policy parameterizations, we also develop\nexplicit bounds on the gap between optimal values of initial, infinite\ndimensional resource allocation problems, and dual values of their\nparameterized smoothed surrogates. In fact, we show that this duality gap\ndecreases at a linear rate relative to smoothing and universality parameters.\nThus, it can be made arbitrarily small at will, also justifying our proposed\nprimal-dual algorithmic recipe. Numerical simulations confirm the effectiveness\nof our approach.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 19:56:12 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kalogerias", "Dionysios S.", ""], ["Eisen", "Mark", ""], ["Pappas", "George J.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1911.04013", "submitter": "Vishal Anand", "authors": "Vishal Anand, Ravi Shukla, Ashwani Gupta and Abhishek Kumar", "title": "Customized video filtering on YouTube", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inappropriate and profane content on social media is exponentially increasing\nand big corporations are becoming more aware of the type of content on which\nthey are advertising and how it may affect their brand reputation. But with a\nhuge surge in content being posted online it becomes seemingly difficult to\nfilter out related videos on which they can run their ads without compromising\nbrand name. Advertising on youtube videos generates a huge amount of revenue\nfor corporations. It becomes increasingly important for such corporations to\nadvertise on only the videos that don't hurt the feelings, community or harmony\nof the audience at large. In this paper, we propose a system to identify\ninappropriate content on YouTube and leverage it to perform a first of its\nkind, large scale, quantitative characterization that reveals some of the risks\nof YouTube ads consumption on inappropriate videos. Customization of the\narchitecture have also been included to serve different requirements of\ncorporations. Our analysis reveals that YouTube is still plagued by such\ndisturbing videos and its currently deployed countermeasures are ineffective in\nterms of detecting them in a timely manner. Our framework tries to fill this\ngap by providing a handy, add on solution to filter the videos and help\ncorporations and companies to push ads on the platform without worrying about\nthe content on which the ads are displayed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:05:17 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:31:25 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Anand", "Vishal", ""], ["Shukla", "Ravi", ""], ["Gupta", "Ashwani", ""], ["Kumar", "Abhishek", ""]]}, {"id": "1911.04014", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Vitaly Feldman", "title": "Interaction is necessary for distributed learning with privacy or\n  communication constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a model where users send privatized data\nto an untrusted central server whose goal it to solve some data analysis task.\nIn the non-interactive version of this model the protocol consists of a single\nround in which a server sends requests to all users then receives their\nresponses. This version is deployed in industry due to its practical advantages\nand has attracted significant research interest. Our main result is an\nexponential lower bound on the number of samples necessary to solve the\nstandard task of learning a large-margin linear separator in the\nnon-interactive LDP model. Via a standard reduction this lower bound implies an\nexponential lower bound for stochastic convex optimization and specifically,\nfor learning linear models with a convex, Lipschitz and smooth loss. These\nresults answer the questions posed in \\citep{SmithTU17,DanielyF18}. Our lower\nbound relies on a new technique for constructing pairs of distributions with\nnearly matching moments but whose supports can be nearly separated by a large\nmargin hyperplane. These lower bounds also hold in the model where\ncommunication from each user is limited and follow from a lower bound on\nlearning using non-adaptive \\emph{statistical queries}.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:06:17 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:04:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1911.04018", "submitter": "Yang Yang", "authors": "Yang Yang, Guillaume Sauti\\`ere, J. Jon Ryu, Taco S Cohen", "title": "Feedback Recurrent AutoEncoder", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new recurrent autoencoder architecture, termed\nFeedback Recurrent AutoEncoder (FRAE), for online compression of sequential\ndata with temporal dependency. The recurrent structure of FRAE is designed to\nefficiently extract the redundancy along the time dimension and allows a\ncompact discrete representation of the data to be learned. We demonstrate its\neffectiveness in speech spectrogram compression. Specifically, we show that the\nFRAE, paired with a powerful neural vocoder, can produce high-quality speech\nwaveforms at a low, fixed bitrate. We further show that by adding a learned\nprior for the latent space and using an entropy coder, we can achieve an even\nlower variable bitrate.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:31:14 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:10:50 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yang", "Yang", ""], ["Sauti\u00e8re", "Guillaume", ""], ["Ryu", "J. Jon", ""], ["Cohen", "Taco S", ""]]}, {"id": "1911.04024", "submitter": "Swaminathan Gurumurthy", "authors": "Swaminathan Gurumurthy, Sumit Kumar, Katia Sycara", "title": "MAME : Model-Agnostic Meta-Exploration", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-Reinforcement learning approaches aim to develop learning procedures\nthat can adapt quickly to a distribution of tasks with the help of a few\nexamples. Developing efficient exploration strategies capable of finding the\nmost useful samples becomes critical in such settings. Existing approaches\ntowards finding efficient exploration strategies add auxiliary objectives to\npromote exploration by the pre-update policy, however, this makes the\nadaptation using a few gradient steps difficult as the pre-update (exploration)\nand post-update (exploitation) policies are often quite different. Instead, we\npropose to explicitly model a separate exploration policy for the task\ndistribution. Having two different policies gives more flexibility in training\nthe exploration policy and also makes adaptation to any specific task easier.\nWe show that using self-supervised or supervised learning objectives for\nadaptation allows for more efficient inner-loop updates and also demonstrate\nthe superior performance of our model compared to prior works in this domain.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:58:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gurumurthy", "Swaminathan", ""], ["Kumar", "Sumit", ""], ["Sycara", "Katia", ""]]}, {"id": "1911.04048", "submitter": "Rogers Silva", "authors": "Rogers F. Silva (1 and 2), Sergey M. Plis (1 and 2), Tulay Adali (3),\n  Marios S. Pattichis (4), Vince D. Calhoun (1 and 2) ((1) Tri-Institutional\n  Center for Translational Research in Neuroimaging and Data Science (TReNDS),\n  Georgia State University, Georgia Institute of Technology, and Emory\n  University, Atlanta, GA, USA, (2) The Mind Research Network, Albuquerque, NM,\n  USA, (3) Dept. of CSEE, University of Maryland Baltimore County, Baltimore,\n  Maryland, USA, (4) Dept. of ECE at The University of New Mexico, Albuquerque,\n  NM, USA)", "title": "Multidataset Independent Subspace Analysis with Application to\n  Multimodal Fusion", "comments": "For associated code, see https://github.com/rsilva8/MISA For\n  associated data, see https://github.com/rsilva8/MISA-data Submitted to IEEE\n  Transactions on Image Processing on Nov/7/2019: 13 pages, 8 figures\n  Supplement: 16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, unsupervised latent variable models---blind source\nseparation (BSS) especially---have enjoyed a strong reputation for the\ninterpretable features they produce. Seldom do these models combine the rich\ndiversity of information available in multiple datasets. Multidatasets, on the\nother hand, yield joint solutions otherwise unavailable in isolation, with a\npotential for pivotal insights into complex systems.\n  To take advantage of the complex multidimensional subspace structures that\ncapture underlying modes of shared and unique variability across and within\ndatasets, we present a direct, principled approach to multidataset combination.\nWe design a new method called multidataset independent subspace analysis (MISA)\nthat leverages joint information from multiple heterogeneous datasets in a\nflexible and synergistic fashion.\n  Methodological innovations exploiting the Kotz distribution for subspace\nmodeling in conjunction with a novel combinatorial optimization for evasion of\nlocal minima enable MISA to produce a robust generalization of independent\ncomponent analysis (ICA), independent vector analysis (IVA), and independent\nsubspace analysis (ISA) in a single unified model.\n  We highlight the utility of MISA for multimodal information fusion, including\nsample-poor regimes and low signal-to-noise ratio scenarios, promoting novel\napplications in both unimodal and multimodal brain imaging data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 02:52:55 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Silva", "Rogers F.", "", "1 and 2"], ["Plis", "Sergey M.", "", "1 and 2"], ["Adali", "Tulay", "", "1 and 2"], ["Pattichis", "Marios S.", "", "1 and 2"], ["Calhoun", "Vince D.", "", "1 and 2"]]}, {"id": "1911.04060", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Daniel Moyer, Greg Ver Steeg, Wael AbdAlmageed,\n  Premkumar Natarajan", "title": "Invariant Representations through Adversarial Forgetting", "comments": "To appear in Proceedings of the 34th AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to achieving invariance for deep neural networks\nin the form of inducing amnesia to unwanted factors of data through a new\nadversarial forgetting mechanism. We show that the forgetting mechanism serves\nas an information-bottleneck, which is manipulated by the adversarial training\nto learn invariance to unwanted factors. Empirical results show that the\nproposed framework achieves state-of-the-art performance at learning invariance\nin both nuisance and bias settings on a diverse collection of datasets and\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:29:13 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 23:36:20 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Moyer", "Daniel", ""], ["Steeg", "Greg Ver", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1911.04061", "submitter": "Jeremiah Zhe Liu", "authors": "Jeremiah Zhe Liu, John Paisley, Marianthi-Anna Kioumourtzoglou, Brent\n  Coull", "title": "Accurate Uncertainty Estimation and Decomposition in Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble learning is a standard approach to building machine learning systems\nthat capture complex phenomena in real-world data. An important aspect of these\nsystems is the complete and valid quantification of model uncertainty. We\nintroduce a Bayesian nonparametric ensemble (BNE) approach that augments an\nexisting ensemble model to account for different sources of model uncertainty.\nBNE augments a model's prediction and distribution functions using Bayesian\nnonparametric machinery. It has a theoretical guarantee in that it robustly\nestimates the uncertainty patterns in the data distribution, and can decompose\nits overall predictive uncertainty into distinct components that are due to\ndifferent sources of noise and error. We show that our method achieves accurate\nuncertainty estimates under complex observational noise, and illustrate its\nreal-world utility in terms of uncertainty decomposition and model bias\ndetection for an ensemble in predict air pollution exposures in Eastern\nMassachusetts, USA.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:39:13 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Jeremiah Zhe", ""], ["Paisley", "John", ""], ["Kioumourtzoglou", "Marianthi-Anna", ""], ["Coull", "Brent", ""]]}, {"id": "1911.04062", "submitter": "Junjie Liang", "authors": "Junjie Liang, Dongkuan Xu, Yiwei Sun and Vasant Honavar", "title": "LMLFM: Longitudinal Multi-Level Factorization Machine", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence, accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning predictive models from longitudinal data,\nconsisting of irregularly repeated, sparse observations from a set of\nindividuals over time. Such data often exhibit {\\em longitudinal correlation}\n(LC) (correlations among observations for each individual over time), {\\em\ncluster correlation} (CC) (correlations among individuals that have similar\ncharacteristics), or both. These correlations are often accounted for using\n{\\em mixed effects models} that include {\\em fixed effects} and {\\em random\neffects}, where the fixed effects capture the regression parameters that are\nshared by all individuals, whereas random effects capture those parameters that\nvary across individuals. However, the current state-of-the-art methods are\nunable to select the most predictive fixed effects and random effects from a\nlarge number of variables, while accounting for complex correlation structure\nin the data and non-linear interactions among the variables. We propose\nLongitudinal Multi-Level Factorization Machine (LMLFM), to the best of our\nknowledge, the first model to address these challenges in learning predictive\nmodels from longitudinal data. We establish the convergence properties, and\nanalyze the computational complexity, of LMLFM. We present results of\nexperiments with both simulated and real-world longitudinal data which show\nthat LMLFM outperforms the state-of-the-art methods in terms of predictive\naccuracy, variable selection ability, and scalability to data with large number\nof variables. The code and supplemental material is available at\n\\url{https://github.com/junjieliang672/LMLFM}.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:45:39 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:06:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Liang", "Junjie", ""], ["Xu", "Dongkuan", ""], ["Sun", "Yiwei", ""], ["Honavar", "Vasant", ""]]}, {"id": "1911.04069", "submitter": "Hyemin Ahn", "authors": "Hyemin Ahn, Jaehun Kim, Kihyun Kim, Songhwai Oh", "title": "Generative Autoregressive Networks for 3D Dancing Move Synthesis from\n  Music", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework which is able to generate a sequence of\nthree-dimensional human dance poses for a given music. The proposed framework\nconsists of three components: a music feature encoder, a pose generator, and a\nmusic genre classifier. We focus on integrating these components for generating\na realistic 3D human dancing move from music, which can be applied to\nartificial agents and humanoid robots. The trained dance pose generator, which\nis a generative autoregressive model, is able to synthesize a dance sequence\nlonger than 5,000 pose frames. Experimental results of generated dance\nsequences from various songs show how the proposed method generates human-like\ndancing move to a given music. In addition, a generated 3D dance sequence is\napplied to a humanoid robot, showing that the proposed framework can make a\nrobot to dance just by listening to music.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:27:22 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ahn", "Hyemin", ""], ["Kim", "Jaehun", ""], ["Kim", "Kihyun", ""], ["Oh", "Songhwai", ""]]}, {"id": "1911.04107", "submitter": "Gang Chen", "authors": "Gang Chen, Dingcheng Li and Ran Xu", "title": "Context-aware Active Multi-Step Reinforcement Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has attracted great attention recently, especially\npolicy gradient algorithms, which have been demonstrated on challenging\ndecision making and control tasks. In this paper, we propose an active\nmulti-step TD algorithm with adaptive stepsizes to learn actor and critic.\nSpecifically, our model consists of two components: active stepsize learning\nand adaptive multi-step TD algorithm. Firstly, we divide the time horizon into\nchunks and actively select state and action inside each chunk. Then given the\nselected samples, we propose the adaptive multi-step TD, which generalizes\nTD($\\lambda$), but adaptively switch on/off the backups from future returns of\ndifferent steps. Particularly, the adaptive multi-step TD introduces a\ncontext-aware mechanism, here a binary classifier, which decides whether or not\nto turn on its future backups based on the context changes. Thus, our model is\nkind of combination of active learning and multi-step TD algorithm, which has\nthe capacity for learning off-policy without the need of importance sampling.\nWe evaluate our approach on both discrete and continuous space tasks in an\noff-policy setting respectively, and demonstrate competitive results compared\nto other reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:37:47 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 06:47:54 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Gang", ""], ["Li", "Dingcheng", ""], ["Xu", "Ran", ""]]}, {"id": "1911.04120", "submitter": "Emir Konuk Konuk", "authors": "Emir Konuk, Kevin Smith", "title": "An empirical study of the relation between network architecture and\n  complexity", "comments": "Accepted to ICCV 2019 Preregistration Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this preregistration submission, we propose an empirical study of how\nnetworks handle changes in complexity of the data. We investigate the effect of\nnetwork capacity on generalization performance in the face of increasing data\ncomplexity. For this, we measure the generalization error for an image\nclassification task where the number of classes steadily increases. We compare\na number of modern architectures at different scales in this setting. The\nmethodology, setup, and hypotheses described in this proposal were evaluated by\npeer review before experiments were conducted.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 07:45:01 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Konuk", "Emir", ""], ["Smith", "Kevin", ""]]}, {"id": "1911.04129", "submitter": "Songtao Liu", "authors": "Songtao Liu, Lingwei Chen, Hanze Dong, Zihao Wang, Dinghao Wu,\n  Zengfeng Huang", "title": "Higher-order Weighted Graph Convolutional Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Network (GCN) has been recognized as one of the most\neffective graph models for semi-supervised learning, but it extracts merely the\nfirst-order or few-order neighborhood information through information\npropagation, which suffers performance drop-off for deeper structure. Existing\napproaches that deal with the higher-order neighbors tend to take advantage of\nadjacency matrix power. In this paper, we assume a seemly trivial condition\nthat the higher-order neighborhood information may be similar to that of the\nfirst-order neighbors. Accordingly, we present an unsupervised approach to\ndescribe such similarities and learn the weight matrices of higher-order\nneighbors automatically through Lasso that minimizes the feature loss between\nthe first-order and higher-order neighbors, based on which we formulate the new\nconvolutional filter for GCN to learn the better node representations. Our\nmodel, called higher-order weighted GCN(HWGCN), has achieved the\nstate-of-the-art results on a number of node classification tasks over Cora,\nCiteseer and Pubmed datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:20:56 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 03:10:03 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Liu", "Songtao", ""], ["Chen", "Lingwei", ""], ["Dong", "Hanze", ""], ["Wang", "Zihao", ""], ["Wu", "Dinghao", ""], ["Huang", "Zengfeng", ""]]}, {"id": "1911.04143", "submitter": "Ziqiang Cheng", "authors": "Ziqiang Cheng, Yang Yang, Wei Wang, Wenjie Hu, Yueting Zhuang, Guojie\n  Song", "title": "Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets", "comments": "An extended version with 11 pages including appendix; Accepted by\n  AAAI'2020", "journal-ref": null, "doi": "10.1609/aaai.v34i04.5769", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series modeling has attracted extensive research efforts; however,\nachieving both reliable efficiency and interpretability from a unified model\nstill remains a challenging problem. Among the literature, shapelets offer\ninterpretable and explanatory insights in the classification tasks, while most\nexisting works ignore the differing representative power at different time\nslices, as well as (more importantly) the evolution pattern of shapelets. In\nthis paper, we propose to extract time-aware shapelets by designing a two-level\ntiming factor. Moreover, we define and construct the shapelet evolution graph,\nwhich captures how shapelets evolve over time and can be incorporated into the\ntime series embeddings by graph embedding algorithms. To validate whether the\nrepresentations obtained in this way can be applied effectively in various\nscenarios, we conduct experiments based on three public time series datasets,\nand two real-world datasets from different domains. Experimental results\nclearly show the improvements achieved by our approach compared with 17\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:55:55 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 12:28:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cheng", "Ziqiang", ""], ["Yang", "Yang", ""], ["Wang", "Wei", ""], ["Hu", "Wenjie", ""], ["Zhuang", "Yueting", ""], ["Song", "Guojie", ""]]}, {"id": "1911.04174", "submitter": "Hiroshi Kera", "authors": "Hiroshi Kera, Yoshihiko Hasegawa", "title": "Gradient Boosts the Approximate Vanishing Ideal", "comments": "9+10 pages, 1+4 figures, AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the approximate vanishing ideal and its basis\nconstruction algorithms have been extensively studied in computer algebra and\nmachine learning as a general model to reconstruct the algebraic variety on\nwhich noisy data approximately lie. In particular, the basis construction\nalgorithms developed in machine learning are widely used in applications across\nmany fields because of their monomial-order-free property; however, they lose\nmany of the theoretical properties of computer-algebraic algorithms. In this\npaper, we propose general methods that equip monomial-order-free algorithms\nwith several advantageous theoretical properties. Specifically, we exploit the\ngradient to (i) sidestep the spurious vanishing problem in polynomial time to\nremove symbolically trivial redundant bases, (ii) achieve consistent output\nwith respect to the translation and scaling of input, and (iii) remove\nnontrivially redundant bases. The proposed methods work in a fully numerical\nmanner, whereas existing algorithms require the awkward monomial order or\nexponentially costly (and mostly symbolic) computation to realize properties\n(i) and (iii). To our knowledge, property (ii) has not been achieved by any\nexisting basis construction algorithm of the approximate vanishing ideal.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:52:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kera", "Hiroshi", ""], ["Hasegawa", "Yoshihiko", ""]]}, {"id": "1911.04175", "submitter": "Praveen Palanisamy", "authors": "Praveen Palanisamy", "title": "Multi-Agent Connected Autonomous Driving using Deep Reinforcement\n  Learning", "comments": "Accepted, Machine Learning for Autonomous Driving Workshop at the\n  33rd Conference on Neural Information Processing Systems(NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to learn and adapt to changes in the driving environment is\ncrucial for developing autonomous driving systems that are scalable beyond\ngeo-fenced operational design domains. Deep Reinforcement Learning (RL)\nprovides a promising and scalable framework for developing adaptive learning\nbased solutions. Deep RL methods usually model the problem as a (Partially\nObservable) Markov Decision Process in which an agent acts in a stationary\nenvironment to learn an optimal behavior policy. However, driving involves\ncomplex interaction between multiple, intelligent (artificial or human) agents\nin a highly non-stationary environment. In this paper, we propose the use of\nPartially Observable Markov Games(POSG) for formulating the connected\nautonomous driving problems with realistic assumptions. We provide a taxonomy\nof multi-agent learning environments based on the nature of tasks, nature of\nagents and the nature of the environment to help in categorizing various\nautonomous driving problems that can be addressed under the proposed\nformulation. As our main contributions, we provide MACAD-Gym, a Multi-Agent\nConnected, Autonomous Driving agent learning platform for furthering research\nin this direction. Our MACAD-Gym platform provides an extensible set of\nConnected Autonomous Driving (CAD) simulation environments that enable the\nresearch and development of Deep RL- based integrated sensing, perception,\nplanning and control algorithms for CAD systems with unlimited operational\ndesign domain under realistic, multi-agent settings. We also share the\nMACAD-Agents that were trained successfully using the MACAD-Gym platform to\nlearn control policies for multiple vehicle agents in a partially observable,\nstop-sign controlled, 3-way urban intersection environment with raw (camera)\nsensor observations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:55:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Palanisamy", "Praveen", ""]]}, {"id": "1911.04180", "submitter": "M. Alex O. Vasilescu", "authors": "M. Alex O. Vasilescu and Eric Kim", "title": "Compositional Hierarchical Tensor Factorization: Representing\n  Hierarchical Intrinsic and Extrinsic Causal Factors", "comments": "VERS 2: Fixed out of sync ref. Added\n  [7,14,15,28,37,50,52,53,61,77,78] M.A.O. Vasilescu and E.Kim. Compositional\n  Hierarchical Tensor Factorization: Representing Hierarchical Intrinsic and\n  Extrinsic Causal Factors. In 25th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD'19): Tensor Methods for Emerging Data Science\n  Challenges, August 04-08, 2019, Anchorage, AK.ACM, New York, NY", "journal-ref": "25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD'19): Tensor Methods for Emerging Data Science Challenges Workshop,\n  August 04-08, 2019, Anchorage, AK.ACM, New York, NY", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual objects are composed of a recursive hierarchy of perceptual wholes and\nparts, whose properties, such as shape, reflectance, and color, constitute a\nhierarchy of intrinsic causal factors of object appearance. However, object\nappearance is the compositional consequence of both an object's intrinsic and\nextrinsic causal factors, where the extrinsic causal factors are related to\nillumination, and imaging conditions. Therefore, this paper proposes a unified\ntensor model of wholes and parts, and introduces a compositional hierarchical\ntensor factorization that disentangles the hierarchical causal structure of\nobject image formation, and subsumes multilinear block tensor decomposition as\na special case. The resulting object representation is an interpretable\ncombinatorial choice of wholes' and parts' representations that renders object\nrecognition robust to occlusion and reduces training data requirements. We\ndemonstrate ourapproach in the context of face recognition by training on an\nextremely reduced dataset of synthetic images, and report encouragingface\nverification results on two datasets - the Freiburg dataset, andthe Labeled\nFace in the Wild (LFW) dataset consisting of real world images, thus,\nsubstantiating the suitability of our approach for data starved domains.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 11:03:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 06:23:19 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Vasilescu", "M. Alex O.", ""], ["Kim", "Eric", ""]]}, {"id": "1911.04206", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zeyi Wen, Bingsheng He", "title": "Practical Federated Gradient Boosting Decision Trees", "comments": "Accepted to AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosting Decision Trees (GBDTs) have become very successful in\nrecent years, with many awards in machine learning and data mining\ncompetitions. There have been several recent studies on how to train GBDTs in\nthe federated learning setting. In this paper, we focus on horizontal federated\nlearning, where data samples with the same features are distributed among\nmultiple parties. However, existing studies are not efficient or effective\nenough for practical use. They suffer either from the inefficiency due to the\nusage of costly data transformations such as secret sharing and homomorphic\nencryption, or from the low model accuracy due to differential privacy designs.\nIn this paper, we study a practical federated environment with relaxed privacy\nconstraints. In this environment, a dishonest party might obtain some\ninformation about the other parties' data, but it is still impossible for the\ndishonest party to derive the actual raw data of other parties. Specifically,\neach party boosts a number of trees by exploiting similarity information based\non locality-sensitive hashing. We prove that our framework is secure without\nexposing the original record to other parties, while the computation overhead\nin the training process is kept low. Our experimental studies show that,\ncompared with normal training with the local data of each party, our approach\ncan significantly improve the predictive accuracy, and achieve comparable\naccuracy to the original GBDT with the data from all parties.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:15:23 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:15:43 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Li", "Qinbin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.04207", "submitter": "Ling Pan", "authors": "Ling Pan, Qingpeng Cai, Longbo Huang", "title": "Multi-Path Policy Optimization", "comments": "AAMAS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a tremendous improvement of deep reinforcement\nlearning. However, a challenging problem is that an agent may suffer from\ninefficient exploration, particularly for on-policy methods. Previous\nexploration methods either rely on complex structure to estimate the novelty of\nstates, or incur sensitive hyper-parameters causing instability. We propose an\nefficient exploration method, Multi-Path Policy Optimization (MPPO), which does\nnot incur high computation cost and ensures stability. MPPO maintains an\nefficient mechanism that effectively utilizes a population of diverse policies\nto enable better exploration, especially in sparse environments. We also give a\ntheoretical guarantee of the stable performance. We build our scheme upon two\nwidely-adopted on-policy methods, the Trust-Region Policy Optimization\nalgorithm and Proximal Policy Optimization algorithm. We conduct extensive\nexperiments on several MuJoCo tasks and their sparsified variants to fairly\nevaluate the proposed method. Results show that MPPO significantly outperforms\nstate-of-the-art exploration methods in terms of both sample efficiency and\nfinal performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:19:23 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 06:34:06 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:17:23 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pan", "Ling", ""], ["Cai", "Qingpeng", ""], ["Huang", "Longbo", ""]]}, {"id": "1911.04209", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zhaomin Wu, Zeyi Wen, Bingsheng He", "title": "Privacy-Preserving Gradient Boosting Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gradient Boosting Decision Tree (GBDT) is a popular machine learning\nmodel for various tasks in recent years. In this paper, we study how to improve\nmodel accuracy of GBDT while preserving the strong guarantee of differential\nprivacy. Sensitivity and privacy budget are two key design aspects for the\neffectiveness of differential private models. Existing solutions for GBDT with\ndifferential privacy suffer from the significant accuracy loss due to too loose\nsensitivity bounds and ineffective privacy budget allocations (especially\nacross different trees in the GBDT model). Loose sensitivity bounds lead to\nmore noise to obtain a fixed privacy level. Ineffective privacy budget\nallocations worsen the accuracy loss especially when the number of trees is\nlarge. Therefore, we propose a new GBDT training algorithm that achieves\ntighter sensitivity bounds and more effective noise allocations. Specifically,\nby investigating the property of gradient and the contribution of each tree in\nGBDTs, we propose to adaptively control the gradients of training data for each\niteration and leaf node clipping in order to tighten the sensitivity bounds.\nFurthermore, we design a novel boosting framework to allocate the privacy\nbudget between trees so that the accuracy loss can be further reduced. Our\nexperiments show that our approach can achieve much better model accuracy than\nother baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:20:24 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 16:24:01 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 02:38:31 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 06:25:41 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Li", "Qinbin", ""], ["Wu", "Zhaomin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.04221", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Convergence to minima for the continuous version of Backtracking\n  Gradient Descent", "comments": "20 pages. Definition 1.2 is revised to ensure that Armijo's condition\n  is satisfied. A part iv is added to Theorem 1.3. For readers' convenience,\n  two lemmas are added to help make proofs easy to follow. Typos corrected,\n  exposition revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result of this paper is:\n  {\\bf Theorem.} Let $f:\\mathbb{R}^k\\rightarrow \\mathbb{R}$ be a $C^{1}$\nfunction, so that $\\nabla f$ is locally Lipschitz continuous. Assume moreover\nthat $f$ is $C^2$ near its generalised saddle points. Fix real numbers\n$\\delta_0>0$ and $0<\\alpha <1$. Then there is a smooth function\n$h:\\mathbb{R}^k\\rightarrow (0,\\delta_0]$ so that the map\n$H:\\mathbb{R}^k\\rightarrow \\mathbb{R}^k$ defined by $H(x)=x-h(x)\\nabla f(x)$\nhas the following property:\n  (i) For all $x\\in \\mathbb{R}^k$, we have $f(H(x)))-f(x)\\leq -\\alpha\nh(x)||\\nabla f(x)||^2$.\n  (ii) For every $x_0\\in \\mathbb{R}^k$, the sequence $x_{n+1}=H(x_n)$ either\nsatisfies $\\lim_{n\\rightarrow\\infty}||x_{n+1}-x_n||=0$ or $\n\\lim_{n\\rightarrow\\infty}||x_n||=\\infty$. Each cluster point of $\\{x_n\\}$ is a\ncritical point of $f$. If moreover $f$ has at most countably many critical\npoints, then $\\{x_n\\}$ either converges to a critical point of $f$ or\n$\\lim_{n\\rightarrow\\infty}||x_n||=\\infty$.\n  (iii) There is a set $\\mathcal{E}_1\\subset \\mathbb{R}^k$ of Lebesgue measure\n$0$ so that for all $x_0\\in \\mathbb{R}^k\\backslash \\mathcal{E}_1$, the sequence\n$x_{n+1}=H(x_n)$, {\\bf if converges}, cannot converge to a {\\bf generalised}\nsaddle point.\n  (iv) There is a set $\\mathcal{E}_2\\subset \\mathbb{R}^k$ of Lebesgue measure\n$0$ so that for all $x_0\\in \\mathbb{R}^k\\backslash \\mathcal{E}_2$, any cluster\npoint of the sequence $x_{n+1}=H(x_n)$ is not a saddle point, and more\ngenerally cannot be an isolated generalised saddle point.\n  Some other results are proven.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:58:21 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 12:54:04 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "1911.04225", "submitter": "Adarsh Barik", "authors": "Adarsh Barik and Jean Honorio", "title": "Provable Computational and Statistical Guarantees for Efficient Learning\n  of Continuous-Action Graphical Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning the set of pure strategy Nash\nequilibria and the exact structure of a continuous-action graphical game with\nquadratic payoffs by observing a small set of perturbed equilibria. A\ncontinuous-action graphical game can possibly have an uncountable set of Nash\neuqilibria. We propose a $\\ell_{12}-$ block regularized method which recovers a\ngraphical game, whose Nash equilibria are the $\\epsilon$-Nash equilibria of the\ngame from which the data was generated (true game). Under a slightly stringent\ncondition on the parameters of the true game, our method recovers the exact\nstructure of the graphical game. Our method has a logarithmic sample complexity\nwith respect to the number of players. It also runs in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:49:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "1911.04227", "submitter": "Valentina Zantedeschi Dr", "authors": "Valentina Zantedeschi, Fabrizio Falasca, Alyson Douglas, Richard\n  Strange, Matt J. Kusner, Duncan Watson-Parris", "title": "Cumulo: A Dataset for Learning Cloud Classes", "comments": null, "journal-ref": "Tackling Climate Change with Machine Learning Workshop, 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "physics.ao-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest sources of uncertainty in future climate projections\ncomes from limitations in modelling clouds and in understanding how different\ncloud types interact with the climate system. A key first step in reducing this\nuncertainty is to accurately classify cloud types at high spatial and temporal\nresolution. In this paper, we introduce Cumulo, a benchmark dataset for\ntraining and evaluating global cloud classification models. It consists of one\nyear of 1km resolution MODIS hyperspectral imagery merged with pixel-width\n'tracks' of CloudSat cloud labels. Bringing these complementary datasets\ntogether is a crucial first step, enabling the Machine-Learning community to\ndevelop innovative new techniques which could greatly benefit the Climate\ncommunity. To showcase Cumulo, we provide baseline performance analysis using\nan invertible flow generative model (IResNet), which further allows us to\ndiscover new sub-classes for a given cloud class by exploring the latent space.\nTo compare methods, we introduce a set of evaluation criteria, to identify\nmodels that are not only accurate, but also physically-realistic. CUMULO can be\ndownload from\nhttps://www.dropbox.com/sh/6gca7f0mb3b0ikz/AADq2lk4u7k961Qa31FwIDEpa?dl=0 .\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:36:16 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 10:01:33 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Zantedeschi", "Valentina", ""], ["Falasca", "Fabrizio", ""], ["Douglas", "Alyson", ""], ["Strange", "Richard", ""], ["Kusner", "Matt J.", ""], ["Watson-Parris", "Duncan", ""]]}, {"id": "1911.04240", "submitter": "Nikhil Muralidhar", "authors": "Nikhil Muralidhar, Jie Bu, Ze Cao, Long He, Naren Ramakrishnan, Danesh\n  Tafti, Anuj Karpatne", "title": "Physics-guided Design and Learning of Neural Networks for Predicting\n  Drag Force on Particle Suspensions in Moving Fluids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-based simulations are often used to model and understand complex\nphysical systems and processes in domains like fluid dynamics. Such\nsimulations, although used frequently, have many limitations which could arise\neither due to the inability to accurately model a physical process owing to\nincomplete knowledge about certain facets of the process or due to the\nunderlying process being too complex to accurately encode into a simulation\nmodel. In such situations, it is often useful to rely on machine learning\nmethods to fill in the gap by learning a model of the complex physical process\ndirectly from simulation data. However, as data generation through simulations\nis costly, we need to develop models, being cognizant of data paucity issues.\nIn such scenarios it is often helpful if the rich physical knowledge of the\napplication domain is incorporated in the architectural design of machine\nlearning models. Further, we can also use information from physics-based\nsimulations to guide the learning process using aggregate supervision to\nfavorably constrain the learning process. In this paper, we propose PhyDNN, a\ndeep learning model using physics-guided structural priors and physics-guided\naggregate supervision for modeling the drag forces acting on each particle in a\nComputational Fluid Dynamics-Discrete Element Method(CFD-DEM). We conduct\nextensive experiments in the context of drag force prediction and showcase the\nusefulness of including physics knowledge in our deep learning formulation both\nin the design and through learning process. Our proposed PhyDNN model has been\ncompared to several state-of-the-art models and achieves a significant\nperformance improvement of 8.46% on average across all baseline models. The\nsource code has been made available and the dataset used is detailed in [1, 2].\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:05:37 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Muralidhar", "Nikhil", ""], ["Bu", "Jie", ""], ["Cao", "Ze", ""], ["He", "Long", ""], ["Ramakrishnan", "Naren", ""], ["Tafti", "Danesh", ""], ["Karpatne", "Anuj", ""]]}, {"id": "1911.04252", "submitter": "Qizhe Xie", "authors": "Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le", "title": "Self-training with Noisy Student improves ImageNet classification", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Noisy Student Training, a semi-supervised learning approach that\nworks well even when labeled data is abundant. Noisy Student Training achieves\n88.4% top-1 accuracy on ImageNet, which is 2.0% better than the\nstate-of-the-art model that requires 3.5B weakly labeled Instagram images. On\nrobustness test sets, it improves ImageNet-A top-1 accuracy from 61.0% to\n83.7%, reduces ImageNet-C mean corruption error from 45.7 to 28.3, and reduces\nImageNet-P mean flip rate from 27.8 to 12.2.\n  Noisy Student Training extends the idea of self-training and distillation\nwith the use of equal-or-larger student models and noise added to the student\nduring learning. On ImageNet, we first train an EfficientNet model on labeled\nimages and use it as a teacher to generate pseudo labels for 300M unlabeled\nimages. We then train a larger EfficientNet as a student model on the\ncombination of labeled and pseudo labeled images. We iterate this process by\nputting back the student as the teacher. During the learning of the student, we\ninject noise such as dropout, stochastic depth, and data augmentation via\nRandAugment to the student so that the student generalizes better than the\nteacher. Models are available at\nhttps://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.\nCode is available at https://github.com/google-research/noisystudent.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:59:27 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:07:57 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 22:27:37 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 17:36:57 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Xie", "Qizhe", ""], ["Luong", "Minh-Thang", ""], ["Hovy", "Eduard", ""], ["Le", "Quoc V.", ""]]}, {"id": "1911.04278", "submitter": "Giulio Zizzo", "authors": "Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones", "title": "Intrusion Detection for Industrial Control Systems: Evaluation Analysis\n  and Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly used in security applications for intrusion\ndetection on industrial control systems. In this work we examine two areas that\nmust be considered for their effective use. Firstly, is their vulnerability to\nadversarial attacks when used in a time series setting. Secondly, is potential\nover-estimation of performance arising from data leakage artefacts.\n  To investigate these areas we implement a long short-term memory (LSTM) based\nintrusion detection system (IDS) which effectively detects cyber-physical\nattacks on a water treatment testbed representing a strong baseline IDS.\n  For investigating adversarial attacks we model two different white box\nattackers. The first attacker is able to manipulate sensor readings on a subset\nof the Secure Water Treatment (SWaT) system. By creating a stream of\nadversarial data the attacker is able to hide the cyber-physical attacks from\nthe IDS. For the cyber-physical attacks which are detected by the IDS, the\nattacker required on average 2.48 out of 12 total sensors to be compromised for\nthe cyber-physical attacks to be hidden from the IDS. The second attacker model\nwe explore is an $L_{\\infty}$ bounded attacker who can send fake readings to\nthe IDS, but to remain imperceptible, limits their perturbations to the\nsmallest $L_{\\infty}$ value needed.\n  Additionally, we examine data leakage problems arising from tuning for $F_1$\nscore on the whole SWaT attack set and propose a method to tune detection\nparameters that does not utilise any attack data. If attack after-effects are\naccounted for then our new parameter tuning method achieved an $F_1$ score of\n0.811$\\pm$0.0103.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:27:33 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zizzo", "Giulio", ""], ["Hankin", "Chris", ""], ["Maffeis", "Sergio", ""], ["Jones", "Kevin", ""]]}, {"id": "1911.04285", "submitter": "Patrick Flaherty", "authors": "Patrick Flaherty, Pitchaya Wiratchotisatian, Ji Ah Lee, Zhou Tang,\n  Andrew C. Trapp", "title": "MAP Clustering under the Gaussian Mixture Model via Mixed Integer\n  Nonlinear Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a global optimization approach for solving the maximum\na-posteriori (MAP) clustering problem under the Gaussian mixture model.Our\napproach can accommodate side constraints and it preserves the combinatorial\nstructure of the MAP clustering problem by formulating it asa mixed-integer\nnonlinear optimization problem (MINLP). We approximate the MINLP through a\nmixed-integer quadratic program (MIQP) transformation that improves\ncomputational aspects while guaranteeing $\\epsilon$-global optimality. An\nimportant benefit of our approach is the explicit quantification of the degree\nof suboptimality, via the optimality gap, en route to finding the globally\noptimal MAP clustering. Numerical experiments comparing our method to other\napproaches show that our method finds a better solution than standard\nclustering methods. Finally, we cluster a real breast cancer gene expression\ndata set incorporating intrinsic subtype information; the induced constraints\nsubstantially improve the computational performance and produce more coherent\nand bio-logically meaningful clusters.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:53:26 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 02:51:11 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Flaherty", "Patrick", ""], ["Wiratchotisatian", "Pitchaya", ""], ["Lee", "Ji Ah", ""], ["Tang", "Zhou", ""], ["Trapp", "Andrew C.", ""]]}, {"id": "1911.04289", "submitter": "Maria Ines Meyer", "authors": "Maria Ines Meyer and Ezequiel de la Rosa and Koen Van Leemput and\n  Diana M. Sima", "title": "Relevance Vector Machines for harmonization of MRI brain volumes using\n  image descriptors", "comments": "9 pages, 4 figures. Presented at the International Workshop on\n  Machine Learning in Clinical Neuroimaging (MLCN) 2019", "journal-ref": "OR 2.0 Context-Aware Operating Theaters and Machine Learning in\n  Clinical Neuroimaging. OR 2.0 2019, MLCN 2019. Lecture Notes in Computer\n  Science, vol 11796. Springer, Cham", "doi": "10.1007/978-3-030-32695-1_9", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased need for multi-center magnetic resonance imaging studies,\nproblems arise related to differences in hardware and software between centers.\nNamely, current algorithms for brain volume quantification are unreliable for\nthe longitudinal assessment of volume changes in this type of setting.\nCurrently most methods attempt to decrease this issue by regressing the\nscanner- and/or center-effects from the original data. In this work, we explore\na novel approach to harmonize brain volume measurements by using only image\ndescriptors. First, we explore the relationships between volumes and image\ndescriptors. Then, we train a Relevance Vector Machine (RVM) model over a large\nmulti-site dataset of healthy subjects to perform volume harmonization.\nFinally, we validate the method over two different datasets: i) a subset of\nunseen healthy controls; and ii) a test-retest dataset of multiple sclerosis\n(MS) patients. The method decreases scanner and center variability while\npreserving measurements that did not require correction in MS patient data. We\nshow that image descriptors can be used as input to a machine learning\nalgorithm to improve the reliability of longitudinal volumetric studies.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:37:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Meyer", "Maria Ines", ""], ["de la Rosa", "Ezequiel", ""], ["Van Leemput", "Koen", ""], ["Sima", "Diana M.", ""]]}, {"id": "1911.04291", "submitter": "Matthias Mehlhose", "authors": "Matthias Mehlhose, Daniyal Amir Awany, Renato L. G. Cavalcante, Martin\n  Kurras and Slawomir Stanczak", "title": "Machine Learning-Based Adaptive Receive Filtering: Proof-of-Concept on\n  an SDR Platform", "comments": "submitted to ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional multiuser detection techniques either require a large number of\nantennas at the receiver for a desired performance, or they are too complex for\npractical implementation. Moreover, many of these techniques, such as\nsuccessive interference cancellation (SIC), suffer from errors in parameter\nestimation (user channels, covariance matrix, noise variance, etc.) that is\nperformed before detection of user data symbols. As an alternative to\nconventional methods, this paper proposes and demonstrates a low-complexity\npractical Machine Learning (ML) based receiver that achieves similar (and at\ntimes better) performance to the SIC receiver. The proposed receiver does not\nrequire parameter estimation; instead it uses supervised learning to detect the\nuser modulation symbols directly. We perform comparisons with minimum mean\nsquare error (MMSE) and SIC receivers in terms of symbol error rate (SER) and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:10:44 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Mehlhose", "Matthias", ""], ["Awany", "Daniyal Amir", ""], ["Cavalcante", "Renato L. G.", ""], ["Kurras", "Martin", ""], ["Stanczak", "Slawomir", ""]]}, {"id": "1911.04293", "submitter": "Ting Tao", "authors": "Ting Tao, Shaohua Pan and Shujun Bi", "title": "Error bound of critical points and KL property of exponent $1/2$ for\n  squared F-norm regularized factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the squared F(robenius)-norm regularized\nfactorization form for noisy low-rank matrix recovery problems. Under a\nsuitable assumption on the restricted condition number of the Hessian for the\nloss function, we derive an error bound to the true matrix for the non-strict\ncritical points with rank not more than that of the true matrix. Then, for the\nsquared F-norm regularized factorized least squares loss function, under the\nnoisy and full sample setting we establish its KL property of exponent $1/2$ on\nits global minimizer set, and under the noisy and partial sample setting\nachieve this property for a class of critical points. These theoretical\nfindings are also confirmed by solving the squared F-norm regularized\nfactorization problem with an accelerated alternating minimization method.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:14:13 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 13:15:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tao", "Ting", ""], ["Pan", "Shaohua", ""], ["Bi", "Shujun", ""]]}, {"id": "1911.04301", "submitter": "Antonia Marcu", "authors": "Antonia Marcu and Adam Pr\\\"ugel-Bennett", "title": "Rethinking Generalisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new approach to computing the generalisation performance is\npresented that assumes the distribution of risks, $\\rho(r)$, for a learning\nscenario is known. From this, the expected error of a learning machine using\nempirical risk minimisation is computed for both classification and regression\nproblems. A critical quantity in determining the generalisation performance is\nthe power-law behaviour of $\\rho(r)$ around its minimum value---a quantity we\ncall attunement. The distribution $\\rho(r)$ is computed for the case of all\nBoolean functions and for the perceptron used in two different problem\nsettings. Initially a simplified analysis is presented where an independence\nassumption about the losses is made. A more accurate analysis is carried out\ntaking into account chance correlations in the training set. This leads to\ncorrections in the typical behaviour that is observed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:25:50 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 15:03:06 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Marcu", "Antonia", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1911.04307", "submitter": "Douglas Leith", "authors": "Daron Anderson and Douglas J. Leith", "title": "Learning The Best Expert Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning problems where the aim is to achieve regret which\nis efficient in the sense that it is the same order as the lowest regret\namongst K experts. This is a substantially stronger requirement that achieving\n$O(\\sqrt{n})$ or $O(\\log n)$ regret with respect to the best expert and\nstandard algorithms are insufficient, even in easy cases where the regrets of\nthe available actions are very different from one another. We show that a\nparticular lazy form of the online subgradient algorithm can be used to achieve\nminimal regret in a number of \"easy\" regimes while retaining an $O(\\sqrt{n})$\nworst-case regret guarantee. We also show that for certain classes of problem\nminimal regret strategies exist for some of the remaining \"hard\" regimes.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:40:04 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Anderson", "Daron", ""], ["Leith", "Douglas J.", ""]]}, {"id": "1911.04317", "submitter": "Aravind Sampathkumar", "authors": "Jiayi He, Aravind Sampath Kumar, Arun Chada, Bhyrav Mutnury, James\n  Drewniak", "title": "Machine Learning for high speed channel optimization", "comments": "3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Design of printed circuit board (PCB) stack-up requires the consideration of\ncharacteristic impedance, insertion loss and crosstalk. As there are many\nparameters in a PCB stack-up design, the optimization of these parameters needs\nto be efficient and accurate. A less optimal stack-up would lead to expensive\nPCB material choices in high speed designs. In this paper, an efficient global\noptimization method using parallel and intelligent Bayesian optimization is\nproposed for the stripline design.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:46:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["He", "Jiayi", ""], ["Kumar", "Aravind Sampath", ""], ["Chada", "Arun", ""], ["Mutnury", "Bhyrav", ""], ["Drewniak", "James", ""]]}, {"id": "1911.04322", "submitter": "Zhu Li", "authors": "Zhu Li, Adrian Perez-Suay, Gustau Camps-Valls, Dino Sejdinovic", "title": "Kernel Dependence Regularizers and Gaussian Processes with Applications\n  to Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current adoption of machine learning in industrial, societal and economical\nactivities has raised concerns about the fairness, equity and ethics of\nautomated decisions. Predictive models are often developed using biased\ndatasets and thus retain or even exacerbate biases in their decisions and\nrecommendations. Removing the sensitive covariates, such as gender or race, is\ninsufficient to remedy this issue since the biases may be retained due to other\nrelated covariates. We present a regularization approach to this problem that\ntrades off predictive accuracy of the learned models (with respect to biased\nlabels) for the fairness in terms of statistical parity, i.e. independence of\nthe decisions from the sensitive covariates. In particular, we consider a\ngeneral framework of regularized empirical risk minimization over reproducing\nkernel Hilbert spaces and impose an additional regularizer of dependence\nbetween predictors and sensitive covariates using kernel-based measures of\ndependence, namely the Hilbert-Schmidt Independence Criterion (HSIC) and its\nnormalized version. This approach leads to a closed-form solution in the case\nof squared loss, i.e. ridge regression. Moreover, we show that the dependence\nregularizer has an interpretation as modifying the corresponding Gaussian\nprocess (GP) prior. As a consequence, a GP model with a prior that encourages\nfairness to sensitive variables can be derived, allowing principled\nhyperparameter selection and studying of the relative relevance of covariates\nunder fairness constraints. Experimental results in synthetic examples and in\nreal problems of income and crime prediction illustrate the potential of the\napproach to improve fairness of automated decisions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:09:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Zhu", ""], ["Perez-Suay", "Adrian", ""], ["Camps-Valls", "Gustau", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1911.04335", "submitter": "Fabian Horst", "authors": "Johannes Burdack, Fabian Horst, Sven Giesselbach, Ibrahim Hassan,\n  Sabrina Daffner, Wolfgang I. Sch\\\"ollhorn", "title": "Systematic Comparison of the Influence of Different Data Preprocessing\n  Methods on the Performance of Gait Classifications Using Machine Learning", "comments": "12 pages, 3 figures, 4 tables", "journal-ref": "Front. Bioeng. Biotechnol. 8 (2020) 260", "doi": "10.3389/fbioe.2020.00260", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human movements are characterized by highly non-linear and multi-dimensional\ninteractions within the motor system. Recently, an increasing emphasis on\nmachine-learning applications has led to a significant contribution to the\nfield of gait analysis, e.g., in increasing the classification performance. In\norder to ensure the generalizability of the machine-learning models, different\ndata preprocessing steps are usually carried out to process the measured raw\ndata before the classifications. In the past, various methods have been used\nfor each of these preprocessing steps. However, there are hardly any standard\nprocedures or rather systematic comparisons of these different methods and\ntheir impact on the classification performance. Therefore, the aim of this\nanalysis is to compare different combinations of commonly applied data\npreprocessing steps and test their effects on the classification performance of\ngait patterns. A publicly available dataset on intra-individual changes of gait\npatterns was used for this analysis. Forty-two healthy participants performed 6\nsessions of 15 gait trials for 1 day. For each trial, two force plates recorded\nthe 3D ground reaction forces (GRFs). The data was preprocessed with the\nfollowing steps: GRF filtering, time derivative, time normalization, data\nreduction, weight normalization and data scaling. Subsequently, combinations of\nall methods from each preprocessing step were analyzed by comparing their\nprediction performance in a six-session classification using Support Vector\nMachines, Random Forest Classifiers, Multi-Layer Perceptrons, and Convolutional\nNeural Networks. In conclusion, the present results provide first\ndomain-specific recommendations for commonly applied data preprocessing methods\nand might help to build more comparable and more robust classification models\nbased on machine learning that are suitable for a practical application.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:27:40 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 15:15:00 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Burdack", "Johannes", ""], ["Horst", "Fabian", ""], ["Giesselbach", "Sven", ""], ["Hassan", "Ibrahim", ""], ["Daffner", "Sabrina", ""], ["Sch\u00f6llhorn", "Wolfgang I.", ""]]}, {"id": "1911.04336", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sorelle Friedler, Emile Givental", "title": "Fair Meta-Learning: Learning How to Learn Fairly", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.09092", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sets for fairness relevant tasks can lack examples or be biased\naccording to a specific label in a sensitive attribute. We demonstrate the\nusefulness of weight based meta-learning approaches in such situations. For\nmodels that can be trained through gradient descent, we demonstrate that there\nare some parameter configurations that allow models to be optimized from a few\nnumber of gradient steps and with minimal data which are both fair and\naccurate. To learn such weight sets, we adapt the popular MAML algorithm to\nFair-MAML by the inclusion of a fairness regularization term. In practice,\nFair-MAML allows practitioners to train fair machine learning models from only\na few examples when data from related tasks is available. We empirically\nexhibit the value of this technique by comparing to relevant baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 21:43:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Slack", "Dylan", ""], ["Friedler", "Sorelle", ""], ["Givental", "Emile", ""]]}, {"id": "1911.04351", "submitter": "Talha Cihad Gulcu", "authors": "Talha Cihad Gulcu", "title": "Stronger Convergence Results for Deep Residual Networks: Network Width\n  Scales Linearly with Training Data Size", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are highly expressive machine learning models with the\nability to interpolate arbitrary datasets. Deep nets are typically optimized\nvia first-order methods and the optimization process crucially depends on the\ncharacteristics of the network as well as the dataset. This work sheds light on\nthe relation between the network size and the properties of the dataset with an\nemphasis on deep residual networks (ResNets). Our contribution is that if the\nnetwork Jacobian is full rank, gradient descent for the quadratic loss and\nsmooth activation converges to the global minima even if the network width $m$\nof the ResNet scales linearly with the sample size $n$, and independently from\nthe network depth. To the best of our knowledge, this is the first work which\nprovides a theoretical guarantee for the convergence of neural networks in the\n$m=\\Omega(n)$ regime.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:50:11 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gulcu", "Talha Cihad", ""]]}, {"id": "1911.04362", "submitter": "Nicole Fitzgerald", "authors": "Nicole Fitzgerald", "title": "To Populate is To Regulate", "comments": "EmeCom Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effects of instantiating Lewis signaling games within a\npopulation of speaker and listener agents with the aim of producing a set of\ngeneral and robust representations of unstructured pixel data. Preliminary\nexperiments suggest that the set of representations associated with languages\ngenerated within a population outperform those generated between a single\nspeaker-listener pair on this objective, making a case for the adoption of\npopulation-based approaches in emergent communication studies. Furthermore,\npost-hoc analysis reveals that population-based learning induces a number of\nnovel factors to the conventional emergent communication setup, inviting a wide\nrange of future research questions regarding communication dynamics and the\nflow of information within them.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:51:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fitzgerald", "Nicole", ""]]}, {"id": "1911.04377", "submitter": "Attila Lovas", "authors": "Attila Lovas and Mikl\\'os R\\'asonyi", "title": "Markov chains in random environment with applications in queueing theory\n  and machine learning", "comments": "34 pages, 3rd version, we extended the applicability of our theorems\n  to autoregressive processes in random environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the existence of limiting distributions for a large class of Markov\nchains on a general state space in a random environment. We assume suitable\nversions of the standard drift and minorization conditions. In particular, the\nsystem dynamics should be contractive on the average with respect to the\nLyapunov function and large enough small sets should exist with large enough\nminorization constants. We also establish that a law of large numbers holds for\nbounded functionals of the process. Applications to queuing systems, to machine\nlearning algorithms and to autoregressive processes are presented.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:39:58 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:26:47 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 12:35:38 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Lovas", "Attila", ""], ["R\u00e1sonyi", "Mikl\u00f3s", ""]]}, {"id": "1911.04379", "submitter": "Sharaj Panwar", "authors": "Sharaj Panwar, Paul Rad, Tzyy-Ping Jung, Yufei Huang", "title": "Modeling EEG data distribution with a Wasserstein Generative Adversarial\n  Network to predict RSVP Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) data are difficult to obtain due to complex\nexperimental setups and reduced comfort with prolonged wearing. This poses\nchallenges to train powerful deep learning model with the limited EEG data.\nBeing able to generate EEG data computationally could address this limitation.\nWe propose a novel Wasserstein Generative Adversarial Network with gradient\npenalty (WGAN-GP) to synthesize EEG data. This network addresses several\nmodeling challenges of simulating time-series EEG data including frequency\nartifacts and training instability. We further extended this network to a\nclass-conditioned variant that also includes a classification branch to perform\nevent-related classification. We trained the proposed networks to generate one\nand 64-channel data resembling EEG signals routinely seen in a rapid serial\nvisual presentation (RSVP) experiment and demonstrated the validity of the\ngenerated samples. We also tested intra-subject cross-session classification\nperformance for classifying the RSVP target events and showed that\nclass-conditioned WGAN-GP can achieve improved event-classification performance\nover EEGNet.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:43:06 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 16:17:27 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Panwar", "Sharaj", ""], ["Rad", "Paul", ""], ["Jung", "Tzyy-Ping", ""], ["Huang", "Yufei", ""]]}, {"id": "1911.04383", "submitter": "Zilong Zhao", "authors": "Zilong Zhao, Robert Birke, Rui Han, Bogdan Robu, Sara Bouchenak, Sonia\n  Ben Mokhtar, Lydia Y. Chen", "title": "RAD: On-line Anomaly Detection for Highly Unreliable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms have been widely adopted to detect anomalies for\nvarious systems, e.g., IoT, cloud and face recognition, under the common\nassumption that the data source is clean, i.e., features and labels are\ncorrectly set. However, data collected from the wild can be unreliable due to\ncareless annotations or malicious data transformation for incorrect anomaly\ndetection. In this paper, we present a two-layer on-line learning framework for\nrobust anomaly detection (RAD) in the presence of unreliable anomaly labels,\nwhere the first layer is to filter out the suspicious data, and the second\nlayer detects the anomaly patterns from the remaining data. To adapt to the\non-line nature of anomaly detection, we extend RAD with additional features of\nrepetitively cleaning, conflicting opinions of classifiers, and oracle\nknowledge. We on-line learn from the incoming data streams and continuously\ncleanse the data, so as to adapt to the increasing learning capacity from the\nlarger accumulated data set. Moreover, we explore the concept of oracle\nlearning that provides additional information of true labels for difficult data\npoints. We specifically focus on three use cases, (i) detecting 10 classes of\nIoT attacks, (ii) predicting 4 classes of task failures of big data jobs, (iii)\nrecognising 20 celebrities faces. Our evaluation results show that RAD can\nrobustly improve the accuracy of anomaly detection, to reach up to 98% for IoT\ndevice attacks (i.e., +11%), up to 84% for cloud task failures (i.e., +20%)\nunder 40% noise, and up to 74% for face recognition (i.e., +28%) under 30%\nnoisy labels. The proposed RAD is general and can be applied to different\nanomaly detection algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:50:13 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhao", "Zilong", ""], ["Birke", "Robert", ""], ["Han", "Rui", ""], ["Robu", "Bogdan", ""], ["Bouchenak", "Sara", ""], ["Mokhtar", "Sonia Ben", ""], ["Chen", "Lydia Y.", ""]]}, {"id": "1911.04384", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson", "title": "Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function\n  Approximation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first provably convergent two-timescale off-policy\nactor-critic algorithm (COF-PAC) with function approximation. Key to COF-PAC is\nthe introduction of a new critic, the emphasis critic, which is trained via\nGradient Emphasis Learning (GEM), a novel combination of the key ideas of\nGradient Temporal Difference Learning and Emphatic Temporal Difference\nLearning. With the help of the emphasis critic and the canonical value function\ncritic, we show convergence for COF-PAC, where the critics are linear and the\nactor can be nonlinear.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:50:14 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 18:34:28 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 15:26:50 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 04:06:07 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 00:01:02 GMT"}, {"version": "v6", "created": "Wed, 29 Jul 2020 22:11:24 GMT"}, {"version": "v7", "created": "Fri, 31 Jul 2020 18:19:26 GMT"}, {"version": "v8", "created": "Sat, 31 Oct 2020 00:23:49 GMT"}, {"version": "v9", "created": "Mon, 23 Nov 2020 21:22:42 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Yao", "Hengshuai", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1911.04386", "submitter": "Antonio Paiva", "authors": "Weike Sun, Antonio R. C. Paiva, Peng Xu, Anantha Sundaram, Richard D.\n  Braatz", "title": "Fault Detection and Identification using Bayesian Recurrent Neural\n  Networks", "comments": "43 pages, 23 figures. Accepted for publication in Computers &\n  Chemical Engineering", "journal-ref": null, "doi": "10.1016/j.compchemeng.2020.106991", "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In processing and manufacturing industries, there has been a large push to\nproduce higher quality products and ensure maximum efficiency of processes.\nThis requires approaches to effectively detect and resolve disturbances to\nensure optimal operations. While the control system can compensate for many\ntypes of disturbances, there are changes to the process which it still cannot\nhandle adequately. It is therefore important to further develop monitoring\nsystems to effectively detect and identify those faults such that they can be\nquickly resolved by operators. In this paper, a novel probabilistic fault\ndetection and identification method is proposed which adopts a newly developed\ndeep learning approach using Bayesian recurrent neural networks~(BRNNs) with\nvariational dropout. The BRNN model is general and can model complex nonlinear\ndynamics. Moreover, compared to traditional statistic-based data-driven fault\ndetection and identification methods, the proposed BRNN-based method yields\nuncertainty estimates which allow for simultaneous fault detection of chemical\nprocesses, direct fault identification, and fault propagation analysis. The\noutstanding performance of this method is demonstrated and contrasted to\n(dynamic) principal component analysis, which are widely applied in the\nindustry, in the benchmark Tennessee Eastman process~(TEP) and a real chemical\nmanufacturing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:56:28 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 20:47:17 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Sun", "Weike", ""], ["Paiva", "Antonio R. C.", ""], ["Xu", "Peng", ""], ["Sundaram", "Anantha", ""], ["Braatz", "Richard D.", ""]]}, {"id": "1911.04389", "submitter": "Niklas Rindtorff", "authors": "Niklas T. Rindtorff, MingYu Lu, Nisarg A. Patel, Huahua Zheng,\n  Alexander D'Amour", "title": "A Biologically Plausible Benchmark for Contextual Bandit Algorithms in\n  Precision Oncology Using in vitro Data", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision oncology, the genetic sequencing of tumors to identify druggable\ntargets, has emerged as the standard of care in the treatment of many cancers.\nNonetheless, due to the pace of therapy development and variability in patient\ninformation, designing effective protocols for individual treatment assignment\nin a sample-efficient way remains a major challenge. One promising approach to\nthis problem is to frame precision oncology treatment as a contextual bandit\nproblem and to apply sequential decision-making algorithms designed to minimize\nregret in this setting. However, a clear prerequisite for considering this\nmethodology in high-stakes clinical decisions is careful benchmarking to\nunderstand realistic costs and benefits. Here, we propose a benchmark dataset\nto evaluate contextual bandit algorithms based on real in vitro drug response\nof approximately 900 cancer cell lines. Specifically, we curated a dataset of\ncomplete treatment responses for a subset of 7 treatments from prior in vitro\nstudies. This allows us to compute the regret of proposed decision policies\nusing biologically plausible counterfactuals. We ran a suite of Bayesian bandit\nalgorithms on our benchmark, and found that the methods accumulate less regret\nover a sequence of treatment assignment tasks than a rule-based baseline\nderived from current clinical practice. This effect was more pronounced when\ngenomic information was included as context. We expect this work to be a\nstarting point for evaluation of both the unique structural requirements and\nethical implications for real-world testing of bandit based clinical decision\nsupport.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:59:11 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rindtorff", "Niklas T.", ""], ["Lu", "MingYu", ""], ["Patel", "Nisarg A.", ""], ["Zheng", "Huahua", ""], ["D'Amour", "Alexander", ""]]}, {"id": "1911.04393", "submitter": "Michael Rapp", "authors": "Michael Rapp, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "Simplifying Random Forests: On the Trade-off between Interpretability\n  and Accuracy", "comments": null, "journal-ref": "1st Workshop on Deep Continuous-Discrete Machine Learning\n  (DeCoDeML), ECML-PKDD 2019, W\\\"urzburg Germany", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the trade-off between model complexity and accuracy for random\nforests by breaking the trees up into individual classification rules and\nselecting a subset of them. We show experimentally that already a few rules are\nsufficient to achieve an acceptable accuracy close to that of the original\nmodel. Moreover, our results indicate that in many cases, this can lead to\nsimpler models that clearly outperform the original ones.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 17:05:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1911.04436", "submitter": "Changxiao Cai", "authors": "Changxiao Cai, Gen Li, H. Vincent Poor, Yuxin Chen", "title": "Nonconvex Low-Rank Tensor Completion from Noisy Data", "comments": "Accepted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a noisy tensor completion problem of broad practical interest,\nnamely, the reconstruction of a low-rank tensor from highly incomplete and\nrandomly corrupted observations of its entries. While a variety of prior work\nhas been dedicated to this problem, prior algorithms either are computationally\ntoo expensive for large-scale applications, or come with sub-optimal\nstatistical guarantees. Focusing on \"incoherent\" and well-conditioned tensors\nof a constant CP rank, we propose a two-stage nonconvex algorithm -- (vanilla)\ngradient descent following a rough initialization -- that achieves the best of\nboth worlds. Specifically, the proposed nonconvex algorithm faithfully\ncompletes the tensor and retrieves all individual tensor factors within nearly\nlinear time, while at the same time enjoying near-optimal statistical\nguarantees (i.e. minimal sample complexity and optimal estimation accuracy).\nThe estimation errors are evenly spread out across all entries, thus achieving\noptimal $\\ell_{\\infty}$ statistical accuracy. We have also discussed how to\nextend our approach to accommodate asymmetric tensors. The insight conveyed\nthrough our analysis of nonconvex optimization might have implications for\nother tensor estimation problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:21:26 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 03:32:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Cai", "Changxiao", ""], ["Li", "Gen", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "1911.04443", "submitter": "Lijun Ding", "authors": "Lijun Ding, Benjamin Grimmer", "title": "Bundle Method Sketching for Low Rank Semidefinite Programming", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that the bundle method can be applied to solve\nsemidefinite programming problems with a low rank solution without ever\nconstructing a full matrix. To accomplish this, we use recent results from\nrandomly sketching matrix optimization problems and from the analysis of bundle\nmethods. Under strong duality and strict complementarity of SDP, our algorithm\nproduces primal and the dual sequences converging in feasibility at a rate of\n$\\tilde{O}(1/\\epsilon)$ and in optimality at a rate of\n$\\tilde{O}(1/\\epsilon^2)$. Moreover, our algorithm outputs a low rank\nrepresentation of its approximate solution with distance to the optimal\nsolution at most $O(\\sqrt{\\epsilon})$ within $\\tilde{O}(1/\\epsilon^2)$\niterations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:41:24 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 02:53:44 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 17:24:14 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ding", "Lijun", ""], ["Grimmer", "Benjamin", ""]]}, {"id": "1911.04448", "submitter": "Simon Ramstedt", "authors": "Simon Ramstedt, Christopher Pal", "title": "Real-Time Reinforcement Learning", "comments": "Neural Information Processing Systems (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Decision Processes (MDPs), the mathematical framework underlying most\nalgorithms in Reinforcement Learning (RL), are often used in a way that\nwrongfully assumes that the state of an agent's environment does not change\nduring action selection. As RL systems based on MDPs begin to find application\nin real-world safety critical situations, this mismatch between the assumptions\nunderlying classical MDPs and the reality of real-time computation may lead to\nundesirable outcomes. In this paper, we introduce a new framework, in which\nstates and actions evolve simultaneously and show how it is related to the\nclassical MDP formulation. We analyze existing algorithms under the new\nreal-time formulation and show why they are suboptimal when used in real-time.\nWe then use those insights to create a new algorithm Real-Time Actor-Critic\n(RTAC) that outperforms the existing state-of-the-art continuous control\nalgorithm Soft Actor-Critic both in real-time and non-real-time settings. Code\nand videos can be found at https://github.com/rmst/rtrl.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:52:04 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 18:56:26 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 18:54:06 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 08:46:32 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Ramstedt", "Simon", ""], ["Pal", "Christopher", ""]]}, {"id": "1911.04453", "submitter": "Xiaocong Du", "authors": "Gokul Krishnan, Xiaocong Du, Yu Cao", "title": "Structural Pruning in Deep Neural Networks: A Small-World Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are usually over-parameterized, causing excessive\nmemory and interconnection cost on the hardware platform. Existing pruning\napproaches remove secondary parameters at the end of training to reduce the\nmodel size; but without exploiting the intrinsic network property, they still\nrequire the full interconnection to prepare the network. Inspired by the\nobservation that brain networks follow the Small-World model, we propose a\nnovel structural pruning scheme, which includes (1) hierarchically trimming the\nnetwork into a Small-World model before training, (2) training the network for\na given dataset, and (3) optimizing the network for accuracy. The new scheme\neffectively reduces both the model size and the interconnection needed before\ntraining, achieving a locally clustered and globally sparse model. We\ndemonstrate our approach on LeNet-5 for MNIST and VGG-16 for CIFAR-10,\ndecreasing the number of parameters to 2.3% and 9.02% of the baseline model,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:53:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Krishnan", "Gokul", ""], ["Du", "Xiaocong", ""], ["Cao", "Yu", ""]]}, {"id": "1911.04462", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Lihong Li and Quanquan Gu", "title": "Neural Contextual Bandits with UCB-based Exploration", "comments": "27 pages, 2 figures, 1 table. In ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic contextual bandit problem, where the reward is\ngenerated from an unknown function with additive noise. No assumption is made\nabout the reward function other than boundedness. We propose a new algorithm,\nNeuralUCB, which leverages the representation power of deep neural networks and\nuses a neural network-based random feature mapping to construct an upper\nconfidence bound (UCB) of reward for efficient exploration. We prove that,\nunder standard assumptions, NeuralUCB achieves $\\tilde O(\\sqrt{T})$ regret,\nwhere $T$ is the number of rounds. To the best of our knowledge, it is the\nfirst neural network-based contextual bandit algorithm with a near-optimal\nregret guarantee. We also show the algorithm is empirically competitive against\nrepresentative baselines in a number of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:58:30 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 05:46:20 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:57:22 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zhou", "Dongruo", ""], ["Li", "Lihong", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.04467", "submitter": "Chenye Wu", "authors": "Kui Wang, Jian Sun, Chenye Wu and Yang Yu", "title": "Conductor Galloping Prediction on Imbalanced Datasets: SVM with Smart\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conductor galloping is the high-amplitude, low-frequency oscillation of\noverhead power lines due to wind. Such movements may lead to severe damages to\ntransmission lines, and hence pose significant risks to the power system\noperation. In this paper, we target to design a prediction framework for\nconductor galloping. The difficulty comes from imbalanced dataset as galloping\nhappens rarely. By examining the impacts of data balance and data volume on the\nprediction performance, we propose to employ proper sample adjustment methods\nto achieve better performance. Numerical study suggests that using only three\nfeatures, together with over sampling, the SVM based prediction framework\nachieves an F_1-score of 98.9%.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 13:13:12 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Wang", "Kui", ""], ["Sun", "Jian", ""], ["Wu", "Chenye", ""], ["Yu", "Yang", ""]]}, {"id": "1911.04489", "submitter": "Daniel Philps", "authors": "Daniel Philps, Artur d'Avila Garcez, Tillman Weyde", "title": "Making Good on LSTMs' Unfulfilled Promise", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada. arXiv admin note: text overlap with\n  arXiv:1812.02340", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs promise much to financial time-series analysis, temporal and\ncross-sectional inference, but we find that they do not deliver in a real-world\nfinancial management task. We examine an alternative called Continual Learning\n(CL), a memory-augmented approach, which can provide transparent explanations,\ni.e. which memory did what and when. This work has implications for many\nfinancial applications including credit, time-varying fairness in decision\nmaking and more. We make three important new observations. Firstly, as well as\nbeing more explainable, time-series CL approaches outperform LSTMs as well as a\nsimple sliding window learner using feed-forward neural networks (FFNN).\nSecondly, we show that CL based on a sliding window learner (FFNN) is more\neffective than CL based on a sequential learner (LSTM). Thirdly, we examine how\nreal-world, time-series noise impacts several similarity approaches used in CL\nmemory addressing. We provide these insights using an approach called Continual\nLearning Augmentation (CLA) tested on a complex real-world problem, emerging\nmarket equities investment decision making. CLA provides a test-bed as it can\nbe based on different types of time-series learners, allowing testing of LSTM\nand FFNN learners side by side. CLA is also used to test several distance\napproaches used in a memory recall-gate: Euclidean distance (ED), dynamic time\nwarping (DTW), auto-encoders (AE) and a novel hybrid approach, warp-AE. We find\nthat ED under-performs DTW and AE but warp-AE shows the best overall\nperformance in a real-world financial task.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:57:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 14:56:54 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 12:44:27 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2019 02:07:27 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Philps", "Daniel", ""], ["Garcez", "Artur d'Avila", ""], ["Weyde", "Tillman", ""]]}, {"id": "1911.04554", "submitter": "Joshua Tobin", "authors": "Josh Tobin, OpenAI Robotics, Pieter Abbeel", "title": "Geometry-Aware Neural Rendering", "comments": "16 pages, 13 figures", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the 3-dimensional structure of the world is a core challenge in\ncomputer vision and robotics. Neural rendering approaches learn an implicit 3D\nmodel by predicting what a camera would see from an arbitrary viewpoint. We\nextend existing neural rendering to more complex, higher dimensional scenes\nthan previously possible. We propose Epipolar Cross Attention (ECA), an\nattention mechanism that leverages the geometry of the scene to perform\nefficient non-local operations, requiring only $O(n)$ comparisons per spatial\ndimension instead of $O(n^2)$. We introduce three new simulated datasets\ninspired by real-world robotics and demonstrate that ECA significantly improves\nthe quantitative and qualitative performance of Generative Query Networks\n(GQN).\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:10:39 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tobin", "Josh", ""], ["Robotics", "OpenAI", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1911.04559", "submitter": "Anirban Das", "authors": "Anirban Das and Thomas Brunschwiler", "title": "Privacy is What We Care About: Experimental Investigation of Federated\n  Learning on Edge Devices", "comments": "Accepted in ACM AIChallengeIoT 2019, New York, USA", "journal-ref": null, "doi": "10.1145/3363347.3363365", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables training of a general model through edge devices\nwithout sending raw data to the cloud. Hence, this approach is attractive for\ndigital health applications, where data is sourced through edge devices and\nusers care about privacy. Here, we report on the feasibility to train deep\nneural networks on the Raspberry Pi4s as edge devices. A CNN, a LSTM and a MLP\nwere successfully trained on the MNIST data-set. Further, federated learning is\ndemonstrated experimentally on IID and non-IID samples in a parametric study,\nto benchmark the model convergence. The weight updates from the workers are\nshared with the cloud to train the general model through federated learning.\nWith the CNN and the non-IID samples a test-accuracy of up to 85% could be\nachieved within a training time of 2 minutes, while exchanging less than $10$\nMB data per device. In addition, we discuss federated learning from an use-case\nstandpoint, elaborating on privacy risks and labeling requirements for the\napplication of emotion detection from sound. Based on the experimental\nfindings, we discuss possible research directions to improve model and system\nperformance. Finally, we provide best practices for a practitioner, considering\nthe implementation of federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 20:44:03 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Das", "Anirban", ""], ["Brunschwiler", "Thomas", ""]]}, {"id": "1911.04574", "submitter": "Ruslan Shaydulin", "authors": "Sami Khairy, Ruslan Shaydulin, Lukasz Cincio, Yuri Alexeev, Prasanna\n  Balaprakash", "title": "Reinforcement-Learning-Based Variational Quantum Circuits Optimization\n  for Combinatorial Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-19-28945", "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing exploits basic quantum phenomena such as state\nsuperposition and entanglement to perform computations. The Quantum Approximate\nOptimization Algorithm (QAOA) is arguably one of the leading quantum algorithms\nthat can outperform classical state-of-the-art methods in the near term. QAOA\nis a hybrid quantum-classical algorithm that combines a parameterized quantum\nstate evolution with a classical optimization routine to approximately solve\ncombinatorial problems. The quality of the solution obtained by QAOA within a\nfixed budget of calls to the quantum computer depends on the performance of the\nclassical optimization routine used to optimize the variational parameters. In\nthis work, we propose an approach based on reinforcement learning (RL) to train\na policy network that can be used to quickly find high-quality variational\nparameters for unseen combinatorial problem instances. The RL agent is trained\non small problem instances which can be simulated on a classical computer, yet\nthe learned RL policy is generalizable and can be used to efficiently solve\nlarger instances. Extensive simulations using the IBM Qiskit Aer quantum\ncircuit simulator demonstrate that our trained RL policy can reduce the\noptimality gap by a factor up to 8.61 compared with other off-the-shelf\noptimizers tested.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:34:33 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Khairy", "Sami", ""], ["Shaydulin", "Ruslan", ""], ["Cincio", "Lukasz", ""], ["Alexeev", "Yuri", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1911.04587", "submitter": "Xintao Wu", "authors": "Depeng Xu, Shuhan Yuan, Xintao Wu", "title": "Achieving Differential Privacy in Vertically Partitioned Multiparty\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preserving differential privacy has been well studied under centralized\nsetting. However, it's very challenging to preserve differential privacy under\nmultiparty setting, especially for the vertically partitioned case. In this\nwork, we propose a new framework for differential privacy preserving multiparty\nlearning in the vertically partitioned setting. Our core idea is based on the\nfunctional mechanism that achieves differential privacy of the released model\nby adding noise to the objective function. We show the server can simply\ndissect the objective function into single-party and cross-party sub-functions,\nand allocate computation and perturbation of their polynomial coefficients to\nlocal parties. Our method needs only one round of noise addition and secure\naggregation. The released model in our framework achieves the same utility as\napplying the functional mechanism in the centralized setting. Evaluation on\nreal-world and synthetic datasets for linear and logistic regressions shows the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 22:28:07 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Xu", "Depeng", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "1911.04594", "submitter": "Babak Esmaeili", "authors": "Alican Bozkurt, Babak Esmaeili, Jean-Baptiste Tristan, Dana H. Brooks,\n  Jennifer G. Dy, Jan-Willem van de Meent", "title": "Rate-Regularization and Generalization in VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders optimize an objective that combines a reconstruction\nloss (the distortion) and a KL term (the rate). The rate is an upper bound on\nthe mutual information, which is often interpreted as a regularizer that\ncontrols the degree of compression. We here examine whether inclusion of the\nrate also acts as an inductive bias that improves generalization. We perform\nrate-distortion analyses that control the strength of the rate term, the\nnetwork capacity, and the difficulty of the generalization problem. Decreasing\nthe strength of the rate paradoxically improves generalization in most\nsettings, and reducing the mutual information typically leads to underfitting.\nMoreover, we show that generalization continues to improve even after the\nmutual information saturates, indicating that the gap on the bound (i.e. the KL\ndivergence relative to the inference marginal) affects generalization. This\nsuggests that the standard Gaussian prior is not an inductive bias that\ntypically aids generalization, prompting work to understand what choices of\npriors improve generalization in VAEs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:06:40 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 02:54:43 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 18:48:43 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 05:56:51 GMT"}, {"version": "v5", "created": "Tue, 16 Mar 2021 17:55:09 GMT"}, {"version": "v6", "created": "Thu, 25 Mar 2021 18:13:55 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Bozkurt", "Alican", ""], ["Esmaeili", "Babak", ""], ["Tristan", "Jean-Baptiste", ""], ["Brooks", "Dana H.", ""], ["Dy", "Jennifer G.", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1911.04597", "submitter": "Chen Tang", "authors": "Chen Tang, Jianyu Chen, Masayoshi Tomizuka", "title": "Adaptive Probabilistic Vehicle Trajectory Prediction Through Physically\n  Feasible Bayesian Recurrent Neural Network", "comments": "Published as Conference Paper at ICRA 2019", "journal-ref": null, "doi": "10.1109/ICRA.2019.8794130", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic vehicle trajectory prediction is essential for robust safety of\nautonomous driving. Current methods for long-term trajectory prediction cannot\nguarantee the physical feasibility of predicted distribution. Moreover, their\nmodels cannot adapt to the driving policy of the predicted target human driver.\nIn this work, we propose to overcome these two shortcomings by a Bayesian\nrecurrent neural network model consisting of Bayesian-neural-network-based\npolicy model and known physical model of the scenario. Bayesian neural network\ncan ensemble complicated output distribution, enabling rich family of\ntrajectory distribution. The embedded physical model ensures feasibility of the\ndistribution. Moreover, the adopted gradient-based training method allows\ndirect optimization for better performance in long prediction horizon.\nFurthermore, a particle-filter-based parameter adaptation algorithm is designed\nto adapt the policy Bayesian neural network to the predicted target online.\nEffectiveness of the proposed methods is verified with a toy example with\nmulti-modal stochastic feedback gain and naturalistic car following data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:13:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tang", "Chen", ""], ["Chen", "Jianyu", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1911.04616", "submitter": "Ziheng Chen", "authors": "Ziheng Chen and Hongshik Ahn", "title": "Item Response Theory based Ensemble in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a novel probabilistic framework to improve the\naccuracy of a weighted majority voting algorithm. In order to assign higher\nweights to the classifiers which can correctly classify hard-to-classify\ninstances, we introduce the Item Response Theory (IRT) framework to evaluate\nthe samples' difficulty and classifiers' ability simultaneously. Three models\nare created with different assumptions suitable for different cases. When\nmaking an inference, we keep a balance between the accuracy and complexity. In\nour experiment, all the base models are constructed by single trees via\nbootstrap. To explain the models, we illustrate how the IRT ensemble model\nconstructs the classifying boundary. We also compare their performance with\nother widely used methods and show that our model performs well on 19 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:48:18 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Chen", "Ziheng", ""], ["Ahn", "Hongshik", ""]]}, {"id": "1911.04620", "submitter": "Xintao Wu", "authors": "Panpan Zheng, Shuhan Yuan, Xintao Wu, Yubao Wu", "title": "Identifying Hidden Buyers in Darknet Markets via Dirichlet Hawkes\n  Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The darknet markets are notorious black markets in cyberspace, which involve\nselling or brokering drugs, weapons, stolen credit cards, and other illicit\ngoods. To combat illicit transactions in the cyberspace, it is important to\nanalyze the behaviors of participants in darknet markets. Currently, many\nstudies focus on studying the behavior of vendors. However, there is no much\nwork on analyzing buyers. The key challenge is that the buyers are anonymized\nin darknet markets. For most of the darknet markets, We only observe the first\nand last digits of a buyer's ID, such as ``a**b''. To tackle this challenge, we\npropose a hidden buyer identification model, called UNMIX, which can group the\ntransactions from one hidden buyer into one cluster given a transaction\nsequence from an anonymized ID. UNMIX is able to model the temporal dynamics\ninformation as well as the product, comment, and vendor information associated\nwith each transaction. As a result, the transactions with similar patterns in\nterms of time and content group together as the subsequence from one hidden\nbuyer. Experiments on the data collected from three real-world darknet markets\ndemonstrate the effectiveness of our approach measured by various clustering\nmetrics. Case studies on real transaction sequences explicitly show that our\napproach can group transactions with similar patterns into the same clusters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:17:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""], ["Wu", "Yubao", ""]]}, {"id": "1911.04628", "submitter": "Alan Yang", "authors": "Alan Yang and AmirEmad Ghassami and Maxim Raginsky and Negar Kiyavash\n  and Elyse Rosenbaum", "title": "Model-Augmented Estimation of Conditional Mutual Information for Feature\n  Selection", "comments": "Accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov blanket feature selection, while theoretically optimal, is generally\nchallenging to implement. This is due to the shortcomings of existing\napproaches to conditional independence (CI) testing, which tend to struggle\neither with the curse of dimensionality or computational complexity. We propose\na novel two-step approach which facilitates Markov blanket feature selection in\nhigh dimensions. First, neural networks are used to map features to\nlow-dimensional representations. In the second step, CI testing is performed by\napplying the $k$-NN conditional mutual information estimator to the learned\nfeature maps. The mappings are designed to ensure that mapped samples both\npreserve information and share similar information about the target variable if\nand only if they are close in Euclidean distance. We show that these properties\nboost the performance of the $k$-NN estimator in the second step. The\nperformance of the proposed method is evaluated on both synthetic and real\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 01:20:54 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 20:45:53 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 20:38:29 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yang", "Alan", ""], ["Ghassami", "AmirEmad", ""], ["Raginsky", "Maxim", ""], ["Kiyavash", "Negar", ""], ["Rosenbaum", "Elyse", ""]]}, {"id": "1911.04636", "submitter": "Arash Rahnama", "authors": "Arash Rahnama, Andre T. Nguyen and Edward Raff", "title": "Robust Design of Deep Neural Networks against Adversarial Attacks based\n  on Lyapunov Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to subtle adversarial\nperturbations applied to the input. These adversarial perturbations, though\nimperceptible, can easily mislead the DNN. In this work, we take a control\ntheoretic approach to the problem of robustness in DNNs. We treat each\nindividual layer of the DNN as a nonlinear dynamical system and use Lyapunov\ntheory to prove stability and robustness locally. We then proceed to prove\nstability and robustness globally for the entire DNN. We develop empirically\ntight bounds on the response of the output layer, or any hidden layer, to\nadversarial perturbations added to the input, or the input of hidden layers.\nRecent works have proposed spectral norm regularization as a solution for\nimproving robustness against l2 adversarial attacks. Our results give new\ninsights into how spectral norm regularization can mitigate the adversarial\neffects. Finally, we evaluate the power of our approach on a variety of data\nsets and network architectures and against some of the well-known adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:17:01 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rahnama", "Arash", ""], ["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1911.04644", "submitter": "Qinglong Wang", "authors": "Qinglong Wang, Kaixuan Zhang, Xue Liu, C. Lee Giles", "title": "Connecting First and Second Order Recurrent Networks with Deterministic\n  Finite Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach that connects recurrent networks with different orders\nof hidden interaction with regular grammars of different levels of complexity.\nWe argue that the correspondence between recurrent networks and formal\ncomputational models gives understanding to the analysis of the complicated\nbehaviors of recurrent networks. We introduce an entropy value that categorizes\nall regular grammars into three classes with different levels of complexity,\nand show that several existing recurrent networks match grammars from either\nall or partial classes. As such, the differences between regular grammars\nreveal the different properties of these models. We also provide a unification\nof all investigated recurrent networks. Our evaluation shows that the unified\nrecurrent network has improved performance in learning grammars, and\ndemonstrates comparable performance on a real-world dataset with more\ncomplicated models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:05:15 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Wang", "Qinglong", ""], ["Zhang", "Kaixuan", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1911.04655", "submitter": "Xinyan Dai", "authors": "Xinyan Dai, Xiao Yan, Kaiwen Zhou, Han Yang, Kelvin K. W. Ng, James\n  Cheng, Yu Fan", "title": "Hyper-Sphere Quantization: Communication-Efficient SGD for Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high cost of communicating gradients is a major bottleneck for federated\nlearning, as the bandwidth of the participating user devices is limited.\nExisting gradient compression algorithms are mainly designed for data centers\nwith high-speed network and achieve $O(\\sqrt{d} \\log d)$ per-iteration\ncommunication cost at best, where $d$ is the size of the model. We propose\nhyper-sphere quantization (HSQ), a general framework that can be configured to\nachieve a continuum of trade-offs between communication efficiency and gradient\naccuracy. In particular, at the high compression ratio end, HSQ provides a low\nper-iteration communication cost of $O(\\log d)$, which is favorable for\nfederated learning. We prove the convergence of HSQ theoretically and show by\nexperiments that HSQ significantly reduces the communication cost of model\ntraining without hurting convergence accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:36:09 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 11:00:41 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Dai", "Xinyan", ""], ["Yan", "Xiao", ""], ["Zhou", "Kaiwen", ""], ["Yang", "Han", ""], ["Ng", "Kelvin K. W.", ""], ["Cheng", "James", ""], ["Fan", "Yu", ""]]}, {"id": "1911.04681", "submitter": "Abhratanu Dutta", "authors": "Pranjal Awasthi, Abhratanu Dutta and Aravindan Vijayaraghavan", "title": "On Robustness to Adversarial Examples and Polynomial Optimization", "comments": "To appear at NeurIPS2019. 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of computationally efficient algorithms with provable\nguarantees, that are robust to adversarial (test time) perturbations. While\nthere has been an proliferation of recent work on this topic due to its\nconnections to test time robustness of deep networks, there is limited\ntheoretical understanding of several basic questions like (i) when and how can\none design provably robust learning algorithms? (ii) what is the price of\nachieving robustness to adversarial examples in a computationally efficient\nmanner?\n  The main contribution of this work is to exhibit a strong connection between\nachieving robustness to adversarial examples, and a rich class of polynomial\noptimization problems, thereby making progress on the above questions. In\nparticular, we leverage this connection to (a) design computationally efficient\nrobust algorithms with provable guarantees for a large class of hypothesis,\nnamely linear classifiers and degree-2 polynomial threshold functions (PTFs),\n(b) give a precise characterization of the price of achieving robustness in a\ncomputationally efficient manner for these classes, (c) design efficient\nalgorithms to certify robustness and generate adversarial attacks in a\nprincipled manner for 2-layer neural networks. We empirically demonstrate the\neffectiveness of these attacks on real data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:33:06 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Dutta", "Abhratanu", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1911.04695", "submitter": "Yadan Luo", "authors": "Yadan Luo, Zi Huang, Zheng Zhang, Ziwei Wang, Mahsa Baktashmotlagh,\n  Yang Yang", "title": "Learning from the Past: Continual Meta-Learning via Bayesian Graph\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meta-learning for few-shot learning allows a machine to leverage previously\nacquired knowledge as a prior, thus improving the performance on novel tasks\nwith only small amounts of data. However, most mainstream models suffer from\ncatastrophic forgetting and insufficient robustness issues, thereby failing to\nfully retain or exploit long-term knowledge while being prone to cause severe\nerror accumulation. In this paper, we propose a novel Continual Meta-Learning\napproach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically\nformulates meta-learning as continual learning of a sequence of tasks. With\neach task forming as a graph, the intra- and inter-task correlations can be\nwell preserved via message-passing and history transition. To remedy\ntopological uncertainty from graph initialization, we utilize Bayes by Backprop\nstrategy that approximates the posterior distribution of task-specific\nparameters with amortized inference networks, which are seamlessly integrated\ninto the end-to-end edge learning. Extensive experiments conducted on the\nminiImageNet and tieredImageNet datasets demonstrate the effectiveness and\nefficiency of the proposed method, improving the performance by 42.8% compared\nwith state-of-the-art on the miniImageNet 5-way 1-shot classification task.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:10:11 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Luo", "Yadan", ""], ["Huang", "Zi", ""], ["Zhang", "Zheng", ""], ["Wang", "Ziwei", ""], ["Baktashmotlagh", "Mahsa", ""], ["Yang", "Yang", ""]]}, {"id": "1911.04699", "submitter": "Sambuddha Ghosal", "authors": "John Just and Sambuddha Ghosal", "title": "Deep Generative Models Strike Back! Improving Understanding and\n  Evaluation in Light of Unmet Expectations for OoD Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep generative and density models have shown impressive capacity\nto model complex probability density functions in lower-dimensional space.\nAlso, applying such models to high-dimensional image data to model the PDF has\nshown poor generalization, with out-of-distribution data being assigned equal\nor higher likelihood than in-sample data. Methods to deal with this have been\nproposed that deviate from a fully unsupervised approach, requiring large\nensembles or additional knowledge about the data, not commonly available in the\nreal-world. In this work, the previously offered reasoning behind these issues\nis challenged empirically, and it is shown that data-sets such as MNIST\nfashion/digits and CIFAR10/SVHN are trivially separable and have no overlap on\ntheir respective data manifolds that explains the higher OoD likelihood. Models\nlike masked autoregressive flows and block neural autoregressive flows are\nshown to not suffer from OoD likelihood issues to the extent of GLOW,\nPixelCNN++, and real NVP. A new avenue is also explored which involves a change\nof basis to a new space of the same dimension with an orthonormal unitary basis\nof eigenvectors before modeling. In the test data-sets and models, this aids in\npushing down the relative likelihood of the contrastive OoD data set and\nimprove discrimination results. The significance of the density of the original\nspace is maintained, while invertibility remains tractable. Finally, a look to\nthe previous generation of generative models in the form of probabilistic\nprincipal component analysis is inspired, and revisited for the same data-sets\nand shown to work really well for discriminating anomalies based on likelihood\nin a fully unsupervised fashion compared with pixelCNN++, GLOW, and real NVP\nwith less complexity and faster training. Also, dimensionality reduction using\nPCA is shown to improve anomaly detection in generative models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:41:22 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Just", "John", ""], ["Ghosal", "Sambuddha", ""]]}, {"id": "1911.04705", "submitter": "Ali Hassani", "authors": "Ali Hassani, Amir Iranmanesh, Najme Mansouri", "title": "Text Mining using Nonnegative Matrix Factorization and Latent Semantic\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text clustering is arguably one of the most important topics in modern data\nmining. Nevertheless, text data require tokenization which usually yields a\nvery large and highly sparse term-document matrix, which is usually difficult\nto process using conventional machine learning algorithms. Methods such as\nLatent Semantic Analysis have helped mitigate this issue, but are nevertheless\nnot completely stable in practice. As a result, we propose a new feature\nagglomeration method based on Nonnegative Matrix Factorization, which is\nemployed to separate the terms into groups, and then each group's term vectors\nare agglomerated into a new feature vector. Together, these feature vectors\ncreate a new feature space much more suitable for clustering. In addition, we\npropose a new deterministic initialization for spherical K-Means, which proves\nvery useful for this specific type of data. In order to evaluate the proposed\nmethod, we compare it to some of the latest research done in this field, as\nwell as some of the most practiced methods. In our experiments, we conclude\nthat the proposed method either significantly improves clustering performance,\nor maintains the performance of other methods, while improving stability in\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:30:46 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 10:13:47 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 07:47:52 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hassani", "Ali", ""], ["Iranmanesh", "Amir", ""], ["Mansouri", "Najme", ""]]}, {"id": "1911.04706", "submitter": "Chi Wang", "authors": "Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu", "title": "FLAML: A Fast and Lightweight AutoML Library", "comments": "14 pages, published in Fourth Conference on Machine Learning and\n  Systems (MLSys 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of using low computational cost to automate the choices\nof learners and hyperparameters for an ad-hoc training dataset and error\nmetric, by conducting trials of different configurations on the given training\ndata. We investigate the joint impact of multiple factors on both trial cost\nand model error, and propose several design guidelines. Following them, we\nbuild a fast and lightweight library FLAML which optimizes for low\ncomputational resource in finding accurate models. FLAML integrates several\nsimple but effective search strategies into an adaptive system. It\nsignificantly outperforms top-ranked AutoML libraries on a large open source\nAutoML benchmark under equal, or sometimes orders of magnitude smaller budget\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:33:35 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 07:57:36 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 00:34:30 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wang", "Chi", ""], ["Wu", "Qingyun", ""], ["Weimer", "Markus", ""], ["Zhu", "Erkang", ""]]}, {"id": "1911.04738", "submitter": "Shion Honda", "authors": "Shion Honda, Shoi Shi, Hiroki R. Ueda", "title": "SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug\n  Discovery", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In drug-discovery-related tasks such as virtual screening, machine learning\nis emerging as a promising way to predict molecular properties. Conventionally,\nmolecular fingerprints (numerical representations of molecules) are calculated\nthrough rule-based algorithms that map molecules to a sparse discrete space.\nHowever, these algorithms perform poorly for shallow prediction models or small\ndatasets. To address this issue, we present SMILES Transformer. Inspired by\nTransformer and pre-trained language models from natural language processing,\nSMILES Transformer learns molecular fingerprints through unsupervised\npre-training of the sequence-to-sequence language model using a huge corpus of\nSMILES, a text representation system for molecules. We performed benchmarks on\n10 datasets against existing fingerprints and graph-based methods and\ndemonstrated the superiority of the proposed algorithms in small-data settings\nwhere pre-training facilitated good generalization. Moreover, we define a novel\nmetric to concurrently measure model accuracy and data efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 08:44:49 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Honda", "Shion", ""], ["Shi", "Shoi", ""], ["Ueda", "Hiroki R.", ""]]}, {"id": "1911.04787", "submitter": "David Paulus", "authors": "David Paulus, Gerdien de Vries, Bartel Van de Walle", "title": "Effects of data ambiguity and cognitive biases on the interpretability\n  of machine learning models in humanitarian decision making", "comments": "3 pager, 1 figure, AAAI Fall Symposium - AI for Social Good, November\n  7-9, 2019, Arlington, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The effectiveness of machine learning algorithms depends on the quality and\namount of data and the operationalization and interpretation by the human\nanalyst. In humanitarian response, data is often lacking or overburdening, thus\nambiguous, and the time-scarce, volatile, insecure environments of humanitarian\nactivities are likely to inflict cognitive biases. This paper proposes to\nresearch the effects of data ambiguity and cognitive biases on the\ninterpretability of machine learning algorithms in humanitarian decision\nmaking.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 10:50:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Paulus", "David", ""], ["de Vries", "Gerdien", ""], ["Van de Walle", "Bartel", ""]]}, {"id": "1911.04808", "submitter": "Guillermo C\\'ambara", "authors": "Guillermo C\\'ambara, Jordi Luque, Mireia Farr\\'us", "title": "Detection of speech events and speaker characteristics through\n  photo-plethysmographic signal neural processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of photoplethysmogram signal (PPG) for heart and sleep monitoring is\ncommonly found nowadays in smartphones and wrist wearables. Besides common\nusages, it has been proposed and reported that person information can be\nextracted from PPG for other uses, like biometry tasks. In this work, we\nexplore several end-to-end convolutional neural network architectures for\ndetection of human's characteristics such as gender or person identity. In\naddition, we evaluate whether speech/non-speech events may be inferred from PPG\nsignal, where speech might translate in fluctuations into the pulse signal. The\nobtained results are promising and clearly show the potential of fully\nend-to-end topologies for automatic extraction of meaningful biomarkers, even\nfrom a noisy signal sampled by a low-cost PPG sensor. The AUCs for best\narchitectures put forward PPG wave as biological discriminant, reaching $79\\%$\nand $89.0\\%$, respectively for gender and person verification tasks.\nFurthermore, speech detection experiments reporting AUCs around $69\\%$\nencourage us for further exploration about the feasibility of PPG for speech\nprocessing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 11:58:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["C\u00e1mbara", "Guillermo", ""], ["Luque", "Jordi", ""], ["Farr\u00fas", "Mireia", ""]]}, {"id": "1911.04817", "submitter": "Mattis Manfred K\\\"ammerer", "authors": "Mattis Manfred K\\\"ammerer", "title": "On Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of policy gradient approaches is to find a policy in a given class\nof policies which maximizes the expected return. Given a differentiable model\nof the policy, we want to apply a gradient-ascent technique to reach a local\noptimum. We mainly use gradient ascent, because it is theoretically well\nresearched. The main issue is that the policy gradient with respect to the\nexpected return is not available, thus we need to estimate it. As policy\ngradient algorithms also tend to require on-policy data for the gradient\nestimate, their biggest weakness is sample efficiency. For this reason, most\nresearch is focused on finding algorithms with improved sample efficiency. This\npaper provides a formal introduction to policy gradient that shows the\ndevelopment of policy gradient approaches, and should enable the reader to\nfollow current research on the topic.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 12:28:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["K\u00e4mmerer", "Mattis Manfred", ""]]}, {"id": "1911.04822", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dat Quoc Nguyen and Dinh Phung", "title": "A Capsule Network-based Model for Learning Node Embeddings", "comments": "Extended version of our CIKM 2020 paper, including inductive results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on learning low-dimensional embeddings for nodes in\ngraph-structured data. To achieve this, we propose Caps2NE -- a new\nunsupervised embedding model leveraging a network of two capsule layers.\nCaps2NE induces a routing process to aggregate feature vectors of context\nneighbors of a given target node at the first capsule layer, then feed these\nfeatures into the second capsule layer to infer a plausible embedding for the\ntarget node. Experimental results show that our proposed Caps2NE obtains\nstate-of-the-art performances on benchmark datasets for the node classification\ntask. Our code is available at: \\url{https://github.com/daiquocnguyen/Caps2NE}.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 12:44:26 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:48:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Nguyen", "Dat Quoc", ""], ["Phung", "Dinh", ""]]}, {"id": "1911.04841", "submitter": "Massih-Reza Amini", "authors": "Vasilii Feofanov and Emilie Devijver and Massih-Reza Amini", "title": "Semi-supervised Wrapper Feature Selection by Modeling Imperfect Labels", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new wrapper feature selection approach with\npartially labeled training examples where unlabeled observations are\npseudo-labeled using the predictions of an initial classifier trained on the\nlabeled training set. The wrapper is composed of a genetic algorithm for\nproposing new feature subsets, and an evaluation measure for scoring the\ndifferent feature subsets. The selection of feature subsets is done by\nassigning weights to characteristics and recursively eliminating those that are\nirrelevant. The selection criterion is based on a new multi-class\n$\\mathcal{C}$-bound that explicitly takes into account the mislabeling errors\ninduced by the pseudo-labeling mechanism, using a probabilistic error model.\nEmpirical results on different data sets show the effectiveness of our\nframework compared to several state-of-the-art semi-supervised feature\nselection approaches.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:35:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 11:18:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Feofanov", "Vasilii", ""], ["Devijver", "Emilie", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1911.04856", "submitter": "Hufei Zhu", "authors": "Hufei Zhu and Chenghao Wei", "title": "Efficient Inverse-Free Algorithms for Extreme Learning Machine Based on\n  the Recursive Matrix Inverse and the Inverse LDL' Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse-free extreme learning machine (ELM) algorithm proposed in [4] was\nbased on an inverse-free algorithm to compute the regularized pseudo-inverse,\nwhich was deduced from an inverse-free recursive algorithm to update the\ninverse of a Hermitian matrix. Before that recursive algorithm was applied in\n[4], its improved version had been utilized in previous literatures [9], [10].\nAccordingly from the improved recursive algorithm [9], [10], we deduce a more\nefficient inverse-free algorithm\n  to update the regularized pseudo-inverse, from which we develop the proposed\ninverse-free ELM algorithm 1. Moreover, the proposed ELM algorithm 2 further\nreduces the computational complexity, which computes the output weights\ndirectly from the updated inverse, and avoids computing the regularized\npseudoinverse. Lastly, instead of updating the inverse, the proposed ELM\nalgorithm 3 updates the LDLT factor of the inverse by the inverse LDLT\nfactorization [11], to avoid numerical instabilities after a very large number\nof iterations [12]. With respect to the existing ELM algorithm, the proposed\nELM algorithms 1, 2 and 3 are expected to require only (8+3)/M , (8+1)/M and\n(8+1)/M of complexities, respectively, where M is the output node number. In\nthe numerical experiments, the standard ELM, the existing inverse-free ELM\nalgorithm and the proposed ELM algorithms 1, 2 and 3 achieve the same\nperformance in regression and classification, while all the 3 proposed\nalgorithms significantly accelerate the existing inverse-free ELM algorithm\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:00:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zhu", "Hufei", ""], ["Wei", "Chenghao", ""]]}, {"id": "1911.04862", "submitter": "Yong Ruan", "authors": "Yong Ruan, Xiangdong Wang, Hong Liu, Zhigang Ou, Yun Gao, Jianfeng\n  Cheng, Yueliang Qian", "title": "An End-to-end Approach for Lexical Stress Detection based on Transformer", "comments": "Submission to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant automatic lexical stress detection method is to split the\nutterance into syllable segments using phoneme sequence and their time-aligned\nboundaries. Then we extract features from syllable to use classification method\nto classify the lexical stress. However, we can't get very accurate time\nboundaries of each phoneme and we have to design some features in the syllable\nsegments to classify the lexical stress. Therefore, we propose a end-to-end\napproach using sequence to sequence model of transformer to estimate lexical\nstress. For this, we train transformer model using feature sequence of audio\nand their phoneme sequence with lexical stress marks. During the recognition\nprocess, the recognized phoneme sequence is restricted according to the\noriginal standard phoneme sequence without lexical stress marks, but the\nlexical stress mark of each phoneme is not limited. We train the model in\ndifferent subset of Librispeech and do lexical stress recognition in TIMIT and\nL2-ARCTIC dataset. For all subsets, the end-to-end model will perform better\nthan the syllable segments classification method. Our method can achieve a\n6.36% phoneme error rate on the TIMIT dataset, which exceeds the 7.2% error\nrate in other studies.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:29:37 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ruan", "Yong", ""], ["Wang", "Xiangdong", ""], ["Liu", "Hong", ""], ["Ou", "Zhigang", ""], ["Gao", "Yun", ""], ["Cheng", "Jianfeng", ""], ["Qian", "Yueliang", ""]]}, {"id": "1911.04870", "submitter": "Elsa Rizk", "authors": "Elsa Rizk, Roula Nassif, Ali H. Sayed", "title": "Network Classifiers With Output Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces two strategies for training network classifiers with\nheterogeneous agents. One strategy promotes global smoothing over the graph and\na second strategy promotes local smoothing over neighbourhoods. It is assumed\nthat the feature sizes can vary from one agent to another, with some agents\nobserving insufficient attributes to be able to make reliable decisions on\ntheir own. As a result, cooperation with neighbours is necessary. However, due\nto the fact that the feature dimensions are different across the agents, their\nclassifier dimensions will also be different. This means that cooperation\ncannot rely on combining the classifier parameters. We instead propose\nsmoothing the outputs of the classifiers, which are the predicted labels. By\ndoing so, the dynamics that describes the evolution of the network classifier\nbecomes more challenging than usual because the classifier parameters end up\nappearing as part of the regularization term as well. We illustrate performance\nby means of computer simulations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:28:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rizk", "Elsa", ""], ["Nassif", "Roula", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1911.04872", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Two Ridge Solutions for the Incremental Broad Learning System on Added\n  Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original Broad Learning System (BLS) on new added nodes and its existing\nefficient implementation both assume the ridge parameter is near 0 in the ridge\ninverse to approximate the generalized inverse, and compute the generalized\ninverse solution for the output weights. In this paper, we propose two ridge\nsolutions for the output weights in the BLS on added nodes, where the ridge\nparameter can be any positive real number. One of the proposed ridge solutions\ncomputes the output weights from the inverse Cholesky factor, which is updated\nby extending the existing inverse Cholesky factorization. The other proposed\nridge solution computes the output weights from the ridge inverse, and updates\nthe ridge inverse by extending the Greville method that can only computes the\ngeneralized inverse of a partitioned matrix. The proposed BLS algorithm based\non the ridge inverse requires the same complexity as the original BLS\nalgorithm, while the proposed BLS algorithm based on the inverse Cholesky\nfactor requires less complexity and training time than the original BLS and the\nexisting efficient BLS. Both the proposed ridge solutions for BLS achieve the\nsame testing accuracy as the standard ridge solution in the numerical\nexperiments. The difference between the testing accuracy of the proposed ridge\nsolutions and that of the existing generalized inverse solutions is negligible\nwhen the ridge parameter is very small, and becomes too big to be ignored when\nthe ridge parameter is not very small. When the ridge parameter is not near 0,\nusually the proposed two ridge solutions for BLS achieve better testing\naccuracy than the existing generalized inverse solutions for BLS, and then the\nformer are more preferred than the latter.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:12:33 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 14:17:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "1911.04894", "submitter": "Yishen Wang", "authors": "Xinan Wang, Yishen Wang, Di Shi, Jianhui Wang, Zhiwei Wang", "title": "Two-stage WECC Composite Load Modeling: A Double Deep Q-Learning\n  Networks Approach", "comments": "To appear in IEEE Transactions on Smart Grid", "journal-ref": null, "doi": "10.1109/TSG.2020.2988171", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing complexity of modern power systems, conventional dynamic\nload modeling with ZIP and induction motors (ZIP + IM) is no longer adequate to\naddress the current load characteristic transitions. In recent years, the WECC\ncomposite load model (WECC CLM) has shown to effectively capture the dynamic\nload responses over traditional load models in various stability studies and\ncontingency analyses. However, a detailed WECC CLM model typically has a high\ndegree of complexity, with over one hundred parameters, and no systematic\napproach to identifying and calibrating these parameters. Enabled by the wide\ndeployment of PMUs and advanced deep learning algorithms, proposed here is a\ndouble deep Q-learning network (DDQN)-based, two-stage load modeling framework\nfor the WECC CLM. This two-stage method decomposes the complicated WECC CLM for\nmore efficient identification and does not require explicit model details. In\nthe first stage, the DDQN agent determines an accurate load composition. In the\nsecond stage, the parameters of the WECC CLM are selected from a group of\nMonte-Carlo simulations. The set of selected load parameters is expected to\nbest approximate the true transient responses. The proposed framework is\nverified using an IEEE 39-bus test system on commercial simulation platforms.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:15:03 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 23:41:04 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Wang", "Xinan", ""], ["Wang", "Yishen", ""], ["Shi", "Di", ""], ["Wang", "Jianhui", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1911.04898", "submitter": "Tom Van Steenkiste", "authors": "Tom Van Steenkiste, Dirk Deschrijver and Tom Dhaene", "title": "Generating an Explainable ECG Beat Space With Variational Auto-Encoders", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. Extended abstract based on previously published research: Van\n  Steenkiste, Tom, Dirk Deschrijver, and Tom Dhaene. \"Interpretable ECG Beat\n  Embedding using Disentangled Variational Auto-Encoders.\" In 2019 IEEE 32nd\n  International Symposium on Computer-Based Medical Systems (CBMS), pp.\n  373-378. IEEE, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram signals are omnipresent in medicine. A vital aspect in the\nanalysis of this data is the identification and classification of heart beat\ntypes which is often done through automated algorithms. Advancements in neural\nnetworks and deep learning have led to a high classification accuracy. However,\nthe final adoption of these models into clinical practice is limited due to the\nblack-box nature of the methods. In this work, we explore the use of\nvariational auto-encoders based on linear dense networks to learn human\ninterpretable beat embeddings in time-series data. We demonstrate that using\nthis method, an interpretable and explainable ECG beat space can be generated,\nset up by characteristic base beats.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:41:15 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Van Steenkiste", "Tom", ""], ["Deschrijver", "Dirk", ""], ["Dhaene", "Tom", ""]]}, {"id": "1911.04908", "submitter": "Nanxin Chen", "authors": "Nanxin Chen, Shinji Watanabe, Jes\\'us Villalba, Najim Dehak", "title": "Listen and Fill in the Missing Letters: Non-Autoregressive Transformer\n  for Speech Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3044547", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently very deep transformers have outperformed conventional bi-directional\nlong short-term memory networks by a large margin in speech recognition.\nHowever, to put it into production usage, inference computation cost is still a\nserious concern in real scenarios. In this paper, we study two different\nnon-autoregressive transformer structure for automatic speech recognition\n(ASR): A-CMLM and A-FMLM. During training, for both frameworks, input tokens\nfed to the decoder are randomly replaced by special mask tokens. The network is\nrequired to predict the tokens corresponding to those mask tokens by taking\nboth unmasked context and input speech into consideration. During inference, we\nstart from all mask tokens and the network iteratively predicts missing tokens\nbased on partial results. We show that this framework can support different\ndecoding strategies, including traditional left-to-right. A new decoding\nstrategy is proposed as an example, which starts from the easiest predictions\nto the most difficult ones. Results on Mandarin (Aishell) and Japanese (CSJ)\nASR benchmarks show the possibility to train such a non-autoregressive network\nfor ASR. Especially in Aishell, the proposed method outperformed the Kaldi ASR\nsystem and it matches the performance of the state-of-the-art autoregressive\ntransformer with 7x speedup. Pretrained models and code will be made available\nafter publication.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:05:14 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:45:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Nanxin", ""], ["Watanabe", "Shinji", ""], ["Villalba", "Jes\u00fas", ""], ["Dehak", "Najim", ""]]}, {"id": "1911.04929", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fairness-Aware Neural R\\'eyni Minimization for Continuous Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen a dramatic rise of academic and societal\ninterest in fair machine learning. While plenty of fair algorithms have been\nproposed recently to tackle this challenge for discrete variables, only a few\nideas exist for continuous ones. The objective in this paper is to ensure some\nindependence level between the outputs of regression models and any given\ncontinuous sensitive variables. For this purpose, we use the\nHirschfeld-Gebelein-R\\'enyi (HGR) maximal correlation coefficient as a fairness\nmetric. We propose two approaches to minimize the HGR coefficient. First, by\nreducing an upper bound of the HGR with a neural network estimation of the\n$\\chi^{2}$ divergence. Second, by minimizing the HGR directly with an\nadversarial neural network architecture. The idea is to predict the output Y\nwhile minimizing the ability of an adversarial neural network to find the\nestimated transformations which are required to predict the HGR coefficient. We\nempirically assess and compare our approaches and demonstrate significant\nimprovements on previously presented work in the field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:20:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.04931", "submitter": "Mohammad Mahdi Kamani", "authors": "Mohammad Mahdi Kamani, Farzin Haddadpour, Rana Forsati, Mehrdad\n  Mahdavi", "title": "Efficient Fair Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that dimension reduction methods such as PCA may be\ninherently prone to unfairness and treat data from different sensitive groups\nsuch as race, color, sex, etc., unfairly. In pursuit of fairness-enhancing\ndimensionality reduction, using the notion of Pareto optimality, we propose an\nadaptive first-order algorithm to learn a subspace that preserves fairness,\nwhile slightly compromising the reconstruction loss. Theoretically, we provide\nsufficient conditions that the solution of the proposed algorithm belongs to\nthe Pareto frontier for all sensitive groups; thereby, the optimal trade-off\nbetween overall reconstruction loss and fairness constraints is guaranteed. We\nalso provide the convergence analysis of our algorithm and show its efficacy\nthrough empirical studies on different datasets, which demonstrates superior\nperformance in comparison with state-of-the-art algorithms. The proposed\nfairness-aware PCA algorithm can be efficiently generalized to multiple group\nsensitive features and effectively reduce the unfairness decisions in\ndownstream tasks such as classification.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:29:05 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 01:31:11 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kamani", "Mohammad Mahdi", ""], ["Haddadpour", "Farzin", ""], ["Forsati", "Rana", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "1911.04932", "submitter": "Jesus Lago", "authors": "Jesus Lago and Karel De Brabandere and Fjo De Ridder and Bart De\n  Schutter", "title": "Short-term forecasting of solar irradiance without local telemetry: a\n  generalized model using satellite data", "comments": null, "journal-ref": "Solar Energy 173 (2018), pages 566-577", "doi": "10.1016/j.solener.2018.07.050", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing integration of solar power into the electrical grid,\nforecasting short-term solar irradiance has become key for many applications,\ne.g.~operational planning, power purchases, reserve activation, etc. In this\ncontext, as solar generators are geographically dispersed and ground\nmeasurements are not always easy to obtain, it is very important to have\ngeneral models that can predict solar irradiance without the need of local\ndata. In this paper, a model that can perform short-term forecasting of solar\nirradiance in any general location without the need of ground measurements is\nproposed. To do so, the model considers satellite-based measurements and\nweather-based forecasts, and employs a deep neural network structure that is\nable to generalize across locations; particularly, the network is trained only\nusing a small subset of sites where ground data is available, and the model is\nable to generalize to a much larger number of locations where ground data does\nnot exist. As a case study, 25 locations in The Netherlands are considered and\nthe proposed model is compared against four local models that are individually\ntrained for each location using ground measurements. Despite the general nature\nof the model, it is shown show that the proposed model is equal or better than\nthe local models: when comparing the average performance across all the\nlocations and prediction horizons, the proposed model obtains a 31.31% rRMSE\n(relative root mean square error) while the best local model achieves a 32.01%\nrRMSE.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:30:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lago", "Jesus", ""], ["De Brabandere", "Karel", ""], ["De Ridder", "Fjo", ""], ["De Schutter", "Bart", ""]]}, {"id": "1911.04933", "submitter": "Aditya Golatkar", "authors": "Aditya Golatkar, Alessandro Achille, Stefano Soatto", "title": "Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep\n  Networks", "comments": "Accepted at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the problem of selectively forgetting a particular subset of the\ndata used for training a deep neural network. While the effects of the data to\nbe forgotten can be hidden from the output of the network, insights may still\nbe gleaned by probing deep into its weights. We propose a method for\n\"scrubbing'\" the weights clean of information about a particular set of\ntraining data. The method does not require retraining from scratch, nor access\nto the data originally used for training. Instead, the weights are modified so\nthat any probing function of the weights is indistinguishable from the same\nfunction applied to the weights of a network trained without the data to be\nforgotten. This condition is a generalized and weaker form of Differential\nPrivacy. Exploiting ideas related to the stability of stochastic gradient\ndescent, we introduce an upper-bound on the amount of information remaining in\nthe weights, which can be estimated efficiently even for deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:35:39 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 20:14:45 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 05:44:33 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 06:53:59 GMT"}, {"version": "v5", "created": "Tue, 31 Mar 2020 22:48:01 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Golatkar", "Aditya", ""], ["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1911.04936", "submitter": "Qiang Ma", "authors": "Qiang Ma, Suwen Ge, Danyang He, Darshan Thaker, Iddo Drori", "title": "Combinatorial Optimization by Graph Pointer Networks and Hierarchical\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce Graph Pointer Networks (GPNs) trained using\nreinforcement learning (RL) for tackling the traveling salesman problem (TSP).\nGPNs build upon Pointer Networks by introducing a graph embedding layer on the\ninput, which captures relationships between nodes. Furthermore, to approximate\nsolutions to constrained combinatorial optimization problems such as the TSP\nwith time windows, we train hierarchical GPNs (HGPNs) using RL, which learns a\nhierarchical policy to find an optimal city permutation under constraints. Each\nlayer of the hierarchy is designed with a separate reward function, resulting\nin stable training. Our results demonstrate that GPNs trained on small-scale\nTSP50/100 problems generalize well to larger-scale TSP500/1000 problems, with\nshorter tour lengths and faster computational times. We verify that for\nconstrained TSP problems such as the TSP with time windows, the feasible\nsolutions found via hierarchical RL training outperform previous baselines. In\nthe spirit of reproducible research we make our data, models, and code publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:39:21 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ma", "Qiang", ""], ["Ge", "Suwen", ""], ["He", "Danyang", ""], ["Thaker", "Darshan", ""], ["Drori", "Iddo", ""]]}, {"id": "1911.04947", "submitter": "Hardik Meisheri", "authors": "Hardik Meisheri, Omkar Shelke, Richa Verma, Harshad Khadilkar", "title": "Accelerating Training in Pommerman with Imitation and Reinforcement\n  Learning", "comments": "Presented at Deep Reinforcement Learning workshop, NeurIPS-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pommerman simulation was recently developed to mimic the classic Japanese\ngame Bomberman, and focuses on competitive gameplay in a multi-agent setting.\nWe focus on the 2$\\times$2 team version of Pommerman, developed for a\ncompetition at NeurIPS 2018. Our methodology involves training an agent\ninitially through imitation learning on a noisy expert policy, followed by a\nproximal-policy optimization (PPO) reinforcement learning algorithm. The basic\nPPO approach is modified for stable transition from the imitation learning\nphase through reward shaping, action filters based on heuristics, and\ncurriculum learning. The proposed methodology is able to beat heuristic and\npure reinforcement learning baselines with a combined 100,000 training games,\nsignificantly faster than other non-tree-search methods in literature. We\npresent results against multiple agents provided by the developers of the\nsimulation, including some that we have enhanced. We include a sensitivity\nanalysis over different parameters, and highlight undesirable effects of some\nstrategies that initially appear promising. Since Pommerman is a complex\nmulti-agent competitive environment, the strategies developed here provide\ninsights into several real-world problems with characteristics such as partial\nobservability, decentralized execution (without communication), and very sparse\nand delayed rewards.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:50:18 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 05:53:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Meisheri", "Hardik", ""], ["Shelke", "Omkar", ""], ["Verma", "Richa", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "1911.04951", "submitter": "Fabien Cardinaux", "authors": "Fabien Cardinaux, Stefan Uhlich, Kazuki Yoshiyama, Javier Alonso\n  Garcia, Lukas Mauch, Stephen Tiedemann, Thomas Kemp, Akira Nakamura", "title": "Iteratively Training Look-Up Tables for Network Quantization", "comments": "Copyright 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating deep neural networks (DNNs) on devices with limited resources\nrequires the reduction of their memory as well as computational footprint.\nPopular reduction methods are network quantization or pruning, which either\nreduce the word length of the network parameters or remove weights from the\nnetwork if they are not needed. In this article we discuss a general framework\nfor network reduction which we call `Look-Up Table Quantization` (LUT-Q). For\neach layer, we learn a value dictionary and an assignment matrix to represent\nthe network weights. We propose a special solver which combines gradient\ndescent and a one-step k-means update to learn both the value dictionaries and\nassignment matrices iteratively. This method is very flexible: by constraining\nthe value dictionary, many different reduction problems such as non-uniform\nnetwork quantization, training of multiplierless networks, network pruning or\nsimultaneous quantization and pruning can be implemented without changing the\nsolver. This flexibility of the LUT-Q method allows us to use the same method\nto train networks for different hardware capabilities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:52:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cardinaux", "Fabien", ""], ["Uhlich", "Stefan", ""], ["Yoshiyama", "Kazuki", ""], ["Garcia", "Javier Alonso", ""], ["Mauch", "Lukas", ""], ["Tiedemann", "Stephen", ""], ["Kemp", "Thomas", ""], ["Nakamura", "Akira", ""]]}, {"id": "1911.04954", "submitter": "Mohammed Elhenawy Dr", "authors": "Mohammed Elhenawy, Arash Jahangiri, Hesham Rakha", "title": "Impact of Narrow Lanes on Arterial Road Vehicle Crashes: A Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we adopted state-of-the-art machine learning algorithms,\nnamely: random forest (RF) and least squares boosting, to model crash data and\nidentify the optimum model to study the impact of narrow lanes on the safety of\narterial roads. Using a ten-year crash dataset in four cities in Nebraska, two\nmachine learning models were assessed based on the prediction error. The RF\nmodel was identified as the best model. The RF was used to compute the\nimportance of the lane width predictors in our regression model based on two\ndifferent measures. Subsequently, the RF model was used to simulate the crash\nrate for different lane widths. The Kruskal-Wallis test, was then conducted to\ndetermine if simulated values from the four lane width groups have equal means.\nThe test null hypothesis of equal means for simulated values from the four lane\nwidth groups was rejected. Consequently, it was concluded that the crash rates\nfrom at least one lane width group was statistically different from the others.\nFinally, the results from the pairwise comparisons using the Tukey and Kramer\ntest showed that the changes in crash rates between any two lane width\nconditions were statistically significant.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 12:21:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Elhenawy", "Mohammed", ""], ["Jahangiri", "Arash", ""], ["Rakha", "Hesham", ""]]}, {"id": "1911.04964", "submitter": "George Monta\\~nez", "authors": "Julius Lauw, Dominique Macias, Akshay Trikha, Julia Vendemiatti,\n  George D. Montanez", "title": "The Bias-Expressivity Trade-off", "comments": "arXiv admin note: text overlap with arXiv:1907.06010", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms need bias to generalize and perform better than random\nguessing. We examine the flexibility (expressivity) of biased algorithms. An\nexpressive algorithm can adapt to changing training data, altering its outcome\nbased on changes in its input. We measure expressivity by using an\ninformation-theoretic notion of entropy on algorithm outcome distributions,\ndemonstrating a trade-off between bias and expressivity. To the degree an\nalgorithm is biased is the degree to which it can outperform uniform random\nsampling, but is also the degree to which is becomes inflexible. We derive\nbounds relating bias to expressivity, proving the necessary trade-offs inherent\nin trying to create strongly performing yet flexible algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:51:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lauw", "Julius", ""], ["Macias", "Dominique", ""], ["Trikha", "Akshay", ""], ["Vendemiatti", "Julia", ""], ["Montanez", "George D.", ""]]}, {"id": "1911.04965", "submitter": "Florence Regol", "authors": "Soumyasundar Pal, Florence Regol, Mark Coates", "title": "Bayesian Graph Convolutional Neural Networks using Node Copying", "comments": "arXiv admin note: text overlap with arXiv:1910.12132", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNN) have numerous applications in\ndifferent graph based learning tasks. Although the techniques obtain impressive\nresults, they often fall short in accounting for the uncertainty associated\nwith the underlying graph structure. In the recently proposed Bayesian GCNN\n(BGCN) framework, this issue is tackled by viewing the observed graph as a\nsample from a parametric random graph model and targeting joint inference of\nthe graph and the GCNN weights. In this paper, we introduce an alternative\ngenerative model for graphs based on copying nodes and incorporate it within\nthe BGCN framework. Our approach has the benefit that it uses information\nprovided by the node features and training labels in the graph topology\ninference. Experiments show that the proposed algorithm compares favorably to\nthe state-of-the-art in benchmark node classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:16:24 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Pal", "Soumyasundar", ""], ["Regol", "Florence", ""], ["Coates", "Mark", ""]]}, {"id": "1911.04967", "submitter": "Louis van Harten", "authors": "Louis D. van Harten, Jelmer M. Wolterink, Joost J.C. Verhoeff, Ivana\n  I\\v{s}gum", "title": "Exploiting Clinically Available Delineations for CNN-based Segmentation\n  in Radiotherapy Treatment Planning", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been widely and successfully used\nfor medical image segmentation. However, CNNs are typically considered to\nrequire large numbers of dedicated expert-segmented training volumes, which may\nbe limiting in practice. This work investigates whether clinically obtained\nsegmentations which are readily available in picture archiving and\ncommunication systems (PACS) could provide a possible source of data to train a\nCNN for segmentation of organs-at-risk (OARs) in radiotherapy treatment\nplanning. In such data, delineations of structures deemed irrelevant to the\ntarget clinical use may be lacking. To overcome this issue, we use multi-label\ninstead of multi-class segmentation. We empirically assess how many clinical\ndelineations would be sufficient to train a CNN for the segmentation of OARs\nand find that increasing the training set size beyond a limited number of\nimages leads to sharply diminishing returns. Moreover, we find that by using\nmulti-label segmentation, missing structures in the reference standard do not\nhave a negative effect on overall segmentation accuracy. These results indicate\nthat segmentations obtained in a clinical workflow can be used to train an\naccurate OAR segmentation model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:58:23 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["van Harten", "Louis D.", ""], ["Wolterink", "Jelmer M.", ""], ["Verhoeff", "Joost J. C.", ""], ["I\u0161gum", "Ivana", ""]]}, {"id": "1911.04969", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Romain Montagne, Barbara Hammer", "title": "Deep-Aligned Convolutional Neural Network for Skeleton-based Action\n  Recognition and Segmentation", "comments": "19th IEEE International Conference on Data Mining (ICDM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are deep learning frameworks which are\nwell-known for their notable performance in classification tasks. Hence, many\nskeleton-based action recognition and segmentation (SBARS) algorithms benefit\nfrom them in their designs. However, a shortcoming of such applications is the\ngeneral lack of spatial relationships between the input features in such data\ntypes. Besides, non-uniform temporal scalings is a common issue in\nskeleton-based data streams which leads to having different input sizes even\nwithin one specific action category. In this work, we propose a novel\ndeep-aligned convolutional neural network (DACNN) to tackle the above\nchallenges for the particular problem of SBARS. Our network is designed by\nintroducing a new type of filters in the context of CNNs which are trained\nbased on their alignments to the local subsequences in the inputs. These\nfilters result in efficient predictions as well as learning interpretable\npatterns in the data. We empirically evaluate our framework on real-world\nbenchmarks showing that the proposed DACNN algorithm obtains a competitive\nperformance compared to the state-of-the-art while benefiting from a less\ncomplicated yet more interpretable model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:00:56 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Hosseini", "Babak", ""], ["Montagne", "Romain", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.04970", "submitter": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k", "authors": "K\\\"ur\\c{s}at Tekb{\\i}y{\\i}k, Ali R{\\i}za Ekti, Ali G\\\"or\\c{c}in,\n  G\\\"une\\c{s} Karabulut Kurt, Cihat Ke\\c{c}eci", "title": "Robust and Fast Automatic Modulation Classification with CNN under\n  Multipath Fading Channels", "comments": null, "journal-ref": null, "doi": "10.1109/VTC2020-Spring48590.2020.9128408", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automatic modulation classification (AMC) has been studied for more than a\nquarter of a century; however, it has been difficult to design a classifier\nthat operates successfully under changing multipath fading conditions and other\nimpairments. Recently, deep learning (DL)-based methods are adopted by AMC\nsystems and major improvements are reported. In this paper, a novel\nconvolutional neural network (CNN) classifier model is proposed to classify\nmodulation classes in terms of their families, i.e., types. The proposed\nclassifier is robust against realistic wireless channel impairments and in\nrelation to that when the data sets that are utilized for testing and\nevaluating the proposed methods are considered, it is seen that RadioML2016.10a\nis the main dataset utilized for testing and evaluation of the proposed\nmethods. However, the channel effects incorporated in this dataset and some\nothers may lack the appropriate modeling of the real-world conditions since it\nonly considers two distributions for channel models for a single tap\nconfiguration. Therefore, in this paper, a more comprehensive dataset, named as\nHisarMod2019.1, is also introduced, considering real-life applicability.\nHisarMod2019.1 includes 26 modulation classes passing through the channels with\n5 different fading types and several numbers of taps for classification. It is\nshown that the proposed model performs better than the existing models in terms\nof both accuracy and training time under more realistic conditions. Even more,\nsurpassed their performance when the RadioML2016.10a dataset is utilized.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:02:52 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 12:24:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Tekb\u0131y\u0131k", "K\u00fcr\u015fat", ""], ["Ekti", "Ali R\u0131za", ""], ["G\u00f6r\u00e7in", "Ali", ""], ["Kurt", "G\u00fcne\u015f Karabulut", ""], ["Ke\u00e7eci", "Cihat", ""]]}, {"id": "1911.04971", "submitter": "Tal Daniel", "authors": "Tal Daniel, Thanard Kurutach and Aviv Tamar", "title": "Deep Variational Semi-Supervised Novelty Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In anomaly detection (AD), one seeks to identify whether a test sample is\nabnormal, given a data set of normal samples. A recent and promising approach\nto AD relies on deep generative models, such as variational autoencoders\n(VAEs), for unsupervised learning of the normal data distribution. In\nsemi-supervised AD (SSAD), the data also includes a small sample of labeled\nanomalies. In this work, we propose two variational methods for training VAEs\nfor SSAD. The intuitive idea in both methods is to train the encoder to\n`separate' between latent vectors for normal and outlier data. We show that\nthis idea can be derived from principled probabilistic formulations of the\nproblem, and propose simple and effective algorithms. Our methods can be\napplied to various data types, as we demonstrate on SSAD datasets ranging from\nnatural images to astronomy and medicine, can be combined with any VAE model\narchitecture, and are naturally compatible with ensembling. When comparing to\nstate-of-the-art SSAD methods that are not specific to particular data types,\nwe obtain marked improvement in outlier detection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:03:50 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 08:52:08 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Daniel", "Tal", ""], ["Kurutach", "Thanard", ""], ["Tamar", "Aviv", ""]]}, {"id": "1911.04972", "submitter": "Tristan Carsault", "authors": "Tristan Carsault, Andrew McLeod, Philippe Esling, J\\'er\\^ome Nika,\n  Eita Nakamura and Kazuyoshi Yoshii", "title": "Multi-Step Chord Sequence Prediction Based on Aggregated Multi-Scale\n  Encoder-Decoder Network", "comments": "Accepted for publication in MLSP, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the prediction of chord progressions for jazz music by\nrelying on machine learning models. The motivation of our study comes from the\nrecent success of neural networks for performing automatic music composition.\nAlthough high accuracies are obtained in single-step prediction scenarios, most\nmodels fail to generate accurate multi-step chord predictions. In this paper,\nwe postulate that this comes from the multi-scale structure of musical\ninformation and propose new architectures based on an iterative temporal\naggregation of input labels. Specifically, the input and ground truth labels\nare merged into increasingly large temporal bags, on which we train a family of\nencoder-decoder networks for each temporal scale. In a second step, we use\nthese pre-trained encoder bottleneck features at each scale in order to train a\nfinal encoder-decoder network. Furthermore, we rely on different reductions of\nthe initial chord alphabet into three adapted chord alphabets. We perform\nevaluations against several state-of-the-art models and show that our\nmulti-scale architecture outperforms existing methods in terms of accuracy and\nperplexity, while requiring relatively few parameters. We analyze musical\nproperties of the results, showing the influence of downbeat position within\nthe analysis window on accuracy, and evaluate errors using a musically-informed\ndistance metric.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:04:04 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Carsault", "Tristan", ""], ["McLeod", "Andrew", ""], ["Esling", "Philippe", ""], ["Nika", "J\u00e9r\u00f4me", ""], ["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1911.04974", "submitter": "Benjamin Lengerich", "authors": "Benjamin Lengerich, Sarah Tan, Chun-Hao Chang, Giles Hooker, Rich\n  Caruana", "title": "Purifying Interaction Effects with the Functional ANOVA: An Efficient\n  Algorithm for Recovering Identifiable Additive Models", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models which estimate main effects of individual variables alongside\ninteraction effects have an identifiability challenge: effects can be freely\nmoved between main effects and interaction effects without changing the model\nprediction. This is a critical problem for interpretability because it permits\n\"contradictory\" models to represent the same function. To solve this problem,\nwe propose pure interaction effects: variance in the outcome which cannot be\nrepresented by any smaller subset of features. This definition has an\nequivalence with the Functional ANOVA decomposition. To compute this\ndecomposition, we present a fast, exact algorithm that transforms any\npiecewise-constant function (such as a tree-based model) into a purified,\ncanonical representation. We apply this algorithm to Generalized Additive\nModels with interactions trained on several datasets and show large disparity,\nincluding contradictions, between the effects before and after purification.\nThese results underscore the need to specify data distributions and ensure\nidentifiability before interpreting model parameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:06:21 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 20:20:28 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 21:45:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lengerich", "Benjamin", ""], ["Tan", "Sarah", ""], ["Chang", "Chun-Hao", ""], ["Hooker", "Giles", ""], ["Caruana", "Rich", ""]]}, {"id": "1911.04975", "submitter": "Tomasz Arodz", "authors": "Aliakbar Panahi, Seyran Saeedi, Tom Arodz", "title": "word2ket: Space-efficient Word Embeddings inspired by Quantum\n  Entanglement", "comments": null, "journal-ref": "International Conference on Learning Representations 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning natural language processing models often use vector word\nembeddings, such as word2vec or GloVe, to represent words. A discrete sequence\nof words can be much more easily integrated with downstream neural layers if it\nis represented as a sequence of continuous vectors. Also, semantic\nrelationships between words, learned from a text corpus, can be encoded in the\nrelative configurations of the embedding vectors. However, storing and\naccessing embedding vectors for all words in a dictionary requires large amount\nof space, and may stain systems with limited GPU memory. Here, we used\napproaches inspired by quantum computing to propose two related methods, {\\em\nword2ket} and {\\em word2ketXS}, for storing word embedding matrix during\ntraining and inference in a highly efficient way. Our approach achieves a\nhundred-fold or more reduction in the space required to store the embeddings\nwith almost no relative drop in accuracy in practical natural language\nprocessing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:06:50 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 12:23:59 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 14:08:07 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Panahi", "Aliakbar", ""], ["Saeedi", "Seyran", ""], ["Arodz", "Tom", ""]]}, {"id": "1911.04986", "submitter": "Louis van Harten", "authors": "Louis D. van Harten, Jelmer M. Wolterink, Joost J.C. Verhoeff, Ivana\n  I\\v{s}gum", "title": "Automatic Online Quality Control of Synthetic CTs", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate MR-to-CT synthesis is a requirement for MR-only workflows in\nradiotherapy (RT) treatment planning. In recent years, deep learning-based\napproaches have shown impressive results in this field. However, to prevent\ndownstream errors in RT treatment planning, it is important that deep learning\nmodels are only applied to data for which they are trained and that generated\nsynthetic CT (sCT) images do not contain severe errors. For this, a mechanism\nfor online quality control should be in place. In this work, we use an ensemble\nof sCT generators and assess their disagreement as a measure of uncertainty of\nthe results. We show that this uncertainty measure can be used for two kinds of\nonline quality control. First, to detect input images that are outside the\nexpected distribution of MR images. Second, to identify sCT images that were\ngenerated from suitable MR images but potentially contain errors. Such\nautomatic online quality control for sCT generation is likely to become an\nintegral part of MR-only RT workflows.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:19:20 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["van Harten", "Louis D.", ""], ["Wolterink", "Jelmer M.", ""], ["Verhoeff", "Joost J. C.", ""], ["I\u0161gum", "Ivana", ""]]}, {"id": "1911.05020", "submitter": "Jianjun Hu", "authors": "Yabo Dan, Yong Zhao, Xiang Li, Shaobo Li, Ming Hu and Jianjun Hu", "title": "Generative adversarial networks (GAN) based efficient sampling of\n  chemical space for inverse design of inorganic materials", "comments": "15 pages", "journal-ref": "npj Comput Mater 6, 84 (2020)", "doi": "10.1038/s41524-020-00352-0", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A major challenge in materials design is how to efficiently search the vast\nchemical design space to find the materials with desired properties. One\neffective strategy is to develop sampling algorithms that can exploit both\nexplicit chemical knowledge and implicit composition rules embodied in the\nlarge materials database. Here, we propose a generative machine learning model\n(MatGAN) based on a generative adversarial network (GAN) for efficient\ngeneration of new hypothetical inorganic materials. Trained with materials from\nthe ICSD database, our GAN model can generate hypothetical materials not\nexisting in the training dataset, reaching a novelty of 92.53% when generating\n2 million samples. The percentage of chemically valid (charge neutral and\nelectronegativity balanced) samples out of all generated ones reaches 84.5% by\nour GAN when trained with materials from ICSD even though no such chemical\nrules are explicitly enforced in our GAN model, indicating its capability to\nlearn implicit chemical composition rules. Our algorithm could be used to speed\nup inverse design or computational screening of inorganic materials.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:31:37 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dan", "Yabo", ""], ["Zhao", "Yong", ""], ["Li", "Xiang", ""], ["Li", "Shaobo", ""], ["Hu", "Ming", ""], ["Hu", "Jianjun", ""]]}, {"id": "1911.05035", "submitter": "Konstantin Rusch", "authors": "Konstantin Rusch, John W. Pearson, Konstantinos C. Zygalakis", "title": "Constructing Gradient Controllable Recurrent Neural Networks Using\n  Hamiltonian Dynamics", "comments": "Reasons: 1. theoretical result of bounding the gradient dynamics is\n  highly important when tackling the exploding gradient problem. However, we\n  only proved the boundedness in one dimension and cannot generalize to the\n  higher dimensional case, as the Hamiltonian argument is not valid in the\n  general higher dimensional case. 2. The only medium strong performance on the\n  widely used sMNIST problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have gained a great deal of attention in\nsolving sequential learning problems. The learning of long-term dependencies,\nhowever, remains challenging due to the problem of a vanishing or exploding\nhidden states gradient. By exploring further the recently established\nconnections between RNNs and dynamical systems we propose a novel RNN\narchitecture, which we call a Hamiltonian recurrent neural network (Hamiltonian\nRNN), based on a symplectic discretization of an appropriately chosen\nHamiltonian system. The key benefit of this approach is that the corresponding\nRNN inherits the favorable long time properties of the Hamiltonian system,\nwhich in turn allows us to control the hidden states gradient with a\nhyperparameter of the Hamiltonian RNN architecture. This enables us to handle\nsequential learning problems with arbitrary sequence lengths, since for a range\nof values of this hyperparameter the gradient neither vanishes nor explodes.\nAdditionally, we provide a heuristic for the optimal choice of the\nhyperparameter, which we use in our numerical simulations to illustrate that\nthe Hamiltonian RNN is able to outperform other state-of-the-art RNNs without\nthe need of computationally intensive hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:38:10 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 08:22:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Rusch", "Konstantin", ""], ["Pearson", "John W.", ""], ["Zygalakis", "Konstantinos C.", ""]]}, {"id": "1911.05059", "submitter": "Quanquan Gu", "authors": "Yuan Cao and Quanquan Gu", "title": "Tight Sample Complexity of Learning One-hidden-layer Convolutional\n  Neural Networks", "comments": "45 pages, 3 figures, 1 table. In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning one-hidden-layer convolutional\nneural networks (CNNs) with non-overlapping filters. We propose a novel\nalgorithm called approximate gradient descent for training CNNs, and show that,\nwith high probability, the proposed algorithm with random initialization grants\na linear convergence to the ground-truth parameters up to statistical\nprecision. Compared with existing work, our result applies to general\nnon-trivial, monotonic and Lipschitz continuous activation functions including\nReLU, Leaky ReLU, Sigmod and Softplus etc. Moreover, our sample complexity\nbeats existing results in the dependency of the number of hidden nodes and\nfilter size. In fact, our result matches the information-theoretic lower bound\nfor learning one-hidden-layer CNNs with linear activation functions, suggesting\nthat our sample complexity is tight. Our theoretical analysis is backed up by\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:34:19 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.05073", "submitter": "Yaohua Hu", "authors": "Xin Li, Yaohua Hu, Chong Li, Xiaoqi Yang, Tianzi Jiang", "title": "Sparse estimation via $\\ell_q$ optimization method in high-dimensional\n  linear regression", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the statistical properties of the $\\ell_q$\noptimization methods $(0<q\\leq 1)$, including the $\\ell_q$ minimization method\nand the $\\ell_q$ regularization method, for estimating a sparse parameter from\nnoisy observations in high-dimensional linear regression with either a\ndeterministic or random design. For this purpose, we introduce a general\n$q$-restricted eigenvalue condition (REC) and provide its sufficient conditions\nin terms of several widely-used regularity conditions such as sparse eigenvalue\ncondition, restricted isometry property, and mutual incoherence property. By\nvirtue of the $q$-REC, we exhibit the stable recovery property of the $\\ell_q$\noptimization methods for either deterministic or random designs by showing that\nthe $\\ell_2$ recovery bound $O(\\epsilon^2)$ for the $\\ell_q$ minimization\nmethod and the oracle inequality and $\\ell_2$ recovery bound\n$O(\\lambda^{\\frac{2}{2-q}}s)$ for the $\\ell_q$ regularization method hold\nrespectively with high probability. The results in this paper are nonasymptotic\nand only assume the weak $q$-REC. The preliminary numerical results verify the\nestablished statistical property and demonstrate the advantages of the $\\ell_q$\nregularization method over some existing sparse optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:34:18 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Xin", ""], ["Hu", "Yaohua", ""], ["Li", "Chong", ""], ["Yang", "Xiaoqi", ""], ["Jiang", "Tianzi", ""]]}, {"id": "1911.05100", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Jelena Gligorijevic and Aaron Flores", "title": "Time-Aware Prospective Modeling of Users for Online Display Advertising", "comments": "Accepted at AdKDD 2019 workshop at KDD'19 conference, Anchorage,\n  Alaska, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prospective display advertising poses a great challenge for large advertising\nplatforms as the strongest predictive signals of users are not eligible to be\nused in the conversion prediction systems. To that end efforts are made to\ncollect as much information as possible about each user from various data\nsources and to design powerful models that can capture weaker signals\nultimately obtaining good quality of conversion prediction probability\nestimates. In this study we propose a novel time-aware approach to model\nheterogeneous sequences of users' activities and capture implicit signals of\nusers' conversion intents. On two real-world datasets we show that our approach\noutperforms other, previously proposed approaches, while providing\ninterpretability of signal impact to conversion probability.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:06:59 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Gligorijevic", "Jelena", ""], ["Flores", "Aaron", ""]]}, {"id": "1911.05109", "submitter": "Jeremy Weiss", "authors": "Yoonjung Kim and Jeremy C. Weiss", "title": "Harmonic Mean Point Processes: Proportional Rate Error Minimization for\n  Obtundation Prediction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, the highest risk individuals for morbidity and mortality are\nrarely those with the greatest modifiable risk. By contrast, many machine\nlearning formulations implicitly attend to the highest risk individuals. We\nfocus on this problem in point processes, a popular modeling technique for the\nanalysis of the temporal event sequences in electronic health records (EHR)\ndata with applications in risk stratification and risk score systems. We show\nthat optimization of the log-likelihood function also gives disproportionate\nattention to high risk individuals and leads to poor prediction results for low\nrisk individuals compared to ones at high risk. We characterize the problem and\npropose an adjusted log-likelihood formulation as a new objective for point\nprocesses. We demonstrate the benefits of our method in simulations and in EHR\ndata of patients admitted to the critical care unit for intracerebral\nhemorrhage.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:19:36 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 18:45:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Yoonjung", ""], ["Weiss", "Jeremy C.", ""]]}, {"id": "1911.05116", "submitter": "Robert MacKay", "authors": "Nicholas Beale, Heather Battey, Anthony C. Davison, and Robert S.\n  MacKay", "title": "An Unethical Optimization Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If an artificial intelligence aims to maximise risk-adjusted return, then\nunder mild conditions it is disproportionately likely to pick an unethical\nstrategy unless the objective function allows sufficiently for this risk. Even\nif the proportion ${\\eta}$ of available unethical strategies is small, the\nprobability ${p_U}$ of picking an unethical strategy can become large; indeed\nunless returns are fat-tailed ${p_U}$ tends to unity as the strategy space\nbecomes large. We define an Unethical Odds Ratio Upsilon (${\\Upsilon}$) that\nallows us to calculate ${p_U}$ from ${\\eta}$, and we derive a simple formula\nfor the limit of ${\\Upsilon}$ as the strategy space becomes large. We give an\nalgorithm for estimating ${\\Upsilon}$ and ${p_U}$ in finite cases and discuss\nhow to deal with infinite strategy spaces. We show how this principle can be\nused to help detect unethical strategies and to estimate ${\\eta}$. Finally we\nsketch some policy implications of this work.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:41:46 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Beale", "Nicholas", ""], ["Battey", "Heather", ""], ["Davison", "Anthony C.", ""], ["MacKay", "Robert S.", ""]]}, {"id": "1911.05121", "submitter": "Chufan Gao", "authors": "Chufan Gao, Fabian Falck, Mononito Goswami, Anthony Wertz, Michael R.\n  Pinsky, Artur Dubrawski", "title": "Detecting Patterns of Physiological Response to Hemodynamic Stress via\n  Unsupervised Deep Learning", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring physiological responses to hemodynamic stress can help in\ndetermining appropriate treatment and ensuring good patient outcomes.\nPhysicians' intuition suggests that the human body has a number of\nphysiological response patterns to hemorrhage which escalate as blood loss\ncontinues, however the exact etiology and phenotypes of such responses are not\nwell known or understood only at a coarse level. Although previous research has\nshown that machine learning models can perform well in hemorrhage detection and\nsurvival prediction, it is unclear whether machine learning could help to\nidentify and characterize the underlying physiological responses in raw vital\nsign data. We approach this problem by first transforming the high-dimensional\nvital sign time series into a tractable, lower-dimensional latent space using a\ndilated, causal convolutional encoder model trained purely unsupervised.\nSecond, we identify informative clusters in the embeddings. By analyzing the\nclusters of latent embeddings and visualizing them over time, we hypothesize\nthat the clusters correspond to the physiological response patterns that match\nphysicians' intuition. Furthermore, we attempt to evaluate the latent\nembeddings using a variety of methods, such as predicting the cluster labels\nusing explainable features.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:55:16 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gao", "Chufan", ""], ["Falck", "Fabian", ""], ["Goswami", "Mononito", ""], ["Wertz", "Anthony", ""], ["Pinsky", "Michael R.", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1911.05142", "submitter": "Zhiyuan Liu", "authors": "Zhiyuan Liu, Huazheng Wang, Fan Shen, Kai Liu, Lijun Chen", "title": "Incentivized Exploration for Multi-Armed Bandits under Reward Drift", "comments": "10 pages, 2 figures, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study incentivized exploration for the multi-armed bandit (MAB) problem\nwhere the players receive compensation for exploring arms other than the greedy\nchoice and may provide biased feedback on reward. We seek to understand the\nimpact of this drifted reward feedback by analyzing the performance of three\ninstantiations of the incentivized MAB algorithm: UCB, $\\varepsilon$-Greedy,\nand Thompson Sampling. Our results show that they all achieve $\\mathcal{O}(\\log\nT)$ regret and compensation under the drifted reward, and are therefore\neffective in incentivizing exploration. Numerical examples are provided to\ncomplement the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:04:30 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 21:06:01 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 03:11:49 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Liu", "Zhiyuan", ""], ["Wang", "Huazheng", ""], ["Shen", "Fan", ""], ["Liu", "Kai", ""], ["Chen", "Lijun", ""]]}, {"id": "1911.05159", "submitter": "Lili Du", "authors": "Wang Peng and Lili Du", "title": "Coordination Group Formation for OnLine Coordinated Routing Mechanisms", "comments": "24 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study considers that the collective route choices of travelers en route\nrepresent a resolution of their competition on network routes. Well\nunderstanding this competition and coordinating their route choices help\nmitigate urban traffic congestion. Even though existing studies have developed\nsuch mechanisms (e.g., the CRM [1]), we still lack the quantitative method to\nevaluate the coordination penitential and identify proper coordination groups\n(CG) to implement the CRM. Thus, they hit prohibitive computing difficulty when\nimplemented with many opt-in travelers. Motived by this view, this study\ndevelops mathematical approaches to quantify the coordination potential between\ntwo and among multiple travelers. Next, we develop the adaptive centroid-based\nclustering algorithm (ACCA), which splits travelers en route in a local network\ninto CGs, each with proper size and strong coordination potential. Moreover,\nthe ACCA is statistically secured to stop at a local optimal clustering\nsolution, which balances the inner-cluster and inter-cluster coordination\npotential. It can be implemented by parallel computation to accelerate its\ncomputing efficiency. Furthermore, we propose a clustering based coordinated\nrouting mechanism (CB-CRM), which implements a CRM on each individual CG. The\nnumerical experiments built upon both Sioux Falls and Hardee city networks show\nthat the ACCA works efficiently to form proper coordination groups so that as\ncompared to the CRM, the CB-CRM significantly improves computation efficiency\nwith minor system performance loss in a large network. This merit becomes more\napparent under high penetration and congested traffic condition. Last, the\nexperiments validate the good features of the ACCA as well as the value of\nimplementing parallel computation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:56:14 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Peng", "Wang", ""], ["Du", "Lili", ""]]}, {"id": "1911.05166", "submitter": "John Chen", "authors": "John Chen, Vatsal Shah, Anastasios Kyrillidis", "title": "Negative sampling in semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Negative Sampling in Semi-Supervised Learning (NS3L), a simple,\nfast, easy to tune algorithm for semi-supervised learning (SSL). NS3L is\nmotivated by the success of negative sampling/contrastive estimation. We\ndemonstrate that adding the NS3L loss to state-of-the-art SSL algorithms, such\nas the Virtual Adversarial Training (VAT), significantly improves upon vanilla\nVAT and its variant, VAT with Entropy Minimization. By adding the NS3L loss to\nMixMatch, the current state-of-the-art approach on semi-supervised tasks, we\nobserve significant improvements over vanilla MixMatch. We conduct extensive\nexperiments on the CIFAR10, CIFAR100, SVHN and STL10 benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:13:25 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 18:43:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chen", "John", ""], ["Shah", "Vatsal", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "1911.05167", "submitter": "Zhongruo Wang", "authors": "Zhongruo Wang", "title": "Nonconvex Stochastic Nested Optimization via Stochastic ADMM", "comments": "Nested ADMM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic nested composition optimization problem where the\nobjective is a composition of two expected-value functions. We proposed the\nstochastic ADMM to solve this complicated objective. In order to find an\n$\\epsilon$ stationary point where the expected norm of the subgradient of\ncorresponding augmented Lagrangian is smaller than $\\epsilon$, the total sample\ncomplexity of our method is $\\mathcal{O}(\\epsilon^{-3})$ for the online case\nand $\\mathcal{O} \\Bigl((2N_1 + N_2) + (2N_1 + N_2)^{1/2}\\epsilon^{-2}\\Bigr)$\nfor the finite sum case. The computational complexity is consistent with\nproximal version proposed in \\cite{zhang2019multi}, but our algorithm can solve\nmore general problem when the proximal mapping of the penalty is not easy to\ncompute.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:14:04 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Wang", "Zhongruo", ""]]}, {"id": "1911.05181", "submitter": "Jonathan Baxter", "authors": "Douglas Aberdeen, Jonathan Baxter and Robert Edwards", "title": "92c/MFlops/s, Ultra-Large-Scale Neural-Network Training on a PIII\n  Cluster", "comments": "SC '00: Proceedings of the 2000 ACM/IEEE Conference on Supercomputing", "journal-ref": "ACM/IEEE SC 2000 Conference (SC00)", "doi": "10.1109/SC.2000.10031", "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks with millions of adjustable parameters and a\nsimilar number of training examples are a potential solution for difficult,\nlarge-scale pattern recognition problems in areas such as speech and face\nrecognition, classification of large volumes of web data, and finance. The\nbottleneck is that neural network training involves iterative gradient descent\nand is extremely computationally intensive. In this paper we present a\ntechnique for distributed training of Ultra Large Scale Neural Networks (ULSNN)\non Bunyip, a Linux-based cluster of 196 Pentium III processors. To illustrate\nULSNN training we describe an experiment in which a neural network with 1.73\nmillion adjustable parameters was trained to recognize machine-printed Japanese\ncharacters from a database containing 9 million training patterns. The training\nruns with a average performance of 163.3 GFlops/s (single precision). With a\nmachine cost of \\$150,913, this yields a price/performance ratio of\n92.4c/MFlops/s (single precision). For comparison purposes, training using\ndouble precision and the ATLAS DGEMM produces a sustained performance of 70\nMFlops/s or \\$2.16 / MFlop/s (double precision).\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:57:09 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Aberdeen", "Douglas", ""], ["Baxter", "Jonathan", ""], ["Edwards", "Robert", ""]]}, {"id": "1911.05184", "submitter": "Qiao Zhang", "authors": "Qiao Zhang, Cong Wang, Chunsheng Xin and Hongyi Wu", "title": "CHEETAH: An Ultra-Fast, Approximation-Free, and Privacy-Preserved Neural\n  Network Framework based on Joint Obscure Linear and Nonlinear Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) is enabling a wide range of smart\napplications on end devices. However, such convenience comes with a cost of\nprivacy because users have to upload their private data to the cloud. This\nresearch aims to provide effective and efficient MLaaS such that the cloud\nserver learns nothing about user data and the users cannot infer the\nproprietary model parameters owned by the server. This work makes the following\ncontributions. First, it unveils the fundamental performance bottleneck of\nexisting schemes due to the heavy permutations in computing linear\ntransformation and the use of communication intensive Garbled Circuits for\nnonlinear transformation. Second, it introduces an ultra-fast secure MLaaS\nframework, CHEETAH, which features a carefully crafted secret sharing scheme\nthat runs significantly faster than existing schemes without accuracy loss.\nThird, CHEETAH is evaluated on the benchmark of well-known, practical deep\nnetworks such as AlexNet and VGG-16 on the MNIST and ImageNet datasets. The\nresults demonstrate more than 100x speedup over the fastest GAZELLE (Usenix\nSecurity'18), 2000x speedup over MiniONN (ACM CCS'17) and five orders of\nmagnitude speedup over CryptoNets (ICML'16). This significant speedup enables a\nwide range of practical applications based on privacy-preserved deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:08:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 23:58:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhang", "Qiao", ""], ["Wang", "Cong", ""], ["Xin", "Chunsheng", ""], ["Wu", "Hongyi", ""]]}, {"id": "1911.05186", "submitter": "Wei Zou", "authors": "Wubo Li, Wei Zou, Xiangang Li", "title": "TCT: A Cross-supervised Learning Method for Multimodal Sequence\n  Representation", "comments": "submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodalities provide promising performance than unimodality in most tasks.\nHowever, learning the semantic of the representations from multimodalities\nefficiently is extremely challenging. To tackle this, we propose the\nTransformer based Cross-modal Translator (TCT) to learn unimodal sequence\nrepresentations by translating from other related multimodal sequences on a\nsupervised learning method. Combined TCT with Multimodal Transformer Network\n(MTN), we evaluate MTN-TCT on the video-grounded dialogue which uses\nmultimodality. The proposed method reports new state-of-the-art performance on\nvideo-grounded dialogue which indicates representations learned by TCT are more\nsemantics compared to directly use unimodality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:02:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Wubo", ""], ["Zou", "Wei", ""], ["Li", "Xiangang", ""]]}, {"id": "1911.05187", "submitter": "Carl Norman", "authors": "Carl Norman", "title": "AI in Pursuit of Happiness, Finding Only Sadness: Multi-Modal Facial\n  Emotion Recognition Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of automated Facial Emotion Recognition (FER) grows the more\ncommon human-machine interactions become, which will only continue to increase\ndramatically with time. A common method to describe human sentiment or feeling\nis the categorical model the `7 basic emotions', consisting of `Angry',\n`Disgust', `Fear', `Happiness', `Sadness', `Surprise' and `Neutral'. The\n`Emotion Recognition in the Wild' (EmotiW) competition is now in its 7th year\nand has become the standard benchmark for measuring FER performance. The focus\nof this paper is the EmotiW sub-challenge of classifying videos in the `Acted\nFacial Expression in the Wild' (AFEW) dataset, consisting of both visual and\naudio modalities, into one of the above classes. Machine learning has exploded\nas a research topic in recent years, with advancements in `Deep Learning' a key\npart of this. Although Deep Learning techniques have been widely applied to the\nFER task by entrants in previous years, this paper has two main contributions:\n(i) to apply the latest `state-of-the-art' visual and temporal networks and\n(ii) exploring various methods of fusing features extracted from the visual and\naudio elements to enrich the information available to the final model making\nthe prediction. There are a number of complex issues that arise when trying to\nclassify emotions for `in-the-wild' video sequences, which the above two\napproaches attempt to directly address. There are some positive findings when\ncomparing the results of this paper to past submissions, indicating that\nfurther research into the proposed methods and fine-tuning of the models\ndeployed, could result in another step forwards in the field of automated FER.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:49:39 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Norman", "Carl", ""]]}, {"id": "1911.05189", "submitter": "Dmitry Rodin", "authors": "Dmitry Rodin and Nikita Orlov", "title": "Fast Glare Detection in Document Images", "comments": "4 pages, Workshop on Industrial Applications of Document Analysis and\n  Recognition 2019", "journal-ref": null, "doi": "10.1109/ICDARW.2019.60123", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glare is a phenomenon that occurs when the scene has a reflection of a light\nsource or has one in it. This luminescence can hide useful information from the\nimage, making text recognition virtually impossible. In this paper, we propose\nan approach to detect glare in images taken by users via mobile devices. Our\nmethod divides the document into blocks and collects luminance features from\nthe original image and black-white strokes histograms of the binarized image.\nFinally, glare is detected using a convolutional neural network on the\naforementioned histograms and luminance features. The network consists of\nseveral feature extraction blocks, one for each type of input, and the\ndetection block, which calculates the resulting glare heatmap based on the\noutput of the extraction part. The proposed solution detects glare with high\nrecall and f-score.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 09:12:01 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Rodin", "Dmitry", ""], ["Orlov", "Nikita", ""]]}, {"id": "1911.05210", "submitter": "Fei Ding", "authors": "Fei Ding and Feng Luo and Yin Yang", "title": "Double cycle-consistent generative adversarial network for unsupervised\n  conditional generation", "comments": "12 pages, 4 figures, and 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative models have achieved considerable success in the past\nfew years, but usually require a lot of labeled data. Recently, ClusterGAN\ncombines GAN with an encoder to achieve remarkable clustering performance via\nunsupervised conditional generation. However, it ignores the real conditional\ndistribution of data, which leads to generating less diverse samples for each\nclass and makes the encoder only achieve sub-optimal clustering performance.\nHere, we propose a new unsupervised conditional generation framework, Double\nCycle-Consistent Conditional GAN (DC3-GAN), which can generate diverse\nclass-conditioned samples. We enforce the encoder and the generator of GAN to\nform an encoder-generator pair in addition to the generator-encoder pair, which\nenables us to avoid the low-diversity generation and the triviality of latent\nfeatures. We train the encoder-generator pair using real data, which can\nindirectly estimate the real conditional distribution. Meanwhile, this\nframework enforces the outputs of the encoder to match the inputs of GAN and\nthe prior noise distribution, which disentangles latent space into two parts:\none-hot discrete and continuous latent variables. The former can be directly\nexpressed as clusters and the latter represents remaining unspecified factors.\nThis work demonstrates that enhancing the diversity of unsupervised conditional\ngenerated samples can improve the clustering performance. Experiments on\ndifferent benchmark datasets show that the proposed method outperforms existing\ngenerative model-based clustering methods, and also achieves the optimal\ndisentanglement performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 00:11:50 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:52:00 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 15:25:55 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ding", "Fei", ""], ["Luo", "Feng", ""], ["Yang", "Yin", ""]]}, {"id": "1911.05211", "submitter": "Amanda Minnich", "authors": "Amanda J. Minnich, Kevin McLoughlin, Margaret Tse, Jason Deng, Andrew\n  Weber, Neha Murad, Benjamin D. Madej, Bharath Ramsundar, Tom Rush, Stacie\n  Calad-Thomson, Jim Brase, Jonathan E. Allen", "title": "AMPL: A Data-Driven Modeling Pipeline for Drug Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key requirements for incorporating machine learning into the drug\ndiscovery process is complete reproducibility and traceability of the model\nbuilding and evaluation process. With this in mind, we have developed an\nend-to-end modular and extensible software pipeline for building and sharing\nmachine learning models that predict key pharma-relevant parameters. The ATOM\nModeling PipeLine, or AMPL, extends the functionality of the open source\nlibrary DeepChem and supports an array of machine learning and molecular\nfeaturization tools. We have benchmarked AMPL on a large collection of\npharmaceutical datasets covering a wide range of parameters. As a result of\nthese comprehensive experiments, we have found that physicochemical descriptors\nand deep learning-based graph representations significantly outperform\ntraditional fingerprints in the characterization of molecular features. We have\nalso found that dataset size is directly correlated to prediction performance,\nand that single-task deep learning models only outperform shallow learners if\nthere is sufficient data. Likewise, dataset size has a direct impact on model\npredictivity, independent of comprehensive hyperparameter model tuning. Our\nfindings point to the need for public dataset integration or\nmulti-task/transfer learning approaches. Lastly, we found that uncertainty\nquantification (UQ) analysis may help identify model error; however, efficacy\nof UQ to filter predictions varies considerably between datasets and\nfeaturization/model types. AMPL is open source and available for download at\nhttp://github.com/ATOMconsortium/AMPL.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 00:13:08 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 01:38:49 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Minnich", "Amanda J.", ""], ["McLoughlin", "Kevin", ""], ["Tse", "Margaret", ""], ["Deng", "Jason", ""], ["Weber", "Andrew", ""], ["Murad", "Neha", ""], ["Madej", "Benjamin D.", ""], ["Ramsundar", "Bharath", ""], ["Rush", "Tom", ""], ["Calad-Thomson", "Stacie", ""], ["Brase", "Jim", ""], ["Allen", "Jonathan E.", ""]]}, {"id": "1911.05242", "submitter": "Abdelrahman Zayed", "authors": "Abdelrahman Zayed and Hassan Rivaz", "title": "Fast Approximate Time-Delay Estimation in Ultrasound Elastography Using\n  Principal Component Analysis", "comments": "Accepted to be Published in 2019, 41th Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),\n  Berlin, Germany", "journal-ref": "2019 41st Annual International Conference of the IEEE Engineering\n  in Medicine and Biology Society (EMBC)", "doi": "10.1109/embc.2019.8857242", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time delay estimation (TDE) is a critical and challenging step in all\nultrasound elastography methods. A growing number of TDE techniques require an\napproximate but robust and fast method to initialize solving for TDE. Herein,\nwe present a fast method for calculating an approximate TDE between two radio\nfrequency (RF) frames of ultrasound. Although this approximate TDE can be\nuseful for several algorithms, we focus on GLobal Ultrasound Elastography\n(GLUE), which currently relies on Dynamic Programming (DP) to provide this\napproximate TDE. We exploit Principal Component Analysis (PCA) to find the\ngeneral modes of deformation in quasi-static elastography, and therefore call\nour method PCA-GLUE. PCA-GLUE is a data-driven approach that learns a set of\nTDE principal components from a training database in real experiments. In the\ntest phase, TDE is approximated as a weighted sum of these principal\ncomponents. Our algorithm robustly estimates the weights from sparse feature\nmatches, then passes the resulting displacement field to GLUE as initial\nestimates to perform a more accurate displacement estimation. PCA-GLUE is more\nthan ten times faster than DP in estimation of the initial displacement field\nand yields similar results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 01:54:18 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zayed", "Abdelrahman", ""], ["Rivaz", "Hassan", ""]]}, {"id": "1911.05248", "submitter": "Sara Hooker", "authors": "Sara Hooker, Aaron Courville, Gregory Clark, Yann Dauphin, Andrea\n  Frome", "title": "What Do Compressed Deep Neural Networks Forget?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network pruning and quantization techniques have demonstrated it\nis possible to achieve high levels of compression with surprisingly little\ndegradation to test set accuracy. However, this measure of performance conceals\nsignificant differences in how different classes and images are impacted by\nmodel compression techniques. We find that models with radically different\nnumbers of weights have comparable top-line performance metrics but diverge\nconsiderably in behavior on a narrow subset of the dataset. This small subset\nof data points, which we term Pruning Identified Exemplars (PIEs) are\nsystematically more impacted by the introduction of sparsity. Compression\ndisproportionately impacts model performance on the underrepresented long-tail\nof the data distribution. PIEs over-index on atypical or noisy images that are\nfar more challenging for both humans and algorithms to classify. Our work\nprovides intuition into the role of capacity in deep neural networks and the\ntrade-offs incurred by compression. An understanding of this disparate impact\nis critical given the widespread deployment of compressed models in the wild.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:02:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:24:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hooker", "Sara", ""], ["Courville", "Aaron", ""], ["Clark", "Gregory", ""], ["Dauphin", "Yann", ""], ["Frome", "Andrea", ""]]}, {"id": "1911.05256", "submitter": "Michael Lingzhi Li", "authors": "Michael Lingzhi Li, Meng Dong, Jiawei Zhou, Alexander M. Rush", "title": "A Hierarchy of Graph Neural Networks Based on Learnable Local Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a powerful tool to learn representations on\ngraphs by iteratively aggregating features from node neighbourhoods. Many\nvariant models have been proposed, but there is limited understanding on both\nhow to compare different architectures and how to construct GNNs\nsystematically. Here, we propose a hierarchy of GNNs based on their aggregation\nregions. We derive theoretical results about the discriminative power and\nfeature representation capabilities of each class. Then, we show how this\nframework can be utilized to systematically construct arbitrarily powerful\nGNNs. As an example, we construct a simple architecture that exceeds the\nexpressiveness of the Weisfeiler-Lehman graph isomorphism test. We empirically\nvalidate our theory on both synthetic and real-world benchmarks, and\ndemonstrate our example's theoretical power translates to strong results on\nnode classification, graph classification, and graph regression tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:22:54 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Michael Lingzhi", ""], ["Dong", "Meng", ""], ["Zhou", "Jiawei", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1911.05266", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Akshay Chawla, Marios Savvides", "title": "Learning Non-Parametric Invariances from Data with Permanent Random\n  Connectomes", "comments": "Preprint (accepted at NeurIPS SVRHM 2019 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental problems in supervised classification and in machine\nlearning in general, is the modelling of non-parametric invariances that exist\nin data. Most prior art has focused on enforcing priors in the form of\ninvariances to parametric nuisance transformations that are expected to be\npresent in data. Learning non-parametric invariances directly from data remains\nan important open problem. In this paper, we introduce a new architectural\nlayer for convolutional networks which is capable of learning general\ninvariances from data itself. This layer can learn invariance to non-parametric\ntransformations and interestingly, motivates and incorporates permanent random\nconnectomes, thereby being called Permanent Random Connectome Non-Parametric\nTransformation Networks (PRC-NPTN). PRC-NPTN networks are initialized with\nrandom connections (not just weights) which are a small subset of the\nconnections in a fully connected convolution layer. Importantly, these\nconnections in PRC-NPTNs once initialized remain permanent throughout training\nand testing. Permanent random connectomes make these architectures loosely more\nbiologically plausible than many other mainstream network architectures which\nrequire highly ordered structures. We motivate randomly initialized connections\nas a simple method to learn invariance from data itself while invoking\ninvariance towards multiple nuisance transformations simultaneously. We find\nthat these randomly initialized permanent connections have positive effects on\ngeneralization, outperform much larger ConvNet baselines and the recently\nproposed Non-Parametric Transformation Network (NPTN) on benchmarks that\nenforce learning invariances from the data itself.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:03:48 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:32:41 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 00:54:18 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Pal", "Dipan K.", ""], ["Chawla", "Akshay", ""], ["Savvides", "Marios", ""]]}, {"id": "1911.05268", "submitter": "Rey Wiyatno", "authors": "Rey Reza Wiyatno, Anqi Xu, Ousmane Dia, Archy de Berker", "title": "Adversarial Examples in Modern Machine Learning: A Review", "comments": "Work in progress, 97 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has found that many families of machine learning models are\nvulnerable to adversarial examples: inputs that are specifically designed to\ncause the target model to produce erroneous outputs. In this survey, we focus\non machine learning models in the visual domain, where methods for generating\nand detecting such examples have been most extensively studied. We explore a\nvariety of adversarial attack methods that apply to image-space content, real\nworld adversarial attacks, adversarial defenses, and the transferability\nproperty of adversarial examples. We also discuss strengths and weaknesses of\nvarious methods of adversarial attack and defense. Our aim is to provide an\nextensive coverage of the field, furnishing the reader with an intuitive\nunderstanding of the mechanics of adversarial attack and defense mechanisms and\nenlarging the community of researchers studying this fundamental set of\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:09:40 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:07:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wiyatno", "Rey Reza", ""], ["Xu", "Anqi", ""], ["Dia", "Ousmane", ""], ["de Berker", "Archy", ""]]}, {"id": "1911.05275", "submitter": "Gaurav Menghani", "authors": "Gaurav Menghani, Sujith Ravi", "title": "Learning from a Teacher using Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is a widely used technique for model compression. We\nposit that the teacher model used in a distillation setup, captures\nrelationships between classes, that extend beyond the original dataset. We\nempirically show that a teacher model can transfer this knowledge to a student\nmodel even on an {\\it out-of-distribution} dataset. Using this approach, we\nshow promising results on MNIST, CIFAR-10, and Caltech-256 datasets using\nunlabeled image data from different sources. Our results are encouraging and\nhelp shed further light from the perspective of understanding knowledge\ndistillation and utilizing unlabeled data to improve model quality.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:43:29 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Menghani", "Gaurav", ""], ["Ravi", "Sujith", ""]]}, {"id": "1911.05276", "submitter": "Jae-woong Lee", "authors": "Jae-woong Lee, Minjin Choi, Jongwuk Lee, and Hyunjung Shim", "title": "Collaborative Distillation for Top-N Recommendation", "comments": "10 pages, ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a well-known method to reduce inference\nlatency by compressing a cumbersome teacher model to a small student model.\nDespite the success of KD in the classification task, applying KD to\nrecommender models is challenging due to the sparsity of positive feedback, the\nambiguity of missing feedback, and the ranking problem associated with the\ntop-N recommendation. To address the issues, we propose a new KD model for the\ncollaborative filtering approach, namely collaborative distillation (CD).\nSpecifically, (1) we reformulate a loss function to deal with the ambiguity of\nmissing feedback. (2) We exploit probabilistic rank-aware sampling for the\ntop-N recommendation. (3) To train the proposed model effectively, we develop\ntwo training strategies for the student model, called the teacher- and the\nstudent-guided training methods, selecting the most useful feedback from the\nteacher model. Via experimental results, we demonstrate that the proposed model\noutperforms the state-of-the-art method by 2.7-33.2% and 2.7-29.1% in hit rate\n(HR) and normalized discounted cumulative gain (NDCG), respectively. Moreover,\nthe proposed model achieves the performance comparable to the teacher model.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:43:35 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lee", "Jae-woong", ""], ["Choi", "Minjin", ""], ["Lee", "Jongwuk", ""], ["Shim", "Hyunjung", ""]]}, {"id": "1911.05289", "submitter": "Jeffrey Dean", "authors": "Jeffrey Dean", "title": "The Deep Learning Revolution and Its Implications for Computer\n  Architecture and Chip Design", "comments": "Companion paper to accompany a keynote talk at ISSCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen a remarkable series of advances in machine learning,\nand in particular deep learning approaches based on artificial neural networks,\nto improve our abilities to build more accurate systems across a broad range of\nareas, including computer vision, speech recognition, language translation, and\nnatural language understanding tasks. This paper is a companion paper to a\nkeynote talk at the 2020 International Solid-State Circuits Conference (ISSCC)\ndiscussing some of the advances in machine learning, and their implications on\nthe kinds of computational devices we need to build, especially in the\npost-Moore's Law-era. It also discusses some of the ways that machine learning\nmay also be able to help with some aspects of the circuit design process.\nFinally, it provides a sketch of at least one interesting direction towards\nmuch larger-scale multi-task models that are sparsely activated and employ much\nmore dynamic, example- and task-based routing than the machine learning models\nof today.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 04:41:31 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Dean", "Jeffrey", ""]]}, {"id": "1911.05309", "submitter": "Mengying Zhu", "authors": "Mengying Zhu, Xiaolin Zheng, Yan Wang, Yuyuan Li, Qianqiao Liang", "title": "Adaptive Portfolio by Solving Multi-armed Bandit via Thompson Sampling", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the cornerstone of modern portfolio theory, Markowitz's mean-variance\noptimization is considered a major model adopted in portfolio management.\nHowever, due to the difficulty of estimating its parameters, it cannot be\napplied to all periods. In some cases, naive strategies such as\nEqually-weighted and Value-weighted portfolios can even get better performance.\nUnder these circumstances, we can use multiple classic strategies as multiple\nstrategic arms in multi-armed bandit to naturally establish a connection with\nthe portfolio selection problem. This can also help to maximize the rewards in\nthe bandit algorithm by the trade-off between exploration and exploitation. In\nthis paper, we present a portfolio bandit strategy through Thompson sampling\nwhich aims to make online portfolio choices by effectively exploiting the\nperformances among multiple arms. Also, by constructing multiple strategic\narms, we can obtain the optimal investment portfolio to adapt different\ninvestment periods. Moreover, we devise a novel reward function based on users'\ndifferent investment risk preferences, which can be adaptive to various\ninvestment styles. Our experimental results demonstrate that our proposed\nportfolio strategy has marked superiority across representative real-world\nmarket datasets in terms of extensive evaluation criteria.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:08:44 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 06:39:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zhu", "Mengying", ""], ["Zheng", "Xiaolin", ""], ["Wang", "Yan", ""], ["Li", "Yuyuan", ""], ["Liang", "Qianqiao", ""]]}, {"id": "1911.05312", "submitter": "Mohammed Elhenawy Dr", "authors": "Mohammed Elhenawy, Mahmoud Masoud, Sebastian Glaser, Andry\n  Rakotonirainy", "title": "Topological Stability: a New Algorithm for Selecting The Nearest\n  Neighbors in Non-Linear Dimensionality Reduction Techniques", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.16800.17922", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the machine learning field, dimensionality reduction is an important task.\nIt mitigates the undesired properties of high-dimensional spaces to facilitate\nclassification, compression, and visualization of high-dimensional data. During\nthe last decade, researchers proposed many new (non-linear) techniques for\ndimensionality reduction. Most of these techniques are based on the intuition\nthat data lies on or near a complex low-dimensional manifold that is embedded\nin the high-dimensional space. New techniques for dimensionality reduction aim\nat identifying and extracting the manifold from the high-dimensional space.\nIsomap is one of widely-used low-dimensional embedding methods, where geodesic\ndistances on a weighted graph are incorporated with the classical scaling\n(metric multidimensional scaling). The Isomap chooses the nearest neighbours\nbased on the distance only which causes bridges and topological instability. In\nthis paper, we propose a new algorithm to choose the nearest neighbours to\nreduce the number of short-circuit errors and hence improves the topological\nstability. Because at any point on the manifold, that point and its nearest\nneighbours form a vector subspace and the orthogonal to that subspace is\northogonal to all vectors spans the vector subspace. The prposed algorithmuses\nthe point itself and its two nearest neighbours to find the bases of the\nsubspace and the orthogonal to that subspace which belongs to the orthogonal\ncomplementary subspace. The proposed algorithm then adds new points to the two\nnearest neighbours based on the distance and the angle between each new point\nand the orthogonal to the subspace. The superior performance of the new\nalgorithm in choosing the nearest neighbours is confirmed through experimental\nwork with several datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:17:12 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 04:22:43 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Elhenawy", "Mohammed", ""], ["Masoud", "Mahmoud", ""], ["Glaser", "Sebastian", ""], ["Rakotonirainy", "Andry", ""]]}, {"id": "1911.05332", "submitter": "Anqi Liu", "authors": "Anqi Liu, Maya Srikanth, Nicholas Adams-Cohen, R. Michael Alvarez,\n  Anima Anandkumar", "title": "Finding Social Media Trolls: Dynamic Keyword Selection Methods for\n  Rapidly-Evolving Online Debates", "comments": "AI for Social Good workshop at NeurIPS (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online harassment is a significant social problem. Prevention of online\nharassment requires rapid detection of harassing, offensive, and negative\nsocial media posts. In this paper, we propose the use of word embedding models\nto identify offensive and harassing social media messages in two aspects:\ndetecting fast-changing topics for more effective data collection and\nrepresenting word semantics in different domains. We demonstrate with\npreliminary results that using the GloVe (Global Vectors for Word\nRepresentation) model facilitates the discovery of new and relevant keywords to\nuse for data collection and trolling detection. Our paper concludes with a\ndiscussion of a research agenda to further develop and test word embedding\nmodels for identification of social media harassment and trolling.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 07:20:24 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:05:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Anqi", ""], ["Srikanth", "Maya", ""], ["Adams-Cohen", "Nicholas", ""], ["Alvarez", "R. Michael", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1911.05346", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "Anastasiia Kabeshova, Yiyang Yu, Bertrand Lukacs, Emmanuel Bacry,\n  St\\'ephane Ga\\\"iffas", "title": "ZiMM: a deep learning model for long term and blurry relapses with\n  non-clinical claims data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problems of modeling and predicting a long-term and\n``blurry'' relapse that occurs after a medical act, such as a surgery. The\nrelapse is observed only indirectly, in a ``blurry'' fashion, through\nlongitudinal prescriptions of drugs over a long period of time after the\nmedical act. We introduce a new model, called ZiMM (Zero-inflated Mixture of\nMultinomial distributions) in order to capture long-term and blurry relapses.\nOn top of it, we build an end-to-end deep-learning architecture called ZiMM\nEncoder-Decoder (ZiMM ED) that can learn from the complex, irregular, highly\nheterogeneous and sparse patterns of health events that are observed through a\nclaims-only database. ZiMM ED is applied on a ``non-clinical'' claims database,\nthat contains only timestamped reimbursement codes for drug purchases, medical\nprocedures and hospital diagnoses, the only available clinical feature being\nthe age of the patient. This setting is more challenging than a setting where\nbedside clinical signals are available. Our motivation for using such a\nnon-clinical claims database is its exhaustivity population-wise, compared to\nclinical electronic health records coming from a single or a small set of\nhospitals. Indeed, we consider a dataset containing the claims of almost\n\\emph{all French citizens} who had surgery for prostatic problems, with a\nhistory between 1.5 and 5 years. We consider a long-term (18 months) relapse\n(urination problems still occur despite surgery), which is blurry since it is\nobserved only through the reimbursement of a specific set of drugs for\nurination problems. Our experiments show that ZiMM ED improves several\nbaselines, including non-deep learning and deep-learning approaches, and that\nit allows working on such a dataset with minimal preprocessing work.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:23:20 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 22:12:47 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 19:42:46 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kabeshova", "Anastasiia", ""], ["Yu", "Yiyang", ""], ["Lukacs", "Bertrand", ""], ["Bacry", "Emmanuel", ""], ["Ga\u00efffas", "St\u00e9phane", ""]]}, {"id": "1911.05350", "submitter": "Shingo Yashima", "authors": "Shingo Yashima, Atsushi Nitanda, Taiji Suzuki", "title": "Exponential Convergence Rates of Classification Errors on Learning with\n  SGD and Random Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although kernel methods are widely used in many learning problems, they have\npoor scalability to large datasets. To address this problem, sketching and\nstochastic gradient methods are the most commonly used techniques to derive\nefficient large-scale learning algorithms. In this study, we consider solving a\nbinary classification problem using random features and stochastic gradient\ndescent. In recent research, an exponential convergence rate of the expected\nclassification error under the strong low-noise condition has been shown. We\nextend these analyses to a random features setting, analyzing the error induced\nby the approximation of random features in terms of the distance between the\ngenerated hypothesis including population risk minimizers and empirical risk\nminimizers when using general Lipschitz loss functions, to show that an\nexponential convergence of the expected classification error is achieved even\nif random features approximation is applied. Additionally, we demonstrate that\nthe convergence rate does not depend on the number of features and there is a\nsignificant computational benefit in using random features in classification\nproblems because of the strong low-noise condition.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:46:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yashima", "Shingo", ""], ["Nitanda", "Atsushi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1911.05369", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fair Adversarial Gradient Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has become an important topic in machine learning\nresearch. While most bias mitigation strategies focus on neural networks, we\nnoticed a lack of work on fair classifiers based on decision trees even though\nthey have proven very efficient. In an up-to-date comparison of\nstate-of-the-art classification algorithms in tabular data, tree boosting\noutperforms deep learning. For this reason, we have developed a novel approach\nof adversarial gradient tree boosting. The objective of the algorithm is to\npredict the output $Y$ with gradient tree boosting while minimizing the ability\nof an adversarial neural network to predict the sensitive attribute $S$. The\napproach incorporates at each iteration the gradient of the neural network\ndirectly in the gradient tree boosting. We empirically assess our approach on 4\npopular data sets and compare against state-of-the-art algorithms. The results\nshow that our algorithm achieves a higher accuracy while obtaining the same\nlevel of fairness, as measured using a set of different common fairness\ndefinitions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:43:55 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:28:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.05384", "submitter": "Cl\\'ement Vignac", "authors": "Cl\\'ement Vignac, Guillermo Ortiz-Jim\\'enez, Pascal Frossard", "title": "On the choice of graph neural network architectures", "comments": "5 pages, 1 figure, accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seminal works on graph neural networks have primarily targeted\nsemi-supervised node classification problems with few observed labels and\nhigh-dimensional signals. With the development of graph networks, this setup\nhas become a de facto benchmark for a significant body of research.\nInterestingly, several works have recently shown that in this particular\nsetting, graph neural networks do not perform much better than predefined\nlow-pass filters followed by a linear classifier. However, when learning from\nlittle data in a high-dimensional space, it is not surprising that simple and\nheavily regularized methods are near-optimal. In this paper, we show\nempirically that in settings with fewer features and more training data, more\ncomplex graph networks significantly outperform simple models, and propose a\nfew insights towards the proper choice of graph network architectures. We\nfinally outline the importance of using sufficiently diverse benchmarks\n(including lower dimensional signals as well) when designing and studying new\ntypes of graph neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 10:25:08 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 17:35:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Vignac", "Cl\u00e9ment", ""], ["Ortiz-Jim\u00e9nez", "Guillermo", ""], ["Frossard", "Pascal", ""]]}, {"id": "1911.05419", "submitter": "Hubert Banville", "authors": "Hubert Banville, Isabela Albuquerque, Aapo Hyv\\\"arinen, Graeme Moffat,\n  Denis-Alexander Engemann and Alexandre Gramfort", "title": "Self-supervised representation learning from electroencephalography\n  signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The supervised learning paradigm is limited by the cost - and sometimes the\nimpracticality - of data collection and labeling in multiple domains.\nSelf-supervised learning, a paradigm which exploits the structure of unlabeled\ndata to create learning problems that can be solved with standard supervised\napproaches, has shown great promise as a pretraining or feature learning\napproach in fields like computer vision and time series processing. In this\nwork, we present self-supervision strategies that can be used to learn\ninformative representations from multivariate time series. One successful\napproach relies on predicting whether time windows are sampled from the same\ntemporal context or not. As demonstrated on a clinically relevant task (sleep\nscoring) and with two electroencephalography datasets, our approach outperforms\na purely supervised approach in low data regimes, while capturing important\nphysiological information without any access to labels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 12:17:31 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Banville", "Hubert", ""], ["Albuquerque", "Isabela", ""], ["Hyv\u00e4rinen", "Aapo", ""], ["Moffat", "Graeme", ""], ["Engemann", "Denis-Alexander", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1911.05438", "submitter": "Etienne Bennequin", "authors": "Mohamed Salah Za\\\"iem and Etienne Bennequin", "title": "Learning to Communicate in Multi-Agent Reinforcement Learning : A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the issue of multiple agents learning to communicate through\nreinforcement learning within partially observable environments, with a focus\non information asymmetry in the second part of our work. We provide a review of\nthe recent algorithms developed to improve the agents' policy by allowing the\nsharing of information between agents and the learning of communication\nstrategies, with a focus on Deep Recurrent Q-Network-based models. We also\ndescribe recent efforts to interpret the languages generated by these agents\nand study their properties in an attempt to generate human-language-like\nsentences. We discuss the metrics used to evaluate the generated communication\nstrategies and propose a novel entropy-based evaluation metric. Finally, we\naddress the issue of the cost of communication and introduce the idea of an\nexperimental setup to expose this cost in cooperative-competitive game.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:08:46 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Za\u00efem", "Mohamed Salah", ""], ["Bennequin", "Etienne", ""]]}, {"id": "1911.05441", "submitter": "Xinyu Fan", "authors": "Faen Zhang, Xinyu Fan, Hui Xu, Pengcheng Zhou, Yujian He, Junlong Liu", "title": "Regression via Arbitrary Quantile Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the regression problem, L1 and L2 are the most commonly used loss\nfunctions, which produce mean predictions with different biases. However, the\npredictions are neither robust nor adequate enough since they only capture a\nfew conditional distributions instead of the whole distribution, especially for\nsmall datasets. To address this problem, we proposed arbitrary quantile\nmodeling to regulate the prediction, which achieved better performance compared\nto traditional loss functions. More specifically, a new distribution regression\nmethod, Deep Distribution Regression (DDR), is proposed to estimate arbitrary\nquantiles of the response variable. Our DDR method consists of two models: a Q\nmodel, which predicts the corresponding value for arbitrary quantile, and an F\nmodel, which predicts the corresponding quantile for arbitrary value.\nFurthermore, the duality between Q and F models enables us to design a novel\nloss function for joint training and perform a dual inference mechanism. Our\nexperiments demonstrate that our DDR-joint and DDR-disjoint methods outperform\nprevious methods such as AdaBoost, random forest, LightGBM, and neural networks\nboth in terms of mean and quantile prediction.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:11:30 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zhang", "Faen", ""], ["Fan", "Xinyu", ""], ["Xu", "Hui", ""], ["Zhou", "Pengcheng", ""], ["He", "Yujian", ""], ["Liu", "Junlong", ""]]}, {"id": "1911.05443", "submitter": "Xinyu Fan", "authors": "Xinyu Fan", "title": "Dynamic Connected Neural Decision Classifier and Regressor with Dynamic\n  Softing Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with various datasets over different complexity, this paper presents\nan self-adaptive learning model that combines the proposed Dynamic Connected\nNeural Decision Networks (DNDN) and a new pruning method--Dynamic Soft Pruning\n(DSP). DNDN is a combination of random forests and deep neural networks that\nenjoys both the advantages of strong classification capability of tree-like\nstructure and representation learning capability of network structure. Based on\nDeep Neural Decision Forests (DNDF), this paper adopts an end-to-end training\napproach by representing the classification distribution with multiple randomly\ninitialized softmax layers, which further allows an ensemble of multiple random\nforests attached to layers of neural network with different depth. We also\npropose a soft pruning method DSP to reduce the redundant connections of the\nnetwork adaptively to avoid over-fitting simple dataset. The model demonstrates\nno performance loss compared with unpruned models and even higher robustness\nover different data and feature distribution. Extensive experiments on\ndifferent datasets demonstrate the superiority of the proposed model over other\npopular algorithms in solving classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:21:10 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:12:09 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 07:35:07 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fan", "Xinyu", ""]]}, {"id": "1911.05461", "submitter": "Rodrigo Fernandes De Mello", "authors": "Rodrigo Fernandes de Mello", "title": "On the Complexity of Labeled Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Statistical Learning Theory (SLT) provides the foundation to ensure that\na supervised algorithm generalizes the mapping $f: \\mathcal{X} \\to \\mathcal{Y}$\ngiven $f$ is selected from its search space bias $\\mathcal{F}$. SLT depends on\nthe Shattering coefficient function $\\mathcal{N}(\\mathcal{F},n)$ to upper bound\nthe empirical risk minimization principle, from which one can estimate the\nnecessary training sample size to ensure the probabilistic learning convergence\nand, most importantly, the characterization of the capacity of $\\mathcal{F}$,\nincluding its underfitting and overfitting abilities while addressing specific\ntarget problems. However, the analytical solution of the Shattering coefficient\nis still an open problem since the first studies by Vapnik and Chervonenkis in\n$1962$, which we address on specific datasets, in this paper, by employing\nequivalence relations from Topology, data separability results by Har-Peled and\nJones, and combinatorics. Our approach computes the Shattering coefficient for\nboth binary and multi-class datasets, leading to the following additional\ncontributions: (i) the estimation of the required number of hyperplanes in the\nworst and best-case classification scenarios and the respective $\\Omega$ and\n$O$ complexities; (ii) the estimation of the training sample sizes required to\nensure supervised learning; and (iii) the comparison of dataset embeddings,\nonce they (re)organize samples into some new space configuration. All results\nintroduced and discussed along this paper are supported by the R package\nshattering (https://cran.r-project.org/web/packages/shattering).\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:50:46 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 16:45:38 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 13:07:33 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["de Mello", "Rodrigo Fernandes", ""]]}, {"id": "1911.05464", "submitter": "Riccardo di Clemente", "authors": "Sharon Xu, Riccardo Di Clemente, Marta C. Gonz\\'alez", "title": "Mining urban lifestyles: urban computing, human behavior and recommender\n  systems", "comments": "8 pages, 4 figures", "journal-ref": "Big Data Recommender Systems - Volume 2: Application Paradigms,\n  Chapter 5 Mining urban lifestyles: urban computing, human behavior and\n  recommender systems, pp. 71-81, (Institution of Engineering and Technology\n  2019)", "doi": "10.1049/PBPC035G_ch5", "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the digital age has sharply redefined the way we study\nhuman behavior. With the advancement of data storage and sensing technologies,\nelectronic records now encompass a diverse spectrum of human activity, ranging\nfrom location data, phone and email communication to Twitter activity and\nopen-source contributions on Wikipedia and OpenStreetMap. In particular, the\nstudy of the shopping and mobility patterns of individual consumers has the\npotential to give deeper insight into the lifestyles and infrastructure of the\nregion. Credit card records (CCRs) provide detailed insight into purchase\nbehavior and have been found to have inherent regularity in consumer shopping\npatterns; call detail records (CDRs) present new opportunities to understand\nhuman mobility, analyze wealth, and model social network dynamics. In this\nchapter, we jointly model the lifestyles of individuals, a more challenging\nproblem with higher variability when compared to the aggregated behavior of\ncity regions. Using collective matrix factorization, we propose a unified dual\nview of lifestyles. Understanding these lifestyles will not only inform\ncommercial opportunities, but also help policymakers and nonprofit\norganizations understand the characteristics and needs of the entire region, as\nwell as of the individuals within that region. The applications of this range\nfrom targeted advertisements and promotions to the diffusion of digital\nfinancial services among low-income groups.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:19:39 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xu", "Sharon", ""], ["Di Clemente", "Riccardo", ""], ["Gonz\u00e1lez", "Marta C.", ""]]}, {"id": "1911.05466", "submitter": "Fei Yu", "authors": "Fei Yu, Feiyi Fan, Shouxu Jiang, Kaiping Zheng", "title": "Attentive Geo-Social Group Recommendation", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social activities play an important role in people's daily life since they\ninteract. For recommendations based on social activities, it is vital to have\nnot only the activity information but also individuals' social relations.\nThanks to the geo-social networks and widespread use of location-aware mobile\ndevices, massive geo-social data is now readily available for exploitation by\nthe recommendation system. In this paper, a novel group recommendation method,\ncalled attentive geo-social group recommendation, is proposed to recommend the\ntarget user with both activity locations and a group of users that may join the\nactivities. We present an attention mechanism to model the influence of the\ntarget user $u_T$ in candidate user groups that satisfy the social constraints.\nIt helps to retrieve the optimal user group and activity topic candidates, as\nwell as explains the group decision-making process. Once the user group and\ntopics are retrieved, a novel efficient spatial query algorithm SPA-DF is\nemployed to determine the activity location under the constraints of the given\nuser group and activity topic candidates. The proposed method is evaluated in\nreal-world datasets and the experimental results show that the proposed model\nsignificantly outperforms baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 11:13:27 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 03:31:32 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Yu", "Fei", ""], ["Fan", "Feiyi", ""], ["Jiang", "Shouxu", ""], ["Zheng", "Kaiping", ""]]}, {"id": "1911.05469", "submitter": "Anuththari Gamage", "authors": "Anuththari Gamage, Eli Chien, Jianhao Peng, Olgica Milenkovic", "title": "Multi-MotifGAN (MMGAN): Motif-targeted Graph Generation and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative graph models create instances of graphs that mimic the properties\nof real-world networks. Generative models are successful at retaining pairwise\nassociations in the underlying networks but often fail to capture higher-order\nconnectivity patterns known as network motifs. Different types of graphs\ncontain different network motifs, an example of which are triangles that often\narise in social and biological networks. It is hence vital to capture these\nhigher-order structures to simulate real-world networks accurately. We propose\nMulti-MotifGAN (MMGAN), a motif-targeted Generative Adversarial Network (GAN)\nthat generalizes the benchmark NetGAN approach. The generalization consists of\ncombining multiple biased random walks, each of which captures a different\nmotif structure. MMGAN outperforms NetGAN at creating new graphs that\naccurately reflect the network motif statistics of input graphs such as\nCiteseer, Cora and Facebook.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:28:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gamage", "Anuththari", ""], ["Chien", "Eli", ""], ["Peng", "Jianhao", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1911.05473", "submitter": "Francesco Farina", "authors": "Francesco Farina, Stefano Melacci, Andrea Garulli, Antonio\n  Giannitrapani", "title": "Asynchronous Distributed Learning from Constraints", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2947740", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the extension of the framework of Learning from Constraints\n(LfC) to a distributed setting where multiple parties, connected over the\nnetwork, contribute to the learning process is studied. LfC relies on the\ngeneric notion of \"constraint\" to inject knowledge into the learning problem\nand, due to its generality, it deals with possibly nonconvex constraints,\nenforced either in a hard or soft way. Motivated by recent progresses in the\nfield of distributed and constrained nonconvex optimization, we apply the\n(distributed) Asynchronous Method of Multipliers (ASYMM) to LfC. The study\nshows that such a method allows us to support scenarios where selected\nconstraints (i.e., knowledge), data, and outcomes of the learning process can\nbe locally stored in each computational node without being shared with the rest\nof the network, opening the road to further investigations into\nprivacy-preserving LfC. Constraints act as a bridge between what is shared over\nthe net and what is private to each node and no central authority is required.\nWe demonstrate the applicability of these ideas in two distributed real-world\nsettings in the context of digit recognition and document classification.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:08:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Farina", "Francesco", ""], ["Melacci", "Stefano", ""], ["Garulli", "Andrea", ""], ["Giannitrapani", "Antonio", ""]]}, {"id": "1911.05485", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Stefan Wei{\\ss}enberger, Stephan G\\\"unnemann", "title": "Diffusion Improves Graph Learning", "comments": "Published as a conference paper at NeurIPS 2019", "journal-ref": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS), Vancouver, Canada, 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution is the core of most Graph Neural Networks (GNNs) and\nusually approximated by message passing between direct (one-hop) neighbors. In\nthis work, we remove the restriction of using only the direct neighbors by\nintroducing a powerful, yet spatially localized graph convolution: Graph\ndiffusion convolution (GDC). GDC leverages generalized graph diffusion,\nexamples of which are the heat kernel and personalized PageRank. It alleviates\nthe problem of noisy and often arbitrarily defined edges in real graphs. We\nshow that GDC is closely related to spectral-based models and thus combines the\nstrengths of both spatial (message passing) and spectral methods. We\ndemonstrate that replacing message passing with graph diffusion convolution\nconsistently leads to significant performance improvements across a wide range\nof models on both supervised and unsupervised tasks and a variety of datasets.\nFurthermore, GDC is not limited to GNNs but can trivially be combined with any\ngraph-based model or algorithm (e.g. spectral clustering) without requiring any\nchanges to the latter or affecting its computational complexity. Our\nimplementation is available online.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:51:46 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 08:41:14 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 14:42:37 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 21:13:40 GMT"}, {"version": "v5", "created": "Sun, 29 Dec 2019 22:33:56 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Klicpera", "Johannes", ""], ["Wei\u00dfenberger", "Stefan", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1911.05489", "submitter": "James Atwood", "authors": "James Atwood, Hansa Srinivasan, Yoni Halpern, D Sculley", "title": "Fair treatment allocations in social networks", "comments": "To appear in the Fair ML for Health workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulations of infectious disease spread have long been used to understand\nhow epidemics evolve and how to effectively treat them. However, comparatively\nlittle attention has been paid to understanding the fairness implications of\ndifferent treatment strategies -- that is, how might such strategies distribute\nthe expected disease burden differentially across various subgroups or\ncommunities in the population? In this work, we define the precision disease\ncontrol problem -- the problem of optimally allocating vaccines in a social\nnetwork in a step-by-step fashion -- and we use the ML Fairness Gym to simulate\nepidemic control and study it from both an efficiency and fairness perspective.\nWe then present an exploratory analysis of several different environments and\ndiscuss the fairness implications of different treatment strategies.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 15:31:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Atwood", "James", ""], ["Srinivasan", "Hansa", ""], ["Halpern", "Yoni", ""], ["Sculley", "D", ""]]}, {"id": "1911.05493", "submitter": "Sirui Song", "authors": "Sirui Song, Tong Xia, Depeng Jin, Pan Hui, Yong Li", "title": "UrbanRhythm: Revealing Urban Dynamics Hidden in Mobility Data", "comments": "Submitted to IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding urban dynamics, i.e., how the types and intensity of urban\nresidents' activities in the city change along with time, is of urgent demand\nfor building an efficient and livable city. Nonetheless, this is challenging\ndue to the expanding urban population and the complicated spatial distribution\nof residents. In this paper, to reveal urban dynamics, we propose a novel\nsystem UrbanRhythm to reveal the urban dynamics hidden in human mobility data.\nUrbanRhythm addresses three questions: 1) What mobility feature should be used\nto present residents' high-dimensional activities in the city? 2) What are\nbasic components of urban dynamics? 3) What are the long-term periodicity and\nshort-term regularity of urban dynamics? In UrbanRhythm, we extract staying,\nleaving, arriving three attributes of mobility and use a image processing\nmethod Saak transform to calculate the mobility distribution feature. For the\nsecond question, several city states are identified by hierarchy clustering as\nthe basic components of urban dynamics, such as sleeping states and working\nstates. We further characterize the urban dynamics as the transform of city\nstates along time axis. For the third question, we directly observe the\nlong-term periodicity of urban dynamics from visualization. Then for the\nshort-term regularity, we design a novel motif analysis method to discovery\nmotifs as well as their hierarchy relationships. We evaluate our proposed\nsystem on two real-life datesets and validate the results according to App\nusage records. This study sheds light on urban dynamics hidden in human\nmobility and can further pave the way for more complicated mobility behavior\nmodeling and deeper urban understanding.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:45:20 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Song", "Sirui", ""], ["Xia", "Tong", ""], ["Jin", "Depeng", ""], ["Hui", "Pan", ""], ["Li", "Yong", ""]]}, {"id": "1911.05494", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Aibek Musaev, Calton Pu", "title": "Concept Drift Adaptive Physical Event Detection for Social Media Streams", "comments": null, "journal-ref": "Services Congress 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection has long been the domain of physical sensors operating in a\nstatic dataset assumption. The prevalence of social media and web access has\nled to the emergence of social, or human sensors who report on events globally.\nThis warrants development of event detectors that can take advantage of the\ntruly dense and high spatial and temporal resolution data provided by more than\n3 billion social users. The phenomenon of concept drift, which causes terms and\nsignals associated with a topic to change over time, renders static machine\nlearning ineffective. Towards this end, we present an application for physical\nevent detection on social sensors that improves traditional physical event\ndetection with concept drift adaptation. Our approach continuously updates its\nmachine learning classifiers automatically, without the need for human\nintervention. It integrates data from heterogeneous sources and is designed to\nhandle weak-signal events (landslides, wildfires) with around ten posts per\nevent in addition to large-signal events (hurricanes, earthquakes) with\nhundreds of thousands of posts per event. We demonstrate a landslide detector\non our application that detects almost 350% more land-slides compared to static\napproaches. Our application has high performance: using classifiers trained in\n2014, achieving event detection accuracy of 0.988, compared to 0.762 for static\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:15:23 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Suprem", "Abhijit", ""], ["Musaev", "Aibek", ""], ["Pu", "Calton", ""]]}, {"id": "1911.05495", "submitter": "Prakamya Mishra", "authors": "Prakamya Mishra", "title": "Correlated Feature Selection for Tweet Spam Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of spam messages on social networks is a very challenging\ntask. Social media sites like Twitter \\& Facebook attracts a lot of users and\ncompanies to advertise and attract users of personal gains. These\nadvertisements most of the time leads to spamming, which in return leads to\npoor user experience. The purpose of this paper is to undertake the analysis of\nspamming on Twitter. To classify spams efficiently, it is necessary to first\nunderstand the features of the spam tweets as well as identify attributes of\nthe spammer. We extract both tweet based features and user-based features for\nour analysis and observe the correlation between these features. This step is\nnecessary as we can reduce the training time if we combine the highly\ncorrelated features. Our proposed approach uses a classification model based on\nartificial neural networks to classify the tweets as spam or non-spam giving\nthe highest accuracy of 97.57\\% when compared with four other standard\nclassifiers namely, SVM, K Nearest Neighbours, Naive Bayes, and Random Forest.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 15:16:35 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 22:22:01 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 22:44:27 GMT"}, {"version": "v4", "created": "Sun, 25 Oct 2020 20:23:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mishra", "Prakamya", ""]]}, {"id": "1911.05496", "submitter": "Lutz Oettershagen", "authors": "Lutz Oettershagen, Nils M. Kriege, Christopher Morris, Petra Mutzel", "title": "Temporal Graph Kernels for Classifying Dissemination Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world graphs or networks are temporal, e.g., in a social network\npersons only interact at specific points in time. This information directs\ndissemination processes on the network, such as the spread of rumors, fake\nnews, or diseases. However, the current state-of-the-art methods for supervised\ngraph classification are designed mainly for static graphs and may not be able\nto capture temporal information. Hence, they are not powerful enough to\ndistinguish between graphs modeling different dissemination processes. To\naddress this, we introduce a framework to lift standard graph kernels to the\ntemporal domain. Specifically, we explore three different approaches and\ninvestigate the trade-offs between loss of temporal information and efficiency.\nMoreover, to handle large-scale graphs, we propose stochastic variants of our\nkernels with provable approximation guarantees. We evaluate our methods on a\nwide range of real-world social networks. Our methods beat static kernels by a\nlarge margin in terms of accuracy while still being scalable to large graphs\nand data sets. Hence, we confirm that taking temporal information into account\nis crucial for the successful classification of dissemination processes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:19:58 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Oettershagen", "Lutz", ""], ["Kriege", "Nils M.", ""], ["Morris", "Christopher", ""], ["Mutzel", "Petra", ""]]}, {"id": "1911.05497", "submitter": "Hongtao Liu", "authors": "Hongtao Liu", "title": "Going Negative Online? -- A Study of Negative Advertising on Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of empirical studies suggest that negative advertising is\neffective in campaigning, while the mechanisms are rarely mentioned. With the\nscandal of Cambridge Analytica and Russian intervention behind the Brexit and\nthe 2016 presidential election, people have become aware of the political ads\non social media and have pressured congress to restrict political advertising\non social media. Following the related legislation, social media companies\nbegan disclosing their political ads archive for transparency during the summer\nof 2018 when the midterm election campaign was just beginning. This research\ncollects the data of the related political ads in the context of the U.S.\nmidterm elections since August to study the overall pattern of political ads on\nsocial media and uses sets of machine learning methods to conduct sentiment\nanalysis on these ads to classify the negative ads. A novel approach is applied\nthat uses AI image recognition to study the image data. Through data\nvisualization, this research shows that negative advertising is still the\nminority, Republican advertisers and third party organizations are more likely\nto engage in negative advertising than their counterparts. Based on ordinal\nregressions, this study finds that anger evoked information-seeking is one of\nthe main mechanisms causing negative ads to be more engaging and effective\nrather than the negative bias theory. Overall, this study provides a unique\nunderstanding of political advertising on social media by applying innovative\ndata science methods. Further studies can extend the findings, methods, and\ndatasets in this study, and several suggestions are given for future research.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:43:23 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Liu", "Hongtao", ""]]}, {"id": "1911.05503", "submitter": "Bertrand Charpentier", "authors": "Marin Bilo\\v{s}, Bertrand Charpentier, Stephan G\\\"unnemann", "title": "Uncertainty on Asynchronous Time Event Prediction", "comments": "Neurips 2019 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous event sequences are the basis of many applications throughout\ndifferent industries. In this work, we tackle the task of predicting the next\nevent (given a history), and how this prediction changes with the passage of\ntime. Since at some time points (e.g. predictions far into the future) we might\nnot be able to predict anything with confidence, capturing uncertainty in the\npredictions is crucial. We present two new architectures, WGP-LN and FD-Dir,\nmodelling the evolution of the distribution on the probability simplex with\ntime-dependent logistic normal and Dirichlet distributions. In both cases, the\ncombination of RNNs with either Gaussian process or function decomposition\nallows to express rich temporal evolution of the distribution parameters, and\nnaturally captures uncertainty. Experiments on class prediction, time\nprediction and anomaly detection demonstrate the high performances of our\nmodels on various datasets compared to other approaches.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:26:30 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 12:20:50 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Bilo\u0161", "Marin", ""], ["Charpentier", "Bertrand", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1911.05507", "submitter": "Jack Rae", "authors": "Jack W. Rae and Anna Potapenko and Siddhant M. Jayakumar and Timothy\n  P. Lillicrap", "title": "Compressive Transformers for Long-Range Sequence Modelling", "comments": "19 pages, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Compressive Transformer, an attentive sequence model which\ncompresses past memories for long-range sequence learning. We find the\nCompressive Transformer obtains state-of-the-art language modelling results in\nthe WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc\nrespectively. We also find it can model high-frequency speech effectively and\ncan be used as a memory mechanism for RL, demonstrated on an object matching\ntask. To promote the domain of long-range sequence learning, we propose a new\nopen-vocabulary language modelling benchmark derived from books, PG-19.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:36:01 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Rae", "Jack W.", ""], ["Potapenko", "Anna", ""], ["Jayakumar", "Siddhant M.", ""], ["Lillicrap", "Timothy P.", ""]]}, {"id": "1911.05522", "submitter": "Tyler McCormick", "authors": "Wesley Lee and Tyler H. McCormick and Joshua Neil and Cole Sodja and\n  Yanran Cui", "title": "Anomaly Detection in Large Scale Networks with Latent Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CR cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a real-time anomaly detection algorithm for directed activity on\nlarge, sparse networks. We model the propensity for future activity using a\ndynamic logistic model with interaction terms for sender- and receiver-specific\nlatent factors in addition to sender- and receiver-specific popularity scores;\ndeviations from this underlying model constitute potential anomalies. Latent\nnodal attributes are estimated via a variational Bayesian approach and may\nchange over time, representing natural shifts in network activity. Estimation\nis augmented with a case-control approximation to take advantage of the\nsparsity of the network and reduces computational complexity from $O(N^2)$ to\n$O(E)$, where $N$ is the number of nodes and $E$ is the number of observed\nedges. We run our algorithm on network event records collected from an\nenterprise network of over 25,000 computers and are able to identify a red team\nattack with half the detection rate required of the model without latent\ninteraction terms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:57:20 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:20:46 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Lee", "Wesley", ""], ["McCormick", "Tyler H.", ""], ["Neil", "Joshua", ""], ["Sodja", "Cole", ""], ["Cui", "Yanran", ""]]}, {"id": "1911.05531", "submitter": "Iddo Drori", "authors": "Iddo Drori, Darshan Thaker, Arjun Srivatsa, Daniel Jeong, Yueqi Wang,\n  Linyong Nan, Fan Wu, Dimitri Leggas, Jinhao Lei, Weiyi Lu, Weilong Fu, Yuan\n  Gao, Sashank Karri, Anand Kannan, Antonio Moretti, Mohammed AlQuraishi, Chen\n  Keasar, Itsik Pe'er", "title": "Accurate Protein Structure Prediction by Embeddings and Deep Learning\n  Representations", "comments": null, "journal-ref": "Machine Learning in Computational Biology, 2019", "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proteins are the major building blocks of life, and actuators of almost all\nchemical and biophysical events in living organisms. Their native structures in\nturn enable their biological functions which have a fundamental role in drug\ndesign. This motivates predicting the structure of a protein from its sequence\nof amino acids, a fundamental problem in computational biology. In this work,\nwe demonstrate state-of-the-art protein structure prediction (PSP) results\nusing embeddings and deep learning models for prediction of backbone atom\ndistance matrices and torsion angles. We recover 3D coordinates of backbone\natoms and reconstruct full atom protein by optimization. We create a new gold\nstandard dataset of proteins which is comprehensive and easy to use. Our\ndataset consists of amino acid sequences, Q8 secondary structures, position\nspecific scoring matrices, multiple sequence alignment co-evolutionary\nfeatures, backbone atom distance matrices, torsion angles, and 3D coordinates.\nWe evaluate the quality of our structure prediction by RMSD on the latest\nCritical Assessment of Techniques for Protein Structure Prediction (CASP) test\ndata and demonstrate competitive results with the winning teams and AlphaFold\nin CASP13 and supersede the results of the winning teams in CASP12. We make our\ndata, models, and code publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 00:21:17 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Drori", "Iddo", ""], ["Thaker", "Darshan", ""], ["Srivatsa", "Arjun", ""], ["Jeong", "Daniel", ""], ["Wang", "Yueqi", ""], ["Nan", "Linyong", ""], ["Wu", "Fan", ""], ["Leggas", "Dimitri", ""], ["Lei", "Jinhao", ""], ["Lu", "Weiyi", ""], ["Fu", "Weilong", ""], ["Gao", "Yuan", ""], ["Karri", "Sashank", ""], ["Kannan", "Anand", ""], ["Moretti", "Antonio", ""], ["AlQuraishi", "Mohammed", ""], ["Keasar", "Chen", ""], ["Pe'er", "Itsik", ""]]}, {"id": "1911.05544", "submitter": "Zhongkai Sun", "authors": "Zhongkai Sun, Prathusha Sarma, William Sethares, Yingyu Liang", "title": "Learning Relationships between Text, Audio, and Video via Deep Canonical\n  Correlation for Multimodal Language Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Multimodal language analysis often considers relationships between features\nbased on text and those based on acoustical and visual properties. Text\nfeatures typically outperform non-text features in sentiment analysis or\nemotion recognition tasks in part because the text features are derived from\nadvanced language models or word embeddings trained on massive data sources\nwhile audio and video features are human-engineered and comparatively\nunderdeveloped. Given that the text, audio, and video are describing the same\nutterance in different ways, we hypothesize that the multimodal sentiment\nanalysis and emotion recognition can be improved by learning (hidden)\ncorrelations between features extracted from the outer product of text and\naudio (we call this text-based audio) and analogous text-based video. This\npaper proposes a novel model, the Interaction Canonical Correlation Network\n(ICCN), to learn such multimodal embeddings. ICCN learns correlations between\nall three modes via deep canonical correlation analysis (DCCA) and the proposed\nembeddings are then tested on several benchmark datasets and against other\nstate-of-the-art multimodal embedding algorithms. Empirical results and\nablation studies confirm the effectiveness of ICCN in capturing useful\ninformation from all three views.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:27:37 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 23:48:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sun", "Zhongkai", ""], ["Sarma", "Prathusha", ""], ["Sethares", "William", ""], ["Liang", "Yingyu", ""]]}, {"id": "1911.05546", "submitter": "Daniela Mihai", "authors": "Daniela Mihai and Jonathon Hare", "title": "Avoiding hashing and encouraging visual semantics in referential\n  emergent language games", "comments": "4 pages, presented at Emergent Communication: Towards Natural\n  Language workshop (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been an increasing interest in the area of emergent communication\nbetween agents which learn to play referential signalling games with realistic\nimages. In this work, we consider the signalling game setting of Havrylov and\nTitov and investigate the effect of the feature extractor's weights and of the\ntask being solved on the visual semantics learned or captured by the models. We\nimpose various augmentation to the input images and additional tasks in the\ngame with the aim to induce visual representations which capture conceptual\nproperties of images. Through our set of experiments, we demonstrate that\ncommunication systems which capture visual semantics can be learned in a\ncompletely self-supervised manner by playing the right types of game.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:31:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Mihai", "Daniela", ""], ["Hare", "Jonathon", ""]]}, {"id": "1911.05584", "submitter": "Feng Huang", "authors": "Feng Huang, Xiang Yue, Zhankun Xiong, Zhouxin Yu and Wen Zhang", "title": "Tensor Decomposition with Relational Constraints for Predicting Multiple\n  Types of MicroRNA-disease Associations", "comments": null, "journal-ref": null, "doi": "10.1093/bib/bbaa140", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MicroRNAs (miRNAs) play crucial roles in multifarious biological processes\nassociated with human diseases. Identifying potential miRNA-disease\nassociations contributes to understanding the molecular mechanisms of\nmiRNA-related diseases. Most of the existing computational methods mainly focus\non predicting whether a miRNA-disease association exists or not. However, the\nroles of miRNAs in diseases are prominently diverged, for instance, Genetic\nvariants of microRNA (mir-15) may affect expression level of miRNAs leading to\nB cell chronic lymphocytic leukemia, while circulating miRNAs (including\nmir-1246, mir-1307-3p, etc.) have potentials to detecting breast cancer in the\nearly stage. In this paper, we aim to predict multi-type miRNA-disease\nassociations instead of taking them as binary. To this end, we innovatively\nrepresent miRNA-disease-type triplets as a tensor and introduce Tensor\nDecomposition methods to solve the prediction task. Experimental results on two\nwidely-adopted miRNA-disease datasets: HMDD v2.0 and HMDD v3.2 show that tensor\ndecomposition methods improve a recent baseline in a large scale (up to 38% in\ntop-1 F1). We further propose a novel method, Tensor Decomposition with\nRelational Constraints (TDRC), which incorporates biological features as\nrelational constraints to further the existing tensor decomposition methods.\nCompared with two existing tensor decomposition methods, TDRC can produce\nbetter performance while being more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:25:24 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 11:43:02 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Huang", "Feng", ""], ["Yue", "Xiang", ""], ["Xiong", "Zhankun", ""], ["Yu", "Zhouxin", ""], ["Zhang", "Wen", ""]]}, {"id": "1911.05585", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Nadezhda Chirkova, Alexander Markovich, Dmitry\n  Vetrov", "title": "Structured Sparsification of Gated Recurrent Neural Networks", "comments": "Published in Workshop on Context and Compositionality in Biological\n  and Artificial Neural Systems, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a lot of techniques were developed to sparsify the weights of\nneural networks and to remove networks' structure units, e.g. neurons. We\nadjust the existing sparsification approaches to the gated recurrent\narchitectures. Specifically, in addition to the sparsification of weights and\nneurons, we propose sparsifying the preactivations of gates. This makes some\ngates constant and simplifies LSTM structure. We test our approach on the text\nclassification and language modeling tasks. We observe that the resulting\nstructure of gate sparsity depends on the task and connect the learned\nstructure to the specifics of the particular tasks. Our method also improves\nneuron-wise compression of the model in most of the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:26:22 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Chirkova", "Nadezhda", ""], ["Markovich", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1911.05588", "submitter": "Quanshi Zhang", "authors": "A. Deliege, A. Cioppa and M. Van Droogenbroeck", "title": "An Effective Hit-or-Miss Layer Favoring Feature Interpretation as\n  Learned Prototypes Deformations", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  Published version of arXiv:1806.06519", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks designed for the task of classification have become a\ncommodity in recent years. Many works target the development of more effective\nnetworks, which results in a complexification of their architectures with more\nlayers, multiple sub-networks, or even the combination of multiple classifiers,\nbut this often comes at the expense of producing uninterpretable black boxes.\nIn this paper, we redesign a simple capsule network to enable it to synthesize\nclass-representative samples, called prototypes, by replacing the last layer\nwith a novel Hit-or-Miss layer. This layer contains activated vectors, called\ncapsules, that we train to hit or miss a fixed target capsule by tailoring a\nspecific centripetal loss function. This possibility allows to develop a data\naugmentation step combining information from the data space and the feature\nspace, resulting in a hybrid data augmentation process. We show that our\nnetwork, named HitNet, is able to reach better performances than those\nreproduced with the initial CapsNet on several datasets, while allowing to\nvisualize the nature of the features extracted as deformations of the\nprototypes, which provides a direct insight into the feature representation\nlearned by the network .\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 01:28:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Deliege", "A.", ""], ["Cioppa", "A.", ""], ["Van Droogenbroeck", "M.", ""]]}, {"id": "1911.05620", "submitter": "Weiguan Wang", "authors": "Johannes Ruf, Weiguan Wang", "title": "Neural networks for option pricing and hedging: a literature review", "comments": "Minor changes. Accepted for publications in Journal of Computational\n  Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.RM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been used as a nonparametric method for option pricing\nand hedging since the early 1990s. Far over a hundred papers have been\npublished on this topic. This note intends to provide a comprehensive review.\nPapers are compared in terms of input features, output variables, benchmark\nmodels, performance measures, data partition methods, and underlying assets.\nFurthermore, related work and regularisation techniques are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 17:01:36 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 12:45:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ruf", "Johannes", ""], ["Wang", "Weiguan", ""]]}, {"id": "1911.05627", "submitter": "Prashnna Gyawali", "authors": "Prashnna K Gyawali, Rudra Saha, Linwei Wang, VSR Veeravasarapu and\n  Maneesh Singh", "title": "Wavelets to the Rescue: Improving Sample Quality of Latent Variable Deep\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAE) are probabilistic deep generative models\nunderpinned by elegant theory, stable training processes, and meaningful\nmanifold representations. However, they produce blurry images due to a lack of\nexplicit emphasis over high-frequency textural details of the images, and the\ndifficulty to directly model the complex joint probability distribution over\nthe high-dimensional image space. In this work, we approach these two\nchallenges with a novel wavelet space VAE that uses the decoder to model the\nimages in the wavelet coefficient space. This enables the VAE to emphasize over\nhigh-frequency components within an image obtained via wavelet decomposition.\nAdditionally, by decomposing the complex function of generating\nhigh-dimensional images into inverse wavelet transformation and generation of\nwavelet coefficients, the latter becomes simpler to model by the VAE. We\nempirically validate that deep generative models operating in the wavelet space\ncan generate images of higher quality than the image (RGB) space counterparts.\nQuantitatively, on benchmark natural image datasets, we achieve consistently\nbetter FID scores than VAE based architectures and competitive FID scores with\na variety of GAN models for the same architectural and experimental setup.\nFurthermore, the proposed wavelet-based generative model retains desirable\nattributes like disentangled and informative latent representation without\nlosing the quality in the generated samples.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 15:16:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gyawali", "Prashnna K", ""], ["Saha", "Rudra", ""], ["Wang", "Linwei", ""], ["Veeravasarapu", "VSR", ""], ["Singh", "Maneesh", ""]]}, {"id": "1911.05628", "submitter": "Adam Kashlak", "authors": "Milad Kiaee, Adam B Kashlak, Jisu Kim, Giseon Heo", "title": "Diagnosis of Pediatric Obstructive Sleep Apnea via Face Classification\n  with Persistent Homology and Convolutional Neural Networks", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obstructive sleep apnea is a serious condition causing a litany of health\nproblems especially in the pediatric population. However, this chronic\ncondition can be treated if diagnosis is possible. The gold standard for\ndiagnosis is an overnight sleep study, which is often unobtainable by many\npotentially suffering from this condition. Hence, we attempt to develop a fast\nnon-invasive diagnostic tool by training a classifier on 2D and 3D facial\nimages of a patient to recognize facial features associated with obstructive\nsleep apnea. In this comparative study, we consider both persistent homology\nand geometric shape analysis from the field of computational topology as well\nas convolutional neural networks, a powerful method from deep learning whose\nsuccess in image and specifically facial recognition has already been\ndemonstrated by computer scientists.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 03:43:44 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Kiaee", "Milad", ""], ["Kashlak", "Adam B", ""], ["Kim", "Jisu", ""], ["Heo", "Giseon", ""]]}, {"id": "1911.05630", "submitter": "Lucas C. Uzal", "authors": "Marcos Pividori and Guillermo L. Grinblat and Lucas C. Uzal", "title": "Exploiting GAN Internal Capacity for High-Quality Reconstruction of\n  Natural Images", "comments": "This preprint is the result of the work done for the undergraduate\n  dissertation of M. Pividori supervised by L.C. Uzal and G.L. Grinblat, and\n  presented in July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have demonstrated impressive results in\nmodeling the distribution of natural images, learning latent representations\nthat capture semantic variations in an unsupervised basis. Beyond the\ngeneration of novel samples, it is of special interest to exploit the ability\nof the GAN generator to model the natural image manifold and hence generate\ncredible changes when manipulating images. However, this line of work is\nconditioned by the quality of the reconstruction. Until now, only inversion to\nthe latent space has been considered, we propose to exploit the representation\nin intermediate layers of the generator, and we show that this leads to\nincreased capacity. In particular, we observe that the representation after the\nfirst dense layer, present in all state-of-the-art GAN models, is expressive\nenough to represent natural images with high visual fidelity. It is possible to\ninterpolate around these images obtaining a sequence of new plausible synthetic\nimages that cannot be generated from the latent space. Finally, as an example\nof potential applications that arise from this inversion mechanism, we show\npreliminary results in exploiting the learned representation in the attention\nmap of the generator to obtain an unsupervised segmentation of natural images.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 22:07:24 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Pividori", "Marcos", ""], ["Grinblat", "Guillermo L.", ""], ["Uzal", "Lucas C.", ""]]}, {"id": "1911.05647", "submitter": "Ishanu Chattopadhyay", "authors": "Timmy Li, Yi Huang, James Evans and Ishanu Chattopadhyay", "title": "Long-range Event-level Prediction and Response Simulation for Urban\n  Crime and Global Terrorism with Granger Networks", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale trends in urban crime and global terrorism are well-predicted by\nsocio-economic drivers, but focused, event-level predictions have had limited\nsuccess. Standard machine learning approaches are promising, but lack\ninterpretability, are generally interpolative, and ineffective for precise\nfuture interventions with costly and wasteful false positives. Here, we are\nintroducing Granger Network inference as a new forecasting approach for\nindividual infractions with demonstrated performance far surpassing past\nresults, yet transparent enough to validate and extend social theory.\nConsidering the problem of predicting crime in the City of Chicago, we achieve\nan average AUC of ~90\\% for events predicted a week in advance within spatial\ntiles approximately $1000$ ft across. Instead of pre-supposing that crimes\nunfold across contiguous spaces akin to diffusive systems, we learn the local\ntransport rules from data. As our key insights, we uncover indications of\nsuburban bias -- how law-enforcement response is modulated by socio-economic\ncontexts with disproportionately negative impacts in the inner city -- and how\nthe dynamics of violent and property crimes co-evolve and constrain each other\n-- lending quantitative support to controversial pro-active policing policies.\nTo demonstrate broad applicability to spatio-temporal phenomena, we analyze\nterror attacks in the middle-east in the recent past, and achieve an AUC of\n~80% for predictions made a week in advance, and within spatial tiles measuring\napproximately 120 miles across. We conclude that while crime operates near an\nequilibrium quickly dissipating perturbations, terrorism does not. Indeed\nterrorism aims to destabilize social order, as shown by its dynamics being\nsusceptible to run-away increases in event rates under small perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:41:50 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Timmy", ""], ["Huang", "Yi", ""], ["Evans", "James", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1911.05652", "submitter": "Petr Plechac", "authors": "Petr Plech\\'a\\v{c}", "title": "Relative contributions of Shakespeare and Fletcher in Henry VIII: An\n  Analysis Based on Most Frequent Words and Most Frequent Rhythmic Patterns", "comments": null, "journal-ref": null, "doi": "10.1093/llc/fqaa032", "report-no": null, "categories": "cs.CL cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The versified play Henry VIII is nowadays widely recognized to be a\ncollaborative work not written solely by William Shakespeare. We employ\ncombined analysis of vocabulary and versification together with machine\nlearning techniques to determine which authors also took part in the writing of\nthe play and what were their relative contributions. Unlike most previous\nstudies, we go beyond the attribution of particular scenes and use the rolling\nattribution approach to determine the probabilities of authorship of pieces of\ntexts, without respecting the scene boundaries. Our results highly support the\ncanonical division of the play between William Shakespeare and John Fletcher\nproposed by James Spedding, but also bring new evidence supporting the\nmodifications proposed later by Thomas Merriam.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:40:05 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Plech\u00e1\u010d", "Petr", ""]]}, {"id": "1911.05663", "submitter": "Rohan Gala", "authors": "Rohan Gala, Nathan Gouwens, Zizhen Yao, Agata Budzillo, Osnat Penn,\n  Bosiljka Tasic, Gabe Murphy, Hongkui Zeng, Uygar S\\\"umb\\\"ul", "title": "A coupled autoencoder approach for multi-modal analysis of cell types", "comments": "Main text : 10 pages, 5 figures. Supp text : 6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in high throughput profiling of individual neurons have\nspurred data driven exploration of the idea that there exist natural groupings\nof neurons referred to as cell types. The promise of this idea is that the\nimmense complexity of brain circuits can be reduced, and effectively studied by\nmeans of interactions between cell types. While clustering of neuron\npopulations based on a particular data modality can be used to define cell\ntypes, such definitions are often inconsistent across different\ncharacterization modalities. We pose this issue of cross-modal alignment as an\noptimization problem and develop an approach based on coupled training of\nautoencoders as a framework for such analyses. We apply this framework to a\nPatch-seq dataset consisting of transcriptomic and electrophysiological\nprofiles for the same set of neurons to study consistency of representations\nacross modalities, and evaluate cross-modal data prediction ability. We explore\nthe problem where only a subset of neurons is characterized with more than one\nmodality, and demonstrate that representations learned by coupled autoencoders\ncan be used to identify types sampled only by a single modality.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:58:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Gala", "Rohan", ""], ["Gouwens", "Nathan", ""], ["Yao", "Zizhen", ""], ["Budzillo", "Agata", ""], ["Penn", "Osnat", ""], ["Tasic", "Bosiljka", ""], ["Murphy", "Gabe", ""], ["Zeng", "Hongkui", ""], ["S\u00fcmb\u00fcl", "Uygar", ""]]}, {"id": "1911.05683", "submitter": "Leon Gatys", "authors": "Jonas Rauber, Emily B. Fox, Leon A. Gatys", "title": "Modeling patterns of smartphone usage and their relationship to\n  cognitive health", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of smartphone usage in many people's lives make it a rich source\nof information about a person's mental and cognitive state. In this work we\nanalyze 12 weeks of phone usage data from 113 older adults, 31 with diagnosed\ncognitive impairment and 82 without. We develop structured models of users'\nsmartphone interactions to reveal differences in phone usage patterns between\npeople with and without cognitive impairment. In particular, we focus on\ninferring specific types of phone usage sessions that are predictive of\ncognitive impairment. Our model achieves an AUROC of 0.79 when discriminating\nbetween healthy and symptomatic subjects, and its interpretability enables\nnovel insights into which aspects of phone usage strongly relate with cognitive\nhealth in our dataset.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:04:18 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Rauber", "Jonas", ""], ["Fox", "Emily B.", ""], ["Gatys", "Leon A.", ""]]}, {"id": "1911.05697", "submitter": "Kamanchi Chandramouli", "authors": "Raghuram Bharadwaj Diddigi, Chandramouli Kamanchi, Shalabh Bhatnagar", "title": "A Convergent Off-Policy Temporal Difference Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the value function of a given policy (target policy) from the data\nsamples obtained from a different policy (behavior policy) is an important\nproblem in Reinforcement Learning (RL). This problem is studied under the\nsetting of off-policy prediction. Temporal Difference (TD) learning algorithms\nare a popular class of algorithms for solving the prediction problem. TD\nalgorithms with linear function approximation are shown to be convergent when\nthe samples are generated from the target policy (known as on-policy\nprediction). However, it has been well established in the literature that\noff-policy TD algorithms under linear function approximation diverge. In this\nwork, we propose a convergent on-line off-policy TD algorithm under linear\nfunction approximation. The main idea is to penalize the updates of the\nalgorithm in a way as to ensure convergence of the iterates. We provide a\nconvergence analysis of our algorithm. Through numerical evaluations, we\nfurther demonstrate the effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:17:38 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Diddigi", "Raghuram Bharadwaj", ""], ["Kamanchi", "Chandramouli", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1911.05700", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Qiaozhu Mei", "title": "Graph Representation Learning via Multi-task Knowledge Distillation", "comments": "NeurIPS 2019 GRL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on graph structured data has attracted much research\ninterest due to its ubiquity in real world data. However, how to efficiently\nrepresent graph data in a general way is still an open problem. Traditional\nmethods use handcraft graph features in a tabular form but suffer from the\ndefects of domain expertise requirement and information loss. Graph\nrepresentation learning overcomes these defects by automatically learning the\ncontinuous representations from graph structures, but they require abundant\ntraining labels, which are often hard to fulfill for graph-level prediction\nproblems. In this work, we demonstrate that, if available, the domain expertise\nused for designing handcraft graph features can improve the graph-level\nrepresentation learning when training labels are scarce. Specifically, we\nproposed a multi-task knowledge distillation method. By incorporating\nnetwork-theory-based graph metrics as auxiliary tasks, we show on both\nsynthetic and real datasets that the proposed multi-task learning method can\nimprove the prediction performance of the original learning task, especially\nwhen the training data size is small.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:42:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Ma", "Jiaqi", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1911.05712", "submitter": "Edoardo Manino", "authors": "Edoardo Manino, Long Tran-Thanh, Nicholas R. Jennings", "title": "Streaming Bayesian Inference for Crowdsourced Classification", "comments": "Accepted at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in crowdsourcing is inferring the ground truth from noisy and\nunreliable data. To do so, existing approaches rely on collecting redundant\ninformation from the crowd, and aggregating it with some probabilistic method.\nHowever, oftentimes such methods are computationally inefficient, are\nrestricted to some specific settings, or lack theoretical guarantees. In this\npaper, we revisit the problem of binary classification from crowdsourced data.\nSpecifically we propose Streaming Bayesian Inference for Crowdsourcing (SBIC),\na new algorithm that does not suffer from any of these limitations. First, SBIC\nhas low complexity and can be used in a real-time online setting. Second, SBIC\nhas the same accuracy as the best state-of-the-art algorithms in all settings.\nThird, SBIC has provable asymptotic guarantees both in the online and offline\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:41:08 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Manino", "Edoardo", ""], ["Tran-Thanh", "Long", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1911.05774", "submitter": "Jicong Fan", "authors": "Jicong Fan, Lijun Ding, Yudong Chen, and Madeleine Udell", "title": "Factor Group-Sparse Regularization for Efficient Low-Rank Matrix\n  Recovery", "comments": "Accepted by NeurIPS 2019. The supplementary material is at\n  https://github.com/jicongfan/Supplementary-material-of-conference-papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new class of nonconvex regularizers for low-rank matrix\nrecovery. Many regularizers are motivated as convex relaxations of the matrix\nrank function. Our new factor group-sparse regularizers are motivated as a\nrelaxation of the number of nonzero columns in a factorization of the matrix.\nThese nonconvex regularizers are sharper than the nuclear norm; indeed, we show\nthey are related to Schatten-$p$ norms with arbitrarily small $0 < p \\leq 1$.\nMoreover, these factor group-sparse regularizers can be written in a factored\nform that enables efficient and effective nonconvex optimization; notably, the\nmethod does not use singular value decomposition. We provide generalization\nerror bounds for low-rank matrix completion which show improved upper bounds\nfor Schatten-$p$ norm reglarization as $p$ decreases. Compared to the max norm\nand the factored formulation of the nuclear norm, factor group-sparse\nregularizers are more efficient, accurate, and robust to the initial guess of\nrank. Experiments show promising performance of factor group-sparse\nregularization for low-rank matrix completion and robust principal component\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:30:35 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:30:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fan", "Jicong", ""], ["Ding", "Lijun", ""], ["Chen", "Yudong", ""], ["Udell", "Madeleine", ""]]}, {"id": "1911.05781", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Internal Representations (COLT 1995)", "comments": null, "journal-ref": "COLT '95 Proceedings of the eighth annual conference on\n  Computational learning theory (1995) 311-320", "doi": "10.1145/225298.225336", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probably the most important problem in machine learning is the preliminary\nbiasing of a learner's hypothesis space so that it is small enough to ensure\ngood generalisation from reasonable training sets, yet large enough that it\ncontains a good solution to the problem being learnt. In this paper a mechanism\nfor {\\em automatically} learning or biasing the learner's hypothesis space is\nintroduced. It works by first learning an appropriate {\\em internal\nrepresentation} for a learning environment and then using that representation\nto bias the learner's hypothesis space for the learning of future tasks drawn\nfrom the same environment.\n  An internal representation must be learnt by sampling from {\\em many similar\ntasks}, not just a single task as occurs in ordinary machine learning. It is\nproved that the number of examples $m$ {\\em per task} required to ensure good\ngeneralisation from a representation learner obeys $m = O(a+b/n)$ where $n$ is\nthe number of tasks being learnt and $a$ and $b$ are constants. If the tasks\nare learnt independently ({\\em i.e.} without a common representation) then\n$m=O(a+b)$. It is argued that for learning environments such as speech and\ncharacter recognition $b\\gg a$ and hence representation learning in these\nenvironments can potentially yield a drastic reduction in the number of\nexamples required per task. It is also proved that if $n = O(b)$ (with\n$m=O(a+b/n)$) then the representation learnt will be good for learning novel\ntasks from the same environment, and that the number of examples required to\ngeneralise well on a novel task will be reduced to $O(a)$ (as opposed to\n$O(a+b)$ if no representation is used).\n  It is shown that gradient descent can be used to train neural network\nrepresentations and experiment results are reported providing strong\nqualitative support for the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:48:11 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:53:48 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 13:45:56 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.05806", "submitter": "Yule Vaz", "authors": "Yule Vaz, Rodrigo Fernandes de Mello and Carlos Henrique Grossi", "title": "Coarse-Refinement Dilemma: On Generalization Bounds for Data Clustering", "comments": "52 pages (in which 5 pages contain references, 1 contains notation, 1\n  contains dictionary of terms, 2 contain proofs, 5 contain dataset images and\n  7 contain results)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Data Clustering (DC) problem is of central importance for the area of\nMachine Learning (ML), given its usefulness to represent data structural\nsimilarities from input spaces. Differently from Supervised Machine Learning\n(SML), which relies on the theoretical frameworks of the Statistical Learning\nTheory (SLT) and the Algorithm Stability (AS), DC has scarce literature on\ngeneral-purpose learning guarantees, affecting conclusive remarks on how those\nalgorithms should be designed as well as on the validity of their results. In\nthis context, this manuscript introduces a new concept, based on\nmultidimensional persistent homology, to analyze the conditions on which a\nclustering model is capable of generalizing data. As a first step, we propose a\nmore general definition of DC problem by relying on Topological Spaces, instead\nof metric ones as typically approached in the literature. From that, we show\nthat the DC problem presents an analogous dilemma to the Bias-Variance one,\nwhich is here referred to as the Coarse-Refinement (CR) dilemma. CR is intended\nto clarify the contrast between: (i) highly-refined partitions and the\nclustering instability (overfitting); and (ii) over-coarse partitions and the\nlack of representativeness (underfitting); consequently, the CR dilemma\nsuggests the need of a relaxation of Kleinberg's richness axiom. Experimental\nresults were used to illustrate that multidimensional persistent homology\nsupport the measurement of divergences among DC models, leading to a\nconsistency criterion.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:42:17 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Vaz", "Yule", ""], ["de Mello", "Rodrigo Fernandes", ""], ["Grossi", "Carlos Henrique", ""]]}, {"id": "1911.05811", "submitter": "Anqi Liu", "authors": "Anqi Liu, Hao Liu, Anima Anandkumar, Yisong Yue", "title": "Triply Robust Off-Policy Evaluation", "comments": "Preliminary Work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust regression approach to off-policy evaluation (OPE) for\ncontextual bandits. We frame OPE as a covariate-shift problem and leverage\nmodern robust regression tools. Ours is a general approach that can be used to\naugment any existing OPE method that utilizes the direct method. When\naugmenting doubly robust methods, we call the resulting method Triply Robust.\nWe prove upper bounds on the resulting bias and variance, as well as derive\nnovel minimax bounds based on robust minimax analysis for covariate shift. Our\nrobust regression method is compatible with deep learning, and is thus\napplicable to complex OPE settings that require powerful function\napproximators. Finally, we demonstrate superior empirical performance across\nthe standard OPE benchmarks, especially in the case where the logging policy is\nunknown and must be estimated from data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:57:36 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:15:24 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Anqi", ""], ["Liu", "Hao", ""], ["Anandkumar", "Anima", ""], ["Yue", "Yisong", ""]]}, {"id": "1911.05815", "submitter": "Dipendra Misra", "authors": "Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy and John Langford", "title": "Kinematic State Abstraction and Provably Efficient Rich-Observation\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm, HOMER, for exploration and reinforcement learning in\nrich observation environments that are summarizable by an unknown latent state\nspace. The algorithm interleaves representation learning to identify a new\nnotion of kinematic state abstraction with strategic exploration to reach new\nstates using the learned abstraction. The algorithm provably explores the\nenvironment with sample complexity scaling polynomially in the number of latent\nstates and the time horizon, and, crucially, with no dependence on the size of\nthe observation space, which could be infinitely large. This exploration\nguarantee further enables sample-efficient global policy optimization for any\nreward function. On the computational side, we show that the algorithm can be\nimplemented efficiently whenever certain supervised learning problems are\ntractable. Empirically, we evaluate HOMER on a challenging exploration problem,\nwhere we show that the algorithm is exponentially more sample efficient than\nstandard reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 21:07:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Misra", "Dipendra", ""], ["Henaff", "Mikael", ""], ["Krishnamurthy", "Akshay", ""], ["Langford", "John", ""]]}, {"id": "1911.05822", "submitter": "Christos Thrampoulidis", "authors": "Zeyu Deng, Abla Kammoun and Christos Thrampoulidis", "title": "A Model of Double Descent for High-dimensional Binary Linear\n  Classification", "comments": "Short version submitted to ICASSP 2020; Updates in 2nd version:\n  revised proofs, typos fixed, extended discussions and numerical illustrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model for logistic regression where only a subset of features\nof size $p$ is used for training a linear classifier over $n$ training samples.\nThe classifier is obtained by running gradient descent (GD) on logistic loss.\nFor this model, we investigate the dependence of the classification error on\nthe overparameterization ratio $\\kappa=p/n$. First, building on known\ndeterministic results on the implicit bias of GD, we uncover a phase-transition\nphenomenon for the case of Gaussian features: the classification error of GD is\nthe same as that of the maximum-likelihood (ML) solution when\n$\\kappa<\\kappa_\\star$, and that of the max-margin (SVM) solution when\n$\\kappa>\\kappa_\\star$. Next, using the convex Gaussian min-max theorem (CGMT),\nwe sharply characterize the performance of both the ML and the SVM solutions.\nCombining these results, we obtain curves that explicitly characterize the\nclassification error for varying values of $\\kappa$. The numerical results\nvalidate the theoretical predictions and unveil double-descent phenomena that\ncomplement similar recent findings in linear regression settings as well as\nempirical observations in more complex learning scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 21:41:38 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 19:10:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Deng", "Zeyu", ""], ["Kammoun", "Abla", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1911.05843", "submitter": "Ardavan Afshar", "authors": "Ardavan Afshar, Ioakeim Perros, Haesun Park, Christopher deFilippi,\n  Xiaowei Yan, Walter Stewart, Joyce Ho, Jimeng Sun", "title": "TASTE: Temporal and Static Tensor Factorization for Phenotyping\n  Electronic Health Records", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phenotyping electronic health records (EHR) focuses on defining meaningful\npatient groups (e.g., heart failure group and diabetes group) and identifying\nthe temporal evolution of patients in those groups. Tensor factorization has\nbeen an effective tool for phenotyping. Most of the existing works assume\neither a static patient representation with aggregate data or only model\ntemporal data. However, real EHR data contain both temporal (e.g., longitudinal\nclinical visits) and static information (e.g., patient demographics), which are\ndifficult to model simultaneously. In this paper, we propose Temporal And\nStatic TEnsor factorization (TASTE) that jointly models both static and\ntemporal information to extract phenotypes. TASTE combines the PARAFAC2 model\nwith non-negative matrix factorization to model a temporal and a static tensor.\nTo fit the proposed model, we transform the original problem into simpler ones\nwhich are optimally solved in an alternating fashion. For each of the\nsub-problems, our proposed mathematical reformulations lead to efficient\nsub-problem solvers. Comprehensive experiments on large EHR data from a heart\nfailure (HF) study confirmed that TASTE is up to 14x faster than several\nbaselines and the resulting phenotypes were confirmed to be clinically\nmeaningful by a cardiologist. Using 80 phenotypes extracted by TASTE, a simple\nlogistic regression can achieve the same level of area under the curve (AUC)\nfor HF prediction compared to a deep learning model using recurrent neural\nnetworks (RNN) with 345 features.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 22:28:57 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Afshar", "Ardavan", ""], ["Perros", "Ioakeim", ""], ["Park", "Haesun", ""], ["deFilippi", "Christopher", ""], ["Yan", "Xiaowei", ""], ["Stewart", "Walter", ""], ["Ho", "Joyce", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.05861", "submitter": "Stephen Pfohl", "authors": "Stephen R. Pfohl, Andrew M. Dai, Katherine Heller", "title": "Federated and Differentially Private Learning for Electronic Health\n  Records", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of collaborative and decentralized machine learning techniques such\nas federated learning have the potential to enable the development and\ndeployment of clinical risk predictions models in low-resource settings without\nrequiring sensitive data be shared or stored in a central repository. This\nprocess necessitates communication of model weights or updates between\ncollaborating entities, but it is unclear to what extent patient privacy is\ncompromised as a result. To gain insight into this question, we study the\nefficacy of centralized versus federated learning in both private and\nnon-private settings. The clinical prediction tasks we consider are the\nprediction of prolonged length of stay and in-hospital mortality across thirty\none hospitals in the eICU Collaborative Research Database. We find that while\nit is straightforward to apply differentially private stochastic gradient\ndescent to achieve strong privacy bounds when training in a centralized\nsetting, it is considerably more difficult to do so in the federated setting.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 23:42:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Pfohl", "Stephen R.", ""], ["Dai", "Andrew M.", ""], ["Heller", "Katherine", ""]]}, {"id": "1911.05865", "submitter": "Pulong Ma", "authors": "Pulong Ma and Anindya Bhadra", "title": "Beyond Mat\\'ern: On A Class of Interpretable Confluent Hypergeometric\n  Covariance Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mat\\'ern covariance function is a popular choice for prediction in\nspatial statistics and uncertainty quantification literature. A key benefit of\nthe Mat\\'ern class is that it is possible to get precise control over the\ndegree of differentiability of the process realizations. However, the Mat\\'ern\nclass possesses exponentially decaying tails, and thus may not be suitable for\nmodeling polynomially decaying dependence. This problem can be remedied using\npolynomial covariances; however one loses control over the degree of\nmean-square differentiability of corresponding processes, in that the random\nprocesses with polynomial covariances are either infinitely mean-square\ndifferentiable or nowhere mean-square differentiable at all. We construct a new\nfamily of covariance functions called the \\emph{Confluent Hypergeometric} (CH)\nclass using a scale mixture representation of the Mat\\'ern class where one\nobtains the benefits of both Mat\\'ern and polynomial covariances. The resultant\ncovariance contains two parameters: one controls the degree of mean-square\ndifferentiability near the origin and the other controls the tail heaviness,\nindependently of each other. Using a spectral representation, we derive\ntheoretical properties of this new covariance including equivalent measures and\nasymptotic behavior of the maximum likelihood estimators under infill\nasymptotics. The improved theoretical properties of the CH class are verified\nvia extensive simulations. Application using NASA's Orbiting Carbon\nObservatory-2 satellite data confirms the advantage of the CH class over the\nMat\\'ern class, especially in extrapolative settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 00:01:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:38:46 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 14:09:33 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2021 03:05:12 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ma", "Pulong", ""], ["Bhadra", "Anindya", ""]]}, {"id": "1911.05873", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Remi Tachet des Combes, Byron Boots, Geoff Gordon", "title": "A Reduction from Reinforcement Learning to No-Regret Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reduction from reinforcement learning (RL) to no-regret online\nlearning based on the saddle-point formulation of RL, by which \"any\" online\nalgorithm with sublinear regret can generate policies with provable performance\nguarantees. This new perspective decouples the RL problem into two parts:\nregret minimization and function approximation. The first part admits a\nstandard online-learning analysis, and the second part can be quantified\nindependently of the learning algorithm. Therefore, the proposed reduction can\nbe used as a tool to systematically design new RL algorithms. We demonstrate\nthis idea by devising a simple RL algorithm based on mirror descent and the\ngenerative-model oracle. For any $\\gamma$-discounted tabular RL problem, with\nprobability at least $1-\\delta$, it learns an $\\epsilon$-optimal policy using\nat most\n$\\tilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\log(\\frac{1}{\\delta})}{(1-\\gamma)^4\\epsilon^2}\\right)$\nsamples. Furthermore, this algorithm admits a direct extension to linearly\nparameterized function approximators for large-scale applications, with\ncomputation and sample complexities independent of\n$|\\mathcal{S}|$,$|\\mathcal{A}|$, though at the cost of potential approximation\nbias.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 00:47:47 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 21:25:39 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Cheng", "Ching-An", ""], ["Combes", "Remi Tachet des", ""], ["Boots", "Byron", ""], ["Gordon", "Geoff", ""]]}, {"id": "1911.05887", "submitter": "Jiawei Wen", "authors": "Jiawei Wen, Hossein Vahabi, Mihajlo Grbovic", "title": "Revenue Maximization of Airbnb Marketplace using Search Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly pricing products or services in an online marketplace presents a\nchallenging problem and one of the critical factors for the success of the\nbusiness. When users are looking to buy an item they typically search for it.\nQuery relevance models are used at this stage to retrieve and rank the items on\nthe search page from most relevant to least relevant. The presented items are\nnaturally \"competing\" against each other for user purchases. We provide a\npractical two-stage model to price this set of retrieved items for which\ndistributions of their values are learned. The initial output of the pricing\nstrategy is a price vector for the top displayed items in one search event. We\nlater aggregate these results over searches to provide the supplier with the\noptimal price for each item. We applied our solution to large-scale search data\nobtained from Airbnb Experiences marketplace. Offline evaluation results show\nthat our strategy improves upon baseline pricing strategies on key metrics by\nat least +20% in terms of booking regret and +55% in terms of revenue\npotential.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:43:27 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 02:12:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wen", "Jiawei", ""], ["Vahabi", "Hossein", ""], ["Grbovic", "Mihajlo", ""]]}, {"id": "1911.05894", "submitter": "Aren Jansen", "authors": "Aren Jansen, Daniel P. W. Ellis, Shawn Hershey, R. Channing Moore,\n  Manoj Plakal, Ashok C. Popat, Rif A. Saurous", "title": "Coincidence, Categorization, and Consolidation: Learning to Recognize\n  Sounds with Minimal Supervision", "comments": "This extended version of a ICASSP 2020 submission under same title\n  has an added figure and additional discussion for easier consumption", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans do not acquire perceptual abilities in the way we train machines.\nWhile machine learning algorithms typically operate on large collections of\nrandomly-chosen, explicitly-labeled examples, human acquisition relies more\nheavily on multimodal unsupervised learning (as infants) and active learning\n(as children). With this motivation, we present a learning framework for sound\nrepresentation and recognition that combines (i) a self-supervised objective\nbased on a general notion of unimodal and cross-modal coincidence, (ii) a\nclustering objective that reflects our need to impose categorical structure on\nour experiences, and (iii) a cluster-based active learning procedure that\nsolicits targeted weak supervision to consolidate categories into relevant\nsemantic classes. By training a combined sound\nembedding/clustering/classification network according to these criteria, we\nachieve a new state-of-the-art unsupervised audio representation and\ndemonstrate up to a 20-fold reduction in the number of labels required to reach\na desired classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:07:47 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Jansen", "Aren", ""], ["Ellis", "Daniel P. W.", ""], ["Hershey", "Shawn", ""], ["Moore", "R. Channing", ""], ["Plakal", "Manoj", ""], ["Popat", "Ashok C.", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1911.05904", "submitter": "Dong Yizhen", "authors": "Yizhen Dong, Peixin Zhang, Jingyi Wang, Shuang Liu, Jun Sun, Jianye\n  Hao, Xinyu Wang, Li Wang, Jin Song Dong, Dai Ting", "title": "There is Limited Correlation between Coverage and Robustness for Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are increasingly applied in safety-critical\nsystems, e.g., for face recognition, autonomous car control and malware\ndetection. It is also shown that DNNs are subject to attacks such as\nadversarial perturbation and thus must be properly tested. Many coverage\ncriteria for DNN since have been proposed, inspired by the success of code\ncoverage criteria for software programs. The expectation is that if a DNN is a\nwell tested (and retrained) according to such coverage criteria, it is more\nlikely to be robust. In this work, we conduct an empirical study to evaluate\nthe relationship between coverage, robustness and attack/defense metrics for\nDNN. Our study is the largest to date and systematically done based on 100 DNN\nmodels and 25 metrics. One of our findings is that there is limited correlation\nbetween coverage and robustness, i.e., improving coverage does not help improve\nthe robustness. Our dataset and implementation have been made available to\nserve as a benchmark for future studies on testing DNN.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:36:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Dong", "Yizhen", ""], ["Zhang", "Peixin", ""], ["Wang", "Jingyi", ""], ["Liu", "Shuang", ""], ["Sun", "Jun", ""], ["Hao", "Jianye", ""], ["Wang", "Xinyu", ""], ["Wang", "Li", ""], ["Dong", "Jin Song", ""], ["Ting", "Dai", ""]]}, {"id": "1911.05909", "submitter": "Mengzhuo Guo", "authors": "Mengzhuo Guo, Zhongzhi Xu, Qingpeng Zhang, Xiuwu Liao, Jiapeng Liu", "title": "Explainable Ordinal Factorization Model: Deciphering the Effects of\n  Attributes by Piece-wise Linear Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal regression predicts the objects' labels that exhibit a natural\nordering, which is important to many managerial problems such as credit scoring\nand clinical diagnosis. In these problems, the ability to explain how the\nattributes affect the prediction is critical to users. However, most, if not\nall, existing ordinal regression models simplify such explanation in the form\nof constant coefficients for the main and interaction effects of individual\nattributes. Such explanation cannot characterize the contributions of\nattributes at different value scales. To address this challenge, we propose a\nnew explainable ordinal regression model, namely, the Explainable Ordinal\nFactorization Model (XOFM). XOFM uses the piece-wise linear functions to\napproximate the actual contributions of individual attributes and their\ninteractions. Moreover, XOFM introduces a novel ordinal transformation process\nto assign each object the probabilities of belonging to multiple relevant\nclasses, instead of fixing boundaries to differentiate classes. XOFM is based\non the Factorization Machines to handle the potential sparsity problem as a\nresult of discretizing the attribute scales. Comprehensive experiments with\nbenchmark datasets and baseline models demonstrate that the proposed XOFM\nexhibits superior explainability and leads to state-of-the-art prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:53:15 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Guo", "Mengzhuo", ""], ["Xu", "Zhongzhi", ""], ["Zhang", "Qingpeng", ""], ["Liao", "Xiuwu", ""], ["Liu", "Jiapeng", ""]]}, {"id": "1911.05911", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane", "title": "Recent Advances in Algorithmic High-Dimensional Robust Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the presence of outliers is a fundamental problem in statistics.\nUntil recently, all known efficient unsupervised learning algorithms were very\nsensitive to outliers in high dimensions. In particular, even for the task of\nrobust mean estimation under natural distributional assumptions, no efficient\nalgorithm was known. Recent work in theoretical computer science gave the first\nefficient robust estimators for a number of fundamental statistical tasks,\nincluding mean and covariance estimation. Since then, there has been a flurry\nof research activity on algorithmic high-dimensional robust estimation in a\nrange of settings. In this survey article, we introduce the core ideas and\nalgorithmic techniques in the emerging area of algorithmic high-dimensional\nrobust statistics with a focus on robust mean estimation. We also provide an\noverview of the approaches that have led to computationally efficient robust\nestimators for a range of broader statistical tasks and discuss new directions\nand opportunities for future work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:56:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""]]}, {"id": "1911.05916", "submitter": "Ziang Yan", "authors": "Ziang Yan, Yiwen Guo, Changshui Zhang", "title": "Adversarial Margin Maximization Networks", "comments": "11 pages + 1 page appendix, accepted by T-PAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2019.2948348", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous recent success of deep neural networks (DNNs) has sparked a\nsurge of interest in understanding their predictive ability. Unlike the human\nvisual system which is able to generalize robustly and learn with little\nsupervision, DNNs normally require a massive amount of data to learn new\nconcepts. In addition, research works also show that DNNs are vulnerable to\nadversarial examples-maliciously generated images which seem perceptually\nsimilar to the natural ones but are actually formed to fool learning models,\nwhich means the models have problem generalizing to unseen data with certain\ntype of distortions. In this paper, we analyze the generalization ability of\nDNNs comprehensively and attempt to improve it from a geometric point of view.\nWe propose adversarial margin maximization (AMM), a learning-based\nregularization which exploits an adversarial perturbation as a proxy. It\nencourages a large margin in the input space, just like the support vector\nmachines. With a differentiable formulation of the perturbation, we train the\nregularized DNNs simply through back-propagation in an end-to-end manner.\nExperimental results on various datasets (including MNIST, CIFAR-10/100, SVHN\nand ImageNet) and different DNN architectures demonstrate the superiority of\nour method over previous state-of-the-arts. Code and models for reproducing our\nresults will be made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 03:13:17 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Yan", "Ziang", ""], ["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "1911.05922", "submitter": "Nicholas Kullman", "authors": "Nicholas D. Kullman, Jorge E. Mendoza, Martin Cousineau, Justin C.\n  Goodson", "title": "Atari-fying the Vehicle Routing Problem with Stochastic Service Requests", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new general approach to modeling research problems as Atari-like\nvideogames to make them amenable to recent groundbreaking solution methods from\nthe deep reinforcement learning community. The approach is flexible, applicable\nto a wide range of problems. We demonstrate its application on a well known\nvehicle routing problem. Our preliminary results on this problem, though not\ntransformative, show signs of success and suggest that Atari-fication may be a\nuseful modeling approach for researchers studying problems involving sequential\ndecision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 03:41:11 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kullman", "Nicholas D.", ""], ["Mendoza", "Jorge E.", ""], ["Cousineau", "Martin", ""], ["Goodson", "Justin C.", ""]]}, {"id": "1911.05934", "submitter": "Raul Astudillo", "authors": "Raul Astudillo, Peter I. Frazier", "title": "Multi-Attribute Bayesian Optimization With Interactive Preference\n  Learning", "comments": "In Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider black-box global optimization of time-consuming-to-evaluate\nfunctions on behalf of a decision-maker (DM) whose preferences must be learned.\nEach feasible design is associated with a time-consuming-to-evaluate vector of\nattributes and each vector of attributes is assigned a utility by the DM's\nutility function, which may be learned approximately using preferences\nexpressed over pairs of attribute vectors. Past work has used a point estimate\nof this utility function as if it were error-free within single-objective\noptimization. However, utility estimation errors may yield a poor suggested\ndesign. Furthermore, this approach produces a single suggested \"best\" design,\nwhereas DMs often prefer to choose from a menu. We propose a novel\nmulti-attribute Bayesian optimization with preference learning approach. Our\napproach acknowledges the uncertainty in preference estimation and implicitly\nchooses designs to evaluate that are good not just for a single estimated\nutility function but a range of likely ones. The outcome of our approach is a\nmenu of designs and evaluated attributes from which the DM makes a final\nselection. We demonstrate the value and flexibility of our approach in a\nvariety of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:29:31 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:37:57 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Astudillo", "Raul", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1911.05940", "submitter": "Arvind Krishna", "authors": "Arvind Krishna, Simon Mak and Roshan Joseph", "title": "Distributional Clustering: A distribution-preserving clustering method", "comments": "Submitted to Statistica Sinica", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key use of k-means clustering is to identify cluster prototypes which can\nserve as representative points for a dataset. However, a drawback of using\nk-means cluster centers as representative points is that such points distort\nthe distribution of the underlying data. This can be highly disadvantageous in\nproblems where the representative points are subsequently used to gain insights\non the data distribution, as these points do not mimic the distribution of the\ndata. To this end, we propose a new clustering method called \"distributional\nclustering\", which ensures cluster centers capture the distribution of the\nunderlying data. We first prove the asymptotic convergence of the proposed\ncluster centers to the data generating distribution, then present an efficient\nalgorithm for computing these cluster centers in practice. Finally, we\ndemonstrate the effectiveness of distributional clustering on synthetic and\nreal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:06:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Krishna", "Arvind", ""], ["Mak", "Simon", ""], ["Joseph", "Roshan", ""]]}, {"id": "1911.05941", "submitter": "Yoeng Jye Yeoh", "authors": "Yoeng Jye Yeoh, Takashi Morie, Hakaru Tamukoh", "title": "An Efficient Hardware-Oriented Dropout Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hardware-oriented dropout algorithm, which is efficient\nfor field programmable gate array (FPGA) implementation. In deep neural\nnetworks (DNNs), overfitting occurs when networks are overtrained and adapt too\nwell to training data. Consequently, they fail in predicting unseen data used\nas test data. Dropout is a common technique that is often applied in DNNs to\novercome this problem. In general, implementing such training algorithms of\nDNNs in embedded systems is difficult due to power and memory constraints.\nTraining DNNs is power-, time-, and memory- intensive; however, embedded\nsystems require low power consumption and real-time processing. An FPGA is\nsuitable for embedded systems for its parallel processing characteristic and\nlow operating power; however, due to its limited memory and different\narchitecture, it is difficult to apply general neural network algorithms.\nTherefore, we propose a hardware-oriented dropout algorithm that can\neffectively utilize the characteristics of an FPGA with less memory required.\nSoftware program verification demonstrates that the performance of the proposed\nmethod is identical to that of conventional dropout, and hardware synthesis\ndemonstrates that it results in significant resource reduction.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:22:11 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Yeoh", "Yoeng Jye", ""], ["Morie", "Takashi", ""], ["Tamukoh", "Hakaru", ""]]}, {"id": "1911.05942", "submitter": "Quan Chen", "authors": "Bo Wang, Quan Chen, Min Zhou, Zhiqiang Zhang, Xiaogang Jin, Kun Gai", "title": "Progressive Feature Polishing Network for Salient Object Detection", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature matters for salient object detection. Existing methods mainly focus\non designing a sophisticated structure to incorporate multi-level features and\nfilter out cluttered features. We present Progressive Feature Polishing Network\n(PFPN), a simple yet effective framework to progressively polish the\nmulti-level features to be more accurate and representative. By employing\nmultiple Feature Polishing Modules (FPMs) in a recurrent manner, our approach\nis able to detect salient objects with fine details without any\npost-processing. A FPM parallelly updates the features of each level by\ndirectly incorporating all higher level context information. Moreover, it can\nkeep the dimensions and hierarchical structures of the feature maps, which\nmakes it flexible to be integrated with any CNN-based models. Empirical\nexperiments show that our results are monotonically getting better with\nincreasing number of FPMs. Without bells and whistles, PFPN outperforms the\nstate-of-the-art methods significantly on five benchmark datasets under various\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:22:12 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wang", "Bo", ""], ["Chen", "Quan", ""], ["Zhou", "Min", ""], ["Zhang", "Zhiqiang", ""], ["Jin", "Xiaogang", ""], ["Gai", "Kun", ""]]}, {"id": "1911.05944", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Katie M. Groves and Syed Rafay Hasan", "title": "2L-3W: 2-Level 3-Way Hardware-Software Co-Verification for the Mapping\n  of Deep Learning Architecture (DLA) onto FPGA Boards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGAs have become a popular choice for deploying deep learning architectures\n(DLA). There are many researchers that have explored the deployment and mapping\nof DLA on FPGA. However, there has been a growing need to do design-time\nhardware-software co-verification of these deployments. To the best of our\nknowledge this is the first work that proposes a 2-Level 3-Way (2L-3W)\nhardware-software co-verification methodology and provides a step-by-step guide\nfor the successful mapping, deployment and verification of DLA on FPGA boards.\nThe 2-Level verification is to make sure the implementation in each stage\n(software and hardware) are following the desired behavior. The 3-Way\nco-verification provides a cross-paradigm (software, design and hardware)\nlayer-by-layer parameter check to assure the correct implementation and mapping\nof the DLA onto FPGA boards. The proposed 2L-3W co-verification methodology has\nbeen evaluated over several test cases. In each case, the prediction and\nlayer-by-layer output of the DLA deployed on PYNQ FPGA board (hardware)\nalongside with the intermediate design results of the layer-by-layer output of\nthe DLA implemented on Vivado HLS and the prediction and layer-by-layer output\nof the software level (Caffe deep learning framework) are compared to obtain a\nlayer-by-layer similarity score. The comparison is achieved using a completely\nautomated Python script. The comparison provides a layer-by-layer similarity\nscore that informs us the degree of success of the DLA mapping to the FPGA or\nhelp identify in design time the layer to be debugged in the case of\nunsuccessful mapping. We demonstrated our technique on LeNet DLA and Caffe\ninspired Cifar-10 DLA and the co-verification results yielded layer-by-layer\nsimilarity scores of 99\\% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:33:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Groves", "Katie M.", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.05949", "submitter": "Haoyu Zhao", "authors": "Haoyu Zhao, Wei Chen", "title": "Online Second Price Auction with Semi-bandit Feedback Under the\n  Non-Stationary Setting", "comments": "Accepted to AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the non-stationary online second price auction\nproblem. We assume that the seller is selling the same type of items in $T$\nrounds by the second price auction, and she can set the reserve price in each\nround. In each round, the bidders draw their private values from a joint\ndistribution unknown to the seller. Then, the seller announced the reserve\nprice in this round. Next, bidders with private values higher than the\nannounced reserve price in that round will report their values to the seller as\ntheir bids. The bidder with the highest bid larger than the reserved price\nwould win the item and she will pay to the seller the price equal to the\nsecond-highest bid or the reserve price, whichever is larger. The seller wants\nto maximize her total revenue during the time horizon $T$ while learning the\ndistribution of private values over time. The problem is more challenging than\nthe standard online learning scenario since the private value distribution is\nnon-stationary, meaning that the distribution of bidders' private values may\nchange over time, and we need to use the \\emph{non-stationary regret} to\nmeasure the performance of our algorithm. To our knowledge, this paper is the\nfirst to study the repeated auction in the non-stationary setting\ntheoretically. Our algorithm achieves the non-stationary regret upper bound\n$\\tilde{\\mathcal{O}}(\\min\\{\\sqrt{\\mathcal S T},\n\\bar{\\mathcal{V}}^{\\frac{1}{3}}T^{\\frac{2}{3}}\\})$, where $\\mathcal S$ is the\nnumber of switches in the distribution, and $\\bar{\\mathcal{V}}$ is the sum of\ntotal variation, and $\\mathcal S$ and $\\bar{\\mathcal{V}}$ are not needed to be\nknown by the algorithm. We also prove regret lower bounds\n$\\Omega(\\sqrt{\\mathcal S T})$ in the switching case and\n$\\Omega(\\bar{\\mathcal{V}}^{\\frac{1}{3}}T^{\\frac{2}{3}})$ in the dynamic case,\nshowing that our algorithm has nearly optimal \\emph{non-stationary regret}.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:46:42 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zhao", "Haoyu", ""], ["Chen", "Wei", ""]]}, {"id": "1911.05954", "submitter": "Zhen Zhang", "authors": "Zhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Zhi\n  Yu, Can Wang", "title": "Hierarchical Graph Pooling with Structure Learning", "comments": "Typo corrected, reference added and code is available at\n  https://github.com/cszhangzhen/HGP-SL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs), which generalize deep neural networks to\ngraph-structured data, have drawn considerable attention and achieved\nstate-of-the-art performance in numerous graph related tasks. However, existing\nGNN models mainly focus on designing graph convolution operations. The graph\npooling (or downsampling) operations, that play an important role in learning\nhierarchical representations, are usually overlooked. In this paper, we propose\na novel graph pooling operator, called Hierarchical Graph Pooling with\nStructure Learning (HGP-SL), which can be integrated into various graph neural\nnetwork architectures. HGP-SL incorporates graph pooling and structure learning\ninto a unified module to generate hierarchical representations of graphs. More\nspecifically, the graph pooling operation adaptively selects a subset of nodes\nto form an induced subgraph for the subsequent layers. To preserve the\nintegrity of graph's topological information, we further introduce a structure\nlearning mechanism to learn a refined graph structure for the pooled graph at\neach layer. By combining HGP-SL operator with graph neural networks, we perform\ngraph level representation learning with focus on graph classification task.\nExperimental results on six widely used benchmarks demonstrate the\neffectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:55:17 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 02:00:59 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 15:09:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhang", "Zhen", ""], ["Bu", "Jiajun", ""], ["Ester", "Martin", ""], ["Zhang", "Jianfeng", ""], ["Yao", "Chengwei", ""], ["Yu", "Zhi", ""], ["Wang", "Can", ""]]}, {"id": "1911.05956", "submitter": "Vishal Jain", "authors": "Harsh Deshpande, Vishal Jain, Sharayu Moharir", "title": "Contextual Bandits Evolving Over Finite Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits have the same exploration-exploitation trade-off as\nstandard multi-armed bandits. On adding positive externalities that decay with\ntime, this problem becomes much more difficult as wrong decisions at the start\nare hard to recover from. We explore existing policies in this setting and\nhighlight their biases towards the inherent reward matrix. We propose a\nrejection based policy that achieves a low regret irrespective of the structure\nof the reward probability matrix.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 06:14:14 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Deshpande", "Harsh", ""], ["Jain", "Vishal", ""], ["Moharir", "Sharayu", ""]]}, {"id": "1911.05990", "submitter": "David Kappel", "authors": "Lukas Hahne, Timo L\\\"uddecke, Florentin W\\\"org\\\"otter, David Kappel", "title": "Attention on Abstract Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have been boosting the performance of deep learning\nmodels on a wide range of applications, ranging from speech understanding to\nprogram induction. However, despite experiments from psychology which suggest\nthat attention plays an essential role in visual reasoning, the full potential\nof attention mechanisms has so far not been explored to solve abstract\ncognitive tasks on image data. In this work, we propose a hybrid network\narchitecture, grounded on self-attention and relational reasoning. We call this\nnew model Attention Relation Network (ARNe). ARNe combines features from the\nrecently introduced Transformer and the Wild Relation Network (WReN). We test\nARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual\nreasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational\nconcepts between objects are efficiently learned demanding only 35% of the\ntraining samples to surpass reported accuracy of the base line model. Our\nproposed hybrid model, represents an alternative on learning abstract relations\nusing self-attention and demonstrates that the Transformer network is also well\nsuited for abstract visual reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:33:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Hahne", "Lukas", ""], ["L\u00fcddecke", "Timo", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""], ["Kappel", "David", ""]]}, {"id": "1911.05996", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro, Hamed Haddadi", "title": "Privacy and Utility Preserving Sensor-Data Transformations", "comments": "Accepted to appear in Pervasive and Mobile computing (PMC) Journal,\n  Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive inferences and user re-identification are major threats to privacy\nwhen raw sensor data from wearable or portable devices are shared with\ncloud-assisted applications. To mitigate these threats, we propose mechanisms\nto transform sensor data before sharing them with applications running on\nusers' devices. These transformations aim at eliminating patterns that can be\nused for user re-identification or for inferring potentially sensitive\nactivities, while introducing a minor utility loss for the target application\n(or task). We show that, on gesture and activity recognition tasks, we can\nprevent inference of potentially sensitive activities while keeping the\nreduction in recognition accuracy of non-sensitive activities to less than 5\npercentage points. We also show that we can reduce the accuracy of user\nre-identification and of the potential inference of gender to the level of a\nrandom guess, while keeping the accuracy of activity recognition comparable to\nthat obtained on the original data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:47:29 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1911.05999", "submitter": "Daiki Suehiro", "authors": "Daiki Suehiro, Eiji Takimoto", "title": "Reduction Scheme for Empirical Risk Minimization and Its Applications to\n  Multiple-Instance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple reduction scheme for empirical risk\nminimization (ERM) that preserves empirical Rademacher complexity. The\nreduction allows us to transfer known generalization bounds and algorithms for\nERM to the target learning problems in a straightforward way. In particular, we\napply our reduction scheme to the multiple-instance learning (MIL) problem, for\nwhich generalization bounds and ERM algorithms have been extensively studied.\nWe show that various learning problems can be reduced to MIL. Examples include\ntop-1 ranking learning, multi-class learning, and labeled and complementarily\nlabeled learning. It turns out that, some of the generalization bounds derived\nare, despite the simplicity of derivation, incomparable or competitive with the\nexisting bounds. Moreover, in some setting of labeled and complementarily\nlabeled learning, the algorithm derived is the first polynomial-time algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:56:06 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 03:19:34 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Suehiro", "Daiki", ""], ["Takimoto", "Eiji", ""]]}, {"id": "1911.06009", "submitter": "Hideaki Hayashi D.Eng.", "authors": "Hideaki Hayashi, Taro Shibanoki, Keisuke Shima, Yuichi Kurita and\n  Toshio Tsuji", "title": "A Recurrent Probabilistic Neural Network with Dimensionality Reduction\n  Based on Time-series Discriminant Component Analysis", "comments": "Published in IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, Vol.\n  26, No.12, pp. 3021-3033, 2015", "doi": "10.1109/TNNLS.2015.2400448", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a probabilistic neural network developed on the basis of\ntime-series discriminant component analysis (TSDCA) that can be used to\nclassify high-dimensional time-series patterns. TSDCA involves the compression\nof high-dimensional time series into a lower-dimensional space using a set of\northogonal transformations and the calculation of posterior probabilities based\non a continuous-density hidden Markov model with a Gaussian mixture model\nexpressed in the reduced-dimensional space. The analysis can be incorporated\ninto a neural network, which is named a time-series discriminant component\nnetwork (TSDCN), so that parameters of dimensionality reduction and\nclassification can be obtained simultaneously as network coefficients according\nto a backpropagation through time-based learning algorithm with the Lagrange\nmultiplier method. The TSDCN is considered to enable high-accuracy\nclassification of high-dimensional time-series patterns and to reduce the\ncomputation time taken for network training. The validity of the TSDCN is\ndemonstrated for high-dimensional artificial data and EEG signals in the\nexperiments conducted during the study.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 09:48:41 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Hayashi", "Hideaki", ""], ["Shibanoki", "Taro", ""], ["Shima", "Keisuke", ""], ["Kurita", "Yuichi", ""], ["Tsuji", "Toshio", ""]]}, {"id": "1911.06015", "submitter": "Maximilian Toller", "authors": "Maximilian Toller and Roman Kern", "title": "Robust Parameter-Free Season Length Detection in Time Series", "comments": "MileTS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The in-depth analysis of time series has gained a lot of research interest in\nrecent years, with the identification of periodic patterns being one important\naspect. Many of the methods for identifying periodic patterns require time\nseries' season length as input parameter. There exist only a few algorithms for\nautomatic season length approximation. Many of these rely on simplifications\nsuch as data discretization and user defined parameters. This paper presents an\nalgorithm for season length detection that is designed to be sufficiently\nreliable to be used in practical applications and does not require any input\nother than the time series to be analyzed. The algorithm estimates a time\nseries' season length by interpolating, filtering and detrending the data. This\nis followed by analyzing the distances between zeros in the directly\ncorresponding autocorrelation function. Our algorithm was tested against a\ncomparable algorithm and outperformed it by passing 122 out of 165 tests, while\nthe existing algorithm passed 83 tests. The robustness of our method can be\njointly attributed to both the algorithmic approach and also to design\ndecisions taken at the implementational level.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 10:07:41 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Toller", "Maximilian", ""], ["Kern", "Roman", ""]]}, {"id": "1911.06028", "submitter": "Hideaki Hayashi D.Eng.", "authors": "Hideaki Hayashi and Seiichi Uchida", "title": "A Discriminative Gaussian Mixture Model with Sparsity", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In probabilistic classification, a discriminative model based on the softmax\nfunction has a potential limitation in that it assumes unimodality for each\nclass in the feature space. The mixture model can address this issue, although\nit leads to an increase in the number of parameters. We propose a sparse\nclassifier based on a discriminative GMM, referred to as a sparse\ndiscriminative Gaussian mixture (SDGM). In the SDGM, a GMM-based discriminative\nmodel is trained via sparse Bayesian learning. Using this sparse learning\nframework, we can simultaneously remove redundant Gaussian components and\nreduce the number of parameters used in the remaining components during\nlearning; this learning method reduces the model complexity, thereby improving\nthe generalization capability. Furthermore, the SDGM can be embedded into\nneural networks (NNs), such as convolutional NNs, and can be trained in an\nend-to-end manner. Experimental results demonstrated that the proposed method\noutperformed the existing softmax-based discriminative models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 10:42:41 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 08:23:12 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hayashi", "Hideaki", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1911.06048", "submitter": "Simon Bartels", "authors": "Simon Bartels and Philipp Hennig", "title": "Conjugate Gradients for Kernel Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized least-squares (kernel-ridge / Gaussian process) regression is a\nfundamental algorithm of statistics and machine learning. Because generic\nalgorithms for the exact solution have cubic complexity in the number of\ndatapoints, large datasets require to resort to approximations. In this work,\nthe computation of the least-squares prediction is itself treated as a\nprobabilistic inference problem. We propose a structured Gaussian regression\nmodel on the kernel function that uses projections of the kernel matrix to\nobtain a low-rank approximation of the kernel and the matrix. A central result\nis an enhanced way to use the method of conjugate gradients for the specific\nsetting of least-squares regression as encountered in machine learning. Our\nmethod improves the approximation of the kernel ridge regressor / Gaussian\nprocess posterior mean over vanilla conjugate gradients and, allows computation\nof the posterior variance and the log marginal likelihood (evidence) without\nfurther overhead.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 11:38:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Bartels", "Simon", ""], ["Hennig", "Philipp", ""]]}, {"id": "1911.06057", "submitter": "Takayuki Osogami Ph.D.", "authors": "Takayuki Osogami", "title": "Supplementary material for Uncorrected least-squares temporal difference\n  with lambda-return", "comments": "9 pages, supplementary material for an AAAI-20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we provide a supplementary material for Takayuki Osogami, \"Uncorrected\nleast-squares temporal difference with lambda-return,\" which appears in {\\it\nProceedings of the 34th AAAI Conference on Artificial Intelligence} (AAAI-20).\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 12:18:34 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Osogami", "Takayuki", ""]]}, {"id": "1911.06106", "submitter": "Fayyaz Minhas", "authors": "Sadaf Gull and Fayyaz Minhas", "title": "AMP0: Species-Specific Prediction of Anti-microbial Peptides using Zero\n  and Few Shot Learning", "comments": "Under journal submission, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of drug-resistant microbial species is one of the major\nchallenges to global health. The development of new antimicrobial treatments\nsuch as antimicrobial peptides needs to be accelerated to combat this threat.\nHowever, the discovery of novel antimicrobial peptides is hampered by\nlow-throughput biochemical assays. Computational techniques can be used for\nrapid screening of promising antimicrobial peptide candidates prior to testing\nin the wet lab. The vast majority of existing antimicrobial peptide predictors\nare non-targeted in nature, i.e., they can predict whether a given peptide\nsequence is antimicrobial, but they are unable to predict whether the sequence\ncan target a particular microbial species. In this work, we have developed a\ntargeted antimicrobial peptide activity predictor that can predict whether a\npeptide is effective against a given microbial species or not. This has been\nmade possible through zero-shot and few-shot machine learning. The proposed\npredictor called AMP0 takes in the peptide amino acid sequence and any\nN/C-termini modifications together with the genomic sequence of a target\nmicrobial species to generate targeted predictions. It is important to note\nthat the proposed method can generate predictions for species that are not part\nof its training set. The accuracy of predictions for novel test species can be\nfurther improved by providing a few example peptides for that species. Our\ncomputational cross-validation results show that the pro-posed scheme is\nparticularly effective for targeted antimicrobial prediction in comparison to\nexisting approaches and can be used for screening potential antimicrobial\npeptides in a targeted manner especially for cases in which the number of\ntraining examples is small. The webserver of the method is available at\nhttp://ampzero.pythonanywhere.com.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 08:27:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gull", "Sadaf", ""], ["Minhas", "Fayyaz", ""]]}, {"id": "1911.06107", "submitter": "Joe Kileel", "authors": "Nathan Zelesko, Amit Moscovich, Joe Kileel, Amit Singer", "title": "Earthmover-based manifold learning for analyzing molecular conformation\n  spaces", "comments": "5 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for manifold learning that\ncombines the Earthmover's distance (EMD) with the diffusion maps method for\ndimensionality reduction. We demonstrate the potential benefits of this\napproach for learning shape spaces of proteins and other flexible\nmacromolecules using a simulated dataset of 3-D density maps that mimic the\nnon-uniform rotary motion of ATP synthase. Our results show that EMD-based\ndiffusion maps require far fewer samples to recover the intrinsic geometry than\nthe standard diffusion maps algorithm that is based on the Euclidean distance.\nTo reduce the computational burden of calculating the EMD for all volume pairs,\nwe employ a wavelet-based approximation to the EMD which reduces the\ncomputation of the pairwise EMDs to a computation of pairwise weighted-$\\ell_1$\ndistances between wavelet coefficient vectors.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:38:52 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zelesko", "Nathan", ""], ["Moscovich", "Amit", ""], ["Kileel", "Joe", ""], ["Singer", "Amit", ""]]}, {"id": "1911.06111", "submitter": "Andrew O. Arnold", "authors": "Andrew O. Arnold, William W. Cohen", "title": "Instance-based Transfer Learning for Multilingual Deep Retrieval", "comments": null, "journal-ref": "The Web Conference Workshop on Multilingual Search, 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of search in the multilingual setting. Examining the\nproblems of next-sentence prediction and inverse cloze, we show that at large\nscale, instance-based transfer learning is surprisingly effective in the\nmultilingual setting, leading to positive transfer on all of the 35 target\nlanguages and two tasks tested. We analyze this improvement and argue that the\nmost natural explanation, namely direct vocabulary overlap between languages,\nonly partially explains the performance gains: in fact, we demonstrate\ntarget-language improvement can occur after adding data from an auxiliary\nlanguage even with no vocabulary in common with the target. This surprising\nresult is due to the effect of transitive vocabulary overlaps between pairs of\nauxiliary and target languages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:23:30 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 18:11:37 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 15:22:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Arnold", "Andrew O.", ""], ["Cohen", "William W.", ""]]}, {"id": "1911.06118", "submitter": "Jayashree P.", "authors": "P. Jayashree, Ballijepalli Shreya, and P.K. Srijith", "title": "Learning Multi-Sense Word Distributions using Approximate\n  Kullback-Leibler Divergence", "comments": "7 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning word representations has garnered greater attention in the recent\npast due to its diverse text applications. Word embeddings encapsulate the\nsyntactic and semantic regularities of sentences. Modelling word embedding as\nmulti-sense gaussian mixture distributions, will additionally capture\nuncertainty and polysemy of words. We propose to learn the Gaussian mixture\nrepresentation of words using a Kullback-Leibler (KL) divergence based\nobjective function. The KL divergence based energy function provides a better\ndistance metric which can effectively capture entailment and distribution\nsimilarity among the words. Due to the intractability of KL divergence for\nGaussian mixture, we go for a KL approximation between Gaussian mixtures. We\nperform qualitative and quantitative experiments on benchmark word similarity\nand entailment datasets which demonstrate the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:59:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Jayashree", "P.", ""], ["Shreya", "Ballijepalli", ""], ["Srijith", "P. K.", ""]]}, {"id": "1911.06129", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "A Bayesian/Information Theoretic Model of Bias Learning", "comments": null, "journal-ref": "COLT 96 Proceedings of the ninth annual conference on\n  Computational learning theory (1996) Pages 77-88", "doi": "10.1145/238061.238071", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of learning appropriate bias for an environment of\nrelated tasks is examined from a Bayesian perspective. The environment of\nrelated tasks is shown to be naturally modelled by the concept of an {\\em\nobjective} prior distribution. Sampling from the objective prior corresponds to\nsampling different learning tasks from the environment. It is argued that for\nmany common machine learning problems, although we don't know the true\n(objective) prior for the problem, we do have some idea of a set of possible\npriors to which the true prior belongs. It is shown that under these\ncircumstances a learner can use Bayesian inference to learn the true prior by\nsampling from the objective prior. Bounds are given on the amount of\ninformation required to learn a task when it is simultaneously learnt with\nseveral other tasks. The bounds show that if the learner has little knowledge\nof the true prior, and the dimensionality of the true prior is small, then\nsampling multiple tasks is highly advantageous.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 14:34:58 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.06154", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Vishrav Chaudhary, Francisco Guzman, Philipp Koehn", "title": "CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual document alignment aims to identify pairs of documents in two\ndistinct languages that are of comparable content or translations of each\nother. In this paper, we exploit the signals embedded in URLs to label web\ndocuments at scale with an average precision of 94.5% across different language\npairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify\nweb document pairs that are translations of each other. We release a new web\ndataset consisting of over 392 million URL pairs from Common Crawl covering\ndocuments in 8144 language pairs of which 137 pairs include English. In\naddition to curating this massive dataset, we introduce baseline methods that\nleverage cross-lingual representations to identify aligned documents based on\ntheir textual content. Finally, we demonstrate the value of this parallel\ndocuments dataset through a downstream task of mining parallel sentences and\nmeasuring the quality of machine translations from models trained on this mined\ndata. Our objective in releasing this dataset is to foster new research in\ncross-lingual NLP across a variety of low, medium, and high-resource languages.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:09:11 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 06:00:35 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Chaudhary", "Vishrav", ""], ["Guzman", "Francisco", ""], ["Koehn", "Philipp", ""]]}, {"id": "1911.06156", "submitter": "Dhanasekar Sundararaman", "authors": "Dhanasekar Sundararaman, Vivek Subramanian, Guoyin Wang, Shijing Si,\n  Dinghan Shen, Dong Wang, Lawrence Carin", "title": "Syntax-Infused Transformer and BERT models for Machine Translation and\n  Natural Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have shown significant improvement over traditional\nalgorithms in several NLP tasks. The Transformer, for instance, is an\nillustrative example that generates abstract representations of tokens inputted\nto an encoder based on their relationships to all tokens in a sequence. Recent\nstudies have shown that although such models are capable of learning syntactic\nfeatures purely by seeing examples, explicitly feeding this information to deep\nlearning models can significantly enhance their performance. Leveraging\nsyntactic information like part of speech (POS) may be particularly beneficial\nin limited training data settings for complex models such as the Transformer.\nWe show that the syntax-infused Transformer with multiple features achieves an\nimprovement of 0.7 BLEU when trained on the full WMT 14 English to German\ntranslation dataset and a maximum improvement of 1.99 BLEU points when trained\non a fraction of the dataset. In addition, we find that the incorporation of\nsyntax into BERT fine-tuning outperforms baseline on a number of downstream\ntasks from the GLUE benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:42:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Sundararaman", "Dhanasekar", ""], ["Subramanian", "Vivek", ""], ["Wang", "Guoyin", ""], ["Si", "Shijing", ""], ["Shen", "Dinghan", ""], ["Wang", "Dong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1911.06164", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Model Bias", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 8, 1995, 169-175", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of {\\em learning} appropriate domain-specific bias\nis addressed. It is shown that this can be achieved by learning many related\ntasks from the same domain, and a theorem is given bounding the number tasks\nthat must be learnt. A corollary of the theorem is that if the tasks are known\nto possess a common {\\em internal representation} or {\\em preprocessing} then\nthe number of examples required per task for good generalisation when learning\n$n$ tasks simultaneously scales like $O(a + \\frac{b}{n})$, where $O(a)$ is a\nbound on the minimum number of examples required to learn a single task, and\n$O(a + b)$ is a bound on the number of examples required to learn each task\nindependently. An experiment providing strong qualitative support for the\ntheoretical results is reported.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:07:08 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.06177", "submitter": "Thomas Lee", "authors": "Suofei Wu, Jan Hannig and Thomas C. M. Lee", "title": "Uncertainty Quantification in Ensembles of Honest Regression Trees using\n  Generalized Fiducial Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their accuracies, methods based on ensembles of regression trees are a\npopular approach for making predictions. Some common examples include Bayesian\nadditive regression trees, boosting and random forests. This paper focuses on\nhonest random forests, which add honesty to the original form of random forests\nand are proved to have better statistical properties. The main contribution is\na new method that quantifies the uncertainties of the estimates and predictions\nproduced by honest random forests. The proposed method is based on the\ngeneralized fiducial methodology, and provides a fiducial density function that\nmeasures how likely each single honest tree is the true model. With such a\ndensity function, estimates and predictions, as well as their\nconfidence/prediction intervals, can be obtained. The promising empirical\nproperties of the proposed method are demonstrated by numerical comparisons\nwith several state-of-the-art methods, and by applications to a few real data\nsets. Lastly, the proposed method is theoretically backed up by a strong\nasymptotic guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:33:07 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Wu", "Suofei", ""], ["Hannig", "Jan", ""], ["Lee", "Thomas C. M.", ""]]}, {"id": "1911.06182", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Lior Wolf", "title": "MML: Maximal Multiverse Learning for Robust Fine-Tuning of Language\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art language models utilize a two-phase training\nprocedure comprised of (i) unsupervised pre-training on unlabeled text, and\n(ii) fine-tuning for a specific supervised task. More recently, many studies\nhave been focused on trying to improve these models by enhancing the\npre-training phase, either via better choice of hyperparameters or by\nleveraging an improved formulation. However, the pre-training phase is\ncomputationally expensive and often done on private datasets. In this work, we\npresent a method that leverages BERT's fine-tuning phase to its fullest, by\napplying an extensive number of parallel classifier heads, which are enforced\nto be orthogonal, while adaptively eliminating the weaker heads during\ntraining. Our method allows the model to converge to an optimal number of\nparallel classifiers, depending on the given dataset at hand.\n  We conduct an extensive inter- and intra-dataset evaluations, showing that\nour method improves the robustness of BERT, sometimes leading to a +9\\% gain in\naccuracy. These results highlight the importance of a proper fine-tuning\nprocedure, especially for relatively smaller-sized datasets. Our code is\nattached as supplementary and our models will be made completely public.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:21:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Malkiel", "Itzik", ""], ["Wolf", "Lior", ""]]}, {"id": "1911.06187", "submitter": "Christopher Grumiau Dr", "authors": "Robin Van Oirbeek, Christopher Grumiau, Tim Verdonck", "title": "Concordance probability in a big data setting: application in non-life\n  insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concordance probability or C-index is a popular measure to capture the\ndiscriminatory ability of a regression model. In this article, the definition\nof this measure is adapted to the specific needs of the frequency and severity\nmodel, typically used during the technical pricing of a non-life insurance\nproduct. Due to the typical large sample size of the frequency data in\nparticular, two different adaptations of the estimation procedure of the\nconcordance probability are presented. Note that the latter procedures can be\napplied to all different versions of the concordance probability.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:42:36 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Van Oirbeek", "Robin", ""], ["Grumiau", "Christopher", ""], ["Verdonck", "Tim", ""]]}, {"id": "1911.06191", "submitter": "Yingce Xia", "authors": "Yingce Xia, Xu Tan, Fei Tian, Fei Gao, Weicong Chen, Yang Fan, Linyuan\n  Gong, Yichong Leng, Renqian Luo, Yiren Wang, Lijun Wu, Jinhua Zhu, Tao Qin,\n  Tie-Yan Liu", "title": "Microsoft Research Asia's Systems for WMT19", "comments": "Accepted to \"Fourth Conference on Machine Translation (WMT19)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We Microsoft Research Asia made submissions to 11 language directions in the\nWMT19 news translation tasks. We won the first place for 8 of the 11 directions\nand the second place for the other three. Our basic systems are built on\nTransformer, back translation and knowledge distillation. We integrate several\nof our rececent techniques to enhance the baseline systems: multi-agent dual\nlearning (MADL), masked sequence-to-sequence pre-training (MASS), neural\narchitecture optimization (NAO), and soft contextual data augmentation (SCA).\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:55:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Xia", "Yingce", ""], ["Tan", "Xu", ""], ["Tian", "Fei", ""], ["Gao", "Fei", ""], ["Chen", "Weicong", ""], ["Fan", "Yang", ""], ["Gong", "Linyuan", ""], ["Leng", "Yichong", ""], ["Luo", "Renqian", ""], ["Wang", "Yiren", ""], ["Wu", "Lijun", ""], ["Zhu", "Jinhua", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.06192", "submitter": "Li Zhou", "authors": "Li Zhou and Kevin Small", "title": "Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain dialogue state tracking (DST) is a critical component for\nconversational AI systems. The domain ontology (i.e., specification of domains,\nslots, and values) of a conversational AI system is generally incomplete,\nmaking the capability for DST models to generalize to new slots, values, and\ndomains during inference imperative. In this paper, we propose to model\nmulti-domain DST as a question answering problem, referred to as Dialogue State\nTracking via Question Answering (DSTQA). Within DSTQA, each turn generates a\nquestion asking for the value of a (domain, slot) pair, thus making it\nnaturally extensible to unseen domains, slots, and values. Additionally, we use\na dynamically-evolving knowledge graph to explicitly learn relationships\nbetween (domain, slot) pairs. Our model has a 5.80% and 12.21% relative\nimprovement over the current state-of-the-art model on MultiWOZ 2.0 and\nMultiWOZ 2.1 datasets, respectively. Additionally, our model consistently\noutperforms the state-of-the-art model in domain adaptation settings. (Code is\nreleased at https://github.com/alexa/dstqa )\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:00:16 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 21:07:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""]]}, {"id": "1911.06194", "submitter": "Xisen Jin", "authors": "Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, Xiang Ren", "title": "Towards Hierarchical Importance Attribution: Explaining Compositional\n  Semantics for Neural Sequence Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance of neural networks on natural language processing\ntasks attributes to their ability to model complicated word and phrase\ncompositions. To explain how the model handles semantic compositions, we study\nhierarchical explanation of neural network predictions. We identify\nnon-additivity and context independent importance attributions within\nhierarchies as two desirable properties for highlighting word and phrase\ncompositions. We show some prior efforts on hierarchical explanations, e.g.\ncontextual decomposition, do not satisfy the desired properties mathematically,\nleading to inconsistent explanation quality in different models. In this paper,\nwe start by proposing a formal and general way to quantify the importance of\neach word and phrase. Following the formulation, we propose Sampling and\nContextual Decomposition (SCD) algorithm and Sampling and Occlusion (SOC)\nalgorithm. Human and metrics evaluation on both LSTM models and BERT\nTransformer models on multiple datasets show that our algorithms outperform\nprior hierarchical explanation algorithms. Our algorithms help to visualize\nsemantic composition captured by models, extract classification rules and\nimprove human trust of models. Project page: https://inklab.usc.edu/hiexpl/\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:25:04 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 05:47:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jin", "Xisen", ""], ["Wei", "Zhongyu", ""], ["Du", "Junyi", ""], ["Xue", "Xiangyang", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.06197", "submitter": "Vivian Chou", "authors": "Vivian T. Chou, LeAnna Kent, Joel A. G\\'ongora, Sam Ballerini, Carl D.\n  Hoover", "title": "Towards automatic extractive text summarization of A-133 Single Audit\n  reports with machine learning", "comments": "8 pages, first version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of text data has motivated the development of\nmachine-learning based automatic text summarization strategies that concisely\ncapture the essential ideas in a larger text. This study aimed to devise an\nextractive summarization method for A-133 Single Audits, which assess if\nrecipients of federal grants are compliant with program requirements for use of\nfederal funding. Currently, these voluminous audits must be manually analyzed\nby officials for oversight, risk management, and prioritization purposes.\nAutomated summarization has the potential to streamline these processes.\nAnalysis focused on the \"Findings\" section of ~20,000 Single Audits spanning\n2016-2018. Following text preprocessing and GloVe embedding, sentence-level\nk-means clustering was performed to partition sentences by topic and to\nestablish the importance of each sentence. For each audit, key summary\nsentences were extracted by proximity to cluster centroids. Summaries were\njudged by non-expert human evaluation and compared to human-generated summaries\nusing the ROUGE metric. Though the goal was to fully automate summarization of\nA-133 audits, human input was required at various stages due to large\nvariability in audit writing style, content, and context. Examples of human\ninputs include the number of clusters, the choice to keep or discard certain\nclusters based on their content relevance, and the definition of a top\nsentence. Overall, this approach made progress towards automated extractive\nsummaries of A-133 audits, with future work to focus on full automation and\nimproving summary consistency. This work highlights the inherent difficulty and\nsubjective nature of automated summarization in a real-world application.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:49:25 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Chou", "Vivian T.", ""], ["Kent", "LeAnna", ""], ["G\u00f3ngora", "Joel A.", ""], ["Ballerini", "Sam", ""], ["Hoover", "Carl D.", ""]]}, {"id": "1911.06213", "submitter": "Simone Gramsch", "authors": "Simone Gramsch and Alex Sarishvili and Andre Schmei{\\ss}er", "title": "Analysis of the fiber laydown quality in spunbond processes with\n  simulation experiments evaluated by blocked neural networks", "comments": "12 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simulation framework for spunbond processes and use a design of\nexperiments to investigate the cause-and-effect-relations of process and\nmaterial parameters onto the fiber laydown on a conveyor belt. The virtual\nexperiments are analyzed by a blocked neural network. This forms the basis for\nthe prediction of the fiber laydown characteristics and enables a quick ranking\nof the significance of the influencing effects. We conclude our research by an\nanalysis of the nonlinear cause-and-effect relations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:10:01 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 12:45:07 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Gramsch", "Simone", ""], ["Sarishvili", "Alex", ""], ["Schmei\u00dfer", "Andre", ""]]}, {"id": "1911.06217", "submitter": "Tobias Skovgaard Jepsen", "authors": "Tobias Skovgaard Jepsen, Christian S. Jensen, Thomas Dyhre Nielsen", "title": "On Network Embedding for Machine Learning on Road Networks: A Case Study\n  on the Danish Road Network", "comments": "Best Paper at the 3rd IEEE International Workshop on Big Spatial Data\n  (BSD 2018)", "journal-ref": "2018 IEEE International Conference on Big Data (Big Data), 2018,\n  pp. 3422-3431", "doi": "10.1109/BigData.2018.8622416", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road networks are a type of spatial network, where edges may be associated\nwith qualitative information such as road type and speed limit. Unfortunately,\nsuch information is often incomplete; for instance, OpenStreetMap only has\nspeed limits for 13% of all Danish road segments. This is problematic for\nanalysis tasks that rely on such information for machine learning. To enable\nmachine learning in such circumstances, one may consider the application of\nnetwork embedding methods to extract structural information from the network.\nHowever, these methods have so far mostly been used in the context of social\nnetworks, which differ significantly from road networks in terms of, e.g., node\ndegree and level of homophily (which are key to the performance of many network\nembedding methods). We analyze the use of network embedding methods,\nspecifically node2vec, for learning road segment embeddings in road networks.\nDue to the often limited availability of information on other relevant road\ncharacteristics, the analysis focuses on leveraging the spatial network\nstructure. Our results suggest that network embedding methods can indeed be\nused for deriving relevant network features (that may, e.g, be used for\npredicting speed limits), but that the qualities of the embeddings differ from\nembeddings for social networks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:18:36 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 10:51:56 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Jepsen", "Tobias Skovgaard", ""], ["Jensen", "Christian S.", ""], ["Nielsen", "Thomas Dyhre", ""]]}, {"id": "1911.06239", "submitter": "Aditya Narayan Ravi", "authors": "Aditya Narayan Ravi, Pranav Poduval and Dr. Sharayu Moharir", "title": "Unreliable Multi-Armed Bandits: A Novel Approach to Recommendation\n  Systems", "comments": "4 pages, 4 figures, Aditya Narayan Ravi and Pranav Poduval have equal\n  contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a novel modification of Multi-Armed Bandits to create a new model for\nrecommendation systems. We model the recommendation system as a bandit seeking\nto maximize reward by pulling on arms with unknown rewards. The catch however\nis that this bandit can only access these arms through an unreliable\nintermediate that has some level of autonomy while choosing its arms. For\nexample, in a streaming website the user has a lot of autonomy while choosing\ncontent they want to watch. The streaming sites can use targeted advertising as\na means to bias opinions of these users. Here the streaming site is the bandit\naiming to maximize reward and the user is the unreliable intermediate. We model\nthe intermediate as accessing states via a Markov chain. The bandit is allowed\nto perturb this Markov chain. We prove fundamental theorems for this setting\nafter which we show a close-to-optimal Explore-Commit algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:55:29 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ravi", "Aditya Narayan", ""], ["Poduval", "Pranav", ""], ["Moharir", "Dr. Sharayu", ""]]}, {"id": "1911.06242", "submitter": "Fabrizio Ruffini", "authors": "Alessandro Betti (1), Emanuele Crisostomi (2), Gianluca Paolinelli\n  (3), Antonio Piazzi (1), Fabrizio Ruffini (1) and Mauro Tucci (2) ((1) i-EM\n  S.r.l., (2) Department of Energy, Systems, Territory and Constructions\n  Engineering, University of Pisa and (3) Pure Power Control S.r.l.)", "title": "Condition monitoring and early diagnostics methodologies for hydropower\n  plants", "comments": "8 pages, 4 figures. This work has been submitted to the Elsevier\n  Renewable Energy for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydropower plants are one of the most convenient option for power generation,\nas they generate energy exploiting a renewable source, they have relatively low\noperating and maintenance costs, and they may be used to provide ancillary\nservices, exploiting the large reservoirs of available water. The recent\nadvances in Information and Communication Technologies (ICT) and in machine\nlearning methodologies are seen as fundamental enablers to upgrade and\nmodernize the current operation of most hydropower plants, in terms of\ncondition monitoring, early diagnostics and eventually predictive maintenance.\nWhile very few works, or running technologies, have been documented so far for\nthe hydro case, in this paper we propose a novel Key Performance Indicator\n(KPI) that we have recently developed and tested on operating hydropower\nplants. In particular, we show that after more than one year of operation it\nhas been able to identify several faults, and to support the operation and\nmaintenance tasks of plant operators. Also, we show that the proposed KPI\noutperforms conventional multivariable process control charts, like the\nHotelling $t_2$ index.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:15:32 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Betti", "Alessandro", ""], ["Crisostomi", "Emanuele", ""], ["Paolinelli", "Gianluca", ""], ["Piazzi", "Antonio", ""], ["Ruffini", "Fabrizio", ""], ["Tucci", "Mauro", ""]]}, {"id": "1911.06253", "submitter": "Michael Perlmutter", "authors": "Michael Perlmutter and Feng Gao and Guy Wolf and Matthew Hirn", "title": "Understanding Graph Neural Networks with Asymmetric Geometric Scattering\n  Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scattering transform is a multilayered wavelet-based deep learning\narchitecture that acts as a model of convolutional neural networks. Recently,\nseveral works have introduced generalizations of the scattering transform for\nnon-Euclidean settings such as graphs. Our work builds upon these constructions\nby introducing windowed and non-windowed graph scattering transforms based upon\na very general class of asymmetric wavelets. We show that these asymmetric\ngraph scattering transforms have many of the same theoretical guarantees as\ntheir symmetric counterparts. This work helps bridge the gap between scattering\nand other graph neural networks by introducing a large family of networks with\nprovable stability and invariance guarantees. This lays the groundwork for\nfuture deep learning architectures for graph-structured data that have learned\nfilters and also provably have desirable theoretical properties.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:23:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Perlmutter", "Michael", ""], ["Gao", "Feng", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew", ""]]}, {"id": "1911.06256", "submitter": "Luca Della Libera", "authors": "Luca Della Libera", "title": "A Comparative Study between Bayesian and Frequentist Neural Networks for\n  Remaining Useful Life Estimation in Condition-Based Maintenance", "comments": "Withdrawn to resolve an authorship dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, deep learning (DL) has outperformed model-based and\nstatistical approaches in predicting the remaining useful life (RUL) of\nmachinery in the context of condition-based maintenance. One of the major\ndrawbacks of DL is that it heavily depends on a large amount of labeled data,\nwhich are typically expensive and time-consuming to obtain, especially in\nindustrial applications. Scarce training data lead to uncertain estimates of\nthe model's parameters, which in turn result in poor prognostic performance.\nQuantifying this parameter uncertainty is important in order to determine how\nreliable the prediction is. Traditional DL techniques such as neural networks\nare incapable of capturing the uncertainty in the training data, thus they are\noverconfident about their estimates. On the contrary, Bayesian deep learning\nhas recently emerged as a promising solution to account for uncertainty in the\ntraining process, achieving state-of-the-art performance in many classification\nand regression tasks. In this work Bayesian DL techniques such as Bayesian\ndense neural networks and Bayesian convolutional neural networks are applied to\nRUL estimation and compared to their frequentist counterparts from the\nliterature. The effectiveness of the proposed models is verified on the popular\nC-MAPSS dataset. Furthermore, parameter uncertainty is quantified and used to\ngain additional insight into the data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:31:04 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 15:12:36 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Della Libera", "Luca", ""]]}, {"id": "1911.06257", "submitter": "Ahmed Alkhateeb", "authors": "Muhammad Alrabeiah, Andrew Hredzak, Zhenhao Liu, and Ahmed Alkhateeb", "title": "ViWi: A Deep Learning Dataset Framework for Vision-Aided Wireless\n  Communications", "comments": "IEEE VTC 2020. The ViWi datasets and applications are available at\n  https://www.viwi-dataset.net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing role that artificial intelligence and specifically machine\nlearning is playing in shaping the future of wireless communications has opened\nup many new and intriguing research directions. This paper motivates the\nresearch in the novel direction of \\textit{vision-aided wireless\ncommunications}, which aims at leveraging visual sensory information in\ntackling wireless communication problems. Like any new research direction\ndriven by machine learning, obtaining a development dataset poses the first and\nmost important challenge to vision-aided wireless communications. This paper\naddresses this issue by introducing the Vision-Wireless (ViWi) dataset\nframework. It is developed to be a parametric, systematic, and scalable data\ngeneration framework. It utilizes advanced 3D-modeling and ray-tracing\nsoftwares to generate high-fidelity synthetic wireless and vision data samples\nfor the same scenes. The result is a framework that does not only offer a way\nto generate training and testing datasets but helps provide a common ground on\nwhich the quality of different machine learning-powered solutions could be\nassessed.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:32:02 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 13:32:33 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Alrabeiah", "Muhammad", ""], ["Hredzak", "Andrew", ""], ["Liu", "Zhenhao", ""], ["Alkhateeb", "Ahmed", ""]]}, {"id": "1911.06267", "submitter": "Boram Yoon", "authors": "Nga T.T. Nguyen and Garrett T. Kenyon and Boram Yoon", "title": "A regression algorithm for accelerated lattice QCD that exploits sparse\n  inference on the D-Wave quantum annealer", "comments": "12 pages, 4 figures", "journal-ref": "Sci Rep 10, 10915 (2020)", "doi": "10.1038/s41598-020-67769-x", "report-no": "LA-UR-19-31717", "categories": "quant-ph hep-lat stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a regression algorithm that utilizes a learned dictionary\noptimized for sparse inference on a D-Wave quantum annealer. In this regression\nalgorithm, we concatenate the independent and dependent variables as a combined\nvector, and encode the high-order correlations between them into a dictionary\noptimized for sparse reconstruction. On a test dataset, the dependent variable\nis initialized to its average value and then a sparse reconstruction of the\ncombined vector is obtained in which the dependent variable is typically\nshifted closer to its true value, as in a standard inpainting or denoising\ntask. Here, a quantum annealer, which can presumably exploit a fully entangled\ninitial state to better explore the complex energy landscape, is used to solve\nthe highly non-convex sparse coding optimization problem. The regression\nalgorithm is demonstrated for a lattice quantum chromodynamics simulation data\nusing a D-Wave 2000Q quantum annealer and good prediction performance is\nachieved. The regression test is performed using six different values for the\nnumber of fully connected logical qubits, between 20 and 64. The scaling\nresults indicate that a larger number of qubits gives better prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:47:19 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:12:41 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Nguyen", "Nga T. T.", ""], ["Kenyon", "Garrett T.", ""], ["Yoon", "Boram", ""]]}, {"id": "1911.06285", "submitter": "Isaac Corley", "authors": "Isaac Corley, Jonathan Lwowski, Justin Hoffman", "title": "DomainGAN: Generating Adversarial Examples to Attack Domain Generation\n  Algorithm Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Domain Generation Algorithms (DGAs) are frequently used to generate numerous\ndomains for use by botnets. These domains are often utilized as rendezvous\npoints for servers that malware has command and control over. There are many\nalgorithms that are used to generate domains, however many of these algorithms\nare simplistic and easily detected by traditional machine learning techniques.\nIn this paper, three variants of Generative Adversarial Networks (GANs) are\noptimized to generate domains which have similar characteristics of benign\ndomains, resulting in domains which greatly evade several state-of-the-art deep\nlearning based DGA classifiers. We additionally provide a detailed analysis\ninto offensive usability for each variant with respect to repeated and existing\ndomain collisions. Finally, we fine-tune the state-of-the-art DGA classifiers\nby adding GAN generated samples to their original training datasets and analyze\nthe changes in performance. Our results conclude that GAN based DGAs are\nsuperior in evading DGA classifiers in comparison to traditional DGAs, and of\nthe variants, the Wasserstein GAN with Gradient Penalty (WGANGP) is the highest\nperforming DGA for uses both offensively and defensively.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:12:36 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 19:48:07 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 19:08:31 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Corley", "Isaac", ""], ["Lwowski", "Jonathan", ""], ["Hoffman", "Justin", ""]]}, {"id": "1911.06287", "submitter": "Wessel Bruinsma", "authors": "Wessel P. Bruinsma, Eric Perim, Will Tebbutt, J. Scott Hosking, Arno\n  Solin, and Richard E. Turner", "title": "Scalable Exact Inference in Multi-Output Gaussian Processes", "comments": "31 pages, 12 figures, 5 tables, includes appendix; to appear in ICML\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output Gaussian processes (MOGPs) leverage the flexibility and\ninterpretability of GPs while capturing structure across outputs, which is\ndesirable, for example, in spatio-temporal modelling. The key problem with\nMOGPs is their computational scaling $O(n^3 p^3)$, which is cubic in the number\nof both inputs $n$ (e.g., time points or locations) and outputs $p$. For this\nreason, a popular class of MOGPs assumes that the data live around a\nlow-dimensional linear subspace, reducing the complexity to $O(n^3 m^3)$.\nHowever, this cost is still cubic in the dimensionality of the subspace $m$,\nwhich is still prohibitively expensive for many applications. We propose the\nuse of a sufficient statistic of the data to accelerate inference and learning\nin MOGPs with orthogonal bases. The method achieves linear scaling in $m$ in\npractice, allowing these models to scale to large $m$ without sacrificing\nsignificant expressivity or requiring approximation. This advance opens up a\nwide range of real-world tasks and can be combined with existing GP\napproximations in a plug-and-play way. We demonstrate the efficacy of the\nmethod on various synthetic and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:19:22 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:29:46 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 12:10:27 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Bruinsma", "Wessel P.", ""], ["Perim", "Eric", ""], ["Tebbutt", "Will", ""], ["Hosking", "J. Scott", ""], ["Solin", "Arno", ""], ["Turner", "Richard E.", ""]]}, {"id": "1911.06316", "submitter": "Deepjyoti Deka", "authors": "Christopher Hannon, Deepjyoti Deka, Dong Jin, Marc Vuffray, Andrey Y.\n  Lokhov", "title": "Real-time Anomaly Detection and Classification in Streaming PMU Data", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring secure and reliable operations of the power grid is a primary\nconcern of system operators. Phasor measurement units (PMUs) are rapidly being\ndeployed in the grid to provide fast-sampled operational data that should\nenable quicker decision-making. This work presents a general interpretable\nframework for analyzing real-time PMU data, and thus enabling grid operators to\nunderstand the current state and to identify anomalies on the fly. Applying\nstatistical learning tools on the streaming data, we first learn an effective\ndynamical model to describe the current behavior of the system. Next, we use\nthe probabilistic predictions of our learned model to define in a principled\nway an efficient anomaly detection tool. Finally, the last module of our\nframework produces on-the-fly classification of the detected anomalies into\ncommon occurrence classes using features that grid operators are familiar with.\nWe demonstrate the efficacy of our interpretable approach through extensive\nnumerical experiments on real PMU data collected from a transmission operator\nin the USA.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:56:25 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Hannon", "Christopher", ""], ["Deka", "Deepjyoti", ""], ["Jin", "Dong", ""], ["Vuffray", "Marc", ""], ["Lokhov", "Andrey Y.", ""]]}, {"id": "1911.06317", "submitter": "Qiuyi Zhang", "authors": "Daniel Golovin, John Karro, Greg Kochanski, Chansoo Lee, Xingyou Song,\n  Qiuyi Zhang", "title": "Gradientless Descent: High-Dimensional Zeroth-Order Optimization", "comments": "11 main pages, 26 total pages", "journal-ref": "ICLR 2020 Spotlight", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zeroth-order optimization is the process of minimizing an objective $f(x)$,\ngiven oracle access to evaluations at adaptively chosen inputs $x$. In this\npaper, we present two simple yet powerful GradientLess Descent (GLD) algorithms\nthat do not rely on an underlying gradient estimate and are numerically stable.\nWe analyze our algorithm from a novel geometric perspective and present a novel\nanalysis that shows convergence within an $\\epsilon$-ball of the optimum in\n$O(kQ\\log(n)\\log(R/\\epsilon))$ evaluations, for any monotone transform of a\nsmooth and strongly convex objective with latent dimension $k < n$, where the\ninput dimension is $n$, $R$ is the diameter of the input space and $Q$ is the\ncondition number. Our rates are the first of its kind to be both 1)\npoly-logarithmically dependent on dimensionality and 2) invariant under\nmonotone transformations. We further leverage our geometric perspective to show\nthat our analysis is optimal. Both monotone invariance and its ability to\nutilize a low latent dimensionality are key to the empirical success of our\nalgorithms, as demonstrated on BBOB and MuJoCo benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:58:13 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:23:11 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 01:16:07 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 20:08:57 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Golovin", "Daniel", ""], ["Karro", "John", ""], ["Kochanski", "Greg", ""], ["Lee", "Chansoo", ""], ["Song", "Xingyou", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "1911.06319", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "The Canonical Distortion Measure for Vector Quantization and Function\n  Approximation", "comments": null, "journal-ref": "In: Thrun S., Pratt L. (eds) Learning to Learn (1998). Pages\n  159-177", "doi": "10.1007/978-1-4615-5529-2_7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To measure the quality of a set of vector quantization points a means of\nmeasuring the distance between a random point and its quantization is required.\nCommon metrics such as the {\\em Hamming} and {\\em Euclidean} metrics, while\nmathematically simple, are inappropriate for comparing natural signals such as\nspeech or images. In this paper it is shown how an {\\em environment} of\nfunctions on an input space $X$ induces a {\\em canonical distortion measure}\n(CDM) on X. The depiction 'canonical\" is justified because it is shown that\noptimizing the reconstruction error of X with respect to the CDM gives rise to\noptimal piecewise constant approximations of the functions in the environment.\nThe CDM is calculated in closed form for several different function classes. An\nalgorithm for training neural networks to implement the CDM is presented along\nwith some encouraging experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:59:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.06356", "submitter": "Devendra Singh Dhami", "authors": "Devendra Singh Dhami, Siwen Yan, Gautam Kunapuli, David Page and\n  Sriraam Natarajan", "title": "Beyond Textual Data: Predicting Drug-Drug Interactions from Molecular\n  Structure Images using Siamese Neural Networks", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting and discovering drug-drug interactions (DDIs) is an important\nproblem and has been studied extensively both from medical and machine learning\npoint of view. Almost all of the machine learning approaches have focused on\ntext data or textual representation of the structural data of drugs. We present\nthe first work that uses drug structure images as the input and utilizes a\nSiamese convolutional network architecture to predict DDIs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:51:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 04:57:42 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dhami", "Devendra Singh", ""], ["Yan", "Siwen", ""], ["Kunapuli", "Gautam", ""], ["Page", "David", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1911.06363", "submitter": "Feng Jin", "authors": "Feng Jin, Renyuan Zhang, Arindam Sengupta, Siyang Cao, Salim Hariri,\n  Nimit K. Agarwal and Sumit K. Agarwal", "title": "Multiple Patients Behavior Detection in Real-time using mmWave Radar and\n  Deep CNNs", "comments": "This paper has been submitted to IEEE Radar Conference 2019", "journal-ref": null, "doi": "10.1109/RADAR.2019.8835656", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address potential gaps noted in patient monitoring in the hospital, a\nnovel patient behavior detection system using mmWave radar and deep convolution\nneural network (CNN), which supports the simultaneous recognition of multiple\npatients' behaviors in real-time, is proposed. In this study, we use an mmWave\nradar to track multiple patients and detect the scattering point cloud of each\none. For each patient, the Doppler pattern of the point cloud over a time\nperiod is collected as the behavior signature. A three-layer CNN model is\ncreated to classify the behavior for each patient. The tracking and point\nclouds detection algorithm was also implemented on an mmWave radar hardware\nplatform with an embedded graphics processing unit (GPU) board to collect\nDoppler pattern and run the CNN model. A training dataset of six types of\nbehavior were collected, over a long duration, to train the model using Adam\noptimizer with an objective to minimize cross-entropy loss function. Lastly,\nthe system was tested for real-time operation and obtained a very good\ninference accuracy when predicting each patient's behavior in a two-patient\nscenario.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:59:56 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jin", "Feng", ""], ["Zhang", "Renyuan", ""], ["Sengupta", "Arindam", ""], ["Cao", "Siyang", ""], ["Hariri", "Salim", ""], ["Agarwal", "Nimit K.", ""], ["Agarwal", "Sumit K.", ""]]}, {"id": "1911.06364", "submitter": "Feng Jin", "authors": "Feng Jin, Arindam Sengupta, Siyang Cao and Yao-Jan Wu", "title": "MmWave Radar Point Cloud Segmentation using GMM in Multimodal Traffic\n  Monitoring", "comments": "This paper has been accepted by the IEEE International Radar\n  Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multimodal traffic monitoring, we gather traffic statistics for distinct\ntransportation modes, such as pedestrians, cars and bicycles, in order to\nanalyze and improve people's daily mobility in terms of safety and convenience.\nOn account of its robustness to bad light and adverse weather conditions, and\ninherent speed measurement ability, the radar sensor is a suitable option for\nthis application. However, the sparse radar data from conventional commercial\nradars make it extremely challenging for transportation mode classification.\nThus, we propose to use a high-resolution millimeter-wave(mmWave) radar sensor\nto obtain a relatively richer radar point cloud representation for a traffic\nmonitoring scenario. Based on a new feature vector, we use the multivariate\nGaussian mixture model (GMM) to do the radar point cloud segmentation, i.e.\n`point-wise' classification, in an unsupervised learning environment. In our\nexperiment, we collected radar point clouds for pedestrians and cars, which\nalso contained the inevitable clutter from the surroundings. The experimental\nresults using GMM on the new feature vector demonstrated a good segmentation\nperformance in terms of the intersection-over-union (IoU) metrics. The detailed\nmethodology and validation metrics are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 20:00:53 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 04:08:44 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 17:58:19 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Jin", "Feng", ""], ["Sengupta", "Arindam", ""], ["Cao", "Siyang", ""], ["Wu", "Yao-Jan", ""]]}, {"id": "1911.06379", "submitter": "Andr\\'es Almansa", "authors": "Mario Gonz\\'alez, Andr\\'es Almansa, Mauricio Delbracio, Pablo Mus\\'e,\n  Pauline Tan", "title": "Solving Inverse Problems by Joint Posterior Maximization with a VAE\n  Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we address the problem of solving ill-posed inverse problems in\nimaging where the prior is a neural generative model. Specifically we consider\nthe decoupled case where the prior is trained once and can be reused for many\ndifferent log-concave degradation models without retraining. Whereas previous\nMAP-based approaches to this problem lead to highly non-convex optimization\nalgorithms, our approach computes the joint (space-latent) MAP that naturally\nleads to alternate optimization algorithms and to the use of a stochastic\nencoder to accelerate computations. The resulting technique is called JPMAP\nbecause it performs Joint Posterior Maximization using an Autoencoding Prior.\nWe show theoretical and experimental evidence that the proposed objective\nfunction is quite close to bi-convex. Indeed it satisfies a weak bi-convexity\nproperty which is sufficient to guarantee that our optimization scheme\nconverges to a stationary point.\n  Experimental results also show the higher quality of the solutions obtained\nby our JPMAP approach with respect to other non-convex MAP approaches which\nmore often get stuck in spurious local optima.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 20:52:09 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Gonz\u00e1lez", "Mario", ""], ["Almansa", "Andr\u00e9s", ""], ["Delbracio", "Mauricio", ""], ["Mus\u00e9", "Pablo", ""], ["Tan", "Pauline", ""]]}, {"id": "1911.06382", "submitter": "Ahmed Abbasi", "authors": "Ahmed Abbasi, Abiy Tasissa, Shuchin Aeron", "title": "Unlabeled sensing with local permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlabeled sensing is a linear inverse problem where the measurements are\nscrambled under an unknown permutation leading to loss of correspondence\nbetween the measurements and the rows of the sensing matrix. Motivated by\npractical tasks such as mobile sensor networks, target tracking and the pose\nand correspondence estimation between point clouds, we study a special case of\nthis problem restricting the class of permutations to be local and allowing for\nmultiple views. In this setting, namely unlabeled multi-view sensing with local\npermutation, previous results and algorithms are not directly applicable. In\nthis paper, we propose a computationally efficient algorithm that creatively\nexploits the machinery of graph alignment and Gromov-Wasserstein alignment and\nleverages the multiple views to estimate the local permutations. Simulation\nresults on synthetic data sets indicate that the proposed algorithm is scalable\nand applicable to the challenging regimes of low to moderate SNR.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 20:57:35 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 14:17:01 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 21:09:53 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Abbasi", "Ahmed", ""], ["Tasissa", "Abiy", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1911.06393", "submitter": "Daniel Stoller", "authors": "Daniel Stoller, Mi Tian, Sebastian Ewert, Simon Dixon", "title": "Seq-U-Net: A One-Dimensional Causal U-Net for Efficient Sequence\n  Modelling", "comments": "Code available at https://github.com/f90/Seq-U-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) with dilated filters such as the Wavenet\nor the Temporal Convolutional Network (TCN) have shown good results in a\nvariety of sequence modelling tasks. However, efficiently modelling long-term\ndependencies in these sequences is still challenging. Although the receptive\nfield of these models grows exponentially with the number of layers, computing\nthe convolutions over very long sequences of features in each layer is time and\nmemory-intensive, prohibiting the use of longer receptive fields in practice.\nTo increase efficiency, we make use of the \"slow feature\" hypothesis stating\nthat many features of interest are slowly varying over time. For this, we use a\nU-Net architecture that computes features at multiple time-scales and adapt it\nto our auto-regressive scenario by making convolutions causal. We apply our\nmodel (\"Seq-U-Net\") to a variety of tasks including language and audio\ngeneration. In comparison to TCN and Wavenet, our network consistently saves\nmemory and computation time, with speed-ups for training and inference of over\n4x in the audio generation experiment in particular, while achieving a\ncomparable performance in all tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 21:39:20 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Stoller", "Daniel", ""], ["Tian", "Mi", ""], ["Ewert", "Sebastian", ""], ["Dixon", "Simon", ""]]}, {"id": "1911.06407", "submitter": "Ahmed El-Kishky", "authors": "Hyungsul Kim, Ahmed El-Kishky, Xiang Ren, Jiawei Han", "title": "Mining News Events from Comparable News Corpora: A Multi-Attribute\n  Proximity Network Modeling Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ProxiModel, a novel event mining framework for extracting\nhigh-quality structured event knowledge from large, redundant, and noisy news\ndata sources. The proposed model differentiates itself from other approaches by\nmodeling both the event correlation within each individual document as well as\nacross the corpus. To facilitate this, we introduce the concept of a\nproximity-network, a novel space-efficient data structure to facilitate\nscalable event mining. This proximity network captures the corpus-level\nco-occurence statistics for candidate event descriptors, event attributes, as\nwell as their connections. We probabilistically model the proximity network as\na generative process with sparsity-inducing regularization. This allows us to\nefficiently and effectively extract high-quality and interpretable news events.\nExperiments on three different news corpora demonstrate that the proposed\nmethod is effective and robust at generating high-quality event descriptors and\nattributes. We briefly detail many interesting applications from our proposed\nframework such as news summarization, event tracking and multi-dimensional\nanalysis on news. Finally, we explore a case study on visualizing the events\nfor a Japan Tsunami news corpus and demonstrate ProxiModel's ability to\nautomatically summarize emerging news events.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 22:22:12 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kim", "Hyungsul", ""], ["El-Kishky", "Ahmed", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "1911.06410", "submitter": "Andrew Dai", "authors": "Kun Zhang, Yuan Xue, Gerardo Flores, Alvin Rajkomar, Claire Cui,\n  Andrew M. Dai", "title": "Modelling EHR timeseries by restricting feature interaction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data are prevalent in electronic health records, mostly in the\nform of physiological parameters such as vital signs and lab tests. The\npatterns of these values may be significant indicators of patients' clinical\nstates and there might be patterns that are unknown to clinicians but are\nhighly predictive of some outcomes. Many of these values are also missing which\nmakes it difficult to apply existing methods like decision trees. We propose a\nrecurrent neural network model that reduces overfitting to noisy observations\nby limiting interactions between features. We analyze its performance on\nmortality, ICD-9 and AKI prediction from observational values on the Medical\nInformation Mart for Intensive Care III (MIMIC-III) dataset. Our models result\nin an improvement of 1.1% [p<0.01] in AU-ROC for mortality prediction under the\nMetaVision subset and 1.0% and 2.2% [p<0.01] respectively for mortality and AKI\nunder the full MIMIC-III dataset compared to existing state-of-the-art\ninterpolation, embedding and decay-based recurrent models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:06:11 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Zhang", "Kun", ""], ["Xue", "Yuan", ""], ["Flores", "Gerardo", ""], ["Rajkomar", "Alvin", ""], ["Cui", "Claire", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1911.06411", "submitter": "Saloni Dash", "authors": "Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, Andrew Yale,\n  Kristin P. Bennett", "title": "Synthetic Event Time Series Health Data Generation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic medical data which preserves privacy while maintaining utility can\nbe used as an alternative to real medical data, which has privacy costs and\nresource constraints associated with it. At present, most models focus on\ngenerating cross-sectional health data which is not necessarily representative\nof real data. In reality, medical data is longitudinal in nature, with a single\npatient having multiple health events, non-uniformly distributed throughout\ntheir lifetime. These events are influenced by patient covariates such as\ncomorbidities, age group, gender etc. as well as external temporal effects\n(e.g. flu season). While there exist seminal methods to model time series data,\nit becomes increasingly challenging to extend these methods to medical event\ntime series data. Due to the complexity of the real data, in which each patient\nvisit is an event, we transform the data by using summary statistics to\ncharacterize the events for a fixed set of time intervals, to facilitate\nanalysis and interpretability. We then train a generative adversarial network\nto generate synthetic data. We demonstrate this approach by generating human\nsleep patterns, from a publicly available dataset. We empirically evaluate the\ngenerated data and show close univariate resemblance between synthetic and real\ndata. However, we also demonstrate how stratification by covariates is required\nto gain a deeper understanding of synthetic data quality.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:11:19 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 18:47:20 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Dash", "Saloni", ""], ["Dutta", "Ritik", ""], ["Guyon", "Isabelle", ""], ["Pavao", "Adrien", ""], ["Yale", "Andrew", ""], ["Bennett", "Kristin P.", ""]]}, {"id": "1911.06446", "submitter": "Kexin Huang", "authors": "Kexin Huang, Cao Xiao, Trong Nghia Hoang, Lucas M. Glass, Jimeng Sun", "title": "CASTER: Predicting Drug Interactions with Chemical Substructure\n  Representation", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug-drug interactions (DDIs) remain a leading cause of morbidity and\nmortality. Identifying potential DDIs during the drug design process is\ncritical for patients and society. Although several computational models have\nbeen proposed for DDI prediction, there are still limitations: (1) specialized\ndesign of drug representation for DDI predictions is lacking; (2) predictions\nare based on limited labelled data and do not generalize well to unseen drugs\nor DDIs; and (3) models are characterized by a large number of parameters, thus\nare hard to interpret. In this work, we develop a ChemicAl SubstrucTurE\nRepresentation (CASTER) framework that predicts DDIs given chemical structures\nof drugs.CASTER aims to mitigate these limitations via (1) a sequential pattern\nmining module rooted in the DDI mechanism to efficiently characterize\nfunctional sub-structures of drugs; (2) an auto-encoding module that leverages\nboth labelled and unlabelled chemical structure data to improve predictive\naccuracy and generalizability; and (3) a dictionary learning module that\nexplains the prediction via a small set of coefficients which measure the\nrelevance of each input sub-structures to the DDI outcome. We evaluated CASTER\non two real-world DDI datasets and showed that it performed better than\nstate-of-the-art baselines and provided interpretable predictions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 01:50:44 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:55:01 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Huang", "Kexin", ""], ["Xiao", "Cao", ""], ["Hoang", "Trong Nghia", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.06455", "submitter": "Seongjun Yun", "authors": "Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, Hyunwoo J. Kim", "title": "Graph Transformer Networks", "comments": "Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in representation learning\non graphs and achieved state-of-the-art performance in tasks such as node\nclassification and link prediction. However, most existing GNNs are designed to\nlearn node representations on the fixed and homogeneous graphs. The limitations\nespecially become problematic when learning representations on a misspecified\ngraph or a heterogeneous graph that consists of various types of nodes and\nedges. In this paper, we propose Graph Transformer Networks (GTNs) that are\ncapable of generating new graph structures, which involve identifying useful\nconnections between unconnected nodes on the original graph, while learning\neffective node representation on the new graphs in an end-to-end fashion. Graph\nTransformer layer, a core layer of GTNs, learns a soft selection of edge types\nand composite relations for generating useful multi-hop connections so-called\nmeta-paths. Our experiments show that GTNs learn new graph structures, based on\ndata and tasks without domain knowledge, and yield powerful node representation\nvia convolution on the new graphs. Without domain-specific graph preprocessing,\nGTNs achieved the best performance in all three benchmark node classification\ntasks against the state-of-the-art methods that require pre-defined meta-paths\nfrom domain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 06:40:05 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 04:23:19 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Yun", "Seongjun", ""], ["Jeong", "Minbyul", ""], ["Kim", "Raehyun", ""], ["Kang", "Jaewoo", ""], ["Kim", "Hyunwoo J.", ""]]}, {"id": "1911.06459", "submitter": "Haidar Khan", "authors": "Michael P. Perrone, Haidar Khan, Changhoan Kim, Anastasios Kyrillidis,\n  Jerry Quinn, Valentina Salapura", "title": "Optimal Mini-Batch Size Selection for Fast Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for selecting the mini-batch size that\nminimizes Stochastic Gradient Descent (SGD) learning time for single and\nmultiple learner problems. By decoupling algorithmic analysis issues from\nhardware and software implementation details, we reveal a robust empirical\ninverse law between mini-batch size and the average number of SGD updates\nrequired to converge to a specified error threshold. Combining this empirical\ninverse law with measured system performance, we create an accurate,\nclosed-form model of average training time and show how this model can be used\nto identify quantifiable implications for both algorithmic and hardware aspects\nof machine learning. We demonstrate the inverse law empirically, on both image\nrecognition (MNIST, CIFAR10 and CIFAR100) and machine translation (Europarl)\ntasks, and provide a theoretic justification via proving a novel bound on\nmini-batch SGD training.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 03:07:27 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Perrone", "Michael P.", ""], ["Khan", "Haidar", ""], ["Kim", "Changhoan", ""], ["Kyrillidis", "Anastasios", ""], ["Quinn", "Jerry", ""], ["Salapura", "Valentina", ""]]}, {"id": "1911.06465", "submitter": "Tarik Dzanic", "authors": "Tarik Dzanic, Karan Shah, and Freddie Witherden", "title": "Fourier Spectrum Discrepancies in Deep Network Generated Images", "comments": "11 pages, 7 figures", "journal-ref": "Neural Information Processing Systems 33 (2020) 3022-3032", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in deep generative models such as generative adversarial\nnetworks and variational autoencoders have resulted in the ability to generate\nrealistic images that are visually indistinguishable from real images, which\nraises concerns about their potential malicious usage. In this paper, we\npresent an analysis of the high-frequency Fourier modes of real and deep\nnetwork generated images and show that deep network generated images share an\nobservable, systematic shortcoming in replicating the attributes of these\nhigh-frequency modes. Using this, we propose a detection method based on the\nfrequency spectrum of the images which is able to achieve an accuracy of up to\n99.2% in classifying real and deep network generated images from various GAN\nand VAE architectures on a dataset of 5000 images with as few as 8 training\nexamples. Furthermore, we show the impact of image transformations such as\ncompression, cropping, and resolution reduction on the classification accuracy\nand suggest a method for modifying the high-frequency attributes of deep\nnetwork generated images to mimic real images.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 03:55:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:57:52 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:29:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dzanic", "Tarik", ""], ["Shah", "Karan", ""], ["Witherden", "Freddie", ""]]}, {"id": "1911.06468", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin", "title": "$\\ell_{\\infty}$ Vector Contraction for Rademacher Complexity", "comments": "Technical note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Rademacher complexity of any $\\mathbb{R}^{K}$-valued\nfunction class composed with an $\\ell_{\\infty}$-Lipschitz function is bounded\nby the maximum Rademacher complexity of the restriction of the function class\nalong each coordinate, times a factor of $\\tilde{O}(\\sqrt{K})$.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:04:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1911.06471", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi and Mohammad Samragh and Tara Javidi and Farinaz\n  Koushanfar", "title": "ASCAI: Adaptive Sampling for acquiring Compact AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces ASCAI, a novel adaptive sampling methodology that can\nlearn how to effectively compress Deep Neural Networks (DNNs) for accelerated\ninference on resource-constrained platforms. Modern DNN compression techniques\ncomprise various hyperparameters that require per-layer customization to ensure\nhigh accuracy. Choosing such hyperparameters is cumbersome as the pertinent\nsearch space grows exponentially with the number of model layers. To\neffectively traverse this large space, we devise an intelligent sampling\nmechanism that adapts the sampling strategy using customized operations\ninspired by genetic algorithms. As a special case, we consider the space of\nmodel compression as a vector space. The adaptively selected samples enable\nASCAI to automatically learn how to tune per-layer compression hyperparameters\nto optimize the accuracy/model-size trade-off. Our extensive evaluations show\nthat ASCAI outperforms rule-based and reinforcement learning methods in terms\nof compression rate and/or accuracy\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:13:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Samragh", "Mohammad", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1911.06472", "submitter": "Prithwish Chakraborty", "authors": "Prithwish Chakraborty and Fei Wang and Jianying Hu and Daby Sow", "title": "Explicit-Blurred Memory Network for Analyzing Patient Electronic Health\n  Records", "comments": "accepted to DSHealth 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have witnessed an increased interest in temporal modeling\nof patient records from large scale Electronic Health Records (EHR). While\nsimpler RNN models have been used for such problems, memory networks, which in\nother domains were found to generalize well, are underutilized. Traditional\nmemory networks involve diffused and non-linear operations where influence of\npast events on outputs are not readily quantifiable. We posit that this lack of\ninterpretability makes such networks not applicable for EHR analysis. While\nnetworks with explicit memory have been proposed recently, the discontinuities\nimposed by the discrete operations make such networks harder to train and\nrequire more supervision. The problem is further exacerbated in the limited\ndata setting of EHR studies. In this paper, we propose a novel memory\narchitecture that is more interpretable than traditional memory networks while\nbeing easier to train than explicit memory banks. Inspired by well-known models\nof human cognition, we propose partitioning the external memory space into (a)\na primary explicit memory block to store exact replicas of recent events to\nsupport interpretations, followed by (b) a secondary blurred memory block that\naccumulates salient aspects of past events dropped from the explicit block as\nhigher level abstractions and allow training with less supervision by stabilize\nthe gradients. We apply the model for 3 learning problems on ICU records from\nthe MIMIC III database spanning millions of data points. Our model performs\ncomparably to the state-of the art while also, crucially, enabling ready\ninterpretation of the results.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:19:26 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 19:08:58 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Chakraborty", "Prithwish", ""], ["Wang", "Fei", ""], ["Hu", "Jianying", ""], ["Sow", "Daby", ""]]}, {"id": "1911.06478", "submitter": "Mingi Ji", "authors": "Mingi Ji, Weonyoung Joo, Kyungwoo Song, Yoon-Yeong Kim, Il-Chul Moon", "title": "Sequential Recommendation with Relation-Aware Kernelized Self-Attention", "comments": "8 pages, 5 figures, AAAI", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies identified that sequential Recommendation is improved by the\nattention mechanism. By following this development, we propose Relation-Aware\nKernelized Self-Attention (RKSA) adopting a self-attention mechanism of the\nTransformer with augmentation of a probabilistic model. The original\nself-attention of Transformer is a deterministic measure without\nrelation-awareness. Therefore, we introduce a latent space to the\nself-attention, and the latent space models the recommendation context from\nrelation as a multivariate skew-normal distribution with a kernelized\ncovariance matrix from co-occurrences, item characteristics, and user\ninformation. This work merges the self-attention of the Transformer and the\nsequential recommendation by adding a probabilistic model of the recommendation\ntask specifics. We experimented RKSA over the benchmark datasets, and RKSA\nshows significant improvements compared to the recent baseline models. Also,\nRKSA were able to produce a latent space model that answers the reasons for\nrecommendation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:54:54 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ji", "Mingi", ""], ["Joo", "Weonyoung", ""], ["Song", "Kyungwoo", ""], ["Kim", "Yoon-Yeong", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1911.06479", "submitter": "Shufei Zhang Mr", "authors": "Shufei Zhang and Kaizhu Huang and Zenglin Xu", "title": "On Model Robustness Against Adversarial Examples", "comments": "some theoretical bounds need to be revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model robustness against adversarial examples, referred to as\nsmall perturbed input data that may however fool many state-of-the-art deep\nlearning models. Unlike previous research, we establish a novel theory\naddressing the robustness issue from the perspective of stability of the loss\nfunction in the small neighborhood of natural examples. We propose to exploit\nan energy function to describe the stability and prove that reducing such\nenergy guarantees the robustness against adversarial examples. We also show\nthat the traditional training methods including adversarial training with the\n$l_2$ norm constraint (AT) and Virtual Adversarial Training (VAT) tend to\nminimize the lower bound of our proposed energy function. We make an analysis\nshowing that minimization of such lower bound can however lead to insufficient\nrobustness within the neighborhood around the input sample. Furthermore, we\ndesign a more rational method with the energy regularization which proves to\nachieve better robustness than previous methods. Through a series of\nexperiments, we demonstrate the superiority of our model on both supervised\ntasks and semi-supervised tasks. In particular, our proposed adversarial\nframework achieves the best performance compared with previous adversarial\ntraining methods on benchmark datasets MNIST, CIFAR-10, and SVHN. Importantly,\nthey demonstrate much better robustness against adversarial examples than all\nthe other comparison methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 05:02:25 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 05:26:51 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhang", "Shufei", ""], ["Huang", "Kaizhu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.06487", "submitter": "Qi She", "authors": "Qi She, Fan Feng, Xinyue Hao, Qihan Yang, Chuanlin Lan, Vincenzo\n  Lomonaco, Xuesong Shi, Zhengwei Wang, Yao Guo, Yimin Zhang, Fei Qiao, Rosa H.\n  M. Chan", "title": "OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong\n  Deep Learning", "comments": "7 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent breakthroughs in computer vision have benefited from the\navailability of large representative datasets (e.g. ImageNet and COCO) for\ntraining. Yet, robotic vision poses unique challenges for applying visual\nalgorithms developed from these standard computer vision datasets due to their\nimplicit assumption over non-varying distributions for a fixed set of tasks.\nFully retraining models each time a new task becomes available is infeasible\ndue to computational, storage and sometimes privacy issues, while na\\\"{i}ve\nincremental strategies have been shown to suffer from catastrophic forgetting.\nIt is crucial for the robots to operate continuously under open-set and\ndetrimental conditions with adaptive visual perceptual systems, where lifelong\nlearning is a fundamental capability. However, very few datasets and benchmarks\nare available to evaluate and compare emerging techniques. To fill this gap, we\nprovide a new lifelong robotic vision dataset (\"OpenLORIS-Object\") collected\nvia RGB-D cameras. The dataset embeds the challenges faced by a robot in the\nreal-life application and provides new benchmarks for validating lifelong\nobject recognition algorithms. Moreover, we have provided a testbed of $9$\nstate-of-the-art lifelong learning algorithms. Each of them involves $48$ tasks\nwith $4$ evaluation metrics over the OpenLORIS-Object dataset. The results\ndemonstrate that the object recognition task in the ever-changing difficulty\nenvironments is far from being solved and the bottlenecks are at the\nforward/backward transfer designs. Our dataset and benchmark are publicly\navailable at at\n\\href{https://lifelong-robotic-vision.github.io/dataset/object}{\\underline{https://lifelong-robotic-vision.github.io/dataset/object}}.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:27:27 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 05:31:06 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["She", "Qi", ""], ["Feng", "Fan", ""], ["Hao", "Xinyue", ""], ["Yang", "Qihan", ""], ["Lan", "Chuanlin", ""], ["Lomonaco", "Vincenzo", ""], ["Shi", "Xuesong", ""], ["Wang", "Zhengwei", ""], ["Guo", "Yao", ""], ["Zhang", "Yimin", ""], ["Qiao", "Fei", ""], ["Chan", "Rosa H. M.", ""]]}, {"id": "1911.06505", "submitter": "Szabolcs-Botond L\\H{o}rincz", "authors": "Szabolcs-Botond L\\H{o}rincz, Szabolcs P\\'avel and Lehel Csat\\'o", "title": "Single View Distortion Correction using Semantic Guidance", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852065", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most distortion correction methods focus on simple forms of distortion, such\nas radial or linear distortions. These works undistort images either based on\nmeasurements in the presence of a calibration grid, or use multiple views to\nfind point correspondences and predict distortion parameters. When possible\ndistortions are more complex, e.g. in the case of a camera being placed behind\na refractive surface such as glass, the standard method is to use a calibration\ngrid. Considering a high variety of distortions, it is nonviable to conduct\nthese measurements. In this work, we present a single view distortion\ncorrection method which is capable of undistorting images containing\narbitrarily complex distortions by exploiting recent advancements in\ndifferentiable image sampling and in the usage of semantic information to\naugment various tasks. The results of this work show that our model is able to\nestimate and correct highly complex distortions, and that incorporating\nsemantic information mitigates the process of image undistortion.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:05:49 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["L\u0151rincz", "Szabolcs-Botond", ""], ["P\u00e1vel", "Szabolcs", ""], ["Csat\u00f3", "Lehel", ""]]}, {"id": "1911.06515", "submitter": "Ryo Kamoi", "authors": "Ryo Kamoi, Kei Kobayashi", "title": "Likelihood Assignment for Out-of-Distribution Inputs in Deep Generative\n  Models is Sensitive to Prior Distribution Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep generative models assign higher likelihood to\nout-of-distribution inputs than to training data. We show that a factor\nunderlying this phenomenon is a mismatch between the nature of the prior\ndistribution and that of the data distribution, a problem found in widely used\ndeep generative models such as VAEs and Glow. While a typical choice for a\nprior distribution is a standard Gaussian distribution, properties of\ndistributions of real data sets may not be consistent with a unimodal prior\ndistribution. This paper focuses on the relationship between the choice of a\nprior distribution and the likelihoods assigned to out-of-distribution inputs.\nWe propose the use of a mixture distribution as a prior to make likelihoods\nassigned by deep generative models sensitive to out-of-distribution inputs.\nFurthermore, we explain the theoretical advantages of adopting a mixture\ndistribution as the prior, and we present experimental results to support our\nclaims. Finally, we demonstrate that a mixture prior lowers the\nout-of-distribution likelihood with respect to two pairs of real image data\nsets: Fashion-MNIST vs. MNIST and CIFAR10 vs. SVHN.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:40:45 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kamoi", "Ryo", ""], ["Kobayashi", "Kei", ""]]}, {"id": "1911.06537", "submitter": "Graziano Mita", "authors": "Graziano Mita, Paolo Papotti, Maurizio Filippone, Pietro Michiardi", "title": "LIBRE: Learning Interpretable Boolean Rule Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method - LIBRE - to learn an interpretable classifier,\nwhich materializes as a set of Boolean rules. LIBRE uses an ensemble of\nbottom-up weak learners operating on a random subset of features, which allows\nfor the learning of rules that generalize well on unseen data even in\nimbalanced settings. Weak learners are combined with a simple union so that the\nfinal ensemble is also interpretable. Experimental results indicate that LIBRE\nefficiently strikes the right balance between prediction accuracy, which is\ncompetitive with black box methods, and interpretability, which is often\nsuperior to alternative methods from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:45:31 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Mita", "Graziano", ""], ["Papotti", "Paolo", ""], ["Filippone", "Maurizio", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1911.06557", "submitter": "Liang Yang", "authors": "Liang Yang, Xi-Zhu Wu, Yuan Jiang, Zhi-Hua Zhou", "title": "Multi-Label Learning with Deep Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-label learning, each instance is associated with multiple labels and\nthe crucial task is how to leverage label correlations in building models. Deep\nneural network methods usually jointly embed the feature and label information\ninto a latent space to exploit label correlations. However, the success of\nthese methods highly depends on the precise choice of model depth. Deep forest\nis a recent deep learning framework based on tree model ensembles, which does\nnot rely on backpropagation. We consider the advantages of deep forest models\nare very appropriate for solving multi-label problems. Therefore we design the\nMulti-Label Deep Forest (MLDF) method with two mechanisms: measure-aware\nfeature reuse and measure-aware layer growth. The measure-aware feature reuse\nmechanism reuses the good representation in the previous layer guided by\nconfidence. The measure-aware layer growth mechanism ensures MLDF gradually\nincrease the model complexity by performance measure. MLDF handles two\nchallenging problems at the same time: one is restricting the model complexity\nto ease the overfitting issue; another is optimizing the performance measure on\nuser's demand since there are many different measures in the multi-label\nevaluation. Experiments show that our proposal not only beats the compared\nmethods over six measures on benchmark datasets but also enjoys label\ncorrelation discovery and other desired properties in multi-label learning.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 10:40:12 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Yang", "Liang", ""], ["Wu", "Xi-Zhu", ""], ["Jiang", "Yuan", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1911.06615", "submitter": "D\\'avid Sztah\\'o", "authors": "D\\'avid Sztah\\'o, Gy\\\"orgy Szasz\\'ak, Andr\\'as Beke", "title": "Deep learning methods in speaker recognition: a review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the applied deep learning practices in the field of\nspeaker recognition, both verification and identification. Speaker recognition\nhas been a widely used field topic of speech technology. Many research works\nhave been carried out and little progress has been achieved in the past 5-6\nyears. However, as deep learning techniques do advance in most machine learning\nfields, the former state-of-the-art methods are getting replaced by them in\nspeaker recognition too. It seems that DL becomes the now state-of-the-art\nsolution for both speaker verification and identification. The standard\nx-vectors, additional to i-vectors, are used as baseline in most of the novel\nworks. The increasing amount of gathered data opens up the territory to DL,\nwhere they are the most effective.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 12:32:07 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sztah\u00f3", "D\u00e1vid", ""], ["Szasz\u00e1k", "Gy\u00f6rgy", ""], ["Beke", "Andr\u00e1s", ""]]}, {"id": "1911.06616", "submitter": "G\\\"unter Klambauer", "authors": "Susanne Kimeswenger, Elisabeth Rumetshofer, Markus Hofmarcher, Philipp\n  Tschandl, Harald Kittler, Sepp Hochreiter, Wolfram H\\\"otzenecker, G\\\"unter\n  Klambauer", "title": "Detecting cutaneous basal cell carcinomas in ultra-high resolution and\n  weakly labelled histopathological images", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing basal cell carcinomas (BCC), one of the most common cutaneous\nmalignancies in humans, is a task regularly performed by pathologists and\ndermato-pathologists. Improving histological diagnosis by providing diagnosis\nsuggestions, i.e. computer-assisted diagnoses is actively researched to improve\nsafety, quality and efficiency. Increasingly, machine learning methods are\napplied due to their superior performance. However, typical images obtained by\nscanning histological sections often have a resolution that is prohibitive for\nprocessing with current state-of-the-art neural networks. Furthermore, the data\npose a problem of weak labels, since only a tiny fraction of the image is\nindicative of the disease class, whereas a large fraction of the image is\nhighly similar to the non-disease class. The aim of this study is to evaluate\nwhether it is possible to detect basal cell carcinomas in histological sections\nusing attention-based deep learning models and to overcome the ultra-high\nresolution and the weak labels of whole slide images. We demonstrate that\nattention-based models can indeed yield almost perfect classification\nperformance with an AUC of 0.99.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:45:59 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 08:41:40 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 10:35:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kimeswenger", "Susanne", ""], ["Rumetshofer", "Elisabeth", ""], ["Hofmarcher", "Markus", ""], ["Tschandl", "Philipp", ""], ["Kittler", "Harald", ""], ["Hochreiter", "Sepp", ""], ["H\u00f6tzenecker", "Wolfram", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "1911.06646", "submitter": "David Cortes", "authors": "David Cortes", "title": "Imputing missing values with unsupervised random trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a non-iterative strategy for missing value imputations\nwhich is guided by similarity between observations, but instead of explicitly\ndetermining distances or nearest neighbors, it assigns observations to\noverlapping buckets through recursive semi-random hyperplane cuts, in which\nweighted averages are determined as imputations for each variable. The quality\nof these imputations is oftentimes not as good as that of chained equations,\nbut the proposed technique is much faster, non-iterative, can make imputations\non new data without re-calculating anything, and scales easily to large and\nhigh-dimensional datasets, providing a significant boost over simple\nmean/median imputation in regression and classification metrics with imputed\nvalues when other methods are not feasible.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:12:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 20:47:01 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "1911.06663", "submitter": "Matthias Schubert", "authors": "Teodora Pandeva and Matthias Schubert", "title": "MMGAN: Generative Adversarial Networks for Multi-Modal Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, Generative Adversarial Networks (GANs) have shown a\nremarkable generation performance especially in image synthesis. Unfortunately,\nthey are also known for having an unstable training process and might loose\nparts of the data distribution for heterogeneous input data. In this paper, we\npropose a novel GAN extension for multi-modal distribution learning (MMGAN). In\nour approach, we model the latent space as a Gaussian mixture model with a\nnumber of clusters referring to the number of disconnected data manifolds in\nthe observation space, and include a clustering network, which relates each\ndata manifold to one Gaussian cluster. Thus, the training gets more stable.\nMoreover, MMGAN allows for clustering real data according to the learned data\nmanifold in the latent space. By a series of benchmark experiments, we\nillustrate that MMGAN outperforms competitive state-of-the-art models in terms\nof clustering performance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:31:02 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Pandeva", "Teodora", ""], ["Schubert", "Matthias", ""]]}, {"id": "1911.06671", "submitter": "Heng Xiao", "authors": "Zeng Yang, Jin-Long Wu, Heng Xiao", "title": "Enforcing Deterministic Constraints on Generative Adversarial Networks\n  for Emulating Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) were initially proposed to generate\nimages by learning from a large number of samples. Recently, GANs have been\nused to emulate complex physical systems such as turbulent flows. However, a\ncritical question must be answered before GANs can be considered trusted\nemulators for physical systems: do GANs-generated samples conform to the\nvarious physical constraints? These include both deterministic constraints\n(e.g., conservation laws) and statistical constraints (e.g., energy spectrum of\nturbulent flows). The latter have been studied in a companion paper (Wu et al.,\nEnforcing statistical constraints in generative adversarial networks for\nmodeling chaotic dynamical systems. Journal of Computational Physics. 406,\n109209, 2020). In the present work, we enforce deterministic yet imprecise\nconstraints on GANs by incorporating them into the loss function of the\ngenerator. We evaluate the performance of physics-constrained GANs on two\nrepresentative tasks with geometrical constraints (generating points on\ncircles) and differential constraints (generating divergence-free flow velocity\nfields), respectively. In both cases, the constrained GANs produced samples\nthat conform to the underlying constraints rather accurately, even though the\nconstraints are only enforced up to a specified interval. More importantly, the\nimposed constraints significantly accelerate the convergence and improve the\nrobustness in the training, indicating that they serve as a physics-based\nregularization. These improvements are noteworthy, as the convergence and\nrobustness are two well-known obstacles in the training of GANs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:44:07 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 05:48:24 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yang", "Zeng", ""], ["Wu", "Jin-Long", ""], ["Xiao", "Heng", ""]]}, {"id": "1911.06679", "submitter": "Sean Augenstein", "authors": "Sean Augenstein, H. Brendan McMahan, Daniel Ramage, Swaroop Ramaswamy,\n  Peter Kairouz, Mingqing Chen, Rajiv Mathews, Blaise Aguera y Arcas", "title": "Generative Models for Effective ML on Private, Decentralized Datasets", "comments": "26 pages, 8 figures. Camera-ready ICLR 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve real-world applications of machine learning, experienced modelers\ndevelop intuition about their datasets, their models, and how the two interact.\nManual inspection of raw data - of representative samples, of outliers, of\nmisclassifications - is an essential tool in a) identifying and fixing problems\nin the data, b) generating new modeling hypotheses, and c) assigning or\nrefining human-provided labels. However, manual data inspection is problematic\nfor privacy sensitive datasets, such as those representing the behavior of\nreal-world individuals. Furthermore, manual data inspection is impossible in\nthe increasingly important setting of federated learning, where raw examples\nare stored at the edge and the modeler may only access aggregated outputs such\nas metrics or model parameters. This paper demonstrates that generative models\n- trained using federated methods and with formal differential privacy\nguarantees - can be used effectively to debug many commonly occurring data\nissues even when the data cannot be directly inspected. We explore these\nmethods in applications to text with differentially private federated RNNs and\nto images using a novel algorithm for differentially private federated GANs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:56:44 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 22:38:20 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Augenstein", "Sean", ""], ["McMahan", "H. Brendan", ""], ["Ramage", "Daniel", ""], ["Ramaswamy", "Swaroop", ""], ["Kairouz", "Peter", ""], ["Chen", "Mingqing", ""], ["Mathews", "Rajiv", ""], ["Arcas", "Blaise Aguera y", ""]]}, {"id": "1911.06685", "submitter": "Drago Plecko", "authors": "Drago Ple\\v{c}ko, Nicolai Meinshausen", "title": "Fair Data Adaptation with Quantile Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness of classification and regression has received much attention\nrecently and various, partially non-compatible, criteria have been proposed.\nThe fairness criteria can be enforced for a given classifier or, alternatively,\nthe data can be adapated to ensure that every classifier trained on the data\nwill adhere to desired fairness criteria. We present a practical data adaption\nmethod based on quantile preservation in causal structural equation models. The\ndata adaptation is based on a presumed counterfactual model for the data. While\nthe counterfactual model itself cannot be verified experimentally, we show that\ncertain population notions of fairness are still guaranteed even if the\ncounterfactual model is misspecified. The precise nature of the fulfilled\nnon-causal fairness notion (such as demographic parity, separation or\nsufficiency) depends on the structure of the underlying causal model and the\nchoice of resolving variables. We describe an implementation of the proposed\ndata adaptation procedure based on Random Forests and demonstrate its practical\nuse on simulated and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 15:16:24 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ple\u010dko", "Drago", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1911.06704", "submitter": "Tirtharaj Dash", "authors": "Rohit Kaushik, Shikhar Jain, Siddhant Jain, Tirtharaj Dash", "title": "Performance evaluation of deep neural networks for forecasting\n  time-series with multiple structural breaks and high volatility", "comments": "Preprint (18 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic and accurate forecasting of time-series data has\nalways been an interesting challenge for the machine learning and forecasting\ncommunity. A majority of the real-world time-series problems have\nnon-stationary characteristics that make the understanding of trend and\nseasonality difficult. Our interest in this paper is to study the applicability\nof the popular deep neural networks (DNN) as function approximators for\nnon-stationary TSF. We evaluate the following DNN models: Multi-layer\nPerceptron (MLP), Convolutional Neural Network (CNN), and RNN with Long-Short\nTerm Memory (LSTM-RNN) and RNN with Gated-Recurrent Unit (GRU-RNN). These DNN\nmethods have been evaluated over 10 popular Indian financial stocks data.\nFurther, the performance evaluation of these DNNs has been carried out in\nmultiple independent runs for two settings of forecasting: (1) single-step\nforecasting, and (2) multi-step forecasting. These DNN methods show convincing\nperformance for single-step forecasting (one-day ahead forecast). For the\nmulti-step forecasting (multiple days ahead forecast), we have evaluated the\nmethods for different forecast periods. The performance of these methods\ndemonstrates that long forecast periods have an adverse effect on performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:44:23 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 13:26:36 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kaushik", "Rohit", ""], ["Jain", "Shikhar", ""], ["Jain", "Siddhant", ""], ["Dash", "Tirtharaj", ""]]}, {"id": "1911.06716", "submitter": "Kumar Goutam", "authors": "Kumar Goutam, Vineet Goyal, Agathe Soret", "title": "A Generalized Markov Chain Model to Capture Dynamic Preferences and\n  Choice Overload", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assortment optimization is an important problem that arises in many\nindustries such as retailing and online advertising where the goal is to find a\nsubset of products from a universe of substitutable products which maximize\nseller's expected revenue. One of the key challenges in this problem is to\nmodel the customer substitution behavior. Many parametric random utility\nmaximization (RUM) based choice models have been considered in the literature.\nHowever, in all these models, probability of purchase increases as we include\nmore products to an assortment. This is not true in general and in many\nsettings more choices hurt sales. This is commonly referred to as the choice\noverload. In this paper we attempt to address this limitation in RUM through a\ngeneralization of the Markov chain based choice model considered in Blanchet et\nal. (2016). As a special case, we show that our model reduces to a\ngeneralization of MNL with no-purchase attractions dependent on the assortment\nS and strictly increasing with the size of assortment S. While we show that the\nassortment optimization under this model is NP-hard, we present fully\npolynomial-time approximation scheme (FPTAS) under reasonable assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:02:16 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 16:34:27 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 17:15:18 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 04:23:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Goutam", "Kumar", ""], ["Goyal", "Vineet", ""], ["Soret", "Agathe", ""]]}, {"id": "1911.06722", "submitter": "Max Hinne", "authors": "Max Hinne, Marcel A.J. van Gerven, Luca Ambrogioni", "title": "Causal inference using Bayesian non-parametric quasi-experimental design", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The de facto standard for causal inference is the randomized controlled\ntrial, where one compares an manipulated group with a control group in order to\ndetermine the effect of an intervention. However, this research design is not\nalways realistically possible due to pragmatic or ethical concerns. In these\nsituations, quasi-experimental designs may provide a solution, as these allow\nfor causal conclusions at the cost of additional design assumptions. In this\npaper, we provide a framework for quasi-experimental design using Bayesian\nmodel comparison. We provide a theoretical motivation for a Gaussian process\nbased approach, and demonstrate its convenient use in a number of simulations.\nFinally, we apply the framework to determine the effect the 2005 smoking ban in\nSicily on the number of acute coronary events, and of the effect of an alleged\nhistorical phantom border in the Netherlands on Dutch voting behaviour.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:10:00 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:17:40 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hinne", "Max", ""], ["van Gerven", "Marcel A. J.", ""], ["Ambrogioni", "Luca", ""]]}, {"id": "1911.06723", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok,\n  and Suttipong Thajchayapong", "title": "A nonparametric framework for inferring orders of categorical data from\n  category-real ordered pairs", "comments": "The R package can be found at https://github.com/DarkEyes/EDOIF", "journal-ref": "Heliyon, Volume 6, Issue 11, 2020, e05435", "doi": "10.1016/j.heliyon.2020.e05435", "report-no": null, "categories": "stat.ME cs.CY math.ST physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset of careers and incomes, how large a difference of income\nbetween any pair of careers would be? Given a dataset of travel time records,\nhow long do we need to spend more when choosing a public transportation mode\n$A$ instead of $B$ to travel? In this paper, we propose a framework that is\nable to infer orders of categories as well as magnitudes of difference of real\nnumbers between each pair of categories using Estimation statistics framework.\nNot only reporting whether an order of categories exists, but our framework\nalso reports the magnitude of difference of each consecutive pairs of\ncategories in the order. In large dataset, our framework is scalable well\ncompared with the existing framework. The proposed framework has been applied\nto two real-world case studies: 1) ordering careers by incomes based on\ninformation of 350,000 households living in Khon Kaen province, Thailand, and\n2) ordering sectors by closing prices based on 1060 companies' closing prices\nof NASDAQ stock markets between years 2000 and 2016. The results of careers\nordering show income inequality among different careers. The stock market\nresults illustrate dynamics of sector domination that can change over time. Our\napproach is able to be applied in any research area that has category-real\nordered pairs. Our proposed \"Dominant-Distribution Network\" provides a novel\napproach to gain new insight of analyzing category orders. The software of this\nframework is available for researchers or practitioners within R package:\nEDOIF.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:10:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Surasvadi", "Navaporn", ""], ["Plangprasopchok", "Anon", ""], ["Thajchayapong", "Suttipong", ""]]}, {"id": "1911.06741", "submitter": "Behzad Kamgar-Parsi", "authors": "Behzad Kamgar-Parsi and Behrooz Kamgar-Parsi", "title": "Penalized k-means algorithms for finding the correct number of clusters\n  in a dataset", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications we want to find the number of clusters in a dataset. A\ncommon approach is to use the penalized k-means algorithm with an additive\npenalty term linear in the number of clusters. An open problem is estimating\nthe value of the coefficient of the penalty term. Since estimating the value of\nthe coefficient in a principled manner appears to be intractable for general\nclusters, we investigate \"ideal clusters\", i.e. identical spherical clusters\nwith no overlaps and no outlier background noise. In this paper: (a) We derive,\nfor the case of ideal clusters, rigorous bounds for the coefficient of the\nadditive penalty. Unsurprisingly, the bounds depend on the correct number of\nclusters, which we want to find in the first place. We further show that\nadditive penalty, even for this simplest case of ideal clusters, typically\nproduces a weak and often ambiguous signature for the correct number of\nclusters. (b) As an alternative, we examine the k-means with multiplicative\npenalty, and show that this parameter-free formulation has a stronger, and less\noften ambiguous, signature for the correct number of clusters. We also\nempirically investigate certain types of deviations from ideal cluster\nassumption and show that combination of k-means with additive and\nmultiplicative penalties can resolve ambiguous solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:49:10 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kamgar-Parsi", "Behzad", ""], ["Kamgar-Parsi", "Behrooz", ""]]}, {"id": "1911.06750", "submitter": "Chanyoung Park", "authors": "Chanyoung Park, Donghyun Kim, Jiawei Han, Hwanjo Yu", "title": "Unsupervised Attributed Multiplex Network Embedding", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nodes in a multiplex network are connected by multiple types of relations.\nHowever, most existing network embedding methods assume that only a single type\nof relation exists between nodes. Even for those that consider the multiplexity\nof a network, they overlook node attributes, resort to node labels for\ntraining, and fail to model the global properties of a graph. We present a\nsimple yet effective unsupervised network embedding method for attributed\nmultiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that\nmaximizes the mutual information between local patches of a graph, and the\nglobal representation of the entire graph. We devise a systematic way to\njointly integrate the node embeddings from multiple graphs by introducing 1)\nthe consensus regularization framework that minimizes the disagreements among\nthe relation-type specific node embeddings, and 2) the universal discriminator\nthat discriminates true samples regardless of the relation types. We also show\nthat the attention mechanism infers the importance of each relation type, and\nthus can be useful for filtering unnecessary relation types as a preprocessing\nstep. Extensive experiments on various downstream tasks demonstrate that DMGI\noutperforms the state-of-the-art methods, even though DMGI is fully\nunsupervised.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:08:03 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 02:22:54 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Park", "Chanyoung", ""], ["Kim", "Donghyun", ""], ["Han", "Jiawei", ""], ["Yu", "Hwanjo", ""]]}, {"id": "1911.06756", "submitter": "Carlo Lucibello", "authors": "Carlo Baldassi, Riccardo Della Vecchia, Carlo Lucibello, Riccardo\n  Zecchina", "title": "Clustering of solutions in the symmetric binary perceptron", "comments": null, "journal-ref": "J. Stat. Mech. (2020) 073303", "doi": "10.1088/1742-5468/ab99be", "report-no": null, "categories": "cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometrical features of the (non-convex) loss landscape of neural network\nmodels are crucial in ensuring successful optimization and, most importantly,\nthe capability to generalize well. While minimizers' flatness consistently\ncorrelates with good generalization, there has been little rigorous work in\nexploring the condition of existence of such minimizers, even in toy models.\nHere we consider a simple neural network model, the symmetric perceptron, with\nbinary weights. Phrasing the learning problem as a constraint satisfaction\nproblem, the analogous of a flat minimizer becomes a large and dense cluster of\nsolutions, while the narrowest minimizers are isolated solutions. We perform\nthe first steps toward the rigorous proof of the existence of a dense cluster\nin certain regimes of the parameters, by computing the first and second moment\nupper bounds for the existence of pairs of arbitrarily close solutions.\nMoreover, we present a non rigorous derivation of the same bounds for sets of\n$y$ solutions at fixed pairwise distances.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:14:07 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 11:24:38 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 20:29:19 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Baldassi", "Carlo", ""], ["Della Vecchia", "Riccardo", ""], ["Lucibello", "Carlo", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1911.06777", "submitter": "Ali Jahanshahi", "authors": "Ali Jahanshahi", "title": "TinyCNN: A Tiny Modular CNN Accelerator for Embedded FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recent years, Convolutional Neural Network (CNN) based methods have\nachieved great success in a large number of applications and have been among\nthe most powerful and widely used techniques in computer vision. However,\nCNN-based methods are computational-intensive and resource-consuming, and thus\nare hard to be integrated into embedded systems such as smart phones, smart\nglasses, and robots. FPGA is one of the most promising platforms for\naccelerating CNN, but the limited on-chip memory size limit the performance of\nFPGA accelerator for CNN. In this paper, we propose a framework for designing\nCNN accelerator on embedded FPGA for image classification. The proposed\nframework provides a tool for FPGA resource-aware design space exploration of\nCNNs and automatically generates the hardware description of the CNN to be\nprogrammed on a target FPGA. The framework consists of three main backends;\nsoftware, hardware generation, and simulation/precision adjustment. The\nsoftware backend serves as an API to the designer to design the CNN and train\nit according to the hardware resources that are available. Using the CNN model,\nhardware backend generates the necessary hardware components and integrates\nthem to generate the hardware description of the CNN. Finaly,\nSimulation/precision adjustment backend adjusts the inter-layer precision units\nto minimize the classification error. We used 16-bit fixed-point data in a CNN\naccelerator (FPGA) and compared it to the exactly similar software version\nrunning on an ARM processor (32-bit floating point data). We encounter about 3%\naccuracy loss in classification of the accelerated (FPGA) version. In return,\nwe got up to 15.75x speedup by classifying with the accelerated version on the\nFPGA.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:42:52 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Jahanshahi", "Ali", ""]]}, {"id": "1911.06813", "submitter": "Alex Fedorov", "authors": "Usman Mahmood, Md Mahfuzur Rahman, Alex Fedorov, Zening Fu, Sergey\n  Plis", "title": "Transfer Learning of fMRI Dynamics", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a mental disorder progresses, it may affect brain structure, but brain\nfunction expressed in brain dynamics is affected much earlier. Capturing the\nmoment when brain dynamics express the disorder is crucial for early diagnosis.\nThe traditional approach to this problem via training classifiers either\nproceeds from handcrafted features or requires large datasets to combat the\n$m>>n$ problem when a high dimensional fMRI volume only has a single label that\ncarries learning signal. Large datasets may not be available for a study of\neach disorder, or rare disorder types or sub-populations may not warrant for\nthem. In this paper, we demonstrate a self-supervised pre-training method that\nenables us to pre-train directly on fMRI dynamics of healthy control subjects\nand transfer the learning to much smaller datasets of schizophrenia. Not only\nwe enable classification of disorder directly based on fMRI dynamics in small\ndata but also significantly speed up the learning when possible. This is\nencouraging evidence of informative transfer learning across datasets and\ndiagnostic categories.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 07:08:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mahmood", "Usman", ""], ["Rahman", "Md Mahfuzur", ""], ["Fedorov", "Alex", ""], ["Fu", "Zening", ""], ["Plis", "Sergey", ""]]}, {"id": "1911.06832", "submitter": "Kevin Sebastian Luck", "authors": "Kevin Sebastian Luck, Heni Ben Amor, Roberto Calandra", "title": "Data-efficient Co-Adaptation of Morphology and Behaviour with Deep\n  Reinforcement Learning", "comments": "Accepted for the Conference on Robot Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are capable of quickly learning new behaviours to solve\nnew tasks. Yet, we often forget that they also rely on a highly specialized\nmorphology that co-adapted with motor control throughout thousands of years.\nAlthough compelling, the idea of co-adapting morphology and behaviours in\nrobots is often unfeasible because of the long manufacturing times, and the\nneed to re-design an appropriate controller for each morphology. In this paper,\nwe propose a novel approach to automatically and efficiently co-adapt a robot\nmorphology and its controller. Our approach is based on recent advances in deep\nreinforcement learning, and specifically the soft actor critic algorithm. Key\nto our approach is the possibility of leveraging previously tested morphologies\nand behaviors to estimate the performance of new candidate morphologies. As\nsuch, we can make full use of the information available for making more\ninformed decisions, with the ultimate goal of achieving a more data-efficient\nco-adaptation (i.e., reducing the number of morphologies and behaviors tested).\nSimulated experiments show that our approach requires drastically less design\nprototypes to find good morphology-behaviour combinations, making this method\nparticularly suitable for future co-adaptation of robot designs in the real\nworld.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:01:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Luck", "Kevin Sebastian", ""], ["Amor", "Heni Ben", ""], ["Calandra", "Roberto", ""]]}, {"id": "1911.06833", "submitter": "Kevin Sebastian Luck", "authors": "Kevin Sebastian Luck, Mel Vecerik, Simon Stepputtis, Heni Ben Amor,\n  Jonathan Scholz", "title": "Improved Exploration through Latent Trajectory Optimization in Deep\n  Deterministic Policy Gradient", "comments": "Accepted for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning algorithms such as Deep Deterministic\nPolicy Gradient (DDPG) often require additional exploration strategies,\nespecially if the actor is of deterministic nature. This work evaluates the use\nof model-based trajectory optimization methods used for exploration in Deep\nDeterministic Policy Gradient when trained on a latent image embedding. In\naddition, an extension of DDPG is derived using a value function as critic,\nmaking use of a learned deep dynamics model to compute the policy gradient.\nThis approach leads to a symbiotic relationship between the deep reinforcement\nlearning algorithm and the latent trajectory optimizer. The trajectory\noptimizer benefits from the critic learned by the RL algorithm and the latter\nfrom the enhanced exploration generated by the planner. The developed methods\nare evaluated on two continuous control tasks, one in simulation and one in the\nreal world. In particular, a Baxter robot is trained to perform an insertion\ntask, while only receiving sparse rewards and images as observations from the\nenvironment.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:01:29 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Luck", "Kevin Sebastian", ""], ["Vecerik", "Mel", ""], ["Stepputtis", "Simon", ""], ["Amor", "Heni Ben", ""], ["Scholz", "Jonathan", ""]]}, {"id": "1911.06837", "submitter": "Joshua Williams", "authors": "Joshua Williams, J. Zico Kolter", "title": "Dynamic Modeling and Equilibria in Fair Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on fairness in automated decision making systems have both\ninvestigated the potential future impact of these decisions on the population\nat large, and emphasized that imposing ''typical'' fairness constraints such as\ndemographic parity or equality of opportunity does not guarantee a benefit to\ndisadvantaged groups. However, these previous studies have focused on either\nsimple one-step cost/benefit criteria, or on discrete underlying state spaces.\nIn this work, we first propose a natural continuous representation of\npopulation state, governed by the Beta distribution, using a loan granting\nsetting as a running example. Next, we apply a model of population dynamics\nunder lending decisions, and show that when conditional payback probabilities\nare estimated correctly 1) ``optimal'' behavior by lenders can lead to\n''Matthew Effect'' bifurcations (i.e., ''the rich get richer and the poor get\npoorer''), but that 2) many common fairness constraints on the allowable\npolicies cause groups to converge to the same equilibrium point. Last, we\ncontrast our results in the case of misspecified conditional probability\nestimates with prior work, and show that for this model, different levels of\ngroup misestimation guarantees that even fair policies lead to bifurcations. We\nillustrate some of the modeling conclusions on real data from credit scoring.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:09:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Williams", "Joshua", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1911.06854", "submitter": "Cameron Voloshin", "authors": "Cameron Voloshin, Hoang M. Le, Nan Jiang, Yisong Yue", "title": "Empirical Study of Off-Policy Policy Evaluation for Reinforcement\n  Learning", "comments": "Main paper is 8 pages. The appendix contains many pages of tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The disparate experimental conditions in recent off-policy policy evaluation\n(OPE) literature make it difficult both for practitioners to choose a reliable\nestimator for their application domain, as well as for researchers to identify\nfruitful research directions. In this work, we present the first detailed\nempirical study of a broad suite of OPE methods. Based on thousands of\nexperiments and empirical analysis, we offer a summarized set of guidelines to\nadvance the understanding of OPE performance in practice, and suggest\ndirections for future research. Along the way, our empirical findings challenge\nseveral commonly held beliefs about which class of approaches tends to perform\nwell. Our accompanying software implementation serves as a first comprehensive\nbenchmark for OPE.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:58:42 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:24:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Voloshin", "Cameron", ""], ["Le", "Hoang M.", ""], ["Jiang", "Nan", ""], ["Yue", "Yisong", ""]]}, {"id": "1911.06869", "submitter": "Srijan Sengupta", "authors": "Somnath Bhadra, Kaustav Chakraborty, Srijan Sengupta, and Soumendra\n  Lahiri", "title": "A Bootstrap-based Inference Framework for Testing Similarity of Paired\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in an interconnected world where network valued data arises in many\ndomains, and, fittingly, statistical network analysis has emerged as an active\narea in the literature. However, the topic of inference in networks has\nreceived relatively less attention. In this work, we consider the paired\nnetwork inference problem where one is given two networks on the same set of\nnodes, and the goal is to test whether the given networks are stochastically\nsimilar in terms of some notion of similarity. We develop a general inferential\nframework based on parametric bootstrap to address this problem. Under this\nsetting, we address two specific and important problems: the equality problem,\ni.e., whether the two networks are generated from the same random graph model,\nand the scaling problem, i.e., whether the underlying probability matrices of\nthe two random graph models are scaled versions of each other.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 20:50:22 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 00:27:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bhadra", "Somnath", ""], ["Chakraborty", "Kaustav", ""], ["Sengupta", "Srijan", ""], ["Lahiri", "Soumendra", ""]]}, {"id": "1911.06876", "submitter": "Lawrence Phillips", "authors": "Lawrence Phillips, Garrett Goh, Nathan Hodas", "title": "Explanatory Masks for Neural Network Interpretability", "comments": "Presented at IJCAI-18 Workshop on Explainable Artificial Intelligence\n  (XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network interpretability is a vital component for applications across\na wide variety of domains. In such cases it is often useful to analyze a\nnetwork which has already been trained for its specific purpose. In this work,\nwe develop a method to produce explanation masks for pre-trained networks. The\nmask localizes the most important aspects of each input for prediction of the\noriginal network. Masks are created by a secondary network whose goal is to\ncreate as small an explanation as possible while still preserving the\npredictive accuracy of the original network. We demonstrate the applicability\nof our method for image classification with CNNs, sentiment analysis with RNNs,\nand chemical property prediction with mixed CNN/RNN architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 21:10:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Phillips", "Lawrence", ""], ["Goh", "Garrett", ""], ["Hodas", "Nathan", ""]]}, {"id": "1911.06892", "submitter": "Roy Abel", "authors": "Roy Abel, Idan Benami, Yoram Louzoun", "title": "Topological based classification using graph convolutional networks", "comments": "arXiv admin note: text overlap with arXiv:1904.07787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In colored graphs, node classes are often associated with either their\nneighbors class or with information not incorporated in the graph associated\nwith each node. We here propose that node classes are also associated with\ntopological features of the nodes. We use this association to improve Graph\nmachine learning in general and specifically, Graph Convolutional Networks\n(GCN).\n  First, we show that even in the absence of any external information on nodes,\na good accuracy can be obtained on the prediction of the node class using\neither topological features, or using the neighbors class as an input to a GCN.\nThis accuracy is slightly less than the one that can be obtained using content\nbased GCN.\n  Secondly, we show that explicitly adding the topology as an input to the GCN\ndoes not improve the accuracy when combined with external information on nodes.\nHowever, adding an additional adjacency matrix with edges between distant nodes\nwith similar topology to the GCN does significantly improve its accuracy,\nleading to results better than all state of the art methods in multiple\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 10:56:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Abel", "Roy", ""], ["Benami", "Idan", ""], ["Louzoun", "Yoram", ""]]}, {"id": "1911.06903", "submitter": "Kuang Xu", "authors": "Kuang Xu", "title": "Query Complexity of Bayesian Private Learning", "comments": "A conference version of this manuscript appeared in the proceedings\n  of the {Conference on Neural Information Processing Systems (NeurIPS)},\n  December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of Bayesian Private Learning: a learner wishes\nto locate a random target within an interval by submitting queries, in the\npresence of an adversary who observes all of her queries but not the responses.\nHow many queries are necessary and sufficient in order for the learner to\naccurately estimate the target, while simultaneously concealing the target from\nthe adversary?\n  Our main result is a query complexity lower bound that is tight up to the\nfirst order. We show that if the learner wants to estimate the target within an\nerror of $\\varepsilon$, while ensuring that no adversary estimator can achieve\na constant additive error with probability greater than $1/L$, then the query\ncomplexity is on the order of $L\\log(1/\\varepsilon)$, as $\\varepsilon \\to 0$.\nOur result demonstrates that increased privacy, as captured by $L$, comes at\nthe expense of a {multiplicative} increase in query complexity.\n  Our proof method builds on Fano's inequality and a family of\nproportional-sampling estimators. As an illustration of the method's wider\napplicability, we generalize the complexity lower bound to settings involving\nhigh-dimensional linear query learning and partial adversary observation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:10:56 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Kuang", ""]]}, {"id": "1911.06905", "submitter": "Ethan Shi", "authors": "Dai Shi, Junbin Gao, Xia Hong, S.T. Boris Choy and Zhiyong Wang", "title": "Coupling Matrix Manifolds and Their Applications in Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) is a powerful tool for measuring the distance between\ntwo defined probability distributions. In this paper, we develop a new manifold\nnamed the coupling matrix manifold (CMM), where each point on CMM can be\nregarded as the transportation plan of the OT problem. We firstly explore the\nRiemannian geometry of CMM with the metric expressed by the Fisher information.\nThese geometrical features of CMM have paved the way for developing numerical\nRiemannian optimization algorithms such as Riemannian gradient descent and\nRiemannian trust-region algorithms, forming a uniform optimization method for\nall types of OT problems. The proposed method is then applied to solve several\nOT problems studied by previous literature. The results of the numerical\nexperiments illustrate that the optimization algorithms that are based on the\nmethod proposed in this paper are comparable to the classic ones, for example,\nthe Sinkhorn algorithm, while outperforming other state-of-the-art algorithms\nwithout considering the geometry information, especially in the case of\nnon-entropy optimal transport.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:14:53 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 13:31:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shi", "Dai", ""], ["Gao", "Junbin", ""], ["Hong", "Xia", ""], ["Choy", "S. T. Boris", ""], ["Wang", "Zhiyong", ""]]}, {"id": "1911.06911", "submitter": "Yunan Yang", "authors": "Bj\u007forn Engquist, Kui Ren, Yunan Yang", "title": "The quadratic Wasserstein metric for inverse data matching", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": "10.1088/1361-6420/ab7e04", "report-no": null, "categories": "math.NA cs.NA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work characterizes, analytically and numerically, two major effects of\nthe quadratic Wasserstein ($W_2$) distance as the measure of data discrepancy\nin computational solutions of inverse problems. First, we show, in the\ninfinite-dimensional setup, that the $W_2$ distance has a smoothing effect on\nthe inversion process, making it robust against high-frequency noise in the\ndata but leading to a reduced resolution for the reconstructed objects at a\ngiven noise level. Second, we demonstrate that for some finite-dimensional\nproblems, the $W_2$ distance leads to optimization problems that have better\nconvexity than the classical $L^2$ and $H^{-1}$ distances, making it a more\npreferred distance to use when solving such inverse matching problems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:29:27 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 21:22:15 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 19:24:29 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Engquist", "Bj\u007forn", ""], ["Ren", "Kui", ""], ["Yang", "Yunan", ""]]}, {"id": "1911.06922", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "Benanza: Automatic $\\mu$Benchmark Generation to Compute \"Lower-bound\"\n  Latency and Inform Optimizations of Deep Learning Models on GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS47924.2020.00053", "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Deep Learning (DL) models have been increasingly used in latency-sensitive\napplications, there has been a growing interest in improving their response\ntime. An important venue for such improvement is to profile the execution of\nthese models and characterize their performance to identify possible\noptimization opportunities. However, the current profiling tools lack the\nhighly desired abilities to characterize ideal performance, identify sources of\ninefficiency, and quantify the benefits of potential optimizations. Such\ndeficiencies have led to slow characterization/optimization cycles that cannot\nkeep up with the fast pace at which new DL models are introduced.\n  We propose Benanza, a sustainable and extensible benchmarking and analysis\ndesign that speeds up the characterization/optimization cycle of DL models on\nGPUs. Benanza consists of four major components: a model processor that parses\nmodels into an internal representation, a configurable benchmark generator that\nautomatically generates micro-benchmarks given a set of models, a database of\nbenchmark results, and an analyzer that computes the \"lower-bound\" latency of\nDL models using the benchmark data and informs optimizations of model\nexecution. The \"lower-bound\" latency metric estimates the ideal model execution\non a GPU system and serves as the basis for identifying optimization\nopportunities in frameworks or system libraries. We used Benanza to evaluate 30\nONNX models in MXNet, ONNX Runtime, and PyTorch on 7 GPUs ranging from Kepler\nto the latest Turing, and identified optimizations in parallel layer execution,\ncuDNN convolution algorithm selection, framework inefficiency, layer fusion,\nand using Tensor Cores.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:24:05 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 01:15:16 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 16:46:32 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1911.06928", "submitter": "Tien Mai", "authors": "Tien Mai and Kennard Chan and Patrick Jaillet", "title": "Generalized Maximum Causal Entropy for Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning from demonstrated trajectories with\ninverse reinforcement learning (IRL). Motivated by a limitation of the\nclassical maximum entropy model in capturing the structure of the network of\nstates, we propose an IRL model based on a generalized version of the causal\nentropy maximization problem, which allows us to generate a class of maximum\nentropy IRL models. Our generalized model has an advantage of being able to\nrecover, in addition to a reward function, another expert's function that would\n(partially) capture the impact of the connecting structure of the states on\nexperts' decisions. Empirical evaluation on a real-world dataset and a\ngrid-world dataset shows that our generalized model outperforms the classical\nones, in terms of recovering reward functions and demonstrated trajectories.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:07:23 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 10:58:04 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Mai", "Tien", ""], ["Chan", "Kennard", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1911.06930", "submitter": "Tien Mai", "authors": "Tien Mai and Quoc Phong Nguyen and Kian Hsiang Low and Patrick Jaillet", "title": "Inverse Reinforcement Learning with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering an expert's reward function with\ninverse reinforcement learning (IRL) when there are missing/incomplete\nstate-action pairs or observations in the demonstrated trajectories. This issue\nof missing trajectory data or information occurs in many situations, e.g., GPS\nsignals from vehicles moving on a road network are intermittent. In this paper,\nwe propose a tractable approach to directly compute the log-likelihood of\ndemonstrated trajectories with incomplete/missing data. Our algorithm is\nefficient in handling a large number of missing segments in the demonstrated\ntrajectories, as it performs the training with incomplete data by solving a\nsequence of systems of linear equations, and the number of such systems to be\nsolved does not depend on the number of missing segments. Empirical evaluation\non a real-world dataset shows that our training algorithm outperforms other\nconventional techniques.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:17:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mai", "Tien", ""], ["Nguyen", "Quoc Phong", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1911.06935", "submitter": "Martin Bertran", "authors": "Natalia Martinez, Martin Bertran, Guillermo Sapiro", "title": "Fairness With Minimal Harm: A Pareto-Optimal Approach For Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Common fairness definitions in machine learning focus on balancing notions of\ndisparity and utility. In this work, we study fairness in the context of risk\ndisparity among sub-populations. We are interested in learning models that\nminimize performance discrepancies across sensitive groups without causing\nunnecessary harm. This is relevant to high-stakes domains such as healthcare,\nwhere non-maleficence is a core principle. We formalize this objective using\nPareto frontiers, and provide analysis, based on recent works in fairness, to\nexemplify scenarios were perfect fairness might not be feasible without doing\nunnecessary harm. We present a methodology for training neural networks that\nachieve our goal by dynamically re-balancing subgroups risks. We argue that\neven in domains where fairness at cost is required, finding a\nnon-unnecessary-harm fairness model is the optimal initial step. We demonstrate\nthis methodology on real case-studies of predicting ICU patient mortality, and\nclassifying skin lesions from dermatoscopic images.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:51:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Martinez", "Natalia", ""], ["Bertran", "Martin", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1911.06944", "submitter": "Donghui Yan", "authors": "Ke Alexander Wang, Xinran Bian, Pan Liu, Donghui Yan", "title": "$DC^2$: A Divide-and-conquer Algorithm for Large-scale Kernel Learning\n  with Application to Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divide-and-conquer is a general strategy to deal with large scale problems.\nIt is typically applied to generate ensemble instances, which potentially\nlimits the problem size it can handle. Additionally, the data are often divided\nby random sampling which may be suboptimal. To address these concerns, we\npropose the $DC^2$ algorithm. Instead of ensemble instances, we produce\nstructure-preserving signature pieces to be assembled and conquered. $DC^2$\nachieves the efficiency of sampling-based large scale kernel methods while\nenabling parallel multicore or clustered computation. The data partition and\nsubsequent compression are unified by recursive random projections. Empirically\ndividing the data by random projections induces smaller mean squared\napproximation errors than conventional random sampling. The power of $DC^2$ is\ndemonstrated by our clustering algorithm $rpfCluster^+$, which is as accurate\nas some fastest approximate spectral clustering algorithms while maintaining a\nrunning time close to that of K-means clustering. Analysis on $DC^2$ when\napplied to spectral clustering shows that the loss in clustering accuracy due\nto data division and reduction is upper bounded by the data approximation error\nwhich would vanish with recursive random projections. Due to its easy\nimplementation and flexibility, we expect $DC^2$ to be applicable to general\nlarge scale learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 03:10:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wang", "Ke Alexander", ""], ["Bian", "Xinran", ""], ["Liu", "Pan", ""], ["Yan", "Donghui", ""]]}, {"id": "1911.06959", "submitter": "Nazgol Tavabi", "authors": "Nazgol Tavabi, Homa Hosseinmardi, Jennifer L. Villatte, Andr\\'es\n  Abeliuk, Shrikanth Narayanan, Emilio Ferrara, Kristina Lerman", "title": "Learning Behavioral Representations from Wearable Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous collection of physiological data from wearable sensors enables\ntemporal characterization of individual behaviors. Understanding the relation\nbetween an individual's behavioral patterns and psychological states can help\nidentify strategies to improve quality of life. One challenge in analyzing\nphysiological data is extracting the underlying behavioral states from the\ntemporal sensor signals and interpreting them. Here, we use a non-parametric\nBayesian approach to model sensor data from multiple people and discover the\ndynamic behaviors they share. We apply this method to data collected from\nsensors worn by a population of hospital workers and show that the learned\nstates can cluster participants into meaningful groups and better predict their\ncognitive and psychological states. This method offers a way to learn\ninterpretable compact behavioral representations from multivariate sensor\nsignals.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:21:55 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 20:52:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Tavabi", "Nazgol", ""], ["Hosseinmardi", "Homa", ""], ["Villatte", "Jennifer L.", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Narayanan", "Shrikanth", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "1911.06962", "submitter": "Komal Teru", "authors": "Komal K. Teru, Etienne Denis, William L. Hamilton", "title": "Inductive Relation Prediction by Subgraph Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dominant paradigm for relation prediction in knowledge graphs involves\nlearning and operating on latent representations (i.e., embeddings) of entities\nand relations. However, these embedding-based methods do not explicitly capture\nthe compositional logical rules underlying the knowledge graph, and they are\nlimited to the transductive setting, where the full set of entities must be\nknown during training. Here, we propose a graph neural network based relation\nprediction framework, GraIL, that reasons over local subgraph structures and\nhas a strong inductive bias to learn entity-independent relational semantics.\nUnlike embedding-based models, GraIL is naturally inductive and can generalize\nto unseen entities and graphs after training. We provide theoretical proof and\nstrong empirical evidence that GraIL can represent a useful subset of\nfirst-order logic and show that GraIL outperforms existing rule-induction\nbaselines in the inductive setting. We also demonstrate significant gains\nobtained by ensembling GraIL with various knowledge graph embedding methods in\nthe transductive setting, highlighting the complementary inductive bias of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:25:56 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 02:16:11 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Teru", "Komal K.", ""], ["Denis", "Etienne", ""], ["Hamilton", "William L.", ""]]}, {"id": "1911.06965", "submitter": "Stanis{\\l}aw Saganowski", "authors": "Hubert Jegierski, Stanis{\\l}aw Saganowski", "title": "An \"outside the box\" solution for imbalanced data classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem of the real-world data sets is the class imbalance, which\ncan significantly affect the classification abilities of classifiers. Numerous\nmethods have been proposed to cope with this problem; however, even\nstate-of-the-art methods offer a limited improvement (if any) for data sets\nwith critically under-represented minority classes. For such problematic cases,\nan \"outside the box\" solution is required. Therefore, we propose a novel\ntechnique, called enrichment, which uses the information (observations) from\nthe external data set(s). We present three approaches to implement enrichment\ntechnique: (1) selecting observations randomly, (2) iteratively choosing\nobservations that improve the classification result, (3) adding observations\nthat help the classifier to determine the border between classes better. We\nthen thoroughly analyze developed solutions on ten real-world data sets to\nexperimentally validate their usefulness. On average, our best approach\nimproves the classification quality by 27\\%, and in the best case, by\noutstanding 66\\%. We also compare our technique with the universally applicable\nstate-of-the-art methods. We find that our technique surpasses the existing\nmethods performing, on average, 21\\% better. The advantage is especially\nnoticeable for the smallest data sets, for which existing methods failed, while\nour solutions achieved the best results. Additionally, our technique applies to\nboth the multi-class and binary classification tasks. It can also be combined\nwith other techniques dealing with the class imbalance problem.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:36:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jegierski", "Hubert", ""], ["Saganowski", "Stanis\u0142aw", ""]]}, {"id": "1911.06970", "submitter": "Komal Teru", "authors": "Riashat Islam, Komal K. Teru, Deepak Sharma, Joelle Pineau", "title": "Off-Policy Policy Gradient Algorithms by Constraining the State\n  Distribution Shift", "comments": "Accepted at NeurIPS 2019 workshop on Deep Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Off-policy deep reinforcement learning (RL) algorithms are incapable of\nlearning solely from batch offline data without online interactions with the\nenvironment, due to the phenomenon known as \\textit{extrapolation error}. This\nis often due to past data available in the replay buffer that may be quite\ndifferent from the data distribution under the current policy. We argue that\nmost off-policy learning methods fundamentally suffer from a \\textit{state\ndistribution shift} due to the mismatch between the state visitation\ndistribution of the data collected by the behavior and target policies. This\ndata distribution shift between current and past samples can significantly\nimpact the performance of most modern off-policy based policy optimization\nalgorithms. In this work, we first do a systematic analysis of state\ndistribution mismatch in off-policy learning, and then develop a novel\noff-policy policy optimization method to constraint the state distribution\nshift. To do this, we first estimate the state distribution based on features\nof the state, using a density estimator and then develop a novel constrained\noff-policy gradient objective that minimizes the state distribution shift. Our\nexperimental results on continuous control tasks show that minimizing this\ndistribution mismatch can significantly improve performance in most popular\npractical off-policy policy gradient algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 06:00:52 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 05:06:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Islam", "Riashat", ""], ["Teru", "Komal K.", ""], ["Sharma", "Deepak", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.06981", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Oguzhan Teke, Amir Said, Vadim Seregin, Marta\n  Karczewicz", "title": "Parametric Graph-based Separable Transforms for Video Coding", "comments": "5 pages, submitted to IEEE ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many video coding systems, separable transforms (such as two-dimensional\nDCT-2) have been used to code block residual signals obtained after prediction.\nThis paper proposes a parametric approach to build graph-based separable\ntransforms (GBSTs) for video coding. Specifically, a GBST is derived from a\npair of line graphs, whose weights are determined based on two non-negative\nparameters. As certain choices of those parameters correspond to the discrete\nsine and cosine transform types used in recent video coding standards\n(including DCT-2, DST-7 and DCT-8), this paper further optimizes these graph\nparameters to better capture residual block statistics and improve video coding\nefficiency. The proposed GBSTs are tested on the Versatile Video Coding (VVC)\nreference software, and the experimental results show that about 0.4% average\ncoding gain is achieved over the existing set of separable transforms\nconstructed based on DCT-2, DST-7 and DCT-8 in VVC.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 07:24:20 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:13:52 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 12:42:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Teke", "Oguzhan", ""], ["Said", "Amir", ""], ["Seregin", "Vadim", ""], ["Karczewicz", "Marta", ""]]}, {"id": "1911.06996", "submitter": "Berry Weinstein", "authors": "Berry Weinstein, Shai Fine, Yacov Hel-Or", "title": "Selective sampling for accelerating training of deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a selective sampling method designed to accelerate the training of\ndeep neural networks. To this end, we introduce a novel measurement, the\nminimal margin score (MMS), which measures the minimal amount of displacement\nan input should take until its predicted classification is switched. For\nmulti-class linear classification, the MMS measure is a natural generalization\nof the margin-based selection criterion, which was thoroughly studied in the\nbinary classification setting. In addition, the MMS measure provides an\ninteresting insight into the progress of the training process and can be useful\nfor designing and monitoring new training regimes. Empirically we demonstrate a\nsubstantial acceleration when training commonly used deep neural network\narchitectures for popular image classification tasks. The efficiency of our\nmethod is compared against the standard training procedures, and against\ncommonly used selective sampling alternatives: Hard negative mining selection,\nand Entropy-based selection. Finally, we demonstrate an additional speedup when\nwe adopt a more aggressive learning drop regime while using the MMS selective\nsampling method.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 08:49:13 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Weinstein", "Berry", ""], ["Fine", "Shai", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "1911.07013", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xu Sun, Zhiyuan Zhang, Guangxiang Zhao, Junyang Lin", "title": "Understanding and Improving Layer Normalization", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer normalization (LayerNorm) is a technique to normalize the distributions\nof intermediate layers. It enables smoother gradients, faster training, and\nbetter generalization accuracy. However, it is still unclear where the\neffectiveness stems from. In this paper, our main contribution is to take a\nstep further in understanding LayerNorm. Many of previous studies believe that\nthe success of LayerNorm comes from forward normalization. Unlike them, we find\nthat the derivatives of the mean and variance are more important than forward\nnormalization by re-centering and re-scaling backward gradients. Furthermore,\nwe find that the parameters of LayerNorm, including the bias and gain, increase\nthe risk of over-fitting and do not work in most cases. Experiments show that a\nsimple version of LayerNorm (LayerNorm-simple) without the bias and gain\noutperforms LayerNorm on four datasets. It obtains the state-of-the-art\nperformance on En-Vi machine translation. To address the over-fitting problem,\nwe propose a new normalization method, Adaptive Normalization (AdaNorm), by\nreplacing the bias and gain with a new transformation function. Experiments\nshow that AdaNorm demonstrates better results than LayerNorm on seven out of\neight datasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 11:00:16 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Jingjing", ""], ["Sun", "Xu", ""], ["Zhang", "Zhiyuan", ""], ["Zhao", "Guangxiang", ""], ["Lin", "Junyang", ""]]}, {"id": "1911.07015", "submitter": "Anshuman Chhabra", "authors": "Anshuman Chhabra, Abhishek Roy, Prasant Mohapatra", "title": "Suspicion-Free Adversarial Attacks on Clustering Algorithms", "comments": "AAAI 2020 Main Technical Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms are used in a large number of applications and play an\nimportant role in modern machine learning-- yet, adversarial attacks on\nclustering algorithms seem to be broadly overlooked unlike supervised learning.\nIn this paper, we seek to bridge this gap by proposing a black-box adversarial\nattack for clustering models for linearly separable clusters. Our attack works\nby perturbing a single sample close to the decision boundary, which leads to\nthe misclustering of multiple unperturbed samples, named spill-over adversarial\nsamples. We theoretically show the existence of such adversarial samples for\nthe K-Means clustering. Our attack is especially strong as (1) we ensure the\nperturbed sample is not an outlier, hence not detectable, and (2) the exact\nmetric used for clustering is not known to the attacker. We theoretically\njustify that the attack can indeed be successful without the knowledge of the\ntrue metric. We conclude by providing empirical results on a number of\ndatasets, and clustering algorithms. To the best of our knowledge, this is the\nfirst work that generates spill-over adversarial samples without the knowledge\nof the true metric ensuring that the perturbed sample is not an outlier, and\ntheoretically proves the above.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 11:37:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chhabra", "Anshuman", ""], ["Roy", "Abhishek", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "1911.07027", "submitter": "Yang Yu", "authors": "Tian Xu, Ziniu Li, Yang Yu", "title": "On Value Discrepancy of Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning trains a policy from expert demonstrations. Imitation\nlearning approaches have been designed from various principles, such as\nbehavioral cloning via supervised learning, apprenticeship learning via inverse\nreinforcement learning, and GAIL via generative adversarial learning. In this\npaper, we propose a framework to analyze the theoretical property of imitation\nlearning approaches based on discrepancy propagation analysis. Under the\ninfinite-horizon setting, the framework leads to the value discrepancy of\nbehavioral cloning in an order of O((1-\\gamma)^{-2}). We also show that the\nframework leads to the value discrepancy of GAIL in an order of\nO((1-\\gamma)^{-1}). It implies that GAIL has less compounding errors than\nbehavioral cloning, which is also verified empirically in this paper. To the\nbest of our knowledge, we are the first one to analyze GAIL's performance\ntheoretically. The above results indicate that the proposed framework is a\ngeneral tool to analyze imitation learning approaches. We hope our theoretical\nresults can provide insights for future improvements in imitation learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:21:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Tian", ""], ["Li", "Ziniu", ""], ["Yu", "Yang", ""]]}, {"id": "1911.07084", "submitter": "Scott Fleming", "authors": "Scott L. Fleming, Kuhan Jeyapragasan, Tony Duan, Daisy Ding, Saurabh\n  Gombar, Nigam Shah, Emma Brunskill", "title": "Missingness as Stability: Understanding the Structure of Missingness in\n  Longitudinal EHR data and its Impact on Reinforcement Learning in Healthcare", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an emerging trend in the reinforcement learning for healthcare\nliterature. In order to prepare longitudinal, irregularly sampled, clinical\ndatasets for reinforcement learning algorithms, many researchers will resample\nthe time series data to short, regular intervals and use\nlast-observation-carried-forward (LOCF) imputation to fill in these gaps.\nTypically, they will not maintain any explicit information about which values\nwere imputed. In this work, we (1) call attention to this practice and discuss\nits potential implications; (2) propose an alternative representation of the\npatient state that addresses some of these issues; and (3) demonstrate in a\nnovel but representative clinical dataset that our alternative representation\nyields consistently better results for achieving optimal control, as measured\nby off-policy policy evaluation, compared to representations that do not\nincorporate missingness information.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 19:40:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fleming", "Scott L.", ""], ["Jeyapragasan", "Kuhan", ""], ["Duan", "Tony", ""], ["Ding", "Daisy", ""], ["Gombar", "Saurabh", ""], ["Shah", "Nigam", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.07100", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Moinuddin K Qureshi", "title": "Defending Against Model Stealing Attacks with Adaptive Misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose \"Adaptive Misinformation\" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker's clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:13:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Qureshi", "Moinuddin K", ""]]}, {"id": "1911.07101", "submitter": "Qian Lou", "authors": "Qian Lou and Bo Feng and Geoffrey C. Fox and Lei Jiang", "title": "Glyph: Fast and Accurately Training Deep Neural Networks on Encrypted\n  Data", "comments": "10 pages, 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data is one of the cornerstones to enabling and training deep neural\nnetworks (DNNs). Because of the lack of expertise, to gain benefits from their\ndata, average users have to rely on and upload their private data to big data\ncompanies they may not trust. Due to the compliance, legal, or privacy\nconstraints, most users are willing to contribute only their encrypted data,\nand lack interests or resources to join the training of DNNs in cloud. To train\na DNN on encrypted data in a completely non-interactive way, a recent work\nproposes a fully homomorphic encryption (FHE)-based technique implementing all\nactivations in the neural network by \\textit{Brakerski-Gentry-Vaikuntanathan\n(BGV)}-based lookup tables. However, such inefficient lookup-table-based\nactivations significantly prolong the training latency of privacy-preserving\nDNNs.\n  In this paper, we propose, Glyph, a FHE-based scheme to fast and accurately\ntrain DNNs on encrypted data by switching between TFHE (Fast Fully Homomorphic\nEncryption over the Torus) and BGV cryptosystems. Glyph uses\nlogic-operation-friendly TFHE to implement nonlinear activations, while adopts\nvectorial-arithmetic-friendly BGV to perform multiply-accumulation (MAC)\noperations. Glyph further applies transfer learning on the training of DNNs to\nimprove the test accuracy and reduce the number of MAC operations between\nciphertext and ciphertext in convolutional layers. Our experimental results\nshow Glyph obtains the state-of-the-art test accuracy, but reduces the training\nlatency by $99\\%$ over the prior FHE-based technique on various encrypted\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:30:19 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:22:02 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 02:09:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lou", "Qian", ""], ["Feng", "Bo", ""], ["Fox", "Geoffrey C.", ""], ["Jiang", "Lei", ""]]}, {"id": "1911.07104", "submitter": "Farzaneh Khoshnevisan", "authors": "Farzaneh Khoshnevisan, Zhewen Fan", "title": "RSM-GAN: A Convolutional Recurrent GAN for Anomaly Detection in\n  Contaminated Seasonal Multivariate Time Series", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust anomaly detection is a requirement for monitoring complex modern\nsystems with applications such as cyber-security, fraud prevention, and\nmaintenance. These systems generate multiple correlated time series that are\nhighly seasonal and noisy. This paper presents a novel unsupervised deep\nlearning architecture for multivariate time series anomaly detection, called\nRobust Seasonal Multivariate Generative Adversarial Network (RSM-GAN). It\nextends recent advancements in GANs with adoption of convolutional-LSTM layers\nand an attention mechanism to produce state-of-the-art performance. We conduct\nextensive experiments to demonstrate the strength of our architecture in\nadjusting for complex seasonality patterns and handling severe levels of\ntraining data contamination. We also propose a novel anomaly score assignment\nand causal inference framework. We compare RSM-GAN with existing classical and\ndeep-learning based anomaly detection models, and the results show that our\narchitecture is associated with the lowest false positive rate and improves\nprecision by 30% and 16% in real-world and synthetic data, respectively.\nFurthermore, we report the superiority of RSM-GAN regarding accurate root cause\nidentification and NAB scores in all data settings.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:45:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Khoshnevisan", "Farzaneh", ""], ["Fan", "Zhewen", ""]]}, {"id": "1911.07109", "submitter": "Xiaojian Ma", "authors": "Mingxuan Jing, Xiaojian Ma, Wenbing Huang, Fuchun Sun, Chao Yang, Bin\n  Fang, Huaping Liu", "title": "Reinforcement Learning from Imperfect Demonstrations under Soft Expert\n  Guidance", "comments": "Accepted to AAAI 2020. Xiaojian Ma and Mingxuan Jing contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study Reinforcement Learning from Demonstrations (RLfD)\nthat improves the exploration efficiency of Reinforcement Learning (RL) by\nproviding expert demonstrations. Most of existing RLfD methods require\ndemonstrations to be perfect and sufficient, which yet is unrealistic to meet\nin practice. To work on imperfect demonstrations, we first define an imperfect\nexpert setting for RLfD in a formal way, and then point out that previous\nmethods suffer from two issues in terms of optimality and convergence,\nrespectively. Upon the theoretical findings we have derived, we tackle these\ntwo issues by regarding the expert guidance as a soft constraint on regulating\nthe policy exploration of the agent, which eventually leads to a constrained\noptimization problem. We further demonstrate that such problem is able to be\naddressed efficiently by performing a local linear search on its dual form.\nConsiderable empirical evaluations on a comprehensive collection of benchmarks\nindicate our method attains consistent improvement over other RLfD\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 22:33:38 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 23:22:09 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Jing", "Mingxuan", ""], ["Ma", "Xiaojian", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Yang", "Chao", ""], ["Fang", "Bin", ""], ["Liu", "Huaping", ""]]}, {"id": "1911.07123", "submitter": "Donghan Yu", "authors": "Donghan Yu, Ruohong Zhang, Zhengbao Jiang, Yuexin Wu, Yiming Yang", "title": "Graph-Revised Convolutional Network", "comments": "ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have received increasing attention in the\nmachine learning community for effectively leveraging both the content features\nof nodes and the linkage patterns across graphs in various applications. As\nreal-world graphs are often incomplete and noisy, treating them as ground-truth\ninformation, which is a common practice in most GCNs, unavoidably leads to\nsub-optimal solutions. Existing efforts for addressing this problem either\ninvolve an over-parameterized model which is difficult to scale, or simply\nre-weight observed edges without dealing with the missing-edge issue. This\npaper proposes a novel framework called Graph-Revised Convolutional Network\n(GRCN), which avoids both extremes. Specifically, a GCN-based graph revision\nmodule is introduced for predicting missing edges and revising edge weights\nw.r.t. downstream tasks via joint optimization. A theoretical analysis reveals\nthe connection between GRCN and previous work on multigraph belief propagation.\nExperiments on six benchmark datasets show that GRCN consistently outperforms\nstrong baseline methods by a large margin, especially when the original graphs\nare severely incomplete or the labeled instances for model training are highly\nsparse.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 01:00:12 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 01:29:28 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 16:58:18 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yu", "Donghan", ""], ["Zhang", "Ruohong", ""], ["Jiang", "Zhengbao", ""], ["Wu", "Yuexin", ""], ["Yang", "Yiming", ""]]}, {"id": "1911.07128", "submitter": "Ruoxi Jia", "authors": "Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David Dao, Bhavya Kailkhura,\n  Ce Zhang, Bo Li, Dawn Song", "title": "Scalability vs. Utility: Do We Have to Sacrifice One for the Other in\n  Data Importance Quantification?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the importance of each training point to a learning task is a\nfundamental problem in machine learning and the estimated importance scores\nhave been leveraged to guide a range of data workflows such as data\nsummarization and domain adaption. One simple idea is to use the leave-one-out\nerror of each training point to indicate its importance. Recent work has also\nproposed to use the Shapley value, as it defines a unique value distribution\nscheme that satisfies a set of appealing properties. However, calculating\nShapley values is often expensive, which limits its applicability in real-world\napplications at scale. Multiple heuristics to improve the scalability of\ncalculating Shapley values have been proposed recently, with the potential risk\nof compromising their utility in real-world applications.\n  \\textit{How well do existing data quantification methods perform on existing\nworkflows? How do these methods compare with each other, empirically and\ntheoretically? Must we sacrifice scalability for the utility in these workflows\nwhen using these methods?} In this paper, we conduct a novel theoretical\nanalysis comparing the utility of different importance quantification methods,\nand report extensive experimental studies on existing and proposed workflows\nsuch as noisy label detection, watermark removal, data summarization, data\nacquisition, and domain adaptation. We show that Shapley value approximation\nbased on a $K$NN surrogate over pre-trained feature embeddings obtains\ncomparable utility with existing algorithms while achieving significant\nscalability improvement, often by orders of magnitude. Our theoretical analysis\nalso justifies its advantage over the leave-one-out error.\n  The code is available at \\url{https://github.com/AI-secure/Shapley-Study}.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 02:00:10 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 20:36:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jia", "Ruoxi", ""], ["Wu", "Fan", ""], ["Sun", "Xuehui", ""], ["Xu", "Jiacen", ""], ["Dao", "David", ""], ["Kailkhura", "Bhavya", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07132", "submitter": "Quanming Yao", "authors": "Yongqi Zhang, Quanming Yao, Lei Chen", "title": "Interstellar: Searching Recurrent Architecture for Knowledge Graph\n  Embedding", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embedding is well-known in learning representations of\nKGs. Many models have been proposed to learn the interactions between entities\nand relations of the triplets. However, long-term information among multiple\ntriplets is also important to KG. In this work, based on the relational paths,\nwhich are composed of a sequence of triplets, we define the Interstellar as a\nrecurrent neural architecture search problem for the short-term and long-term\ninformation along the paths. First, we analyze the difficulty of using a\nunified model to work as the Interstellar. Then, we propose to search for\nrecurrent architecture as the Interstellar for different KG tasks. A case study\non synthetic data illustrates the importance of the defined search problem.\nExperiments on real datasets demonstrate the effectiveness of the searched\nmodels and the efficiency of the proposed hybrid-search algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 02:16:24 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 14:24:10 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 07:16:19 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zhang", "Yongqi", ""], ["Yao", "Quanming", ""], ["Chen", "Lei", ""]]}, {"id": "1911.07135", "submitter": "Ruoxi Jia", "authors": "Yuheng Zhang, Ruoxi Jia, Hengzhi Pei, Wenxiao Wang, Bo Li, Dawn Song", "title": "The Secret Revealer: Generative Model-Inversion Attacks Against Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies model-inversion attacks, in which the access to a model is\nabused to infer information about the training data. Since its first\nintroduction, such attacks have raised serious concerns given that training\ndata usually contain privacy-sensitive information. Thus far, successful\nmodel-inversion attacks have only been demonstrated on simple models, such as\nlinear regression and logistic regression. Previous attempts to invert neural\nnetworks, even the ones with simple architectures, have failed to produce\nconvincing results. We present a novel attack method, termed the generative\nmodel-inversion attack, which can invert deep neural networks with high success\nrates. Rather than reconstructing private training data from scratch, we\nleverage partial public information, which can be very generic, to learn a\ndistributional prior via generative adversarial networks (GANs) and use it to\nguide the inversion process. Moreover, we theoretically prove that a model's\npredictive power and its vulnerability to inversion attacks are indeed two\nsides of the same coin---highly predictive models are able to establish a\nstrong correlation between features and labels, which coincides exactly with\nwhat an adversary exploits to mount the attacks. Our extensive experiments\ndemonstrate that the proposed attack improves identification accuracy over the\nexisting work by about 75\\% for reconstructing face images from a\nstate-of-the-art face recognition classifier. We also show that differential\nprivacy, in its canonical form, is of little avail to defend against our\nattacks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 02:48:05 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 00:14:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Yuheng", ""], ["Jia", "Ruoxi", ""], ["Pei", "Hengzhi", ""], ["Wang", "Wenxiao", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07140", "submitter": "Zhichao Huang", "authors": "Zhichao Huang, Tong Zhang", "title": "Black-Box Adversarial Attack with Transferable Model-based Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for black-box adversarial attack. Unlike previous\nmethods that combined transfer-based and scored-based methods by using the\ngradient or initialization of a surrogate white-box model, this new method\ntries to learn a low-dimensional embedding using a pretrained model, and then\nperforms efficient search within the embedding space to attack an unknown\ntarget network. The method produces adversarial perturbations with high level\nsemantic patterns that are easily transferable. We show that this approach can\ngreatly improve the query efficiency of black-box adversarial attack across\ndifferent target network architectures. We evaluate our approach on MNIST,\nImageNet and Google Cloud Vision API, resulting in a significant reduction on\nthe number of queries. We also attack adversarially defended networks on\nCIFAR10 and ImageNet, where our method not only reduces the number of queries,\nbut also improves the attack success rate.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:10:49 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 12:39:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Huang", "Zhichao", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.07147", "submitter": "Kui Yu", "authors": "Kui Yu, Xianjie Guo, Lin Liu, Jiuyong Li, Hao Wang, Zhaolong Ling,\n  Xindong Wu", "title": "Causality-based Feature Selection: Methods and Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a crucial preprocessing step in data analytics and\nmachine learning. Classical feature selection algorithms select features based\non the correlations between predictive features and the class variable and do\nnot attempt to capture causal relationships between them. It has been shown\nthat the knowledge about the causal relationships between features and the\nclass variable has potential benefits for building interpretable and robust\nprediction models, since causal relationships imply the underlying mechanism of\na system. Consequently, causality-based feature selection has gradually\nattracted greater attentions and many algorithms have been proposed. In this\npaper, we present a comprehensive review of recent advances in causality-based\nfeature selection. To facilitate the development of new algorithms in the\nresearch area and make it easy for the comparisons between new methods and\nexisting ones, we develop the first open-source package, called CausalFS, which\nconsists of most of the representative causality-based feature selection\nalgorithms (available at https://github.com/kuiy/CausalFS). Using CausalFS, we\nconduct extensive experiments to compare the representative algorithms with\nboth synthetic and real-world data sets. Finally, we discuss some challenging\nproblems to be tackled in future causality-based feature selection research.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:49:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yu", "Kui", ""], ["Guo", "Xianjie", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""], ["Wang", "Hao", ""], ["Ling", "Zhaolong", ""], ["Wu", "Xindong", ""]]}, {"id": "1911.07183", "submitter": "Kunjin Chen", "authors": "Kunjin Chen, Yu Zhang, Qin Wang, Jun Hu, Hang Fan, Jinliang He", "title": "Scale- and Context-Aware Convolutional Non-intrusive Load Monitoring", "comments": "Accepted by IEEE Transactions on Power Systems", "journal-ref": null, "doi": "10.1109/TPWRS.2019.2953225", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive load monitoring addresses the challenging task of decomposing\nthe aggregate signal of a household's electricity consumption into\nappliance-level data without installing dedicated meters. By detecting load\nmalfunction and recommending energy reduction programs, cost-effective\nnon-intrusive load monitoring provides intelligent demand-side management for\nutilities and end users. In this paper, we boost the accuracy of energy\ndisaggregation with a novel neural network structure named scale- and\ncontext-aware network, which exploits multi-scale features and contextual\ninformation. Specifically, we develop a multi-branch architecture with multiple\nreceptive field sizes and branch-wise gates that connect the branches in the\nsub-networks. We build a self-attention module to facilitate the integration of\nglobal context, and we incorporate an adversarial loss and on-state\naugmentation to further improve the model's performance. Extensive simulation\nresults tested on open datasets corroborate the merits of the proposed\napproach, which significantly outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 08:25:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Kunjin", ""], ["Zhang", "Yu", ""], ["Wang", "Qin", ""], ["Hu", "Jun", ""], ["Fan", "Hang", ""], ["He", "Jinliang", ""]]}, {"id": "1911.07198", "submitter": "Evgenii Zheltonozhskii", "authors": "Yaniv Nemcovsky, Evgenii Zheltonozhskii, Chaim Baskin, Brian Chmiel,\n  Maxim Fishman, Alex M. Bronstein, Avi Mendelson", "title": "Smoothed Inference for Adversarially-Trained Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks are known to be vulnerable to adversarial attacks.\nCurrent methods of defense from such attacks are based on either implicit or\nexplicit regularization, e.g., adversarial training. Randomized smoothing, the\naveraging of the classifier outputs over a random distribution centered in the\nsample, has been shown to guarantee the performance of a classifier subject to\nbounded perturbations of the input. In this work, we study the application of\nrandomized smoothing as a way to improve performance on unperturbed data as\nwell as to increase robustness to adversarial attacks. The proposed technique\ncan be applied on top of any existing adversarial defense, but works\nparticularly well with the randomized approaches. We examine its performance on\ncommon white-box (PGD) and black-box (transfer and NAttack) attacks on CIFAR-10\nand CIFAR-100, substantially outperforming previous art for most scenarios and\ncomparable on others. For example, we achieve 60.4% accuracy under a PGD attack\non CIFAR-10 using ResNet-20, outperforming previous art by 11.7%. Since our\nmethod is based on sampling, it lends itself well for trading-off between the\nmodel inference complexity and its performance. A reference implementation of\nthe proposed techniques is provided at https://github.com/yanemcovsky/SIAM\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:38:45 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:13:03 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nemcovsky", "Yaniv", ""], ["Zheltonozhskii", "Evgenii", ""], ["Baskin", "Chaim", ""], ["Chmiel", "Brian", ""], ["Fishman", "Maxim", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1911.07203", "submitter": "Zhuo Yang", "authors": "Zhuo Yang, Yufei Han, Guoxian Yu, Qiang Yang, Xiangliang Zhang", "title": "Prototypical Networks for Multi-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to formulate multi-label learning as a estimation of class\ndistribution in a non-linear embedding space, where for each label, its\npositive data embeddings and negative data embeddings distribute compactly to\nform a positive component and negative component respectively, while the\npositive component and negative component are pushed away from each other. Duo\nto the shared embedding space for all labels, the distribution of embeddings\npreserves instances' label membership and feature matrix, thus encodes the\nfeature-label relation and nonlinear label dependency. Labels of a given\ninstance are inferred in the embedding space by measuring the probabilities of\nits belongingness to the positive or negative components of each label.\nSpecially, the probabilities are modeled as the distance from the given\ninstance to representative positive or negative prototypes. Extensive\nexperiments validate that the proposed solution can provide distinctively more\naccurate multi-label classification than other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 10:16:45 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 07:16:46 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Yang", "Zhuo", ""], ["Han", "Yufei", ""], ["Yu", "Guoxian", ""], ["Yang", "Qiang", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1911.07224", "submitter": "Sujoy Paul", "authors": "Sujoy Paul, Jeroen van Baar, Amit K. Roy-Chowdhury", "title": "Learning from Trajectories via Subgoal Discovery", "comments": "NeurIPS 2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to solve complex goal-oriented tasks with sparse terminal-only\nrewards often requires an enormous number of samples. In such cases, using a\nset of expert trajectories could help to learn faster. However, Imitation\nLearning (IL) via supervised pre-training with these trajectories may not\nperform as well and generally requires additional finetuning with\nexpert-in-the-loop. In this paper, we propose an approach which uses the expert\ntrajectories and learns to decompose the complex main task into smaller\nsub-goals. We learn a function which partitions the state-space into sub-goals,\nwhich can then be used to design an extrinsic reward function. We follow a\nstrategy where the agent first learns from the trajectories using IL and then\nswitches to Reinforcement Learning (RL) using the identified sub-goals, to\nalleviate the errors in the IL step. To deal with states which are\nunder-represented by the trajectory set, we also learn a function to modulate\nthe sub-goal predictions. We show that our method is able to solve complex\ngoal-oriented tasks, which other RL, IL or their combinations in literature are\nnot able to solve.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:55:45 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Paul", "Sujoy", ""], ["van Baar", "Jeroen", ""], ["Roy-Chowdhury", "Amit K.", ""]]}, {"id": "1911.07227", "submitter": "Leen Alawieh", "authors": "Leen Alawieh, Jonathan Goodman, John B. Bell", "title": "Iterative Construction of Gaussian Process Surrogate Models for Bayesian\n  Inference", "comments": null, "journal-ref": null, "doi": "10.1016/j.jspi.2019.11.002", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm is developed to tackle the issue of sampling non-Gaussian\nmodel parameter posterior probability distributions that arise from solutions\nto Bayesian inverse problems. The algorithm aims to mitigate some of the\nhurdles faced by traditional Markov Chain Monte Carlo (MCMC) samplers, through\nconstructing proposal probability densities that are both, easy to sample and\nthat provide a better approximation to the target density than a simple\nGaussian proposal distribution would. To achieve that, a Gaussian proposal\ndistribution is augmented with a Gaussian Process (GP) surface that helps\ncapture non-linearities in the log-likelihood function. In order to train the\nGP surface, an iterative approach is adopted for the optimal selection of\npoints in parameter space. Optimality is sought by maximizing the information\ngain of the GP surface using a minimum number of forward model simulation runs.\nThe accuracy of the GP-augmented surface approximation is assessed in two ways.\nThe first consists of comparing predictions obtained from the approximate\nsurface with those obtained through running the actual simulation model at\nhold-out points in parameter space. The second consists of a measure based on\nthe relative variance of sample weights obtained from sampling the approximate\nposterior probability distribution of the model parameters. The efficacy of\nthis new algorithm is tested on inferring reaction rate parameters in a 3-node\nand 6-node network toy problems, which imitate idealized reaction networks in\ncombustion applications.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 12:57:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Alawieh", "Leen", ""], ["Goodman", "Jonathan", ""], ["Bell", "John B.", ""]]}, {"id": "1911.07231", "submitter": "Francesco Ortelli", "authors": "Francesco Ortelli and Sara van de Geer", "title": "Adaptive Rates for Total Variation Image Denoising", "comments": "38 pages, 6 figures", "journal-ref": "Journal of Machine Learning Research, 21(247), 2020", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the theoretical properties of image denoising via total variation\npenalized least-squares. We define the total vatiation in terms of the\ntwo-dimensional total discrete derivative of the image and show that it gives\nrise to denoised images that are piecewise constant on rectangular sets. We\nprove that, if the true image is piecewise constant on just a few rectangular\nsets, the denoised image converges to the true image at a parametric rate, up\nto a log factor. More generally, we show that the denoised image enjoys oracle\nproperties, that is, it is almost as good as if some aspects of the true image\nwere known. In other words, image denoising with total variation regularization\nleads to an adaptive reconstruction of the true image.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:09:50 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 13:38:22 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 19:31:19 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 09:01:02 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2021 10:21:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Ortelli", "Francesco", ""], ["van de Geer", "Sara", ""]]}, {"id": "1911.07245", "submitter": "Krisztian Buza", "authors": "Krisztian Buza", "title": "Encouraging an Appropriate Representation Simplifies Training of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption about neural networks is that they can learn an\nappropriate internal representations on their own, see e.g. end-to-end\nlearning. In this work we challenge this assumption. We consider two simple\ntasks and show that the state-of-the-art training algorithm fails, although the\nmodel itself is able to represent an appropriate solution. We will demonstrate\nthat encouraging an appropriate internal representation allows the same model\nto solve these tasks. While we do not claim that it is impossible to solve\nthese tasks by other means (such as neural networks with more layers), our\nresults illustrate that integration of domain knowledge in form of a desired\ninternal representation may improve the generalization ability of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:30:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Buza", "Krisztian", ""]]}, {"id": "1911.07247", "submitter": "Jonathan Baxter", "authors": "Peter L. Bartlett and Jonathan Baxter", "title": "Hebbian Synaptic Modifications in Spiking Neurons that Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a new model of synaptic plasticity, based on recent\nalgorithms for reinforcement learning (in which an agent attempts to learn\nappropriate actions to maximize its long-term average reward). We show that\nthese direct reinforcement learning algorithms also give locally optimal\nperformance for the problem of reinforcement learning with multiple agents,\nwithout any explicit communication between agents. By considering a network of\nspiking neurons as a collection of agents attempting to maximize the long-term\naverage of a reward signal, we derive a synaptic update rule that is\nqualitatively similar to Hebb's postulate. This rule requires only simple\ncomputations, such as addition and leaky integration, and involves only\nquantities that are available in the vicinity of the synapse. Furthermore, it\nleads to synaptic connection strengths that give locally optimal values of the\nlong term average reward. The reinforcement learning paradigm is sufficiently\nbroad to encompass many learning problems that are solved by the brain. We\nillustrate, with simulations, that the approach is effective for simple pattern\nclassification and motor learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:36:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Baxter", "Jonathan", ""]]}, {"id": "1911.07249", "submitter": "Martin Gauch", "authors": "Martin Gauch, Juliane Mai, Jimmy Lin", "title": "The Proper Care and Feeding of CAMELS: How Limited Training Data Affects\n  Streamflow Prediction", "comments": "13 pages, 3 figures", "journal-ref": "Environmental Modelling & Software, Volume 135, 2021, 104926", "doi": "10.1016/j.envsoft.2020.104926", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate streamflow prediction largely relies on historical meteorological\nrecords and streamflow measurements. For many regions, however, such data are\nonly scarcely available. Facing this problem, many studies simply trained their\nmachine learning models on the region's available data, leaving possible\nrepercussions of this strategy unclear. In this study, we evaluate the\nsensitivity of tree- and LSTM-based models to limited training data, both in\nterms of geographic diversity and different time spans. We feed the models\nmeteorological observations disseminated with the CAMELS dataset, and\nindividually restrict the training period length, number of training basins,\nand input sequence length. We quantify how additional training data improve\npredictions and how many previous days of forcings we should feed the models to\nobtain best predictions for each training set size. Further, our findings show\nthat tree- and LSTM-based models provide similarly accurate predictions on\nsmall datasets, while LSTMs are superior given more training data.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:50:04 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 13:50:19 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 08:56:22 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Gauch", "Martin", ""], ["Mai", "Juliane", ""], ["Lin", "Jimmy", ""]]}, {"id": "1911.07255", "submitter": "Amit Boyarski", "authors": "Amit Boyarski, Sanketh Vedula, Alex Bronstein", "title": "Spectral Geometric Matrix Completion", "comments": "Accepted to Mathematical and Scientific Machine Learning (MSML) 2021\n  https://msml21.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Matrix Factorization (DMF) is an emerging approach to the problem of\nmatrix completion. Recent works have established that gradient descent applied\nto a DMF model induces an implicit regularization on the rank of the recovered\nmatrix. In this work we interpret the DMF model through the lens of spectral\ngeometry. This allows us to incorporate explicit regularization without\nbreaking the DMF structure, thus enjoying the best of both worlds. In\nparticular, we focus on matrix completion problems with underlying geometric or\ntopological relations between the rows and/or columns. Such relations are\nprevalent in matrix completion problems that arise in many applications, such\nas recommender systems and drug-target interaction. Our contributions enable\nDMF models to exploit these relations, and make them competitive on real\nbenchmarks, while exhibiting one of the first successful applications of deep\nlinear networks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 15:06:34 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 12:10:30 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 14:27:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Boyarski", "Amit", ""], ["Vedula", "Sanketh", ""], ["Bronstein", "Alex", ""]]}, {"id": "1911.07292", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient Ridge Solutions for the Incremental Broad Learning System on\n  Added Inputs by Updating the Inverse or the Inverse Cholesky Factor of the\n  Hermitian matrix in the Ridge Inverse", "comments": "arXiv admin note: text overlap with arXiv:1911.04872", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This brief proposes two BLS algorithms to improve the existing BLS for new\nadded inputs in [7]. The proposed BLS algorithms avoid computing the ridge\ninverse, by computing the ridge solution (i.e., the output weights) from the\ninverse or the inverse Cholesky factor of the Hermitian matrix in the ridge\ninverse. The proposed BLS algorithm 1 updates the inverse of the Hermitian\nmatrix by the matrix inversion lemma [12]. To update the upper-triangular\ninverse Cholesky factor of the Hermitian matrix, the proposed BLS algorithm 2\nmultiplies the inverse Cholesky factor with an upper-triangular intermediate\nmatrix, which is computed by a Cholesky factorization or an inverse Cholesky\nfactorization. Assume that the newly added input matrix corresponding to the\nadded inputs is p * k, where p and k are the number of added training samples\nand the total node number, respectively. When p > k, the inverse of a sum of\nmatrices [11] is utilized to compute the intermediate variables by a smaller\nmatrix inverse in the proposed algorithm 1, or by a smaller inverse Cholesky\nfactorization in the proposed algorithm 2. Usually the Hermitian matrix in the\nridge inverse is smaller than the ridge inverse. Thus the proposed algorithms 1\nand 2 require less flops (floating-point operations) than the existing BLS\nalgorithm, which is verified by the theoretical flops calculation. In numerical\nexperiments, the speedups for the case of p > k in each additional training\ntime of the proposed BLS algorithms 1 and 2 over the existing algorithm are\n1.95 - 5.43 and 2.29 - 6.34, respectively, and the speedups for the case of p <\nk are 8.83 - 10.21 and 2.28 - 2.58, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:19:52 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 04:36:01 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 06:34:18 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "1911.07293", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Ying Wei, Peilin Zhao, Shuaicheng Niu, Qingyao Wu,\n  Mingkui Tan, Junzhou Huang", "title": "Collaborative Unsupervised Domain Adaptation for Medical Image Diagnosis", "comments": "Medical Imaging meets NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning based medical image diagnosis has shown great potential in\nclinical medicine. However, it often suffers two major difficulties in\npractice: 1) only limited labeled samples are available due to expensive\nannotation costs over medical images; 2) labeled images may contain\nconsiderable label noises (e.g., mislabeling labels) due to diagnostic\ndifficulties. In this paper, we seek to exploit rich labeled data from relevant\ndomains to help the learning in the target task with unsupervised domain\nadaptation (UDA). Unlike most existing UDA methods which rely on clean labeled\ndata or assume samples are equally transferable, we propose a novel\nCollaborative Unsupervised Domain Adaptation algorithm to conduct\ntransferability-aware domain adaptation and conquer label noise in a\ncooperative way. Promising empirical results verify the superiority of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 17:18:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Yifan", ""], ["Wei", "Ying", ""], ["Zhao", "Peilin", ""], ["Niu", "Shuaicheng", ""], ["Wu", "Qingyao", ""], ["Tan", "Mingkui", ""], ["Huang", "Junzhou", ""]]}, {"id": "1911.07304", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano and Konstantinos Spiliopoulos", "title": "Asymptotics of Reinforcement Learning with Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1907.04108", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a single-layer neural network trained with the Q-learning\nalgorithm converges in distribution to a random ordinary differential equation\nas the size of the model and the number of training steps become large.\nAnalysis of the limit differential equation shows that it has a unique\nstationary solution which is the solution of the Bellman equation, thus giving\nthe optimal control for the problem. In addition, we study the convergence of\nthe limit differential equation to the stationary solution. As a by-product of\nour analysis, we obtain the limiting behavior of single-layer neural networks\nwhen trained on i.i.d. data with stochastic gradient descent under the\nwidely-used Xavier initialization.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:27:32 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 02:20:03 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 16:57:56 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 19:15:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1911.07309", "submitter": "Anush Sankaran", "authors": "Senthil Mani, Anush Sankaran, Srikanth Tamilselvam, Akshay Sethi", "title": "Coverage Testing of Deep Learning Models using Dataset Characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs), with its promising performance, are being\nincreasingly used in safety critical applications such as autonomous driving,\ncancer detection, and secure authentication. With growing importance in deep\nlearning, there is a requirement for a more standardized framework to evaluate\nand test deep learning models. The primary challenge involved in automated\ngeneration of extensive test cases are: (i) neural networks are difficult to\ninterpret and debug and (ii) availability of human annotators to generate\nspecialized test points. In this research, we explain the necessity to measure\nthe quality of a dataset and propose a test case generation system guided by\nthe dataset properties. From a testing perspective, four different dataset\nquality dimensions are proposed: (i) equivalence partitioning, (ii) centroid\npositioning, (iii) boundary conditioning, and (iv) pair-wise boundary\nconditioning. The proposed system is evaluated on well known image\nclassification datasets such as MNIST, Fashion-MNIST, CIFAR10, CIFAR100, and\nSVHN against popular deep learning models such as LeNet, ResNet-20, VGG-19.\nFurther, we conduct various experiments to demonstrate the effectiveness of\nsystematic test case generation system for evaluating deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 18:07:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mani", "Senthil", ""], ["Sankaran", "Anush", ""], ["Tamilselvam", "Srikanth", ""], ["Sethi", "Akshay", ""]]}, {"id": "1911.07320", "submitter": "Giulia Fracastoro", "authors": "Giuseppe C. Calafiore and Giulia Fracastoro", "title": "Sparse $\\ell_1$ and $\\ell_2$ Center Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nearest-centroid classifier is a simple linear-time classifier based on\ncomputing the centroids of the data classes in the training phase, and then\nassigning a new datum to the class corresponding to its nearest centroid.\nThanks to its very low computational cost, the nearest-centroid classifier is\nstill widely used in machine learning, despite the development of many other\nmore sophisticated classification methods. In this paper, we propose two sparse\nvariants of the nearest-centroid classifier, based respectively on $\\ell_1$ and\n$\\ell_2$ distance criteria. The proposed sparse classifiers perform\nsimultaneous classification and feature selection, by detecting the features\nthat are most relevant for the classification purpose. We show that training of\nthe proposed sparse models, with both distance criteria, can be performed\nexactly (i.e., the globally optimal set of features is selected) and at a\nquasi-linear computational cost. The experimental results show that the\nproposed methods are competitive in accuracy with state-of-the-art feature\nselection techniques, while having a significantly lower computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:15:59 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 11:10:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Calafiore", "Giuseppe C.", ""], ["Fracastoro", "Giulia", ""]]}, {"id": "1911.07323", "submitter": "Ziniu Hu", "authors": "Difan Zou and Ziniu Hu and Yewen Wang and Song Jiang and Yizhou Sun\n  and Quanquan Gu", "title": "Layer-Dependent Importance Sampling for Training Deep and Large Graph\n  Convolutional Networks", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have recently received wide attentions,\ndue to their successful applications in different graph tasks and different\ndomains. Training GCNs for a large graph, however, is still a challenge.\nOriginal full-batch GCN training requires calculating the representation of all\nthe nodes in the graph per GCN layer, which brings in high computation and\nmemory costs. To alleviate this issue, several sampling-based methods have been\nproposed to train GCNs on a subset of nodes. Among them, the node-wise\nneighbor-sampling method recursively samples a fixed number of neighbor nodes,\nand thus its computation cost suffers from exponential growing neighbor size;\nwhile the layer-wise importance-sampling method discards the neighbor-dependent\nconstraints, and thus the nodes sampled across layer suffer from sparse\nconnection problem. To deal with the above two problems, we propose a new\neffective sampling algorithm called LAyer-Dependent ImportancE Sampling\n(LADIES). Based on the sampled nodes in the upper layer, LADIES selects their\nneighborhood nodes, constructs a bipartite subgraph and computes the importance\nprobability accordingly. Then, it samples a fixed number of nodes by the\ncalculated probability, and recursively conducts such procedure per layer to\nconstruct the whole computation graph. We prove theoretically and\nexperimentally, that our proposed sampling algorithm outperforms the previous\nsampling methods in terms of both time and memory costs. Furthermore, LADIES is\nshown to have better generalization accuracy than original full-batch GCN, due\nto its stochastic nature.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:40:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zou", "Difan", ""], ["Hu", "Ziniu", ""], ["Wang", "Yewen", ""], ["Jiang", "Song", ""], ["Sun", "Yizhou", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.07324", "submitter": "Maryam Aliakbarpour", "authors": "Maryam Aliakbarpour, Sandeep Silwal", "title": "Testing Properties of Multiple Distributions with Few Samples", "comments": "ITCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new setting for testing properties of distributions while\nreceiving samples from several distributions, but few samples per distribution.\nGiven samples from $s$ distributions, $p_1, p_2, \\ldots, p_s$, we design\ntesters for the following problems: (1) Uniformity Testing: Testing whether all\nthe $p_i$'s are uniform or $\\epsilon$-far from being uniform in\n$\\ell_1$-distance (2) Identity Testing: Testing whether all the $p_i$'s are\nequal to an explicitly given distribution $q$ or $\\epsilon$-far from $q$ in\n$\\ell_1$-distance, and (3) Closeness Testing: Testing whether all the $p_i$'s\nare equal to a distribution $q$ which we have sample access to, or\n$\\epsilon$-far from $q$ in $\\ell_1$-distance. By assuming an additional natural\ncondition about the source distributions, we provide sample optimal testers for\nall of these problems.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:44:13 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Aliakbarpour", "Maryam", ""], ["Silwal", "Sandeep", ""]]}, {"id": "1911.07335", "submitter": "Haw-Shiuan Chang", "authors": "Haw-Shiuan Chang, Shankar Vembu, Sunil Mohan, Rheeya Uppaal, Andrew\n  McCallum", "title": "Using Error Decay Prediction to Overcome Practical Issues of Deep Active\n  Learning for Named Entity Recognition", "comments": "This is a pre-print of an article published in Springer Machine\n  Learning journal. The final authenticated version is available online at:\n  https://doi.org/10.1007/s10994-020-05897-1", "journal-ref": null, "doi": "10.1007/s10994-020-05897-1", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing deep active learning algorithms achieve impressive sampling\nefficiency on natural language processing tasks. However, they exhibit several\nweaknesses in practice, including (a) inability to use uncertainty sampling\nwith black-box models, (b) lack of robustness to labeling noise, and (c) lack\nof transparency. In response, we propose a transparent batch active sampling\nframework by estimating the error decay curves of multiple feature-defined\nsubsets of the data. Experiments on four named entity recognition (NER) tasks\ndemonstrate that the proposed methods significantly outperform\ndiversification-based methods for black-box NER taggers, and can make the\nsampling process more robust to labeling noise when combined with\nuncertainty-based methods. Furthermore, the analysis of experimental results\nsheds light on the weaknesses of different active sampling strategies, and when\ntraditional uncertainty-based or diversification-based methods can be expected\nto work well.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 20:41:32 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 00:33:11 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Chang", "Haw-Shiuan", ""], ["Vembu", "Shankar", ""], ["Mohan", "Sunil", ""], ["Uppaal", "Rheeya", ""], ["McCallum", "Andrew", ""]]}, {"id": "1911.07337", "submitter": "Scott Cameron", "authors": "Scott A. Cameron, Hans C. Eggers and Steve Kroon", "title": "Stochastic Gradient Annealed Importance Sampling for Efficient Online\n  Marginal Likelihood Estimation", "comments": null, "journal-ref": "Entropy 2019, 21(11), 1109", "doi": "10.3390/e21111109", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider estimating the marginal likelihood in settings with independent\nand identically distributed (i.i.d.) data. We propose estimating the predictive\ndistributions in a sequential factorization of the marginal likelihood in such\nsettings by using stochastic gradient Markov Chain Monte Carlo techniques. This\napproach is far more efficient than traditional marginal likelihood estimation\ntechniques such as nested sampling and annealed importance sampling due to its\nuse of mini-batches to approximate the likelihood. Stability of the estimates\nis provided by an adaptive annealing schedule. The resulting stochastic\ngradient annealed importance sampling (SGAIS) technique, which is the key\ncontribution of our paper, enables us to estimate the marginal likelihood of a\nnumber of models considerably faster than traditional approaches, with no\nnoticeable loss of accuracy. An important benefit of our approach is that the\nmarginal likelihood is calculated in an online fashion as data becomes\navailable, allowing the estimates to be used for applications such as online\nweighted model combination.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 20:59:51 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cameron", "Scott A.", ""], ["Eggers", "Hans C.", ""], ["Kroon", "Steve", ""]]}, {"id": "1911.07346", "submitter": "Haichao Yu", "authors": "Haichao Yu, Haoxiang Li, Honghui Shi, Thomas S. Huang, Gang Hua", "title": "Any-Precision Deep Neural Networks", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present any-precision deep neural networks (DNNs), which are trained with\na new method that allows the learned DNNs to be flexible in numerical precision\nduring inference. The same model in runtime can be flexibly and directly set to\ndifferent bit-widths, by truncating the least significant bits, to support\ndynamic speed and accuracy trade-off. When all layers are set to low-bits, we\nshow that the model achieved accuracy comparable to dedicated models trained at\nthe same precision. This nice property facilitates flexible deployment of deep\nlearning models in real-world applications, where in practice trade-offs\nbetween model accuracy and runtime efficiency are often sought. Previous\nliterature presents solutions to train models at each individual fixed\nefficiency/accuracy trade-off point. But how to produce a model flexible in\nruntime precision is largely unexplored. When the demand of efficiency/accuracy\ntrade-off varies from time to time or even dynamically changes in runtime, it\nis infeasible to re-train models accordingly, and the storage budget may forbid\nkeeping multiple models. Our proposed framework achieves this flexibility\nwithout performance degradation. More importantly, we demonstrate that this\nachievement is agnostic to model architectures and applicable to multiple\nvision tasks. Our code is released at\nhttps://github.com/SHI-Labs/Any-Precision-DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 21:35:32 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 08:13:10 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Yu", "Haichao", ""], ["Li", "Haoxiang", ""], ["Shi", "Honghui", ""], ["Huang", "Thomas S.", ""], ["Hua", "Gang", ""]]}, {"id": "1911.07361", "submitter": "Alessio Bernardo", "authors": "Alessio Bernardo, Emanuele Della Valle and Albert Bifet", "title": "Rebalancing Learning on Evolving Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Nowadays, every device connected to the Internet generates an ever-growing\nstream of data (formally, unbounded). Machine Learning on unbounded data\nstreams is a grand challenge due to its resource constraints. In fact, standard\nmachine learning techniques are not able to deal with data whose statistics is\nsubject to gradual or sudden changes without any warning. Massive Online\nAnalysis (MOA) is the collective name, as well as a software library, for new\nlearners that are able to manage data streams. In this paper, we present a\nresearch study on streaming rebalancing. Indeed, data streams can be imbalanced\nas static data, but there is not a method to rebalance them incrementally, one\nelement at a time. For this reason we propose a new streaming approach able to\nrebalance data streams online. Our new methodology is evaluated against some\nsynthetically generated datasets using prequential evaluation in order to\ndemonstrate that it outperforms the existing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 23:13:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bernardo", "Alessio", ""], ["Della Valle", "Emanuele", ""], ["Bifet", "Albert", ""]]}, {"id": "1911.07368", "submitter": "Jason Wei", "authors": "Lia X. Harrington, Jason W. Wei, Arief A. Suriawinata, Todd A.\n  Mackenzie, Saeed Hassanpour", "title": "Predicting colorectal polyp recurrence using time-to-event analysis of\n  medical records", "comments": "Accepted in AMIA 2020 Informatics Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying patient characteristics that influence the rate of colorectal\npolyp recurrence can provide important insights into which patients are at\nhigher risk for recurrence. We used natural language processing to extract\npolyp morphological characteristics from 953 polyp-presenting patients'\nelectronic medical records. We used subsequent colonoscopy reports to examine\nhow the time to polyp recurrence (731 patients experienced recurrence) is\ninfluenced by these characteristics as well as anthropometric features using\nKaplan-Meier curves, Cox proportional hazards modeling, and random survival\nforest models. We found that the rate of recurrence differed significantly by\npolyp size, number, and location and patient smoking status. Additionally,\nright-sided colon polyps increased recurrence risk by 30% compared to\nleft-sided polyps. History of tobacco use increased polyp recurrence risk by\n20% compared to never-users. A random survival forest model showed an AUC of\n0.65 and identified several other predictive variables, which can inform\ndevelopment of personalized polyp surveillance plans.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:01:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Harrington", "Lia X.", ""], ["Wei", "Jason W.", ""], ["Suriawinata", "Arief A.", ""], ["Mackenzie", "Todd A.", ""], ["Hassanpour", "Saeed", ""]]}, {"id": "1911.07391", "submitter": "Zhaoyuan Yang", "authors": "Nurali Virani, Naresh Iyer, Zhaoyuan Yang", "title": "Justification-Based Reliability in Machine Learning", "comments": "Extended version of paper accepted at AAAI 2020 with supplementary\n  materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Deep Learning, the field of machine learning (ML) has\nsurpassed human-level performance on diverse classification tasks. At the same\ntime, there is a stark need to characterize and quantify reliability of a\nmodel's prediction on individual samples. This is especially true in\napplication of such models in safety-critical domains of industrial control and\nhealthcare. To address this need, we link the question of reliability of a\nmodel's individual prediction to the epistemic uncertainty of the model's\nprediction. More specifically, we extend the theory of Justified True Belief\n(JTB) in epistemology, created to study the validity and limits of\nhuman-acquired knowledge, towards characterizing the validity and limits of\nknowledge in supervised classifiers. We present an analysis of neural network\nclassifiers linking the reliability of its prediction on an input to\ncharacteristics of the support gathered from the input and latent spaces of the\nnetwork. We hypothesize that the JTB analysis exposes the epistemic uncertainty\n(or ignorance) of a model with respect to its inference, thereby allowing for\nthe inference to be only as strong as the justification permits. We explore\nvarious forms of support (for e.g., k-nearest neighbors (k-NN) and l_p-norm\nbased) generated for an input, using the training data to construct a\njustification for the prediction with that input. Through experiments conducted\non simulated and real datasets, we demonstrate that our approach can provide\nreliability for individual predictions and characterize regions where such\nreliability cannot be ascertained.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 01:15:24 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 22:47:44 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Virani", "Nurali", ""], ["Iyer", "Naresh", ""], ["Yang", "Zhaoyuan", ""]]}, {"id": "1911.07409", "submitter": "Qinyi Chen", "authors": "Andrea Boskovic, Qinyi Chen, Dominik Kufel, Zijie Zhou", "title": "Online Learning and Matching for Resource Allocation Problems", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for an e-commerce platform to maximize its revenue, it must\nrecommend customers items they are most likely to purchase. However, the\ncompany often has business constraints on these items, such as the number of\neach item in stock. In this work, our goal is to recommend items to users as\nthey arrive on a webpage sequentially, in an online manner, in order to\nmaximize reward for a company, but also satisfy budget constraints. We first\napproach the simpler online problem in which the customers arrive as a\nstationary Poisson process, and present an integrated algorithm that performs\nonline optimization and online learning together. We then make the model more\ncomplicated but more realistic, treating the arrival processes as\nnon-stationary Poisson processes. To deal with heterogeneous customer arrivals,\nwe propose a time segmentation algorithm that converts a non-stationary problem\ninto a series of stationary problems. Experiments conducted on large-scale\nsynthetic data demonstrate the effectiveness and efficiency of our proposed\napproaches on solving constrained resource allocation problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 03:36:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Boskovic", "Andrea", ""], ["Chen", "Qinyi", ""], ["Kufel", "Dominik", ""], ["Zhou", "Zijie", ""]]}, {"id": "1911.07412", "submitter": "Cenk Baykal", "authors": "Lucas Liebenwein, Cenk Baykal, Harry Lang, Dan Feldman, Daniela Rus", "title": "Provable Filter Pruning for Efficient Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a provable, sampling-based approach for generating compact\nConvolutional Neural Networks (CNNs) by identifying and removing redundant\nfilters from an over-parameterized network. Our algorithm uses a small batch of\ninput data points to assign a saliency score to each filter and constructs an\nimportance sampling distribution where filters that highly affect the output\nare sampled with correspondingly high probability. In contrast to existing\nfilter pruning approaches, our method is simultaneously data-informed, exhibits\nprovable guarantees on the size and performance of the pruned network, and is\nwidely applicable to varying network architectures and data sets. Our\nanalytical bounds bridge the notions of compressibility and importance of\nnetwork structures, which gives rise to a fully-automated procedure for\nidentifying and preserving filters in layers that are essential to the\nnetwork's performance. Our experimental evaluations on popular architectures\nand data sets show that our algorithm consistently generates sparser and more\nefficient models than those constructed by existing filter pruning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 03:56:49 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 04:39:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liebenwein", "Lucas", ""], ["Baykal", "Cenk", ""], ["Lang", "Harry", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "1911.07418", "submitter": "Dian Ang Yap", "authors": "Dian Ang Yap, Nicholas Roberts, Vinay Uday Prabhu", "title": "Grassmannian Packings in Neural Networks: Learning with Maximal Subspace\n  Packings for Diversity and Anti-Sparsity", "comments": "Presented at Bayesian Deep Learning and Workshop on Information\n  Theory and Machine Learning, 33rd Conference on Neural Information\n  ProcessingSystems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Kernel sparsity (\"dying ReLUs\") and lack of diversity are commonly observed\nin CNN kernels, which decreases model capacity. Drawing inspiration from\ninformation theory and wireless communications, we demonstrate the intersection\nof coding theory and deep learning through the Grassmannian subspace packing\nproblem in CNNs. We propose Grassmannian packings for initial kernel layers to\nbe initialized maximally far apart based on chordal or Fubini-Study distance.\nConvolutional kernels initialized with Grassmannian packings exhibit diverse\nfeatures and obtain diverse representations. We show that Grassmannian\npackings, especially in the initial layers, address kernel sparsity and\nencourage diversity, while improving classification accuracy across shallow and\ndeep CNNs with better convergence rates.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:17:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yap", "Dian Ang", ""], ["Roberts", "Nicholas", ""], ["Prabhu", "Vinay Uday", ""]]}, {"id": "1911.07420", "submitter": "Ignavier Ng", "authors": "Ignavier Ng, Shengyu Zhu, Zhitang Chen, Zhuangyan Fang", "title": "A Graph Autoencoder Approach to Causal Structure Learning", "comments": "NeurIPS 2019 Workshop \"Do the right thing\": machine learning and\n  causal inference for improved decision making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal structure learning has been a challenging task in the past decades and\nseveral mainstream approaches such as constraint- and score-based methods have\nbeen studied with theoretical guarantees. Recently, a new approach has\ntransformed the combinatorial structure learning problem into a continuous one\nand then solved it using gradient-based optimization methods. Following the\nrecent state-of-the-arts, we propose a new gradient-based method to learn\ncausal structures from observational data. The proposed method generalizes the\nrecent gradient-based methods to a graph autoencoder framework that allows\nnonlinear structural equation models and is easily applicable to vector-valued\nvariables. We demonstrate that on synthetic datasets, our proposed method\noutperforms other gradient-based methods significantly, especially on large\ncausal graphs. We further investigate the scalability and efficiency of our\nmethod, and observe a near linear training time when scaling up the graph size.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:22:00 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ng", "Ignavier", ""], ["Zhu", "Shengyu", ""], ["Chen", "Zhitang", ""], ["Fang", "Zhuangyan", ""]]}, {"id": "1911.07427", "submitter": "Kai Hu", "authors": "Kai Hu, Barnabas Poczos", "title": "RotationOut as a Regularization Method for Neural Network", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel regularization method, RotationOut, for\nneural networks. Different from Dropout that handles each neuron/channel\nindependently, RotationOut regards its input layer as an entire vector and\nintroduces regularization by randomly rotating the vector. RotationOut can also\nbe used in convolutional layers and recurrent layers with small modifications.\nWe further use a noise analysis method to interpret the difference between\nRotationOut and Dropout in co-adaptation reduction. Using this method, we also\nshow how to use RotationOut/Dropout together with Batch Normalization.\nExtensive experiments in vision and language tasks are conducted to show the\neffectiveness of the proposed method. Codes are available at\n\\url{https://github.com/RotationOut/RotationOut}.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:45:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hu", "Kai", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1911.07446", "submitter": "Cong Hao", "authors": "Cong Hao, Yao Chen, Xinheng Liu, Atif Sarwari, Daryl Sew, Ashutosh\n  Dhar, Bryan Wu, Dongdong Fu, Jinjun Xiong, Wen-mei Hwu, Junli Gu, Deming Chen", "title": "NAIS: Neural Architecture and Implementation Search and its Applications\n  in Autonomous Driving", "comments": "8 pages, ICCAD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing demands for powerful AI algorithms in many application\ndomains have motivated massive investment in both high-quality deep neural\nnetwork (DNN) models and high-efficiency implementations. In this position\npaper, we argue that a simultaneous DNN/implementation co-design methodology,\nnamed Neural Architecture and Implementation Search (NAIS), deserves more\nresearch attention to boost the development productivity and efficiency of both\nDNN models and implementation optimization. We propose a stylized design\nmethodology that can drastically cut down the search cost while preserving the\nquality of the end solution.As an illustration, we discuss this\nDNN/implementation methodology in the context of both FPGAs and GPUs. We take\nautonomous driving as a key use case as it is one of the most demanding areas\nfor high quality AI algorithms and accelerators. We discuss how such a\nco-design methodology can impact the autonomous driving industry significantly.\nWe identify several research opportunities in this exciting domain.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 06:17:14 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hao", "Cong", ""], ["Chen", "Yao", ""], ["Liu", "Xinheng", ""], ["Sarwari", "Atif", ""], ["Sew", "Daryl", ""], ["Dhar", "Ashutosh", ""], ["Wu", "Bryan", ""], ["Fu", "Dongdong", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""], ["Gu", "Junli", ""], ["Chen", "Deming", ""]]}, {"id": "1911.07453", "submitter": "Chenye Wu", "authors": "Jingshi Cui, Haoxiang Wang, Chenye Wu, Yang Yu", "title": "Vulnerability Analysis for Data Driven Pricing Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics and machine learning techniques are being rapidly adopted into\nthe power system, including power system control as well as electricity market\ndesign. In this paper, from an adversarial machine learning point of view, we\nexamine the vulnerability of data-driven electricity market design. More\nprecisely, we follow the idea that consumer's load profile should uniquely\ndetermine its electricity rate, which yields a clustering oriented pricing\nscheme. We first identify the strategic behaviors of malicious users by\ndefining a notion of disguising. Based on this notion, we characterize the\nsensitivity zones to evaluate the percentage of malicious users in each\ncluster. Based on a thorough cost benefit analysis, we conclude with the\nvulnerability analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 06:58:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cui", "Jingshi", ""], ["Wang", "Haoxiang", ""], ["Wu", "Chenye", ""], ["Yu", "Yang", ""]]}, {"id": "1911.07456", "submitter": "Aleksandar Haber", "authors": "Aleksandar Haber", "title": "Steady-State Control and Machine Learning of Large-Scale Deformable\n  Mirror Models", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Machine Learning (ML) and system identification validation approaches\nto estimate neural network models of large-scale Deformable Mirrors (DMs) used\nin Adaptive Optics (AO) systems. To obtain the training, validation, and test\ndata sets, we simulate a realistic large-scale Finite Element (FE) model of a\nfaceplate DM. The estimated models reproduce the input-output behavior of\nVector AutoRegressive with eXogenous (VARX) input models and can be used for\nthe design of high-performance AO systems. We address the model order selection\nand overfitting problems. We also provide an FE based approach for computing\nsteady-state control signals that produce the desired wavefront shape. This\napproach can be used to predict the steady-state DM correction performance for\ndifferent actuator spacings and configurations. The presented methods are\ntested on models with thousands of state variables and hundreds of actuators.\nThe numerical simulations are performed on low-cost high-performance graphic\nprocessing units and implemented using the TensorFlow machine learning\nframework. The used codes are available online. The approaches presented in\nthis paper are useful for the design and optimization of high-performance DMs\nand AO systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 07:09:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Haber", "Aleksandar", ""]]}, {"id": "1911.07489", "submitter": "Haoyi Xiong", "authors": "Ruosi Wan and Haoyi Xiong and Xingjian Li and Zhanxing Zhu and Jun\n  Huan", "title": "Towards Making Deep Transfer Learning Never Hurt", "comments": "10 pages", "journal-ref": "accapted as long paper at the 19th IEEE International Conference\n  on Data Mining, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning have been frequently used to improve deep neural network\ntraining through incorporating weights of pre-trained networks as the\nstarting-point of optimization for regularization. While deep transfer learning\ncan usually boost the performance with better accuracy and faster convergence,\ntransferring weights from inappropriate networks hurts training procedure and\nmay lead to even lower accuracy. In this paper, we consider deep transfer\nlearning as minimizing a linear combination of empirical loss and regularizer\nbased on pre-trained weights, where the regularizer would restrict the training\nprocedure from lowering the empirical loss, with conflicted descent directions\n(e.g., derivatives). Following the view, we propose a novel strategy making\nregularization-based Deep Transfer learning Never Hurt (DTNH) that, for each\niteration of training procedure, computes the derivatives of the two terms\nseparately, then re-estimates a new descent direction that does not hurt the\nempirical loss minimization while preserving the regularization affects from\nthe pre-trained weights. Extensive experiments have been done using common\ntransfer learning regularizers, such as L2-SP and knowledge distillation, on\ntop of a wide range of deep transfer learning benchmarks including Caltech, MIT\nindoor 67, CIFAR-10 and ImageNet. The empirical results show that the proposed\ndescent direction estimation strategy DTNH can always improve the performance\nof deep transfer learning tasks based on all above regularizers, even when\ntransferring pre-trained weights from inappropriate networks. All in all, DTNH\nstrategy can improve state-of-the-art regularizers in all cases with 0.1%--7%\nhigher accuracy in all experiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:00:05 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wan", "Ruosi", ""], ["Xiong", "Haoyi", ""], ["Li", "Xingjian", ""], ["Zhu", "Zhanxing", ""], ["Huan", "Jun", ""]]}, {"id": "1911.07498", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Peilin Zhao, Shuaicheng Niu, Qingyao Wu, Jiezhang Cao,\n  Junzhou Huang, Mingkui Tan", "title": "Online Adaptive Asymmetric Active Learning with Limited Budgets", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online Active Learning (OAL) aims to manage unlabeled datastream by\nselectively querying the label of data. OAL is applicable to many real-world\nproblems, such as anomaly detection in health-care and finance. In these\nproblems, there are two key challenges: the query budget is often limited; the\nratio between classes is highly imbalanced. In practice, it is quite difficult\nto handle imbalanced unlabeled datastream when only a limited budget of labels\ncan be queried for training. To solve this, previous OAL studies adopt either\nasymmetric losses or queries (an isolated asymmetric strategy) to tackle the\nimbalance, and use first-order methods to optimize the cost-sensitive measure.\nHowever, the isolated strategy limits their performance in class imbalance,\nwhile first-order methods restrict their optimization performance. In this\npaper, we propose a novel Online Adaptive Asymmetric Active learning algorithm,\nbased on a new asymmetric strategy (merging both asymmetric losses and queries\nstrategies), and second-order optimization. We theoretically analyze its\nmistake bound and cost-sensitive metric bounds. Moreover, to better balance\nperformance and efficiency, we enhance our algorithm via a sketching technique,\nwhich significantly accelerates the computational speed with quite slight\nperformance degradation. Promising results demonstrate the effectiveness and\nefficiency of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:36:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Yifan", ""], ["Zhao", "Peilin", ""], ["Niu", "Shuaicheng", ""], ["Wu", "Qingyao", ""], ["Cao", "Jiezhang", ""], ["Huang", "Junzhou", ""], ["Tan", "Mingkui", ""]]}, {"id": "1911.07508", "submitter": "Cl\\'ement Elvira", "authors": "Cl\\'ement Elvira and C\\'edric Herzet", "title": "Safe squeezing for antisparse coding", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2995192", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spreading the information over all coefficients of a representation is a\ndesirable property in many applications such as digital communication or\nmachine learning. This so-called antisparse representation can be obtained by\nsolving a convex program involving an $\\ell_\\infty$-norm penalty combined with\na quadratic discrepancy. In this paper, we propose a new methodology, dubbed\nsafe squeezing, to accelerate the computation of antisparse representation. We\ndescribe a test that allows to detect saturated entries in the solution of the\noptimization problem. The contribution of these entries is compacted into a\nsingle vector, thus operating a form of dimensionality reduction. We propose\ntwo algorithms to solve the resulting lower dimensional problem. Numerical\nexperiments show the effectiveness of the proposed method to detect the\nsaturated components of the solution and illustrates the induced computational\ngains in the resolution of the antisparse problem.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:46:20 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 17:35:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Elvira", "Cl\u00e9ment", ""], ["Herzet", "C\u00e9dric", ""]]}, {"id": "1911.07511", "submitter": "Florian Pfisterer", "authors": "Florian Pfisterer and Laura Beggel and Xudong Sun and Fabian Scheipl\n  and Bernd Bischl", "title": "Benchmarking time series classification -- Functional data vs machine\n  learning approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time series classification problems have drawn increasing attention in the\nmachine learning and statistical community. Closely related is the field of\nfunctional data analysis (FDA): it refers to the range of problems that deal\nwith the analysis of data that is continuously indexed over some domain. While\noften employing different methods, both fields strive to answer similar\nquestions, a common example being classification or regression problems with\nfunctional covariates. We study methods from functional data analysis, such as\nfunctional generalized additive models, as well as functionality to concatenate\n(functional-) feature extraction or basis representations with traditional\nmachine learning algorithms like support vector machines or classification\ntrees. In order to assess the methods and implementations, we run a benchmark\non a wide variety of representative (time series) data sets, with in-depth\nanalysis of empirical results, and strive to provide a reference ranking for\nwhich method(s) to use for non-expert practitioners. Additionally, we provide a\nsoftware framework in R for functional data analysis for supervised learning,\nincluding machine learning and more linear approaches from statistics. This\nallows convenient access, and in connection with the machine-learning toolbox\nmlr, those methods can now also be tuned and benchmarked.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:52:28 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 10:31:48 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Pfisterer", "Florian", ""], ["Beggel", "Laura", ""], ["Sun", "Xudong", ""], ["Scheipl", "Fabian", ""], ["Bischl", "Bernd", ""]]}, {"id": "1911.07532", "submitter": "Michael Poli", "authors": "Michael Poli, Stefano Massaroli, Junyoung Park, Atsushi Yamashita,\n  Hajime Asama, Jinkyoo Park", "title": "Graph Neural Ordinary Differential Equations", "comments": "Accepted [Spotlight] at the AAAI workshop DLGMA20. For the extended\n  version, see \"Continuous-Depth Neural Models for Dynamic Graph Prediction\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the framework of continuous--depth graph neural networks (GNNs).\nGraph neural ordinary differential equations (GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nvarious static and autoregressive GNN models. Results prove general\neffectiveness of GDEs: in static settings they offer computational advantages\nby incorporating numerical methods in their forward pass; in dynamic settings,\non the other hand, they are shown to improve performance by exploiting the\ngeometry of the underlying dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:46:15 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 06:18:16 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 05:40:32 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 07:40:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Park", "Junyoung", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1911.07537", "submitter": "Arsany Guirguis", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Arsany Guirguis", "title": "Fast Machine Learning with Byzantine Workers and Servers", "comments": "This paper has been merged with arXiv:1905.03853, which has been\n  accepted to appear in the ACM Symposium on Principles of Distributed\n  Computing (PODC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) solutions are nowadays distributed and are prone to\nvarious types of component failures, which can be encompassed in so-called\nByzantine behavior. This paper introduces LiuBei, a Byzantine-resilient ML\nalgorithm that does not trust any individual component in the network (neither\nworkers nor servers), nor does it induce additional communication rounds (on\naverage), compared to standard non-Byzantine resilient algorithms. LiuBei\nbuilds upon gradient aggregation rules (GARs) to tolerate a minority of\nByzantine workers. Besides, LiuBei replicates the parameter server on multiple\nmachines instead of trusting it. We introduce a novel filtering mechanism that\nenables workers to filter out replies from Byzantine server replicas without\nrequiring communication with all servers. Such a filtering mechanism is based\non network synchrony, Lipschitz continuity of the loss function, and the GAR\nused to aggregate workers' gradients. We also introduce a protocol,\nscatter/gather, to bound drifts between models on correct servers with a small\nnumber of communication messages. We theoretically prove that LiuBei achieves\nByzantine resilience to both servers and workers and guarantees convergence. We\nbuild LiuBei using TensorFlow, and we show that LiuBei tolerates Byzantine\nbehavior with an accuracy loss of around 5% and around 24% convergence overhead\ncompared to vanilla TensorFlow. We moreover show that the throughput gain of\nLiuBei compared to another state-of-the-art Byzantine-resilient ML algorithm\n(that assumes network asynchrony) is 70%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:57:50 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 17:30:12 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 10:23:05 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Guirguis", "Arsany", ""]]}, {"id": "1911.07572", "submitter": "Yang Guo", "authors": "Yang Guo, Zhengyuan Liu, Pavitra Krishnswamy, Savitha Ramasamy", "title": "Bayesian Recurrent Framework for Missing Data Imputation and Prediction\n  with Clinical Time Series", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world clinical time series data sets exhibit a high prevalence of\nmissing values. Hence, there is an increasing interest in missing data\nimputation. Traditional statistical approaches impose constraints on the\ndata-generating process and decouple imputation from prediction. Recent works\npropose recurrent neural network based approaches for missing data imputation\nand prediction with time series data. However, they generate deterministic\noutputs and neglect the inherent uncertainty. In this work, we introduce a\nunified Bayesian recurrent framework for simultaneous imputation and prediction\non time series data sets. We evaluate our approach on two real-world mortality\nprediction tasks using the MIMIC-III and PhysioNet benchmark datasets. We\ndemonstrate strong performance gains over state-of-the-art (SOTA) methods, and\nprovide strategies to use the resulting probability distributions to better\nassess reliability of the imputations and predictions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:05:49 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 08:17:24 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Guo", "Yang", ""], ["Liu", "Zhengyuan", ""], ["Krishnswamy", "Pavitra", ""], ["Ramasamy", "Savitha", ""]]}, {"id": "1911.07596", "submitter": "Anas Barakat", "authors": "Anas Barakat and Pascal Bianchi", "title": "Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for\n  Non Convex Optimization", "comments": "28 pages, 1 figure, published in ACML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although ADAM is a very popular algorithm for optimizing the weights of\nneural networks, it has been recently shown that it can diverge even in simple\nconvex optimization examples. Several variants of ADAM have been proposed to\ncircumvent this convergence issue. In this work, we study the ADAM algorithm\nfor smooth nonconvex optimization under a boundedness assumption on the\nadaptive learning rate. The bound on the adaptive step size depends on the\nLipschitz constant of the gradient of the objective function and provides safe\ntheoretical adaptive step sizes. Under this boundedness assumption, we show a\nnovel first order convergence rate result in both deterministic and stochastic\ncontexts. Furthermore, we establish convergence rates of the function value\nsequence using the Kurdyka-Lojasiewicz property.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:00:02 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 12:52:11 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Barakat", "Anas", ""], ["Bianchi", "Pascal", ""]]}, {"id": "1911.07625", "submitter": "Ahmed Ben Said", "authors": "Ahmed Ben Said and Abdelkarim Erradi", "title": "Deep-Gap: A deep learning framework for forecasting crowdsourcing\n  supply-demand gap based on imaging time series and residual learning", "comments": "Accepted at CloudCom 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile crowdsourcing has become easier thanks to the widespread of\nsmartphones capable of seamlessly collecting and pushing the desired data to\ncloud services. However, the success of mobile crowdsourcing relies on\nbalancing the supply and demand by first accurately forecasting spatially and\ntemporally the supply-demand gap, and then providing efficient incentives to\nencourage participant movements to maintain the desired balance. In this paper,\nwe propose Deep-Gap, a deep learning approach based on residual learning to\npredict the gap between mobile crowdsourced service supply and demand at a\ngiven time and space. The prediction can drive the incentive model to achieve a\ngeographically balanced service coverage in order to avoid the case where some\nareas are over-supplied while other areas are under-supplied. This allows\nanticipating the supply-demand gap and redirecting crowdsourced service\nproviders towards target areas. Deep-Gap relies on historical supply-demand\ntime series data as well as available external data such as weather conditions\nand day type (e.g., weekday, weekend, holiday). First, we roll and encode the\ntime series of supply-demand as images using the Gramian Angular Summation\nField (GASF), Gramian Angular Difference Field (GADF) and the Recurrence Plot\n(REC). These images are then used to train deep Convolutional Neural Networks\n(CNN) to extract the low and high-level features and forecast the crowdsourced\nservices gap. We conduct comprehensive comparative study by establishing two\nsupply-demand gap forecasting scenarios: with and without external data.\nCompared to state-of-art approaches, Deep-Gap achieves the lowest forecasting\nerrors in both scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:32:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Said", "Ahmed Ben", ""], ["Erradi", "Abdelkarim", ""]]}, {"id": "1911.07626", "submitter": "Tong Zhang", "authors": "Cong Fang and Yihong Gu and Weizhong Zhang and Tong Zhang", "title": "Convex Formulation of Overparameterized Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of over-parameterized neural networks has drawn significant\nattention in recentyears. It was shown that such systems behave like convex\nsystems under various restrictedsettings, such as for two-level neural\nnetworks, and when learning is only restricted locally inthe so-called neural\ntangent kernel space around specialized initializations. However, there areno\ntheoretical techniques that can analyze fully trained deep neural networks\nencountered inpractice. This paper solves this fundamental problem by\ninvestigating such overparameterizeddeep neural networks when fully trained. We\ngeneralize a new technique called neural feature repopulation, originally\nintroduced in (Fang et al., 2019a) for two-level neural networks, to analyze\ndeep neural networks. It is shown that under suitable representations,\noverparameterized deep neural networks are inherently convex, and when\noptimized, the system can learn effective features suitable for the underlying\nlearning task under mild conditions. This new analysis is consistent with\nempirical observations that deep neural networks are capable of learning\nefficient feature representations. Therefore, the highly unexpected result of\nthis paper can satisfactorily explain the practical success of deep neural\nnetworks. Empirical studies confirm that predictions of our theory are\nconsistent with results observed in practice.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:42:04 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fang", "Cong", ""], ["Gu", "Yihong", ""], ["Zhang", "Weizhong", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.07629", "submitter": "Atul Sahay", "authors": "Atul Sahay, Smita Gholkar, Kavi Arya", "title": "Selection-based Question Answering of an MOOC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  e-Yantra Robotics Competition (eYRC) is a unique Robotics Competition hosted\nby IIT Bombay that is actually an Embedded Systems and Robotics MOOC.\nRegistrations have been growing exponentially in each year from 4500 in 2012 to\nover 34000 in 2019. In this 5-month long competition students learn complex\nskills under severe time pressure and have access to a discussion forum to post\ndoubts about the learning material. Responding to questions in real-time is a\nchallenge for project staff. Here, we illustrate the advantage of Deep Learning\nfor real-time question answering in the eYRC discussion forum. We illustrate\nthe advantage of Transformer based contextual embedding mechanisms such as\nBidirectional Encoder Representation From Transformer (BERT) over word\nembedding mechanisms such as Word2Vec. We propose a weighted similarity metric\nas a measure of matching and find it more reliable than Content-Content or\nTitle-Title similarities alone. The automation of replying to questions has\nbrought the turn around response time(TART) down from a minimum of 21 mins to a\nminimum of 0.3 secs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:20:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sahay", "Atul", ""], ["Gholkar", "Smita", ""], ["Arya", "Kavi", ""]]}, {"id": "1911.07630", "submitter": "Sandeep Madireddy", "authors": "Peihong Jiang, Hieu Doan, Sandeep Madireddy, Rajeev Surendran Assary,\n  Prasanna Balaprakash", "title": "Value-Added Chemical Discovery Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-assisted synthesis planning aims to help chemists find better\nreaction pathways faster. Finding viable and short pathways from sugar\nmolecules to value-added chemicals can be modeled as a retrosynthesis planning\nproblem with a catalyst allowed. This is a crucial step in efficient biomass\nconversion. The traditional computational chemistry approach to identifying\npossible reaction pathways involves computing the reaction energies of hundreds\nof intermediates, which is a critical bottleneck in silico reaction discovery.\nDeep reinforcement learning has shown in other domains that a well-trained\nagent with little or no prior human knowledge can surpass human performance.\nWhile some effort has been made to adapt machine learning techniques to the\nretrosynthesis planning problem, value-added chemical discovery presents unique\nchallenges. Specifically, the reaction can occur in several different sites in\na molecule, a subtle case that has never been treated in previous works. With a\nmore versatile formulation of the problem as a Markov decision process, we\naddress the problem using deep reinforcement learning techniques and present\npromising preliminary results.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 07:36:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jiang", "Peihong", ""], ["Doan", "Hieu", ""], ["Madireddy", "Sandeep", ""], ["Assary", "Rajeev Surendran", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1911.07643", "submitter": "Miguel Suau", "authors": "Miguel Suau, Jinke He, Elena Congeduti, Rolf A.N. Starre, Aleksander\n  Czechowski, Frans A. Oliehoek", "title": "Influence-aware Memory Architectures for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its perceptual limitations, an agent may have too little information\nabout the state of the environment to act optimally. In such cases, it is\nimportant to keep track of the observation history to uncover hidden state.\nRecent deep reinforcement learning methods use recurrent neural networks (RNN)\nto memorize past observations. However, these models are expensive to train and\nhave convergence difficulties, especially when dealing with high dimensional\ninput spaces. In this paper, we propose influence-aware memory (IAM), a\ntheoretically inspired memory architecture that tries to alleviate the training\ndifficulties by restricting the input of the recurrent layers to those\nvariables that influence the hidden state information. Moreover, as opposed to\nstandard RNNs, in which every piece of information used for estimating Q values\nis inevitably fed back into the network for the next prediction, our model\nallows information to flow without being necessarily stored in the RNN's\ninternal memory. Results indicate that, by letting the recurrent layers focus\non a small fraction of the observation variables while processing the rest of\nthe information with a feedforward neural network, we can outperform standard\nrecurrent architectures both in training speed and policy performance. This\napproach also reduces runtime and obtains better scores than methods that stack\nmultiple observations to remove partial observability.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:54:25 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 20:50:00 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 09:00:18 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2021 18:26:14 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Suau", "Miguel", ""], ["He", "Jinke", ""], ["Congeduti", "Elena", ""], ["Starre", "Rolf A. N.", ""], ["Czechowski", "Aleksander", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "1911.07644", "submitter": "Yan Zhang", "authors": "Yan Zhang, Steve Farrell, Michael Crowley, Lee Makowski, Jack Deslippe", "title": "A Molecular-MNIST Dataset for Machine Learning Study on Diffraction\n  Imaging and Microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image dataset of 10 different size molecules, where each molecule has\n2,000 structural variants, is generated from the 2D cross-sectional projection\nof Molecular Dynamics trajectories. The purpose of this dataset is to provide a\nbenchmark dataset for the increasing need of machine learning, deep learning\nand image processing on the study of scattering, imaging and microscopy.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:48:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Yan", ""], ["Farrell", "Steve", ""], ["Crowley", "Michael", ""], ["Makowski", "Lee", ""], ["Deslippe", "Jack", ""]]}, {"id": "1911.07652", "submitter": "Linara Adilova", "authors": "Linara Adilova, Julia Rosenzweig, Michael Kamp", "title": "Information-Theoretic Perspective of Federated Learning", "comments": "5 pages, 8 figures Workshop on Information Theory and Machine\n  Learning, 33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to distributed machine learning is to train models on local\ndatasets and aggregate these models into a single, stronger model. A popular\ninstance of this form of parallelization is federated learning, where the nodes\nperiodically send their local models to a coordinator that aggregates them and\nredistributes the aggregation back to continue training with it. The most\nfrequently used form of aggregation is averaging the model parameters, e.g.,\nthe weights of a neural network. However, due to the non-convexity of the loss\nsurface of neural networks, averaging can lead to detrimental effects and it\nremains an open question under which conditions averaging is beneficial. In\nthis paper, we study this problem from the perspective of information theory:\nWe measure the mutual information between representation and inputs as well as\nrepresentation and labels in local models and compare it to the respective\ninformation contained in the representation of the averaged model. Our\nempirical results confirm previous observations about the practical usefulness\nof averaging for neural networks, even if local dataset distributions vary\nstrongly. Furthermore, we obtain more insights about the impact of the\naggregation frequency on the information flow and thus on the success of\ndistributed learning. These insights will be helpful both in improving the\ncurrent synchronization process and in further understanding the effects of\nmodel aggregation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 13:51:27 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Adilova", "Linara", ""], ["Rosenzweig", "Julia", ""], ["Kamp", "Michael", ""]]}, {"id": "1911.07654", "submitter": "Alena Harley", "authors": "Alena Harley", "title": "Deep Discriminative Fine-Tuning for Cancer Type Classification", "comments": "4 pages, 1 figure, ML4H NeurIPS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the primary site of origin for metastatic tumors is one of the\nopen problems in cancer care because the efficacy of treatment often depends on\nthe cancer tissue of origin. Classification methods that can leverage tumor\ngenomic data and predict the site of origin are therefore of great value.\nBecause tumor DNA point mutation data is very sparse, only limited accuracy\n(64.5% for 12 tumor classes) was previously demonstrated by methods that rely\non point mutations as features (1). Tumor classification accuracy can be\ngreatly improved (to over 90% for 33 classes) by relying on gene expression\ndata (2). However, this additional data is often not readily available in\nclinical setting, because point mutations are better profiled and targeted by\nclinical mutational profiling.\n  Here we sought to develop an accurate deep transfer learning and fine-tuning\nmethod for tumor sub-type classification, where predicted class is indicative\nof the primary site of origin. Our method significantly outperforms the\nstate-of-the-art for tumor classification using DNA point mutations, reducing\nthe error by more than 30% at the same time discriminating over many more\nclasses on The Cancer Genome Atlas (TCGA) dataset. Using our method, we achieve\nstate-of-the-art tumor type classification accuracy of 78.3% for 29 tumor\nclasses relying on DNA point mutations in the tumor only.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 07:30:17 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Harley", "Alena", ""]]}, {"id": "1911.07656", "submitter": "Xiangzhu Meng", "authors": "Xiangzhu Meng, Huibing Wang, Lin Feng", "title": "The Similarity-Consensus Regularized Multi-view Learning for Dimension\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decades, learning a low-dimensional space with discriminative\ninformation for dimension reduction (DR) has gained a surge of interest.\nHowever, it's not accessible for these DR methods to achieve satisfactory\nperformance when facing the features from multiple views. In multi-view\nlearning problems, one instance can be represented by multiple heterogeneous\nfeatures, which are highly related but sometimes look different from each\nother. In addition, correlations between features from multiple views always\nvary greatly, which challenges the capability of multi-view learning methods.\nConsequently, constructing a multi-view learning framework with generalization\nand scalability, which could take advantage of multi-view information as much\nas possible, is extremely necessary but challenging. To implement the above\ntarget, this paper proposes a novel multi-view learning framework based on\nsimilarity consensus, which makes full use of correlations among multi-view\nfeatures while considering the scalability and robustness of the framework. It\naims to straightforwardly extend those existing DR methods into multi-view\nlearning domain by preserving the similarity between different views to capture\nthe low-dimensional embedding. Two schemes based on pairwise-consensus and\ncentroid-consensus are separately proposed to force multiple views to learn\nfrom each other and then an iterative alternating strategy is developed to\nobtain the optimal solution. The proposed method is evaluated on 5 benchmark\ndatasets and comprehensive experiments show that our proposed multi-view\nframework can yield comparable and promising performance with previous\napproaches proposed in recent literatures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 02:41:46 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Meng", "Xiangzhu", ""], ["Wang", "Huibing", ""], ["Feng", "Lin", ""]]}, {"id": "1911.07662", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Variational mean-field theory for training restricted Boltzmann machines\n  with binary synapses", "comments": "9 pages, 2 figures, a mean-field framework proposed for unsupervised\n  learning in RBM with discrete synapses, which was previously out of reach", "journal-ref": "Phys. Rev. E 102, 030301 (2020)", "doi": "10.1103/PhysRevE.102.030301", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning requiring only raw data is not only a fundamental\nfunction of the cerebral cortex, but also a foundation for a next generation of\nartificial neural networks. However, a unified theoretical framework to treat\nsensory inputs, synapses and neural activity together is still lacking. The\ncomputational obstacle originates from the discrete nature of synapses, and\ncomplex interactions among these three essential elements of learning. Here, we\npropose a variational mean-field theory in which the distribution of synaptic\nweights is considered. The unsupervised learning can then be decomposed into\ntwo intertwined steps: a maximization step is carried out as a gradient ascent\nof the lower-bound on the data log-likelihood, in which the synaptic weight\ndistribution is determined by updating variational parameters, and an\nexpectation step is carried out as a message passing procedure on an equivalent\nor dual neural network whose parameter is specified by the variational\nparameters of the weight distribution. Therefore, our framework provides\ninsights on how data (or sensory inputs), synapses and neural activities\ninteract with each other to achieve the goal of extracting statistical\nregularities in sensory inputs. This variational framework is verified in\nrestricted Boltzmann machines with planted synaptic weights and\nhandwritten-digits learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 02:12:08 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 03:58:24 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1911.07675", "submitter": "Yilun Jin", "authors": "Yilun Jin, Guojie Song, Chuan Shi", "title": "GraLSP: Graph Neural Networks with Local Structural Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not until recently that graph neural networks (GNNs) are adopted to\nperform graph representation learning, among which, those based on the\naggregation of features within the neighborhood of a node achieved great\nsuccess. However, despite such achievements, GNNs illustrate defects in\nidentifying some common structural patterns which, unfortunately, play\nsignificant roles in various network phenomena. In this paper, we propose\nGraLSP, a GNN framework which explicitly incorporates local structural patterns\ninto the neighborhood aggregation through random anonymous walks. Specifically,\nwe capture local graph structures via random anonymous walks, powerful and\nflexible tools that represent structural patterns. The walks are then fed into\nthe feature aggregation, where we design various mechanisms to address the\nimpact of structural features, including adaptive receptive radius, attention\nand amplification. In addition, we design objectives that capture similarities\nbetween structures and are optimized jointly with node proximity objectives.\nWith the adequate leverage of structural patterns, our model is able to\noutperform competitive counterparts in various prediction tasks in multiple\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:53:41 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 08:57:46 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Jin", "Yilun", ""], ["Song", "Guojie", ""], ["Shi", "Chuan", ""]]}, {"id": "1911.07676", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Csaba Szepesvari and Gellert Weisz", "title": "Learning with Good Feature Representations in Bandits and in RL with a\n  Generative Model", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction by Du et al. (2019) implies that even if a learner is given\nlinear features in $\\mathbb R^d$ that approximate the rewards in a bandit with\na uniform error of $\\epsilon$, then searching for an action that is optimal up\nto $O(\\epsilon)$ requires examining essentially all actions. We use the\nKiefer-Wolfowitz theorem to prove a positive result that by checking only a few\nactions, a learner can always find an action that is suboptimal with an error\nof at most $O(\\epsilon \\sqrt{d})$. Thus, features are useful when the\napproximation error is small relative to the dimensionality of the features.\nThe idea is applied to stochastic bandits and reinforcement learning with a\ngenerative model where the learner has access to $d$-dimensional linear\nfeatures that approximate the action-value functions for all policies to an\naccuracy of $\\epsilon$. For linear bandits, we prove a bound on the regret of\norder $\\sqrt{dn \\log(k)} + \\epsilon n \\sqrt{d} \\log(n)$ with $k$ the number of\nactions and $n$ the horizon. For RL we show that approximate policy iteration\ncan learn a policy that is optimal up to an additive error of order $\\epsilon\n\\sqrt{d}/(1 - \\gamma)^2$ and using $d/(\\epsilon^2(1 - \\gamma)^4)$ samples from\na generative model. These bounds are independent of the finer details of the\nfeatures. We also investigate how the structure of the feature set impacts the\ntradeoff between sample complexity and estimation error.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:55:50 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:36:51 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""], ["Weisz", "Gellert", ""]]}, {"id": "1911.07679", "submitter": "Josie Williams", "authors": "Josie Williams and Narges Razavian", "title": "Towards Quantification of Bias in Machine Learning for Healthcare: A\n  Case Study of Renal Failure Prediction", "comments": "Accepted at Fairness in Machine Learning in Health workshop at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) models, trained on real-world datasets, become\ncommon practice, it is critical to measure and quantify their potential biases.\nIn this paper, we focus on renal failure and compare a commonly used\ntraditional risk score, Tangri, with a more powerful machine learning model,\nwhich has access to a larger variable set and trained on 1.6 million patients'\nEHR data. We will compare and discuss the generalization and applicability of\nthese two models, in an attempt to quantify biases of status quo clinical\npractice, compared to ML-driven models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:04:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Williams", "Josie", ""], ["Razavian", "Narges", ""]]}, {"id": "1911.07682", "submitter": "Zhaohui Che", "authors": "Zhaohui Che and Ali Borji and Guangtao Zhai and Suiyi Ling and Jing Li\n  and Patrick Le Callet", "title": "A New Ensemble Adversarial Attack Powered by Long-term Gradient Memories", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:05:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Che", "Zhaohui", ""], ["Borji", "Ali", ""], ["Zhai", "Guangtao", ""], ["Ling", "Suiyi", ""], ["Li", "Jing", ""], ["Callet", "Patrick Le", ""]]}, {"id": "1911.07693", "submitter": "Lu Bai", "authors": "Lu Bai, Yew-Soon Ong, Tiantian He, Abhishek Gupta", "title": "A Multi-Task Gradient Descent Method for Multi-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning studies the problem where an instance is associated with\na set of labels. By treating single-label learning problem as one task, the\nmulti-label learning problem can be casted as solving multiple related tasks\nsimultaneously. In this paper, we propose a novel Multi-task Gradient Descent\n(MGD) algorithm to solve a group of related tasks simultaneously. In the\nproposed algorithm, each task minimizes its individual cost function using\nreformative gradient descent, where the relations among the tasks are\nfacilitated through effectively transferring model parameter values across\nmultiple tasks. Theoretical analysis shows that the proposed algorithm is\nconvergent with a proper transfer mechanism. Compared with the existing\napproaches, MGD is easy to implement, has less requirement on the training\nmodel, can achieve seamless asymmetric transformation such that negative\ntransfer is mitigated, and can benefit from parallel computing when the number\nof tasks is large. The competitive experimental results on multi-label learning\ndatasets validate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:17:33 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:53:08 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bai", "Lu", ""], ["Ong", "Yew-Soon", ""], ["He", "Tiantian", ""], ["Gupta", "Abhishek", ""]]}, {"id": "1911.07702", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Maxim S. Kovalev, Ernest M. Kasimov", "title": "An explanation method for Siamese neural networks", "comments": "International Scientific Conference Telecommunications, Computing and\n  Control (TELECCON-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for explaining the Siamese neural network is proposed. It uses\nthe following main ideas. First, the explained feature vector is compared with\nthe prototype of the corresponding class computed at the embedding level (the\nSiamese neural network output). The important features at this level are\ndetermined as features which are close to the same features of the prototype.\nSecond, an autoencoder is trained in a special way in order to take into\naccount the embedding level of the Si-amese network, and its decoder part is\nused for reconstructing input data with the corresponding changes. Numerical\nexperiments with the well-known dataset MNIST illustrate the propose method.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:30:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Utkin", "Lev V.", ""], ["Kovalev", "Maxim S.", ""], ["Kasimov", "Ernest M.", ""]]}, {"id": "1911.07710", "submitter": "Zilong Zhao", "authors": "Zilong Zhao, Sophie Cerf, Bogdan Robu and Nicolas Marchand", "title": "Feedback Control for Online Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are commonly used for image\nclassification tasks, raising the challenge of their application on data flows.\nDuring their training, adaptation is often performed by tuning the learning\nrate. Usual learning rate strategies are time-based i.e. monotonously\ndecreasing. In this paper, we advocate switching to a performance-based\nadaptation, in order to improve the learning efficiency. We present E\n(Exponential)/PD (Proportional Derivative)-Control, a conditional learning rate\nstrategy that combines a feedback PD controller based on the CNN loss function,\nwith an exponential control signal to smartly boost the learning and adapt the\nPD parameters. Stability proof is provided as well as an experimental\nevaluation using two state of the art image datasets (CIFAR-10 and\nFashion-MNIST). Results show better performances than the related works (faster\nnetwork accuracy growth reaching higher levels) and robustness of the\nE/PD-Control regarding its parametrization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:40:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhao", "Zilong", ""], ["Cerf", "Sophie", ""], ["Robu", "Bogdan", ""], ["Marchand", "Nicolas", ""]]}, {"id": "1911.07716", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki and Michael B. Wakin", "title": "The Effectiveness of Variational Autoencoders for Active Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high cost of acquiring labels is one of the main challenges in deploying\nsupervised machine learning algorithms. Active learning is a promising approach\nto control the learning process and address the difficulties of data labeling\nby selecting labeled training examples from a large pool of unlabeled\ninstances. In this paper, we propose a new data-driven approach to active\nlearning by choosing a small set of labeled data points that are both\ninformative and representative. To this end, we present an efficient geometric\ntechnique to select a diverse core-set in a low-dimensional latent space\nobtained by training a Variational Autoencoder (VAE). Our experiments\ndemonstrate an improvement in accuracy over two related techniques and, more\nimportantly, signify the representation power of generative modeling for\ndeveloping new active learning methods in high-dimensional data settings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:42:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1911.07721", "submitter": "Yihe Lu", "authors": "Lu Yihe, Scott C. Lowe, Penelope A. Lewis, Mark C. W. van Rossum", "title": "Program synthesis performance constrained by non-linear spatial\n  relations in Synthetic Visual Reasoning Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable advances in automated visual recognition by machines, some\nvisual tasks remain challenging for machines. Fleuret et al. (2011) introduced\nthe Synthetic Visual Reasoning Test (SVRT) to highlight this point, which\nrequired classification of images consisting of randomly generated shapes based\non hidden abstract rules using only a few examples. Ellis et al. (2015)\ndemonstrated that a program synthesis approach could solve some of the SVRT\nproblems with unsupervised, few-shot learning, whereas they remained\nchallenging for several convolutional neural networks trained with thousands of\nexamples. Here we re-considered the human and machine experiments, because they\nfollowed different protocols and yielded different statistics. We thus proposed\na quantitative reintepretation of the data between the protocols, so that we\ncould make fair comparison between human and machine performance. We improved\nthe program synthesis classifier by correcting the image parsings, and compared\nthe results to the performance of other machine agents and human subjects. We\ngrouped the SVRT problems into different types by the two aspects of the core\ncharacteristics for classification: shape specification and location relation.\nWe found that the program synthesis classifier could not solve problems\ninvolving shape distances, because it relied on symbolic computation which\nscales poorly with input dimension and adding distances into such computation\nwould increase the dimension combinatorially with the number of shapes in an\nimage. Therefore, although the program synthesis classifier is capable of\nabstract reasoning, its performance is highly constrained by the accessible\ninformation in image parsings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:47:03 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 12:32:25 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Yihe", "Lu", ""], ["Lowe", "Scott C.", ""], ["Lewis", "Penelope A.", ""], ["van Rossum", "Mark C. W.", ""]]}, {"id": "1911.07722", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Nikolas Ioannou, Celestine Mendler-D\\\"unner, Thomas Parnell", "title": "SySCD: A System-Aware Parallel Coordinate Descent Algorithm", "comments": "accepted as a spotlight at NeurIPS 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel parallel stochastic coordinate descent (SCD)\nalgorithm with convergence guarantees that exhibits strong scalability. We\nstart by studying a state-of-the-art parallel implementation of SCD and\nidentify scalability as well as system-level performance bottlenecks of the\nrespective implementation. We then take a principled approach to develop a new\nSCD variant which is designed to avoid the identified system bottlenecks, such\nas limited scaling due to coherence traffic of model sharing across threads,\nand inefficient CPU cache accesses. Our proposed system-aware parallel\ncoordinate descent algorithm (SySCD) scales to many cores and across numa\nnodes, and offers a consistent bottom line speedup in training time of up to\nx12 compared to an optimized asynchronous parallel SCD algorithm and up to x42,\ncompared to state-of-the-art GLM solvers (scikit-learn, Vowpal Wabbit, and H2O)\non a range of datasets and multi-core CPU architectures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:47:30 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ioannou", "Nikolas", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""]]}, {"id": "1911.07729", "submitter": "Luc Frachon", "authors": "Luc Frachon, Wei Pang, George M. Coghill", "title": "ImmuNeCS: Neural Committee Search by an Artificial Immune System", "comments": "16 pages including references, 6 figures, 3 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current Neural Architecture Search techniques can suffer from a few\nshortcomings, including high computational cost, excessive bias from the search\nspace, conceptual complexity or uncertain empirical benefits over random\nsearch. In this paper, we present ImmuNeCS, an attempt at addressing these\nissues with a method that offers a simple, flexible, and efficient way of\nbuilding deep learning models automatically, and we demonstrate its\neffectiveness in the context of convolutional neural networks. Instead of\nsearching for the 1-best architecture for a given task, we focus on building a\npopulation of neural networks that are then ensembled into a neural network\ncommittee, an approach we dub 'Neural Committee Search'. To ensure sufficient\nperformance from the committee, our search algorithm is based on an artificial\nimmune system that balances individual performance with population diversity.\nThis allows us to stop the search when accuracy starts to plateau, and to\nbridge the performance gap through ensembling. In order to justify our method,\nwe first verify that the chosen search space exhibits the locality property. To\nfurther improve efficiency, we also combine partial evaluation, weight\ninheritance, and progressive search. First, experiments are run to verify the\nvalidity of these techniques. Then, preliminary experimental results on two\npopular computer vision benchmarks show that our method consistently\noutperforms random search and yields promising results within reasonable GPU\nbudgets. An additional experiment also shows that ImmuNeCS's solutions transfer\neffectively to a more difficult task, where they achieve results comparable to\na direct search on the new task. We believe these findings can open the way for\nnew, accessible alternatives to traditional NAS.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:00:28 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 15:39:03 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 11:06:38 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 20:23:51 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Frachon", "Luc", ""], ["Pang", "Wei", ""], ["Coghill", "George M.", ""]]}, {"id": "1911.07738", "submitter": "Steven Van Rossem", "authors": "Steven Van Rossem, Wouter Tavernier, Didier Colle, Mario Pickavet,\n  Piet Demeester", "title": "Profile-based Resource Allocation for Virtualized Network Functions", "comments": "accepted in IEEE TNSM journal", "journal-ref": "IEEE Transactions on Network and Service Management, 2019, Early\n  Access", "doi": "10.1109/TNSM.2019.2943779", "report-no": null, "categories": "cs.NI cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The virtualization of compute and network resources enables an unseen\nflexibility for deploying network services. A wide spectrum of emerging\ntechnologies allows an ever-growing range of orchestration possibilities in\ncloud-based environments. But in this context it remains challenging to rhyme\ndynamic cloud configurations with deterministic performance. The service\noperator must somehow map the performance specification in the Service Level\nAgreement (SLA) to an adequate resource allocation in the virtualized\ninfrastructure. We propose the use of a VNF profile to alleviate this process.\nThis is illustrated by profiling the performance of four example network\nfunctions (a virtual router, switch, firewall and cache server) under varying\nworkloads and resource configurations. We then compare several methods to\nderive a model from the profiled datasets. We select the most accurate method\nto further train a model which predicts the services' performance, in function\nof incoming workload and allocated resources. Our presented method can offer\nthe service operator a recommended resource allocation for the targeted\nservice, in function of the targeted performance and maximum workload specified\nin the SLA. This helps to deploy the softwarized service with an optimal amount\nof resources to meet the SLA requirements, thereby avoiding unnecessary scaling\nsteps.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:21:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Van Rossem", "Steven", ""], ["Tavernier", "Wouter", ""], ["Colle", "Didier", ""], ["Pickavet", "Mario", ""], ["Demeester", "Piet", ""]]}, {"id": "1911.07749", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "On the computation of counterfactual explanations -- A survey", "comments": "In progress. arXiv admin note: text overlap with arXiv:1908.00735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing use of machine learning in practice it becomes more and\nmore important to be able to explain the prediction and behavior of machine\nlearning models. An instance of explanations are counterfactual explanations\nwhich provide an intuitive and useful explanations of machine learning models.\nIn this survey we review model-specific methods for efficiently computing\ncounterfactual explanations of many different machine learning models and\npropose methods for models that have not been considered in literature so far.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:14:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.07790", "submitter": "Masahiro Nomura", "authors": "Masahiro Nomura, Kenshi Abe", "title": "A Simple Heuristic for Bayesian Optimization with A Low Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of black-box optimization is to optimize an objective function within\nthe constraints of a given evaluation budget. In this problem, it is generally\nassumed that the computational cost for evaluating a point is large; thus, it\nis important to search efficiently with as low budget as possible. Bayesian\noptimization is an efficient method for black-box optimization and provides\nexploration-exploitation trade-off by constructing a surrogate model that\nconsiders uncertainty of the objective function. However, because Bayesian\noptimization should construct the surrogate model for the entire search space,\nit does not exhibit good performance when points are not sampled sufficiently.\nIn this study, we develop a heuristic method refining the search space for\nBayesian optimization when the available evaluation budget is low. The proposed\nmethod refines a promising region by dividing the original region so that\nBayesian optimization can be executed with the promising region as the initial\nsearch space. We confirm that Bayesian optimization with the proposed method\noutperforms Bayesian optimization alone and shows equal or better performance\nto two search-space division algorithms through experiments on the benchmark\nfunctions and the hyperparameter optimization of machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 17:43:59 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 05:36:30 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 15:42:01 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nomura", "Masahiro", ""], ["Abe", "Kenshi", ""]]}, {"id": "1911.07805", "submitter": "Shokooh Taghian", "authors": "Shokooh Taghian, Mohammad H. Nadimi-Shahraki", "title": "Binary Sine Cosine Algorithms for Feature Selection from Medical Data", "comments": null, "journal-ref": null, "doi": "10.5121/acij.2019.10501", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-constructed classification model highly depends on input feature\nsubsets from a dataset, which may contain redundant, irrelevant, or noisy\nfeatures. This challenge can be worse while dealing with medical datasets. The\nmain aim of feature selection as a pre-processing task is to eliminate these\nfeatures and select the most effective ones. In the literature, metaheuristic\nalgorithms show a successful performance to find optimal feature subsets. In\nthis paper, two binary metaheuristic algorithms named S-shaped binary Sine\nCosine Algorithm (SBSCA) and V-shaped binary Sine Cosine Algorithm (VBSCA) are\nproposed for feature selection from the medical data. In these algorithms, the\nsearch space remains continuous, while a binary position vector is generated by\ntwo transfer functions S-shaped and V-shaped for each solution. The proposed\nalgorithms are compared with four latest binary optimization algorithms over\nfive medical datasets from the UCI repository. The experimental results confirm\nthat using both bSCA variants enhance the accuracy of classification on these\nmedical datasets compared to four other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 12:57:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Taghian", "Shokooh", ""], ["Nadimi-Shahraki", "Mohammad H.", ""]]}, {"id": "1911.07819", "submitter": "Ioana Baldini", "authors": "Shivashankar Subramanian, Ioana Baldini, Sushma Ravichandran, Dmitriy\n  A. Katz-Rogozhnikov, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Kush\n  R. Varshney, Annmarie Wang, Pradeep Mangalath, Laura B. Kleiman", "title": "Drug Repurposing for Cancer: An NLP Approach to Identify Low-Cost\n  Therapies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 200 generic drugs approved by the U.S. Food and Drug Administration\nfor non-cancer indications have shown promise for treating cancer. Due to their\nlong history of safe patient use, low cost, and widespread availability,\nrepurposing of generic drugs represents a major opportunity to rapidly improve\noutcomes for cancer patients and reduce healthcare costs worldwide. Evidence on\nthe efficacy of non-cancer generic drugs being tested for cancer exists in\nscientific publications, but trying to manually identify and extract such\nevidence is intractable. In this paper, we introduce a system to automate this\nevidence extraction from PubMed abstracts. Our primary contribution is to\ndefine the natural language processing pipeline required to obtain such\nevidence, comprising the following modules: querying, filtering, cancer type\nentity extraction, therapeutic association classification, and study type\nclassification. Using the subject matter expertise on our team, we create our\nown datasets for these specialized domain-specific tasks. We obtain promising\nperformance in each of the modules by utilizing modern language modeling\ntechniques and plan to treat them as baseline approaches for future improvement\nof individual components.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:32:25 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:22:39 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Baldini", "Ioana", ""], ["Ravichandran", "Sushma", ""], ["Katz-Rogozhnikov", "Dmitriy A.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Sattigeri", "Prasanna", ""], ["Varshney", "Kush R.", ""], ["Wang", "Annmarie", ""], ["Mangalath", "Pradeep", ""], ["Kleiman", "Laura B.", ""]]}, {"id": "1911.07820", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Coordinate-wise Armijo's condition", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $z=(x,y)$ be coordinates for the product space $\\mathbb{R}^{m_1}\\times\n\\mathbb{R}^{m_2}$. Let $f:\\mathbb{R}^{m_1}\\times \\mathbb{R}^{m_2}\\rightarrow\n\\mathbb{R}$ be a $C^1$ function, and $\\nabla f=(\\partial _xf,\\partial _yf)$ its\ngradient. Fix $0<\\alpha <1$. For a point $(x,y) \\in \\mathbb{R}^{m_1}\\times\n\\mathbb{R}^{m_2}$, a number $\\delta >0$ satisfies Armijo's condition at $(x,y)$\nif the following inequality holds: \\begin{eqnarray*} f(x-\\delta \\partial\n_xf,y-\\delta \\partial _yf)-f(x,y)\\leq -\\alpha \\delta (||\\partial\n_xf||^2+||\\partial _yf||^2). \\end{eqnarray*}\n  When $f(x,y)=f_1(x)+f_2(y)$ is a coordinate-wise sum map, we propose the\nfollowing {\\bf coordinate-wise} Armijo's condition. Fix again $0<\\alpha <1$. A\npair of positive numbers $\\delta _1,\\delta _2>0$ satisfies the coordinate-wise\nvariant of Armijo's condition at $(x,y)$ if the following inequality holds:\n\\begin{eqnarray*} [f_1(x-\\delta _1\\nabla f_1(x))+f_2(y-\\delta _2\\nabla\nf_2(y))]-[f_1(x)+f_2(y)]\\leq -\\alpha (\\delta _1||\\nabla f_1(x)||^2+\\delta\n_2||\\nabla f_2(y)||^2). \\end{eqnarray*}\n  We then extend results in our recent previous results, on Backtracking\nGradient Descent and some variants, to this setting. We show by an example the\nadvantage of using coordinate-wise Armijo's condition over the usual Armijo's\ncondition.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:35:46 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "1911.07831", "submitter": "Mehmet A. S\\\"uzen PhD", "authors": "Mehmet S\\\"uzen, J.J. Cerd\\`a, Cornelius Weber", "title": "Periodic Spectral Ergodicity: A Complexity Measure for Deep Neural\n  Networks and Neural Architecture Search", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Establishing associations between the structure and the generalisation\nability of deep neural networks (DNNs) is a challenging task in modern machine\nlearning. Producing solutions to this challenge will bring progress both in the\ntheoretical understanding of DNNs and in building new architectures\nefficiently. In this work, we address this challenge by developing a new\ncomplexity measure based on the concept of {Periodic Spectral Ergodicity} (PSE)\noriginating from quantum statistical mechanics. Based on this measure a\ntechnique is devised to quantify the complexity of deep neural networks from\nthe learned weights and traversing the network connectivity in a sequential\nmanner, hence the term cascading PSE (cPSE), as an empirical complexity\nmeasure. This measure will capture both topological and internal neural\nprocessing complexity simultaneously. Because of this cascading approach, i.e.,\na symmetric divergence of PSE on the consecutive layers, it is possible to use\nthis measure for Neural Architecture Search (NAS). We demonstrate the\nusefulness of this measure in practice on two sets of vision models, ResNet and\nVGG, and sketch the computation of cPSE for more complex network structures.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 03:10:27 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 16:57:02 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 03:39:35 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 03:32:07 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["S\u00fczen", "Mehmet", ""], ["Cerd\u00e0", "J. J.", ""], ["Weber", "Cornelius", ""]]}, {"id": "1911.07844", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Clinton Fookes, Simon Denman, Sridha Sridharan", "title": "Exploiting Human Social Cognition for the Detection of Fake and\n  Fraudulent Faces via Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computer vision have brought us to the point where we have the\nability to synthesise realistic fake content. Such approaches are seen as a\nsource of disinformation and mistrust, and pose serious concerns to governments\naround the world. Convolutional Neural Networks (CNNs) demonstrate encouraging\nresults when detecting fake images that arise from the specific type of\nmanipulation they are trained on. However, this success has not transitioned to\nunseen manipulation types, resulting in a significant gap in the\nline-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,\nwhich is able to successfully detect faked faces by utilising knowledge stored\nin neural memories as well as visual cues to reason about the perceived face\nand anticipate its future semantic embeddings. This renders a generalisable\nface tampering detection framework. Experimental results demonstrate the\nproposed approach achieves superior performance for fake and fraudulent face\ndetection compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 23:20:23 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Fernando", "Tharindu", ""], ["Fookes", "Clinton", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""]]}, {"id": "1911.07845", "submitter": "Yun-Hao Cao", "authors": "Yun-Hao Cao and Jianxin Wu and Hanchen Wang and Joan Lasenby", "title": "Neural Random Subspace", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random subspace method, known as the pillar of random forests, is good at\nmaking precise and robust predictions. However, there is not a straightforward\nway yet to combine it with deep learning. In this paper, we therefore propose\nNeural Random Subspace (NRS), a novel deep learning based random subspace\nmethod. In contrast to previous forest methods, NRS enjoys the benefits of\nend-to-end, data-driven representation learning, as well as pervasive support\nfrom deep learning software and hardware platforms, hence achieving faster\ninference speed and higher accuracy. Furthermore, as a non-linear component to\nbe encoded into Convolutional Neural Networks (CNNs), NRS learns non-linear\nfeature representations in CNNs more efficiently than previous higher-order\npooling methods, producing good results with negligible increase in parameters,\nfloating point operations (FLOPs) and real running time. Compared with random\nsubspaces, random forests and gradient boosting decision trees (GBDTs), NRS\nachieves superior performance on 35 machine learning datasets. Moreover, on\nboth 2D image and 3D point cloud recognition tasks, integration of NRS with CNN\narchitectures achieves consistent improvements with minor extra cost. Code is\navailable at https://github.com/CupidJay/NRS_pytorch.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 02:28:04 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 01:03:43 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 01:07:47 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Cao", "Yun-Hao", ""], ["Wu", "Jianxin", ""], ["Wang", "Hanchen", ""], ["Lasenby", "Joan", ""]]}, {"id": "1911.07849", "submitter": "David W. Romero", "authors": "David W. Romero, Mark Hoogendoorn", "title": "Co-Attentive Equivariant Neural Networks: Focusing Equivariance On\n  Transformations Co-Occurring In Data", "comments": "Proceedings of the 8th International Conference on Learning\n  Representations (ICLR), 2020", "journal-ref": "Proceedings of the International Conference on Learning\n  Representations, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivariance is a nice property to have as it produces much more parameter\nefficient neural architectures and preserves the structure of the input through\nthe feature mapping. Even though some combinations of transformations might\nnever appear (e.g. an upright face with a horizontal nose), current equivariant\narchitectures consider the set of all possible transformations in a\ntransformation group when learning feature representations. Contrarily, the\nhuman visual system is able to attend to the set of relevant transformations\noccurring in the environment and utilizes this information to assist and\nimprove object recognition. Based on this observation, we modify conventional\nequivariant feature mappings such that they are able to attend to the set of\nco-occurring transformations in data and generalize this notion to act on\ngroups consisting of multiple symmetries. We show that our proposed\nco-attentive equivariant neural networks consistently outperform conventional\nrotation equivariant and rotation & reflection equivariant neural networks on\nrotated MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:41:12 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 13:56:10 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Romero", "David W.", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "1911.07874", "submitter": "Cheng Ji", "authors": "Jianxin Li, Cheng Ji, Hao Peng, Yu He, Yangqiu Song, Xinmiao Zhang,\n  Fanzhang Peng", "title": "RWNE: A Scalable Random-Walk-Based Network Embedding Framework with\n  Personalized Higher-Order Proximity Preserved", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Higher-order proximity preserved network embedding has attracted increasing\nattention. In particular, due to the superior scalability, random-walk-based\nnetwork embedding has also been well developed, which could efficiently explore\nhigher-order neighborhoods via multi-hop random walks. However, despite the\nsuccess of current random-walk-based methods, most of them are usually not\nexpressive enough to preserve the personalized higher-order proximity and lack\na straightforward objective to theoretically articulate what and how network\nproximity is preserved. In this paper, to address the above issues, we present\na general scalable random-walk-based network embedding framework, in which\nrandom walk is explicitly incorporated into a sound objective designed\ntheoretically to preserve arbitrary higher-order proximity. Further, we\nintroduce the random walk with restart process into the framework to naturally\nand effectively achieve personalized-weighted preservation of proximities of\ndifferent orders. We conduct extensive experiments on several real-world\nnetworks and demonstrate that our proposed method consistently and\nsubstantially outperforms the state-of-the-art network embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:02:21 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 11:57:24 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Li", "Jianxin", ""], ["Ji", "Cheng", ""], ["Peng", "Hao", ""], ["He", "Yu", ""], ["Song", "Yangqiu", ""], ["Zhang", "Xinmiao", ""], ["Peng", "Fanzhang", ""]]}, {"id": "1911.07875", "submitter": "Sandhya Tripathi", "authors": "Aditya Petety, Sandhya Tripathi, N Hemachandra", "title": "Attribute noise robust binary classification", "comments": "Accepted for Student Abstract presentation at AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of learning linear classifiers when both features and\nlabels are binary. In addition, the features are noisy, i.e., they could be\nflipped with an unknown probability. In Sy-De attribute noise model, where all\nfeatures could be noisy together with same probability, we show that $0$-$1$\nloss ($l_{0-1}$) need not be robust but a popular surrogate, squared loss\n($l_{sq}$) is. In Asy-In attribute noise model, we prove that $l_{0-1}$ is\nrobust for any distribution over 2 dimensional feature space. However, due to\ncomputational intractability of $l_{0-1}$, we resort to $l_{sq}$ and observe\nthat it need not be Asy-In noise robust. Our empirical results support Sy-De\nrobustness of squared loss for low to moderate noise rates.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:03:02 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Petety", "Aditya", ""], ["Tripathi", "Sandhya", ""], ["Hemachandra", "N", ""]]}, {"id": "1911.07891", "submitter": "Alexander Jung", "authors": "Alexander Jung and Ivan Baranov", "title": "Basic Principles of Clustering Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering methods group a set of data points into a few coherent groups or\nclusters of similar data points. As an example, consider clustering pixels in\nan image (or video) if they belong to the same object. Different clustering\nmethods are obtained by using different notions of similarity and different\nrepresentations of data points.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:32:04 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:28:58 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Jung", "Alexander", ""], ["Baranov", "Ivan", ""]]}, {"id": "1911.07893", "submitter": "Chengjin Xu", "authors": "Chengjin Xu and Mojtaba Nayyeri and Fouad Alkhoury and Hamed Shariat\n  Yazdi and Jens Lehmann", "title": "Temporal Knowledge Graph Embedding Model based on Additive Time Series\n  Decomposition", "comments": "This paper has been accepted by ISWC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph (KG) embedding has attracted more attention in recent years.\nMost KG embedding models learn from time-unaware triples. However, the\ninclusion of temporal information beside triples would further improve the\nperformance of a KGE model. In this regard, we propose ATiSE, a temporal KG\nembedding model which incorporates time information into entity/relation\nrepresentations by using Additive Time Series decomposition. Moreover,\nconsidering the temporal uncertainty during the evolution of entity/relation\nrepresentations over time, we map the representations of temporal KGs into the\nspace of multi-dimensional Gaussian distributions. The mean of each\nentity/relation embedding at a time step shows the current expected position,\nwhereas its covariance (which is temporally stationary) represents its temporal\nuncertainty. Experimental results show that ATiSE chieves the state-of-the-art\non link prediction over four temporal KGs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:36:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 07:23:58 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 08:03:43 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 20:07:17 GMT"}, {"version": "v5", "created": "Sat, 24 Oct 2020 14:14:20 GMT"}, {"version": "v6", "created": "Wed, 28 Oct 2020 12:28:46 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Xu", "Chengjin", ""], ["Nayyeri", "Mojtaba", ""], ["Alkhoury", "Fouad", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1911.07910", "submitter": "Shi Dong", "authors": "Benjamin Van Roy, Shi Dong", "title": "Comments on the Du-Kakade-Wang-Yang Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Du, Kakade, Wang, and Yang recently established intriguing lower bounds on\nsample complexity, which suggest that reinforcement learning with a\nmisspecified representation is intractable. Another line of work, which centers\naround a statistic called the eluder dimension, establishes tractability of\nproblems similar to those considered in the Du-Kakade-Wang-Yang paper. We\ncompare these results and reconcile interpretations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:15:15 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Van Roy", "Benjamin", ""], ["Dong", "Shi", ""]]}, {"id": "1911.07916", "submitter": "Adonis Emmanuel Tio", "authors": "Adonis Emmanuel Tio", "title": "Face shape classification using Inception v3", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present experimental results obtained from retraining the\nlast layer of the Inception v3 model in classifying images of human faces into\none of five basic face shapes. The accuracy of the retrained Inception v3 model\nwas compared with that of the following classification methods that uses facial\nlandmark distance ratios and angles as features: linear discriminant analysis\n(LDA), support vector machines with linear kernel (SVM-LIN), support vector\nmachines with radial basis function kernel (SVM-RBF), artificial neural\nnetworks or multilayer perceptron (MLP), and k-nearest neighbors (KNN). All\nclassifiers were trained and tested using a total of 500 images of female\ncelebrities with known face shapes collected from the Internet. Results show\nthat training accuracy and overall accuracy ranges from 98.0% to 100% and from\n84.4% to 84.8% for Inception v3 and from 50.6% to 73.0% and from 36.4% to 64.6%\nfor the other classifiers depending on the training set size used. This result\nshows that the retrained Inception v3 model was able to fit the training data\nwell and outperform the other classifiers without the need to handpick specific\nfeatures to include in model training. Future work should consider expanding\nthe labeled dataset, preferably one that can also be freely distributed to the\nresearch community, so that proper model cross-validation can be performed. As\nfar as we know, this is the first in the literature to use convolutional neural\nnetworks in face-shape classification. The scripts are available at\nhttps://github.com/adonistio/inception-face-shape-classifier.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 02:29:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Tio", "Adonis Emmanuel", ""]]}, {"id": "1911.07921", "submitter": "Chris Mesterharm", "authors": "Rauf Izmailov and Peter Lin and Chris Mesterharm and Samyadeep Basu", "title": "Privacy Leakage Avoidance with Switching Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider membership inference attacks, one of the main privacy issues in\nmachine learning. These recently developed attacks have been proven successful\nin determining, with confidence better than a random guess, whether a given\nsample belongs to the dataset on which the attacked machine learning model was\ntrained. Several approaches have been developed to mitigate this privacy\nleakage but the tradeoff performance implications of these defensive mechanisms\n(i.e., accuracy and utility of the defended machine learning model) are not\nwell studied yet. We propose a novel approach of privacy leakage avoidance with\nswitching ensembles (PASE), which both protects against current membership\ninference attacks and does that with very small accuracy penalty, while\nrequiring acceptable increase in training and inference time. We test our PASE\nmethod, along with the the current state-of-the-art PATE approach, on three\ncalibration image datasets and analyze their tradeoffs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:33:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Izmailov", "Rauf", ""], ["Lin", "Peter", ""], ["Mesterharm", "Chris", ""], ["Basu", "Samyadeep", ""]]}, {"id": "1911.07922", "submitter": "Marcus Bloice", "authors": "Marcus D. Bloice, Peter M. Roth, Andreas Holzinger", "title": "Patch augmentation: Towards efficient decision boundaries for neural\n  networks", "comments": "Version 2: updated author list, reduced abstract length, plots\n  consolidated as sub-plots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new augmentation technique, called patch\naugmentation, that, in our experiments, improves model accuracy and makes\nnetworks more robust to adversarial attacks. In brief, this data-independent\napproach creates new image data based on image/label pairs, where a patch from\none of the two images in the pair is superimposed on to the other image,\ncreating a new augmented sample. The new image's label is a linear combination\nof the image pair's corresponding labels. Initial experiments show a several\npercentage point increase in accuracy on CIFAR-10, from a baseline of\napproximately 81% to 89%. CIFAR-100 sees larger improvements still, from a\nbaseline of 52% to 68% accuracy. Networks trained using patch augmentation are\nalso more robust to adversarial attacks, which we demonstrate using the Fast\nGradient Sign Method.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:11:31 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 14:05:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bloice", "Marcus D.", ""], ["Roth", "Peter M.", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1911.07929", "submitter": "Jessica Velasco", "authors": "Jessica Velasco, Cherry Pascion, Jean Wilmar Alberio, Jonathan Apuang,\n  John Stephen Cruz, Mark Angelo Gomez, Benjamin Jr. Molina, Lyndon Tuala,\n  August Thio-ac and Romeo Jr. Jorda", "title": "A Smartphone-Based Skin Disease Classification Using MobileNet CNN", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2632-2637", "doi": "10.30534/ijatcse/2019/116852019", "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The MobileNet model was used by applying transfer learning on the 7 skin\ndiseases to create a skin disease classification system on Android application.\nThe proponents gathered a total of 3,406 images and it is considered as\nimbalanced dataset because of the unequal number of images on its classes.\nUsing different sampling method and preprocessing of input data was explored to\nfurther improved the accuracy of the MobileNet. Using under-sampling method and\nthe default preprocessing of input data achieved an 84.28% accuracy. While,\nusing imbalanced dataset and default preprocessing of input data achieved a\n93.6% accuracy. Then, researchers explored oversampling the dataset and the\nmodel attained a 91.8% accuracy. Lastly, by using oversampling technique and\ndata augmentation on preprocessing the input data provide a 94.4% accuracy and\nthis model was deployed on the developed Android application.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:04:05 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Velasco", "Jessica", ""], ["Pascion", "Cherry", ""], ["Alberio", "Jean Wilmar", ""], ["Apuang", "Jonathan", ""], ["Cruz", "John Stephen", ""], ["Gomez", "Mark Angelo", ""], ["Molina", "Benjamin Jr.", ""], ["Tuala", "Lyndon", ""], ["Thio-ac", "August", ""], ["Jorda", "Romeo Jr.", ""]]}, {"id": "1911.07936", "submitter": "Efe Bozkir", "authors": "Efe Bozkir, Ali Burak \\\"Unal, Mete Akg\\\"un, Enkelejda Kasneci, Nico\n  Pfeifer", "title": "Privacy Preserving Gaze Estimation using Synthetic Images via a\n  Randomized Encoding Based Framework", "comments": "In Symposium on Eye Tracking Research and Applications (ETRA '20).\n  Authors' copy of the published paper, refer to the doi for the definitive\n  version", "journal-ref": null, "doi": "10.1145/3379156.3391364", "report-no": null, "categories": "cs.CV cs.CR cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye tracking is handled as one of the key technologies for applications that\nassess and evaluate human attention, behavior, and biometrics, especially using\ngaze, pupillary, and blink behaviors. One of the challenges with regard to the\nsocial acceptance of eye tracking technology is however the preserving of\nsensitive and personal information. To tackle this challenge, we employ a\nprivacy-preserving framework based on randomized encoding to train a Support\nVector Regression model using synthetic eye images privately to estimate the\nhuman gaze. During the computation, none of the parties learn about the data or\nthe result that any other party has. Furthermore, the party that trains the\nmodel cannot reconstruct pupil, blinks or visual scanpath. The experimental\nresults show that our privacy-preserving framework is capable of working in\nreal-time, with the same accuracy as compared to non-private version and could\nbe extended to other eye tracking related problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:52:09 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:57:04 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 21:09:16 GMT"}, {"version": "v4", "created": "Tue, 13 Jul 2021 13:04:07 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bozkir", "Efe", ""], ["\u00dcnal", "Ali Burak", ""], ["Akg\u00fcn", "Mete", ""], ["Kasneci", "Enkelejda", ""], ["Pfeifer", "Nico", ""]]}, {"id": "1911.07937", "submitter": "Talip Ucar", "authors": "Talip Ucar", "title": "Inverse Graphics: Unsupervised Learning of 3D Shapes from Single Images", "comments": "10 pages, 15 figures. In the second version of the paper, a link to a\n  demo site is added under Figure-12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using generative models for Inverse Graphics is an active area of research.\nHowever, most works focus on developing models for supervised and\nsemi-supervised methods. In this paper, we study the problem of unsupervised\nlearning of 3D geometry from single images. Our approach is to use a generative\nmodel that produces 2-D images as projections of a latent 3D voxel grid, which\nwe train either as a variational auto-encoder or using adversarial methods. Our\ncontributions are as follows: First, we show how to recover 3D shape and pose\nfrom general datasets such as MNIST, and MNIST Fashion in good quality. Second,\nwe compare the shapes learned using adversarial and variational methods.\nAdversarial approach gives denser 3D shapes. Third, we explore the idea of\nmodelling the pose of an object as uniform distribution to recover 3D shape\nfrom a single image. Our experiment with the CelebA dataset\n\\cite{liu2015faceattributes} proves that we can recover complete 3D shape from\na single image when the object is symmetric along one, or more axis whilst\nresults obtained using ModelNet40 \\cite{wu20153d} show the potential\nside-effects, in which the model learns 3D shapes such that it can render the\nsame image from any viewpoint. Forth, we present a general end-to-end approach\nto learning 3D shapes from single images in a completely unsupervised fashion\nby modelling the factors of variation such as azimuth as independent latent\nvariables. Our method makes no assumptions about the dataset, and can work with\nsynthetic as well as real images (i.e. unsupervised in true sense). We present\nour results, by training the model using the $\\mu$-VAE objective\n\\cite{ucar2019bridging} and a dataset combining all images from MNIST, MNIST\nFashion, CelebA and six categories of ModelNet40. The model is able to learn 3D\nshapes and the pose in qood quality and leverages information learned across\nall datasets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 09:14:28 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:19:18 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ucar", "Talip", ""]]}, {"id": "1911.07951", "submitter": "Scott Wisdom", "authors": "Efthymios Tzinis, Scott Wisdom, John R. Hershey, Aren Jansen, Daniel\n  P. W. Ellis", "title": "Improving Universal Sound Separation Using Sound Classification", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9053921", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches have recently achieved impressive performance on\nboth audio source separation and sound classification. Most audio source\nseparation approaches focus only on separating sources belonging to a\nrestricted domain of source classes, such as speech and music. However, recent\nwork has demonstrated the possibility of \"universal sound separation\", which\naims to separate acoustic sources from an open domain, regardless of their\nclass. In this paper, we utilize the semantic information learned by sound\nclassifier networks trained on a vast amount of diverse sounds to improve\nuniversal sound separation. In particular, we show that semantic embeddings\nextracted from a sound classifier can be used to condition a separation\nnetwork, providing it with useful additional information. This approach is\nespecially useful in an iterative setup, where source estimates from an initial\nseparation stage and their corresponding classifier-derived embeddings are fed\nto a second separation network. By performing a thorough hyperparameter search\nconsisting of over a thousand experiments, we find that classifier embeddings\nfrom clean sources provide nearly one dB of SNR gain, and our best iterative\nmodels achieve a significant fraction of this oracle performance, establishing\na new state-of-the-art for universal sound separation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:56:26 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Wisdom", "Scott", ""], ["Hershey", "John R.", ""], ["Jansen", "Aren", ""], ["Ellis", "Daniel P. W.", ""]]}, {"id": "1911.07953", "submitter": "Hakan Erdogan", "authors": "Zhong-Qiu Wang, Hakan Erdogan, Scott Wisdom, Kevin Wilson, Desh Raj,\n  Shinji Watanabe, Zhuo Chen, John R. Hershey", "title": "Sequential Multi-Frame Neural Beamforming for Speech Separation and\n  Enhancement", "comments": "7 pages, 7 figures, IEEE SLT 2021 (slt2020.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces sequential neural beamforming, which alternates between\nneural network based spectral separation and beamforming based spatial\nseparation. Our neural networks for separation use an advanced convolutional\narchitecture trained with a novel stabilized signal-to-noise ratio loss\nfunction. For beamforming, we explore multiple ways of computing time-varying\ncovariance matrices, including factorizing the spatial covariance into a\ntime-varying amplitude component and a time-invariant spatial component, as\nwell as using block-based techniques. In addition, we introduce a multi-frame\nbeamforming method which improves the results significantly by adding\ncontextual frames to the beamforming formulations. We extensively evaluate and\nanalyze the effects of window size, block size, and multi-frame context size\nfor these methods. Our best method utilizes a sequence of three neural\nseparation and multi-frame time-invariant spatial beamforming stages, and\ndemonstrates an average improvement of 2.75 dB in scale-invariant\nsignal-to-noise ratio and 14.2% absolute reduction in a comparative speech\nrecognition metric across four challenging reverberant speech enhancement and\nseparation tasks. We also use our three-speaker separation model to separate\nreal recordings in the LibriCSS evaluation set into non-overlapping tracks, and\nachieve a better word error rate as compared to a baseline mask based\nbeamformer.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:59:03 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:01:56 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 19:35:49 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Wang", "Zhong-Qiu", ""], ["Erdogan", "Hakan", ""], ["Wisdom", "Scott", ""], ["Wilson", "Kevin", ""], ["Raj", "Desh", ""], ["Watanabe", "Shinji", ""], ["Chen", "Zhuo", ""], ["Hershey", "John R.", ""]]}, {"id": "1911.07956", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu and Edgar Dobriban and Tongzheng Ren and Shanshan Wu and\n  Zhiyuan Li and Suriya Gunasekar and Rachel Ward and Qiang Liu", "title": "Implicit Regularization and Convergence for Weight Normalization", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization methods such as batch [Ioffe and Szegedy, 2015], weight\n[Salimansand Kingma, 2016], instance [Ulyanov et al., 2016], and layer\nnormalization [Baet al., 2016] have been widely used in modern machine\nlearning. Here, we study the weight normalization (WN) method [Salimans and\nKingma, 2016] and a variant called reparametrized projected gradient descent\n(rPGD) for overparametrized least-squares regression. WN and rPGD reparametrize\nthe weights with a scale g and a unit vector w and thus the objective function\nbecomes non-convex. We show that this non-convex formulation has beneficial\nregularization effects compared to gradient descent on the original objective.\nThese methods adaptively regularize the weights and converge close to the\nminimum l2 norm solution, even for initializations far from zero. For certain\nstepsizes of g and w , we show that they can converge close to the minimum norm\nsolution. This is different from the behavior of gradient descent, which\nconverges to the minimum norm solution only when started at a point in the\nrange space of the feature matrix, and is thus more sensitive to\ninitialization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:10:21 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 04:36:05 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 06:05:43 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 19:09:58 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Dobriban", "Edgar", ""], ["Ren", "Tongzheng", ""], ["Wu", "Shanshan", ""], ["Li", "Zhiyuan", ""], ["Gunasekar", "Suriya", ""], ["Ward", "Rachel", ""], ["Liu", "Qiang", ""]]}, {"id": "1911.07963", "submitter": "Ziteng Sun", "authors": "Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan", "title": "Can You Really Backdoor Federated Learning?", "comments": "To appear at the 2nd International Workshop on Federated Learning for\n  Data Privacy and Confidentiality at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized nature of federated learning makes detecting and defending\nagainst adversarial attacks a challenging task. This paper focuses on backdoor\nattacks in the federated learning setting, where the goal of the adversary is\nto reduce the performance of the model on targeted tasks while maintaining good\nperformance on the main task. Unlike existing works, we allow non-malicious\nclients to have correctly labeled samples from the targeted tasks. We conduct a\ncomprehensive study of backdoor attacks and defenses for the EMNIST dataset, a\nreal-life, user-partitioned, and non-iid dataset. We observe that in the\nabsence of defenses, the performance of the attack largely depends on the\nfraction of adversaries present and the \"complexity'' of the targeted task.\nMoreover, we show that norm clipping and \"weak'' differential privacy mitigate\nthe attacks without hurting the overall performance. We have implemented the\nattacks and defenses in TensorFlow Federated (TFF), a TensorFlow framework for\nfederated learning. In open-sourcing our code, our goal is to encourage\nresearchers to contribute new attacks and defenses and evaluate them on\nstandard federated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:25:03 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 19:00:11 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Sun", "Ziteng", ""], ["Kairouz", "Peter", ""], ["Suresh", "Ananda Theertha", ""], ["McMahan", "H. Brendan", ""]]}, {"id": "1911.07964", "submitter": "Kyle Helfrich", "authors": "Kyle Helfrich and Qiang Ye", "title": "Eigenvalue Normalized Recurrent Neural Networks for Short Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several variants of recurrent neural networks (RNNs) with orthogonal or\nunitary recurrent matrices have recently been developed to mitigate the\nvanishing/exploding gradient problem and to model long-term dependencies of\nsequences. However, with the eigenvalues of the recurrent matrix on the unit\ncircle, the recurrent state retains all input information which may\nunnecessarily consume model capacity. In this paper, we address this issue by\nproposing an architecture that expands upon an orthogonal/unitary RNN with a\nstate that is generated by a recurrent matrix with eigenvalues in the unit\ndisc. Any input to this state dissipates in time and is replaced with new\ninputs, simulating short-term memory. A gradient descent algorithm is derived\nfor learning such a recurrent matrix. The resulting method, called the\nEigenvalue Normalized RNN (ENRNN), is shown to be highly competitive in several\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:28:02 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Helfrich", "Kyle", ""], ["Ye", "Qiang", ""]]}, {"id": "1911.07967", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "DLBricks: Composable Benchmark Generation to Reduce Deep Learning\n  Benchmarking Effort on CPUs (Extended)", "comments": null, "journal-ref": null, "doi": "10.1145/3358960.3379143", "report-no": null, "categories": "cs.LG cs.PF cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past few years have seen a surge of applying Deep Learning (DL) models\nfor a wide array of tasks such as image classification, object detection,\nmachine translation, etc. While DL models provide an opportunity to solve\notherwise intractable tasks, their adoption relies on them being optimized to\nmeet latency and resource requirements. Benchmarking is a key step in this\nprocess but has been hampered in part due to the lack of representative and\nup-to-date benchmarking suites. This is exacerbated by the fast-evolving pace\nof DL models.\n  This paper proposes DLBricks, a composable benchmark generation design that\nreduces the effort of developing, maintaining, and running DL benchmarks on\nCPUs. DLBricks decomposes DL models into a set of unique runnable networks and\nconstructs the original model's performance using the performance of the\ngenerated benchmarks. DLBricks leverages two key observations: DL layers are\nthe performance building blocks of DL models and layers are extensively\nrepeated within and across DL models. Since benchmarks are generated\nautomatically and the benchmarking time is minimized, DLBricks can keep\nup-to-date with the latest proposed models, relieving the pressure of selecting\nrepresentative DL models. Moreover, DLBricks allows users to represent\nproprietary models within benchmark suites. We evaluate DLBricks using $50$\nMXNet models spanning $5$ DL tasks on $4$ representative CPU systems. We show\nthat DLBricks provides an accurate performance estimate for the DL models and\nreduces the benchmarking time across systems (e.g. within $95\\%$ accuracy and\nup to $4.4\\times$ benchmarking time speedup on Amazon EC2 c5.xlarge).\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:42:36 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:51:05 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 16:51:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1911.07970", "submitter": "George Kesidis", "authors": "Zhen Xiang, David J. Miller, George Kesidis", "title": "Revealing Perceptible Backdoors, without the Training Set, via the\n  Maximum Achievable Misclassification Fraction Statistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a backdoor data poisoning attack was proposed, which adds\nmislabeled examples to the training set, with an embedded backdoor pattern,\naiming to have the classifier learn to classify to a target class whenever the\nbackdoor pattern is present in a test sample. Here, we address post-training\ndetection of innocuous perceptible backdoors in DNN image classifiers, wherein\nthe defender does not have access to the poisoned training set, but only to the\ntrained classifier, as well as unpoisoned examples. This problem is challenging\nbecause without the poisoned training set, we have no hint about the actual\nbackdoor pattern used during training. This post-training scenario is also of\ngreat import because in many practical contexts the DNN user did not train the\nDNN and does not have access to the training data. We identify two important\nproperties of perceptible backdoor patterns - spatial invariance and robustness\n- based upon which we propose a novel detector using the maximum achievable\nmisclassification fraction (MAMF) statistic. We detect whether the trained DNN\nhas been backdoor-attacked and infer the source and target classes. Our\ndetector outperforms other existing detectors and, coupled with an\nimperceptible backdoor detector, helps achieve post-training detection of all\nevasive backdoors.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:44:27 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:19:35 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Xiang", "Zhen", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1911.07971", "submitter": "Raj Kumar Maity", "authors": "Venkata Gandikota, Daniel Kane, Raj Kumar Maity, Arya Mazumdar", "title": "vqSGD: Vector Quantized Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a family of vector quantization schemes \\emph{vqSGD}\n(Vector-Quantized Stochastic Gradient Descent) that provide an asymptotic\nreduction in the communication cost with convergence guarantees in first-order\ndistributed optimization. In the process we derive the following fundamental\ninformation theoretic fact: $\\Theta(\\frac{d}{R^2})$ bits are necessary and\nsufficient to describe an unbiased estimator ${\\hat{g}}({g})$ for any ${g}$ in\nthe $d$-dimensional unit sphere, under the constraint that\n$\\|{\\hat{g}}({g})\\|_2\\le R$ almost surely. In particular, we consider a\nrandomized scheme based on the convex hull of a point set, that returns an\nunbiased estimator of a $d$-dimensional gradient vector with almost surely\nbounded norm. We provide multiple efficient instances of our scheme, that are\nnear optimal, and require only $o(d)$ bits of communication at the expense of\ntolerable increase in error. The instances of our quantization scheme are\nobtained using the properties of binary error-correcting codes and provide a\nsmooth tradeoff between the communication and the estimation error of\nquantization. Furthermore, we show that \\emph{vqSGD} also offers strong privacy\nguarantees.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:48:01 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 18:22:02 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 09:18:41 GMT"}, {"version": "v4", "created": "Thu, 24 Dec 2020 21:07:55 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Gandikota", "Venkata", ""], ["Kane", "Daniel", ""], ["Maity", "Raj Kumar", ""], ["Mazumdar", "Arya", ""]]}, {"id": "1911.07979", "submitter": "Ekagra Ranjan", "authors": "Ekagra Ranjan, Soumya Sanyal, Partha Pratim Talukdar", "title": "ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph\n  Representations", "comments": "The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNN) have been shown to work effectively for modeling\ngraph structured data to solve tasks such as node classification, link\nprediction and graph classification. There has been some recent progress in\ndefining the notion of pooling in graphs whereby the model tries to generate a\ngraph level representation by downsampling and summarizing the information\npresent in the nodes. Existing pooling methods either fail to effectively\ncapture the graph substructure or do not easily scale to large graphs. In this\nwork, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and\ndifferentiable pooling method that addresses the limitations of previous graph\npooling architectures. ASAP utilizes a novel self-attention network along with\na modified GNN formulation to capture the importance of each node in a given\ngraph. It also learns a sparse soft cluster assignment for nodes at each layer\nto effectively pool the subgraphs to form the pooled graph. Through extensive\nexperiments on multiple datasets and theoretical analysis, we motivate our\nchoice of the components used in ASAP. Our experimental results show that\ncombining existing GNN architectures with ASAP leads to state-of-the-art\nresults on multiple graph classification benchmarks. ASAP has an average\nimprovement of 4%, compared to current sparse hierarchical state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:04:52 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 13:33:17 GMT"}, {"version": "v3", "created": "Sun, 2 Feb 2020 12:53:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ranjan", "Ekagra", ""], ["Sanyal", "Soumya", ""], ["Talukdar", "Partha Pratim", ""]]}, {"id": "1911.07982", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Unsupervised Domain Adaptation via Structured Prediction Based Selective\n  Pseudo-Labeling", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation aims to address the problem of classifying\nunlabeled samples from the target domain whilst labeled samples are only\navailable from the source domain and the data distributions are different in\nthese two domains. As a result, classifiers trained from labeled samples in the\nsource domain suffer from significant performance drop when directly applied to\nthe samples from the target domain. To address this issue, different approaches\nhave been proposed to learn domain-invariant features or domain-specific\nclassifiers. In either case, the lack of labeled samples in the target domain\ncan be an issue which is usually overcome by pseudo-labeling. Inaccurate\npseudo-labeling, however, could result in catastrophic error accumulation\nduring learning. In this paper, we propose a novel selective pseudo-labeling\nstrategy based on structured prediction. The idea of structured prediction is\ninspired by the fact that samples in the target domain are well clustered\nwithin the deep feature space so that unsupervised clustering analysis can be\nused to facilitate accurate pseudo-labeling. Experimental results on four\ndatasets (i.e. Office-Caltech, Office31, ImageCLEF-DA and Office-Home) validate\nour approach outperforms contemporary state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:21:47 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1911.07984", "submitter": "Shivam Kalra", "authors": "Shivam Kalra, Mohammed Adnan, Graham Taylor, Hamid Tizhoosh", "title": "Learning Permutation Invariant Representations using Memory Networks", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks such as classification of digital histopathology images\nand 3D object detection involve learning from a set of instances. In these\ncases, only a group of instances or a set, collectively, contains meaningful\ninformation and therefore only the sets have labels, and not individual data\ninstances. In this work, we present a permutation invariant neural network\ncalled Memory-based Exchangeable Model (MEM) for learning set functions. The\nMEM model consists of memory units that embed an input sequence to high-level\nfeatures enabling the model to learn inter-dependencies among instances through\na self-attention mechanism. We evaluated the learning ability of MEM on various\ntoy datasets, point cloud classification, and classification of lung whole\nslide images (WSIs) into two subtypes of lung cancer---Lung Adenocarcinoma, and\nLung Squamous Cell Carcinoma. We systematically extracted patches from lung\nWSIs downloaded from The Cancer Genome Atlas~(TCGA) dataset, the largest public\nrepository of WSIs, achieving a competitive accuracy of 84.84\\% for\nclassification of two sub-types of lung cancer. The results on other datasets\nare promising as well, and demonstrate the efficacy of our model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:28:30 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:27:23 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Kalra", "Shivam", ""], ["Adnan", "Mohammed", ""], ["Taylor", "Graham", ""], ["Tizhoosh", "Hamid", ""]]}, {"id": "1911.07989", "submitter": "Micah Goldblum", "authors": "Ping-Yeh Chiang, Jonas Geiping, Micah Goldblum, Tom Goldstein, Renkun\n  Ni, Steven Reich, Ali Shafahi", "title": "WITCHcraft: Efficient PGD attacks with random step size", "comments": "Authors contributed equally and are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art adversarial attacks on neural networks use expensive\niterative methods and numerous random restarts from different initial points.\nIterative FGSM-based methods without restarts trade off performance for\ncomputational efficiency because they do not adequately explore the image space\nand are highly sensitive to the choice of step size. We propose a variant of\nProjected Gradient Descent (PGD) that uses a random step size to improve\nperformance without resorting to expensive random restarts. Our method, Wide\nIterative Stochastic crafting (WITCHcraft), achieves results superior to the\nclassical PGD attack on the CIFAR-10 and MNIST data sets but without additional\ncomputational cost. This simple modification of PGD makes crafting attacks more\neconomical, which is important in situations like adversarial training where\nattacks need to be crafted in real time.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:40:08 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chiang", "Ping-Yeh", ""], ["Geiping", "Jonas", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""], ["Ni", "Renkun", ""], ["Reich", "Steven", ""], ["Shafahi", "Ali", ""]]}, {"id": "1911.08004", "submitter": "Dana Yang", "authors": "Jian Ding, Yihong Wu, Jiaming Xu, and Dana Yang", "title": "Consistent recovery threshold of hidden nearest neighbor graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.SI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications such as discovering strong ties in social networks\nand assembling genome subsequences in biology, we study the problem of\nrecovering a hidden $2k$-nearest neighbor (NN) graph in an $n$-vertex complete\ngraph, whose edge weights are independent and distributed according to $P_n$\nfor edges in the hidden $2k$-NN graph and $Q_n$ otherwise. The special case of\nBernoulli distributions corresponds to a variant of the Watts-Strogatz\nsmall-world graph. We focus on two types of asymptotic recovery guarantees as\n$n\\to \\infty$: (1) exact recovery: all edges are classified correctly with\nprobability tending to one; (2) almost exact recovery: the expected number of\nmisclassified edges is $o(nk)$. We show that the maximum likelihood estimator\nachieves (1) exact recovery for $2 \\le k \\le n^{o(1)}$ if $ \\liminf\n\\frac{2\\alpha_n}{\\log n}>1$; (2) almost exact recovery for $ 1 \\le k \\le\no\\left( \\frac{\\log n}{\\log \\log n} \\right)$ if $\\liminf\n\\frac{kD(P_n||Q_n)}{\\log n}>1$, where $\\alpha_n \\triangleq -2 \\log \\int \\sqrt{d\nP_n d Q_n}$ is the R\\'enyi divergence of order $\\frac{1}{2}$ and $D(P_n||Q_n)$\nis the Kullback-Leibler divergence. Under mild distributional assumptions,\nthese conditions are shown to be information-theoretically necessary for any\nalgorithm to succeed. A key challenge in the analysis is the enumeration of\n$2k$-NN graphs that differ from the hidden one by a given number of edges.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:44:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ding", "Jian", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""], ["Yang", "Dana", ""]]}, {"id": "1911.08011", "submitter": "Iman Niazazari", "authors": "Iman Niazazari, Hanif Livani", "title": "Attack on Grid Event Cause Analysis: An Adversarial Machine Learning\n  Approach", "comments": "5 pages, 4 figures, IEEE Innovative Smart Grid Technologies North\n  American 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing reliance on data for data-driven applications in\npower grids, such as event cause analysis, the authenticity of data streams has\nbecome crucially important. The data can be prone to adversarial stealthy\nattacks aiming to manipulate the data such that residual-based bad data\ndetectors cannot detect them, and the perception of system operators or event\nclassifiers changes about the actual event. This paper investigates the impact\nof adversarial attacks on convolutional neural network-based event cause\nanalysis frameworks. We have successfully verified the ability of adversaries\nto maliciously misclassify events through stealthy data manipulations. The\nvulnerability assessment is studied with respect to the number of compromised\nmeasurements. Furthermore, a defense mechanism to robustify the performance of\nthe event cause analysis is proposed. The effectiveness of adversarial attacks\non changing the output of the framework is studied using the data generated by\nreal-time digital simulator (RTDS) under different scenarios such as type of\nattacks and level of access to data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:14:54 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 06:05:27 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Niazazari", "Iman", ""], ["Livani", "Hanif", ""]]}, {"id": "1911.08017", "submitter": "Neale Ratzlaff", "authors": "Neale Ratzlaff, Qinxun Bai, Li Fuxin, Wei Xu", "title": "Implicit Generative Modeling for Efficient Exploration", "comments": "14 pages, 9 figures, Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration remains a challenging problem in reinforcement\nlearning, especially for those tasks where rewards from environments are\nsparse. A commonly used approach for exploring such environments is to\nintroduce some \"intrinsic\" reward. In this work, we focus on model uncertainty\nestimation as an intrinsic reward for efficient exploration. In particular, we\nintroduce an implicit generative modeling approach to estimate a Bayesian\nuncertainty of the agent's belief of the environment dynamics. Each random draw\nfrom our generative model is a neural network that instantiates the dynamic\nfunction, hence multiple draws would approximate the posterior, and the\nvariance in the future prediction based on this posterior is used as an\nintrinsic reward for exploration. We design a training algorithm for our\ngenerative model based on the amortized Stein Variational Gradient Descent. In\nexperiments, we compare our implementation with state-of-the-art intrinsic\nreward-based exploration approaches, including two recent approaches based on\nan ensemble of dynamic models. In challenging exploration tasks, our implicit\ngenerative model consistently outperforms competing approaches regarding data\nefficiency in exploration.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:37:23 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:56:10 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 19:21:32 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Ratzlaff", "Neale", ""], ["Bai", "Qinxun", ""], ["Fuxin", "Li", ""], ["Xu", "Wei", ""]]}, {"id": "1911.08019", "submitter": "Eugene Belilovsky", "authors": "Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Joelle Pineau", "title": "Online Learned Continual Compression with Adaptive Quantization Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the problem of Online Continual Compression, where one\nattempts to simultaneously learn to compress and store a representative dataset\nfrom a non i.i.d data stream, while only observing each sample once. A naive\napplication of auto-encoders in this setting encounters a major challenge:\nrepresentations derived from earlier encoder states must be usable by later\ndecoder states. We show how to use discrete auto-encoders to effectively\naddress this challenge and introduce Adaptive Quantization Modules (AQM) to\ncontrol variation in the compression ability of the module at any given stage\nof learning. This enables selecting an appropriate compression for incoming\nsamples, while taking into account overall memory constraints and current\nprogress of the learned compression. Unlike previous methods, our approach does\nnot require any pretraining, even on challenging datasets. We show that using\nAQM to replace standard episodic memory in continual learning settings leads to\nsignificant gains on continual learning benchmarks. Furthermore we demonstrate\nthis approach with larger images, LiDAR, and reinforcement learning\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:43:16 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 00:23:18 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 19:19:56 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Caccia", "Lucas", ""], ["Belilovsky", "Eugene", ""], ["Caccia", "Massimo", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.08024", "submitter": "Baokun He", "authors": "Baokun He, Guihong Wan, Haim Schweitzer", "title": "A Bias Trick for Centered Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier based Robust Principal Component Analysis (RPCA) requires centering\nof the non-outliers. We show a \"bias trick\" that automatically centers these\nnon-outliers. Using this bias trick we obtain the first RPCA algorithm that is\noptimal with respect to centering.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 00:59:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["He", "Baokun", ""], ["Wan", "Guihong", ""], ["Schweitzer", "Haim", ""]]}, {"id": "1911.08031", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "The Design and Implementation of a Scalable DL Benchmarking Platform", "comments": null, "journal-ref": "2020 IEEE 13th International Conference on Cloud Computing\n  (CLOUD), 414-425", "doi": "10.1109/CLOUD49709.2020.00063", "report-no": null, "categories": "cs.DC cs.GL cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current Deep Learning (DL) landscape is fast-paced and is rife with\nnon-uniform models, hardware/software (HW/SW) stacks, but lacks a DL\nbenchmarking platform to facilitate evaluation and comparison of DL\ninnovations, be it models, frameworks, libraries, or hardware. Due to the lack\nof a benchmarking platform, the current practice of evaluating the benefits of\nproposed DL innovations is both arduous and error-prone - stifling the adoption\nof the innovations.\n  In this work, we first identify $10$ design features which are desirable\nwithin a DL benchmarking platform. These features include: performing the\nevaluation in a consistent, reproducible, and scalable manner, being framework\nand hardware agnostic, supporting real-world benchmarking workloads, providing\nin-depth model execution inspection across the HW/SW stack levels, etc. We then\npropose MLModelScope, a DL benchmarking platform design that realizes the $10$\nobjectives. MLModelScope proposes a specification to define DL model\nevaluations and techniques to provision the evaluation workflow using the\nuser-specified HW/SW stack. MLModelScope defines abstractions for frameworks\nand supports board range of DL models and evaluation scenarios. We implement\nMLModelScope as an open-source project with support for all major frameworks\nand hardware architectures. Through MLModelScope's evaluation and automated\nanalysis workflows, we performed case-study analyses of $37$ models across $4$\nsystems and show how model, hardware, and framework selection affects model\naccuracy and performance under different benchmarking scenarios. We further\ndemonstrated how MLModelScope's tracing capability gives a holistic view of\nmodel execution and helps pinpoint bottlenecks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:16:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1911.08048", "submitter": "Yixuan Qiu", "authors": "Yixuan Qiu, Jing Lei, and Kathryn Roeder", "title": "Gradient-based Sparse Principal Component Analysis with Extensions to\n  Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (PCA) is an important technique for\ndimensionality reduction of high-dimensional data. However, most existing\nsparse PCA algorithms are based on non-convex optimization, which provide\nlittle guarantee on the global convergence. Sparse PCA algorithms based on a\nconvex formulation, for example the Fantope projection and selection (FPS),\novercome this difficulty, but are computationally expensive. In this work we\nstudy sparse PCA based on the convex FPS formulation, and propose a new\nalgorithm that is computationally efficient and applicable to large and\nhigh-dimensional data sets. Nonasymptotic and explicit bounds are derived for\nboth the optimization error and the statistical accuracy, which can be used for\ntesting and inference problems. We also extend our algorithm to online learning\nproblems, where data are obtained in a streaming fashion. The proposed\nalgorithm is applied to high-dimensional gene expression data for the detection\nof functional gene groups.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:17:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Qiu", "Yixuan", ""], ["Lei", "Jing", ""], ["Roeder", "Kathryn", ""]]}, {"id": "1911.08050", "submitter": "Hwanjun Song", "authors": "Hwanjun Song, Minseok Kim, Sundong Kim, Jae-Gil Lee", "title": "Carpe Diem, Seize the Samples Uncertain \"At the Moment\" for Adaptive\n  Batch Selection", "comments": "Published at CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of deep neural networks is significantly affected by how well\nmini-batches are constructed during the training step. In this paper, we\npropose a novel adaptive batch selection algorithm called Recency Bias that\nexploits the uncertain samples predicted inconsistently in recent iterations.\nThe historical label predictions of each training sample are used to evaluate\nits predictive uncertainty within a sliding window. Then, the sampling\nprobability for the next mini-batch is assigned to each training sample in\nproportion to its predictive uncertainty. By taking advantage of this design,\nRecency Bias not only accelerates the training step but also achieves a more\naccurate network. We demonstrate the superiority of Recency Bias by extensive\nevaluation on two independent tasks. Compared with existing batch selection\nmethods, the results showed that Recency Bias reduced the test error by up to\n20.97% in a fixed wall-clock training time. At the same time, it improved the\ntraining time by up to 59.32% to reach the same test error\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:28:07 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 01:15:51 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Song", "Hwanjun", ""], ["Kim", "Minseok", ""], ["Kim", "Sundong", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1911.08051", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Jessie Rosenberg, Dan Gutfreund, David D. Cox", "title": "SimVAE: Simulator-Assisted Training forInterpretable Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simulator-assisted training method (SimVAE) for\nvariational autoencoders (VAE) that leads to a disentangled and interpretable\nlatent space. Training SimVAE is a two-step process in which first a deep\ngenerator network(decoder) is trained to approximate the simulator. During this\nstep, the simulator acts as the data source or as a teacher network. Then an\ninference network (encoder)is trained to invert the decoder. As such, upon\ncomplete training, the encoder represents an approximately inverted simulator.\nBy decoupling the training of the encoder and decoder we bypass some of the\ndifficulties that arise in training generative models such as VAEs and\ngenerative adversarial networks (GANs). We show applications of our approach in\na variety of domains such as circuit design, graphics de-rendering and other\nnatural science problems that involve inference via simulation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:39:27 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Srivastava", "Akash", ""], ["Rosenberg", "Jessie", ""], ["Gutfreund", "Dan", ""], ["Cox", "David D.", ""]]}, {"id": "1911.08054", "submitter": "Himank Yadav", "authors": "Himank Yadav, Zhengxiao Du, Thorsten Joachims", "title": "Policy-Gradient Training of Fair and Unbiased Ranking Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3462953", "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While implicit feedback (e.g., clicks, dwell times, etc.) is an abundant and\nattractive source of data for learning to rank, it can produce unfair ranking\npolicies for both exogenous and endogenous reasons. Exogenous reasons typically\nmanifest themselves as biases in the training data, which then get reflected in\nthe learned ranking policy and often lead to rich-get-richer dynamics.\nMoreover, even after the correction of such biases, reasons endogenous to the\ndesign of the learning algorithm can still lead to ranking policies that do not\nallocate exposure among items in a fair way. To address both exogenous and\nendogenous sources of unfairness, we present the first learning-to-rank\napproach that addresses both presentation bias and merit-based fairness of\nexposure simultaneously. Specifically, we define a class of amortized\nfairness-of-exposure constraints that can be chosen based on the needs of an\napplication, and we show how these fairness criteria can be enforced despite\nthe selection biases in implicit feedback data. The key result is an efficient\nand flexible policy-gradient algorithm, called FULTR, which is the first to\nenable the use of counterfactual estimators for both utility estimation and\nfairness constraints. Beyond the theoretical justification of the framework, we\nshow empirically that the proposed algorithm can learn accurate and fair\nranking policies from biased and noisy feedback.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:45:42 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 11:15:39 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yadav", "Himank", ""], ["Du", "Zhengxiao", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1911.08056", "submitter": "Nishant Parashar", "authors": "Nishant Parashar and Sawan S. Sinha and Balaji Srinivasan", "title": "Modelling pressure-Hessian from local velocity gradients information in\n  an incompressible turbulent flow field using deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of the dynamics of the velocity gradients in turbulent\nflows is critical to understanding various non-linear turbulent processes. The\npressure-Hessian and the viscous-Laplacian govern the evolution of the\nvelocity-gradients and are known to be non-local in nature. Over the years,\nseveral simplified dynamical models have been proposed that models the\nviscous-Laplacian and the pressure-Hessian primarily in terms of local velocity\ngradients information. These models can also serve as closure models for the\nLagrangian PDF methods. The recent fluid deformation closure model (RFDM) has\nbeen shown to retrieve excellent one-time statistics of the viscous process.\nHowever, the pressure-Hessian modelled by the RFDM has various physical\nlimitations. In this work, we first demonstrate the limitations of the RFDM in\nestimating the pressure-Hessian. Further, we employ a tensor basis neural\nnetwork (TBNN) to model the pressure-Hessian from the velocity gradient tensor\nitself. The neural network is trained on high-resolution data obtained from\ndirect numerical simulation (DNS) of isotropic turbulence at Reynolds number of\n433 (JHU turbulence database, JHTD). The predictions made by the TBNN are\ntested against two different isotropic turbulence datasets at Reynolds number\nof 433 (JHTD) and 315 (UP Madrid turbulence database, UPMTD) and channel flow\ndataset at Reynolds number of 1000 (UT Texas and JHTD). The evaluation of the\nneural network output is made in terms of the alignment statistics of the\npredicted pressure-Hessian eigenvectors with the strain-rate eigenvectors for\nturbulent isotropic flow as well as channel flow. Our analysis of the predicted\nsolution leads to the discovery of ten unique coefficients of the tensor basis\nof strain-rate and rotation-rate tensors, the linear combination over which\naccurately captures key alignment statistics of the pressure-Hessian tensor.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:48:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Parashar", "Nishant", ""], ["Sinha", "Sawan S.", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "1911.08059", "submitter": "Hwanjun Song", "authors": "Hwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee", "title": "How does Early Stopping Help Generalization against Label Noise?", "comments": "International Conference on Machine Learning, Workshop on Uncertainty\n  and Robustness in Deep Learning. See:\n  https://sites.google.com/view/udlworkshop2020/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labels are very common in real-world training data, which lead to poor\ngeneralization on test data because of overfitting to the noisy labels. In this\npaper, we claim that such overfitting can be avoided by \"early stopping\"\ntraining a deep neural network before the noisy labels are severely memorized.\nThen, we resume training the early stopped network using a \"maximal safe set,\"\nwhich maintains a collection of almost certainly true-labeled samples at each\nepoch since the early stop point. Putting them all together, our novel\ntwo-phase training method, called Prestopping, realizes noise-free training\nunder any type of label noise for practical use. Extensive experiments using\nfour image benchmark data sets verify that our method significantly outperforms\nfour state-of-the-art methods in test error by 0.4-8.2 percent points under\nexistence of real-world noise.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:51:15 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 06:23:50 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 06:23:48 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Song", "Hwanjun", ""], ["Kim", "Minseok", ""], ["Park", "Dongmin", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1911.08065", "submitter": "Yingru Liu", "authors": "Yingru Liu, Xuewen Yang, Dongliang Xie, Xin Wang, Li Shen, Haozhi\n  Huang, Niranjan Balasubramanian", "title": "Adaptive Activation Network and Functional Regularization for Efficient\n  and Flexible Deep Multi-Task Learning", "comments": "To appear in AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task learning (MTL) is a common paradigm that seeks to improve the\ngeneralization performance of task learning by training related tasks\nsimultaneously. However, it is still a challenging problem to search the\nflexible and accurate architecture that can be shared among multiple tasks. In\nthis paper, we propose a novel deep learning model called Task Adaptive\nActivation Network (TAAN) that can automatically learn the optimal network\narchitecture for MTL. The main principle of TAAN is to derive flexible\nactivation functions for different tasks from the data with other parameters of\nthe network fully shared. We further propose two functional regularization\nmethods that improve the MTL performance of TAAN. The improved performance of\nboth TAAN and the regularization methods is demonstrated by comprehensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:05:26 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Yingru", ""], ["Yang", "Xuewen", ""], ["Xie", "Dongliang", ""], ["Wang", "Xin", ""], ["Shen", "Li", ""], ["Huang", "Haozhi", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1911.08085", "submitter": "Sushrut Karmalkar", "authors": "Ilias Diakonikolas, Sushrut Karmalkar, Daniel Kane, Eric Price,\n  Alistair Stewart", "title": "Outlier-Robust High-Dimensional Sparse Estimation via Iterative\n  Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study high-dimensional sparse estimation tasks in a robust setting where a\nconstant fraction of the dataset is adversarially corrupted. Specifically, we\nfocus on the fundamental problems of robust sparse mean estimation and robust\nsparse PCA. We give the first practically viable robust estimators for these\nproblems. In more detail, our algorithms are sample and computationally\nefficient and achieve near-optimal robustness guarantees. In contrast to prior\nprovable algorithms which relied on the ellipsoid method, our algorithms use\nspectral techniques to iteratively remove outliers from the dataset. Our\nexperimental evaluation on synthetic data shows that our algorithms are\nscalable and significantly outperform a range of previous approaches, nearly\nmatching the best error rate without corruptions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:12:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Karmalkar", "Sushrut", ""], ["Kane", "Daniel", ""], ["Price", "Eric", ""], ["Stewart", "Alistair", ""]]}, {"id": "1911.08090", "submitter": "Sarfaraz Hussein", "authors": "Javier Echauz, Keith Kenemer, Sarfaraz Hussein, Jay Dhaliwal, Saurabh\n  Shintre, Slawomir Grzonkowski and Andrew Gardner", "title": "Deep Detector Health Management under Adversarial Campaigns", "comments": "International Journal of Prognostics and Health Management, Special\n  Issue: PHM Applications of Deep Learning and Emerging Analytics, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial inputs that induce\nseemingly unjustifiable errors. As automated classifiers are increasingly used\nin industrial control systems and machinery, these adversarial errors could\ngrow to be a serious problem. Despite numerous studies over the past few years,\nthe field of adversarial ML is still considered alchemy, with no practical\nunbroken defenses demonstrated to date, leaving PHM practitioners with few\nmeaningful ways of addressing the problem. We introduce turbidity detection as\na practical superset of the adversarial input detection problem, coping with\nadversarial campaigns rather than statistically invisible one-offs. This\nperspective is coupled with ROC-theoretic design guidance that prescribes an\ninexpensive domain adaptation layer at the output of a deep learning model\nduring an attack campaign. The result aims to approximate the Bayes optimal\nmitigation that ameliorates the detection model's degraded health. A\nproactively reactive type of prognostics is achieved via Monte Carlo simulation\nof various adversarial campaign scenarios, by sampling from the model's own\nturbidity distribution to quickly deploy the correct mitigation during a\nreal-world campaign.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:33:05 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Echauz", "Javier", ""], ["Kenemer", "Keith", ""], ["Hussein", "Sarfaraz", ""], ["Dhaliwal", "Jay", ""], ["Shintre", "Saurabh", ""], ["Grzonkowski", "Slawomir", ""], ["Gardner", "Andrew", ""]]}, {"id": "1911.08121", "submitter": "Nina Miolane", "authors": "Nina Miolane, Fr\\'ed\\'eric Poitevin, Yee-Ting Li, Susan Holmes", "title": "Estimation of Orientation and Camera Parameters from Cryo-Electron\n  Microscopy Images with Variational Autoencoders and Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryo-electron microscopy (cryo-EM) is capable of producing reconstructed 3D\nimages of biomolecules at near-atomic resolution. As such, it represents one of\nthe most promising imaging techniques in structural biology. However, raw\ncryo-EM images are only highly corrupted - noisy and band-pass filtered - 2D\nprojections of the target 3D biomolecules. Reconstructing the 3D molecular\nshape starts with the removal of image outliers, the estimation of the\norientation of the biomolecule that has produced the given 2D image, and the\nestimation of camera parameters to correct for intensity defects. Current\ntechniques performing these tasks are often computationally expensive, while\nthe dataset sizes keep growing. There is a need for next-generation algorithms\nthat preserve accuracy while improving speed and scalability. In this paper, we\ncombine variational autoencoders (VAEs) and generative adversarial networks\n(GANs) to learn a low-dimensional latent representation of cryo-EM images. We\nperform an exploratory analysis of the obtained latent space, that is shown to\nhave a structure of \"orbits\", in the sense of Lie group theory, consistent with\nthe acquisition procedure of cryo-EM images. This analysis leads us to design\nan estimation method for orientation and camera parameters of single-particle\ncryo-EM images, together with an outliers detection procedure. As such, it\nopens the door to geometric approaches for unsupervised estimations of\norientations and camera parameters, making possible fast cryo-EM biomolecule\nreconstruction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 07:04:43 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 19:11:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Miolane", "Nina", ""], ["Poitevin", "Fr\u00e9d\u00e9ric", ""], ["Li", "Yee-Ting", ""], ["Holmes", "Susan", ""]]}, {"id": "1911.08147", "submitter": "Nina Miolane", "authors": "Nina Miolane, Susan Holmes", "title": "Learning Weighted Submanifolds with Variational Autoencoders and\n  Riemannian Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold-valued data naturally arises in medical imaging. In cognitive\nneuroscience, for instance, brain connectomes base the analysis of coactivation\npatterns between different brain regions on the analysis of the correlations of\ntheir functional Magnetic Resonance Imaging (fMRI) time series - an object thus\nconstrained by construction to belong to the manifold of symmetric positive\ndefinite matrices. One of the challenges that naturally arises consists of\nfinding a lower-dimensional subspace for representing such manifold-valued\ndata. Traditional techniques, like principal component analysis, are\nill-adapted to tackle non-Euclidean spaces and may fail to achieve a\nlower-dimensional representation of the data - thus potentially pointing to the\nabsence of lower-dimensional representation of the data. However, these\ntechniques are restricted in that: (i) they do not leverage the assumption that\nthe connectomes belong on a pre-specified manifold, therefore discarding\ninformation; (ii) they can only fit a linear subspace to the data. In this\npaper, we are interested in variants to learn potentially highly curved\nsubmanifolds of manifold-valued data. Motivated by the brain connectomes\nexample, we investigate a latent variable generative model, which has the added\nbenefit of providing us with uncertainty estimates - a crucial quantity in the\nmedical applications we are considering. While latent variable models have been\nproposed to learn linear and nonlinear spaces for Euclidean data, or geodesic\nsubspaces for manifold data, no intrinsic latent variable model exists to learn\nnongeodesic subspaces for manifold data. This paper fills this gap and\nformulates a Riemannian variational autoencoder with an intrinsic generative\nmodel of manifold-valued data. We evaluate its performances on synthetic and\nreal datasets by introducing the formalism of weighted Riemannian submanifolds.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:15:31 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Miolane", "Nina", ""], ["Holmes", "Susan", ""]]}, {"id": "1911.08192", "submitter": "Zhiwei Jia", "authors": "Zhiwei Jia and Hao Su", "title": "Information-Theoretic Local Minima Characterization and Regularization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning theory have evoked the study of\ngeneralizability across different local minima of deep neural networks (DNNs).\nWhile current work focused on either discovering properties of good local\nminima or developing regularization techniques to induce good local minima, no\napproach exists that can tackle both problems. We achieve these two goals\nsuccessfully in a unified manner. Specifically, based on the observed Fisher\ninformation we propose a metric both strongly indicative of generalizability of\nlocal minima and effectively applied as a practical regularizer. We provide\ntheoretical analysis including a generalization bound and empirically\ndemonstrate the success of our approach in both capturing and improving the\ngeneralizability of DNNs. Experiments are performed on CIFAR-10, CIFAR-100 and\nImageNet for various network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:14:33 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 10:23:27 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jia", "Zhiwei", ""], ["Su", "Hao", ""]]}, {"id": "1911.08197", "submitter": "Dhruti Shah", "authors": "Dhruti Shah, Tuhinangshu Choudhury, Nikhil Karamchandani, Aditya\n  Gopalan", "title": "Sequential Mode Estimation with Oracle Queries", "comments": "A shorter version of this paper has been accepted for publication at\n  Association for the Advancement of Artificial Intelligence - AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of adaptively PAC-learning a probability distribution\n$\\mathcal{P}$'s mode by querying an oracle for information about a sequence of\ni.i.d. samples $X_1, X_2, \\ldots$ generated from $\\mathcal{P}$. We consider two\ndifferent query models: (a) each query is an index $i$ for which the oracle\nreveals the value of the sample $X_i$, (b) each query is comprised of two\nindices $i$ and $j$ for which the oracle reveals if the samples $X_i$ and $X_j$\nare the same or not. For these query models, we give sequential mode-estimation\nalgorithms which, at each time $t$, either make a query to the corresponding\noracle based on past observations, or decide to stop and output an estimate for\nthe distribution's mode, required to be correct with a specified confidence. We\nanalyze the query complexity of these algorithms for any underlying\ndistribution $\\mathcal{P}$, and derive corresponding lower bounds on the\noptimal query complexity under the two querying models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:25:32 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Shah", "Dhruti", ""], ["Choudhury", "Tuhinangshu", ""], ["Karamchandani", "Nikhil", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1911.08201", "submitter": "Giulia Fracastoro", "authors": "Giuseppe C. Calafiore, Marisa H. Morales, Vittorio Tiozzo, Giulia\n  Fracastoro, Serge Marquie", "title": "Survival and Neural Models for Private Equity Exit Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the Private Equity (PE) market, the event of a private company\nundertaking an Initial Public Offering (IPO) is usually a very high-return one\nfor the investors in the company. For this reason, an effective predictive\nmodel for the IPO event is considered as a valuable tool in the PE market, an\nendeavor in which publicly available quantitative information is generally\nscarce. In this paper, we describe a data-analytic procedure for predicting the\nprobability with which a company will go public in a given forward period of\ntime. The proposed method is based on the interplay of a neural network (NN)\nmodel for estimating the overall event probability, and Survival Analysis (SA)\nfor further modeling the probability of the IPO event in any given interval of\ntime. The proposed neuro-survival model is tuned and tested across nine\nindustrial sectors using real data from the Thomson Reuters Eikon PE database.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:33:38 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:30:11 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 08:44:12 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 10:56:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Calafiore", "Giuseppe C.", ""], ["Morales", "Marisa H.", ""], ["Tiozzo", "Vittorio", ""], ["Fracastoro", "Giulia", ""], ["Marquie", "Serge", ""]]}, {"id": "1911.08252", "submitter": "Furao Shen", "authors": "Junyi An, Fengshan Liu, Jian Zhao, Furao Shen", "title": "IC-Network: Efficient Structure for Convolutional Neural Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been widely used, and most networks achieve excellent\nperformance by stacking certain types of basic units. Compared to increasing\nthe depth and width of the network, designing more effective basic units has\nbecome an important research topic. Inspired by the elastic collision model in\nphysics, we present a universal structure that could be integrated into the\nexisting network structures to speed up the training process and increase their\ngeneralization abilities. We term this structure the \"Inter-layer Collision\"\n(IC) structure. We built two kinds of basic computational units (IC layer and\nIC block) that compose the convolutional neural networks (CNNs) by combining\nthe IC structure with the convolution operation. Compared to traditional\nconvolutions, both of the proposed computational units have a stronger\nnon-linear representation ability and can filter features useful for a given\ntask. Using these computational units to build networks, we bring significant\nimprovements in performance for existing state-of-the-art CNNs. On the imagenet\nexperiment, we integrate the IC block into ResNet-50 and reduce the top-1 error\nfrom 22.85% to 21.49%, which also exceeds the top-1 error of ResNet-100\n(21.75%).\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:26:06 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 07:13:37 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 02:58:07 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 15:05:47 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["An", "Junyi", ""], ["Liu", "Fengshan", ""], ["Zhao", "Jian", ""], ["Shen", "Furao", ""]]}, {"id": "1911.08265", "submitter": "Julian Schrittwieser", "authors": "Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen\n  Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis\n  Hassabis, Thore Graepel, Timothy Lillicrap, David Silver", "title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model", "comments": null, "journal-ref": null, "doi": "10.1038/s41586-020-03051-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing agents with planning capabilities has long been one of the main\nchallenges in the pursuit of artificial intelligence. Tree-based planning\nmethods have enjoyed huge success in challenging domains, such as chess and Go,\nwhere a perfect simulator is available. However, in real-world problems the\ndynamics governing the environment are often complex and unknown. In this work\nwe present the MuZero algorithm which, by combining a tree-based search with a\nlearned model, achieves superhuman performance in a range of challenging and\nvisually complex domains, without any knowledge of their underlying dynamics.\nMuZero learns a model that, when applied iteratively, predicts the quantities\nmost directly relevant to planning: the reward, the action-selection policy,\nand the value function. When evaluated on 57 different Atari games - the\ncanonical video game environment for testing AI techniques, in which\nmodel-based planning approaches have historically struggled - our new algorithm\nachieved a new state of the art. When evaluated on Go, chess and shogi, without\nany knowledge of the game rules, MuZero matched the superhuman performance of\nthe AlphaZero algorithm that was supplied with the game rules.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:58:52 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 18:05:30 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Schrittwieser", "Julian", ""], ["Antonoglou", "Ioannis", ""], ["Hubert", "Thomas", ""], ["Simonyan", "Karen", ""], ["Sifre", "Laurent", ""], ["Schmitt", "Simon", ""], ["Guez", "Arthur", ""], ["Lockhart", "Edward", ""], ["Hassabis", "Demis", ""], ["Graepel", "Thore", ""], ["Lillicrap", "Timothy", ""], ["Silver", "David", ""]]}, {"id": "1911.08327", "submitter": "Dhruv Paranjpye", "authors": "Dhruv Paranjpye, Ashish Mahabal, A.N. Ramaprakash, Gina Panopoulou,\n  Kieran Cleary, Anthony Readhead, Dmitry Blinov, Kostas Tassis", "title": "Eliminating artefacts in Polarimetric Images using Deep Learning", "comments": "7 pages, 15 figures", "journal-ref": null, "doi": "10.1093/mnras/stz3250", "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarization measurements done using Imaging Polarimeters such as the Robotic\nPolarimeter are very sensitive to the presence of artefacts in images.\nArtefacts can range from internal reflections in a telescope to satellite\ntrails that could contaminate an area of interest in the image. With the advent\nof wide-field polarimetry surveys, it is imperative to develop methods that\nautomatically flag artefacts in images. In this paper, we implement a\nConvolutional Neural Network to identify the most dominant artefacts in the\nimages. We find that our model can successfully classify sources with 98\\% true\npositive and 97\\% true negative rates. Such models, combined with transfer\nlearning, will give us a running start in artefact elimination for near-future\nsurveys like WALOP.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:03:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Paranjpye", "Dhruv", ""], ["Mahabal", "Ashish", ""], ["Ramaprakash", "A. N.", ""], ["Panopoulou", "Gina", ""], ["Cleary", "Kieran", ""], ["Readhead", "Anthony", ""], ["Blinov", "Dmitry", ""], ["Tassis", "Kostas", ""]]}, {"id": "1911.08332", "submitter": "Dhananjay Ram", "authors": "Dhananjay Ram, Lesly Miculicich and Herv\\'e Bourlard", "title": "Neural Network based End-to-End Query by Example Spoken Term Detection", "comments": "Submitted to IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE\n  PROCESSING", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of query by example spoken term detection\n(QbE-STD) in zero-resource scenario. State-of-the-art approaches primarily rely\non dynamic time warping (DTW) based template matching techniques using phone\nposterior or bottleneck features extracted from a deep neural network (DNN). We\nuse both monolingual and multilingual bottleneck features, and show that\nmultilingual features perform increasingly better with more training languages.\nPreviously, it has been shown that the DTW based matching can be replaced with\na CNN based matching while using posterior features. Here, we show that the CNN\nbased matching outperforms DTW based matching using bottleneck features as\nwell. In this case, the feature extraction and pattern matching stages of our\nQbE-STD system are optimized independently of each other. We propose to\nintegrate these two stages in a fully neural network based end-to-end learning\nframework to enable joint optimization of those two stages simultaneously. The\nproposed approaches are evaluated on two challenging multilingual datasets:\nSpoken Web Search 2013 and Query by Example Search on Speech Task 2014,\ndemonstrating in each case significant improvements.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:07:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ram", "Dhananjay", ""], ["Miculicich", "Lesly", ""], ["Bourlard", "Herv\u00e9", ""]]}, {"id": "1911.08342", "submitter": "Max Berrendorf", "authors": "Max Berrendorf, Evgeniy Faerman, Valentyn Melnychuk, Volker Tresp,\n  Thomas Seidl", "title": "Knowledge Graph Entity Alignment with Graph Convolutional Networks:\n  Lessons Learned", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-45442-5_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of entity alignment in Knowledge Graphs\n(KG) and we report on our experiences when applying a Graph Convolutional\nNetwork (GCN) based model for this task. Variants of GCN are used in multiple\nstate-of-the-art approaches and therefore it is important to understand the\nspecifics and limitations of GCN-based models. Despite serious efforts, we were\nnot able to fully reproduce the results from the original paper and after a\nthorough audit of the code provided by authors, we concluded, that their\nimplementation is different from the architecture described in the paper. In\naddition, several tricks are required to make the model work and some of them\nare not very intuitive. We provide an extensive ablation study to quantify the\neffects these tricks and changes of architecture have on final performance.\nFurthermore, we examine current evaluation approaches and systematize available\nbenchmark datasets. We believe that people interested in KG matching might\nprofit from our work, as well as novices entering the field\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:20:53 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 12:20:45 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Melnychuk", "Valentyn", ""], ["Tresp", "Volker", ""], ["Seidl", "Thomas", ""]]}, {"id": "1911.08348", "submitter": "Oran Gafni", "authors": "Oran Gafni, Lior Wolf, Yaniv Taigman", "title": "Live Face De-Identification in Video", "comments": "ICCV 2019", "journal-ref": "Proceedings of the IEEE International Conference on Computer\n  Vision (2019) 9378--9387", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for face de-identification that enables fully automatic\nvideo modification at high frame rates. The goal is to maximally decorrelate\nthe identity, while having the perception (pose, illumination and expression)\nfixed. We achieve this by a novel feed-forward encoder-decoder network\narchitecture that is conditioned on the high-level representation of a person's\nfacial image. The network is global, in the sense that it does not need to be\nretrained for a given video or for a given identity, and it creates natural\nlooking image sequences with little distortion in time.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:28:35 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Gafni", "Oran", ""], ["Wolf", "Lior", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1911.08354", "submitter": "Sorelle Friedler", "authors": "Kadan Lottick, Silvia Susai, Sorelle A. Friedler, and Jonathan P.\n  Wilson", "title": "Energy Usage Reports: Environmental awareness as part of algorithmic\n  accountability", "comments": "Workshop on Tackling Climate Change with Machine Learning at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The carbon footprint of algorithms must be measured and transparently\nreported so computer scientists can take an honest and active role in\nenvironmental sustainability. In this paper, we take analyses usually applied\nat the industrial level and make them accessible for individual computer\nscience researchers with an easy-to-use Python package. Localizing to the\nenergy mixture of the electrical power grid, we make the conversion from energy\nusage to CO2 emissions, in addition to contextualizing these results with more\nhuman-understandable benchmarks such as automobile miles driven. We also\ninclude comparisons with energy mixtures employed in electrical grids around\nthe world. We propose including these automatically-generated Energy Usage\nReports as part of standard algorithmic accountability practices, and\ndemonstrate the use of these reports as part of model-choice in a machine\nlearning context.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:34:28 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 17:48:35 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lottick", "Kadan", ""], ["Susai", "Silvia", ""], ["Friedler", "Sorelle A.", ""], ["Wilson", "Jonathan P.", ""]]}, {"id": "1911.08361", "submitter": "Ilkka Rautiainen", "authors": "Ilkka Rautiainen, Sami \\\"Ayr\\\"am\\\"o", "title": "Predicting overweight and obesity in later life from childhood data: A\n  review of predictive modeling approaches", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Overweight and obesity are an increasing phenomenon worldwide.\nPredicting future overweight or obesity early in the childhood reliably could\nenable a successful intervention by experts. While a lot of research has been\ndone using explanatory modeling methods, capability of machine learning, and\npredictive modeling, in particular, remain mainly unexplored. In predictive\nmodeling models are validated with previously unseen examples, giving a more\naccurate estimate of their performance and generalization ability in real-life\nscenarios.\n  Objective: To find and review existing overweight or obesity research from\nthe perspective of employing childhood data and predictive modeling methods.\n  Methods: The initial phase included bibliographic searches using relevant\nsearch terms in PubMed, IEEE database and Google Scholar. The second phase\nconsisted of iteratively searching references of potential studies and recent\nresearch that cite the potential studies.\n  Results: Eight research articles and three review articles were identified as\nrelevant for this review.\n  Conclusions: Prediction models with high performance either have a relatively\nshort time period to predict or/and are based on late childhood data. Logistic\nregression is currently the most often used method in forming the prediction\nmodels. In addition to child's own weight and height information, maternal\nweight status or body mass index was often used as predictors in the models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:44:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Rautiainen", "Ilkka", ""], ["\u00c4yr\u00e4m\u00f6", "Sami", ""]]}, {"id": "1911.08378", "submitter": "Rishiraj Saha Roy", "authors": "Azin Ghazimatin, Oana Balalau, Rishiraj Saha Roy, Gerhard Weikum", "title": "PRINCE: Provider-side Interpretability with Counterfactual Explanations\n  in Recommender Systems", "comments": "WSDM 2020, 9 pages", "journal-ref": null, "doi": "10.1145/3336191.3371824", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable explanations for recommender systems and other machine learning\nmodels are crucial to gain user trust. Prior works that have focused on paths\nconnecting users and items in a heterogeneous network have several limitations,\nsuch as discovering relationships rather than true explanations, or\ndisregarding other users' privacy. In this work, we take a fresh perspective,\nand present PRINCE: a provider-side mechanism to produce tangible explanations\nfor end-users, where an explanation is defined to be a set of minimal actions\nperformed by the user that, if removed, changes the recommendation to a\ndifferent item. Given a recommendation, PRINCE uses a polynomial-time optimal\nalgorithm for finding this minimal set of a user's actions from an exponential\nsearch space, based on random walks over dynamic graphs. Experiments on two\nreal-world datasets show that PRINCE provides more compact explanations than\nintuitive baselines, and insights from a crowdsourced user-study demonstrate\nthe viability of such action-based explanations. We thus posit that PRINCE\nproduces scrutable, actionable, and concise explanations, owing to its use of\ncounterfactual evidence, a user's own actions, and minimal sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:23:02 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:23:52 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 13:08:49 GMT"}, {"version": "v4", "created": "Tue, 24 Dec 2019 07:31:30 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Ghazimatin", "Azin", ""], ["Balalau", "Oana", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1911.08382", "submitter": "Vladimir Vargas-Calder\\'on", "authors": "Vladimir Vargas-Calder\\'on and Jorge E. Camargo", "title": "A model for predicting price polarity of real estate properties using\n  information of real estate market websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a model that uses the information that sellers publish in\nreal estate market websites to predict whether a property has higher or lower\nprice than the average price of its similar properties. The model learns the\ncorrelation between price and information (text descriptions and features) of\nreal estate properties through automatic identification of latent semantic\ncontent given by a machine learning model based on doc2vec and xgboost. The\nproposed model was evaluated with a data set of 57,516 publications of real\nestate properties collected from 2016 to 2018 of Bogot\\'a city. Results show\nthat the accuracy of a classifier that involves text descriptions is slightly\nhigher than a classifier that only uses features of the real estate properties,\nas text descriptions tends to contain detailed information about the property.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:29:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Vargas-Calder\u00f3n", "Vladimir", ""], ["Camargo", "Jorge E.", ""]]}, {"id": "1911.08395", "submitter": "Ashwin Geet D'Sa", "authors": "Ashwin Geet D'Sa, Irina Illina, Dominique Fohr", "title": "Towards non-toxic landscapes: Automatic toxic comment detection using\n  DNN", "comments": null, "journal-ref": "In Proceedings of the Second Workshop on Trolling, Aggression and\n  Cyberbullying 2020 May (pp. 21-25)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectacular expansion of the Internet has led to the development of a new\nresearch problem in the field of natural language processing: automatic toxic\ncomment detection, since many countries prohibit hate speech in public media.\nThere is no clear and formal definition of hate, offensive, toxic and abusive\nspeeches. In this article, we put all these terms under the umbrella of \"toxic\"\nspeech. The contribution of this paper is the design of binary classification\nand regression-based approaches aiming to predict whether a comment is toxic or\nnot. We compare different unsupervised word representations and different DNN\nbased classifiers. Moreover, we study the robustness of the proposed approaches\nto adversarial attacks by adding one (healthy or toxic) word. We evaluate the\nproposed methodology on the English Wikipedia Detox corpus. Our experiments\nshow that using BERT fine-tuning outperforms feature-based BERT, Mikolov's and\nfastText representations with different DNN classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:58:54 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:09:40 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["D'Sa", "Ashwin Geet", ""], ["Illina", "Irina", ""], ["Fohr", "Dominique", ""]]}, {"id": "1911.08411", "submitter": "Ondrej Skopek", "authors": "Ondrej Skopek, Octavian-Eugen Ganea, Gary B\\'ecigneul", "title": "Mixed-curvature Variational Autoencoders", "comments": "ICLR 2020 camera ready version", "journal-ref": "International Conference on Learning Representations (ICLR) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclidean geometry has historically been the typical \"workhorse\" for machine\nlearning applications due to its power and simplicity. However, it has recently\nbeen shown that geometric spaces with constant non-zero curvature improve\nrepresentations and performance on a variety of data types and downstream\ntasks. Consequently, generative models like Variational Autoencoders (VAEs)\nhave been successfully generalized to elliptical and hyperbolic latent spaces.\nWhile these approaches work well on data with particular kinds of biases e.g.\ntree-like data for a hyperbolic VAE, there exists no generic approach unifying\nand leveraging all three models. We develop a Mixed-curvature Variational\nAutoencoder, an efficient way to train a VAE whose latent space is a product of\nconstant curvature Riemannian manifolds, where the per-component curvature is\nfixed or learnable. This generalizes the Euclidean VAE to curved latent spaces\nand recovers it when curvatures of all latent space components go to 0.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 17:30:45 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 00:05:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Skopek", "Ondrej", ""], ["Ganea", "Octavian-Eugen", ""], ["B\u00e9cigneul", "Gary", ""]]}, {"id": "1911.08414", "submitter": "Hongqian Qin", "authors": "Hongqian Qin", "title": "Comparison of Deep learning models on time series forecasting : a case\n  study of Dissolved Oxygen Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive prediction performance in the field of\nsequence learning recently. Dissolved oxygen prediction, as a kind of\ntime-series forecasting, is suitable for this technique. Although many\nresearchers have developed hybrid models or variant models based on deep\nlearning techniques, there is no comprehensive and sound comparison among the\ndeep learning models in this field currently. Plus, most previous studies\nfocused on one-step forecasting by using a small data set. As the convenient\naccess to high-frequency data, this paper compares multi-step deep learning\nforecasting by using walk-forward validation. Specifically, we test\nConvolutional Neural Network (CNN), Temporal Convolutional Network (TCN), Long\nShort-Term Memory (LSTM), Gated Recurrent Unit (GRU), Bidirectional Recurrent\nNeural Network (BiRNN) based on the real-time data recorded automatically at a\nfixed observation point in the Yangtze River from 2012 to 2016. By comparing\nthe average accumulated statistical metrics of root mean square error (RMSE),\nmean absolute error (MAE), and coefficient of determination in each time step,\nWe find for multi-step time series forecasting, the average performance of each\ntime step does not decrease linearly. GRU outperforms other models with\nsignificant advantages.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 01:44:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 13:22:47 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Qin", "Hongqian", ""]]}, {"id": "1911.08426", "submitter": "Sannidhan M S", "authors": "Sukhada Chokkadi, Sannidhan M S, Sudeepa K B and Abhir Bhandary", "title": "A Study on various state of the art of the Art Face Recognition System\n  using Deep Learning Techniques", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering, 8(4), July- August 2019, 1590", "doi": "10.30534/ijatcse/2019/84842019", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the existence of very large amount of available data repositories\nand reach to the very advanced system of hardware, systems meant for facial\nidentification ave evolved enormously over the past few decades. Sketch\nrecognition is one of the most important areas that have evolved as an integral\ncomponent adopted by the agencies of law administration in current trends of\nforensic science. Matching of derived sketches to photo images of face is also\na difficult assignment as the considered sketches are produced upon the verbal\nexplanation depicted by the eye witness of the crime scene and may have\nscarcity of sensitive elements that exist in the photograph as one can\naccurately depict due to the natural human error. Substantial amount of the\nnovel research work carried out in this area up late used recognition system\nthrough traditional extraction and classification models. But very recently,\nfew researches work focused on using deep learning techniques to take an\nadvantage of learning models for the feature extraction and classification to\nrule out potential domain challenges. The first part of this review paper\nbasically focuses on deep learning techniques used in face recognition and\nmatching which as improved the accuracy of face recognition technique with\ntraining of huge sets of data. This paper also includes a survey on different\ntechniques used to match composite sketches to human images which includes\ncomponent-based representation approach, automatic composite sketch recognition\ntechnique etc.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 17:48:29 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chokkadi", "Sukhada", ""], ["S", "Sannidhan M", ""], ["B", "Sudeepa K", ""], ["Bhandary", "Abhir", ""]]}, {"id": "1911.08437", "submitter": "Mohammad Hashir", "authors": "Mohammad Hashir and Rapinder Sawhney", "title": "Towards unstructured mortality prediction with free-text clinical notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare data continues to flourish yet a relatively small portion, mostly\nstructured, is being utilized effectively for predicting clinical outcomes. The\nrich subjective information available in unstructured clinical notes can\npossibly facilitate higher discrimination but tends to be under-utilized in\nmortality prediction. This work attempts to assess the gain in performance when\nmultiple notes that have been minimally preprocessed are used as an input for\nprediction. A hierarchical architecture consisting of both convolutional and\nrecurrent layers is used to concurrently model the different notes compiled in\nan individual hospital stay. This approach is evaluated on predicting\nin-hospital mortality on the MIMIC-III dataset. On comparison to approaches\nutilizing structured data, it achieved higher metrics despite requiring less\ncleaning and preprocessing. This demonstrates the potential of unstructured\ndata in enhancing mortality prediction and signifies the need to incorporate\nmore raw unstructured data into current clinical prediction methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:02:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hashir", "Mohammad", ""], ["Sawhney", "Rapinder", ""]]}, {"id": "1911.08444", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Shoichiro Yamaguchi, Shin-ichi Maeda", "title": "MANGA: Method Agnostic Neural-policy Generalization and Adaptation", "comments": "Under Review. Video available at\n  https://drive.google.com/file/d/12GsDq3iQDXEutE-xpzXxqrEfD6dYhKjs/view?usp=sharing\n  Other details will be made available in the author's webpage\n  www.homangabharadhwaj.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we target the problem of transferring policies across multiple\nenvironments with different dynamics parameters and motor noise variations, by\nintroducing a framework that decouples the processes of policy learning and\nsystem identification. Efficiently transferring learned policies to an unknown\nenvironment with changes in dynamics configurations in the presence of motor\nnoise is very important for operating robots in the real world, and our work is\na novel attempt in that direction. We introduce MANGA: Method Agnostic\nNeural-policy Generalization and Adaptation, that trains dynamics conditioned\npolicies and efficiently learns to estimate the dynamics parameters of the\nenvironment given off-policy state-transition rollouts in the environment. Our\nscheme is agnostic to the type of training method used - both reinforcement\nlearning (RL) and imitation learning (IL) strategies can be used. We\ndemonstrate the effectiveness of our approach by experimenting with four\ndifferent MuJoCo agents and comparing against previously proposed transfer\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:10:56 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Yamaguchi", "Shoichiro", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1911.08453", "submitter": "Soroush Nasiriany", "authors": "Soroush Nasiriany, Vitchyr H. Pong, Steven Lin, Sergey Levine", "title": "Planning with Goal-Conditioned Policies", "comments": "In Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning methods can solve temporally extended sequential decision making\nproblems by composing simple behaviors. However, planning requires suitable\nabstractions for the states and transitions, which typically need to be\ndesigned by hand. In contrast, model-free reinforcement learning (RL) can\nacquire behaviors from low-level inputs directly, but often struggles with\ntemporally extended tasks. Can we utilize reinforcement learning to\nautomatically form the abstractions needed for planning, thus obtaining the\nbest of both approaches? We show that goal-conditioned policies learned with RL\ncan be incorporated into planning, so that a planner can focus on which states\nto reach, rather than how those states are reached. However, with complex state\nobservations such as images, not all inputs represent valid states. We\ntherefore also propose using a latent variable model to compactly represent the\nset of valid states for the planner, so that the policies provide an\nabstraction of actions, and the latent variable model provides an abstraction\nof states. We compare our method with planning-based and model-free methods and\nfind that our method significantly outperforms prior work when evaluated on\nimage-based robot navigation and manipulation tasks that require non-greedy,\nmulti-staged behavior.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:25:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Nasiriany", "Soroush", ""], ["Pong", "Vitchyr H.", ""], ["Lin", "Steven", ""], ["Levine", "Sergey", ""]]}, {"id": "1911.08459", "submitter": "Tian Han", "authors": "Dandan Zhu, Tian Han, Linqi Zhou, Xiaokang Yang, Ying Nian Wu", "title": "Deep Unsupervised Clustering with Clustered Generator Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unsupervised clustering which remains one\nof the most fundamental challenges in machine learning and artificial\nintelligence. We propose the clustered generator model for clustering which\ncontains both continuous and discrete latent variables. Discrete latent\nvariables model the cluster label while the continuous ones model variations\nwithin each cluster. The learning of the model proceeds in a unified\nprobabilistic framework and incorporates the unsupervised clustering as an\ninner step without the need for an extra inference model as in existing\nvariational-based models. The latent variables learned serve as both observed\ndata embedding or latent representation for data distribution. Our experiments\nshow that the proposed model can achieve competitive unsupervised clustering\naccuracy and can learn disentangled latent representations to generate\nrealistic samples. In addition, the model can be naturally extended to\nper-pixel unsupervised clustering which remains largely unexplored.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:39:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zhu", "Dandan", ""], ["Han", "Tian", ""], ["Zhou", "Linqi", ""], ["Yang", "Xiaokang", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1911.08530", "submitter": "Hongteng Xu", "authors": "Hongteng Xu", "title": "Gromov-Wasserstein Factorization Models for Graph Clustering", "comments": "The Thirty-Fourth AAAI Conference on Artificial Intelligence\n  (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new nonlinear factorization model for graphs that are with\ntopological structures, and optionally, node attributes. This model is based on\na pseudometric called Gromov-Wasserstein (GW) discrepancy, which compares\ngraphs in a relational way. It estimates observed graphs as GW barycenters\nconstructed by a set of atoms with different weights. By minimizing the GW\ndiscrepancy between each observed graph and its GW barycenter-based estimation,\nwe learn the atoms and their weights associated with the observed graphs. The\nmodel achieves a novel and flexible factorization mechanism under GW\ndiscrepancy, in which both the observed graphs and the learnable atoms can be\nunaligned and with different sizes. We design an effective approximate\nalgorithm for learning this Gromov-Wasserstein factorization (GWF) model,\nunrolling loopy computations as stacked modules and computing gradients with\nbackpropagation. The stacked modules can be with two different architectures,\nwhich correspond to the proximal point algorithm (PPA) and Bregman alternating\ndirection method of multipliers (BADMM), respectively. Experiments show that\nour model obtains encouraging results on clustering graphs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:49:04 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Xu", "Hongteng", ""]]}, {"id": "1911.08532", "submitter": "Ayush Jain", "authors": "Ayush Jain, Alon Orlitsky", "title": "Optimal Robust Learning of Discrete Distributions from Batches", "comments": "Added experiments, minor improvement in results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications, including natural language processing, sensor networks,\ncollaborative filtering, and federated learning, call for estimating discrete\ndistributions from data collected in batches, some of which may be\nuntrustworthy, erroneous, faulty, or even adversarial.\n  Previous estimators for this setting ran in exponential time, and for some\nregimes required a suboptimal number of batches. We provide the first\npolynomial-time estimator that is optimal in the number of batches and achieves\nessentially the best possible estimation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:51:25 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 19:18:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""]]}, {"id": "1911.08538", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren, Bo Liu, Chao Huang, Peng Dai, Liefeng Bo, Jiawei Zhang", "title": "Heterogeneous Deep Graph Infomax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning is to learn universal node representations that\npreserve both node attributes and structural information. The derived node\nrepresentations can be used to serve various downstream tasks, such as node\nclassification and node clustering. When a graph is heterogeneous, the problem\nbecomes more challenging than the homogeneous graph node learning problem.\nInspired by the emerging information theoretic-based learning algorithm, in\nthis paper we propose an unsupervised graph neural network Heterogeneous Deep\nGraph Infomax (HDGI) for heterogeneous graph representation learning. We use\nthe meta-path structure to analyze the connections involving semantics in\nheterogeneous graphs and utilize graph convolution module and semantic-level\nattention mechanism to capture local representations. By maximizing\nlocal-global mutual information, HDGI effectively learns high-level node\nrepresentations that can be utilized in downstream graph-related tasks.\nExperiment results show that HDGI remarkably outperforms state-of-the-art\nunsupervised graph representation learning methods on both classification and\nclustering tasks. By feeding the learned representations into a parametric\nmodel, such as logistic regression, we even achieve comparable performance in\nnode classification tasks when comparing with state-of-the-art supervised\nend-to-end GNN models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:07:45 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 17:12:17 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 03:55:24 GMT"}, {"version": "v4", "created": "Fri, 31 Jul 2020 01:19:32 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 07:34:57 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ren", "Yuxiang", ""], ["Liu", "Bo", ""], ["Huang", "Chao", ""], ["Dai", "Peng", ""], ["Bo", "Liefeng", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1911.08551", "submitter": "Jason Ren", "authors": "Jason Ren, Russell Kunes, Finale Doshi-Velez", "title": "Prediction Focused Topic Models for Electronic Health Records", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. arXiv admin note: substantial text overlap with arXiv:1910.05495", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Record (EHR) data can be represented as discrete counts\nover a high dimensional set of possible procedures, diagnoses, and medications.\nSupervised topic models present an attractive option for incorporating EHR data\nas features into a prediction problem: given a patient's record, we estimate a\nset of latent factors that are predictive of the response variable. However,\nexisting methods for supervised topic modeling struggle to balance prediction\nquality and coherence of the latent factors. We introduce a novel approach, the\nprediction-focused topic model, that uses the supervisory signal to retain only\nfeatures that improve, or do not hinder, prediction performance. By removing\nfeatures with irrelevant signal, the topic model is able to learn\ntask-relevant, interpretable topics. We demonstrate on a EHR dataset and a\nmovie review dataset that compared to existing approaches, prediction-focused\ntopic models are able to learn much more coherent topics while maintaining\ncompetitive predictions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:19:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ren", "Jason", ""], ["Kunes", "Russell", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1911.08556", "submitter": "Komal Teru", "authors": "Komal K. Teru and Aishik Chakraborty", "title": "Towards Reducing Bias in Gender Classification", "comments": "arXiv admin note: text overlap with arXiv:1706.00409 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Societal bias towards certain communities is a big problem that affects a lot\nof machine learning systems. This work aims at addressing the racial bias\npresent in many modern gender recognition systems. We learn race invariant\nrepresentations of human faces with an adversarially trained autoencoder model.\nWe show that such representations help us achieve less biased performance in\ngender classification. We use variance in classification accuracy across\ndifferent races as a surrogate for the racial bias of the model and achieve a\ndrop of over 40% in variance with race invariant representations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:21:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Teru", "Komal K.", ""], ["Chakraborty", "Aishik", ""]]}, {"id": "1911.08567", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Lazaros Polymenakos, Spyros Matsoukas", "title": "Multi-domain Conversation Quality Evaluation via User Satisfaction\n  Estimation", "comments": "The 3rd Conversational AI workshop: Today's practice and tomorrow's\n  potential at NeurIPS 2019. arXiv admin note: substantial text overlap with\n  arXiv:1908.07064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and employ annotation\nschemes with limited generalizability to conversations spanning multiple\ndomains. To address these gaps, we created a new Response Quality annotation\nscheme, introduced five new domain-independent feature sets and experimented\nwith six machine learning models to estimate User Satisfaction at both turn and\ndialogue level.\n  Response Quality ratings achieved significantly high correlation (0.76) with\nexplicit turn-level user ratings. Using the new feature sets we introduced,\nGradient Boosting Regression model achieved best (rating [1-5]) prediction\nperformance on 26 seen (linear correlation ~0.79) and one new multi-turn domain\n(linear correlation 0.67). We observed a 16% relative improvement (68% -> 79%)\nin binary (\"satisfactory/dissatisfactory\") class prediction accuracy of a\ndomain-independent dialogue-level satisfaction estimation model after including\npredicted turn-level satisfaction ratings as features.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:11:47 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Polymenakos", "Lazaros", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1911.08577", "submitter": "Vasco Portilheiro", "authors": "Vasco Portilheiro", "title": "Representation Learning with Multisets", "comments": "Under review as a conference paper at ICLR 2020. Preliminary version\n  accepted to the NeurIPS 2019 workshop on Sets and Partitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning permutation invariant representations that\ncan capture \"flexible\" notions of containment. We formalize this problem via a\nmeasure theoretic definition of multisets, and obtain a theoretically-motivated\nlearning model. We propose training this model on a novel task: predicting the\nsize of the symmetric difference (or intersection) between pairs of multisets.\nWe demonstrate that our model not only performs very well on predicting\ncontainment relations (and more effectively predicts the sizes of symmetric\ndifferences and intersections than DeepSets-based approaches with unconstrained\nobject representations), but that it also learns meaningful representations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:50:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Portilheiro", "Vasco", ""]]}, {"id": "1911.08581", "submitter": "Yiheng Han", "authors": "Yiheng Han, Wang Zhao, Jia Pan, Zipeng Ye, Ran Yi, Yong-Jin Liu", "title": "A Configuration-Space Decomposition Scheme for Learning-based Collision\n  Checking", "comments": "7 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning for robots of high degrees-of-freedom (DOFs) is an important\nproblem in robotics with sampling-based methods in configuration space C as one\npopular solution. Recently, machine learning methods have been introduced into\nsampling-based motion planning methods, which train a classifier to distinguish\ncollision free subspace from in-collision subspace in C. In this paper, we\npropose a novel configuration space decomposition method and show two nice\nproperties resulted from this decomposition. Using these two properties, we\nbuild a composite classifier that works compatibly with previous machine\nlearning methods by using them as the elementary classifiers. Experimental\nresults are presented, showing that our composite classifier outperforms\nstate-of-the-art single classifier methods by a large margin. A real\napplication of motion planning in a multi-robot system in plant phenotyping\nusing three UR5 robotic arms is also presented.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 11:48:16 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Han", "Yiheng", ""], ["Zhao", "Wang", ""], ["Pan", "Jia", ""], ["Ye", "Zipeng", ""], ["Yi", "Ran", ""], ["Liu", "Yong-Jin", ""]]}, {"id": "1911.08585", "submitter": "Thomas Mesnard", "authors": "Thomas Mesnard, Gaetan Vignoud, Joao Sacramento, Walter Senn, Yoshua\n  Bengio", "title": "Ghost Units Yield Biologically Plausible Backprop in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, deep learning has transformed artificial intelligence\nresearch and led to impressive performance in various difficult tasks. However,\nit is still unclear how the brain can perform credit assignment across many\nareas as efficiently as backpropagation does in deep neural networks. In this\npaper, we introduce a model that relies on a new role for a neuronal inhibitory\nmachinery, referred to as ghost units. By cancelling the feedback coming from\nthe upper layer when no target signal is provided to the top layer, the ghost\nunits enables the network to backpropagate errors and do efficient credit\nassignment in deep structures. While considering one-compartment neurons and\nrequiring very few biological assumptions, it is able to approximate the error\ngradient and achieve good performance on classification tasks. Error\nbackpropagation occurs through the recurrent dynamics of the network and thanks\nto biologically plausible local learning rules. In particular, it does not\nrequire separate feedforward and feedback circuits. Different mechanisms for\ncancelling the feedback were studied, ranging from complete duplication of the\nconnectivity by long term processes to online replication of the feedback\nactivity. This reduced system combines the essential elements to have a working\nbiologically abstracted analogue of backpropagation with a simple formulation\nand proofs of the associated results. Therefore, this model is a step towards\nunderstanding how learning and memory are implemented in cortical multilayer\nstructures, but it also raises interesting perspectives for neuromorphic\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:47:00 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mesnard", "Thomas", ""], ["Vignoud", "Gaetan", ""], ["Sacramento", "Joao", ""], ["Senn", "Walter", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1911.08587", "submitter": "Mee Seong Im", "authors": "Venkat R. Dasari, Mee Seong Im, Lubjana Beshaj", "title": "Solving machine learning optimization problems using quantum computers", "comments": "5 pages, 3 figures. Submitted to Proc. SPIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical optimization algorithms in machine learning often take a long time\nto compute when applied to a multi-dimensional problem and require a huge\namount of CPU and GPU resource. Quantum parallelism has a potential to speed up\nmachine learning algorithms. We describe a generic mathematical model to\nleverage quantum parallelism to speed-up machine learning algorithms. We also\napply quantum machine learning and quantum parallelism applied to a\n$3$-dimensional image that vary with time.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 17:36:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dasari", "Venkat R.", ""], ["Im", "Mee Seong", ""], ["Beshaj", "Lubjana", ""]]}, {"id": "1911.08603", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "Forbidden knowledge in machine learning -- Reflections on the limits of\n  research and publication", "comments": null, "journal-ref": null, "doi": "10.1007/s00146-020-01045-4", "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain research strands can yield \"forbidden knowledge\". This term refers to\nknowledge that is considered too sensitive, dangerous or taboo to be produced\nor shared. Discourses about such publication restrictions are already\nentrenched in scientific fields like IT security, synthetic biology or nuclear\nphysics research. This paper makes the case for transferring this discourse to\nmachine learning research. Some machine learning applications can very easily\nbe misused and unfold harmful consequences, for instance with regard to\ngenerative video or text synthesis, personality analysis, behavior\nmanipulation, software vulnerability detection and the like. Up to now, the\nmachine learning research community embraces the idea of open access. However,\nthis is opposed to precautionary efforts to prevent the malicious use of\nmachine learning applications. Information about or from such applications may,\nif improperly disclosed, cause harm to people, organizations or whole\nsocieties. Hence, the goal of this work is to outline norms that can help to\ndecide whether and when the dissemination of such information should be\nprevented. It proposes review parameters for the machine learning community to\nestablish an ethical framework on how to deal with forbidden knowledge and\ndual-use applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:43:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1911.08610", "submitter": "Borislav Mavrin", "authors": "Borislav Mavrin, Daniel Graves, Alan Chan", "title": "Efficient decorrelation of features using Gramian in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning good representations is a long standing problem in reinforcement\nlearning (RL). One of the conventional ways to achieve this goal in the\nsupervised setting is through regularization of the parameters. Extending some\nof these ideas to the RL setting has not yielded similar improvements in\nlearning. In this paper, we develop an online regularization framework for\ndecorrelating features in RL and demonstrate its utility in several test\nenvironments. We prove that the proposed algorithm converges in the linear\nfunction approximation setting and does not change the main objective of\nmaximizing cumulative reward. We demonstrate how to scale the approach to deep\nRL using the Gramian of the features achieving linear computational complexity\nin the number of features and squared complexity in size of the batch. We\nconduct an extensive empirical study of the new approach on Atari 2600 games\nand show a significant improvement in sample efficiency in 40 out of 49 games.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:10:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mavrin", "Borislav", ""], ["Graves", "Daniel", ""], ["Chan", "Alan", ""]]}, {"id": "1911.08623", "submitter": "Guansong Pang", "authors": "Guansong Pang, Chunhua Shen, Anton van den Hengel", "title": "Deep Anomaly Detection with Deviation Networks", "comments": "10 Pages, Published in KDD19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has been applied to successfully address many data\nmining problems, relatively limited work has been done on deep learning for\nanomaly detection. Existing deep anomaly detection methods, which focus on\nlearning new feature representations to enable downstream anomaly detection\nmethods, perform indirect optimization of anomaly scores, leading to\ndata-inefficient learning and suboptimal anomaly scoring. Also, they are\ntypically designed as unsupervised learning due to the lack of large-scale\nlabeled anomaly data. As a result, they are difficult to leverage prior\nknowledge (e.g., a few labeled anomalies) when such information is available as\nin many real-world anomaly detection applications.\n  This paper introduces a novel anomaly detection framework and its\ninstantiation to address these problems. Instead of representation learning,\nour method fulfills an end-to-end learning of anomaly scores by a neural\ndeviation learning, in which we leverage a few (e.g., multiple to dozens)\nlabeled anomalies and a prior probability to enforce statistically significant\ndeviations of the anomaly scores of anomalies from that of normal data objects\nin the upper tail. Extensive results show that our method can be trained\nsubstantially more data-efficiently and achieves significantly better anomaly\nscoring than state-of-the-art competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 23:05:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Pang", "Guansong", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1911.08635", "submitter": "Minh Le", "authors": "Minh Le", "title": "Robust Deep Neural Networks Inspired by Fuzzy Logic", "comments": "7 pages, 4 figures, source code:\n  https://bitbucket.org/minhlab/newlogic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep neural networks have achieved impressive performance and become the\nde-facto standard in many tasks. However, troubling phenomena such as\nadversarial and fooling examples suggest that the generalization they make is\nflawed. I argue that among the roots of the phenomena are two geometric\nproperties of common deep learning architectures: their distributed nature and\nthe connectedness of their decision regions. As a remedy, I propose new\narchitectures inspired by fuzzy logic that combine several alternative design\nelements. Through experiments on MNIST and CIFAR-10, the new models are shown\nto be more local, better at rejecting noise samples, and more robust against\nadversarial examples. Ablation analyses reveal behaviors on adversarial\nexamples that cannot be explained by the linearity hypothesis but are\nconsistent with the hypothesis that logic-inspired traits create more robust\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:12:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 09:01:55 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 22:29:40 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Le", "Minh", ""]]}, {"id": "1911.08644", "submitter": "Hiromu Yakura", "authors": "Hiromu Yakura, Youhei Akimoto, Jun Sakuma", "title": "Generate (non-software) Bugs to Fool Classifiers", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial attacks intended to confound deep learning models, most\nstudies have focused on limiting the magnitude of the modification so that\nhumans do not notice the attack. On the other hand, during an attack against\nautonomous cars, for example, most drivers would not find it strange if a small\ninsect image were placed on a stop sign, or they may overlook it. In this\npaper, we present a systematic approach to generate natural adversarial\nexamples against classification models by employing such natural-appearing\nperturbations that imitate a certain object or signal. We first show the\nfeasibility of this approach in an attack against an image classifier by\nemploying generative adversarial networks that produce image patches that have\nthe appearance of a natural object to fool the target model. We also introduce\nan algorithm to optimize placement of the perturbation in accordance with the\ninput image, which makes the generation of adversarial examples fast and likely\nto succeed. Moreover, we experimentally show that the proposed approach can be\nextended to the audio domain, for example, to generate perturbations that sound\nlike the chirping of birds to fool a speech classifier.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:43:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Yakura", "Hiromu", ""], ["Akimoto", "Youhei", ""], ["Sakuma", "Jun", ""]]}, {"id": "1911.08654", "submitter": "Phillip Pope", "authors": "Phillip Pope, Yogesh Balaji, Soheil Feizi", "title": "Adversarial Robustness of Flow-Based Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models leverage invertible generator functions to fit a\ndistribution to the training data using maximum likelihood. Despite their use\nin several application domains, robustness of these models to adversarial\nattacks has hardly been explored. In this paper, we study adversarial\nrobustness of flow-based generative models both theoretically (for some simple\nmodels) and empirically (for more complex ones). First, we consider a linear\nflow-based generative model and compute optimal sample-specific and universal\nadversarial perturbations that maximally decrease the likelihood scores. Using\nthis result, we study the robustness of the well-known adversarial training\nprocedure, where we characterize the fundamental trade-off between model\nrobustness and accuracy. Next, we empirically study the robustness of two\nprominent deep, non-linear, flow-based generative models, namely GLOW and\nRealNVP. We design two types of adversarial attacks; one that minimizes the\nlikelihood scores of in-distribution samples, while the other that maximizes\nthe likelihood scores of out-of-distribution ones. We find that GLOW and\nRealNVP are extremely sensitive to both types of attacks. Finally, using a\nhybrid adversarial training procedure, we significantly boost the robustness of\nthese generative models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 01:16:57 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Pope", "Phillip", ""], ["Balaji", "Yogesh", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.08655", "submitter": "Rui Wang", "authors": "Rui Wang, Karthik Kashinath, Mustafa Mustafa, Adrian Albert, Rose Yu", "title": "Towards Physics-informed Deep Learning for Turbulent Flow Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has shown tremendous success in a wide range of domains,\nit remains a grand challenge to incorporate physical principles in a systematic\nmanner to the design, training, and inference of such models. In this paper, we\naim to predict turbulent flow by learning its highly nonlinear dynamics from\nspatiotemporal velocity fields of large-scale fluid flow simulations of\nrelevance to turbulence modeling and climate modeling. We adopt a hybrid\napproach by marrying two well-established turbulent flow simulation techniques\nwith deep learning. Specifically, we introduce trainable spectral filters in a\ncoupled model of Reynolds-averaged Navier-Stokes (RANS) and Large Eddy\nSimulation (LES), followed by a specialized U-net for prediction. Our approach,\nwhich we call turbulent-Flow Net (TF-Net), is grounded in a principled physics\nmodel, yet offers the flexibility of learned representations. We compare our\nmodel, TF-Net, with state-of-the-art baselines and observe significant\nreductions in error for predictions 60 frames ahead. Most importantly, our\nmethod predicts physical fields that obey desirable physical characteristics,\nsuch as conservation of mass, whilst faithfully emulating the turbulent kinetic\nenergy field and spectrum, which are critical for accurate prediction of\nturbulent flows.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 01:16:57 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 19:50:00 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 16:48:51 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 22:11:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wang", "Rui", ""], ["Kashinath", "Karthik", ""], ["Mustafa", "Mustafa", ""], ["Albert", "Adrian", ""], ["Yu", "Rose", ""]]}, {"id": "1911.08662", "submitter": "Kenichiro McAlinn", "authors": "K\\=osaku Takanashi and Kenichiro McAlinn", "title": "Predictions with dynamic Bayesian predictive synthesis are exact minimax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the combination of multiple predictive distributions for time\nseries data when all forecasts are misspecified. We show that a specific\ndynamic form of Bayesian predictive synthesis -- a general and coherent\nBayesian framework for ensemble methods -- produces exact minimax predictive\ndensities with regard to Kullback-Leibler loss, providing theoretical support\nfor finite sample predictive performance over existing ensemble methods. A\nsimulation study that highlights this theoretical result is presented, showing\nthat dynamic Bayesian predictive synthesis is superior to other ensemble\nmethods using multiple metrics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 01:46:24 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 05:35:43 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 05:16:37 GMT"}, {"version": "v4", "created": "Sat, 3 Jul 2021 15:13:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Takanashi", "K\u014dsaku", ""], ["McAlinn", "Kenichiro", ""]]}, {"id": "1911.08666", "submitter": "Vibhavari Dasagi", "authors": "Vibhavari Dasagi, Robert Lee, Jake Bruce and J\\\"urgen Leitner", "title": "Evaluating task-agnostic exploration for fixed-batch learning of\n  arbitrary future tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been shown to solve challenging tasks where\nlarge amounts of training experience is available, usually obtained online\nwhile learning the task. Robotics is a significant potential application domain\nfor many of these algorithms, but generating robot experience in the real world\nis expensive, especially when each task requires a lengthy online training\nprocedure. Off-policy algorithms can in principle learn arbitrary tasks from a\ndiverse enough fixed dataset. In this work, we evaluate popular exploration\nmethods by generating robotics datasets for the purpose of learning to solve\ntasks completely offline without any further interaction in the real world. We\npresent results on three popular continuous control tasks in simulation, as\nwell as continuous control of a high-dimensional real robot arm. Code\ndocumenting all algorithms, experiments, and hyper-parameters is available at\nhttps://github.com/qutrobotlearning/batchlearning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:03:35 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dasagi", "Vibhavari", ""], ["Lee", "Robert", ""], ["Bruce", "Jake", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1911.08678", "submitter": "Zhao Zhang", "authors": "Huan Zhang, Zhao Zhang, Mingbo Zhao, Qiaolin Ye, Min Zhang and Meng\n  Wang", "title": "Robust Triple-Matrix-Recovery-Based Auto-Weighted Label Propagation for\n  Classification", "comments": "Accepted by IEEE TNNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph-based semi-supervised label propagation algorithm has delivered\nimpressive classification results. However, the estimated soft labels typically\ncontain mixed signs and noise, which cause inaccurate predictions due to the\nlack of suitable constraints. Moreover, available methods typically calculate\nthe weights and estimate the labels in the original input space, which\ntypically contains noise and corruption. Thus, the en-coded similarities and\nmanifold smoothness may be inaccurate for label estimation. In this paper, we\npresent effective schemes for resolving these issues and propose a novel and\nrobust semi-supervised classification algorithm, namely, the\ntri-ple-matrix-recovery-based robust auto-weighted label propa-gation framework\n(ALP-TMR). Our ALP-TMR introduces a triple matrix recovery mechanism to remove\nnoise or mixed signs from the estimated soft labels and improve the robustness\nto noise and outliers in the steps of assigning weights and pre-dicting the\nlabels simultaneously. Our method can jointly re-cover the underlying clean\ndata, clean labels and clean weighting spaces by decomposing the original data,\npredicted soft labels or weights into a clean part plus an error part by\nfitting noise. In addition, ALP-TMR integrates the au-to-weighting process by\nminimizing reconstruction errors over the recovered clean data and clean soft\nlabels, which can en-code the weights more accurately to improve both data\nrep-resentation and classification. By classifying samples in the recovered\nclean label and weight spaces, one can potentially improve the label prediction\nresults. The results of extensive experiments demonstrated the satisfactory\nperformance of our ALP-TMR.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:10:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Huan", ""], ["Zhang", "Zhao", ""], ["Zhao", "Mingbo", ""], ["Ye", "Qiaolin", ""], ["Zhang", "Min", ""], ["Wang", "Meng", ""]]}, {"id": "1911.08684", "submitter": "Kaiqun Fu", "authors": "Kaiqun Fu, Taoran Ji, Liang Zhao, Chang-Tien Lu", "title": "TITAN: A Spatiotemporal Feature Learning Framework for Traffic Incident\n  Duration Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3347146.3359381", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical incident stages identification and reasonable prediction of traffic\nincident duration are essential in traffic incident management. In this paper,\nwe propose a traffic incident duration prediction model that simultaneously\npredicts the impact of the traffic incidents and identifies the critical groups\nof temporal features via a multi-task learning framework. First, we formulate a\nsparsity optimization problem that extracts low-level temporal features based\non traffic speed readings and then generalizes higher level features as phases\nof traffic incidents. Second, we propose novel constraints on feature\nsimilarity exploiting prior knowledge about the spatial connectivity of the\nroad network to predict the incident duration. The proposed problem is\nchallenging to solve due to the orthogonality constraints, non-convexity\nobjective, and non-smoothness penalties. We develop an algorithm based on the\nalternating direction method of multipliers (ADMM) framework to solve the\nproposed formulation. Extensive experiments and comparisons to other models on\nreal-world traffic data and traffic incident records justify the efficacy of\nour model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:32:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Fu", "Kaiqun", ""], ["Ji", "Taoran", ""], ["Zhao", "Liang", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1911.08689", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Max Simchowitz, Aleksandrs Slivkins, Wen Sun", "title": "Corruption robust exploration in episodic reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of multi-stage episodic reinforcement learning under\nadversarial corruptions in both the rewards and the transition probabilities of\nthe underlying system extending recent results for the special case of\nstochastic bandits. We provide a framework which modifies the aggressive\nexploration enjoyed by existing reinforcement learning approaches based on\n\"optimism in the face of uncertainty\", by complementing them with principles\nfrom \"action elimination\". Importantly, our framework circumvents the major\nchallenges posed by naively applying action elimination in the RL setting, as\nformalized by a lower bound we demonstrate. Our framework yields efficient\nalgorithms which (a) attain near-optimal regret in the absence of corruptions\nand (b) adapt to unknown levels corruption, enjoying regret guarantees which\ndegrade gracefully in the total corruption encountered. To showcase the\ngenerality of our approach, we derive results for both tabular settings (where\nstates and actions are finite) as well as linear-function-approximation\nsettings (where the dynamics and rewards admit a linear underlying\nrepresentation). Notably, our work provides the first sublinear regret\nguarantee which accommodates any deviation from purely i.i.d. transitions in\nthe bandit-feedback model for episodic reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:49:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 21:20:40 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Simchowitz", "Max", ""], ["Slivkins", "Aleksandrs", ""], ["Sun", "Wen", ""]]}, {"id": "1911.08696", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Bo Han, Gang Niu, Tongliang Liu, Masashi Sugiyama", "title": "Where is the Bottleneck of Adversarial Learning with Unlabeled Data?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are incredibly brittle due to adversarial\nexamples. To robustify DNNs, adversarial training was proposed, which requires\nlarge-scale but well-labeled data. However, it is quite expensive to annotate\nlarge-scale data well. To compensate for this shortage, several seminal works\nare utilizing large-scale unlabeled data. In this paper, we observe that\nseminal works do not perform well, since the quality of pseudo labels on\nunlabeled data is quite poor, especially when the amount of unlabeled data is\nsignificantly larger than that of labeled data. We believe that the quality of\npseudo labels is the bottleneck of adversarial learning with unlabeled data. To\ntackle this bottleneck, we leverage deep co-training, which trains two deep\nnetworks and encourages two networks diverged by exploiting peer's adversarial\nexamples. Based on deep co-training, we propose robust co-training (RCT) for\nadversarial learning with unlabeled data. We conduct comprehensive experiments\non CIFAR-10 and SVHN datasets. Empirical results demonstrate that our RCT can\nsignificantly outperform baselines (e.g., robust self-training (RST)) in both\nstandard test accuracy and robust test accuracy w.r.t. different datasets,\ndifferent network structures, and different types of adversarial training.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:13:46 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Liu", "Tongliang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1911.08701", "submitter": "Tom Blau", "authors": "Tom Blau, Lionel Ott, Fabio Ramos", "title": "Bayesian Curiosity for Efficient Exploration in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing exploration and exploitation is a fundamental part of reinforcement\nlearning, yet most state-of-the-art algorithms use a naive exploration protocol\nlike $\\epsilon$-greedy. This contributes to the problem of high sample\ncomplexity, as the algorithm wastes effort by repeatedly visiting parts of the\nstate space that have already been explored. We introduce a novel method based\non Bayesian linear regression and latent space embedding to generate an\nintrinsic reward signal that encourages the learning agent to seek out\nunexplored parts of the state space. This method is computationally efficient,\nsimple to implement, and can extend any state-of-the-art reinforcement learning\nalgorithm. We evaluate the method on a range of algorithms and challenging\ncontrol tasks, on both simulated and physical robots, demonstrating how the\nproposed method can significantly improve sample complexity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:30:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Blau", "Tom", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "1911.08703", "submitter": "Kaito Shimamura", "authors": "Kaito Shimamura, Shuichi Kawano", "title": "Bayesian sparse convex clustering via global-local shrinkage priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse convex clustering is to cluster observations and conduct variable\nselection simultaneously in the framework of convex clustering. Although a\nweighted $L_1$ norm is usually employed for the regularization term in sparse\nconvex clustering, its use increases the dependence on the data and reduces the\nestimation accuracy if the sample size is not sufficient. To tackle these\nproblems, this paper proposes a Bayesian sparse convex clustering method based\non the ideas of Bayesian lasso and global-local shrinkage priors. We introduce\nGibbs sampling algorithms for our method using scale mixtures of normal\ndistributions. The effectiveness of the proposed methods is shown in simulation\nstudies and a real data analysis.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:41:05 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 17:25:18 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Shimamura", "Kaito", ""], ["Kawano", "Shuichi", ""]]}, {"id": "1911.08709", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Hongteng Xu, Zhe Gan, Bai Li, Guoyin Wang, Liqun Chen,\n  Qian Yang, Wenqi Wang and Lawrence Carin", "title": "Graph-Driven Generative Models for Heterogeneous Multi-Task Learning", "comments": "Accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel graph-driven generative model, that unifies multiple\nheterogeneous learning tasks into the same framework. The proposed model is\nbased on the fact that heterogeneous learning tasks, which correspond to\ndifferent generative processes, often rely on data with a shared graph\nstructure. Accordingly, our model combines a graph convolutional network (GCN)\nwith multiple variational autoencoders, thus embedding the nodes of the graph\ni.e., samples for the tasks) in a uniform manner while specializing their\norganization and usage to different tasks. With a focus on healthcare\napplications (tasks), including clinical topic modeling, procedure\nrecommendation and admission-type prediction, we demonstrate that our method\nsuccessfully leverages information across different tasks, boosting performance\nin all tasks and outperforming existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:14:35 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Wang", "Wenlin", ""], ["Xu", "Hongteng", ""], ["Gan", "Zhe", ""], ["Li", "Bai", ""], ["Wang", "Guoyin", ""], ["Chen", "Liqun", ""], ["Yang", "Qian", ""], ["Wang", "Wenqi", ""], ["Carin", "Lawrence", ""]]}, {"id": "1911.08717", "submitter": "Junliang Guo", "authors": "Junliang Guo, Xu Tan, Linli Xu, Tao Qin, Enhong Chen, Tie-Yan Liu", "title": "Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine\n  Translation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive translation (NAT) models remove the dependence on previous\ntarget tokens and generate all target tokens in parallel, resulting in\nsignificant inference speedup but at the cost of inferior translation accuracy\ncompared to autoregressive translation (AT) models. Considering that AT models\nhave higher accuracy and are easier to train than NAT models, and both of them\nshare the same model configurations, a natural idea to improve the accuracy of\nNAT models is to transfer a well-trained AT model to an NAT model through\nfine-tuning. However, since AT and NAT models differ greatly in training\nstrategy, straightforward fine-tuning does not work well. In this work, we\nintroduce curriculum learning into fine-tuning for NAT. Specifically, we design\na curriculum in the fine-tuning process to progressively switch the training\nfrom autoregressive generation to non-autoregressive generation. Experiments on\nfour benchmark translation datasets show that the proposed method achieves good\nimprovement (more than $1$ BLEU score) over previous NAT baselines in terms of\ntranslation accuracy, and greatly speed up (more than $10$ times) the inference\nprocess over AT baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:48:31 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:43:45 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Guo", "Junliang", ""], ["Tan", "Xu", ""], ["Xu", "Linli", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.08723", "submitter": "Lirong He", "authors": "Lirong He, Ziyi Guo, Kaizhu Huang, Zenglin Xu", "title": "Deep Minimax Probability Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks enjoy a powerful representation and have proven\neffective in a number of applications. However, recent advances show that deep\nneural networks are vulnerable to adversarial attacks incurred by the so-called\nadversarial examples. Although the adversarial example is only slightly\ndifferent from the input sample, the neural network classifies it as the wrong\nclass. In order to alleviate this problem, we propose the Deep Minimax\nProbability Machine (DeepMPM), which applies MPM to deep neural networks in an\nend-to-end fashion. In a worst-case scenario, MPM tries to minimize an upper\nbound of misclassification probabilities, considering the global information\n(i.e., mean and covariance information of each class). DeepMPM can be more\nrobust since it learns the worst-case bound on the probability of\nmisclassification of future data. Experiments on two real-world datasets can\nachieve comparable classification performance with CNN, while can be more\nrobust on adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:11:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["He", "Lirong", ""], ["Guo", "Ziyi", ""], ["Huang", "Kaizhu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.08727", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Zhenheng Tang, Qiang Wang, Kaiyong Zhao, Xiaowen Chu", "title": "Layer-wise Adaptive Gradient Sparsification for Distributed Deep\n  Learning with Convergence Guarantees", "comments": "8 pages. To appear at ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the long training time of large deep neural network (DNN) models,\ndistributed synchronous stochastic gradient descent (S-SGD) is commonly used on\na cluster of workers. However, the speedup brought by multiple workers is\nlimited by the communication overhead. Two approaches, namely pipelining and\ngradient sparsification, have been separately proposed to alleviate the impact\nof communication overheads. Yet, the gradient sparsification methods can only\ninitiate the communication after the backpropagation, and hence miss the\npipelining opportunity. In this paper, we propose a new distributed\noptimization method named LAGS-SGD, which combines S-SGD with a novel\nlayer-wise adaptive gradient sparsification (LAGS) scheme. In LAGS-SGD, every\nworker selects a small set of \"significant\" gradients from each layer\nindependently whose size can be adaptive to the communication-to-computation\nratio of that layer. The layer-wise nature of LAGS-SGD opens the opportunity of\noverlapping communications with computations, while the adaptive nature of\nLAGS-SGD makes it flexible to control the communication time. We prove that\nLAGS-SGD has convergence guarantees and it has the same order of convergence\nrate as vanilla S-SGD under a weak analytical assumption. Extensive experiments\nare conducted to verify the analytical assumption and the convergence\nperformance of LAGS-SGD. Experimental results on a 16-GPU cluster show that\nLAGS-SGD outperforms the original S-SGD and existing sparsified S-SGD without\nlosing obvious model accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:24:50 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 06:46:41 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:22:12 GMT"}, {"version": "v4", "created": "Mon, 2 Mar 2020 01:54:25 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Shi", "Shaohuai", ""], ["Tang", "Zhenheng", ""], ["Wang", "Qiang", ""], ["Zhao", "Kaiyong", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1911.08729", "submitter": "Stefan Lessmann", "authors": "Robin M. Gubela, Stefan Lessmann, Szymon Jaroszewicz", "title": "Response Transformation and Profit Decomposition for Revenue Uplift\n  Modeling", "comments": "53 pages including online appendix", "journal-ref": "European Journal of Operational Research 2019", "doi": "10.1016/j.ejor.2019.11.030", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift models support decision-making in marketing campaign planning.\nEstimating the causal effect of a marketing treatment, an uplift model\nfacilitates targeting communication to responsive customers and efficient\nallocation of marketing budgets. Research into uplift models focuses on\nconversion models to maximize incremental sales. The paper introduces uplift\nmodeling strategies for maximizing incremental revenues. If customers differ in\ntheir spending behavior, revenue maximization is a more plausible business\nobjective compared to maximizing conversions. The proposed methodology entails\na transformation of the prediction target, customer-level revenues, that\nfacilitates implementing a causal uplift model using standard machine learning\nalgorithms. The distribution of campaign revenues is typically zero-inflated\nbecause of many non-buyers. Remedies to this modeling challenge are\nincorporated in the proposed revenue uplift strategies in the form of two-stage\nmodels. Empirical experiments using real-world e-commerce data confirm the\nmerits of the proposed revenue uplift strategy over relevant alternatives\nincluding uplift models for conver-sion and recently developed causal machine\nlearning algorithms. To quantify the degree to which improved targeting\ndecisions raise return on marketing, the paper develops a decomposition of\ncampaign profit. Applying the decomposition to a digital coupon targeting\ncampaign, the paper provides evidence that revenue uplift modeling, as well as\ncausal machine learning, can improve cam-paign profit substantially.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:36:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gubela", "Robin M.", ""], ["Lessmann", "Stefan", ""], ["Jaroszewicz", "Szymon", ""]]}, {"id": "1911.08731", "submitter": "Shiori Sagawa", "authors": "Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, Percy Liang", "title": "Distributionally Robust Neural Networks for Group Shifts: On the\n  Importance of Regularization for Worst-Case Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized neural networks can be highly accurate on average on an\ni.i.d. test set yet consistently fail on atypical groups of the data (e.g., by\nlearning spurious correlations that hold on average but not in such groups).\nDistributionally robust optimization (DRO) allows us to learn models that\ninstead minimize the worst-case training loss over a set of pre-defined groups.\nHowever, we find that naively applying group DRO to overparameterized neural\nnetworks fails: these models can perfectly fit the training data, and any model\nwith vanishing average training loss also already has vanishing worst-case\ntraining loss. Instead, the poor worst-case performance arises from poor\ngeneralization on some groups. By coupling group DRO models with increased\nregularization---a stronger-than-typical L2 penalty or early stopping---we\nachieve substantially higher worst-group accuracies, with 10-40 percentage\npoint improvements on a natural language inference task and two image tasks,\nwhile maintaining high average accuracies. Our results suggest that\nregularization is important for worst-group generalization in the\noverparameterized regime, even if it is not needed for average generalization.\nFinally, we introduce a stochastic optimization algorithm, with convergence\nguarantees, to efficiently train group DRO models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 06:43:41 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 05:40:29 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Sagawa", "Shiori", ""], ["Koh", "Pang Wei", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1911.08744", "submitter": "Amir Farzad", "authors": "Amir Farzad and T. Aaron Gulliver", "title": "Log Message Anomaly Detection and Classification Using Auto-B/LSTM and\n  Auto-GRU", "comments": "18 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log messages are now widely used in software systems. They are important for\nclassification as millions of logs are generated each day. Most logs are\nunstructured which makes classification a challenge. In this paper, Deep\nLearning (DL) methods called Auto-LSTM, Auto-BLSTM and Auto-GRU are developed\nfor anomaly detection and log classification. These models are used to convert\nunstructured log data to extracted features which is suitable for\nclassification algorithms. They are evaluated using four data sets, namely BGL,\nOpenstack, Thunderbird and IMDB. The first three are popular log data sets\nwhile the fourth is a movie review data set which is used for sentiment\nclassification. The results obtained show that Auto-LSTM, Auto-BLSTM and\nAuto-GRU perform better than other well-known algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:18:38 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 02:01:36 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Farzad", "Amir", ""], ["Gulliver", "T. Aaron", ""]]}, {"id": "1911.08747", "submitter": "Zhijian Ou", "authors": "Keyu An, Hongyu Xiang, Zhijian Ou", "title": "CAT: CRF-based ASR Toolkit", "comments": "Code released at: https://github.com/thu-spmi/cat", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new open source toolkit for automatic speech\nrecognition (ASR), named CAT (CRF-based ASR Toolkit). A key feature of CAT is\ndiscriminative training in the framework of conditional random field (CRF),\nparticularly with connectionist temporal classification (CTC) inspired state\ntopology. CAT contains a full-fledged implementation of CTC-CRF and provides a\ncomplete workflow for CRF-based end-to-end speech recognition. Evaluation\nresults on Chinese and English benchmarks such as Switchboard and Aishell show\nthat CAT obtains the state-of-the-art results among existing end-to-end models\nwith less parameters, and is competitive compared with the hybrid DNN-HMM\nmodels. Towards flexibility, we show that i-vector based speaker-adapted\nrecognition and latency control mechanism can be explored easily and\neffectively in CAT. We hope CAT, especially the CRF-based framework and\nsoftware, will be of broad interest to the community, and can be further\nexplored and improved.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:33:21 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["An", "Keyu", ""], ["Xiang", "Hongyu", ""], ["Ou", "Zhijian", ""]]}, {"id": "1911.08756", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Hierarchical Multiple-Instance Data Classification with Costly Features", "comments": "RL4RealLife @ ICML2021; code available at\n  https://github.com/jaromiru/rcwcf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of Classification with Costly Features (CwCF) that\nworks with samples of fixed dimensions to trees of varying depth and breadth\n(similar to a JSON/XML file). In this setting, the sample is a tree - sets of\nsets of features. Individually for each sample, the task is to sequentially\nselect informative features that help the classification. Each feature has a\nreal-valued cost, and the objective is to maximize accuracy while minimizing\nthe total cost. The process is modeled as an MDP where the states represent the\nacquired features, and the actions select unknown features. We present a\nspecialized neural network architecture trained through deep reinforcement\nlearning that naturally fits the data and directly selects features in the\ntree. We demonstrate our method in seven datasets and compare it to two\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:15:09 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 13:20:38 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 13:21:42 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 13:59:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1911.08769", "submitter": "Md. Aminur Rab Ratul", "authors": "Syeda Noor Jaha Azim, Md. Aminur Rab Ratul", "title": "Inspect Transfer Learning Architecture with Dilated Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many award-winning pre-trained Convolutional Neural Network (CNN),\nwhich have a common phenomenon of increasing depth in convolutional layers.\nHowever, I inspect on VGG network, which is one of the famous model submitted\nto ILSVRC-2014, to show that slight modification in the basic architecture can\nenhance the accuracy result of the image classification task. In this paper, We\npresent two improve architectures of pre-trained VGG-16 and VGG-19 networks\nthat apply transfer learning when trained on a different dataset. I report a\nseries of experimental result on various modification of the primary VGG\nnetworks and achieved significant out-performance on image classification task\nby: (1) freezing the first two blocks of the convolutional layers to prevent\nover-fitting and (2) applying different combination of dilation rate in the\nlast three blocks of convolutional layer to reduce image resolution for feature\nextraction. Both the proposed architecture achieves a competitive result on\nCIFAR-10 and CIFAR-100 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:45:56 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Azim", "Syeda Noor Jaha", ""], ["Ratul", "Md. Aminur Rab", ""]]}, {"id": "1911.08772", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Xiaowen Chu, Ka Chun Cheung, Simon See", "title": "Understanding Top-k Sparsification in Distributed Deep Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stochastic gradient descent (SGD) algorithms are widely deployed\nin training large-scale deep learning models, while the communication overhead\namong workers becomes the new system bottleneck. Recently proposed gradient\nsparsification techniques, especially Top-$k$ sparsification with error\ncompensation (TopK-SGD), can significantly reduce the communication traffic\nwithout an obvious impact on the model accuracy. Some theoretical studies have\nbeen carried out to analyze the convergence property of TopK-SGD. However,\nexisting studies do not dive into the details of Top-$k$ operator in gradient\nsparsification and use relaxed bounds (e.g., exact bound of Random-$k$) for\nanalysis; hence the derived results cannot well describe the real convergence\nperformance of TopK-SGD. To this end, we first study the gradient distributions\nof TopK-SGD during the training process through extensive experiments. We then\ntheoretically derive a tighter bound for the Top-$k$ operator. Finally, we\nexploit the property of gradient distribution to propose an approximate top-$k$\nselection algorithm, which is computing-efficient for GPUs, to improve the\nscaling efficiency of TopK-SGD by significantly reducing the computing\noverhead. Codes are available at:\n\\url{https://github.com/hclhkbu/GaussianK-SGD}.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:50:59 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""], ["Cheung", "Ka Chun", ""], ["See", "Simon", ""]]}, {"id": "1911.08780", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Ioannis Vlahavas, Grigorios\n  Tsoumakas", "title": "LionForests: Local Interpretation of Random Forests", "comments": "8 Pages, 4 Tables, 6 Figures, Submitted to NeHuAI-2020 Workshop of\n  ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards a future where machine learning systems will integrate into every\naspect of people's lives, researching methods to interpret such systems is\nnecessary, instead of focusing exclusively on enhancing their performance.\nEnriching the trust between these systems and people will accelerate this\nintegration process. Many medical and retail banking/finance applications use\nstate-of-the-art machine learning techniques to predict certain aspects of new\ninstances. Tree ensembles, like random forests, are widely acceptable solutions\non these tasks, while at the same time they are avoided due to their black-box\nuninterpretable nature, creating an unreasonable paradox. In this paper, we\nprovide a methodology for shedding light on the predictions of the misjudged\nfamily of tree ensemble algorithms. Using classic unsupervised learning\ntechniques and an enhanced similarity metric, to wander among transparent trees\ninside a forest following breadcrumbs, the interpretable essence of tree\nensembles arises. An interpretation provided by these systems using our\napproach, which we call \"LionForests\", can be a simple, comprehensive rule.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:18:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:12:20 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 13:19:52 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Vlahavas", "Ioannis", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1911.08784", "submitter": "Qun Liu", "authors": "Qun Liu, Lihua Fu, and Meng Zhang", "title": "Deep-seismic-prior-based reconstruction of seismic data using\n  convolutional neural networks", "comments": "5 pages,12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of seismic data with missing traces is a long-standing issue\nin seismic data processing. In recent years, rank reduction operations are\nbeing commonly utilized to overcome this problem, which require the rank of\nseismic data to be a prior. However, the rank of field data is unknown; usually\nit requires much time to manually adjust the rank and just obtain an\napproximated rank. Methods based on deep learning require very large datasets\nfor training; however acquiring large datasets is difficult owing to physical\nor financial constraints in practice. Therefore, in this work, we developed a\nnovel method based on unsupervised learning using the intrinsic properties of a\nconvolutional neural network known as U-net, without training datasets. Only\none undersampled seismic data was needed, and the deep seismic prior of input\ndata could be exploited by the network itself, thus making the reconstruction\nconvenient. Furthermore, this method can handle both irregular and regular\nseismic data. Synthetic and field data were tested to assess the performance of\nthe proposed algorithm (DSPRecon algorithm); the advantages of using our method\nwere evaluated by comparing it with the singular spectrum analysis (SSA) method\nfor irregular data reconstruction and de-aliased Cadzow method for regular data\nreconstruction. Experimental results showed that our method provided better\nreconstruction performance than the SSA or Cadzow methods. The recovered\nsignal-to-noise ratios (SNRs) were 32.68 dB and 19.11 dB for the DSPRecon and\nSSA algorithms, respectively. Those for the DSPRecon and Cadzow methods were\n35.91 dB and 15.32 dB, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:30:34 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Liu", "Qun", ""], ["Fu", "Lihua", ""], ["Zhang", "Meng", ""]]}, {"id": "1911.08793", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "A Framework for End-to-End Deep Learning-Based Anomaly Detection in\n  Transportation Networks", "comments": "Preprint submitted to Elsevier TRIP. arXiv admin note: text overlap\n  with arXiv:1909.06041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an end-to-end deep learning-based anomaly detection model for\ntemporal data in transportation networks. The proposed EVT-LSTM model is\nderived from the popular LSTM (Long Short-Term Memory) network and adopts an\nobjective function that is based on fundamental results from EVT (Extreme Value\nTheory). We compare the EVT-LSTM model with some established statistical,\nmachine learning, and hybrid deep learning baselines. Experiments on seven\ndiverse real-world data sets demonstrate the superior anomaly detection\nperformance of our proposed model over the other models considered in the\ncomparison study.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:49:58 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1911.08795", "submitter": "Chi Thang Duong", "authors": "Chi Thang Duong, Thanh Dat Hoang, Ha The Hien Dang, Quoc Viet Hung\n  Nguyen, Karl Aberer", "title": "On Node Features for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN) is a deep model for graph representation learning.\nOne advantage of graph neural network is its ability to incorporate node\nfeatures into the learning process. However, this prevents graph neural network\nfrom being applied into featureless graphs. In this paper, we first analyze the\neffects of node features on the performance of graph neural network. We show\nthat GNNs work well if there is a strong correlation between node features and\nnode labels. Based on these results, we propose new feature initialization\nmethods that allows to apply graph neural network to non-attributed graphs. Our\nexperimental results show that the artificial features are highly competitive\nwith real features.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:02:19 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Duong", "Chi Thang", ""], ["Hoang", "Thanh Dat", ""], ["Dang", "Ha The Hien", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Aberer", "Karl", ""]]}, {"id": "1911.08815", "submitter": "Yawogan Jean Eudes Gbodjo", "authors": "Yawogan Jean Eudes Gbodjo and Dino Ienco and Louise Leroux and Roberto\n  Interdonato and Raffaele Gaetano and Babacar Ndao and Stephane Dupuy", "title": "Object-based multi-temporal and multi-source land cover mapping\n  leveraging hierarchical class relationships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  European satellite missions Sentinel-1 (S1) and Sentinel-2 (S2) provide at\nhighspatial resolution and high revisit time, respectively, radar and optical\nimagesthat support a wide range of Earth surface monitoring tasks such as\nLandUse/Land Cover mapping. A long-standing challenge in the remote\nsensingcommunity is about how to efficiently exploit multiple sources of\ninformation and leverage their complementary. In this particular case, get the\nmost out ofradar and optical satellite image time series (SITS). Here, we\npropose to dealwith land cover mapping through a deep learning framework\nespecially tailoredto leverage the multi-source complementarity provided by\nradar and opticalSITS. The proposed architecture is based on an extension of\nRecurrent NeuralNetwork (RNN) enriched via a customized attention mechanism\ncapable to fitthe specificity of SITS data. In addition, we propose a new\npretraining strategythat exploits domain expert knowledge to guide the model\nparameter initial-ization. Thorough experimental evaluations involving several\nmachine learningcompetitors, on two contrasted study sites, have demonstrated\nthe suitabilityof our new attention mechanism combined with the extend RNN\nmodel as wellas the benefit/limit to inject domain expert knowledge in the\nneural networktraining process.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:50:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gbodjo", "Yawogan Jean Eudes", ""], ["Ienco", "Dino", ""], ["Leroux", "Louise", ""], ["Interdonato", "Roberto", ""], ["Gaetano", "Raffaele", ""], ["Ndao", "Babacar", ""], ["Dupuy", "Stephane", ""]]}, {"id": "1911.08817", "submitter": "Laurens Bliek", "authors": "Laurens Bliek, Sicco Verwer and Mathijs de Weerdt", "title": "Black-box Combinatorial Optimization using Models with Integer-valued\n  Minima", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence 89, 639-653\n  (2021)", "doi": "10.1007/s10472-020-09712-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a black-box optimization objective can only be evaluated with costly or\nnoisy measurements, most standard optimization algorithms are unsuited to find\nthe optimal solution. Specialized algorithms that deal with exactly this\nsituation make use of surrogate models. These models are usually continuous and\nsmooth, which is beneficial for continuous optimization problems, but not\nnecessarily for combinatorial problems. However, by choosing the basis\nfunctions of the surrogate model in a certain way, we show that it can be\nguaranteed that the optimal solution of the surrogate model is integer. This\napproach outperforms random search, simulated annealing and one Bayesian\noptimization algorithm on the problem of finding robust routes for a\nnoise-perturbed traveling salesman benchmark problem, with similar performance\nas another Bayesian optimization algorithm, and outperforms all compared\nalgorithms on a convex binary optimization problem with a large number of\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:56:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Bliek", "Laurens", ""], ["Verwer", "Sicco", ""], ["de Weerdt", "Mathijs", ""]]}, {"id": "1911.08820", "submitter": "Daniel Chao Zhou", "authors": "Daniel Chao Zhou, Zhongming Jin, Tong Zhang", "title": "A Fast Sampling Gradient Tree Boosting Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an adaptive, interpretable, robust, and accurate meta-algorithm for\narbitrary differentiable loss functions, gradient tree boosting is one of the\nmost popular machine learning techniques, though the computational\nexpensiveness severely limits its usage. Stochastic gradient boosting could be\nadopted to accelerates gradient boosting by uniformly sampling training\ninstances, but its estimator could introduce a high variance. This situation\narises motivation for us to optimize gradient tree boosting. We combine\ngradient tree boosting with importance sampling, which achieves better\nperformance by reducing the stochastic variance. Furthermore, we use a\nregularizer to improve the diagonal approximation in the Newton step of\ngradient boosting. The theoretical analysis supports that our strategies\nachieve a linear convergence rate on logistic loss. Empirical results show that\nour algorithm achieves a 2.5x--18x acceleration on two different gradient\nboosting algorithms (LogitBoost and LambdaMART) without appreciable performance\nloss.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:00:53 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhou", "Daniel Chao", ""], ["Jin", "Zhongming", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.08856", "submitter": "Redouane Lguensat", "authors": "Redouane Lguensat, Julien Le Sommer, Sammy Metref, Emmanuel Cosme,\n  Ronan Fablet", "title": "Learning Generalized Quasi-Geostrophic Models Using Deep Neural\n  Numerical Models", "comments": "Accepted for the 2nd Workshop on Machine Learning and the Physical\n  Sciences (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new strategy designed to help physicists discover hidden laws\ngoverning dynamical systems. We propose to use machine learning automatic\ndifferentiation libraries to develop hybrid numerical models that combine\ncomponents based on prior physical knowledge with components based on neural\nnetworks. In these architectures, named Deep Neural Numerical Models (DNNMs),\nthe neural network components are used as building-blocks then deployed for\nlearning hidden variables of underlying physical laws governing dynamical\nsystems. In this paper, we illustrate an application of DNNMs to upper ocean\ndynamics, more precisely the dynamics of a sea surface tracer, the Sea Surface\nHeight (SSH). We develop an advection-based fully differentiable numerical\nscheme, where parts of the computations can be replaced with learnable\nConvNets, and make connections with the single-layer Quasi-Geostrophic (QG)\nmodel, a baseline theory in physical oceanography developed decades ago.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 12:30:58 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Lguensat", "Redouane", ""], ["Sommer", "Julien Le", ""], ["Metref", "Sammy", ""], ["Cosme", "Emmanuel", ""], ["Fablet", "Ronan", ""]]}, {"id": "1911.08871", "submitter": "Jayasree Saha", "authors": "Jayasree Saha and Jayanta Mukherjee", "title": "CNAK : Cluster Number Assisted K-means", "comments": null, "journal-ref": "Pattern Recognition (Elsevier) 2020", "doi": "10.1016/j.patcog.2020.107625", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Determining the number of clusters present in a dataset is an important\nproblem in cluster analysis. Conventional clustering techniques generally\nassume this parameter to be provided up front. %user supplied. %Recently,\nrobustness of any given clustering algorithm is analyzed to measure cluster\nstability/instability which in turn determines the cluster number. In this\npaper, we propose a method which analyzes cluster stability for predicting the\ncluster number. Under the same computational framework, the technique also\nfinds representatives of the clusters. The method is apt for handling big data,\nas we design the algorithm using \\emph{Monte-Carlo} simulation. Also, we\nexplore a few pertinent issues found to be of also clustering. Experiments\nreveal that the proposed method is capable of identifying a single cluster. It\nis robust in handling high dimensional dataset and performs reasonably well\nover datasets having cluster imbalance. Moreover, it can indicate cluster\nhierarchy, if present. Overall we have observed significant improvement in\nspeed and quality for predicting cluster numbers as well as the composition of\nclusters in a large dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:03:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Saha", "Jayasree", ""], ["Mukherjee", "Jayanta", ""]]}, {"id": "1911.08874", "submitter": "Serkan Ak", "authors": "Serkan Ak and Stefan Bruggenwirth", "title": "Avoiding Jammers: A Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the anti-jamming performance of a cognitive radar\nunder a partially observable Markov decision process (POMDP) model. First, we\nobtain an explicit expression for uncertainty of jammer dynamics, which paves\nthe way for illuminating the performance metric of probability of being jammed\nfor the radar beyond a conventional signal-to-noise ratio ($\\mathsf{SNR}$)\nbased analysis. Considering two frequency hopping strategies developed in the\nframework of reinforcement learning (RL), this performance metric is analyzed\nwith deep Q-network (DQN) and long short term memory (LSTM) networks under\nvarious uncertainty values. Finally, the requirement of the target network in\nthe RL algorithm for both network architectures is replaced with a softmax\noperator. Simulation results show that this operator improves upon the\nperformance of the traditional target network.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:06:22 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 08:45:41 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ak", "Serkan", ""], ["Bruggenwirth", "Stefan", ""]]}, {"id": "1911.08934", "submitter": "Guillaume Carbajal", "authors": "Guillaume Carbajal, Romain Serizel, Emmanuel Vincent, Eric Humbert", "title": "Joint NN-Supported Multichannel Reduction of Acoustic Echo,\n  Reverberation and Noise", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing\n  2020", "doi": "10.1109/TASLP.2020.3008974", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneous reduction of acoustic echo,\nreverberation and noise. In real scenarios, these distortion sources may occur\nsimultaneously and reducing them implies combining the corresponding\ndistortion-specific filters. As these filters interact with each other, they\nmust be jointly optimized. We propose to model the target and residual signals\nafter linear echo cancellation and dereverberation using a multichannel\nGaussian modeling framework and to jointly represent their spectra by means of\na neural network. We develop an iterative block-coordinate ascent algorithm to\nupdate all the filters. We evaluate our system on real recordings of acoustic\necho, reverberation and noise acquired with a smart speaker in various\nsituations. The proposed approach outperforms in terms of overall distortion a\ncascade of the individual approaches and a joint reduction approach which does\nnot rely on a spectral model of the target and residual signals.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:37:36 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 10:10:53 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 12:59:50 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 09:13:04 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Carbajal", "Guillaume", ""], ["Serizel", "Romain", ""], ["Vincent", "Emmanuel", ""], ["Humbert", "Eric", ""]]}, {"id": "1911.08941", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Fast and Deep Graph Neural Networks", "comments": "Pre-print of 'Fast and Deep Graph Neural Networks', accepted for AAAI\n  2020. This document includes the Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the efficiency issue for the construction of a deep graph neural\nnetwork (GNN). The approach exploits the idea of representing each input graph\nas a fixed point of a dynamical system (implemented through a recurrent neural\nnetwork), and leverages a deep architectural organization of the recurrent\nunits. Efficiency is gained by many aspects, including the use of small and\nvery sparse networks, where the weights of the recurrent units are left\nuntrained under the stability condition introduced in this work. This can be\nviewed as a way to study the intrinsic power of the architecture of a deep GNN,\nand also to provide insights for the set-up of more complex fully-trained\nmodels. Through experimental results, we show that even without training of the\nrecurrent connections, the architecture of small deep GNN is surprisingly able\nto achieve or improve the state-of-the-art performance on a significant set of\ntasks in the field of graphs classification.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:46:54 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1911.08942", "submitter": "Zikri Bayraktar", "authors": "Zikri Bayraktar", "title": "Adaptive Wind Driven Optimization Trained Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the application of a newly developed nature-inspired\nmetaheuristic optimization method, namely the Adaptive Wind Driven Optimization\n(AWDO), to the training of feedforward artificial neural networks (NN) and\npresents a discussion into the future research of AWDO implementation in Deep\nLearning (DL). Application example of digit classification with MNIST dataset\nreveals interesting behavior of the derivative-free AWDO method compared to\nsteepest descent method where results and future work on the implementation of\nAWDO in deep neural networks are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:49:33 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bayraktar", "Zikri", ""]]}, {"id": "1911.08967", "submitter": "Fuzhen Zhuang", "authors": "Fuzhen Zhuang, Keyu Duan, Tongjia Guo, Yongchun Zhu, Dongbo Xi,\n  Zhiyuan Qi, Qing He", "title": "Transfer Learning Toolkit: Primers and Benchmarks", "comments": "A Transfer Learning Toolkit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer learning toolkit wraps the codes of 17 transfer learning models\nand provides integrated interfaces, allowing users to use those models by\ncalling a simple function. It is easy for primary researchers to use this\ntoolkit and to choose proper models for real-world applications. The toolkit is\nwritten in Python and distributed under MIT open source license. In this paper,\nthe current state of this toolkit is described and the necessary environment\nsetting and usage are introduced.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:30:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhuang", "Fuzhen", ""], ["Duan", "Keyu", ""], ["Guo", "Tongjia", ""], ["Zhu", "Yongchun", ""], ["Xi", "Dongbo", ""], ["Qi", "Zhiyuan", ""], ["He", "Qing", ""]]}, {"id": "1911.09002", "submitter": "\\c{C}a\\u{g}kan Yapar", "authors": "Ron Levie, \\c{C}a\\u{g}kan Yapar, Gitta Kutyniok, Giuseppe Caire", "title": "RadioUNet: Fast Radio Map Estimation with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a highly efficient and very accurate deep learning\nmethod for estimating the propagation pathloss from a point $x$ (transmitter\nlocation) to any point $y$ on a planar domain. For applications such as\nuser-cell site association and device-to-device link scheduling, an accurate\nknowledge of the pathloss function for all pairs of transmitter-receiver\nlocations is very important. Commonly used statistical models approximate the\npathloss as a decaying function of the distance between transmitter and\nreceiver. However, in realistic propagation environments characterized by the\npresence of buildings, street canyons, and objects at different heights, such\nradial-symmetric functions yield very misleading results. In this paper we show\nthat properly designed and trained deep neural networks are able to learn how\nto estimate the pathloss function, given an urban environment, in a very\naccurate and computationally efficient manner. Our proposed method, termed\nRadioUNet, learns from a physical simulation dataset, and generates pathloss\nestimations that are very close to the simulations, but are much faster to\ncompute for real-time applications. Moreover, we propose methods for\ntransferring what was learned from simulations to real-life. Numerical results\nshow that our method significantly outperforms previously proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 10:31:11 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 18:57:08 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 15:14:31 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Levie", "Ron", ""], ["Yapar", "\u00c7a\u011fkan", ""], ["Kutyniok", "Gitta", ""], ["Caire", "Giuseppe", ""]]}, {"id": "1911.09006", "submitter": "Gilles Kratzer", "authors": "Gilles Kratzer, Fraser Iain Lewis, Arianna Comin, Marta Pittavino,\n  Reinhard Furrer", "title": "Additive Bayesian Network Modelling with the R Package abn", "comments": "37 pages, 14 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R package abn is designed to fit additive Bayesian models to\nobservational datasets. It contains routines to score Bayesian networks based\non Bayesian or information theoretic formulations of generalized linear models.\nIt is equipped with exact search and greedy search algorithms to select the\nbest network. It supports a possible blend of continuous, discrete and count\ndata and input of prior knowledge at a structural level. The Bayesian\nimplementation supports random effects to control for one-layer clustering. In\nthis paper, we give an overview of the methodology and illustrate the package's\nfunctionalities using a veterinary dataset about respiratory diseases in\ncommercial swine production.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:22:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Kratzer", "Gilles", ""], ["Lewis", "Fraser Iain", ""], ["Comin", "Arianna", ""], ["Pittavino", "Marta", ""], ["Furrer", "Reinhard", ""]]}, {"id": "1911.09007", "submitter": "Abdulkadir Celikkanat", "authors": "Abdulkadir \\c{C}elikkanat and Fragkiskos D. Malliaros", "title": "Exponential Family Graph Embeddings", "comments": "Accepted to the The Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20), New York City, New York, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing networks in a low dimensional latent space is a crucial task\nwith many interesting applications in graph learning problems, such as link\nprediction and node classification. A widely applied network representation\nlearning paradigm is based on the combination of random walks for sampling\ncontext nodes and the traditional \\textit{Skip-Gram} model to capture\ncenter-context node relationships. In this paper, we emphasize on exponential\nfamily distributions to capture rich interaction patterns between nodes in\nrandom walk sequences. We introduce the generic \\textit{exponential family\ngraph embedding} model, that generalizes random walk-based network\nrepresentation learning techniques to exponential family conditional\ndistributions. We study three particular instances of this model, analyzing\ntheir properties and showing their relationship to existing unsupervised\nlearning models. Our experimental evaluation on real-world datasets\ndemonstrates that the proposed techniques outperform well-known baseline\nmethods in two downstream machine learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:23:09 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1911.09008", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Yasmeen Kussad, Dominic Kirkham, John W\n  Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Learning Embeddings from Cancer Mutation Sets for Classification Tasks", "comments": "Sets & Partitions Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of somatic mutation profiles from cancer patients is essential in\nthe development of cancer research. However, the low frequency of most\nmutations and the varying rates of mutations across patients makes the data\nextremely challenging to statistically analyze as well as difficult to use in\nclassification problems, for clustering, visualization or for learning useful\ninformation. Thus, the creation of low dimensional representations of somatic\nmutation profiles that hold useful information about the DNA of cancer cells\nwill facilitate the use of such data in applications that will progress\nprecision medicine. In this paper, we talk about the open problem of learning\nfrom somatic mutations, and present Flatsomatic: a solution that utilizes\nvariational autoencoders (VAEs) to create latent representations of somatic\nprofiles. The work done in this paper shows great potential for this method,\nwith the VAE embeddings performing better than PCA for a clustering task, and\nperforming equally well to the raw high dimensional data for a classification\ntask. We believe the methods presented herein can be of great value in future\nresearch and in bringing data-driven models into precision oncology.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:23:30 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Kussad", "Yasmeen", ""], ["Kirkham", "Dominic", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1911.09011", "submitter": "Soma Yokoi", "authors": "Soma Yokoi and Issei Sato", "title": "Bayesian interpretation of SGD as Ito process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current interpretation of stochastic gradient descent (SGD) as a\nstochastic process lacks generality in that its numerical scheme restricts\ncontinuous-time dynamics as well as the loss function and the distribution of\ngradient noise. We introduce a simplified scheme with milder conditions that\nflexibly interprets SGD as a discrete-time approximation of an Ito process. The\nscheme also works as a common foundation of SGD and stochastic gradient\nLangevin dynamics (SGLD), providing insights into their asymptotic properties.\nWe investigate the convergence of SGD with biased gradient in terms of the\nequilibrium mode and the overestimation problem of the second moment of SGLD.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:29:45 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Yokoi", "Soma", ""], ["Sato", "Issei", ""]]}, {"id": "1911.09017", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Jiayi Chen, Haotian Xue, Quanshi Zhang", "title": "Towards a Unified Evaluation of Explanation Methods without Ground Truth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a set of criteria to evaluate the objectiveness of\nexplanation methods of neural networks, which is crucial for the development of\nexplainable AI, but it also presents significant challenges. The core challenge\nis that people usually cannot obtain ground-truth explanations of the neural\nnetwork. To this end, we design four metrics to evaluate explanation results\nwithout ground-truth explanations. Our metrics can be broadly applied to nine\nbenchmark methods of interpreting neural networks, which provides new insights\nof explanation methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:44:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Jiayi", ""], ["Xue", "Haotian", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09030", "submitter": "Cong Xie", "authors": "Cong Xie, Oluwasanmi Koyejo, Indranil Gupta, Haibin Lin", "title": "Local AdaAlter: Communication-Efficient Stochastic Gradient Descent with\n  Adaptive Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When scaling distributed training, the communication overhead is often the\nbottleneck. In this paper, we propose a novel SGD variant with reduced\ncommunication and adaptive learning rates. We prove the convergence of the\nproposed algorithm for smooth but non-convex problems. Empirical results show\nthat the proposed algorithm significantly reduces the communication overhead,\nwhich, in turn, reduces the training time by up to 30% for the 1B word dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:58:40 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 00:26:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Oluwasanmi", ""], ["Gupta", "Indranil", ""], ["Lin", "Haibin", ""]]}, {"id": "1911.09032", "submitter": "Christian Schilling", "authors": "Thomas A. Henzinger and Anna Lukina and Christian Schilling", "title": "Outside the Box: Abstraction-Based Monitoring of Neural Networks", "comments": "accepted at ECAI 2020", "journal-ref": null, "doi": "10.3233/FAIA200375", "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrated unmatched performance in a range of\nclassification tasks. Despite numerous efforts of the research community,\nnovelty detection remains one of the significant limitations of neural\nnetworks. The ability to identify previously unseen inputs as novel is crucial\nfor our understanding of the decisions made by neural networks. At runtime,\ninputs not falling into any of the categories learned during training cannot be\nclassified correctly by the neural network. Existing approaches treat the\nneural network as a black box and try to detect novel inputs based on the\nconfidence of the output predictions. However, neural networks are not trained\nto reduce their confidence for novel inputs, which limits the effectiveness of\nthese approaches. We propose a framework to monitor a neural network by\nobserving the hidden layers. We employ a common abstraction from program\nanalysis - boxes - to identify novel behaviors in the monitored layers, i.e.,\ninputs that cause behaviors outside the box. For each neuron, the boxes range\nover the values seen in training. The framework is efficient and flexible to\nachieve a desired trade-off between raising false warnings and detecting novel\ninputs. We illustrate the performance and the robustness to variability in the\nunknown classes on popular image-classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:03:21 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 10:32:30 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 15:46:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Henzinger", "Thomas A.", ""], ["Lukina", "Anna", ""], ["Schilling", "Christian", ""]]}, {"id": "1911.09033", "submitter": "Eric Crawford", "authors": "Eric Crawford, Joelle Pineau", "title": "Exploiting Spatial Invariance for Scalable Unsupervised Object Tracking", "comments": "Accepted at AAAI 2020. Code: https://github.com/e2crawfo/silot.\n  Visualizations: https://sites.google.com/view/silot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect and track objects in the visual world is a crucial\nskill for any intelligent agent, as it is a necessary precursor to any\nobject-level reasoning process. Moreover, it is important that agents learn to\ntrack objects without supervision (i.e. without access to annotated training\nvideos) since this will allow agents to begin operating in new environments\nwith minimal human assistance. The task of learning to discover and track\nobjects in videos, which we call \\textit{unsupervised object tracking}, has\ngrown in prominence in recent years; however, most architectures that address\nit still struggle to deal with large scenes containing many objects. In the\ncurrent work, we propose an architecture that scales well to the large-scene,\nmany-object setting by employing spatially invariant computations (convolutions\nand spatial attention) and representations (a spatially local object\nspecification scheme). In a series of experiments, we demonstrate a number of\nattractive features of our architecture; most notably, that it outperforms\ncompeting methods at tracking objects in cluttered scenes with many objects,\nand that it can generalize well to videos that are larger and/or contain more\nobjects than videos encountered during training.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:03:51 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Crawford", "Eric", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.09040", "submitter": "Quanshi Zhang", "authors": "Wen Shen, Binbin Zhang, Shikun Huang, Zhihua Wei, Quanshi Zhang", "title": "3D-Rotation-Equivariant Quaternion Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a set of rules to revise various neural networks for 3D\npoint cloud processing to rotation-equivariant quaternion neural networks\n(REQNNs). We find that when a neural network uses quaternion features under\ncertain conditions, the network feature naturally has the rotation-equivariance\nproperty. Rotation equivariance means that applying a specific rotation\ntransformation to the input point cloud is equivalent to applying the same\nrotation transformation to all intermediate-layer quaternion features. Besides,\nthe REQNN also ensures that the intermediate-layer features are invariant to\nthe permutation of input points. Compared with the original neural network, the\nREQNN exhibits higher rotation robustness.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:10:52 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 08:24:30 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Shen", "Wen", ""], ["Zhang", "Binbin", ""], ["Huang", "Shikun", ""], ["Wei", "Zhihua", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09045", "submitter": "Saeed Khaki", "authors": "Saeed Khaki, Lizhi Wang and Sotirios V. Archontoulis", "title": "A CNN-RNN Framework for Crop Yield Prediction", "comments": "26 Pages, 14 Figures", "journal-ref": "Frontiers in Plant Science, 2019", "doi": "10.3389/fpls.2019.01750", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crop yield prediction is extremely challenging due to its dependence on\nmultiple factors such as crop genotype, environmental factors, management\npractices, and their interactions. This paper presents a deep learning\nframework using convolutional neural networks (CNN) and recurrent neural\nnetworks (RNN) for crop yield prediction based on environmental data and\nmanagement practices. The proposed CNN-RNN model, along with other popular\nmethods such as random forest (RF), deep fully-connected neural networks\n(DFNN), and LASSO, was used to forecast corn and soybean yield across the\nentire Corn Belt (including 13 states) in the United States for years 2016,\n2017, and 2018 using historical data. The new model achieved a\nroot-mean-square-error (RMSE) 9% and 8% of their respective average yields,\nsubstantially outperforming all other methods that were tested. The CNN-RNN\nhave three salient features that make it a potentially useful method for other\ncrop yield prediction studies. (1) The CNN-RNN model was designed to capture\nthe time dependencies of environmental factors and the genetic improvement of\nseeds over time without having their genotype information. (2) The model\ndemonstrated the capability to generalize the yield prediction to untested\nenvironments without significant drop in the prediction accuracy. (3) Coupled\nwith the backpropagation method, the model could reveal the extent to which\nweather conditions, accuracy of weather predictions, soil conditions, and\nmanagement practices were able to explain the variation in the crop yields.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:18:48 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 19:10:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Khaki", "Saeed", ""], ["Wang", "Lizhi", ""], ["Archontoulis", "Sotirios V.", ""]]}, {"id": "1911.09046", "submitter": "Xiangfeng Wang", "authors": "Junjie Wang, Xiangfeng Wang, Bo Jin, Junchi Yan, Wenjie Zhang,\n  Hongyuan Zha", "title": "Heterogeneous Graph-based Knowledge Transfer for Generalized Zero-shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized zero-shot learning (GZSL) tackles the problem of learning to\nclassify instances involving both seen classes and unseen ones. The key issue\nis how to effectively transfer the model learned from seen classes to unseen\nclasses. Existing works in GZSL usually assume that some prior information\nabout unseen classes are available. However, such an assumption is unrealistic\nwhen new unseen classes appear dynamically. To this end, we propose a novel\nheterogeneous graph-based knowledge transfer method (HGKT) for GZSL, agnostic\nto unseen classes and instances, by leveraging graph neural network.\nSpecifically, a structured heterogeneous graph is constructed with high-level\nrepresentative nodes for seen classes, which are chosen through Wasserstein\nbarycenter in order to simultaneously capture inter-class and intra-class\nrelationship. The aggregation and embedding functions can be learned through\ngraph neural network, which can be used to compute the embeddings of unseen\nclasses by transferring the knowledge from their neighbors. Extensive\nexperiments on public benchmark datasets show that our method achieves\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:20:05 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Wang", "Junjie", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Yan", "Junchi", ""], ["Zhang", "Wenjie", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1911.09052", "submitter": "Olga Ohrimenko", "authors": "Olga Ohrimenko and Shruti Tople and Sebastian Tschiatschek", "title": "Collaborative Machine Learning Markets with Data-Replication-Robust\n  Payments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of collaborative machine learning markets where multiple\nparties can achieve improved performance on their machine learning tasks by\ncombining their training data. We discuss desired properties for these machine\nlearning markets in terms of fair revenue distribution and potential threats,\nincluding data replication. We then instantiate a collaborative market for\ncases where parties share a common machine learning task and where parties'\ntasks are different. Our marketplace incentivizes parties to submit high\nquality training and true validation data. To this end, we introduce a novel\npayment division function that is robust-to-replication and customized output\nmodels that perform well only on requested machine learning tasks. In\nexperiments, we validate the assumptions underlying our theoretical analysis\nand show that these are approximately satisfied for commonly used machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:58:31 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ohrimenko", "Olga", ""], ["Tople", "Shruti", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "1911.09053", "submitter": "Quanshi Zhang", "authors": "Wen Shen, Zhihua Wei, Shikun Huang, Binbin Zhang, Panyue Chen, Ping\n  Zhao, Quanshi Zhang", "title": "Verifiability and Predictability: Interpreting Utilities of Network\n  Architectures for Point Cloud Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we diagnose deep neural networks for 3D point cloud processing\nto explore utilities of different intermediate-layer network architectures. We\npropose a number of hypotheses on the effects of specific intermediate-layer\nnetwork architectures on the representation capacity of DNNs. In order to prove\nthe hypotheses, we design five metrics to diagnose various types of DNNs from\nthe following perspectives, information discarding, information concentration,\nrotation robustness, adversarial robustness, and neighborhood inconsistency. We\nconduct comparative studies based on such metrics to verify the hypotheses. We\nfurther use the verified hypotheses to revise intermediate-layer architectures\nof existing DNNs and improve their utilities. Experiments demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:33:19 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 09:00:39 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 03:54:03 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Shen", "Wen", ""], ["Wei", "Zhihua", ""], ["Huang", "Shikun", ""], ["Zhang", "Binbin", ""], ["Chen", "Panyue", ""], ["Zhao", "Ping", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09058", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Tianxing Jiang, Yordanos Goshu, Harry Yang, Serge\n  Belongie, Ser-Nam Lim", "title": "Fine-grained Synthesis of Unrestricted Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for generating unrestricted adversarial examples\nby manipulating fine-grained aspects of image generation. Unlike existing\nunrestricted attacks that typically hand-craft geometric transformations, we\nlearn stylistic and stochastic modifications leveraging state-of-the-art\ngenerative models. This allows us to manipulate an image in a controlled,\nfine-grained manner without being bounded by a norm threshold. Our approach can\nbe used for targeted and non-targeted unrestricted attacks on classification,\nsemantic segmentation and object detection models. Our attacks can bypass\ncertified defenses, yet our adversarial images look indistinguishable from\nnatural images as verified by human evaluation. Moreover, we demonstrate that\nadversarial training with our examples improves performance of the model on\nclean images without requiring any modifications to the architecture. We\nperform experiments on LSUN, CelebA-HQ and COCO-Stuff as high resolution\ndatasets to validate efficacy of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:42:12 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:53:26 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Poursaeed", "Omid", ""], ["Jiang", "Tianxing", ""], ["Goshu", "Yordanos", ""], ["Yang", "Harry", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1911.09061", "submitter": "Azim Ahmadzadeh", "authors": "Azim Ahmadzadeh, Maxwell Hostetter, Berkay Aydin, Manolis K.\n  Georgoulis, Dustin J. Kempton, Sushant S. Mahajan, and Rafal A. Angryk", "title": "Challenges with Extreme Class-Imbalance and Temporal Coherence: A Study\n  on Solar Flare Data", "comments": "9 pages, 9 figures, and 1 table, accepted in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.SR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In analyses of rare-events, regardless of the domain of application,\nclass-imbalance issue is intrinsic. Although the challenges are known to data\nexperts, their explicit impact on the analytic and the decisions made based on\nthe findings are often overlooked. This is in particular prevalent in\ninterdisciplinary research where the theoretical aspects are sometimes\novershadowed by the challenges of the application. To show-case these\nundesirable impacts, we conduct a series of experiments on a recently created\nbenchmark data, named Space Weather ANalytics for Solar Flares (SWAN-SF). This\nis a multivariate time series dataset of magnetic parameters of active regions.\nAs a remedy for the imbalance issue, we study the impact of data manipulation\n(undersampling and oversampling) and model manipulation (using class weights).\nFurthermore, we bring to focus the auto-correlation of time series that is\ninherited from the use of sliding window for monitoring flares' history.\nTemporal coherence, as we call this phenomenon, invalidates the randomness\nassumption, thus impacting all sampling practices including different\ncross-validation techniques. We illustrate how failing to notice this concept\ncould give an artificial boost in the forecast performance and result in\nmisleading findings. Throughout this study we utilized Support Vector Machine\nas a classifier, and True Skill Statistics as a verification metric for\ncomparison of experiments. We conclude our work by specifying the correct\npractice in each case, and we hope that this study could benefit researchers in\nother domains where time series of rare events are of interest.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:46:38 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ahmadzadeh", "Azim", ""], ["Hostetter", "Maxwell", ""], ["Aydin", "Berkay", ""], ["Georgoulis", "Manolis K.", ""], ["Kempton", "Dustin J.", ""], ["Mahajan", "Sushant S.", ""], ["Angryk", "Rafal A.", ""]]}, {"id": "1911.09067", "submitter": "Bruno Sudret", "authors": "X. Zhu and B. Sudret", "title": "Replication-based emulation of the response distribution of stochastic\n  simulators using generalized lambda distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2019-008", "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to limited computational power, performing uncertainty quantification\nanalyses with complex computational models can be a challenging task. This is\nexacerbated in the context of stochastic simulators, the response of which to a\ngiven set of input parameters, rather than being a deterministic value, is a\nrandom variable with unknown probability density function (PDF). Of interest in\nthis paper is the construction of a surrogate that can accurately predict this\nresponse PDF for any input parameters. We suggest using a flexible distribution\nfamily -- the generalized lambda distribution -- to approximate the response\nPDF. The associated distribution parameters are cast as functions of input\nparameters and represented by sparse polynomial chaos expansions. To build such\na surrogate model, we propose an approach based on a local inference of the\nresponse PDF at each point of the experimental design based on replicated model\nevaluations. Two versions of this framework are proposed and compared on\nanalytical examples and case studies.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:03:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhu", "X.", ""], ["Sudret", "B.", ""]]}, {"id": "1911.09086", "submitter": "Monica Arul", "authors": "Monica Arul and Ahsan Kareem", "title": "Shapelets for earthquake detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces EQShapelets (EarthQuake Shapelets) a time-series\nshape-based approach embedded in machine learning to autonomously detect\nearthquakes. It promises to overcome the challenges in the field of seismology\nrelated to automated detection and cataloging of earthquakes. EQShapelets are\namplitude and phase-independent, i.e., their detection sensitivity is\nirrespective of the magnitude of the earthquake and the time of occurrence.\nThey are also robust to noise and other spurious signals. The detection\ncapability of EQShapelets is tested on one week of continuous seismic data\nprovided by the Northern California Seismic Network (NCSN) obtained from a\nstation in central California near the Calaveras Fault. EQShapelets combined\nwith a Random Forest classifier, detected all of the cataloged earthquakes and\n281 uncataloged events with lower false detection rate thus offering a better\nperformance than autocorrelation and FAST algorithms. The primary advantage of\nEQShapelets over competing methods is the interpretability and insight it\noffers. Shape-based approaches are intuitive, visually meaningful and offers\nimmediate insight into the problem domain that goes beyond their use in\naccurate detection. EQShapelets, if implemented at a large scale, can\nsignificantly reduce catalog completeness magnitudes and can serve as an\neffective tool for near real-time earthquake monitoring and cataloging.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:50:25 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Arul", "Monica", ""], ["Kareem", "Ahsan", ""]]}, {"id": "1911.09103", "submitter": "Andrew White", "authors": "Rainier Barrett and Andrew D. White", "title": "Investigating Active Learning and Meta-Learning for Iterative Peptide\n  Design", "comments": "19 pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often the development of novel functional peptides is not amenable to high\nthroughput or purely computational screening methods. Peptides must be\nsynthesized one at a time in a process that does not generate large amounts of\ndata. One way this method can be improved is by ensuring that each experiment\nprovides the best improvement in both peptide properties and predictive\nmodeling accuracy. Here, we study the effectiveness of active learning,\noptimizing experiment order, and meta-learning, transferring knowledge between\ncontexts, to reduce the number of experiments necessary to build a predictive\nmodel. We present a multi-task benchmark database of peptides designed to\nadvance these methods for experimental design. Each task is binary\nclassification of peptides represented as a sequence string. We find neither\nactive learning method tested to be better than random choice. The\nmeta-learning method Reptile was found to improve average accuracy across\ndatasets. Combining meta-learning with active learning offers inconsistent\nbenefits.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:33:01 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:46:46 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 23:33:27 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 22:02:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Barrett", "Rainier", ""], ["White", "Andrew D.", ""]]}, {"id": "1911.09105", "submitter": "Gregory Wornell", "authors": "Shao-Lun Huang, Anuran Makur, Gregory W. Wornell, and Lizhong Zheng", "title": "On Universal Features for High-Dimensional Learning and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying universal low-dimensional features\nfrom high-dimensional data for inference tasks in settings involving learning.\nFor such problems, we introduce natural notions of universality and we show a\nlocal equivalence among them. Our analysis is naturally expressed via\ninformation geometry, and represents a conceptually and computationally useful\nanalysis. The development reveals the complementary roles of the singular value\ndecomposition, Hirschfeld-Gebelein-R\\'enyi maximal correlation, the canonical\ncorrelation and principle component analyses of Hotelling and Pearson, Tishby's\ninformation bottleneck, Wyner's common information, Ky Fan $k$-norms, and\nBrieman and Friedman's alternating conditional expectations algorithm. We\nfurther illustrate how this framework facilitates understanding and optimizing\naspects of learning systems, including multinomial logistic (softmax)\nregression and the associated neural network architecture, matrix factorization\nmethods for collaborative filtering and other applications, rank-constrained\nmultivariate linear regression, and forms of semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:00:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Huang", "Shao-Lun", ""], ["Makur", "Anuran", ""], ["Wornell", "Gregory W.", ""], ["Zheng", "Lizhong", ""]]}, {"id": "1911.09107", "submitter": "Patrick Komiske", "authors": "Anders Andreassen, Patrick T. Komiske, Eric M. Metodiev, Benjamin\n  Nachman, and Jesse Thaler", "title": "OmniFold: A Method to Simultaneously Unfold All Observables", "comments": "8 pages, 3 figures, 1 table, 1 poem; v2: updated to approximate PRL\n  version", "journal-ref": "Phys. Rev. Lett. 124, 182001 (2020)", "doi": "10.1103/PhysRevLett.124.182001", "report-no": "MIT-CTP 5155", "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collider data must be corrected for detector effects (\"unfolded\") to be\ncompared with many theoretical calculations and measurements from other\nexperiments. Unfolding is traditionally done for individual, binned observables\nwithout including all information relevant for characterizing the detector\nresponse. We introduce OmniFold, an unfolding method that iteratively reweights\na simulated dataset, using machine learning to capitalize on all available\ninformation. Our approach is unbinned, works for arbitrarily high-dimensional\ndata, and naturally incorporates information from the full phase space. We\nillustrate this technique on a realistic jet substructure example from the\nLarge Hadron Collider and compare it to standard binned unfolding methods. This\nnew paradigm enables the simultaneous measurement of all observables, including\nthose not yet invented at the time of the analysis.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:00:00 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 16:50:38 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Andreassen", "Anders", ""], ["Komiske", "Patrick T.", ""], ["Metodiev", "Eric M.", ""], ["Nachman", "Benjamin", ""], ["Thaler", "Jesse", ""]]}, {"id": "1911.09145", "submitter": "Justin Sirignano", "authors": "Jonathan B. Freund, Jonathan F. MacArt, and Justin Sirignano", "title": "DPM: A deep learning PDE augmentation method (with application to\n  large-eddy simulation)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for scientific applications faces the challenge of limited\ndata. We propose a framework that leverages a priori known physics to reduce\noverfitting when training on relatively small datasets. A deep neural network\nis embedded in a partial differential equation (PDE) that expresses the known\nphysics and learns to describe the corresponding unknown or unrepresented\nphysics from the data. Crafted as such, the neural network can also provide\ncorrections for erroneously represented physics, such as discretization errors\nassociated with the PDE's numerical solution. Once trained, the deep learning\nPDE model (DPM) can make out-of-sample predictions for new physical parameters,\ngeometries, and boundary conditions.\n  Our approach optimizes over the functional form of the PDE. Estimating the\nembedded neural network requires optimizing over the entire PDE, which itself\nis a function of the neural network. Adjoint partial differential equations are\nused to efficiently calculate the high-dimensional gradient of the objective\nfunction with respect to the neural network parameters. A stochastic adjoint\nmethod (SAM), similar in spirit to stochastic gradient descent, further\naccelerates training.\n  The approach is demonstrated and evaluated for turbulence predictions using\nlarge-eddy simulation (LES), a filtered version of the Navier--Stokes equation\ncontaining unclosed sub-filter-scale terms. The DPM outperforms the widely-used\nconstant-coefficient and dynamic Smagorinsky models, even for filter sizes so\nlarge that these established models become qualitatively incorrect. It also\nsignificantly outperforms a priori trained models, which do not account for the\nfull PDE. A relaxation of the discrete enforcement of the divergence-free\nconstraint is also considered, instead allowing the DPM to approximately\nenforce incompressibility physics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:51:14 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Freund", "Jonathan B.", ""], ["MacArt", "Jonathan F.", ""], ["Sirignano", "Justin", ""]]}, {"id": "1911.09153", "submitter": "Tyler Lu", "authors": "Ivan Vendrov, Tyler Lu, Qingqing Huang, Craig Boutilier", "title": "Gradient-based Optimization for Bayesian Preference Elicitation", "comments": "To appear in the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective techniques for eliciting user preferences have taken on added\nimportance as recommender systems (RSs) become increasingly interactive and\nconversational. A common and conceptually appealing Bayesian criterion for\nselecting queries is expected value of information (EVOI). Unfortunately, it is\ncomputationally prohibitive to construct queries with maximum EVOI in RSs with\nlarge item spaces. We tackle this issue by introducing a continuous formulation\nof EVOI as a differentiable network that can be optimized using gradient\nmethods available in modern machine learning (ML) computational frameworks\n(e.g., TensorFlow, PyTorch). We exploit this to develop a novel, scalable Monte\nCarlo method for EVOI optimization, which is more scalable for large item\nspaces than methods requiring explicit enumeration of items. While we emphasize\nthe use of this approach for pairwise (or k-wise) comparisons of items, we also\ndemonstrate how our method can be adapted to queries involving subsets of item\nattributes or \"partial items,\" which are often more cognitively manageable for\nusers. Experiments show that our gradient-based EVOI technique achieves\nstate-of-the-art performance across several domains while scaling to large item\nspaces.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:08:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Vendrov", "Ivan", ""], ["Lu", "Tyler", ""], ["Huang", "Qingqing", ""], ["Boutilier", "Craig", ""]]}, {"id": "1911.09158", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Xiaolin Huang, Yudong Chen, Jie Yang, Johan A.K. Suykens", "title": "Random Fourier Features via Fast Surrogate Leverage Weighted Sampling", "comments": "accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fast surrogate leverage weighted sampling\nstrategy to generate refined random Fourier features for kernel approximation.\nCompared to the current state-of-the-art method that uses the leverage weighted\nscheme [Li-ICML2019], our new strategy is simpler and more effective. It uses\nkernel alignment to guide the sampling process and it can avoid the matrix\ninversion operator when we compute the leverage function. Given n observations\nand s random features, our strategy can reduce the time complexity from\nO(ns^2+s^3) to O(ns^2), while achieving comparable (or even slightly better)\nprediction performance when applied to kernel ridge regression (KRR). In\naddition, we provide theoretical guarantees on the generalization performance\nof our approach, and in particular characterize the number of random features\nrequired to achieve statistical guarantees in KRR. Experiments on several\nbenchmark datasets demonstrate that our algorithm achieves comparable\nprediction performance and takes less time cost when compared to [Li-ICML2019].\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:24:41 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Liu", "Fanghui", ""], ["Huang", "Xiaolin", ""], ["Chen", "Yudong", ""], ["Yang", "Jie", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1911.09159", "submitter": "JInglai Li", "authors": "Yuzhou Gao, Tengchao Yu, Jinglai Li", "title": "Bayesian optimization with local search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global optimization finds applications in a wide range of real world\nproblems. The multi-start methods are a popular class of global optimization\ntechniques, which are based on the ideas of conducting local searches at\nmultiple starting points. In this work we propose a new multi-start algorithm\nwhere the starting points are determined in a Bayesian optimization framework.\nSpecifically, the method can be understood as to construct a new function by\nconducting local searches of the original objective function, where the new\nfunction attains the same global optima as the original one. Bayesian\noptimization is then applied to find the global optima of the new local search\ndefined function.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:25:49 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:21:57 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 11:46:57 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Gao", "Yuzhou", ""], ["Yu", "Tengchao", ""], ["Li", "Jinglai", ""]]}, {"id": "1911.09162", "submitter": "Changjian Shui", "authors": "Changjian Shui, Fan Zhou, Christian Gagn\\'e, Boyu Wang", "title": "Deep Active Learning: Unified and Principled Method for Query and\n  Training", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are proposing a unified and principled method for both the\nquerying and training processes in deep batch active learning. We are providing\ntheoretical insights from the intuition of modeling the interactive procedure\nin active learning as distribution matching, by adopting the Wasserstein\ndistance. As a consequence, we derived a new training loss from the theoretical\nanalysis, which is decomposed into optimizing deep neural network parameters\nand batch query selection through alternative optimization. In addition, the\nloss for training a deep neural network is naturally formulated as a min-max\noptimization problem through leveraging the unlabeled data information.\nMoreover, the proposed principles also indicate an explicit\nuncertainty-diversity trade-off in the query batch selection. Finally, we\nevaluate our proposed method on different benchmarks, consistently showing\nbetter empirical performances and a better time-efficient query strategy\ncompared to the baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:36:45 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:39:02 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Shui", "Changjian", ""], ["Zhou", "Fan", ""], ["Gagn\u00e9", "Christian", ""], ["Wang", "Boyu", ""]]}, {"id": "1911.09189", "submitter": "Alexander Alemi", "authors": "Ravid Shwartz-Ziv, Alexander A. Alemi", "title": "Information in Infinite Ensembles of Infinitely-Wide Neural Networks", "comments": "2nd Symposium on Advances in Approximate Bayesian Inference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this preliminary work, we study the generalization properties of infinite\nensembles of infinitely-wide neural networks. Amazingly, this model family\nadmits tractable calculations for many information-theoretic quantities. We\nreport analytical and empirical investigations in the search for signals that\ncorrelate with generalization.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 21:56:11 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 23:17:55 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shwartz-Ziv", "Ravid", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1911.09251", "submitter": "Tunhou Zhang", "authors": "Tunhou Zhang, Hsin-Pai Cheng, Zhenwen Li, Feng Yan, Chengyu Huang, Hai\n  Li, Yiran Chen", "title": "AutoShrink: A Topology-aware NAS for Discovering Efficient Neural\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource is an important constraint when deploying Deep Neural Networks\n(DNNs) on mobile and edge devices. Existing works commonly adopt the cell-based\nsearch approach, which limits the flexibility of network patterns in learned\ncell structures. Moreover, due to the topology-agnostic nature of existing\nworks, including both cell-based and node-based approaches, the search process\nis time consuming and the performance of found architecture may be sub-optimal.\nTo address these problems, we propose AutoShrink, a topology-aware Neural\nArchitecture Search(NAS) for searching efficient building blocks of neural\narchitectures. Our method is node-based and thus can learn flexible network\npatterns in cell structures within a topological search space. Directed Acyclic\nGraphs (DAGs) are used to abstract DNN architectures and progressively optimize\nthe cell structure through edge shrinking. As the search space intrinsically\nreduces as the edges are progressively shrunk, AutoShrink explores more\nflexible search space with even less search time. We evaluate AutoShrink on\nimage classification and language tasks by crafting ShrinkCNN and ShrinkRNN\nmodels. ShrinkCNN is able to achieve up to 48% parameter reduction and save 34%\nMultiply-Accumulates (MACs) on ImageNet-1K with comparable accuracy of\nstate-of-the-art (SOTA) models. Specifically, both ShrinkCNN and ShrinkRNN are\ncrafted within 1.5 GPU hours, which is 7.2x and 6.7x faster than the crafting\ntime of SOTA CNN and RNN models, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:40:00 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Zhang", "Tunhou", ""], ["Cheng", "Hsin-Pai", ""], ["Li", "Zhenwen", ""], ["Yan", "Feng", ""], ["Huang", "Chengyu", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1911.09260", "submitter": "Yifan Cui", "authors": "Yifan Cui, Eric Tchetgen Tchetgen", "title": "A semiparametric instrumental variable approach to optimal treatment\n  regimes under endogeneity", "comments": "To appear in Journal of the American Statistical Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a fast-growing literature on estimating optimal treatment regimes\nbased on randomized trials or observational studies under a key identifying\ncondition of no unmeasured confounding. Because confounding by unmeasured\nfactors cannot generally be ruled out with certainty in observational studies\nor randomized trials subject to noncompliance, we propose a general\ninstrumental variable approach to learning optimal treatment regimes under\nendogeneity. Specifically, we establish identification of both value function\n$E[Y_{\\mathcal{D}(L)}]$ for a given regime $\\mathcal{D}$ and optimal regimes\n$\\text{argmax}_{\\mathcal{D}} E[Y_{\\mathcal{D}(L)}]$ with the aid of a binary\ninstrumental variable, when no unmeasured confounding fails to hold. We also\nconstruct novel multiply robust classification-based estimators. Furthermore,\nwe propose to identify and estimate optimal treatment regimes among those who\nwould comply to the assigned treatment under a standard monotonicity\nassumption. In this latter case, we establish the somewhat surprising result\nthat complier optimal regimes can be consistently estimated without directly\ncollecting compliance information and therefore without the complier average\ntreatment effect itself being identified. Our approach is illustrated via\nextensive simulation studies and a data application on the effect of child\nrearing on labor participation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:10:08 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 00:22:59 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 16:52:58 GMT"}, {"version": "v4", "created": "Thu, 21 May 2020 20:24:14 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 16:09:39 GMT"}, {"version": "v6", "created": "Thu, 25 Jun 2020 20:43:31 GMT"}, {"version": "v7", "created": "Sat, 4 Jul 2020 01:13:19 GMT"}, {"version": "v8", "created": "Mon, 10 Aug 2020 19:35:06 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cui", "Yifan", ""], ["Tchetgen", "Eric Tchetgen", ""]]}, {"id": "1911.09272", "submitter": "Alexander Levine", "authors": "Alexander Levine, Soheil Feizi", "title": "Robustness Certificates for Sparse Adversarial Attacks by Randomized\n  Ablation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, techniques have been developed to provably guarantee the robustness\nof a classifier to adversarial perturbations of bounded L_1 and L_2 magnitudes\nby using randomized smoothing: the robust classification is a consensus of base\nclassifications on randomly noised samples where the noise is additive. In this\npaper, we extend this technique to the L_0 threat model. We propose an\nefficient and certifiably robust defense against sparse adversarial attacks by\nrandomly ablating input features, rather than using additive noise.\nExperimentally, on MNIST, we can certify the classifications of over 50% of\nimages to be robust to any distortion of at most 8 pixels. This is comparable\nto the observed empirical robustness of unprotected classifiers on MNIST to\nmodern L_0 attacks, demonstrating the tightness of the proposed robustness\ncertificate. We also evaluate our certificate on ImageNet and CIFAR-10. Our\ncertificates represent an improvement on those provided in a concurrent work\n(Lee et al. 2019) which uses random noise rather than ablation (median\ncertificates of 8 pixels versus 4 pixels on MNIST; 16 pixels versus 1 pixel on\nImageNet.) Additionally, we empirically demonstrate that our classifier is\nhighly robust to modern sparse adversarial attacks on MNIST. Our\nclassifications are robust, in median, to adversarial perturbations of up to 31\npixels, compared to 22 pixels reported as the state-of-the-art defense, at the\ncost of a slight decrease (around 2.3%) in the classification accuracy. Code is\navailable at https://github.com/alevine0/randomizedAblation/.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:52:32 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Levine", "Alexander", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.09281", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem and Calton Pu", "title": "Event Detection in Noisy Streaming Data with Combination of\n  Corroborative and Probabilistic Sources", "comments": null, "journal-ref": "IEEE Collaboration in Computing 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global physical event detection has traditionally relied on dense coverage of\nphysical sensors around the world; while this is an expensive undertaking,\nthere have not been alternatives until recently. The ubiquity of social\nnetworks and human sensors in the field provides a tremendous amount of\nreal-time, live data about true physical events from around the world. However,\nwhile such human sensor data have been exploited for retrospective large-scale\nevent detection, such as hurricanes or earthquakes, they has been limited to no\nsuccess in exploiting this rich resource for general physical event detection.\n  Prior implementation approaches have suffered from the concept drift\nphenomenon, where real-world data exhibits constant, unknown, unbounded changes\nin its data distribution, making static machine learning models ineffective in\nthe long term. We propose and implement an end-to-end collaborative drift\nadaptive system that integrates corroborative and probabilistic sources to\ndeliver real-time predictions. Furthermore, out system is adaptive to concept\ndrift and performs automated continuous learning to maintain high performance.\nWe demonstrate our approach in a real-time demo available online for landslide\ndisaster detection, with extensibility to other real-world physical events such\nas flooding, wildfires, hurricanes, and earthquakes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 04:19:16 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Suprem", "Abhijit", ""], ["Pu", "Calton", ""]]}, {"id": "1911.09287", "submitter": "Adam Dziedzic", "authors": "Adam Dziedzic and John Paparrizos and Sanjay Krishnan and Aaron Elmore\n  and Michael Franklin", "title": "Band-limited Training and Inference for Convolutional Neural Networks", "comments": "Published at International Conference on Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolutional layers are core building blocks of neural network\narchitectures. In general, a convolutional filter applies to the entire\nfrequency spectrum of the input data. We explore artificially constraining the\nfrequency spectra of these filters and data, called band-limiting, during\ntraining. The frequency domain constraints apply to both the feed-forward and\nback-propagation steps. Experimentally, we observe that Convolutional Neural\nNetworks (CNNs) are resilient to this compression scheme and results suggest\nthat CNNs learn to leverage lower-frequency components. In particular, we\nfound: (1) band-limited training can effectively control the resource usage\n(GPU and memory); (2) models trained with band-limited layers retain high\nprediction accuracy; and (3) requires no modification to existing training\nalgorithms or neural network architectures to use unlike other compression\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 04:43:02 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Dziedzic", "Adam", ""], ["Paparrizos", "John", ""], ["Krishnan", "Sanjay", ""], ["Elmore", "Aaron", ""], ["Franklin", "Michael", ""]]}, {"id": "1911.09290", "submitter": "Zhao Kang", "authors": "Zhao Kang, Wangtao Zhou, Zhitong Zhao, Junming Shao, Meng Han, Zenglin\n  Xu", "title": "Large-scale Multi-view Subspace Clustering in Linear Time", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of multi-view subspace clustering (MVSC) methods have been\nproposed over the past few years. Researchers manage to boost clustering\naccuracy from different points of view. However, many state-of-the-art MVSC\nalgorithms, typically have a quadratic or even cubic complexity, are\ninefficient and inherently difficult to apply at large scales. In the era of\nbig data, the computational issue becomes critical. To fill this gap, we\npropose a large-scale MVSC (LMVSC) algorithm with linear order complexity.\nInspired by the idea of anchor graph, we first learn a smaller graph for each\nview. Then, a novel approach is designed to integrate those graphs so that we\ncan implement spectral clustering on a smaller graph. Interestingly, it turns\nout that our model also applies to single-view scenario. Extensive experiments\non various large-scale benchmark data sets validate the effectiveness and\nefficiency of our approach with respect to state-of-the-art clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:10:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Kang", "Zhao", ""], ["Zhou", "Wangtao", ""], ["Zhao", "Zhitong", ""], ["Shao", "Junming", ""], ["Han", "Meng", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.09291", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro", "title": "Scalable methods for computing state similarity in deterministic Markov\n  Decision Processes", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for computing and approximating bisimulation\nmetrics in Markov Decision Processes (MDPs). Bisimulation metrics are an\nelegant formalism that capture behavioral equivalence between states and\nprovide strong theoretical guarantees on differences in optimal behaviour.\nUnfortunately, their computation is expensive and requires a tabular\nrepresentation of the states, which has thus far rendered them impractical for\nlarge problems. In this paper we present a new version of the metric that is\ntied to a behavior policy in an MDP, along with an analysis of its theoretical\nproperties. We then present two new algorithms for approximating bisimulation\nmetrics in large, deterministic MDPs. The first does so via sampling and is\nguaranteed to converge to the true metric. The second is a differentiable loss\nwhich allows us to learn an approximation even for continuous state MDPs, which\nprior to this work had not been possible.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:11:20 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Castro", "Pablo Samuel", ""]]}, {"id": "1911.09307", "submitter": "Ke Sun", "authors": "Ke Sun, Bing Yu, Zhouchen Lin, Zhanxing Zhu", "title": "Patch-level Neighborhood Interpolation: A General and Effective\n  Graph-based Regularization Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays a crucial role in machine learning models, especially\nfor deep neural networks. The existing regularization techniques mainly reply\non the i.i.d. assumption and only employ the information of the current sample,\nwithout the leverage of neighboring information between samples. In this work,\nwe propose a general regularizer called Patch-level Neighborhood\nInterpolation~(\\textbf{Pani}) that fully exploits the relationship between\nsamples. Furthermore, by explicitly constructing a patch-level graph in the\ndifferent network layers and interpolating the neighborhood features to refine\nthe representation of the current sample, our Patch-level Neighborhood\nInterpolation can then be applied to enhance two popular regularization\nstrategies, namely Virtual Adversarial Training (VAT) and MixUp, yielding their\nneighborhood versions. The first derived \\textbf{Pani VAT} presents a novel way\nto construct non-local adversarial smoothness by incorporating patch-level\ninterpolated perturbations. In addition, the \\textbf{Pani MixUp} method extends\nthe original MixUp regularization to the patch level and then can be developed\nto MixMatch, achieving the state-of-the-art performance. Finally, extensive\nexperiments are conducted to verify the effectiveness of the Patch-level\nNeighborhood Interpolation in both supervised and semi-supervised settings.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:31:59 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sun", "Ke", ""], ["Yu", "Bing", ""], ["Lin", "Zhouchen", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1911.09310", "submitter": "Lantao Yu", "authors": "Yuxuan Song, Lantao Yu, Zhangjie Cao, Zhiming Zhou, Jian Shen, Shuo\n  Shao, Weinan Zhang, Yong Yu", "title": "Improving Unsupervised Domain Adaptation with Variational Information\n  Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to leverage the supervision signal of source domain to\nobtain an accurate model for target domain, where the labels are not available.\nTo leverage and adapt the label information from source domain, most existing\nmethods employ a feature extracting function and match the marginal\ndistributions of source and target domains in a shared feature space. In this\npaper, from the perspective of information theory, we show that representation\nmatching is actually an insufficient constraint on the feature space for\nobtaining a model with good generalization performance in target domain. We\nthen propose variational bottleneck domain adaptation (VBDA), a new domain\nadaptation method which improves feature transferability by explicitly\nenforcing the feature extractor to ignore the task-irrelevant factors and focus\non the information that is essential to the task of interest for both source\nand target domains. Extensive experimental results demonstrate that VBDA\nsignificantly outperforms state-of-the-art methods across three domain\nadaptation benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:07:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Song", "Yuxuan", ""], ["Yu", "Lantao", ""], ["Cao", "Zhangjie", ""], ["Zhou", "Zhiming", ""], ["Shen", "Jian", ""], ["Shao", "Shuo", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1911.09311", "submitter": "Tenavi Nakamura-Zimmerer", "authors": "Tenavi Nakamura-Zimmerer and Daniele Venturi and Qi Gong and Wei Kang", "title": "Density Propagation with Characteristics-based Deep Learning", "comments": "This work has been submitted to IFAC for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty propagation in nonlinear dynamic systems remains an outstanding\nproblem in scientific computing and control. Numerous approaches have been\ndeveloped, but are limited in their capability to tackle problems with more\nthan a few uncertain variables or require large amounts of simulation data. In\nthis paper, we propose a data-driven method for approximating joint probability\ndensity functions (PDFs) of nonlinear dynamic systems with initial condition\nand parameter uncertainty. Our approach leverages on the power of deep learning\nto deal with high-dimensional inputs, but we overcome the need for huge\nquantities of training data by encoding PDF evolution equations directly into\nthe optimization problem. We demonstrate the potential of the proposed method\nby applying it to evaluate the robustness of a feedback controller for a\nsix-dimensional rigid body with parameter uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:09:38 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Nakamura-Zimmerer", "Tenavi", ""], ["Venturi", "Daniele", ""], ["Gong", "Qi", ""], ["Kang", "Wei", ""]]}, {"id": "1911.09322", "submitter": "Minje Park", "authors": "Minje Park", "title": "Data Proxy Generation for Fast and Efficient Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent advances on Neural Architecture Search (NAS), it gains\npopularity in designing best networks for specific tasks. Although it shows\npromising results on many benchmarks and competitions, NAS still suffers from\nits demanding computation cost for searching high dimensional architectural\ndesign space, and this problem becomes even worse when we want to use a\nlarge-scale dataset. If we can make a reliable data proxy for NAS, the\nefficiency of NAS approaches increase accordingly. Our basic observation for\nmaking a data proxy is that each example in a specific dataset has a different\nimpact on NAS process and most of examples are redundant from a relative\naccuracy ranking perspective, which we should preserve when making a data\nproxy. We propose a systematic approach to measure the importance of each\nexample from this relative accuracy ranking point of view, and make a reliable\ndata proxy based on the statistics of training and testing examples. Our\nexperiment shows that we can preserve the almost same relative accuracy ranking\nbetween all possible network configurations even with 10-20$\\times$ smaller\ndata proxy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:39:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Park", "Minje", ""]]}, {"id": "1911.09336", "submitter": "Han Shi", "authors": "Han Shi, Renjie Pi, Hang Xu, Zhenguo Li, James T. Kwok, Tong Zhang", "title": "Bridging the Gap between Sample-based and One-shot Neural Architecture\n  Search with BONAS", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has shown great potentials in finding better\nneural network designs. Sample-based NAS is the most reliable approach which\naims at exploring the search space and evaluating the most promising\narchitectures. However, it is computationally very costly. As a remedy, the\none-shot approach has emerged as a popular technique for accelerating NAS using\nweight-sharing. However, due to the weight-sharing of vastly different\nnetworks, the one-shot approach is less reliable than the sample-based\napproach. In this work, we propose BONAS (Bayesian Optimized Neural\nArchitecture Search), a sample-based NAS framework which is accelerated using\nweight-sharing to evaluate multiple related architectures simultaneously.\nSpecifically, we apply Graph Convolutional Network predictor as a surrogate\nmodel for Bayesian Optimization to select multiple related candidate models in\neach iteration. We then apply weight-sharing to train multiple candidate models\nsimultaneously. This approach not only accelerates the traditional sample-based\napproach significantly, but also keeps its reliability. This is because\nweight-sharing among related architectures are more reliable than those in the\none-shot approach. Extensive experiments are conducted to verify the\neffectiveness of our method over many competing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:29:00 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 09:23:45 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 03:47:56 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 02:13:43 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Shi", "Han", ""], ["Pi", "Renjie", ""], ["Xu", "Hang", ""], ["Li", "Zhenguo", ""], ["Kwok", "James T.", ""], ["Zhang", "Tong", ""]]}, {"id": "1911.09344", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "Convolutional Mixture Density Recurrent Neural Network for Predicting\n  User Location with WiFi Fingerprints", "comments": "5 pages, 3 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting smartphone users activity using WiFi fingerprints has been a\npopular approach for indoor positioning in recent years. However, such a high\ndimensional time-series prediction problem can be very tricky to solve. To\naddress this issue, we propose a novel deep learning model, the convolutional\nmixture density recurrent neural network (CMDRNN), which combines the strengths\nof convolutional neural networks, recurrent neural networks and mixture density\nnetworks. In our model, the CNN sub-model is employed to detect the feature of\nthe high dimensional input, the RNN sub-model is utilized to capture the time\ndependency and the MDN sub-model is for predicting the final output. For\nvalidation, we conduct the experiments on the real-world dataset and the\nobtained results illustrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:47:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09355", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "A Probabilistic Approach for Discovering Daily Human Mobility Patterns\n  with Mobile Data", "comments": "10 pages, 14 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discovering human mobility patterns with geo-location data collected from\nsmartphone users has been a hot research topic in recent years. In this paper,\nwe attempt to discover daily mobile patterns based on GPS data. We view this\nproblem from a probabilistic perspective in order to explore more information\nfrom the original GPS data compared to other conventional methods. A\nnon-parameter Bayesian modeling method, Infinite Gaussian Mixture Model, is\nused to estimate the probability density for the daily mobility. Then, we use\nKullback-Leibler divergence as the metrics to measure the similarity of\ndifferent probability distributions. And combining Infinite Gaussian Mixture\nModel and Kullback-Leibler divergence, we derived an automatic clustering\nalgorithm to discover mobility patterns for each individual user without\nsetting the number of clusters in advance. In the experiments, the\neffectiveness of our method is validated on the real user data collected from\ndifferent users. The results show that the IGMM-based algorithm outperforms the\nGMM-based algorithm. We also test our methods on the dataset with different\nlengths to discover the minimum data length for discovering mobility patterns.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:17:32 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09391", "submitter": "Eivind B{\\o}hn", "authors": "Eivind B{\\o}hn, Signe Moe, Tor Arne Johansen", "title": "Accelerating Reinforcement Learning with Suboptimal Guidance", "comments": "Submitted to IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning in domains with sparse rewards is a difficult problem,\nand a large part of the training process is often spent searching the state\nspace in a more or less random fashion for any learning signals. For control\nproblems, we often have some controller readily available which might be\nsuboptimal but nevertheless solves the problem to some degree. This controller\ncan be used to guide the initial exploration phase of the learning controller\ntowards reward yielding states, reducing the time before refinement of a viable\npolicy can be initiated. In our work, the agent is guided through an auxiliary\nbehaviour cloning loss which is made conditional on a Q-filter, i.e. it is only\napplied in situations where the critic deems the guiding controller to be\nbetter than the agent. The Q-filter provides a natural way to adjust the\nguidance throughout the training process, allowing the agent to exceed the\nguiding controller in a manner that is adaptive to the task at hand and the\nproficiency of the guiding controller. The contribution of this paper lies in\nidentifying shortcomings in previously proposed implementations of the Q-filter\nconcept, and in suggesting some ways these issues can be mitigated. These\nmodifications are tested on the OpenAI Gym Fetch environments, showing clear\nimprovements in adaptivity and yielding increased performance in all robotic\nenvironments tested.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:27:46 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["B\u00f8hn", "Eivind", ""], ["Moe", "Signe", ""], ["Johansen", "Tor Arne", ""]]}, {"id": "1911.09411", "submitter": "Anderson Ara", "authors": "Anderson Ara, Mateus Maia, Samuel Mac\\^edo and Francisco Louzada", "title": "Random Machines: A bagged-weighted support vector model with free kernel\n  choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improvement of statistical learning models in order to increase efficiency in\nsolving classification or regression problems is still a goal pursued by the\nscientific community. In this way, the support vector machine model is one of\nthe most successful and powerful algorithms for those tasks. However, its\nperformance depends directly from the choice of the kernel function and their\nhyperparameters. The traditional choice of them, actually, can be\ncomputationally expensive to do the kernel choice and the tuning processes. In\nthis article, it is proposed a novel framework to deal with the kernel function\nselection called Random Machines. The results improved accuracy and reduced\ncomputational time. The data study was performed in simulated data and over 27\nreal benchmarking datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:11:22 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ara", "Anderson", ""], ["Maia", "Mateus", ""], ["Mac\u00eado", "Samuel", ""], ["Louzada", "Francisco", ""]]}, {"id": "1911.09419", "submitter": "Jie Wang", "authors": "Zhanqiu Zhang, Jianyu Cai, Yongdong Zhang, and Jie Wang", "title": "Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding, which aims to represent entities and relations as\nlow dimensional vectors (or matrices, tensors, etc.), has been shown to be a\npowerful technique for predicting missing links in knowledge graphs. Existing\nknowledge graph embedding models mainly focus on modeling relation patterns\nsuch as symmetry/antisymmetry, inversion, and composition. However, many\nexisting approaches fail to model semantic hierarchies, which are common in\nreal-world applications. To address this challenge, we propose a novel\nknowledge graph embedding model---namely, Hierarchy-Aware Knowledge Graph\nEmbedding (HAKE)---which maps entities into the polar coordinate system. HAKE\nis inspired by the fact that concentric circles in the polar coordinate system\ncan naturally reflect the hierarchy. Specifically, the radial coordinate aims\nto model entities at different levels of the hierarchy, and entities with\nsmaller radii are expected to be at higher levels; the angular coordinate aims\nto distinguish entities at the same level of the hierarchy, and these entities\nare expected to have roughly the same radii but different angles. Experiments\ndemonstrate that HAKE can effectively model the semantic hierarchies in\nknowledge graphs, and significantly outperforms existing state-of-the-art\nmethods on benchmark datasets for the link prediction task.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:37:18 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 12:31:40 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhang", "Zhanqiu", ""], ["Cai", "Jianyu", ""], ["Zhang", "Yongdong", ""], ["Wang", "Jie", ""]]}, {"id": "1911.09427", "submitter": "Guy Shalev", "authors": "Guy Shalev, Ran El-Yaniv, Daniel Klotz, Frederik Kratzert, Asher\n  Metzger, Sella Nevo", "title": "Accurate Hydrologic Modeling Using Less Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint models are a common and important tool in the intersection of machine\nlearning and the physical sciences, particularly in contexts where real-world\nmeasurements are scarce. Recent developments in rainfall-runoff modeling, one\nof the prime challenges in hydrology, show the value of a joint model with\nshared representation in this important context. However, current\nstate-of-the-art models depend on detailed and reliable attributes\ncharacterizing each site to help the model differentiate correctly between the\nbehavior of different sites. This dependency can present a challenge in\ndata-poor regions. In this paper, we show that we can replace the need for such\nlocation-specific attributes with a completely data-driven learned embedding,\nand match previous state-of-the-art results with less information.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:01:19 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shalev", "Guy", ""], ["El-Yaniv", "Ran", ""], ["Klotz", "Daniel", ""], ["Kratzert", "Frederik", ""], ["Metzger", "Asher", ""], ["Nevo", "Sella", ""]]}, {"id": "1911.09430", "submitter": "Tao Zhang", "authors": "Tao Zhang, Yang Cong, Gan Sun, Qianqian Wang, Zhenming Ding", "title": "Visual Tactile Fusion Object Clustering", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object clustering, aiming at grouping similar objects into one cluster with\nan unsupervised strategy, has been extensivelystudied among various data-driven\napplications. However, most existing state-of-the-art object clustering methods\n(e.g., single-view or multi-view clustering methods) only explore visual\ninformation, while ignoring one of most important sensing modalities, i.e.,\ntactile information which can help capture different object properties and\nfurther boost the performance of object clustering task. To effectively benefit\nboth visual and tactile modalities for object clustering, in this paper, we\npropose a deep Auto-Encoder-like Non-negative Matrix Factorization framework\nfor visual-tactile fusion clustering. Specifically, deep matrix factorization\nconstrained by an under-complete Auto-Encoder-like architecture is employed to\njointly learn hierarchical expression of visual-tactile fusion data, and\npreserve the local structure of data generating distribution of visual and\ntactile modalities. Meanwhile, a graph regularizer is introduced to capture the\nintrinsic relations of data samples within each modality. Furthermore, we\npropose a modality-level consensus regularizer to effectively align thevisual\nand tactile data in a common subspace in which the gap between visual and\ntactile data is mitigated. For the model optimization, we present an efficient\nalternating minimization strategy to solve our proposed model. Finally, we\nconduct extensive experiments on public datasets to verify the effectiveness of\nour framework.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:04:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhang", "Tao", ""], ["Cong", "Yang", ""], ["Sun", "Gan", ""], ["Wang", "Qianqian", ""], ["Ding", "Zhenming", ""]]}, {"id": "1911.09431", "submitter": "Thomas Demeester", "authors": "Thomas Demeester", "title": "System Identification with Time-Aware Neural Sequence Models", "comments": "34th AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Established recurrent neural networks are well-suited to solve a wide variety\nof prediction tasks involving discrete sequences. However, they do not perform\nas well in the task of dynamical system identification, when dealing with\nobservations from continuous variables that are unevenly sampled in time, for\nexample due to missing observations. We show how such neural sequence models\ncan be adapted to deal with variable step sizes in a natural way. In\nparticular, we introduce a time-aware and stationary extension of existing\nmodels (including the Gated Recurrent Unit) that allows them to deal with\nunevenly sampled system observations by adapting to the observation times,\nwhile facilitating higher-order temporal behavior. We discuss the properties\nand demonstrate the validity of the proposed approach, based on samples from\ntwo industrial input/output processes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:09:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Demeester", "Thomas", ""]]}, {"id": "1911.09445", "submitter": "Guoqiang Zhang", "authors": "Guoqiang Zhang, Kenta Niwa and W. B. Kleijn", "title": "Approximated Orthonormal Normalisation in Training Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalisation of a deep neural network (DNN) is one major concern when\nemploying the deep learning approach for solving practical problems. In this\npaper we propose a new technique, named approximated orthonormal normalisation\n(AON), to improve the generalisation capacity of a DNN model. Considering a\nweight matrix W from a particular neural layer in the model, our objective is\nto design a function h(W) such that its row vectors are approximately\northogonal to each other while allowing the DNN model to fit the training data\nsufficiently accurate. By doing so, it would avoid co-adaptation among neurons\nof the same layer to be able to improve network-generalisation capacity.\nSpecifically, at each iteration, we first approximate (WW^T)^(-1/2) using its\nTaylor expansion before multiplying the matrix W. After that, the matrix\nproduct is then normalised by applying the spectral normalisation (SN)\ntechnique to obtain h(W). Conceptually speaking, AON is designed to turn\northonormal regularisation into orthonormal normalisation to avoid manual\nbalancing the original and penalty functions. Experimental results show that\nAON yields promising validation performance compared to orthonormal\nregularisation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:57:50 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 11:05:56 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhang", "Guoqiang", ""], ["Niwa", "Kenta", ""], ["Kleijn", "W. B.", ""]]}, {"id": "1911.09450", "submitter": "Haoli Bai", "authors": "Haoli Bai, Jiaxiang Wu, Irwin King, Michael Lyu", "title": "Few Shot Network Compression via Cross Distillation", "comments": "AAAI 2020", "journal-ref": "The Thirty-Fourth AAAI Conference on Artificial Intelligence\n  (AAAI), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has been widely adopted to obtain light-weighted deep\nneural networks. Most prevalent methods, however, require fine-tuning with\nsufficient training data to ensure accuracy, which could be challenged by\nprivacy and security issues. As a compromise between privacy and performance,\nin this paper we investigate few shot network compression: given few samples\nper class, how can we effectively compress the network with negligible\nperformance drop? The core challenge of few shot network compression lies in\nhigh estimation errors from the original network during inference, since the\ncompressed network can easily over-fits on the few training instances. The\nestimation errors could propagate and accumulate layer-wisely and finally\ndeteriorate the network output. To address the problem, we propose cross\ndistillation, a novel layer-wise knowledge distillation approach. By\ninterweaving hidden layers of teacher and student network, layer-wisely\naccumulated estimation errors can be effectively reduced.The proposed method\noffers a general framework compatible with prevalent network compression\ntechniques such as pruning. Extensive experiments on benchmark datasets\ndemonstrate that cross distillation can significantly improve the student\nnetwork's accuracy when only a few training instances are available.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:07:52 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 10:20:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bai", "Haoli", ""], ["Wu", "Jiaxiang", ""], ["King", "Irwin", ""], ["Lyu", "Michael", ""]]}, {"id": "1911.09458", "submitter": "Jinhang Zuo", "authors": "Jinhang Zuo, Xiaoxi Zhang, Carlee Joe-Wong", "title": "Observe Before Play: Multi-armed Bandit with Pre-observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic multi-armed bandit (MAB) problem in a setting\nwhere a player can pay to pre-observe arm rewards before playing an arm in each\nround. Apart from the usual trade-off between exploring new arms to find the\nbest one and exploiting the arm believed to offer the highest reward, we\nencounter an additional dilemma: pre-observing more arms gives a higher chance\nto play the best one, but incurs a larger cost. For the single-player setting,\nwe design an Observe-Before-Play Upper Confidence Bound (OBP-UCB) algorithm for\n$K$ arms with Bernoulli rewards, and prove a $T$-round regret upper bound\n$O(K^2\\log T)$. In the multi-player setting, collisions will occur when players\nselect the same arm to play in the same round. We design a centralized\nalgorithm, C-MP-OBP, and prove its $T$-round regret relative to an offline\ngreedy strategy is upper bounded in $O(\\frac{K^4}{M^2}\\log T)$ for $K$ arms and\n$M$ players. We also propose distributed versions of the C-MP-OBP policy,\ncalled D-MP-OBP and D-MP-Adapt-OBP, achieving logarithmic regret with respect\nto collision-free target policies. Experiments on synthetic data and wireless\nchannel traces show that C-MP-OBP and D-MP-OBP outperform random heuristics and\noffline optimal policies that do not allow pre-observations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:22:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zuo", "Jinhang", ""], ["Zhang", "Xiaoxi", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "1911.09464", "submitter": "Xu Shen", "authors": "Jiwei Yang, Xu Shen, Jun Xing, Xinmei Tian, Houqiang Li, Bing Deng,\n  Jianqiang Huang, Xiansheng Hua", "title": "Quantization Networks", "comments": "10 pages, CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks are highly effective, their high computational\nand memory costs severely challenge their applications on portable devices. As\na consequence, low-bit quantization, which converts a full-precision neural\nnetwork into a low-bitwidth integer version, has been an active and promising\nresearch topic. Existing methods formulate the low-bit quantization of networks\nas an approximation or optimization problem. Approximation-based methods\nconfront the gradient mismatch problem, while optimization-based methods are\nonly suitable for quantizing weights and could introduce high computational\ncost in the training stage. In this paper, we propose a novel perspective of\ninterpreting and implementing neural network quantization by formulating\nlow-bit quantization as a differentiable non-linear function (termed\nquantization function). The proposed quantization function can be learned in a\nlossless and end-to-end manner and works for any weights and activations of\nneural networks in a simple and uniform way. Extensive experiments on image\nclassification and object detection tasks show that our quantization networks\noutperform the state-of-the-art methods. We believe that the proposed method\nwill shed new insights on the interpretation of neural network quantization.\nOur code is available at\nhttps://github.com/aliyun/alibabacloud-quantization-networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:44:03 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 02:37:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yang", "Jiwei", ""], ["Shen", "Xu", ""], ["Xing", "Jun", ""], ["Tian", "Xinmei", ""], ["Li", "Houqiang", ""], ["Deng", "Bing", ""], ["Huang", "Jianqiang", ""], ["Hua", "Xiansheng", ""]]}, {"id": "1911.09471", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz and John\n  Shawe-Taylor", "title": "TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to\n  Open Educational Resources", "comments": "In Proceedings of AAAI Conference on Artificial Intelligence 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in computer-assisted learning systems and the\navailability of open educational resources today promise a pathway to providing\ncost-efficient, high-quality education to large masses of learners. One of the\nmost ambitious use cases of computer-assisted learning is to build a lifelong\nlearning recommendation system. Unlike short-term courses, lifelong learning\npresents unique challenges, requiring sophisticated recommendation models that\naccount for a wide range of factors such as background knowledge of learners or\nnovelty of the material while effectively maintaining knowledge states of\nmasses of learners for significantly longer periods of time (ideally, a\nlifetime). This work presents the foundations towards building a dynamic,\nscalable and transparent recommendation system for education, modelling\nlearner's knowledge from implicit data in the form of engagement with open\neducational resources. We i) use a text ontology based on Wikipedia to\nautomatically extract knowledge components of educational resources and, ii)\npropose a set of online Bayesian strategies inspired by the well-known areas of\nitem response theory and knowledge tracing. Our proposal, TrueLearn, focuses on\nrecommendations for which the learner has enough background knowledge (so they\nare able to understand and learn from the material), and the material has\nenough novelty that would help the learner improve their knowledge about the\nsubject and keep them engaged. We further construct a large open educational\nvideo lectures dataset and test the performance of the proposed algorithms,\nwhich show clear promise towards building an effective educational\nrecommendation system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:56:40 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1911.09501", "submitter": "Kia Khezeli", "authors": "Kia Khezeli and Eilyan Bitar", "title": "Safe Linear Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the safe linear stochastic bandit framework---a generalization\nof linear stochastic bandits---where, in each stage, the learner is required to\nselect an arm with an expected reward that is no less than a predetermined\n(safe) threshold with high probability. We assume that the learner initially\nhas knowledge of an arm that is known to be safe, but not necessarily optimal.\nLeveraging on this assumption, we introduce a learning algorithm that\nsystematically combines known safe arms with exploratory arms to safely expand\nthe set of safe arms over time, while facilitating safe greedy exploitation in\nsubsequent stages. In addition to ensuring the satisfaction of the safety\nconstraint at every stage of play, the proposed algorithm is shown to exhibit\nan expected regret that is no more than $O(\\sqrt{T}\\log (T))$ after $T$ stages\nof play.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:45:43 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Khezeli", "Kia", ""], ["Bitar", "Eilyan", ""]]}, {"id": "1911.09508", "submitter": "Szilvia Lestyan", "authors": "Mina Remeli, Szilvia Lestyan, Gergely Acs, and Gergely Biczok", "title": "Automatic Driver Identification from In-Vehicle Network Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generated by cars is growing at an unprecedented scale. As cars\ngradually become part of the Internet of Things (IoT) ecosystem, several\nstakeholders discover the value of in-vehicle network logs containing the\nmeasurements of the multitude of sensors deployed within the car. This wealth\nof data is also expected to be exploitable by third parties for the purpose of\nprofiling drivers in order to provide personalized, valueadded services.\nAlthough several prior works have successfully demonstrated the feasibility of\ndriver re-identification using the in-vehicle network data captured on the\nvehicle's CAN (Controller Area Network) bus, they inferred the identity of the\ndriver only from known sensor signals (such as the vehicle's speed, brake pedal\nposition, steering wheel angle, etc.) extracted from the CAN messages. However,\ncar manufacturers intentionally do not reveal exact signal location and\nsemantics within CAN logs. We show that the inference of driver identity is\npossible even with off-the-shelf machine learning techniques without\nreverse-engineering the CAN protocol. We demonstrate our approach on a dataset\nof 33 drivers and show that a driver can be re-identified and distinguished\nfrom other drivers with an accuracy of 75-85%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:28:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Remeli", "Mina", ""], ["Lestyan", "Szilvia", ""], ["Acs", "Gergely", ""], ["Biczok", "Gergely", ""]]}, {"id": "1911.09512", "submitter": "Akbar Siami Namin", "authors": "Sima Siami-Namini and Neda Tavakoli and Akbar Siami Namin", "title": "A Comparative Analysis of Forecasting Financial Time Series Using ARIMA,\n  LSTM, and BiLSTM", "comments": "8 pages, 3 figures, 3 tables, 1 listing, IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine and deep learning-based algorithms are the emerging approaches in\naddressing prediction problems in time series. These techniques have been shown\nto produce more accurate results than conventional regression-based modeling.\nIt has been reported that artificial Recurrent Neural Networks (RNN) with\nmemory, such as Long Short-Term Memory (LSTM), are superior compared to\nAutoregressive Integrated Moving Average (ARIMA) with a large margin. The\nLSTM-based models incorporate additional \"gates\" for the purpose of memorizing\nlonger sequences of input data. The major question is that whether the gates\nincorporated in the LSTM architecture already offers a good prediction and\nwhether additional training of data would be necessary to further improve the\nprediction.\n  Bidirectional LSTMs (BiLSTMs) enable additional training by traversing the\ninput data twice (i.e., 1) left-to-right, and 2) right-to-left). The research\nquestion of interest is then whether BiLSTM, with additional training\ncapability, outperforms regular unidirectional LSTM. This paper reports a\nbehavioral analysis and comparison of BiLSTM and LSTM models. The objective is\nto explore to what extend additional layers of training of data would be\nbeneficial to tune the involved parameters. The results show that additional\ntraining of data and thus BiLSTM-based modeling offers better predictions than\nregular LSTM-based models. More specifically, it was observed that BiLSTM\nmodels provide better predictions compared to ARIMA and LSTM models. It was\nalso observed that BiLSTM models reach the equilibrium much slower than\nLSTM-based models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:58:52 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Siami-Namini", "Sima", ""], ["Tavakoli", "Neda", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1911.09514", "submitter": "Tameem Adel", "authors": "Tameem Adel, Han Zhao, Richard E. Turner", "title": "Continual Learning with Adaptive Weights (CLAW)", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to continual learning aim to successfully learn a set of related\ntasks that arrive in an online manner. Recently, several frameworks have been\ndeveloped which enable deep learning to be deployed in this learning scenario.\nA key modelling decision is to what extent the architecture should be shared\nacross tasks. On the one hand, separately modelling each task avoids\ncatastrophic forgetting but it does not support transfer learning and leads to\nlarge models. On the other hand, rigidly specifying a shared component and a\ntask-specific part enables task transfer and limits the model size, but it is\nvulnerable to catastrophic forgetting and restricts the form of task-transfer\nthat can occur. Ideally, the network should adaptively identify which parts of\nthe network to share in a data driven way. Here we introduce such an approach\ncalled Continual Learning with Adaptive Weights (CLAW), which is based on\nprobabilistic modelling and variational inference. Experiments show that CLAW\nachieves state-of-the-art performance on six benchmarks in terms of overall\ncontinual learning performance, as measured by classification accuracy, and in\nterms of addressing catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:59:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 01:00:11 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Adel", "Tameem", ""], ["Zhao", "Han", ""], ["Turner", "Richard E.", ""]]}, {"id": "1911.09537", "submitter": "Jindong Gu", "authors": "Jindong Gu and Volker Tresp", "title": "Neural Network Memorization Dissection", "comments": "Workshop on Machine Learning with Guarantees, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) can easily fit a random labeling of the training\ndata with zero training error. What is the difference between DNNs trained with\nrandom labels and the ones trained with true labels? Our paper answers this\nquestion with two contributions. First, we study the memorization properties of\nDNNs. Our empirical experiments shed light on how DNNs prioritize the learning\nof simple input patterns. In the second part, we propose to measure the\nsimilarity between what different DNNs have learned and memorized. With the\nproposed approach, we analyze and compare DNNs trained on data with true labels\nand random labels. The analysis shows that DNNs have \\textit{One way to Learn}\nand \\textit{N ways to Memorize}. We also use gradient information to gain an\nunderstanding of the analysis results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:24:55 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Gu", "Jindong", ""], ["Tresp", "Volker", ""]]}, {"id": "1911.09539", "submitter": "Andr\\'e Hottung", "authors": "Andr\\'e Hottung and Kevin Tierney", "title": "Neural Large Neighborhood Search for the Capacitated Vehicle Routing\n  Problem", "comments": null, "journal-ref": "ECAI 2020: 443-450", "doi": "10.3233/FAIA200124", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning how to automatically solve optimization problems has the potential\nto provide the next big leap in optimization technology. The performance of\nautomatically learned heuristics on routing problems has been steadily\nimproving in recent years, but approaches based purely on machine learning are\nstill outperformed by state-of-the-art optimization methods. To close this\nperformance gap, we propose a novel large neighborhood search (LNS) framework\nfor vehicle routing that integrates learned heuristics for generating new\nsolutions. The learning mechanism is based on a deep neural network with an\nattention mechanism and has been especially designed to be integrated into an\nLNS search setting. We evaluate our approach on the capacitated vehicle routing\nproblem (CVRP) and the split delivery vehicle routing problem (SDVRP). On CVRP\ninstances with up to 297 customers, our approach significantly outperforms an\nLNS that uses only handcrafted heuristics and a well-known heuristic from the\nliterature. Furthermore, we show for the CVRP and the SDVRP that our approach\nsurpasses the performance of existing machine learning approaches and comes\nclose to the performance of state-of-the-art optimization approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:29:41 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 16:45:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hottung", "Andr\u00e9", ""], ["Tierney", "Kevin", ""]]}, {"id": "1911.09554", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Pedro H. C. Avelar, Anderson R. Tavares, Marco Gori, Luis C. Lamb", "title": "Discrete and Continuous Deep Residual Learning Over Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the use of continuous residual modules for graph\nkernels in Graph Neural Networks. We show how both discrete and continuous\nresidual layers allow for more robust training, being that continuous residual\nlayers are those which are applied by integrating through an Ordinary\nDifferential Equation (ODE) solver to produce their output. We experimentally\nshow that these residuals achieve better results than the ones with\nnon-residual modules when multiple layers are used, mitigating the low-pass\nfiltering effect of GCN-based models. Finally, we apply and analyse the\nbehaviour of these techniques and give pointers to how this technique can be\nuseful in other domains by allowing more predictable behaviour under dynamic\ntimes of computation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:48:15 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 11:15:03 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Tavares", "Anderson R.", ""], ["Gori", "Marco", ""], ["Lamb", "Luis C.", ""]]}, {"id": "1911.09559", "submitter": "Jed Duersch", "authors": "Jed A. Duersch and Thomas A. Catanach", "title": "Generalizing Information to the Evolution of Rational Belief", "comments": null, "journal-ref": null, "doi": "10.3390/e22010108", "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory provides a mathematical foundation to measure uncertainty\nin belief. Belief is represented by a probability distribution that captures\nour understanding of an outcome's plausibility. Information measures based on\nShannon's concept of entropy include realization information, Kullback-Leibler\ndivergence, Lindley's information in experiment, cross entropy, and mutual\ninformation.\n  We derive a general theory of information from first principles that accounts\nfor evolving belief and recovers all of these measures. Rather than simply\ngauging uncertainty, information is understood in this theory to measure change\nin belief. We may then regard entropy as the information we expect to gain upon\nrealization of a discrete latent random variable.\n  This theory of information is compatible with the Bayesian paradigm in which\nrational belief is updated as evidence becomes available. Furthermore, this\ntheory admits novel measures of information with well-defined properties, which\nwe explore in both analysis and experiment. This view of information\nilluminates the study of machine learning by allowing us to quantify\ninformation captured by a predictive model and distinguish it from residual\ninformation contained in training data. We gain related insights regarding\nfeature selection, anomaly detection, and novel Bayesian approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:54:43 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 23:30:31 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Duersch", "Jed A.", ""], ["Catanach", "Thomas A.", ""]]}, {"id": "1911.09560", "submitter": "Kai Arulkumaran", "authors": "Andrea Agostinelli, Kai Arulkumaran, Marta Sarrico, Pierre Richemond,\n  Anil Anthony Bharath", "title": "Memory-Efficient Episodic Control Reinforcement Learning with Dynamic\n  Online k-means", "comments": "Workshop on Biological and Artificial Reinforcement Learning, NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neuro-inspired episodic control (EC) methods have been developed to\novercome the data-inefficiency of standard deep reinforcement learning\napproaches. Using non-/semi-parametric models to estimate the value function,\nthey learn rapidly, retrieving cached values from similar past states. In\nrealistic scenarios, with limited resources and noisy data, maintaining\nmeaningful representations in memory is essential to speed up the learning and\navoid catastrophic forgetting. Unfortunately, EC methods have a large space and\ntime complexity. We investigate different solutions to these problems based on\nprioritising and ranking stored states, as well as online clustering\ntechniques. We also propose a new dynamic online k-means algorithm that is both\ncomputationally-efficient and yields significantly better performance at\nsmaller memory sizes; we validate this approach on classic reinforcement\nlearning environments and Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:54:49 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Agostinelli", "Andrea", ""], ["Arulkumaran", "Kai", ""], ["Sarrico", "Marta", ""], ["Richemond", "Pierre", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1911.09564", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Francesco Orabona", "title": "Parameter-Free Locally Differentially Private Stochastic Subgradient\n  Descent", "comments": "to appear at Privacy in Machine Learning (PriML) workshop, NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a convex risk with stochastic\nsubgradients guaranteeing $\\epsilon$-locally differentially private\n($\\epsilon$-LDP). While it has been shown that stochastic optimization is\npossible with $\\epsilon$-LDP via the standard SGD (Song et al., 2013), its\nconvergence rate largely depends on the learning rate, which must be tuned via\nrepeated runs. Further, tuning is detrimental to privacy loss since it\nsignificantly increases the number of gradient requests. In this work, we\npropose BANCO (Betting Algorithm for Noisy COins), the first $\\epsilon$-LDP SGD\nalgorithm that essentially matches the convergence rate of the tuned SGD\nwithout any learning rate parameter, reducing privacy loss and saving privacy\nbudget.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:58:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Orabona", "Francesco", ""]]}, {"id": "1911.09576", "submitter": "Gordon MacDonald", "authors": "Gordon MacDonald and Andrew Godbout and Bryn Gillcash and Stephanie\n  Cairns", "title": "Volume-preserving Neural Networks", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to addressing the vanishing (or exploding)\ngradient problem in deep neural networks. We construct a new architecture for\ndeep neural networks where all layers (except the output layer) of the network\nare a combination of rotation, permutation, diagonal, and activation sublayers\nwhich are all volume preserving. Our approach replaces the standard weight\nmatrix of a neural network with a combination of diagonal, rotational and\npermutation matrices, all of which are volume-preserving. We introduce a\ncoupled activation function allowing us to preserve volume even in the\nactivation function portion of a neural network layer. This control on the\nvolume forces the gradient (on average) to maintain equilibrium and not explode\nor vanish. To demonstrate our architecture we apply our volume-preserving\nneural network model to two standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:10:41 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 17:29:50 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 16:05:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["MacDonald", "Gordon", ""], ["Godbout", "Andrew", ""], ["Gillcash", "Bryn", ""], ["Cairns", "Stephanie", ""]]}, {"id": "1911.09592", "submitter": "Arindam Sengupta", "authors": "Arindam Sengupta, Feng Jin, Renyuan Zhang and Siyang Cao", "title": "mm-Pose: Real-Time Human Skeletal Posture Estimation using mmWave Radars\n  and CNNs", "comments": "Submitted to IEEE Sensors Journal", "journal-ref": null, "doi": "10.1109/JSEN.2020.2991741", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, mm-Pose, a novel approach to detect and track human skeletons\nin real-time using an mmWave radar, is proposed. To the best of the authors'\nknowledge, this is the first method to detect >15 distinct skeletal joints\nusing mmWave radar reflection signals. The proposed method would find several\napplications in traffic monitoring systems, autonomous vehicles, patient\nmonitoring systems and defense forces to detect and track human skeleton for\neffective and preventive decision making in real-time. The use of radar makes\nthe system operationally robust to scene lighting and adverse weather\nconditions. The reflected radar point cloud in range, azimuth and elevation are\nfirst resolved and projected in Range-Azimuth and Range-Elevation planes. A\nnovel low-size high-resolution radar-to-image representation is also presented,\nthat overcomes the sparsity in traditional point cloud data and offers\nsignificant reduction in the subsequent machine learning architecture. The RGB\nchannels were assigned with the normalized values of range, elevation/azimuth\nand the power level of the reflection signals for each of the points. A forked\nCNN architecture was used to predict the real-world position of the skeletal\njoints in 3-D space, using the radar-to-image representation. The proposed\nmethod was tested for a single human scenario for four primary motions, (i)\nWalking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging\nboth arms to validate accurate predictions for motion in range, azimuth and\nelevation. The detailed methodology, implementation, challenges, and validation\nresults are presented.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:37:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sengupta", "Arindam", ""], ["Jin", "Feng", ""], ["Zhang", "Renyuan", ""], ["Cao", "Siyang", ""]]}, {"id": "1911.09615", "submitter": "Kai Arulkumaran", "authors": "Marta Sarrico, Kai Arulkumaran, Andrea Agostinelli, Pierre Richemond,\n  Anil Anthony Bharath", "title": "Sample-Efficient Reinforcement Learning with Maximum Entropy Mellowmax\n  Episodic Control", "comments": "Workshop on Biological and Artificial Reinforcement Learning, NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have enabled reinforcement learning to scale to more complex\nand challenging domains, but these methods typically require large quantities\nof training data. An alternative is to use sample-efficient episodic control\nmethods: neuro-inspired algorithms which use non-/semi-parametric models that\npredict values based on storing and retrieving previously experienced\ntransitions. One way to further improve the sample efficiency of these\napproaches is to use more principled exploration strategies. In this work, we\ntherefore propose maximum entropy mellowmax episodic control (MEMEC), which\nsamples actions according to a Boltzmann policy with a state-dependent\ntemperature. We demonstrate that MEMEC outperforms other uncertainty- and\nsoftmax-based exploration methods on classic reinforcement learning\nenvironments and Atari games, achieving both more rapid learning and higher\nfinal rewards.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 17:19:36 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sarrico", "Marta", ""], ["Arulkumaran", "Kai", ""], ["Agostinelli", "Andrea", ""], ["Richemond", "Pierre", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1911.09647", "submitter": "David Kofler", "authors": "Lukas Gonon, Philipp Grohs, Arnulf Jentzen, David Kofler, and David\n  \\v{S}i\\v{s}ka", "title": "Uniform error estimates for artificial neural network approximations for\n  heat equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, artificial neural networks (ANNs) in conjunction with stochastic\ngradient descent optimization methods have been employed to approximately\ncompute solutions of possibly rather high-dimensional partial differential\nequations (PDEs). Very recently, there have also been a number of rigorous\nmathematical results in the scientific literature which examine the\napproximation capabilities of such deep learning based approximation algorithms\nfor PDEs. These mathematical results from the scientific literature prove in\npart that algorithms based on ANNs are capable of overcoming the curse of\ndimensionality in the numerical approximation of high-dimensional PDEs. In\nthese mathematical results from the scientific literature usually the error\nbetween the solution of the PDE and the approximating ANN is measured in the\n$L^p$-sense with respect to some $p \\in [1,\\infty)$ and some probability\nmeasure. In many applications it is, however, also important to control the\nerror in a uniform $L^\\infty$-sense. The key contribution of the main result of\nthis article is to develop the techniques to obtain error estimates between\nsolutions of PDEs and approximating ANNs in the uniform $L^\\infty$-sense. In\nparticular, we prove that the number of parameters of an ANN to uniformly\napproximate the classical solution of the heat equation in a region $ [a,b]^d $\nfor a fixed time point $ T \\in (0,\\infty) $ grows at most polynomially in the\ndimension $ d \\in \\mathbb{N} $ and the reciprocal of the approximation\nprecision $ \\varepsilon > 0 $. This shows that ANNs can overcome the curse of\ndimensionality in the numerical approximation of the heat equation when the\nerror is measured in the uniform $L^\\infty$-norm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:29:17 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 08:00:25 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 05:53:30 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gonon", "Lukas", ""], ["Grohs", "Philipp", ""], ["Jentzen", "Arnulf", ""], ["Kofler", "David", ""], ["\u0160i\u0161ka", "David", ""]]}, {"id": "1911.09660", "submitter": "Sabber Ahamed", "authors": "Sabber Ahamed", "title": "Estimating uncertainty of earthquake rupture using Bayesian neural\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural networks (BNN) are the probabilistic model that combines the\nstrengths of both neural network (NN) and stochastic processes. As a result,\nBNN can combat overfitting and perform well in applications where data is\nlimited. Earthquake rupture study is such a problem where data is insufficient,\nand scientists have to rely on many trial and error numerical or physical\nmodels. Lack of resources and computational expenses, often, it becomes hard to\ndetermine the reasons behind the earthquake rupture. In this work, a BNN has\nbeen used (1) to combat the small data problem and (2) to find out the\nparameter combinations responsible for earthquake rupture and (3) to estimate\nthe uncertainty associated with earthquake rupture. Two thousand rupture\nsimulations are used to train and test the model. A simple 2D rupture geometry\nis considered where the fault has a Gaussian geometric heterogeneity at the\ncenter, and eight parameters vary in each simulation. The test F1-score of BNN\n(0.8334), which is 2.34% higher than plain NN score. Results show that the\nparameters of rupture propagation have higher uncertainty than the rupture\narrest. Normal stresses play a vital role in determining rupture propagation\nand are also the highest source of uncertainty, followed by the dynamic\nfriction coefficient. Shear stress has a moderate role, whereas the geometric\nfeatures such as the width and height of the fault are least significant and\nuncertain.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:42:35 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ahamed", "Sabber", ""]]}, {"id": "1911.09669", "submitter": "Alex Labach", "authors": "Alex Labach and Shahrokh Valaee", "title": "Regularizing Neural Networks by Stochastically Training Layer Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout and similar stochastic neural network regularization methods are\noften interpreted as implicitly averaging over a large ensemble of models. We\npropose STE (stochastically trained ensemble) layers, which enhance the\naveraging properties of such methods by training an ensemble of weight matrices\nwith stochastic regularization while explicitly averaging outputs. This\nprovides stronger regularization with no additional computational cost at test\ntime. We show consistent improvement on various image classification tasks\nusing standard network topologies.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:56:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Labach", "Alex", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1911.09676", "submitter": "Deepak Pathak", "authors": "Pratyusha Sharma, Deepak Pathak, Abhinav Gupta", "title": "Third-Person Visual Imitation Learning via Decoupled Hierarchical\n  Controller", "comments": "Accepted at NeurIPS 2019. Videos at\n  https://pathak22.github.io/hierarchical-imitation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalized setup for learning from demonstration to build an\nagent that can manipulate novel objects in unseen scenarios by looking at only\na single video of human demonstration from a third-person perspective. To\naccomplish this goal, our agent should not only learn to understand the intent\nof the demonstrated third-person video in its context but also perform the\nintended task in its environment configuration. Our central insight is to\nenforce this structure explicitly during learning by decoupling what to achieve\n(intended task) from how to perform it (controller). We propose a hierarchical\nsetup where a high-level module learns to generate a series of first-person\nsub-goals conditioned on the third-person video demonstration, and a low-level\ncontroller predicts the actions to achieve those sub-goals. Our agent acts from\nraw image observations without any access to the full state information. We\nshow results on a real robotic platform using Baxter for the manipulation tasks\nof pouring and placing objects in a box. Project video and code are at\nhttps://pathak22.github.io/hierarchical-imitation/\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:59:29 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sharma", "Pratyusha", ""], ["Pathak", "Deepak", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1911.09698", "submitter": "Christian P. Robert", "authors": "Wu Changye and Christian P. Robert", "title": "Parallelising MCMC via Random Forests", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  For Bayesian computation in big data contexts, the divide-and-conquer MCMC\nconcept splits the whole data set into batches, runs MCMC algorithms separately\nover each batch to produce samples of parameters, and combines them to produce\nan approximation of the target distribution. In this article, we embed random\nforests into this framework and use each subposterior/partial-posterior as a\nproposal distribution to implement importance sampling. Unlike the existing\ndivide-and-conquer MCMC, our methods are based on scaled subposteriors, whose\nscale factors are not necessarily restricted to being equal to one or to the\nnumber of subsets. Through several experiments, we show that our methods work\nwell with models ranging from Gaussian cases to strongly non-Gaussian cases,\nand include model misspecification.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:02:13 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Changye", "Wu", ""], ["Robert", "Christian P.", ""]]}, {"id": "1911.09704", "submitter": "Tanner Bohn", "authors": "Charles X. Ling and Tanner Bohn", "title": "A Conceptual Framework for Lifelong Learning", "comments": "39 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn a variety of concepts and skills incrementally over the\ncourse of their lives while exhibiting many desirable properties, such as\ncontinual learning without forgetting, forward transfer and backward transfer\nof knowledge, and learning a new concept or task with only a few examples.\nSeveral lines of machine learning research, such as lifelong learning, few-shot\nlearning, and transfer learning, attempt to capture these properties. However,\nmost previous approaches can only demonstrate subsets of these properties,\noften by different complex mechanisms. In this work, we propose a simple yet\npowerful unified framework that supports almost all of these properties and\napproaches through one central mechanism. We also draw connections between many\npeculiarities of human learning (such as memory loss and \"rain man\") and our\nframework. While we do not present any state-of-the-art results, we hope that\nthis conceptual framework provides a novel perspective on existing work and\nproposes many new research directions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:08:18 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 21:38:51 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 23:01:24 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 18:34:47 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ling", "Charles X.", ""], ["Bohn", "Tanner", ""]]}, {"id": "1911.09721", "submitter": "Raj Kumar Maity", "authors": "Avishek Ghosh, Raj Kumar Maity, Swanand Kadhe, Arya Mazumdar and\n  Kannan Ramchandran", "title": "Communication-Efficient and Byzantine-Robust Distributed Learning with\n  Error Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a communication-efficient distributed learning algorithm that is\nrobust against Byzantine worker machines. We propose and analyze a distributed\ngradient-descent algorithm that performs a simple thresholding based on\ngradient norms to mitigate Byzantine failures. We show the (statistical)\nerror-rate of our algorithm matches that of Yin et al.~\\cite{dong}, which uses\nmore complicated schemes (coordinate-wise median, trimmed mean). Furthermore,\nfor communication efficiency, we consider a generic class of\n$\\delta$-approximate compressors from Karimireddi et al.~\\cite{errorfeed} that\nencompasses sign-based compressors and top-$k$ sparsification. Our algorithm\nuses compressed gradients and gradient norms for aggregation and Byzantine\nremoval respectively. We establish the statistical error rate for non-convex\nsmooth loss functions. We show that, in certain range of the compression factor\n$\\delta$, the (order-wise) rate of convergence is not affected by the\ncompression operation. Moreover, we analyze the compressed gradient descent\nalgorithm with error feedback (proposed in \\cite{errorfeed}) in a distributed\nsetting and in the presence of Byzantine worker machines. We show that\nexploiting error feedback improves the statistical error rate. Finally, we\nexperimentally validate our results and show good performance in convergence\nfor convex (least-square regression) and non-convex (neural network training)\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:39:53 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 20:04:58 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 20:27:47 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 20:21:26 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Ghosh", "Avishek", ""], ["Maity", "Raj Kumar", ""], ["Kadhe", "Swanand", ""], ["Mazumdar", "Arya", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1911.09722", "submitter": "A Lakshmi", "authors": "Lakshmi Annamalai, Anirban Chakraborty and Chetan Singh Thakur", "title": "EvAn: Neuromorphic Event-based Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-based cameras are bio-inspired novel sensors that asynchronously record\nchanges in illumination in the form of events, thus resulting in significant\nadvantages over conventional cameras in terms of low power utilization, high\ndynamic range, and no motion blur. Moreover, such cameras, by design, encode\nonly the relative motion between the scene and the sensor (and not the static\nbackground) to yield a very sparse data structure, which can be utilized for\nvarious motion analytics tasks. In this paper, for the first time in event data\nanalytics community, we leverage these advantages of an event camera towards a\ncritical vision application - video anomaly detection. We propose to model the\nmotion dynamics in the event domain with dual discriminator conditional\nGenerative adversarial Network (cGAN) built on state-of-the-art architectures.\nTo adapt event data for using as input to cGAN, we also put forward a deep\nlearning solution to learn a novel representation of event data, which retains\nthe sparsity of the data as well as encode the temporal information readily\navailable from these sensors. Since there is no existing dataset for anomaly\ndetection in event domain, we also provide an anomaly detection event dataset\nwith an exhaustive set of anomalies. Careful analysis reveals that the proposed\nmethod results in huge reduction in computational complexity as compared to\nprevious state-of-the-art conventional anomaly detection networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:43:51 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 19:23:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Annamalai", "Lakshmi", ""], ["Chakraborty", "Anirban", ""], ["Thakur", "Chetan Singh", ""]]}, {"id": "1911.09724", "submitter": "Xiuyuan Lu", "authors": "Xiuyuan Lu, Benjamin Van Roy", "title": "Information-Theoretic Confidence Bounds for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We integrate information-theoretic concepts into the design and analysis of\noptimistic algorithms and Thompson sampling. By making a connection between\ninformation-theoretic quantities and confidence bounds, we obtain results that\nrelate the per-period performance of the agent with its information gain about\nthe environment, thus explicitly characterizing the exploration-exploitation\ntradeoff. The resulting cumulative regret bound depends on the agent's\nuncertainty over the environment and quantifies the value of prior information.\nWe show applicability of this approach to several environments, including\nlinear bandits, tabular MDPs, and factored MDPs. These examples demonstrate the\npotential of a general information-theoretic approach for the design and\nanalysis of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:48:43 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lu", "Xiuyuan", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1911.09737", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Shankar Krishnan", "title": "Filter Response Normalization Layer: Eliminating Batch Dependence in the\n  Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Batch Normalization (BN) uses mini-batch statistics to normalize the\nactivations during training, introducing dependence between mini-batch\nelements. This dependency can hurt the performance if the mini-batch size is\ntoo small, or if the elements are correlated. Several alternatives, such as\nBatch Renormalization and Group Normalization (GN), have been proposed to\naddress this issue. However, they either do not match the performance of BN for\nlarge batches, or still exhibit degradation in performance for smaller batches,\nor introduce artificial constraints on the model architecture. In this paper we\npropose the Filter Response Normalization (FRN) layer, a novel combination of a\nnormalization and an activation function, that can be used as a replacement for\nother normalizations and activations. Our method operates on each activation\nchannel of each batch element independently, eliminating the dependency on\nother batch elements. Our method outperforms BN and other alternatives in a\nvariety of settings for all batch sizes. FRN layer performs $\\approx 0.7-1.0\\%$\nbetter than BN on top-1 validation accuracy with large mini-batch sizes for\nImagenet classification using InceptionV3 and ResnetV2-50 architectures.\nFurther, it performs $>1\\%$ better than GN on the same problem in the small\nmini-batch size regime. For object detection problem on COCO dataset, FRN layer\noutperforms all other methods by at least $0.3-0.5\\%$ in all batch size\nregimes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:32:04 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 04:19:08 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Singh", "Saurabh", ""], ["Krishnan", "Shankar", ""]]}, {"id": "1911.09771", "submitter": "Ruqi Zhang", "authors": "Ruqi Zhang and Christopher De Sa", "title": "Poisson-Minibatching for Gibbs Sampling with Convergence Rate Guarantees", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling is a Markov chain Monte Carlo method that is often used for\nlearning and inference on graphical models. Minibatching, in which a small\nrandom subset of the graph is used at each iteration, can help make Gibbs\nsampling scale to large graphical models by reducing its computational cost. In\nthis paper, we propose a new auxiliary-variable minibatched Gibbs sampling\nmethod, {\\it Poisson-minibatching Gibbs}, which both produces unbiased samples\nand has a theoretical guarantee on its convergence rate. In comparison to\nprevious minibatched Gibbs algorithms, Poisson-minibatching Gibbs supports fast\nsampling from continuous state spaces and avoids the need for a\nMetropolis-Hastings correction on discrete state spaces. We demonstrate the\neffectiveness of our method on multiple applications and in comparison with\nboth plain Gibbs and previous minibatched methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:05:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Ruqi", ""], ["De Sa", "Christopher", ""]]}, {"id": "1911.09777", "submitter": "Stacey Truex", "authors": "Stacey Truex, Ling Liu, Mehmet Emre Gursoy, Wenqi Wei, Lei Yu", "title": "Effects of Differential Privacy and Data Skewness on Membership\n  Inference Vulnerability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference attacks seek to infer the membership of individual\ntraining instances of a privately trained model. This paper presents a\nmembership privacy analysis and evaluation system, called MPLens, with three\nunique contributions. First, through MPLens, we demonstrate how membership\ninference attack methods can be leveraged in adversarial machine learning.\nSecond, through MPLens, we highlight how the vulnerability of pre-trained\nmodels under membership inference attack is not uniform across all classes,\nparticularly when the training data itself is skewed. We show that risk from\nmembership inference attacks is routinely increased when models use skewed\ntraining data. Finally, we investigate the effectiveness of differential\nprivacy as a mitigation technique against membership inference attacks. We\ndiscuss the trade-offs of implementing such a mitigation strategy with respect\nto the model complexity, the learning task complexity, the dataset complexity\nand the privacy parameter settings. Our empirical results reveal that (1)\nminority groups within skewed datasets display increased risk for membership\ninference and (2) differential privacy presents many challenging trade-offs as\na mitigation technique to membership inference risk.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:54:40 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Truex", "Stacey", ""], ["Liu", "Ling", ""], ["Gursoy", "Mehmet Emre", ""], ["Wei", "Wenqi", ""], ["Yu", "Lei", ""]]}, {"id": "1911.09781", "submitter": "Lu Jiang", "authors": "Lu Jiang, Di Huang, Mason Liu, Weilong Yang", "title": "Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels", "comments": "published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing controlled experiments on noisy data is essential in understanding\ndeep learning across noise levels. Due to the lack of suitable datasets,\nprevious research has only examined deep learning on controlled synthetic label\nnoise, and real-world label noise has never been studied in a controlled\nsetting. This paper makes three contributions. First, we establish the first\nbenchmark of controlled real-world label noise from the web. This new benchmark\nenables us to study the web label noise in a controlled setting for the first\ntime. The second contribution is a simple but effective method to overcome both\nsynthetic and real noisy labels. We show that our method achieves the best\nresult on our dataset as well as on two public benchmarks (CIFAR and\nWebVision). Third, we conduct the largest study by far into understanding deep\nneural networks trained on noisy labels across different noise levels, noise\ntypes, network architectures, and training settings. The data and code are\nreleased at the following link: http://www.lujiang.info/cnlw.html\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:05:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 03:27:24 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 06:07:44 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jiang", "Lu", ""], ["Huang", "Di", ""], ["Liu", "Mason", ""], ["Yang", "Weilong", ""]]}, {"id": "1911.09783", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Tianjun Ma, Soujanya Poria, Louis-Philippe Morency", "title": "WildMix Dataset and Spectro-Temporal Transformer Model for Monoaural\n  Audio Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monoaural audio source separation is a challenging research area in machine\nlearning. In this area, a mixture containing multiple audio sources is given,\nand a model is expected to disentangle the mixture into isolated atomic\nsources. In this paper, we first introduce a challenging new dataset for\nmonoaural source separation called WildMix. WildMix is designed with the goal\nof extending the boundaries of source separation beyond what previous datasets\nin this area would allow. It contains diverse in-the-wild recordings from 25\ndifferent sound classes, combined with each other using arbitrary composition\npolicies. Source separation often requires modeling long-range dependencies in\nboth temporal and spectral domains. To this end, we introduce a novel\ntrasnformer-based model called Spectro-Temporal Transformer (STT). STT utilizes\na specialized encoder, called Spectro-Temporal Encoder (STE). STE highlights\ntemporal and spectral components of sources within a mixture, using a\nself-attention mechanism. It subsequently disentangles them in a hierarchical\nmanner. In our experiments, STT swiftly outperforms various previous baselines\nfor monoaural source separation on the challenging WildMix dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:23:02 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zadeh", "Amir", ""], ["Ma", "Tianjun", ""], ["Poria", "Soujanya", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1911.09785", "submitter": "David Berthelot", "authors": "David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Kihyuk\n  Sohn, Han Zhang, Colin Raffel", "title": "ReMixMatch: Semi-Supervised Learning with Distribution Alignment and\n  Augmentation Anchoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the recently-proposed \"MixMatch\" semi-supervised learning\nalgorithm by introducing two new techniques: distribution alignment and\naugmentation anchoring. Distribution alignment encourages the marginal\ndistribution of predictions on unlabeled data to be close to the marginal\ndistribution of ground-truth labels. Augmentation anchoring feeds multiple\nstrongly augmented versions of an input into the model and encourages each\noutput to be close to the prediction for a weakly-augmented version of the same\ninput. To produce strong augmentations, we propose a variant of AutoAugment\nwhich learns the augmentation policy while the model is being trained. Our new\nalgorithm, dubbed ReMixMatch, is significantly more data-efficient than prior\nwork, requiring between $5\\times$ and $16\\times$ less data to reach the same\naccuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\\%$\naccuracy (compared to MixMatch's accuracy of $93.58\\%$ with $4{,}000$ examples)\nand a median accuracy of $84.92\\%$ with just four labels per class. We make our\ncode and data open-source at https://github.com/google-research/remixmatch.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:44:25 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:14:46 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Berthelot", "David", ""], ["Carlini", "Nicholas", ""], ["Cubuk", "Ekin D.", ""], ["Kurakin", "Alex", ""], ["Sohn", "Kihyuk", ""], ["Zhang", "Han", ""], ["Raffel", "Colin", ""]]}, {"id": "1911.09787", "submitter": "Busra Celikkaya", "authors": "Ming Zhu, Busra Celikkaya, Parminder Bhatia, Chandan K. Reddy", "title": "LATTE: Latent Type Modeling for Biomedical Entity Linking", "comments": "AAAI 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of linking mentions of named entities in natural\nlanguage text, to entities in a curated knowledge-base. This is of significant\nimportance in the biomedical domain, where it could be used to semantically\nannotate a large volume of clinical records and biomedical literature, to\nstandardized concepts described in an ontology such as Unified Medical Language\nSystem (UMLS). We observe that with precise type information, entity\ndisambiguation becomes a straightforward task. However, fine-grained type\ninformation is usually not available in biomedical domain. Thus, we propose\nLATTE, a LATent Type Entity Linking model, that improves entity linking by\nmodeling the latent fine-grained type information about mentions and entities.\nUnlike previous methods that perform entity linking directly between the\nmentions and the entities, LATTE jointly does entity disambiguation, and latent\nfine-grained type learning, without direct supervision. We evaluate our model\non two biomedical datasets: MedMentions, a large scale public dataset annotated\nwith UMLS concepts, and a de-identified corpus of dictated doctor's notes that\nhas been annotated with ICD concepts. Extensive experimental evaluation shows\nour model achieves significant performance improvements over several\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:55:15 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 23:17:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhu", "Ming", ""], ["Celikkaya", "Busra", ""], ["Bhatia", "Parminder", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1911.09798", "submitter": "Sebastian Bruch", "authors": "Sebastian Bruch", "title": "An Alternative Cross Entropy Loss for Learning-to-Rank", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3449794", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Listwise learning-to-rank methods form a powerful class of ranking algorithms\nthat are widely adopted in applications such as information retrieval. These\nalgorithms learn to rank a set of items by optimizing a loss that is a function\nof the entire set -- as a surrogate to a typically non-differentiable ranking\nmetric. Despite their empirical success, existing listwise methods are based on\nheuristics and remain theoretically ill-understood. In particular, none of the\nempirically successful loss functions are related to ranking metrics. In this\nwork, we propose a cross entropy-based learning-to-rank loss function that is\ntheoretically sound, is a convex bound on NDCG -- a popular ranking metric --\nand is consistent with NDCG under learning scenarios common in information\nretrieval. Furthermore, empirical evaluation of an implementation of the\nproposed method with gradient boosting machines on benchmark learning-to-rank\ndatasets demonstrates the superiority of our proposed formulation over existing\nalgorithms in quality and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 00:58:11 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 01:14:31 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 19:41:23 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 12:51:42 GMT"}, {"version": "v5", "created": "Thu, 4 Feb 2021 19:02:56 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bruch", "Sebastian", ""]]}, {"id": "1911.09804", "submitter": "Zhijie Deng", "authors": "Zhijie Deng, Yucen Luo, Jun Zhu, Bo Zhang", "title": "Measuring Uncertainty through Bayesian Learning of Deep Neural Network\n  Structure", "comments": "2nd Workshop on Neural Architecture Search at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) augment deep networks with uncertainty\nquantification by Bayesian treatment of the network weights. However, such\nmodels face the challenge of Bayesian inference in a high-dimensional and\nusually over-parameterized space. This paper investigates a new line of\nBayesian deep learning by performing Bayesian inference on network structure.\nInstead of building structure from scratch inefficiently, we draw inspirations\nfrom neural architecture search to represent the network structure. We then\ndevelop an efficient stochastic variational inference approach which unifies\nthe learning of both network structure and weights. Empirically, our method\nexhibits competitive predictive performance while preserving the benefits of\nBayesian principles across challenging scenarios. We also provide convincing\nexperimental justification for our modeling choice.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 01:31:28 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:31:19 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 08:51:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Deng", "Zhijie", ""], ["Luo", "Yucen", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1911.09811", "submitter": "Cecilia Clementi", "authors": "Frank No\\'e, Gianni De Fabritiis, Cecilia Clementi", "title": "Machine learning for protein folding and dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph physics.chem-ph q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of the study of protein folding and dynamics have been affected\nby the recent advances in machine learning. Methods for the prediction of\nprotein structures from their sequences are now heavily based on machine\nlearning tools. The way simulations are performed to explore the energy\nlandscape of protein systems is also changing as force-fields are started to be\ndesigned by means of machine learning methods. These methods are also used to\nextract the essential information from large simulation datasets and to enhance\nthe sampling of rare events such as folding/unfolding transitions. While\nsignificant challenges still need to be tackled, we expect these methods to\nplay an important role on the study of protein folding and dynamics in the near\nfuture. We discuss here the recent advances on all these fronts and the\nquestions that need to be addressed for machine learning approaches to become\nmainstream in protein simulation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:05:12 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["No\u00e9", "Frank", ""], ["De Fabritiis", "Gianni", ""], ["Clementi", "Cecilia", ""]]}, {"id": "1911.09818", "submitter": "Jing Pan", "authors": "Jing Pan, Weian Sheng, Santanu Dey", "title": "Order Matters at Fanatics Recommending Sequentially Ordered Products by\n  LSTM Embedded with Word2Vec", "comments": "5 pages, 2 figures, KDD 2019 Workshop, Deep Learning on Graphics,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A unique challenge for e-commerce recommendation is that customers are often\ninterested in products that are more advanced than their already purchased\nproducts, but not reversed. The few existing recommender systems modeling\nunidirectional sequence output a limited number of categories or continuous\nvariables. To model the ordered sequence, we design the first recommendation\nsystem that both embed purchased items with Word2Vec, and model the sequence\nwith stateless LSTM RNN. The click-through rate of this recommender system in\nproduction outperforms its solely Word2Vec based predecessor. Developed in\n2017, it was perhaps the first published real-world application that makes\ndistributed predictions of a single machine trained Keras model on Spark slave\nnodes at a scale of more than 0.4 million columns per row.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:39:41 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Pan", "Jing", ""], ["Sheng", "Weian", ""], ["Dey", "Santanu", ""]]}, {"id": "1911.09821", "submitter": "Canran Xu", "authors": "Canran Xu, Ming Wu", "title": "Learning Feature Interactions with Lorentzian Factorization Machine", "comments": "8 pages, 5 figures, accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for feature interactions to model user behaviors is\ncritical for recommendation system and click-trough rate (CTR) predictions.\nRecent advances in this area are empowered by deep learning methods which could\nlearn sophisticated feature interactions and achieve the state-of-the-art\nresult in an end-to-end manner. These approaches require large number of\ntraining parameters integrated with the low-level representations, and thus are\nmemory and computational inefficient. In this paper, we propose a new model\nnamed \"LorentzFM\" that can learn feature interactions embedded in a hyperbolic\nspace in which the violation of triangle inequality for Lorentz distances is\navailable. To this end, the learned representation is benefited by the peculiar\ngeometric properties of hyperbolic triangles, and result in a significant\nreduction in the number of parameters (20\\% to 80\\%) because all the top deep\nlearning layers are not required. With such a lightweight architecture,\nLorentzFM achieves comparable and even materially better results than the deep\nlearning methods such as DeepFM, xDeepFM and Deep \\& Cross in both\nrecommendation and CTR prediction tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:43:39 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Xu", "Canran", ""], ["Wu", "Ming", ""]]}, {"id": "1911.09826", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Chengfeng Mao, Kelly Shi, Yiwei Zhang, Paul Pu Liang,\n  Soujanya Poria, Louis-Philippe Morency", "title": "Factorized Multimodal Transformer for Multimodal Sequential Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complex world around us is inherently multimodal and sequential\n(continuous). Information is scattered across different modalities and requires\nmultiple continuous sensors to be captured. As machine learning leaps towards\nbetter generalization to real world, multimodal sequential learning becomes a\nfundamental research area. Arguably, modeling arbitrarily distributed\nspatio-temporal dynamics within and across modalities is the biggest challenge\nin this research area. In this paper, we present a new transformer model,\ncalled the Factorized Multimodal Transformer (FMT) for multimodal sequential\nlearning. FMT inherently models the intramodal and intermodal (involving two or\nmore modalities) dynamics within its multimodal input in a factorized manner.\nThe proposed factorization allows for increasing the number of self-attentions\nto better model the multimodal phenomena at hand; without encountering\ndifficulties during training (e.g. overfitting) even on relatively low-resource\nsetups. All the attention mechanisms within FMT have a full time-domain\nreceptive field which allows them to asynchronously capture long-range\nmultimodal dynamics. In our experiments we focus on datasets that contain the\nthree commonly studied modalities of language, vision and acoustic. We perform\na wide range of experiments, spanning across 3 well-studied datasets and 21\ndistinct labels. FMT shows superior performance over previously proposed\nmodels, setting new state of the art in the studied datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:14:32 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zadeh", "Amir", ""], ["Mao", "Chengfeng", ""], ["Shi", "Kelly", ""], ["Zhang", "Yiwei", ""], ["Liang", "Paul Pu", ""], ["Poria", "Soujanya", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1911.09827", "submitter": "Xinglong Zhang", "authors": "Xinglong Zhang, Jiahang Liu, Xin Xu, Shuyou Yu, and Hong Chen", "title": "Robust Learning-based Predictive Control for Discrete-time Nonlinear\n  Systems with Unknown Dynamics and State Constraints", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model predictive control (MPC) has been widely employed as an effective\nmethod for model-based constrained control. For systems with unknown dynamics,\nreinforcement learning (RL) and adaptive dynamic programming (ADP) have\nreceived notable attention to solving adaptive optimal control problems.\nRecently, works on the use of RL in the framework of MPC have emerged, which\ncan enhance the ability of MPC for data-driven control. However, the safety\nunder state constraints and the closed-loop robustness are difficult to be\nverified due to approximation errors of RL with function approximation\nstructures. Aiming at the above problem, we propose a data-driven robust MPC\nsolution based on incremental RL, called data-driven robust learning-based\npredictive control (dr-LPC), for perturbed unknown nonlinear systems subject to\nsafety constraints. A data-driven robust MPC (dr-MPC) is firstly formulated\nwith a learned predictor. The incremental Dual Heuristic Programming (DHP)\nalgorithm using an actor-critic architecture is then utilized to solve the\nonline optimization problem of dr-MPC. In each prediction horizon, the actor\nand critic learn time-varying laws for approximating the optimal control policy\nand costate respectively, which is different from classical MPCs. The state and\ncontrol constraints are enforced in the learning process via building a\nHamilton-Jacobi-Bellman (HJB) equation and a regularized actor-critic learning\nstructure using logarithmic barrier functions. The closed-loop robustness and\nsafety of the dr-LPC are proven under function approximation errors. Simulation\nresults on two control examples have been reported, which show that the dr-LPC\ncan outperform the DHP and dr-MPC in terms of state regulation, and its average\ncomputational time is much smaller than that with the dr-MPC in both examples.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:15:18 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 05:23:26 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 01:31:47 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhang", "Xinglong", ""], ["Liu", "Jiahang", ""], ["Xu", "Xin", ""], ["Yu", "Shuyou", ""], ["Chen", "Hong", ""]]}, {"id": "1911.09839", "submitter": "Wonyeol Lee", "authors": "Hyoungjin Lim, Gwonsoo Che, Wonyeol Lee, Hongseok Yang", "title": "Differentiable Algorithm for Marginalising Changepoints", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for marginalising changepoints in time-series models\nthat assume a fixed number of unknown changepoints. Our algorithm is\ndifferentiable with respect to its inputs, which are the values of latent\nrandom variables other than changepoints. Also, it runs in time O(mn) where n\nis the number of time steps and m the number of changepoints, an improvement\nover a naive marginalisation method with O(n^m) time complexity. We derive the\nalgorithm by identifying quantities related to this marginalisation problem,\nshowing that these quantities satisfy recursive relationships, and transforming\nthe relationships to an algorithm via dynamic programming. Since our algorithm\nis differentiable, it can be applied to convert a model non-differentiable due\nto changepoints to a differentiable one, so that the resulting models can be\nanalysed using gradient-based inference or learning techniques. We empirically\nshow the effectiveness of our algorithm in this application by tackling the\nposterior inference problem on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:54:25 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lim", "Hyoungjin", ""], ["Che", "Gwonsoo", ""], ["Lee", "Wonyeol", ""], ["Yang", "Hongseok", ""]]}, {"id": "1911.09858", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh K. Ghafoor, Sid C. Bundy,\n  Douglas A. Talbert, and Ambareen Siraj", "title": "Investigating bankruptcy prediction models in the presence of extreme\n  class imbalance and multiple stages of economy", "comments": "Under review in Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of credit risk analytics, current Bankruptcy Prediction Models\n(BPMs) struggle with (a) the availability of comprehensive and real-world data\nsets and (b) the presence of extreme class imbalance in the data (i.e., very\nfew samples for the minority class) that degrades the performance of the\nprediction model. Moreover, little research has compared the relative\nperformance of well-known BPM's on public datasets addressing the class\nimbalance problem. In this work, we apply eight classes of well-known BPMs, as\nsuggested by a review of decades of literature, on a new public dataset named\nFreddie Mac Single-Family Loan-Level Dataset with resampling (i.e., adding\nsynthetic minority samples) of the minority class to tackle class imbalance.\nAdditionally, we apply some recent AI techniques (e.g., tree-based ensemble\ntechniques) that demonstrate potentially better results on models trained with\nresampled data. In addition, from the analysis of 19 years (1999-2017) of data,\nwe discover that models behave differently when presented with sudden changes\nin the economy (e.g., a global financial crisis) resulting in abrupt\nfluctuations in the national default rate. In summary, this study should aid\npractitioners/researchers in determining the appropriate model with respect to\ndata that contains a class imbalance and various economic stages.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 05:00:09 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh K.", ""], ["Bundy", "Sid C.", ""], ["Talbert", "Douglas A.", ""], ["Siraj", "Ambareen", ""]]}, {"id": "1911.09860", "submitter": "Ganesh Ramakrishnan", "authors": "Oishik Chatterjee, Ganesh Ramakrishnan, Sunita Sarawagi", "title": "Data Programming using Continuous and Quality-Guided Labeling Functions", "comments": "Accepted paper at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-18), New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of labeled data is a bottleneck for supervised learning models. A\nparadigm that has evolved for dealing with this problem is data programming. An\nexisting data programming paradigm allows human supervision to be provided as a\nset of discrete labeling functions (LF) that output possibly noisy labels to\ninput instances and a generative modelfor consolidating the weak labels. We\nenhance and generalize this paradigm by supporting functions that output a\ncontinuous score (instead of a hard label) that noisily correlates with labels.\nWe show across five applications that continuous LFs are more natural to\nprogram and lead to improved recall. We also show that accuracy of existing\ngenerative models is unstable with respect to initialization, training epochs,\nand learning rates. We give control to the data programmer to guide the\ntraining process by providing intuitive quality guides with each LF. We propose\nan elegant method of incorporating these guides into the generative model. Our\noverall method, called CAGE, makes the data programming paradigm more reliable\nthan other tricks based on initialization, sign-penalties, or soft-accuracy\nconstraints.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 05:05:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Chatterjee", "Oishik", ""], ["Ramakrishnan", "Ganesh", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1911.09873", "submitter": "Amit Daniely", "authors": "Amit Daniely", "title": "Neural Networks Learning and Memorization with (almost) no\n  Over-Parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many results in recent years established polynomial time learnability of\nvarious models via neural networks algorithms. However, unless the model is\nlinear separable, or the activation is a polynomial, these results require very\nlarge networks -- much more than what is needed for the mere existence of a\ngood predictor.\n  In this paper we prove that SGD on depth two neural networks can memorize\nsamples, learn polynomials with bounded weights, and learn certain kernel\nspaces, with near optimal network size, sample complexity, and runtime. In\nparticular, we show that SGD on depth two network with\n$\\tilde{O}\\left(\\frac{m}{d}\\right)$ hidden neurons (and hence $\\tilde{O}(m)$\nparameters) can memorize $m$ random labeled points in $\\mathbb{S}^{d-1}$.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:26:53 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Daniely", "Amit", ""]]}, {"id": "1911.09876", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Percy Liang", "title": "Feature Noise Induces Loss Discrepancy Across Groups", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of standard learning procedures has been observed to differ\nwidely across groups. Recent studies usually attribute this loss discrepancy to\nan information deficiency for one group (e.g., one group has less data). In\nthis work, we point to a more subtle source of loss discrepancy---feature\nnoise. Our main result is that even when there is no information deficiency\nspecific to one group (e.g., both groups have infinite data), adding the same\namount of feature noise to all individuals leads to loss discrepancy. For\nlinear regression, we thoroughly characterize the effect of feature noise on\nloss discrepancy in terms of the amount of noise, the difference between\nmoments of the two groups, and whether group information is used or not. We\nthen show this loss discrepancy does not vanish immediately if a shift in\ndistribution causes the groups to have similar moments. On three real-world\ndatasets, we show feature noise increases the loss discrepancy if groups have\ndifferent distributions, while it does not affect the loss discrepancy on\ndatasets where groups have similar distributions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:36:23 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 01:51:22 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Khani", "Fereshte", ""], ["Liang", "Percy", ""]]}, {"id": "1911.09879", "submitter": "Saurabh Khanna", "authors": "Saurabh Khanna and Vincent Y. F. Tan", "title": "Economy Statistical Recurrent Units For Inferring Nonlinear Granger\n  Causality", "comments": "A new RNN architecture for inferring nonlinear Granger causality from\n  time series data with emphasis on learning time-localized predictive features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality is a widely-used criterion for analyzing interactions in\nlarge-scale networks. As most physical interactions are inherently nonlinear,\nwe consider the problem of inferring the existence of pairwise Granger\ncausality between nonlinearly interacting stochastic processes from their time\nseries measurements. Our proposed approach relies on modeling the embedded\nnonlinearities in the measurements using a component-wise time series\nprediction model based on Statistical Recurrent Units (SRUs). We make a case\nthat the network topology of Granger causal relations is directly inferrable\nfrom a structured sparse estimate of the internal parameters of the SRU\nnetworks trained to predict the processes$'$ time series measurements. We\npropose a variant of SRU, called economy-SRU, which, by design has considerably\nfewer trainable parameters, and therefore less prone to overfitting. The\neconomy-SRU computes a low-dimensional sketch of its high-dimensional hidden\nstate in the form of random projections to generate the feedback for its\nrecurrent processing. Additionally, the internal weight parameters of the\neconomy-SRU are strategically regularized in a group-wise manner to facilitate\nthe proposed network in extracting meaningful predictive features that are\nhighly time-localized to mimic real-world causal events. Extensive experiments\nare carried out to demonstrate that the proposed economy-SRU based time series\nprediction model outperforms the MLP, LSTM and attention-gated CNN-based time\nseries models considered previously for inferring Granger causality.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:40:07 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 04:48:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Khanna", "Saurabh", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1911.09906", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "Supervised and Semi-supervised Deep Probabilistic Models for Indoor\n  Positioning Problems", "comments": "11 pages, 10 figures", "journal-ref": "Neurocomputing, vol. 435C, pp. 228-238, 2021", "doi": "10.1016/j.neucom.2020.12.131", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting smartphone users location with WiFi fingerprints has been a\npopular research topic recently. In this work, we propose two novel deep\nlearning-based models, the convolutional mixture density recurrent neural\nnetwork and the VAE-based semi-supervised learning model. The convolutional\nmixture density recurrent neural network is designed for path prediction, in\nwhich the advantages of convolutional neural networks, recurrent neural\nnetworks and mixture density networks are combined. Further, since most of\nreal-world datasets are not labeled, we devise the VAE-based model for the\nsemi-supervised learning tasks. In order to test the proposed models, we\nconduct the validation experiments on the real-world datasets. The final\nresults verify the effectiveness of our approaches and show the superiority\nover other existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:50:27 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 14:02:39 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 07:46:27 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09946", "submitter": "Mona Buisson-Fenet", "authors": "Mona Buisson-Fenet, Friedrich Solowjow, and Sebastian Trimpe", "title": "Actively Learning Gaussian Process Dynamics", "comments": null, "journal-ref": "Actively Learning Gaussian Process Dynamics, Proceedings of the\n  2nd Conference on Learning for Dynamics and Control, Proceedings of Machine\n  Learning Research vol 120, pp. 5-15, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the availability of ever more data enabled through modern sensor and\ncomputer technology, it still remains an open problem to learn dynamical\nsystems in a sample-efficient way. We propose active learning strategies that\nleverage information-theoretical properties arising naturally during Gaussian\nprocess regression, while respecting constraints on the sampling process\nimposed by the system dynamics. Sample points are selected in regions with high\nuncertainty, leading to exploratory behavior and data-efficient training of the\nmodel. All results are finally verified in an extensive numerical benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 09:47:17 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 09:48:49 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 11:25:00 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Buisson-Fenet", "Mona", ""], ["Solowjow", "Friedrich", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1911.09976", "submitter": "Xinshao Wang Mr", "authors": "Xinshao Wang, Elyor Kodirov, Yang Hua, Neil Robertson", "title": "Instance Cross Entropy for Deep Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loss functions play a crucial role in deep metric learning thus a variety of\nthem have been proposed. Some supervise the learning process by pairwise or\ntripletwise similarity constraints while others take advantage of structured\nsimilarity information among multiple data points. In this work, we approach\ndeep metric learning from a novel perspective. We propose instance cross\nentropy (ICE) which measures the difference between an estimated instance-level\nmatching distribution and its ground-truth one. ICE has three main appealing\nproperties. Firstly, similar to categorical cross entropy (CCE), ICE has clear\nprobabilistic interpretation and exploits structured semantic similarity\ninformation for learning supervision. Secondly, ICE is scalable to infinite\ntraining data as it learns on mini-batches iteratively and is independent of\nthe training set size. Thirdly, motivated by our relative weight analysis,\nseamless sample reweighting is incorporated. It rescales samples' gradients to\ncontrol the differentiation degree over training examples instead of truncating\nthem by sample mining. In addition to its simplicity and intuitiveness,\nextensive experiments on three real-world benchmarks demonstrate the\nsuperiority of ICE.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 11:12:48 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Xinshao", ""], ["Kodirov", "Elyor", ""], ["Hua", "Yang", ""], ["Robertson", "Neil", ""]]}, {"id": "1911.10008", "submitter": "Sambuddha Saha", "authors": "Sambuddha Saha, Aashish Kumar, Pratyush Sahay, George Jose, Srinivas\n  Kruthiventi, Harikrishna Muralidhara", "title": "Attack Agnostic Statistical Method for Adversarial Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning based AI systems have shown great promise in various domains\nsuch as vision, audio, autonomous systems (vehicles, drones), etc. Recent\nresearch on neural networks has shown the susceptibility of deep networks to\nadversarial attacks - a technique of adding small perturbations to the inputs\nwhich can fool a deep network into misclassifying them. Developing defenses\nagainst such adversarial attacks is an active research area, with some\napproaches proposing robust models that are immune to such adversaries, while\nother techniques attempt to detect such adversarial inputs. In this paper, we\npresent a novel statistical approach for adversarial detection in image\nclassification. Our approach is based on constructing a per-class feature\ndistribution and detecting adversaries based on comparison of features of a\ntest image with the feature distribution of its class. For this purpose, we\nmake use of various statistical distances such as ED (Energy Distance), MMD\n(Maximum Mean Discrepancy) for adversarial detection, and analyze the\nperformance of each metric. We experimentally show that our approach achieves\ngood adversarial detection performance on MNIST and CIFAR-10 datasets\nirrespective of the attack method, sample size and the degree of adversarial\nperturbation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 12:52:11 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Saha", "Sambuddha", ""], ["Kumar", "Aashish", ""], ["Sahay", "Pratyush", ""], ["Jose", "George", ""], ["Kruthiventi", "Srinivas", ""], ["Muralidhara", "Harikrishna", ""]]}, {"id": "1911.10017", "submitter": "Sixin Zhang", "authors": "Sixin Zhang, St\\'ephane Mallat", "title": "Maximum Entropy Models from Phase Harmonic Covariances", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2021.01.003", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The covariance of a stationary process $X$ is diagonalized by a Fourier\ntransform. It does not take into account the complex Fourier phase and defines\nGaussian maximum entropy models. We introduce a general family of phase\nharmonic covariance moments, which rely on complex phases to capture\nnon-Gaussian properties. They are defined as the covariance of $\\hat{H} (L X)$,\nwhere $L$ is a complex linear operator and $\\hat{H} $ is a non-linear phase\nharmonic operator which multiplies the phase of each complex coefficient by\nintegers. The operator $\\hat{H} (L X)$ can also be calculated from rectifiers,\nwhich relates $\\hat{H} (L X)$ to neural network coefficients. If $L$ is a\nFourier transform then the covariance is a sparse matrix whose non-zero\noff-diagonal coefficients capture dependencies between frequencies. These\ncoefficients have similarities with high order moment, but smaller statistical\nvariabilities because $\\hat{H} (L X)$ is Lipschitz. If $L$ is a complex wavelet\ntransform then off-diagonal coefficients reveal dependencies across scales,\nwhich specify the geometry of local coherent structures. We introduce maximum\nentropy models conditioned by these wavelet phase harmonic covariances. The\nprecision of these models is numerically evaluated to synthesize images of\nturbulent flows and other stationary processes.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:04:37 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 15:04:46 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zhang", "Sixin", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1911.10022", "submitter": "Friso Heslinga", "authors": "Friso G. Heslinga, Josien P.W. Pluim, A.J.H.M. Houben, Miranda T.\n  Schram, Ronald M.A. Henry, Coen D.A. Stehouwer, Marleen J. van Greevenbroek,\n  Tos T.J.M. Berendschot, and Mitko Veta", "title": "Direct Classification of Type 2 Diabetes From Retinal Fundus Images in a\n  Population-based Sample From The Maastricht Study", "comments": "to be published in the proceeding of SPIE - Medical Imaging 2020, 6\n  pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type 2 Diabetes (T2D) is a chronic metabolic disorder that can lead to\nblindness and cardiovascular disease. Information about early stage T2D might\nbe present in retinal fundus images, but to what extent these images can be\nused for a screening setting is still unknown. In this study, deep neural\nnetworks were employed to differentiate between fundus images from individuals\nwith and without T2D. We investigated three methods to achieve high\nclassification performance, measured by the area under the receiver operating\ncurve (ROC-AUC). A multi-target learning approach to simultaneously output\nretinal biomarkers as well as T2D works best (AUC = 0.746 [$\\pm$0.001]).\nFurthermore, the classification performance can be improved when images with\nhigh prediction uncertainty are referred to a specialist. We also show that the\ncombination of images of the left and right eye per individual can further\nimprove the classification performance (AUC = 0.758 [$\\pm$0.003]), using a\nsimple averaging approach. The results are promising, suggesting the\nfeasibility of screening for T2D from retinal fundus images.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:17:04 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Heslinga", "Friso G.", ""], ["Pluim", "Josien P. W.", ""], ["Houben", "A. J. H. M.", ""], ["Schram", "Miranda T.", ""], ["Henry", "Ronald M. A.", ""], ["Stehouwer", "Coen D. A.", ""], ["van Greevenbroek", "Marleen J.", ""], ["Berendschot", "Tos T. J. M.", ""], ["Veta", "Mitko", ""]]}, {"id": "1911.10036", "submitter": "Artyom Gadetsky", "authors": "Artyom Gadetsky, Kirill Struminsky, Christopher Robinson, Novi\n  Quadrianto, Dmitry Vetrov", "title": "Low-variance Black-box Gradient Estimates for the Plackett-Luce\n  Distribution", "comments": "Accepted as a conference paper at AAAI 2020. Shortened version of the\n  paper appears at BDL NeurIPS 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models with discrete latent variables using stochastic gradient\ndescent remains a challenge due to the high variance of gradient estimates.\nModern variance reduction techniques mostly consider categorical distributions\nand have limited applicability when the number of possible outcomes becomes\nlarge. In this work, we consider models with latent permutations and propose\ncontrol variates for the Plackett-Luce distribution. In particular, the control\nvariates allow us to optimize black-box functions over permutations using\nstochastic gradient descent. To illustrate the approach, we consider a variety\nof causal structure learning tasks for continuous and discrete data. We show\nthat our method outperforms competitive relaxation-based optimization methods\nand is also applicable to non-differentiable score functions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:34:50 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Gadetsky", "Artyom", ""], ["Struminsky", "Kirill", ""], ["Robinson", "Christopher", ""], ["Quadrianto", "Novi", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1911.10071", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Federated Learning with Bayesian Differential Privacy", "comments": "Accepted at 2019 IEEE International Conference on Big Data (IEEE Big\n  Data 2019). 10 pages, 2 figures, 4 tables. arXiv admin note: text overlap\n  with arXiv:1901.09697", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005465", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcing federated learning with formal privacy\nguarantees. We propose to employ Bayesian differential privacy, a relaxation of\ndifferential privacy for similarly distributed data, to provide sharper privacy\nloss bounds. We adapt the Bayesian privacy accounting method to the federated\nsetting and suggest multiple improvements for more efficient privacy budgeting\nat different levels. Our experiments show significant advantage over the\nstate-of-the-art differential privacy bounds for federated learning on image\nclassification tasks, including a medical application, bringing the privacy\nbudget below 1 at the client level, and below 0.1 at the instance level. Lower\namounts of noise also benefit the model accuracy and reduce the number of\ncommunication rounds.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:54:04 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1911.10073", "submitter": "Abolfazl Asudeh", "authors": "Abolfazl Asudeh and H. V. Jagadish", "title": "Responsible Scoring Mechanisms Through Function Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human decision-makers often receive assistance from data-driven algorithmic\nsystems that provide a score for evaluating objects, including individuals. The\nscores are generated by a function (mechanism) that takes a set of features as\ninput and generates a score.The scoring functions are either machine-learned or\nhuman-designed and can be used for different decision purposes such as ranking\nor classification.\n  Given the potential impact of these scoring mechanisms on individuals' lives\nand on society, it is important to make sure these scores are computed\nresponsibly. Hence we need tools for responsible scoring mechanism design. In\nthis paper, focusing on linear scoring functions, we highlight the importance\nof unbiased function sampling and perturbation in the function space for\ndevising such tools. We provide unbiased samplers for the entire function\nspace, as well as a $\\theta$-vicinity around a given function.\n  We then illustrate the value of these samplers for designing effective\nalgorithms in three diverse problem scenarios in the context of ranking.\nFinally, as a fundamental method for designing responsible scoring mechanisms,\nwe propose a novel approach for approximating the construction of the\narrangement of hyperplanes. Despite the exponential complexity of an\narrangement in the number of dimensions, using function sampling, our algorithm\nis linear in the number of samples and hyperplanes, and independent of the\nnumber of dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:05:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Asudeh", "Abolfazl", ""], ["Jagadish", "H. V.", ""]]}, {"id": "1911.10081", "submitter": "Taha Ceritli", "authors": "Taha Ceritli, Christopher K. I. Williams, James Geddes", "title": "ptype: Probabilistic Type Inference", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery (2020)", "doi": "10.1007/s10618-020-00680-1", "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type inference refers to the task of inferring the data type of a given\ncolumn of data. Current approaches often fail when data contains missing data\nand anomalies, which are found commonly in real-world data sets. In this paper,\nwe propose ptype, a probabilistic robust type inference method that allows us\nto detect such entries, and infer data types. We further show that the proposed\nmethod outperforms the existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:21:15 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 12:25:40 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ceritli", "Taha", ""], ["Williams", "Christopher K. I.", ""], ["Geddes", "James", ""]]}, {"id": "1911.10088", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Hieu Pham, Paul Michel, Antonios Anastasopoulos, Jaime\n  Carbonell, Graham Neubig", "title": "Optimizing Data Usage via Differentiable Rewards", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To acquire a new skill, humans learn better and faster if a tutor, based on\ntheir current knowledge level, informs them of how much attention they should\npay to particular content or practice problems. Similarly, a machine learning\nmodel could potentially be trained better with a scorer that \"adapts\" to its\ncurrent learning state and estimates the importance of each training data\ninstance. Training such an adaptive scorer efficiently is a challenging\nproblem; in order to precisely quantify the effect of a data instance at a\ngiven time during the training, it is typically necessary to first complete the\nentire training process. To efficiently optimize data usage, we propose a\nreinforcement learning approach called Differentiable Data Selection (DDS). In\nDDS, we formulate a scorer network as a learnable function of the training\ndata, which can be efficiently updated along with the main model being trained.\nSpecifically, DDS updates the scorer with an intuitive reward signal: it should\nup-weigh the data that has a similar gradient with a dev set upon which we\nwould finally like to perform well. Without significant computing overhead, DDS\ndelivers strong and consistent improvements over several strong baselines on\ntwo very different tasks of machine translation and image classification.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:38:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:46:58 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 18:33:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Xinyi", ""], ["Pham", "Hieu", ""], ["Michel", "Paul", ""], ["Anastasopoulos", "Antonios", ""], ["Carbonell", "Jaime", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.10113", "submitter": "Mohammed K Alzaylaee Dr", "authors": "Mohammed K. Alzaylaee, Suleiman Y. Yerima and Sakir Sezer", "title": "DL-Droid: Deep learning based android malware detection using real\n  devices", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2019.101663", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Android operating system has been the most popular for smartphones and\ntablets since 2012. This popularity has led to a rapid raise of Android malware\nin recent years. The sophistication of Android malware obfuscation and\ndetection avoidance methods have significantly improved, making many\ntraditional malware detection methods obsolete. In this paper, we propose\nDL-Droid, a deep learning system to detect malicious Android applications\nthrough dynamic analysis using stateful input generation. Experiments performed\nwith over 30,000 applications (benign and malware) on real devices are\npresented. Furthermore, experiments were also conducted to compare the\ndetection performance and code coverage of the stateful input generation method\nwith the commonly used stateless approach using the deep learning system. Our\nstudy reveals that DL-Droid can achieve up to 97.8% detection rate (with\ndynamic features only) and 99.6% detection rate (with dynamic + static\nfeatures) respectively which outperforms traditional machine learning\ntechniques. Furthermore, the results highlight the significance of enhanced\ninput generation for dynamic analysis as DL-Droid with the state-based input\ngeneration is shown to outperform the existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:16:15 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Alzaylaee", "Mohammed K.", ""], ["Yerima", "Suleiman Y.", ""], ["Sezer", "Sakir", ""]]}, {"id": "1911.10120", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Eugenio Bargiacchi and Pieter JK Libin and Jan\n  Helsen and Diederik M Roijers and Ann Now\\'e", "title": "Multi-Agent Thompson Sampling for Bandit Applications with Sparse\n  Neighbourhood Structures", "comments": null, "journal-ref": "Sci Rep 10, 6728 (2020)", "doi": "10.1038/s41598-020-62939-3", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent coordination is prevalent in many real-world applications.\nHowever, such coordination is challenging due to its combinatorial nature. An\nimportant observation in this regard is that agents in the real world often\nonly directly affect a limited set of neighbouring agents. Leveraging such\nloose couplings among agents is key to making coordination in multi-agent\nsystems feasible. In this work, we focus on learning to coordinate.\nSpecifically, we consider the multi-agent multi-armed bandit framework, in\nwhich fully cooperative loosely-coupled agents must learn to coordinate their\ndecisions to optimize a common objective. We propose multi-agent Thompson\nsampling (MATS), a new Bayesian exploration-exploitation algorithm that\nleverages loose couplings. We provide a regret bound that is sublinear in time\nand low-order polynomial in the highest number of actions of a single agent for\nsparse coordination graphs. Additionally, we empirically show that MATS\noutperforms the state-of-the-art algorithm, MAUCE, on two synthetic benchmarks,\nand a novel benchmark with Poisson distributions. An example of a\nloosely-coupled multi-agent system is a wind farm. Coordination within the wind\nfarm is necessary to maximize power production. As upstream wind turbines only\naffect nearby downstream turbines, we can use MATS to efficiently learn the\noptimal control mechanism for the farm. To demonstrate the benefits of our\nmethod toward applications we apply MATS to a realistic wind farm control task.\nIn this task, wind turbines must coordinate their alignments with respect to\nthe incoming wind vector in order to optimize power production. Our results\nshow that MATS improves significantly upon state-of-the-art coordination\nmethods in terms of performance, demonstrating the value of using MATS in\npractical applications with sparse neighbourhood structures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:21:25 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 10:42:24 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Bargiacchi", "Eugenio", ""], ["Libin", "Pieter JK", ""], ["Helsen", "Jan", ""], ["Roijers", "Diederik M", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10121", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Pieter JK Libin and Ann Now\\'e", "title": "Fleet Control using Coregionalized Gaussian Process Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, as for example wind farms, multiple machines are\ninstantiated to perform the same task, which is called a fleet. The recent\nadvances with respect to the Internet of Things allow control devices and/or\nmachines to connect through cloud-based architectures in order to share\ninformation about their status and environment. Such an infrastructure allows\nseamless data sharing between fleet members, which could greatly improve the\nsample-efficiency of reinforcement learning techniques. However in practice,\nthese machines, while almost identical in design, have small discrepancies due\nto production errors or degradation, preventing control algorithms to simply\naggregate and employ all fleet data. We propose a novel reinforcement learning\nmethod that learns to transfer knowledge between similar fleet members and\ncreates member-specific dynamics models for control. Our algorithm uses\nGaussian processes to establish cross-member covariances. This is significantly\ndifferent from standard transfer learning methods, as the focus is not on\nsharing information over tasks, but rather over system specifications. We\ndemonstrate our approach on two benchmarks and a realistic wind farm setting.\nOur method significantly outperforms two baseline approaches, namely individual\nlearning and joint learning where all samples are aggregated, in terms of the\nmedian and variance of the results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:23:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Libin", "Pieter JK", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10124", "submitter": "Timoth\\'ee Masquelier Dr", "authors": "Romain Zimmer, Thomas Pellegrini, Srisht Fateh Singh, Timoth\\'ee\n  Masquelier", "title": "Technical report: supervised training of convolutional spiking neural\n  networks with PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been shown that spiking neural networks (SNNs) can be\ntrained efficiently, in a supervised manner, using backpropagation through\ntime. Indeed, the most commonly used spiking neuron model, the leaky\nintegrate-and-fire neuron, obeys a differential equation which can be\napproximated using discrete time steps, leading to a recurrent relation for the\npotential. The firing threshold causes optimization issues, but they can be\novercome using a surrogate gradient. Here, we extend previous approaches in two\nways. Firstly, we show that the approach can be used to train convolutional\nlayers. Convolutions can be done in space, time (which simulates conduction\ndelays), or both. Secondly, we include fast horizontal connections \\`a la\nDen\\`eve: when a neuron N fires, we subtract to the potentials of all the\nneurons with the same receptive the dot product between their weight vectors\nand the one of neuron N. As Den\\`eve et al. showed, this is useful to represent\na dynamic multidimensional analog signal in a population of spiking neurons.\nHere we demonstrate that, in addition, such connections also allow implementing\na multidimensional send-on-delta coding scheme. We validate our approach on one\nspeech classification benchmarks: the Google speech command dataset. We managed\nto reach nearly state-of-the-art accuracy (94%) while maintaining low firing\nrates (about 5Hz). Our code is based on PyTorch and is available in open source\nat http://github.com/romainzimmer/s2net\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:24:38 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zimmer", "Romain", ""], ["Pellegrini", "Thomas", ""], ["Singh", "Srisht Fateh", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1911.10150", "submitter": "Alex Lang", "authors": "Sourabh Vora, Alex H. Lang, Bassam Helou, and Oscar Beijbom", "title": "PointPainting: Sequential Fusion for 3D Object Detection", "comments": "11 pages, 6 figures, 8 tables. v1 is initial submission to CVPR 2020.\n  v2 is final version accepted for publication at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera and lidar are important sensor modalities for robotics in general and\nself-driving cars in particular. The sensors provide complementary information\noffering an opportunity for tight sensor-fusion. Surprisingly, lidar-only\nmethods outperform fusion methods on the main benchmark datasets, suggesting a\ngap in the literature. In this work, we propose PointPainting: a sequential\nfusion method to fill this gap. PointPainting works by projecting lidar points\ninto the output of an image-only semantic segmentation network and appending\nthe class scores to each point. The appended (painted) point cloud can then be\nfed to any lidar-only method. Experiments show large improvements on three\ndifferent state-of-the art methods, Point-RCNN, VoxelNet and PointPillars on\nthe KITTI and nuScenes datasets. The painted version of PointRCNN represents a\nnew state of the art on the KITTI leaderboard for the bird's-eye view detection\ntask. In ablation, we study how the effects of Painting depends on the quality\nand format of the semantic segmentation output, and demonstrate how latency can\nbe minimized through pipelining.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:19:50 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:17:18 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Vora", "Sourabh", ""], ["Lang", "Alex H.", ""], ["Helou", "Bassam", ""], ["Beijbom", "Oscar", ""]]}, {"id": "1911.10153", "submitter": "Ikjyot Singh Kohli", "authors": "Ikjyot Singh Kohli and Katherine Goff Inglis", "title": "On an Optimal Solution to the Film Scheduling and Showtime Staggering\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scheduling of films is a major problem for the movie theatre exhibition\nbusiness. The problem is two-fold: movie exhibitors ideally would like to\nschedule films to screens in their various locations to maximize attendance and\nrevenue, but would also like to schedule these films such that neighbouring\ntheatre locations play the same films at different times thus giving guests a\nmultitude of showtime options. We refer to this latter problem as the showtime\n\\emph{staggering} problem. We give an exact formulation of this scheduling\nproblem using binary integer linear optimization, and provide a solved example\nas well. This work further shows that the optimal scheduling of films cannot be\ndone across all theatre locations at once, but rather, must be done for each\ncluster of neighbouring locations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:23:03 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kohli", "Ikjyot Singh", ""], ["Inglis", "Katherine Goff", ""]]}, {"id": "1911.10164", "submitter": "Jacob Rafati", "authors": "Jacob Rafati, David C. Noelle", "title": "Efficient Exploration through Intrinsic Motivation Learning for\n  Unsupervised Subgoal Discovery in Model-Free Hierarchical Reinforcement\n  Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.10096", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration for automatic subgoal discovery is a challenging\nproblem in Hierarchical Reinforcement Learning (HRL). In this paper, we show\nthat intrinsic motivation learning increases the efficiency of exploration,\nleading to successful subgoal discovery. We introduce a model-free subgoal\ndiscovery method based on unsupervised learning over a limited memory of\nagent's experiences during intrinsic motivation. Additionally, we offer a\nunified approach to learning representations in model-free HRL.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:30:36 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1911.10167", "submitter": "Marco Avella", "authors": "Marco Avella-Medina", "title": "Privacy-preserving parametric inference: a case for robust statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a cryptographically-motivated approach to privacy\nthat has become a very active field of research over the last decade in\ntheoretical computer science and machine learning. In this paradigm one assumes\nthere is a trusted curator who holds the data of individuals in a database and\nthe goal of privacy is to simultaneously protect individual data while allowing\nthe release of global characteristics of the database. In this setting we\nintroduce a general framework for parametric inference with differential\nprivacy guarantees. We first obtain differentially private estimators based on\nbounded influence M-estimators by leveraging their gross-error sensitivity in\nthe calibration of a noise term added to them in order to ensure privacy. We\nthen show how a similar construction can also be applied to construct\ndifferentially private test statistics analogous to the Wald, score and\nlikelihood ratio tests. We provide statistical guarantees for all our proposals\nvia an asymptotic analysis. An interesting consequence of our results is to\nfurther clarify the connection between differential privacy and robust\nstatistics. In particular, we demonstrate that differential privacy is a weaker\nstability requirement than infinitesimal robustness, and show that robust\nM-estimators can be easily randomized in order to guarantee both differential\nprivacy and robustness towards the presence of contaminated data. We illustrate\nour results both on simulated and real data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:59:58 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Avella-Medina", "Marco", ""]]}, {"id": "1911.10175", "submitter": "Houxiang Ji", "authors": "Zhangxiaowen Gong, Houxiang Ji, Christopher Fletcher, Christopher\n  Hughes, Josep Torrellas", "title": "SparseTrain:Leveraging Dynamic Sparsity in Training DNNs on\n  General-Purpose SIMD Processors", "comments": null, "journal-ref": null, "doi": "10.1145/3410463.3414655", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our community has greatly improved the efficiency of deep learning\napplications, including by exploiting sparsity in inputs. Most of that work,\nthough, is for inference, where weight sparsity is known statically, and/or for\nspecialized hardware. We propose a scheme to leverage dynamic sparsity during\ntraining. In particular, we exploit zeros introduced by the ReLU activation\nfunction to both feature maps and their gradients. This is challenging because\nthe sparsity degree is moderate and the locations of zeros change over time. We\nalso rely purely on software. We identify zeros in a dense data representation\nwithout transforming the data and performs conventional vectorized computation.\nVariations of the scheme are applicable to all major components of training:\nforward propagation, backward propagation by inputs, and backward propagation\nby weights. Our method significantly outperforms a highly-optimized dense\ndirect convolution on several popular deep neural networks. At realistic\nsparsity, we speed up the training of the non-initial convolutional layers in\nVGG16, ResNet-34, ResNet-50, and Fixup ResNet-50 by 2.19x, 1.37x, 1.31x, and\n1.51x respectively on an Intel Skylake-X CPU.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:19:32 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gong", "Zhangxiaowen", ""], ["Ji", "Houxiang", ""], ["Fletcher", "Christopher", ""], ["Hughes", "Christopher", ""], ["Torrellas", "Josep", ""]]}, {"id": "1911.10182", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo and Roberto Santana", "title": "Universal adversarial examples in speech command classification", "comments": "14 pages, 2 figures, 4 tables; Revised external links", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial examples are inputs intentionally perturbed with the aim of\nforcing a machine learning model to produce a wrong prediction, while the\nchanges are not easily detectable by a human. Although this topic has been\nintensively studied in the image domain, classification tasks in the audio\ndomain have received less attention. In this paper we address the existence of\nuniversal perturbations for speech command classification. We provide evidence\nthat universal attacks can be generated for speech command classification\ntasks, which are able to generalize across different models to a significant\nextent. Additionally, a novel analytical framework is proposed for the\nevaluation of universal perturbations under different levels of universality,\ndemonstrating that the feasibility of generating effective perturbations\ndecreases as the universality level increases. Finally, we propose a more\ndetailed and rigorous framework to measure the amount of distortion introduced\nby the perturbations, demonstrating that the methods employed by convention are\nnot realistic in audio-based problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:31:52 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 22:55:43 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 19:20:15 GMT"}, {"version": "v4", "created": "Sat, 13 Feb 2021 12:00:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""]]}, {"id": "1911.10225", "submitter": "Juan Jose Giraldo Gutierrez", "authors": "Juan-Jos\\'e Giraldo and Mauricio A. \\'Alvarez", "title": "A Fully Natural Gradient Scheme for Improving Inference of the\n  Heterogeneous Multi-Output Gaussian Process Model", "comments": "we have rewritten: sections 2 and 3, included details of the HetMOGP\n  and our proposed inference method in sections 4 and 6; a brief\n  state-of-the-art review of MOGPs in 4.1; included a novel extension of the\n  HetMOGP with convolution processes in 5. We derived the fully natural\n  gradient updates for the new model in section 6.2; new results and discussion\n  in experiments section; new appendices added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent novel extension of multi-output Gaussian processes handles\nheterogeneous outputs assuming that each output has its own likelihood\nfunction. It uses a vector-valued Gaussian process prior to jointly model all\nlikelihoods' parameters as latent functions drawn from a Gaussian process with\na linear model of coregionalisation covariance. By means of an inducing points\nframework, the model is able to obtain tractable variational bounds amenable to\nstochastic variational inference. Nonetheless, the strong conditioning between\nthe variational parameters and the hyper-parameters burdens the adaptive\ngradient optimisation methods used in the original approach. To overcome this\nissue we borrow ideas from variational optimisation introducing an exploratory\ndistribution over the hyper-parameters, allowing inference together with the\nposterior's variational parameters through a fully natural gradient\noptimisation scheme. Furthermore, in this work we introduce an extension of the\nheterogeneous multi-output model, where its latent functions are drawn from\nconvolution processes. We show that our optimisation scheme can achieve better\nlocal optima solutions with higher test performance rates than adaptive\ngradient methods, this for both the linear model of coregionalisation and the\nconvolution processes model. We also show how to make the convolutional model\nscalable by means of stochastic variational inference and how to optimise it\nthrough a fully natural gradient scheme. We compare the performance of the\ndifferent methods over toy and real databases.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:29:27 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:52:01 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 20:32:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Giraldo", "Juan-Jos\u00e9", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1911.10232", "submitter": "Kai Ni", "authors": "Amit Pande, Kai Ni and Venkataramani Kini", "title": "SWAG: Item Recommendations using Convolutions on Weighted Graphs", "comments": "10 pages, 8 figures, 2019 IEEE BigData special session", "journal-ref": "2019 IEEE International Conference on Big Data", "doi": "10.1109/BigData47090.2019.9005633", "report-no": null, "categories": "cs.IR cs.LG stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent advancements in deep neural networks for graph-structured data have\nled to state-of-the-art performance on recommender system benchmarks. In this\nwork, we present a Graph Convolutional Network (GCN) algorithm SWAG (Sample\nWeight and AGgregate), which combines efficient random walks and graph\nconvolutions on weighted graphs to generate embeddings for nodes (items) that\nincorporate both graph structure as well as node feature information such as\nitem-descriptions and item-images. The three important SWAG operations that\nenable us to efficiently generate node embeddings based on graph structures are\n(a) Sampling of graph to homogeneous structure, (b) Weighting the sampling,\nwalks and convolution operations, and (c) using AGgregation functions for\ngenerating convolutions. The work is an adaptation of graphSAGE over weighted\ngraphs. We deploy SWAG at Target and train it on a graph of more than 500K\nproducts sold online with over 50M edges. Offline and online evaluations reveal\nthe benefit of using a graph-based approach and the benefits of weighing to\nproduce high quality embeddings and product recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:51:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Pande", "Amit", ""], ["Ni", "Kai", ""], ["Kini", "Venkataramani", ""]]}, {"id": "1911.10241", "submitter": "Samuel Finlayson", "authors": "Samuel G. Finlayson, Matthew B.A. McDermott, Alex V. Pickering, Scott\n  L. Lipnick, Isaac S. Kohane", "title": "Cross-modal representation alignment of molecular structure and\n  perturbation-induced transcriptional profiles", "comments": "Accepted for oral presentation at the Pacific Symposium of\n  Biocomputing, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the relationship between chemical structure and molecular activity\nis a key goal in drug development. Many benchmark tasks have been proposed for\nmolecular property prediction, but these tasks are generally aimed at specific,\nisolated biomedical properties. In this work, we propose a new cross-modal\nsmall molecule retrieval task, designed to force a model to learn to associate\nthe structure of a small molecule with the transcriptional change it induces.\nWe develop this task formally as multi-view alignment problem, and present a\ncoordinated deep learning approach that jointly optimizes representations of\nboth chemical structure and perturbational gene expression profiles. We\nbenchmark our results against oracle models and principled baselines, and find\nthat cell line variability markedly influences performance in this domain. Our\nwork establishes the feasibility of this new task, elucidates the limitations\nof current data and systems, and may serve to catalyze future research in small\nmolecule representation learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:30:43 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 01:15:26 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Finlayson", "Samuel G.", ""], ["McDermott", "Matthew B. A.", ""], ["Pickering", "Alex V.", ""], ["Lipnick", "Scott L.", ""], ["Kohane", "Isaac S.", ""]]}, {"id": "1911.10244", "submitter": "Daniel Kroening", "authors": "Mohammadhosein Hasanbeig, Natasha Yogananda Jeppu, Alessandro Abate,\n  Tom Melham, Daniel Kroening", "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep\n  Reinforcement Learning", "comments": "Extended version of AAAI 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes DeepSynth, a method for effective training of deep\nReinforcement Learning (RL) agents when the reward is sparse and non-Markovian,\nbut at the same time progress towards the reward requires achieving an unknown\nsequence of high-level objectives. Our method employs a novel algorithm for\nsynthesis of compact automata to uncover this sequential structure\nautomatically. We synthesise a human-interpretable automaton from trace data\ncollected by exploring the environment. The state space of the environment is\nthen enriched with the synthesised automaton so that the generation of a\ncontrol policy by deep RL is guided by the discovered structure encoded in the\nautomaton. The proposed approach is able to cope with both high-dimensional,\nlow-level features and unknown sparse non-Markovian rewards. We have evaluated\nDeepSynth's performance in a set of experiments that includes the Atari game\nMontezuma's Revenge. Compared to existing approaches, we obtain a reduction of\ntwo orders of magnitude in the number of iterations required for policy\nsynthesis, and also a significant improvement in scalability.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:44:27 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:51:38 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 17:46:02 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 19:58:16 GMT"}, {"version": "v5", "created": "Sat, 6 Mar 2021 09:53:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Jeppu", "Natasha Yogananda", ""], ["Abate", "Alessandro", ""], ["Melham", "Tom", ""], ["Kroening", "Daniel", ""]]}, {"id": "1911.10258", "submitter": "Sahil Singla", "authors": "Sahil Singla, Soheil Feizi", "title": "Fantastic Four: Differentiable Bounds on Singular Values of Convolution\n  Layers", "comments": "Accepted at ICLR, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep neural networks, the spectral norm of the Jacobian of a layer bounds\nthe factor by which the norm of a signal changes during forward/backward\npropagation. Spectral norm regularizations have been shown to improve\ngeneralization, robustness and optimization of deep learning methods. Existing\nmethods to compute the spectral norm of convolution layers either rely on\nheuristics that are efficient in computation but lack guarantees or are\ntheoretically-sound but computationally expensive. In this work, we obtain the\nbest of both worlds by deriving {\\it four} provable upper bounds on the\nspectral norm of a standard 2D multi-channel convolution layer. These bounds\nare differentiable and can be computed efficiently during training with\nnegligible overhead. One of these bounds is in fact the popular heuristic\nmethod of Miyato et al. (multiplied by a constant factor depending on filter\nsizes). Each of these four bounds can achieve the tightest gap depending on\nconvolution filters. Thus, we propose to use the minimum of these four bounds\nas a tight, differentiable and efficient upper bound on the spectral norm of\nconvolution layers. We show that our spectral bound is an effective regularizer\nand can be used to bound either the lipschitz constant or curvature values\n(eigenvalues of the Hessian) of neural networks. Through experiments on MNIST\nand CIFAR-10, we demonstrate the effectiveness of our spectral bound in\nimproving generalization and provable robustness of deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 21:29:32 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 14:35:43 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 10:04:31 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Singla", "Sahil", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.10273", "submitter": "Xianfeng Tang", "authors": "Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Charu Aggarwal, Prasenjit Mitra,\n  Suhang Wang", "title": "Joint Modeling of Local and Global Temporal Dynamics for Multivariate\n  Time Series Forecasting with Missing Values", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) forecasting is widely used in various domains,\nsuch as meteorology and traffic. Due to limitations on data collection,\ntransmission, and storage, real-world MTS data usually contains missing values,\nmaking it infeasible to apply existing MTS forecasting models such as linear\nregression and recurrent neural networks. Though many efforts have been devoted\nto this problem, most of them solely rely on local dependencies for imputing\nmissing values, which ignores global temporal dynamics. Local\ndependencies/patterns would become less useful when the missing ratio is high,\nor the data have consecutive missing values; while exploring global patterns\ncan alleviate such problems. Thus, jointly modeling local and global temporal\ndynamics is very promising for MTS forecasting with missing values. However,\nwork in this direction is rather limited. Therefore, we study a novel problem\nof MTS forecasting with missing values by jointly exploring local and global\ntemporal dynamics. We propose a new framework LGnet, which leverages memory\nnetwork to explore global patterns given estimations from local perspectives.\nWe further introduce adversarial training to enhance the modeling of global\ntemporal distribution. Experimental results on real-world datasets show the\neffectiveness of LGnet for MTS forecasting with missing values and its\nrobustness under various missing ratios.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 22:52:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tang", "Xianfeng", ""], ["Yao", "Huaxiu", ""], ["Sun", "Yiwei", ""], ["Aggarwal", "Charu", ""], ["Mitra", "Prasenjit", ""], ["Wang", "Suhang", ""]]}, {"id": "1911.10287", "submitter": "Ghouthi Boukli Hacene", "authors": "Ghouthi Boukli Hacene, Fran\\c{c}ois Leduc-Primeau, Amal Ben Soussia,\n  Vincent Gripon and Fran\\c{c}ois Gagnon", "title": "Training Modern Deep Neural Networks for Memory-Fault Robustness", "comments": null, "journal-ref": "In 2019 IEEE International Symposium on Circuits and Systems\n  (ISCAS) (pp. 1-5). IEEE", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because deep neural networks (DNNs) rely on a large number of parameters and\ncomputations, their implementation in energy-constrained systems is\nchallenging. In this paper, we investigate the solution of reducing the supply\nvoltage of the memories used in the system, which results in bit-cell faults.\nWe explore the robustness of state-of-the-art DNN architectures towards such\ndefects and propose a regularizer meant to mitigate their effects on accuracy.\nOur experiments clearly demonstrate the interest of operating the system in a\nfaulty regime to save energy without reducing accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 00:09:36 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hacene", "Ghouthi Boukli", ""], ["Leduc-Primeau", "Fran\u00e7ois", ""], ["Soussia", "Amal Ben", ""], ["Gripon", "Vincent", ""], ["Gagnon", "Fran\u00e7ois", ""]]}, {"id": "1911.10291", "submitter": "Wei-An Lin", "authors": "Wei-An Lin and Yogesh Balaji and Pouya Samangouei and Rama Chellappa", "title": "Invert and Defend: Model-based Approximate Inversion of Generative\n  Adversarial Networks for Secure Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the latent variable generating a given test sample is a challenging\nproblem in Generative Adversarial Networks (GANs). In this paper, we propose\nInvGAN - a novel framework for solving the inference problem in GANs, which\ninvolves training an encoder network capable of inverting a pre-trained\ngenerator network without access to any training data. Under mild assumptions,\nwe theoretically show that using InvGAN, we can approximately invert the\ngenerations of any latent code of a trained GAN model. Furthermore, we\nempirically demonstrate the superiority of our inference scheme by quantitative\nand qualitative comparisons with other methods that perform a similar task. We\nalso show the effectiveness of our framework in the problem of adversarial\ndefenses where InvGAN can successfully be used as a projection-based defense\nmechanism. Additionally, we show how InvGAN can be used to implement\nreparameterization white-box attacks on projection-based defense mechanisms.\nExperimental validation on several benchmark datasets demonstrate the efficacy\nof our method in achieving improved performance on several white-box and\nblack-box attacks. Our code is available at\nhttps://github.com/yogeshbalaji/InvGAN.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:15:32 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Wei-An", ""], ["Balaji", "Yogesh", ""], ["Samangouei", "Pouya", ""], ["Chellappa", "Rama", ""]]}, {"id": "1911.10293", "submitter": "Jianguo Chen", "authors": "Jianguo Chen and Philip S. Yu", "title": "A Domain Adaptive Density Clustering Algorithm for Data with Varying\n  Density Distribution", "comments": "IEEE Transactions on Knowledge and Data Engineering, 2019", "journal-ref": null, "doi": "10.1109/TKDE.2019.2954133", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one type of efficient unsupervised learning methods, clustering algorithms\nhave been widely used in data mining and knowledge discovery with noticeable\nadvantages. However, clustering algorithms based on density peak have limited\nclustering effect on data with varying density distribution (VDD), equilibrium\ndistribution (ED), and multiple domain-density maximums (MDDM), leading to the\nproblems of sparse cluster loss and cluster fragmentation. To address these\nproblems, we propose a Domain-Adaptive Density Clustering (DADC) algorithm,\nwhich consists of three steps: domain-adaptive density measurement, cluster\ncenter self-identification, and cluster self-ensemble. For data with VDD\nfeatures, clusters in sparse regions are often neglected by using uniform\ndensity peak thresholds, which results in the loss of sparse clusters. We\ndefine a domain-adaptive density measurement method based on K-Nearest\nNeighbors (KNN) to adaptively detect the density peaks of different density\nregions. We treat each data point and its KNN neighborhood as a subgroup to\nbetter reflect its density distribution in a domain view. In addition, for data\nwith ED or MDDM features, a large number of density peaks with similar values\ncan be identified, which results in cluster fragmentation. We propose a cluster\ncenter self-identification and cluster self-ensemble method to automatically\nextract the initial cluster centers and merge the fragmented clusters.\nExperimental results demonstrate that compared with other comparative\nalgorithms, the proposed DADC algorithm can obtain more reasonable clustering\nresults on data with VDD, ED and MDDM features. Benefitting from a few\nparameter requirements and non-iterative nature, DADC achieves low\ncomputational complexity and is suitable for large-scale data clustering.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:21:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chen", "Jianguo", ""], ["Yu", "Philip S.", ""]]}, {"id": "1911.10298", "submitter": "Eric Wolff", "authors": "Tung Phan-Minh, Elena Corina Grigore, Freddy A. Boulton, Oscar\n  Beijbom, and Eric M. Wolff", "title": "CoverNet: Multimodal Behavior Prediction using Trajectory Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CoverNet, a new method for multimodal, probabilistic trajectory\nprediction for urban driving. Previous work has employed a variety of methods,\nincluding multimodal regression, occupancy maps, and 1-step stochastic\npolicies. We instead frame the trajectory prediction problem as classification\nover a diverse set of trajectories. The size of this set remains manageable due\nto the limited number of distinct actions that can be taken over a reasonable\nprediction horizon. We structure the trajectory set to a) ensure a desired\nlevel of coverage of the state space, and b) eliminate physically impossible\ntrajectories. By dynamically generating trajectory sets based on the agent's\ncurrent state, we can further improve our method's efficiency. We demonstrate\nour approach on public, real-world self-driving datasets, and show that it\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 01:46:59 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 22:41:55 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Phan-Minh", "Tung", ""], ["Grigore", "Elena Corina", ""], ["Boulton", "Freddy A.", ""], ["Beijbom", "Oscar", ""], ["Wolff", "Eric M.", ""]]}, {"id": "1911.10305", "submitter": "Yibo Yang", "authors": "Yibo Yang, Jianlong Wu, Hongyang Li, Xia Li, Tiancheng Shen, Zhouchen\n  Lin", "title": "Dynamical System Inspired Adaptive Time Stepping Controller for Residual\n  Network Families", "comments": "AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correspondence between residual networks and dynamical systems motivates\nresearchers to unravel the physics of ResNets with well-developed tools in\nnumeral methods of ODE systems. The Runge-Kutta-Fehlberg method is an adaptive\ntime stepping that renders a good trade-off between the stability and\nefficiency. Can we also have an adaptive time stepping for ResNets to ensure\nboth stability and performance? In this study, we analyze the effects of time\nstepping on the Euler method and ResNets. We establish a stability condition\nfor ResNets with step sizes and weight parameters, and point out the effects of\nstep sizes on the stability and performance. Inspired by our analyses, we\ndevelop an adaptive time stepping controller that is dependent on the\nparameters of the current step, and aware of previous steps. The controller is\njointly optimized with the network training so that variable step sizes and\nevolution time can be adaptively adjusted. We conduct experiments on ImageNet\nand CIFAR to demonstrate the effectiveness. It is shown that our proposed\nmethod is able to improve both stability and accuracy without introducing\nadditional overhead in inference phase.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 03:22:24 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Yibo", ""], ["Wu", "Jianlong", ""], ["Li", "Hongyang", ""], ["Li", "Xia", ""], ["Shen", "Tiancheng", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1911.10309", "submitter": "Sai Ravela", "authors": "Margaret Trautner and Sai Ravela", "title": "Neural Integration of Continuous Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dynamical systems are dynamical systems that are described at least in\npart by neural networks. The class of continuous-time neural dynamical systems\nmust, however, be numerically integrated for simulation and learning. Here, we\npresent a compact neural circuit for two common numerical integrators: the\nexplicit fixed-step Runge-Kutta method of any order and the\nsemi-implicit/predictor-corrector Adams-Bashforth-Moulton method. Modeled as\nconstant-sized recurrent networks embedding a continuous neural differential\nequation, they achieve fully neural temporal output. Using the polynomial class\nof dynamical systems, we demonstrate the equivalence of neural and numerical\nintegration.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 03:52:42 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Trautner", "Margaret", ""], ["Ravela", "Sai", ""]]}, {"id": "1911.10311", "submitter": "Shijie Xu", "authors": "Shijie Xu and Jiayan Fang and Xiang-Yang Li", "title": "Weighted Laplacian and Its Theoretical Applications", "comments": null, "journal-ref": null, "doi": "10.1088/1757-899X/768/7/072032", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a novel weighted Laplacian method, which is\npartially inspired by the theory of graph Laplacian, to study recent popular\ngraph problems, such as multilevel graph partitioning and balanced minimum cut\nproblem, in a more convenient manner. Since the weighted Laplacian strategy\ninherits the virtues of spectral methods, graph algorithms designed using\nweighted Laplacian will necessarily possess more robust theoretical guarantees\nfor algorithmic performances, comparing with those existing algorithms that are\nheuristically proposed. In order to illustrate its powerful utility both in\ntheory and in practice, we also present two effective applications of our\nweighted Laplacian method to multilevel graph partitioning and balanced minimum\ncut problem, respectively. By means of variational methods and theory of\npartial differential equations (PDEs), we have established the equivalence\nrelations among the weighted cut problem, balanced minimum cut problem and the\ninitial clustering problem that arises in the middle stage of graph\npartitioning algorithms under a multilevel structure. These equivalence\nrelations can indeed provide solid theoretical support for algorithms based on\nour proposed weighted Laplacian strategy. Moreover, from the perspective of the\napplication to the balanced minimum cut problem, weighted Laplacian can make it\npossible for research of numerical solutions of PDEs to be a powerful tool for\nthe algorithmic study of graph problems. Experimental results also indicate\nthat the algorithm embedded with our strategy indeed outperforms other existing\ngraph algorithms, especially in terms of accuracy, thus verifying the efficacy\nof the proposed weighted Laplacian.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 04:14:37 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Xu", "Shijie", ""], ["Fang", "Jiayan", ""], ["Li", "Xiang-Yang", ""]]}, {"id": "1911.10321", "submitter": "Juliano S. Assine", "authors": "Juliano S. Assine, Alan Godoy, Eduardo Valle", "title": "Compressing Representations for Embedded Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in architectures for mobile devices, deep learning\ncomputational requirements remains prohibitive for most embedded devices. To\naddress that issue, we envision sharing the computational costs of inference\nbetween local devices and the cloud, taking advantage of the compression\nperformed by the first layers of the networks to reduce communication costs.\nInference in such distributed setting would allow new applications, but\nrequires balancing a triple trade-off between computation cost, communication\nbandwidth, and model accuracy. We explore that trade-off by studying the\ncompressibility of representations at different stages of MobileNetV2, showing\nthose results agree with theoretical intuitions about deep learning, and that\nan optimal splitting layer for network can be found with a simple PCA-based\ncompression scheme.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 07:12:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Assine", "Juliano S.", ""], ["Godoy", "Alan", ""], ["Valle", "Eduardo", ""]]}, {"id": "1911.10322", "submitter": "Kiran Lekkala", "authors": "Kiran Lekkala and Sami Abu-El-Haija and Laurent Itti", "title": "Meta Adaptation using Importance Weighted Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has gained immense popularity because of its high\nsample-efficiency. However, in real-world scenarios, where the trajectory\ndistribution of most of the tasks dynamically shifts, model fitting on\ncontinuously aggregated data alone would be futile. In some cases, the\ndistribution shifts, so much, that it is difficult for an agent to infer the\nnew task. We propose a novel algorithm to generalize on any related task by\nleveraging prior knowledge on a set of specific tasks, which involves assigning\nimportance weights to each past demonstration. We show experiments where the\nrobot is trained from a diversity of environmental tasks and is also able to\nadapt to an unseen environment, using few-shot learning. We also developed a\nprototype robot system to test our approach on the task of visual navigation,\nand experimental results obtained were able to confirm these suppositions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 07:22:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Lekkala", "Kiran", ""], ["Abu-El-Haija", "Sami", ""], ["Itti", "Laurent", ""]]}, {"id": "1911.10373", "submitter": "Zhuo Feng", "authors": "Yongyu Wang, Zhiqiang Zhao, and Zhuo Feng", "title": "GRASPEL: Graph Spectral Learning at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful graphs from data plays important roles in many data\nmining and machine learning tasks, such as data representation and analysis,\ndimension reduction, data clustering, and visualization, etc. In this work, for\nthe first time, we present a highly-scalable spectral approach (GRASPEL) for\nlearning large graphs from data. By limiting the precision matrix to be a graph\nLaplacian, our approach aims to estimate ultra-sparse (tree-like) weighted\nundirected graphs and shows a clear connection with the prior graphical Lasso\nmethod. By interleaving the latest high-performance nearly-linear time spectral\nmethods for graph sparsification, coarsening and embedding, ultra-sparse yet\nspectrally-robust graphs can be learned by identifying and including the most\nspectrally-critical edges into the graph. Compared with prior state-of-the-art\ngraph learning approaches, GRASPEL is more scalable and allows substantially\nimproving computing efficiency and solution quality of a variety of data mining\nand machine learning applications, such as spectral clustering (SC), and\nt-Distributed Stochastic Neighbor Embedding (t-SNE). {For example, when\ncomparing with graphs constructed using existing methods, GRASPEL achieved the\nbest spectral clustering efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 14:51:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 00:19:38 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 21:08:51 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Wang", "Yongyu", ""], ["Zhao", "Zhiqiang", ""], ["Feng", "Zhuo", ""]]}, {"id": "1911.10395", "submitter": "Siddharth Biswal", "authors": "Siddharth Biswal, Cao Xiao, Lucas M. Glass, Elizabeth Milkovits,\n  Jimeng Sun", "title": "Doctor2Vec: Dynamic Doctor Representation Learning for Clinical Trial\n  Recruitment", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive electronic health records (EHRs) enable the success of learning\naccurate patient representations to support various predictive health\napplications. In contrast, doctor representation was not well studied despite\nthat doctors play pivotal roles in healthcare. How to construct the right\ndoctor representations? How to use doctor representation to solve important\nhealth analytic problems? In this work, we study the problem on {\\it clinical\ntrial recruitment}, which is about identifying the right doctors to help\nconduct the trials based on the trial description and patient EHR data of those\ndoctors. We propose doctor2vec which simultaneously learns 1) doctor\nrepresentations from EHR data and 2) trial representations from the description\nand categorical information about the trials. In particular, doctor2vec\nutilizes a dynamic memory network where the doctor's experience with patients\nare stored in the memory bank and the network will dynamically assign weights\nbased on the trial representation via an attention mechanism. Validated on\nlarge real-world trials and EHR data including 2,609 trials, 25K doctors and\n430K patients, doctor2vec demonstrated improved performance over the best\nbaseline by up to $8.7\\%$ in PR-AUC. We also demonstrated that the doctor2vec\nembedding can be transferred to benefit data insufficiency settings including\ntrial recruitment in less populated/newly explored country with $13.7\\%$\nimprovement or for rare diseases with $8.1\\%$ improvement in PR-AUC.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:59:12 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Biswal", "Siddharth", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Milkovits", "Elizabeth", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.10416", "submitter": "Yuyang Wang", "authors": "Ali Caner Turkmen, Yuyang Wang, Tim Januschowski", "title": "Intermittent Demand Forecasting with Deep Renewal Processes", "comments": "NeurIPS 2019 Workshop on Temporal Point Processes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intermittent demand, where demand occurrences appear sporadically in time, is\na common and challenging problem in forecasting. In this paper, we first make\nthe connections between renewal processes, and a collection of current models\nused for intermittent demand forecasting. We then develop a set of models that\nbenefit from recurrent neural networks to parameterize conditional interdemand\ntime and size distributions, building on the latest paradigm in \"deep\" temporal\npoint processes. We present favorable empirical findings on discrete and\ncontinuous time intermittent demand data, validating the practical value of our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 20:39:23 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Turkmen", "Ali Caner", ""], ["Wang", "Yuyang", ""], ["Januschowski", "Tim", ""]]}, {"id": "1911.10418", "submitter": "Yue Zhao", "authors": "Yue Zhao and Maciej K. Hryniewicki", "title": "DCSO: Dynamic Combination of Detector Scores for Outlier Ensembles", "comments": "ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),\n  Outlier Detection De-constructed Workshop, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting and combining the outlier scores of different base detectors used\nwithin outlier ensembles can be quite challenging in the absence of ground\ntruth. In this paper, an unsupervised outlier detector combination framework\ncalled DCSO is proposed, demonstrated and assessed for the dynamic selection of\nmost competent base detectors, with an emphasis on data locality. The proposed\nDCSO framework first defines the local region of a test instance by its k\nnearest neighbors and then identifies the top-performing base detectors within\nthe local region. Experimental results on ten benchmark datasets demonstrate\nthat DCSO provides consistent performance improvement over existing static\ncombination approaches in mining outlying objects. To facilitate\ninterpretability and reliability of the proposed method, DCSO is analyzed using\nboth theoretical frameworks and visualization techniques, and presented\nalongside empirical parameter setting instructions that can be used to improve\nthe overall performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 21:16:00 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhao", "Yue", ""], ["Hryniewicki", "Maciej K.", ""]]}, {"id": "1911.10434", "submitter": "Yuedong Wang", "authors": "Danqing Xu and Yuedong Wang", "title": "Low Rank Approximation for Smoothing Spline via Eigensystem Truncation", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing splines provide a powerful and flexible means for nonparametric\nestimation and inference. With a cubic time complexity, fitting smoothing\nspline models to large data is computationally prohibitive. In this paper, we\nuse the theoretical optimal eigenspace to derive a low rank approximation of\nthe smoothing spline estimates. We develop a method to approximate the\neigensystem when it is unknown and derive error bounds for the approximate\nestimates. The proposed methods are easy to implement with existing software.\nExtensive simulations show that the new methods are accurate, fast, and\ncompares favorably against existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 23:50:29 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 17:04:32 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Xu", "Danqing", ""], ["Wang", "Yuedong", ""]]}, {"id": "1911.10442", "submitter": "Eli (Omid) David", "authors": "Ido Faran, Nathan S. Netanyahu, Eli David, Maxim Shoshany, Fadi Kizel,\n  Jisung Geba Chang, Ronit Rud", "title": "Ground Truth Simulation for Deep Learning Classification of\n  Mid-Resolution Venus Images Via Unmixing of High-Resolution Hyperspectral\n  Fenix Data", "comments": null, "journal-ref": "IEEE International Geoscience and Remote Sensing Symposium\n  (IGARSS), pages 807-810, Yokohama, Japan, July 2019", "doi": "10.1109/IGARSS.2019.8900186", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network for classification constitutes a major problem\nin remote sensing due to the lack of adequate field data. Acquiring\nhigh-resolution ground truth (GT) by human interpretation is both\ncost-ineffective and inconsistent. We propose, instead, to utilize\nhigh-resolution, hyperspectral images for solving this problem, by unmixing\nthese images to obtain reliable GT for training a deep network. Specifically,\nwe simulate GT from high-resolution, hyperspectral FENIX images, and use it for\ntraining a convolutional neural network (CNN) for pixel-based classification.\nWe show how the model can be transferred successfully to classify new\nmid-resolution VENuS imagery.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 01:31:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Faran", "Ido", ""], ["Netanyahu", "Nathan S.", ""], ["David", "Eli", ""], ["Shoshany", "Maxim", ""], ["Kizel", "Fadi", ""], ["Chang", "Jisung Geba", ""], ["Rud", "Ronit", ""]]}, {"id": "1911.10454", "submitter": "Davoud Ataee Tarzanagh", "authors": "Davoud Ataee Tarzanagh and George Michailidis", "title": "Regularized and Smooth Double Core Tensor Factorization for\n  Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general tensor model suitable for data analytic tasks for\nheterogeneous data sets, wherein there are joint low-rank structures within\ngroups of observations, but also discriminative structures across different\ngroups. To capture such complex structures, a double core tensor (DCOT)\nfactorization model is introduced together with a family of smoothing loss\nfunctions. By leveraging the proposed smoothing function, the model accurately\nestimates the model factors, even in the presence of missing entries. A\nlinearized ADMM method is employed to solve regularized versions of DCOT\nfactorizations, that avoid large tensor operations and large memory storage\nrequirements. Further, we establish theoretically its global convergence,\ntogether with consistency of the estimates of the model parameters. The\neffectiveness of the DCOT model is illustrated on several real-world examples\nincluding image completion, recommender systems, subspace clustering and\ndetecting modules in heterogeneous Omics multi-modal data, since it provides\nmore insightful decompositions than conventional tensor methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 04:01:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tarzanagh", "Davoud Ataee", ""], ["Michailidis", "George", ""]]}, {"id": "1911.10500", "submitter": "Bernhard Sch\\\"olkopf", "authors": "Bernhard Sch\\\"olkopf", "title": "Causality for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical causal inference as pioneered by Judea Pearl arose from research on\nartificial intelligence (AI), and for a long time had little connection to the\nfield of machine learning.\n  This article discusses where links have been and should be established,\nintroducing key concepts along the way. It argues that the hard open problems\nof machine learning and AI are intrinsically related to causality, and explains\nhow the field is beginning to understand them.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:04:56 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 16:20:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1911.10504", "submitter": "Ahnjae Shin", "authors": "Ahnjae Shin, Dong-Jin Shin, Sungwoo Cho, Do Yoon Kim, Eunji Jeong,\n  Gyeong-In Yu, Byung-Gon Chun", "title": "Stage-based Hyper-parameter Optimization for Deep Learning", "comments": null, "journal-ref": "Workshop on Systems for ML at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning techniques advance more than ever, hyper-parameter\noptimization is the new major workload in deep learning clusters. Although\nhyper-parameter optimization is crucial in training deep learning models for\nhigh model performance, effectively executing such a computation-heavy workload\nstill remains a challenge. We observe that numerous trials issued from existing\nhyper-parameter optimization algorithms share common hyper-parameter sequence\nprefixes, which implies that there are redundant computations from training the\nsame hyper-parameter sequence multiple times. We propose a stage-based\nexecution strategy for efficient execution of hyper-parameter optimization\nalgorithms. Our strategy removes redundancy in the training process by\nsplitting the hyper-parameter sequences of trials into homogeneous stages, and\ngenerating a tree of stages by merging the common prefixes. Our preliminary\nexperiment results show that applying stage-based execution to hyper-parameter\noptimization algorithms outperforms the original trial-based method, saving\nrequired GPU-hours and end-to-end training time by up to 6.60 times and 4.13\ntimes, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:24:33 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shin", "Ahnjae", ""], ["Shin", "Dong-Jin", ""], ["Cho", "Sungwoo", ""], ["Kim", "Do Yoon", ""], ["Jeong", "Eunji", ""], ["Yu", "Gyeong-In", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "1911.10506", "submitter": "Riddhish Bhalodia", "authors": "Riddhish Bhalodia, Iain Lee, Shireen Elhabian", "title": "dpVAEs: Fixing Sample Generation for Regularized VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning via generative modeling is a staple to\nmany computer vision applications in the absence of labeled data. Variational\nAutoencoders (VAEs) are powerful generative models that learn representations\nuseful for data generation. However, due to inherent challenges in the training\nobjective, VAEs fail to learn useful representations amenable for downstream\ntasks. Regularization-based methods that attempt to improve the representation\nlearning aspect of VAEs come at a price: poor sample generation. In this paper,\nwe explore this representation-generation trade-off for regularized VAEs and\nintroduce a new family of priors, namely decoupled priors, or dpVAEs, that\ndecouple the representation space from the generation space. This decoupling\nenables the use of VAE regularizers on the representation space without\nimpacting the distribution used for sample generation, and thereby reaping the\nrepresentation learning benefits of the regularizations without sacrificing the\nsample generation. dpVAE leverages invertible networks to learn a bijective\nmapping from an arbitrarily complex representation distribution to a simple,\ntractable, generative distribution. Decoupled priors can be adapted to the\nstate-of-the-art VAE regularizers without additional hyperparameter tuning. We\nshowcase the use of dpVAEs with different regularizers. Experiments on MNIST,\nSVHN, and CelebA demonstrate, quantitatively and qualitatively, that dpVAE\nfixes sample generation for regularized VAEs.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:31:39 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 03:54:34 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bhalodia", "Riddhish", ""], ["Lee", "Iain", ""], ["Elhabian", "Shireen", ""]]}, {"id": "1911.10516", "submitter": "Weijia Zhang", "authors": "Weijia Zhang, Hao Liu, Yanchi Liu, Jingbo Zhou, Hui Xiong", "title": "Semi-Supervised Hierarchical Recurrent Graph Neural Network for\n  City-Wide Parking Availability Prediction", "comments": "8 pages, 9 figures, AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict city-wide parking availability is crucial for the\nsuccessful development of Parking Guidance and Information (PGI) systems.\nIndeed, the effective prediction of city-wide parking availability can improve\nparking efficiency, help urban planning, and ultimately alleviate city\ncongestion. However, it is a non-trivial task for predicting citywide parking\navailability because of three major challenges: 1) the non-Euclidean spatial\nautocorrelation among parking lots, 2) the dynamic temporal autocorrelation\ninside of and between parking lots, and 3) the scarcity of information about\nreal-time parking availability obtained from real-time sensors (e.g., camera,\nultrasonic sensor, and GPS). To this end, we propose Semi-supervised\nHierarchical Recurrent Graph Neural Network (SHARE) for predicting city-wide\nparking availability. Specifically, we first propose a hierarchical graph\nconvolution structure to model non-Euclidean spatial autocorrelation among\nparking lots. Along this line, a contextual graph convolution block and a soft\nclustering graph convolution block are respectively proposed to capture local\nand global spatial dependencies between parking lots. Additionally, we adopt a\nrecurrent neural network to incorporate dynamic temporal dependencies of\nparking lots. Moreover, we propose a parking availability approximation module\nto estimate missing real-time parking availabilities from both spatial and\ntemporal domain. Finally, experiments on two real-world datasets demonstrate\nthe prediction performance of SHARE outperforms seven state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 12:17:04 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Weijia", ""], ["Liu", "Hao", ""], ["Liu", "Yanchi", ""], ["Zhou", "Jingbo", ""], ["Xiong", "Hui", ""]]}, {"id": "1911.10527", "submitter": "Gang Chen", "authors": "Gang Chen", "title": "Merging Deterministic Policy Gradient Estimations with Varied\n  Bias-Variance Tradeoff for Effective Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) on Markov decision processes (MDPs) with\ncontinuous action spaces is often approached by directly training parametric\npolicies along the direction of estimated policy gradients (PGs). Previous\nresearch revealed that the performance of these PG algorithms depends heavily\non the bias-variance tradeoffs involved in estimating and using PGs. A notable\napproach towards balancing this tradeoff is to merge both on-policy and\noff-policy gradient estimations. However existing PG merging methods can be\nsample inefficient and are not suitable to train deterministic policies\ndirectly. To address these issues, this paper introduces elite PGs and\nstrengthens their variance reduction effect by adopting elitism and policy\nconsolidation techniques to regularize policy training based on policy\nbehavioral knowledge extracted from elite trajectories. Meanwhile, we propose a\ntwo-step method to merge elite PGs and conventional PGs as a new extension of\nthe conventional interpolation merging method. At both the theoretical and\nexperimental levels, we show that both two-step merging and interpolation\nmerging can induce varied bias-variance tradeoffs during policy training. They\nenable us to effectively use elite PGs and mitigate their performance impact on\ntrained policies. Our experiments also show that two-step merging can\noutperform interpolation merging and several state-of-the-art algorithms on six\nbenchmark control tasks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 13:44:32 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 06:10:58 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 09:11:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chen", "Gang", ""]]}, {"id": "1911.10541", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Vitaly Feldman", "title": "PAC learning with stable and private predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study binary classification algorithms for which the prediction on any\npoint is not too sensitive to individual examples in the dataset. Specifically,\nwe consider the notions of uniform stability (Bousquet and Elisseeff, 2001) and\nprediction privacy (Dwork and Feldman, 2018). Previous work on these notions\nshows how they can be achieved in the standard PAC model via simple aggregation\nof models trained on disjoint subsets of data. Unfortunately, this approach\nleads to a significant overhead in terms of sample complexity. Here we\ndemonstrate several general approaches to stable and private prediction that\neither eliminate or significantly reduce the overhead. Specifically, we\ndemonstrate that for any class $C$ of VC dimension $d$ there exists a\n$\\gamma$-uniformly stable algorithm for learning $C$ with excess error $\\alpha$\nusing $\\tilde O(d/(\\alpha\\gamma) + d/\\alpha^2)$ samples. We also show that this\nbound is nearly tight. For $\\epsilon$-differentially private prediction we give\ntwo new algorithms: one using $\\tilde O(d/(\\alpha^2\\epsilon))$ samples and\nanother one using $\\tilde O(d^2/(\\alpha\\epsilon) + d/\\alpha^2)$ samples. The\nbest previously known bounds for these problems are $O(d/(\\alpha^2\\gamma))$ and\n$O(d/(\\alpha^3\\epsilon))$, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 14:48:29 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:11:58 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1911.10558", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Minrun Wu, Shao-Bo Lin, Ding-Xuan Zhou", "title": "Fast Polynomial Kernel Classification for Massive Data", "comments": "arXiv admin note: text overlap with arXiv:1402.4735 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, it is highly desired to develop efficient machine\nlearning algorithms to tackle massive data challenges such as storage\nbottleneck, algorithmic scalability, and interpretability. In this paper, we\ndevelop a novel efficient classification algorithm, called fast polynomial\nkernel classification (FPC), to conquer the scalability and storage challenges.\nOur main tools are a suitable selected feature mapping based on polynomial\nkernels and an alternating direction method of multipliers (ADMM) algorithm for\na related non-smooth convex optimization problem. Fast learning rates as well\nas feasibility verifications including the convergence of ADMM and the\nselection of center points are established to justify theoretical behaviors of\nFPC. Our theoretical assertions are verified by a series of simulations and\nreal data applications. The numerical results demonstrate that FPC\nsignificantly reduces the computational burden and storage memory of the\nexisting learning schemes such as support vector machines and boosting, without\nsacrificing their generalization abilities much.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:02:21 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 10:19:30 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zeng", "Jinshan", ""], ["Wu", "Minrun", ""], ["Lin", "Shao-Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1911.10563", "submitter": "Mrinank Sharma", "authors": "Mrinank Sharma, Michael Hutchinson, Siddharth Swaroop, Antti Honkela,\n  Richard E. Turner", "title": "Differentially Private Federated Variational Inference", "comments": "Privacy in Machine Learning Workshop (PriML 2019) at the 33rd\n  Conference in Neural Information and Processing Systems (NeurIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications of machine learning, data are distributed\nacross many clients and cannot leave the devices they are stored on.\nFurthermore, each client's data, computational resources and communication\nconstraints may be very different. This setting is known as federated learning,\nin which privacy is a key concern. Differential privacy is commonly used to\nprovide mathematical privacy guarantees. This work, to the best of our\nknowledge, is the first to consider federated, differentially private, Bayesian\nlearning. We build on Partitioned Variational Inference (PVI) which was\nrecently developed to support approximate Bayesian inference in the federated\nsetting. We modify the client-side optimisation of PVI to provide an\n(${\\epsilon}$, ${\\delta}$)-DP guarantee. We show that it is possible to learn\nmoderately private logistic regression models in the federated setting that\nachieve similar performance to models trained non-privately on centralised\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:15:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sharma", "Mrinank", ""], ["Hutchinson", "Michael", ""], ["Swaroop", "Siddharth", ""], ["Honkela", "Antti", ""], ["Turner", "Richard E.", ""]]}, {"id": "1911.10594", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Sreena Nallamothu, Marios Savvides", "title": "Towards a Hypothesis on Visual Transformation based Self-Supervision", "comments": "Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first qualitative hypothesis characterizing the behavior of\nvisual transformation based self-supervision, called the VTSS hypothesis. Given\na dataset upon which a self-supervised task is performed while predicting\ninstantiations of a transformation, the hypothesis states that if the predicted\ninstantiations of the transformations are already present in the dataset, then\nthe representation learned will be less useful. The hypothesis was derived by\nobserving a key constraint in the application of self-supervision using a\nparticular transformation. This constraint, which we term the transformation\nconflict for this paper, forces a network learn degenerative features thereby\nreducing the usefulness of the representation. The VTSS hypothesis helps us\nidentify transformations that have the potential to be effective as a\nself-supervision task. Further, it helps to generally predict whether a\nparticular transformation based self-supervision technique would be effective\nor not for a particular dataset. We provide extensive evaluations on CIFAR 10,\nCIFAR 100, SVHN and FMNIST confirming the hypothesis and the trends it\npredicts. We also propose novel cost-effective self-supervision techniques\nbased on translation and scale, which when combined with rotation outperforms\nall transformations applied individually. Overall, this paper aims to shed\nlight on the phenomenon of visual transformation based self-supervision.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 19:27:35 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 03:51:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Pal", "Dipan K.", ""], ["Nallamothu", "Sreena", ""], ["Savvides", "Marios", ""]]}, {"id": "1911.10599", "submitter": "Erik Norlander", "authors": "Erik Norlander and Alexandros Sopasakis", "title": "Latent space conditioning for improved classification and anomaly\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of variational autoencoder to perform improved\npre-processing for clustering and anomaly detection on data with a given label.\nAnomalies however are not known or labeled. We call our method conditional\nlatent space variational autonencoder since it separates the latent space by\nconditioning on information within the data. The method fits one prior\ndistribution to each class in the dataset, effectively expanding the prior\ndistribution to include a Gaussian mixture model. Our approach is compared\nagainst the capabilities of a typical variational autoencoder by measuring\ntheir V-score during cluster formation with respect to the k-means and EM\nalgorithms.\n  For anomaly detection, we use a new metric composed of the mass-volume and\nexcess-mass curves which can work in an unsupervised setting. We compare the\nresults between established methods such as as isolation forest, local outlier\nfactor and one-class support vector machine.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 19:39:58 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 13:55:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Norlander", "Erik", ""], ["Sopasakis", "Alexandros", ""]]}, {"id": "1911.10601", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Manuel Baltieri, Anil. K. Seth, Christopher L.\n  Buckley", "title": "Scaling active inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.SY eess.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), agents often operate in partially observed\nand uncertain environments. Model-based RL suggests that this is best achieved\nby learning and exploiting a probabilistic model of the world. 'Active\ninference' is an emerging normative framework in cognitive and computational\nneuroscience that offers a unifying account of how biological agents achieve\nthis. On this framework, inference, learning and action emerge from a single\nimperative to maximize the Bayesian evidence for a niched model of the world.\nHowever, implementations of this process have thus far been restricted to\nlow-dimensional and idealized situations. Here, we present a working\nimplementation of active inference that applies to high-dimensional tasks, with\nproof-of-principle results demonstrating efficient exploration and an order of\nmagnitude increase in sample efficiency over strong model-free baselines. Our\nresults demonstrate the feasibility of applying active inference at scale and\nhighlight the operational homologies between active inference and current\nmodel-based approaches to RL.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:03:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tschantz", "Alexander", ""], ["Baltieri", "Manuel", ""], ["Seth", "Anil. K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "1911.10608", "submitter": "Manpreet Singh Minhas", "authors": "Manpreet Singh Minhas, John Zelek", "title": "AnoNet: Weakly Supervised Anomaly Detection in Textured Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humans can easily detect a defect (anomaly) because it is different or\nsalient when compared to the surface it resides on. Today, manual human visual\ninspection is still the norm because it is difficult to automate anomaly\ndetection. Neural networks are a useful tool that can teach a machine to find\ndefects. However, they require a lot of training examples to learn what a\ndefect is and it is tedious and expensive to get these samples. We tackle the\nproblem of teaching a network with a low number of training samples with a\nsystem we call AnoNet. AnoNet's architecture is similar to CompactCNN with the\nexceptions that (1) it is a fully convolutional network and does not use\nstrided convolution; (2) it is shallow and compact which minimizes over-fitting\nby design; (3) the compact design constrains the size of intermediate features\nwhich allows training to be done without image downsizing; (4) the model\nfootprint is low making it suitable for edge computation; and (5) the anomaly\ncan be detected and localized despite the weak labelling. AnoNet learns to\ndetect the underlying shape of the anomalies despite the weak annotation as\nwell as preserves the spatial localization of the anomaly. Pre-seeding AnoNet\nwith an engineered filter bank initialization technique reduces the total\nsamples required for training and also achieves state-of-the-art performance.\nCompared to the CompactCNN, AnoNet achieved a massive 94% reduction of network\nparameters from 1.13 million to 64 thousand parameters. Experiments were\nconducted on four data-sets and results were compared against CompactCNN and\nDeepLabv3. AnoNet improved the performance on an average across all data-sets\nby 106% to an F1 score of 0.98 and by 13% to an AUROC value of 0.942. AnoNet\ncan learn from a limited number of images. For one of the data-sets, AnoNet\nlearnt to detect anomalies after a single pass through just 53 training images.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 21:05:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Minhas", "Manpreet Singh", ""], ["Zelek", "John", ""]]}, {"id": "1911.10621", "submitter": "Samet Demir", "authors": "Samet Demir, Hasan Ferit Eniser, Alper Sen", "title": "DeepSmartFuzzer: Reward Guided Test Generation For Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing Deep Neural Network (DNN) models has become more important than ever\nwith the increasing usage of DNN models in safety-critical domains such as\nautonomous cars. The traditional approach of testing DNNs is to create a test\nset, which is a random subset of the dataset about the problem of interest.\nThis kind of approach is not enough for testing most of the real-world\nscenarios since these traditional test sets do not include corner cases, while\na corner case input is generally considered to introduce erroneous behaviors.\nRecent works on adversarial input generation, data augmentation, and\ncoverage-guided fuzzing (CGF) have provided new ways to extend traditional test\nsets. Among those, CGF aims to produce new test inputs by fuzzing existing ones\nto achieve high coverage on a test adequacy criterion (i.e. coverage\ncriterion). Given that the subject test adequacy criterion is a\nwell-established one, CGF can potentially find error inducing inputs for\ndifferent underlying reasons. In this paper, we propose a novel CGF solution\nfor structural testing of DNNs. The proposed fuzzer employs Monte Carlo Tree\nSearch to drive the coverage-guided search in the pursuit of achieving high\ncoverage. Our evaluation shows that the inputs generated by our method result\nin higher coverage than the inputs produced by the previously introduced\ncoverage-guided fuzzing techniques.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:18:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Demir", "Samet", ""], ["Eniser", "Hasan Ferit", ""], ["Sen", "Alper", ""]]}, {"id": "1911.10635", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, and Tamer Ba\\c{s}ar", "title": "Multi-Agent Reinforcement Learning: A Selective Overview of Theories and\n  Algorithms", "comments": "Invited Chapter in Handbook on RL and Control (Springer Studies in\n  Systems, Decision and Control); Proofread version from the Publisher", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed significant advances in reinforcement learning\n(RL), which has registered great success in solving various sequential\ndecision-making problems in machine learning. Most of the successful RL\napplications, e.g., the games of Go and Poker, robotics, and autonomous\ndriving, involve the participation of more than one single agent, which\nnaturally fall into the realm of multi-agent RL (MARL), a domain with a\nrelatively long history, and has recently re-emerged due to advances in\nsingle-agent RL techniques. Though empirically successful, theoretical\nfoundations for MARL are relatively lacking in the literature. In this chapter,\nwe provide a selective overview of MARL, with focus on algorithms backed by\ntheoretical analysis. More specifically, we review the theoretical results of\nMARL algorithms mainly within two representative frameworks, Markov/stochastic\ngames and extensive-form games, in accordance with the types of tasks they\naddress, i.e., fully cooperative, fully competitive, and a mix of the two. We\nalso introduce several significant but challenging applications of these\nalgorithms. Orthogonal to the existing reviews on MARL, we highlight several\nnew angles and taxonomies of MARL theory, including learning in extensive-form\ngames, decentralized MARL with networked agents, MARL in the mean-field regime,\n(non-)convergence of policy-based methods for learning in games, etc. Some of\nthe new angles extrapolate from our own research endeavors and interests. Our\noverall goal with this chapter is, beyond providing an assessment of the\ncurrent state of the field on the mark, to identify fruitful future research\ndirections on theoretical studies of MARL. We expect this chapter to serve as\ncontinuing stimulus for researchers interested in working on this exciting\nwhile challenging topic.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:50:32 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 21:33:13 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1911.10640", "submitter": "Aria Khademi", "authors": "Aria Khademi and Vasant Honavar", "title": "Algorithmic Bias in Recidivism Prediction: A Causal Perspective", "comments": "Accepted for publication at the Thirty Fourth AAAI conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProPublica's analysis of recidivism predictions produced by Correctional\nOffender Management Profiling for Alternative Sanctions (COMPAS) software tool\nfor the task, has shown that the predictions were racially biased against\nAfrican American defendants. We analyze the COMPAS data using a causal\nreformulation of the underlying algorithmic fairness problem. Specifically, we\nassess whether COMPAS exhibits racial bias against African American defendants\nusing FACT, a recently introduced causality grounded measure of algorithmic\nfairness. We use the Neyman-Rubin potential outcomes framework for causal\ninference from observational data to estimate FACT from COMPAS data. Our\nanalysis offers strong evidence that COMPAS exhibits racial bias against\nAfrican American defendants. We further show that the FACT estimates from\nCOMPAS data are robust in the presence of unmeasured confounding.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 23:47:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Khademi", "Aria", ""], ["Honavar", "Vasant", ""]]}, {"id": "1911.10651", "submitter": "Ilan Price", "authors": "Ilan Price, Jared Tanner", "title": "Trajectory growth lower bounds for random sparse deep ReLU networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the growth in the length of one-dimensional trajectories\nas they are passed through deep ReLU neural networks, which, among other\nthings, is one measure of the expressivity of deep networks. We generalise\nexisting results, providing an alternative, simpler method for lower bounding\nexpected trajectory growth through random networks, for a more general class of\nweights distributions, including sparsely connected networks. We illustrate\nthis approach by deriving bounds for sparse-Gaussian, sparse-uniform, and\nsparse-discrete-valued random nets. We prove that trajectory growth can remain\nexponential in depth with these new distributions, including their sparse\nvariants, with the sparsity parameter appearing in the base of the exponent.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:01:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Price", "Ilan", ""], ["Tanner", "Jared", ""]]}, {"id": "1911.10653", "submitter": "Ilianna Kollia", "authors": "James Wingate and Ilianna Kollia and Luc Bidaut and Stefanos Kollias", "title": "A Unified Deep Learning Approach for Prediction of Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel approach, based on deep learning, for diagnosis of\nParkinson's disease through medical imaging. The approach includes analysis and\nuse of the knowledge extracted by Deep Convolutional and Recurrent Neural\nNetworks (DNNs) when trained with medical images, such as Magnetic Resonance\nImages and DaTscans. Internal representations of the trained DNNs constitute\nthe extracted knowledge which is used in a transfer learning and domain\nadaptation manner, so as to create a unified framework for prediction of\nParkinson's across different medical environments. A large experimental study\nis presented illustrating the ability of the proposed approach to effectively\npredict Parkinson's, using different medical image sets from real environments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:20:38 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wingate", "James", ""], ["Kollia", "Ilianna", ""], ["Bidaut", "Luc", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1911.10654", "submitter": "Md Rashidul Hasan", "authors": "Md Rashidul Hasan and Muntasir Al Kabir", "title": "Lung Cancer Detection and Classification based on Image Processing and\n  Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is one of the death threatening diseases among human beings.\nEarly and accurate detection of lung cancer can increase the survival rate from\nlung cancer. Computed Tomography (CT) images are commonly used for detecting\nthe lung cancer.Using a data set of thousands of high-resolution lung scans\ncollected from Kaggle competition [1], we will develop algorithms that\naccurately determine in the lungs are cancerous or not. The proposed system\npromises better result than the existing systems, which would be beneficial for\nthe radiologist for the accurate and early detection of cancer. The method has\nbeen tested on 198 slices of CT images of various stages of cancer obtained\nfrom Kaggle dataset[1] and is found satisfactory results. The accuracy of the\nproposed method in this dataset is 72.2%\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:24:13 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hasan", "Md Rashidul", ""], ["Kabir", "Muntasir Al", ""]]}, {"id": "1911.10658", "submitter": "Wenye Ma", "authors": "Wenye Ma", "title": "Projective Quadratic Regression for Online Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers online convex optimization (OCO) problems - the\nparamount framework for online learning algorithm design. The loss function of\nlearning task in OCO setting is based on streaming data so that OCO is a\npowerful tool to model large scale applications such as online recommender\nsystems. Meanwhile, real-world data are usually of extreme high-dimensional due\nto modern feature engineering techniques so that the quadratic regression is\nimpractical. Factorization Machine as well as its variants are efficient models\nfor capturing feature interactions with low-rank matrix model but they can't\nfulfill the OCO setting due to their non-convexity. In this paper, We propose a\nprojective quadratic regression (PQR) model. First, it can capture the import\nsecond-order feature information. Second, it is a convex model, so the\nrequirements of OCO are fulfilled and the global optimal solution can be\nachieved. Moreover, existing modern online optimization methods such as Online\nGradient Descent (OGD) or Follow-The-Regularized-Leader (FTRL) can be applied\ndirectly. In addition, by choosing a proper hyper-parameter, we show that it\nhas the same order of space and time complexity as the linear model and thus\ncan handle high-dimensional data. Experimental results demonstrate the\nperformance of the proposed PQR model in terms of accuracy and efficiency by\ncomparing with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 01:43:30 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ma", "Wenye", ""]]}, {"id": "1911.10674", "submitter": "Kun Song", "authors": "Kun Song", "title": "Adaptive Nearest Neighbor: A General Framework for Distance Metric\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $K$-NN classifier is one of the most famous classification algorithms, whose\nperformance is crucially dependent on the distance metric. When we consider the\ndistance metric as a parameter of $K$-NN, learning an appropriate distance\nmetric for $K$-NN can be seen as minimizing the empirical risk of $K$-NN. In\nthis paper, we design a new type of continuous decision function of the $K$-NN\nclassification rule which can be used to construct the continuous empirical\nrisk function of $K$-NN. By minimizing this continuous empirical risk function,\nwe obtain a novel distance metric learning algorithm named as adaptive nearest\nneighbor (ANN). We have proved that the current algorithms such as the large\nmargin nearest neighbor (LMNN), neighbourhood components analysis (NCA) and the\npairwise constraint methods are special cases of the proposed ANN by setting\nthe parameter different values. Compared with the LMNN, NCA, and pairwise\nconstraint methods, our method has a broader searching space which may contain\nbetter solutions. At last, extensive experiments on various data sets are\nconducted to demonstrate the effectiveness and efficiency of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:31:25 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Song", "Kun", ""]]}, {"id": "1911.10684", "submitter": "Yuguang Yang", "authors": "Yuguang Yang", "title": "A Deep Reinforcement Learning Architecture for Multi-stage Optimal\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning for high dimensional, hierarchical control tasks\nusually requires the use of complex neural networks as functional\napproximators, which can lead to inefficiency, instability and even divergence\nin the training process. Here, we introduce stacked deep Q learning (SDQL), a\nflexible modularized deep reinforcement learning architecture, that can enable\nfinding of optimal control policy of control tasks consisting of multiple\nlinear stages in a stable and efficient way. SDQL exploits the linear stage\nstructure by approximating the Q function via a collection of deep Q\nsub-networks stacking along an axis marking the stage-wise progress of the\nwhole task. By back-propagating the learned state values from later stages to\nearlier stages, all sub-networks co-adapt to maximize the total reward of the\nwhole task, although each sub-network is responsible for learning optimal\ncontrol policy for its own stage. This modularized architecture offers\nconsiderable flexibility in terms of environment and policy modeling, as it\nallows choices of different state spaces, action spaces, reward structures, and\nQ networks for each stage, Further, the backward stage-wise training procedure\nof SDQL can offers additional transparency, stability, and flexibility to the\ntraining process, thus facilitating model fine-tuning and hyper-parameter\nsearch. We demonstrate that SDQL is capable of learning competitive strategies\nfor problems with characteristics of high-dimensional state space,\nheterogeneous action space(both discrete and continuous), multiple scales, and\nsparse and delayed rewards.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:36:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Yuguang", ""]]}, {"id": "1911.10687", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Seishirou Ueno", "title": "Improvement of Batch Normalization in Imbalanced Data", "comments": null, "journal-ref": "Proceedings of the 2019 International Symposium on Nonlinear\n  Theory and its Applications (NOLTA2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we consider classification problems based on neural networks\nin data-imbalanced environment. Learning from an imbalanced data set is one of\nthe most important and practical problems in the field of machine learning. A\nweighted loss function based on cost-sensitive approach is a well-known\neffective method for imbalanced data sets. We consider a combination of\nweighted loss function and batch normalization (BN) in this study. BN is a\npowerful standard technique in the recent developments in deep learning. A\nsimple combination of both methods leads to a size-mismatch problem due to a\nmismatch between interpretations of effective size of data set in both methods.\nWe propose a simple modification to BN to correct the size-mismatch and\ndemonstrate that this modified BN is effective in data-imbalanced environment.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:43:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yasuda", "Muneki", ""], ["Ueno", "Seishirou", ""]]}, {"id": "1911.10688", "submitter": "Zhenyue Qin", "authors": "Zhenyue Qin and Dongwoo Kim and Tom Gedeon", "title": "Rethinking Softmax with Cross-Entropy: Neural Network Classifier as\n  Mutual Information Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information is widely applied to learn latent representations of\nobservations, whilst its implication in classification neural networks remain\nto be better explained. We show that optimising the parameters of\nclassification neural networks with softmax cross-entropy is equivalent to\nmaximising the mutual information between inputs and labels under the balanced\ndata assumption. Through experiments on synthetic and real datasets, we show\nthat softmax cross-entropy can estimate mutual information approximately. When\napplied to image classification, this relation helps approximate the point-wise\nmutual information between an input image and a label without modifying the\nnetwork structure. To this end, we propose infoCAM, informative class\nactivation map, which highlights regions of the input image that are the most\nrelevant to a given label based on differences in information. The activation\nmap helps localise the target object in an input image. Through experiments on\nthe semi-supervised object localisation task with two real-world datasets, we\nevaluate the effectiveness of our information-theoretic approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:44:34 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 11:46:40 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 12:53:51 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2020 04:47:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Qin", "Zhenyue", ""], ["Kim", "Dongwoo", ""], ["Gedeon", "Tom", ""]]}, {"id": "1911.10695", "submitter": "Yuzhe Yang", "authors": "Minghao Guo, Yuzhe Yang, Rui Xu, Ziwei Liu, Dahua Lin", "title": "When NAS Meets Robustness: In Search of Robust Architectures against\n  Adversarial Attacks", "comments": "CVPR 2020. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in adversarial attacks uncover the intrinsic vulnerability of\nmodern deep neural networks. Since then, extensive efforts have been devoted to\nenhancing the robustness of deep networks via specialized learning algorithms\nand loss functions. In this work, we take an architectural perspective and\ninvestigate the patterns of network architectures that are resilient to\nadversarial attacks. To obtain the large number of networks needed for this\nstudy, we adopt one-shot neural architecture search, training a large network\nfor once and then finetuning the sub-networks sampled therefrom. The sampled\narchitectures together with the accuracies they achieve provide a rich basis\nfor our study. Our \"robust architecture Odyssey\" reveals several valuable\nobservations: 1) densely connected patterns result in improved robustness; 2)\nunder computational budget, adding convolution operations to direct connection\nedge is effective; 3) flow of solution procedure (FSP) matrix is a good\nindicator of network robustness. Based on these observations, we discover a\nfamily of robust architectures (RobNets). On various datasets, including CIFAR,\nSVHN, Tiny-ImageNet, and ImageNet, RobNets exhibit superior robustness\nperformance to other widely used architectures. Notably, RobNets substantially\nimprove the robust accuracy (~5% absolute gains) under both white-box and\nblack-box attacks, even with fewer parameter numbers. Code is available at\nhttps://github.com/gmh14/RobNets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 04:14:02 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 06:07:55 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 01:37:40 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Guo", "Minghao", ""], ["Yang", "Yuzhe", ""], ["Xu", "Rui", ""], ["Liu", "Ziwei", ""], ["Lin", "Dahua", ""]]}, {"id": "1911.10699", "submitter": "Ruijia Wang", "authors": "Xiao Wang, Ruijia Wang, Chuan Shi, Guojie Song, Qingyong Li", "title": "Multi-Component Graph Convolutional Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactions of users and items in recommender system could be naturally\nmodeled as a user-item bipartite graph. In recent years, we have witnessed an\nemerging research effort in exploring user-item graph for collaborative\nfiltering methods. Nevertheless, the formation of user-item interactions\ntypically arises from highly complex latent purchasing motivations, such as\nhigh cost performance or eye-catching appearance, which are indistinguishably\nrepresented by the edges. The existing approaches still remain the differences\nbetween various purchasing motivations unexplored, rendering the inability to\ncapture fine-grained user preference. Therefore, in this paper we propose a\nnovel Multi-Component graph convolutional Collaborative Filtering (MCCF)\napproach to distinguish the latent purchasing motivations underneath the\nobserved explicit user-item interactions. Specifically, there are two\nelaborately designed modules, decomposer and combiner, inside MCCF. The former\nfirst decomposes the edges in user-item graph to identify the latent components\nthat may cause the purchasing relationship; the latter then recombines these\nlatent components automatically to obtain unified embeddings for prediction.\nFurthermore, the sparse regularizer and weighted random sample strategy are\nutilized to alleviate the overfitting problem and accelerate the optimization.\nEmpirical results on three real datasets and a synthetic dataset not only show\nthe significant performance gains of MCCF, but also well demonstrate the\nnecessity of considering multiple components.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 04:41:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Ruijia", ""], ["Shi", "Chuan", ""], ["Song", "Guojie", ""], ["Li", "Qingyong", ""]]}, {"id": "1911.10720", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi, Ismail Ben Ayed, Luke McCaffrey, Eric Granger", "title": "Non-parametric Uni-modality Constraints for Deep Ordinal Classification", "comments": "11 pages, 2 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new constrained-optimization formulation for deep ordinal\nclassification, in which uni-modality of the label distribution is enforced\nimplicitly via a set of inequality constraints over all the pairs of adjacent\nlabels. Based on (c-1) constraints for c labels, our model is non-parametric\nand, therefore, more flexible than the existing deep ordinal classification\ntechniques. Unlike these, it does not restrict the learned representation to a\nsingle and specific parametric model (or penalty) imposed on all the labels.\nTherefore, it enables the training to explore larger spaces of solutions, while\nremoving the need for ad hoc choices and scaling up to large numbers of labels.\nIt can be used in conjunction with any standard classification loss and any\ndeep architecture. To tackle the ensuing challenging optimization problem, we\nsolve a sequence of unconstrained losses based on a powerful extension of the\nlog-barrier method.\n  This handles effectively competing constraints and accommodates standard SGD\nfor deep networks, while avoiding computationally expensive Lagrangian dual\nsteps and outperforming substantially penalty methods. Furthermore, we propose\na new performance metric for ordinal classification, as a proxy to measure\ndistribution uni-modality, referred to as the Sides Order Index (SOI). We\nreport comprehensive evaluations and comparisons to state-of-the-art methods on\nbenchmark public datasets for several ordinal classification tasks, showing the\nmerits of our approach in terms of label consistency, classification accuracy\nand scalability. Importantly, enforcing label consistency with our model does\nnot incur higher classification errors, unlike many existing ordinal\nclassification methods. A public reproducible PyTorch implementation is\nprovided.\n(https://github.com/sbelharbi/unimodal-prob-deep-oc-free-distribution)\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 06:35:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 20:54:09 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:26:31 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Belharbi", "Soufiane", ""], ["Ayed", "Ismail Ben", ""], ["McCaffrey", "Luke", ""], ["Granger", "Eric", ""]]}, {"id": "1911.10728", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang", "title": "Automatic Ensemble Learning for Online Influence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting a seed set to maximize the expected\nnumber of influenced nodes in the social network, referred to as the\n\\textit{influence maximization} (IM) problem. We assume that the topology of\nthe social network is prescribed while the influence probabilities among edges\nare unknown. In order to learn the influence probabilities and simultaneously\nmaximize the influence spread, we consider the tradeoff between exploiting the\ncurrent estimation of the influence probabilities to ensure certain influence\nspread and exploring more nodes to learn better about the influence\nprobabilities. The exploitation-exploration trade-off is the core issue in the\nmulti-armed bandit (MAB) problem. If we regard the influence spread as the\nreward, then the IM problem could be reduced to the combinatorial multi-armed\nbandits. At each round, the learner selects a limited number of seed nodes in\nthe social network, then the influence spreads over the network according to\nthe real influence probabilities. The learner could observe the activation\nstatus of the edge if and only if its start node is influenced, which is\nreferred to as the edge-level semi-bandit feedback. Two classical bandit\nalgorithms including Thompson Sampling and Epsilon Greedy are used to solve\nthis combinatorial problem. To ensure the robustness of these two algorithms,\nwe use an automatic ensemble learning strategy, which combines the exploration\nstrategy with exploitation strategy. The ensemble algorithm is self-adaptive\nregarding that the probability of each algorithm could be adjusted based on the\nhistorical performance of the algorithm. Experimental evaluation illustrates\nthe effectiveness of the automatically adjusted hybridization of exploration\nalgorithm with exploitation algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:00:01 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Xiaojin", ""]]}, {"id": "1911.10796", "submitter": "Shihua Zhang", "authors": "Chihao Zhang, Kuo Gai and Shihua Zhang", "title": "Matrix Normal PCA for Interpretable Dimension Reduction and Graphical\n  Noise Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is one of the most widely used dimension\nreduction and multivariate statistical techniques. From a probabilistic\nperspective, PCA seeks a low-dimensional representation of data in the presence\nof independent identical Gaussian noise. Probabilistic PCA (PPCA) and its\nvariants have been extensively studied for decades. Most of them assume the\nunderlying noise follows a certain independent identical distribution. However,\nthe noise in the real world is usually complicated and structured. To address\nthis challenge, some variants of PCA for data with non-IID noise have been\nproposed. However, most of the existing methods only assume that the noise is\ncorrelated in the feature space while there may exist two-way structured noise.\nTo this end, we propose a powerful and intuitive PCA method (MN-PCA) through\nmodeling the graphical noise by the matrix normal distribution, which enables\nus to explore the structure of noise in both the feature space and the sample\nspace. MN-PCA obtains a low-rank representation of data and the structure of\nnoise simultaneously. And it can be explained as approximating data over the\ngeneralized Mahalanobis distance. We develop two algorithms to solve this\nmodel: one maximizes the regularized likelihood, the other exploits the\nWasserstein distance, which is more robust. Extensive experiments on various\ndata demonstrate their effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:59:33 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 15:01:38 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhang", "Chihao", ""], ["Gai", "Kuo", ""], ["Zhang", "Shihua", ""]]}, {"id": "1911.10800", "submitter": "Timothy Cannings", "authors": "Timothy I. Cannings", "title": "Random projections: data perturbation for classification problems", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projections offer an appealing and flexible approach to a wide range\nof large-scale statistical problems. They are particularly useful in\nhigh-dimensional settings, where we have many covariates recorded for each\nobservation. In classification problems there are two general techniques using\nrandom projections. The first involves many projections in an ensemble -- the\nidea here is to aggregate the results after applying different random\nprojections, with the aim of achieving superior statistical accuracy. The\nsecond class of methods include hashing and sketching techniques, which are\nstraightforward ways to reduce the complexity of a problem, perhaps therefore\nwith a huge computational saving, while approximately preserving the\nstatistical efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 10:13:56 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Cannings", "Timothy I.", ""]]}, {"id": "1911.10819", "submitter": "Maxim Berman", "authors": "Maxim Berman and Matthew B. Blaschko", "title": "Discriminative training of conditional random fields with probably\n  submodular constraints", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems of segmentation, denoising, registration and 3D reconstruction are\noften addressed with the graph cut algorithm. However, solving an unconstrained\ngraph cut problem is NP-hard. For tractable optimization, pairwise potentials\nhave to fulfill the submodularity inequality. In our learning paradigm,\npairwise potentials are created as the dot product of a learned vector w with\npositive feature vectors. In order to constrain such a model to remain\ntractable, previous approaches have enforced the weight vector to be positive\nfor pairwise potentials in which the labels differ, and set pairwise potentials\nto zero in the case that the label remains the same. Such constraints are\nsufficient to guarantee that the resulting pairwise potentials satisfy the\nsubmodularity inequality. However, we show that such an approach unnecessarily\nrestricts the capacity of the learned models. Guaranteeing submodularity for\nall possible inputs, no matter how improbable, reduces inference error to\neffectively zero, but increases model error. In contrast, we relax the\nrequirement of guaranteed submodularity to solutions that are probably\napproximately submodular. We show that the conceptually simple strategy of\nenforcing submodularity on the training examples guarantees with low sample\ncomplexity that test images will also yield submodular pairwise potentials.\nResults are presented in the binary and muticlass settings, showing substantial\nimprovement from the resulting increased model capacity.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 10:38:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Berman", "Maxim", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "1911.10829", "submitter": "Christoph Reinders", "authors": "Christoph Reinders and Bodo Rosenhahn", "title": "Neural Random Forest Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural Random Forest Imitation - a novel approach for transforming\nrandom forests into neural networks. Existing methods produce very inefficient\narchitectures and do not scale. In this paper, we introduce a new method for\ngenerating data from a random forest and learning a neural network that\nimitates it. Without any additional training data, this transformation creates\nvery efficient neural networks that learn the decision boundaries of a random\nforest. The generated model is fully differentiable and can be combined with\nthe feature extraction in a single pipeline enabling further end-to-end\nprocessing. Experiments on several real-world benchmark datasets demonstrate\noutstanding performance in terms of scalability, accuracy, and learning with\nvery few training examples. Compared to state-of-the-art mappings, we\nsignificantly reduce the network size while achieving the same or even improved\naccuracy due to better generalization.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:04:30 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Reinders", "Christoph", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1911.10866", "submitter": "Irina Higgins", "authors": "Christopher Grimm, Irina Higgins, Andre Barreto, Denis Teplyashin,\n  Markus Wulfmeier, Tim Hertweck, Raia Hadsell, Satinder Singh", "title": "Disentangled Cumulants Help Successor Representations Transfer to New\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological intelligence can learn to solve many diverse tasks in a data\nefficient manner by re-using basic knowledge and skills from one task to\nanother. Furthermore, many of such skills are acquired without explicit\nsupervision in an intrinsically driven fashion. This is in contrast to the\nstate-of-the-art reinforcement learning agents, which typically start learning\neach new task from scratch and struggle with knowledge transfer. In this paper\nwe propose a principled way to learn a basis set of policies, which, when\nrecombined through generalised policy improvement, come with guarantees on the\ncoverage of the final task space. In particular, we concentrate on solving\ngoal-based downstream tasks where the execution order of actions is not\nimportant. We demonstrate both theoretically and empirically that learning a\nsmall number of policies that reach intrinsically specified goal regions in a\ndisentangled latent space can be re-used to quickly achieve a high level of\nperformance on an exponentially larger number of externally specified, often\nsignificantly more complex downstream tasks. Our learning pipeline consists of\ntwo stages. First, the agent learns to perform intrinsically generated,\ngoal-based tasks in the total absence of environmental rewards. Second, the\nagent leverages this experience to quickly achieve a high level of performance\non numerous diverse externally specified tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:31:51 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Grimm", "Christopher", ""], ["Higgins", "Irina", ""], ["Barreto", "Andre", ""], ["Teplyashin", "Denis", ""], ["Wulfmeier", "Markus", ""], ["Hertweck", "Tim", ""], ["Hadsell", "Raia", ""], ["Singh", "Satinder", ""]]}, {"id": "1911.10868", "submitter": "Marin Toromanoff", "authors": "Marin Toromanoff, Emilie Wirbel, Fabien Moutarde", "title": "End-to-End Model-Free Reinforcement Learning for Urban Driving using\n  Implicit Affordances", "comments": "Accepted at main conference of CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) aims at learning an optimal behavior policy from\nits own experiments and not rule-based control methods. However, there is no RL\nalgorithm yet capable of handling a task as difficult as urban driving. We\npresent a novel technique, coined implicit affordances, to effectively leverage\nRL for urban driving thus including lane keeping, pedestrians and vehicles\navoidance, and traffic light detection. To our knowledge we are the first to\npresent a successful RL agent handling such a complex task especially regarding\nthe traffic light detection. Furthermore, we have demonstrated the\neffectiveness of our method by winning the Camera Only track of the CARLA\nchallenge.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:34:26 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:44:13 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Toromanoff", "Marin", ""], ["Wirbel", "Emilie", ""], ["Moutarde", "Fabien", ""]]}, {"id": "1911.10875", "submitter": "Shiliang Sun", "authors": "Ziang Dong, Liang Mao, Shiliang Sun", "title": "Adversarial Attack with Pattern Replacement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative model for adversarial attack. The model generates\nsubtle but predictive patterns from the input. To perform an attack, it\nreplaces the patterns of the input with those generated based on examples from\nsome other class. We demonstrate our model by attacking CNN on MNIST.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:48:08 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Dong", "Ziang", ""], ["Mao", "Liang", ""], ["Sun", "Shiliang", ""]]}, {"id": "1911.10885", "submitter": "Frantzeska Lavda", "authors": "Frantzeska Lavda, Magda Gregorov\\'a and Alexandros Kalousis", "title": "Improving VAE generations of multimodal data through data-dependent\n  conditional priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major shortcomings of variational autoencoders is the inability to\nproduce generations from the individual modalities of data originating from\nmixture distributions. This is primarily due to the use of a simple isotropic\nGaussian as the prior for the latent code in the ancestral sampling procedure\nfor the data generations. We propose a novel formulation of variational\nautoencoders, conditional prior VAE (CP-VAE), which learns to differentiate\nbetween the individual mixture components and therefore allows for generations\nfrom the distributional data clusters. We assume a two-level generative process\nwith a continuous (Gaussian) latent variable sampled conditionally on a\ndiscrete (categorical) latent component. The new variational objective\nnaturally couples the learning of the posterior and prior conditionals, and the\nlearning of the latent categories encoding the multimodality of the original\ndata in an unsupervised manner. The data-dependent conditional priors are then\nused to sample the continuous latent code when generating new samples from the\nindividual mixture components corresponding to the multimodal structure of the\noriginal data. Our experimental results illustrate the generative performance\nof our new model comparing to multiple baselines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:00:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lavda", "Frantzeska", ""], ["Gregorov\u00e1", "Magda", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1911.10914", "submitter": "Patrick Putzky", "authors": "Patrick Putzky and Max Welling", "title": "Invert to Learn to Invert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative learning to infer approaches have become popular solvers for\ninverse problems. However, their memory requirements during training grow\nlinearly with model depth, limiting in practice model expressiveness. In this\nwork, we propose an iterative inverse model with constant memory that relies on\ninvertible networks to avoid storing intermediate activations. As a result, the\nproposed approach allows us to train models with 400 layers on 3D volumes in an\nMRI image reconstruction task. In experiments on a public data set, we\ndemonstrate that these deeper, and thus more expressive, networks perform\nstate-of-the-art image reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:46:01 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Putzky", "Patrick", ""], ["Welling", "Max", ""]]}, {"id": "1911.10922", "submitter": "Xiaojiang Yang", "authors": "Xiaojiang Yang, Wendong Bi, Yitong Sun, Yu Cheng, Junchi Yan", "title": "Towards Better Understanding of Disentangled Representations via Mutual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing works on disentangled representation learning are solely built\nupon an marginal independence assumption: all factors in disentangled\nrepresentations should be statistically independent. This assumption is\nnecessary but definitely not sufficient for the disentangled representations\nwithout additional inductive biases in the modeling process, which is shown\ntheoretically in recent studies. We argue in this work that disentangled\nrepresentations should be characterized by their relation with observable data.\nIn particular, we formulate such a relation through the concept of mutual\ninformation: the mutual information between each factor of the disentangled\nrepresentations and data should be invariant conditioned on values of the other\nfactors. Together with the widely accepted independence assumption, we further\nbridge it with the conditional independence of factors in representations\nconditioned on data. Moreover, we note that conditional independence of latent\nvariables has been imposed on most VAE-type models and InfoGAN due to the\nartificial choice of factorized approximate posterior $q(\\rvz|\\rvx)$ in the\nencoders. Such an arrangement of encoders introduces a crucial inductive bias\nfor disentangled representations. To demonstrate the importance of our proposed\nassumption and the related inductive bias, we show in experiments that\nviolating the assumption leads to decline of disentanglement among factors in\nthe learned representations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:56:53 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 07:16:05 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 12:19:04 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Yang", "Xiaojiang", ""], ["Bi", "Wendong", ""], ["Sun", "Yitong", ""], ["Cheng", "Yu", ""], ["Yan", "Junchi", ""]]}, {"id": "1911.10924", "submitter": "Sileye Ba", "authors": "Sileye 0. Ba", "title": "Discovering topics with neural topic models built from PLSA assumptions", "comments": "10 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a model for unsupervised topic discovery in texts\ncorpora. The proposed model uses documents, words, and topics lookup table\nembedding as neural network model parameters to build probabilities of words\ngiven topics, and probabilities of topics given documents. These probabilities\nare used to recover by marginalization probabilities of words given documents.\nFor very large corpora where the number of documents can be in the order of\nbillions, using a neural auto-encoder based document embedding is more scalable\nthen using a lookup table embedding as classically done. We thus extended the\nlookup based document embedding model to continuous auto-encoder based model.\nOur models are trained using probabilistic latent semantic analysis (PLSA)\nassumptions. We evaluated our models on six datasets with a rich variety of\ncontents. Conducted experiments demonstrate that the proposed neural topic\nmodels are very effective in capturing relevant topics. Furthermore,\nconsidering perplexity metric, conducted evaluation benchmarks show that our\ntopic models outperform latent Dirichlet allocation (LDA) model which is\nclassically used to address topic discovery tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:59:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ba", "Sileye 0.", ""]]}, {"id": "1911.10936", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar, Ibrahim Ekren, Xin Zhang", "title": "Finite-Time 4-Expert Prediction Problem", "comments": "Keywords: machine learning, expert advice framework, asymptotic\n  expansion, inverse Laplace transform, regret minimization, Jacobi-theta\n  function", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.GT cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explicitly solve the nonlinear PDE that is the continuous limit of dynamic\nprogramming of \\emph{expert prediction problem} in finite horizon setting with\n$N=4$ experts. The \\emph{expert prediction problem} is formulated as a zero sum\ngame between a player and an adversary. By showing that the solution is\n$\\mathcal{C}^2$, we are able to show that the strategies conjectured in\narXiv:1409.3040G form an asymptotic Nash equilibrium. We also prove the \"Finite\nvs Geometric regret\" conjecture proposed in arXiv:1409.3040G for $N=4$, and and\nshow that this conjecture in fact follows from the conjecture that the comb\nstrategies are optimal.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:00:39 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:22:47 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Ekren", "Ibrahim", ""], ["Zhang", "Xin", ""]]}, {"id": "1911.10947", "submitter": "Fangchen Liu", "authors": "Fangchen Liu, Zhan Ling, Tongzhou Mu, Hao Su", "title": "State Alignment-based Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an imitation learning problem that the imitator and the expert have\ndifferent dynamics models. Most of the current imitation learning methods fail\nbecause they focus on imitating actions. We propose a novel state\nalignment-based imitation learning method to train the imitator to follow the\nstate sequences in expert demonstrations as much as possible. The state\nalignment comes from both local and global perspectives and we combine them\ninto a reinforcement learning framework by a regularized policy update\nobjective. We show the superiority of our method on standard imitation learning\nsettings and imitation learning settings where the expert and imitator have\ndifferent dynamics models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:18:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Liu", "Fangchen", ""], ["Ling", "Zhan", ""], ["Mu", "Tongzhou", ""], ["Su", "Hao", ""]]}, {"id": "1911.10978", "submitter": "Brendan Odigwe", "authors": "Brendan E. Odigwe, Jesuloluwa S. Eyitayo, Celestine I. Odigwe,\n  Homayoun Valafar", "title": "Modelling of Sickle Cell Anemia Patients Response to Hydroxyurea using\n  Artificial Neural Networks", "comments": "7 Pages, 9 figures, Int'l Conf. Health Informatics and Medical\n  Systems | HIMS'19 |, Las Vegas, NV, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydroxyurea (HU) has been shown to be effective in alleviating the symptoms\nof Sickle Cell Anemia disease. While Hydroxyurea reduces the complications\nassociated with Sickle Cell Anemia in some patients, others do not benefit from\nthis drug and experience deleterious effects since it is also a\nchemotherapeutic agent. Therefore, to whom, should the administration of HU be\nconsidered as a viable option, is the main question asked by the responsible\nphysician. We address this question by developing modeling techniques that can\npredict a patient's response to HU and therefore spare the non-responsive\npatients from the unnecessary effects of HU on the values of 22 parameters that\ncan be obtained from blood samples in 122 patients. Using this data, we\ndeveloped Deep Artificial Neural Network models that can predict with 92.6%\naccuracy, the final HbF value of a subject after undergoing HU therapy. Our\ncurrent studies are focussing on forecasting a patient's HbF response, 30 days\nahead of time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:22:29 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Odigwe", "Brendan E.", ""], ["Eyitayo", "Jesuloluwa S.", ""], ["Odigwe", "Celestine I.", ""], ["Valafar", "Homayoun", ""]]}, {"id": "1911.10979", "submitter": "Yong-Goo Shin", "authors": "Yong-Goo Shin, Yoon-Jae Yeo, and Sung-Jea Ko", "title": "Simple yet Effective Way for Improving the Performance of GAN", "comments": "Accepted to IEEE transactions on neural networks and learning systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3045000", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial learning, discriminator often fails to guide the generator\nsuccessfully since it distinguishes between real and generated images using\nsilly or non-robust features. To alleviate this problem, this brief presents a\nsimple but effective way that improves the performance of generative\nadversarial network (GAN) without imposing the training overhead or modifying\nthe network architectures of existing methods. The proposed method employs a\nnovel cascading rejection (CR) module for discriminator, which extracts\nmultiple non-overlapped features in an iterative manner using the vector\nrejection operation. Since the extracted diverse features prevent the\ndiscriminator from concentrating on non-meaningful features, the discriminator\ncan guide the generator effectively to produce the images that are more similar\nto the real images. In addition, since the proposed CR module requires only a\nfew simple vector operations, it can be readily applied to existing frameworks\nwith marginal training overheads. Quantitative evaluations on various datasets\nincluding CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet confirm that the\nproposed method significantly improves the performance of GAN and conditional\nGAN in terms of Frechet inception distance (FID) indicating the diversity and\nvisual appearance of the generated images.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:31:19 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 03:50:17 GMT"}, {"version": "v3", "created": "Sun, 10 May 2020 04:33:33 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 16:19:15 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Shin", "Yong-Goo", ""], ["Yeo", "Yoon-Jae", ""], ["Ko", "Sung-Jea", ""]]}, {"id": "1911.11000", "submitter": "Borja Rodr\\'iguez G\\'alvez", "authors": "Borja Rodr\\'iguez-G\\'alvez, Ragnar Thobaben and Mikael Skoglund", "title": "The Convex Information Bottleneck Lagrangian", "comments": "10 pages of main text, 2 page of references and 14 pages of\n  appendices with the proofs, experimental details and caveats", "journal-ref": null, "doi": "10.3390/e22010098", "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The information bottleneck (IB) problem tackles the issue of obtaining\nrelevant compressed representations $T$ of some random variable $X$ for the\ntask of predicting $Y$. It is defined as a constrained optimization problem\nwhich maximizes the information the representation has about the task,\n$I(T;Y)$, while ensuring that a certain level of compression $r$ is achieved\n(i.e., $ I(X;T) \\leq r$). For practical reasons, the problem is usually solved\nby maximizing the IB Lagrangian (i.e., $\\mathcal{L}_{\\text{IB}}(T;\\beta) =\nI(T;Y) - \\beta I(X;T)$) for many values of $\\beta \\in [0,1]$. Then, the curve\nof maximal $I(T;Y)$ for a given $I(X;T)$ is drawn and a representation with the\ndesired predictability and compression is selected. It is known when $Y$ is a\ndeterministic function of $X$, the IB curve cannot be explored and another\nLagrangian has been proposed to tackle this problem: the squared IB Lagrangian:\n$\\mathcal{L}_{\\text{sq-IB}}(T;\\beta_{\\text{sq}})=I(T;Y)-\\beta_{\\text{sq}}I(X;T)^2$.\nIn this paper, we (i) present a general family of Lagrangians which allow for\nthe exploration of the IB curve in all scenarios; (ii) provide the exact\none-to-one mapping between the Lagrange multiplier and the desired compression\nrate $r$ for known IB curve shapes; and (iii) show we can approximately obtain\na specific compression level with the convex IB Lagrangian for both known and\nunknown IB curve shapes. This eliminates the burden of solving the optimization\nproblem for many values of the Lagrange multiplier. That is, we prove that we\ncan solve the original constrained problem with a single optimization.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:48:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 18:57:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Rodr\u00edguez-G\u00e1lvez", "Borja", ""], ["Thobaben", "Ragnar", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1911.11018", "submitter": "Xiaowei Gu", "authors": "Xiaowei Gu, Plamen P Angelov and Eduardo Almeida Soares", "title": "A Self-Adaptive Synthetic Over-Sampling Technique for Imbalanced\n  Classification", "comments": "This paper has been submitted to International Journal of Intelligent\n  Systems for publication", "journal-ref": null, "doi": "10.1002/int.22230", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, in supervised machine learning, (a significant) part of the\navailable data (usually 50% to 80%) is used for training and the rest for\nvalidation. In many problems, however, the data is highly imbalanced in regard\nto different classes or does not have good coverage of the feasible data space\nwhich, in turn, creates problems in validation and usage phase. In this paper,\nwe propose a technique for synthesising feasible and likely data to help\nbalance the classes as well as to boost the performance in terms of confusion\nmatrix as well as overall. The idea, in a nutshell, is to synthesise data\nsamples in close vicinity to the actual data samples specifically for the less\nrepresented (minority) classes. This has also implications to the so-called\nfairness of machine learning. In this paper, we propose a specific method for\nsynthesising data in a way to balance the classes and boost the performance,\nespecially of the minority classes. It is generic and can be applied to\ndifferent base algorithms, e.g. support vector machine, k-nearest neighbour,\ndeep networks, rule-based classifiers, decision trees, etc. The results\ndemonstrated that: i) a significantly more balanced (and fair) classification\nresults can be achieved; ii) that the overall performance as well as the\nperformance per class measured by confusion matrix can be boosted. In addition,\nthis approach can be very valuable for the cases when the number of actual\navailable labelled data is small which itself is one of the problems of the\ncontemporary machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:08:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gu", "Xiaowei", ""], ["Angelov", "Plamen P", ""], ["Soares", "Eduardo Almeida", ""]]}, {"id": "1911.11024", "submitter": "Cooper Mellema", "authors": "Cooper J. Mellema, Alex Treacher, Kevin P. Nguyen, Albert Montillo", "title": "Architectural configurations, atlas granularity and functional\n  connectivity with diagnostic value in Autism Spectrum Disorder", "comments": "Presented at ISBI 2020", "journal-ref": "ISBI 2020. Iowa City, IA, USA, April 3-7: IEEE", "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the diagnosis of Autism Spectrum Disorder (ASD) is dependent upon\na subjective, time-consuming evaluation of behavioral tests by an expert\nclinician. Non-invasive functional MRI (fMRI) characterizes brain connectivity\nand may be used to inform diagnoses and democratize medicine. However,\nsuccessful construction of deep learning models from fMRI requires addressing\nkey choices about the model's architecture, including the number of layers and\nnumber of neurons per layer. Meanwhile, deriving functional connectivity (FC)\nfeatures from fMRI requires choosing an atlas with an appropriate level of\ngranularity. Once a model has been built, it is vital to determine which\nfeatures are predictive of ASD and if similar features are learned across atlas\ngranularity levels. To identify aptly suited architectural configurations,\nprobability distributions of the configurations of high versus low performing\nmodels are compared. To determine the effect of atlas granularity, connectivity\nfeatures are derived from atlases with 3 levels of granularity and important\nfeatures are ranked with permutation feature importance. Results show the\nhighest performing models use between 2-4 hidden layers and 16-64 neurons per\nlayer, granularity dependent. Connectivity features identified as important\nacross all 3 atlas granularity levels include FC to the supplementary motor\ngyrus and language association cortex, regions associated with deficits in\nsocial and sensory processing in ASD. Importantly, the cerebellum, often not\nincluded in functional analyses, is also identified as a region whose abnormal\nconnectivity is highly predictive of ASD. Results of this study identify\nimportant regions to include in future studies of ASD, help assist in the\nselection of network architectures, and help identify appropriate levels of\ngranularity to facilitate the development of accurate diagnostic models of ASD.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:15:11 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 21:05:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Mellema", "Cooper J.", ""], ["Treacher", "Alex", ""], ["Nguyen", "Kevin P.", ""], ["Montillo", "Albert", ""]]}, {"id": "1911.11030", "submitter": "Tom Viering", "authors": "Tom J. Viering, Alexander Mey, Marco Loog", "title": "Making Learners (More) Monotone", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning performance can show non-monotonic behavior. That is, more data does\nnot necessarily lead to better models, even on average. We propose three\nalgorithms that take a supervised learning model and make it perform more\nmonotone. We prove consistency and monotonicity with high probability, and\nevaluate the algorithms on scenarios where non-monotone behaviour occurs. Our\nproposed algorithm $\\text{MT}_{\\text{HT}}$ makes less than $1\\%$ non-monotone\ndecisions on MNIST while staying competitive in terms of error rate compared to\nseveral baselines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:35:03 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Viering", "Tom J.", ""], ["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1911.11034", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar (1), David O Brien (2), Kendra Albert (3),\n  Salom\\'e Vilj\\\"oen (2), Jeffrey Snover (1) ((1) Microsoft, (2) Berkman Klein\n  Center for Internet and Society at Harvard University, (3) Harvard Law\n  School)", "title": "Failure Modes in Machine Learning Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two years, more than 200 papers have been written on how machine\nlearning (ML) systems can fail because of adversarial attacks on the algorithms\nand data; this number balloons if we were to incorporate papers covering\nnon-adversarial failure modes. The spate of papers has made it difficult for ML\npractitioners, let alone engineers, lawyers, and policymakers, to keep up with\nthe attacks against and defenses of ML systems. However, as these systems\nbecome more pervasive, the need to understand how they fail, whether by the\nhand of an adversary or due to the inherent design of a system, will only\nbecome more pressing. In order to equip software developers, security incident\nresponders, lawyers, and policy makers with a common vernacular to talk about\nthis problem, we developed a framework to classify failures into \"Intentional\nfailures\" where the failure is caused by an active adversary attempting to\nsubvert the system to attain her goals; and \"Unintentional failures\" where the\nfailure is because an ML system produces an inherently unsafe outcome. After\ndeveloping the initial version of the taxonomy last year, we worked with\nsecurity and ML teams across Microsoft, 23 external partners, standards\norganization, and governments to understand how stakeholders would use our\nframework. Throughout the paper, we attempt to highlight how machine learning\nfailure modes are meaningfully different from traditional software failures\nfrom a technology and policy perspective.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:37:28 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Brien", "David O", ""], ["Albert", "Kendra", ""], ["Vilj\u00f6en", "Salom\u00e9", ""], ["Snover", "Jeffrey", ""]]}, {"id": "1911.11043", "submitter": "Yunan Wu", "authors": "Yunan Wu and Lan Wang", "title": "Resampling-based Confidence Intervals for Model-free Robust Inference on\n  Optimal Treatment Regimes", "comments": "59 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new procedure for inference on optimal treatment regimes in the\nmodel-free setting, which does not require to specify an outcome regression\nmodel. Existing model-free estimators for optimal treatment regimes are usually\nnot suitable for the purpose of inference, because they either have nonstandard\nasymptotic distributions or do not necessarily guarantee consistent estimation\nof the parameter indexing the Bayes rule due to the use of surrogate loss. We\nfirst study a smoothed robust estimator that directly targets the parameter\ncorresponding to the Bayes decision rule for optimal treatment regimes\nestimation. This estimator is shown to have an asymptotic normal distribution.\nFurthermore, we verify that a resampling procedure provides asymptotically\naccurate inference for both the parameter indexing the optimal treatment regime\nand the optimal value function. A new algorithm is developed to calculate the\nproposed estimator with substantially improved speed and stability. Numerical\nresults demonstrate the satisfactory performance of the new methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:55:40 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 04:10:23 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wu", "Yunan", ""], ["Wang", "Lan", ""]]}, {"id": "1911.11049", "submitter": "Roy Mitz", "authors": "Roy Mitz, Yoel Shkolnisky", "title": "ROIPCA: An Online PCA algorithm based on rank-one updates", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal components analysis (PCA) is a fundamental algorithm in data\nanalysis. Its online version is useful in many modern applications where the\ndata are too large to fit in memory, or when speed of calculation is important.\nIn this paper we propose ROIPCA, an online PCA algorithm based on rank-one\nupdates. ROIPCA is linear in both the dimension of the data and the number of\ncomponents calculated. We demonstrate its advantages over existing\nstate-of-the-art algorithms in terms of accuracy and running time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:00:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Mitz", "Roy", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "1911.11061", "submitter": "Tommy Jones", "authors": "Tommy Jones", "title": "A Coefficient of Determination for Probabilistic Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes a new (old) metric for evaluating goodness of fit in\ntopic models, the coefficient of determination, or $R^2$. Within the context of\ntopic modeling, $R^2$ has the same interpretation that it does when used in a\nbroader class of statistical models. Reporting $R^2$ with topic models\naddresses two current problems in topic modeling: a lack of standard\ncross-contextual evaluation metrics for topic modeling and ease of\ncommunication with lay audiences. The author proposes that $R^2$ should be\nreported as a standard metric when constructing topic models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:55:30 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 03:07:01 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jones", "Tommy", ""]]}, {"id": "1911.11070", "submitter": "Joanna Misztal-Radecka", "authors": "Joanna Misztal-Radecka, Dominik Rusiecki, Micha{\\l} \\.Zmuda, Artur\n  Bujak", "title": "Trend-responsive User Segmentation Enabling Traceable Publishing\n  Insights. A Case Study of a Real-world Large-scale News Recommendation System", "comments": null, "journal-ref": "7th International Workshop on News Recommendation and Analytics\n  (INRA 2019), in conjunction with RecSys 2019, September 19, 2019, Copenhagen,\n  Denmark", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The traditional offline approaches are no longer sufficient for building\nmodern recommender systems in domains such as online news services, mainly due\nto the high dynamics of environment changes and necessity to operate on a large\nscale with high data sparsity. The ability to balance exploration with\nexploitation makes the multi-armed bandits an efficient alternative to the\nconventional methods, and a robust user segmentation plays a crucial role in\nproviding the context for such online recommendation algorithms. In this work,\nwe present an unsupervised and trend-responsive method for segmenting users\naccording to their semantic interests, which has been integrated with a\nreal-world system for large-scale news recommendations. The results of an\nonline A/B test show significant improvements compared to a global-optimization\nalgorithm on several services with different characteristics. Based on the\nexperimental results as well as the exploration of segments descriptions and\ntrend dynamics, we propose extensions to this approach that address particular\nreal-world challenges for different use-cases. Moreover, we describe a method\nof generating traceable publishing insights facilitating the creation of\ncontent that serves the diversity of all users needs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 18:42:16 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Misztal-Radecka", "Joanna", ""], ["Rusiecki", "Dominik", ""], ["\u017bmuda", "Micha\u0142", ""], ["Bujak", "Artur", ""]]}, {"id": "1911.11071", "submitter": "Sami Khairy", "authors": "Sami Khairy, Ruslan Shaydulin, Lukasz Cincio, Yuri Alexeev, Prasanna\n  Balaprakash", "title": "Learning to Optimize Variational Quantum Circuits to Solve Combinatorial\n  Problems", "comments": "To appear in the proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI), New York, USA, February 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i03.5616", "report-no": "LA-UR-19-28945", "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is a computational paradigm with the potential to\noutperform classical methods for a variety of problems. Proposed recently, the\nQuantum Approximate Optimization Algorithm (QAOA) is considered as one of the\nleading candidates for demonstrating quantum advantage in the near term. QAOA\nis a variational hybrid quantum-classical algorithm for approximately solving\ncombinatorial optimization problems. The quality of the solution obtained by\nQAOA for a given problem instance depends on the performance of the classical\noptimizer used to optimize the variational parameters. In this paper, we\nformulate the problem of finding optimal QAOA parameters as a learning task in\nwhich the knowledge gained from solving training instances can be leveraged to\nfind high-quality solutions for unseen test instances. To this end, we develop\ntwo machine-learning-based approaches. Our first approach adopts a\nreinforcement learning (RL) framework to learn a policy network to optimize\nQAOA circuits. Our second approach adopts a kernel density estimation (KDE)\ntechnique to learn a generative model of optimal QAOA parameters. In both\napproaches, the training procedure is performed on small-sized problem\ninstances that can be simulated on a classical computer; yet the learned RL\npolicy and the generative model can be used to efficiently solve larger\nproblems. Extensive simulations using the IBM Qiskit Aer quantum circuit\nsimulator demonstrate that our proposed RL- and KDE-based approaches reduce the\noptimality gap by factors up to 30.15 when compared with other commonly used\noff-the-shelf optimizers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:23:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Khairy", "Sami", ""], ["Shaydulin", "Ruslan", ""], ["Cincio", "Lukasz", ""], ["Alexeev", "Yuri", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1911.11082", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Krikamol Muandet, Moritz Diehl, Bernhard Sch\\\"olkopf", "title": "A New Distribution-Free Concept for Representing, Comparing, and\n  Propagating Uncertainty in Dynamical Systems with Kernel Probabilistic\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the concept of kernel mean embedding and kernel\nprobabilistic programming in the context of stochastic systems. We propose\nformulations to represent, compare, and propagate uncertainties for fairly\ngeneral stochastic dynamics in a distribution-free manner. The new tools enjoy\nsound theory rooted in functional analysis and wide applicability as\ndemonstrated in distinct numerical examples. The implication of this new\nconcept is a new mode of thinking about the statistical nature of uncertainty\nin dynamical systems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:41:21 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 17:53:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Muandet", "Krikamol", ""], ["Diehl", "Moritz", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1911.11090", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Benedikt Staffler, Jan Hendrik Metzen, Frank Hutter", "title": "Meta-Learning of Neural Architectures for Few-Shot Learning", "comments": null, "journal-ref": "2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress in neural architecture search (NAS) has allowed scaling\nthe automated design of neural architectures to real-world domains, such as\nobject detection and semantic segmentation. However, one prerequisite for the\napplication of NAS are large amounts of labeled data and compute resources.\nThis renders its application challenging in few-shot learning scenarios, where\nmany related tasks need to be learned, each with limited amounts of data and\ncompute time. Thus, few-shot learning is typically done with a fixed neural\narchitecture. To improve upon this, we propose MetaNAS, the first method which\nfully integrates NAS with gradient-based meta-learning. MetaNAS optimizes a\nmeta-architecture along with the meta-weights during meta-training. During\nmeta-testing, architectures can be adapted to a novel task with a few steps of\nthe task optimizer, that is: task adaptation becomes computationally cheap and\nrequires only little data per task. Moreover, MetaNAS is agnostic in that it\ncan be used with arbitrary model-agnostic meta-learning algorithms and\narbitrary gradient-based NAS methods. %We present encouraging results for\nMetaNAS with a combination of DARTS and REPTILE on few-shot classification\nbenchmarks. Empirical results on standard few-shot classification benchmarks\nshow that MetaNAS with a combination of DARTS and REPTILE yields\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:45:39 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 15:14:40 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 09:33:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Elsken", "Thomas", ""], ["Staffler", "Benedikt", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "1911.11091", "submitter": "Tijana Radivojevic", "authors": "Tijana Radivojevi\\'c, Zak Costello, Kenneth Workman, Hector Garcia\n  Martin", "title": "ART: A machine learning Automated Recommendation Tool for synthetic\n  biology", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-18008-4", "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biology has changed radically in the last two decades, transitioning from a\ndescriptive science into a design science. Synthetic biology allows us to\nbioengineer cells to synthesize novel valuable molecules such as renewable\nbiofuels or anticancer drugs. However, traditional synthetic biology approaches\ninvolve ad-hoc engineering practices, which lead to long development times.\nHere, we present the Automated Recommendation Tool (ART), a tool that leverages\nmachine learning and probabilistic modeling techniques to guide synthetic\nbiology in a systematic fashion, without the need for a full mechanistic\nunderstanding of the biological system. Using sampling-based optimization, ART\nprovides a set of recommended strains to be built in the next engineering\ncycle, alongside probabilistic predictions of their production levels. We\ndemonstrate the capabilities of ART on simulated data sets, as well as\nexperimental data from real metabolic engineering projects producing renewable\nbiofuels, hoppy flavored beer without hops, and fatty acids. Finally, we\ndiscuss the limitations of this approach, and the practical consequences of the\nunderlying assumptions failing.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:46:36 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 20:33:03 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Radivojevi\u0107", "Tijana", ""], ["Costello", "Zak", ""], ["Workman", "Kenneth", ""], ["Martin", "Hector Garcia", ""]]}, {"id": "1911.11119", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian En-Hsu Yen, Zhen Zhang, Kun Xu, Liang Zhao, Xi Peng,\n  Yinglong Xia and Charu Aggarwal", "title": "Scalable Global Alignment Graph Kernel Using Random Features: From Node\n  Embedding to Graph Embedding", "comments": "KDD'19, Oral Paper, Data and Code link available in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernels are widely used for measuring the similarity between graphs.\nMany existing graph kernels, which focus on local patterns within graphs rather\nthan their global properties, suffer from significant structure information\nloss when representing graphs. Some recent global graph kernels, which utilizes\nthe alignment of geometric node embeddings of graphs, yield state-of-the-art\nperformance. However, these graph kernels are not necessarily\npositive-definite. More importantly, computing the graph kernel matrix will\nhave at least quadratic {time} complexity in terms of the number and the size\nof the graphs. In this paper, we propose a new family of global alignment graph\nkernels, which take into account the global properties of graphs by using\ngeometric node embeddings and an associated node transportation based on earth\nmover's distance. Compared to existing global kernels, the proposed kernel is\npositive-definite. Our graph kernel is obtained by defining a distribution over\n\\emph{random graphs}, which can naturally yield random feature approximations.\nThe random feature approximations lead to our graph embeddings, which is named\nas \"random graph embeddings\" (RGE). In particular, RGE is shown to achieve\n\\emph{(quasi-)linear scalability} with respect to the number and the size of\nthe graphs. The experimental results on nine benchmark datasets demonstrate\nthat RGE outperforms or matches twelve state-of-the-art graph classification\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:46:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian En-Hsu", ""], ["Zhang", "Zhen", ""], ["Xu", "Kun", ""], ["Zhao", "Liang", ""], ["Peng", "Xi", ""], ["Xia", "Yinglong", ""], ["Aggarwal", "Charu", ""]]}, {"id": "1911.11120", "submitter": "Lingfei Wu", "authors": "Zhen Zhang, Yijian Xiang, Lingfei Wu, Bing Xue, Arye Nehorai", "title": "KerGM: Kernelized Graph Matching", "comments": "NeurIPS'19, Spotlight Paper, Data and Code link available in the\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching plays a central role in such fields as computer vision,\npattern recognition, and bioinformatics. Graph matching problems can be cast as\ntwo types of quadratic assignment problems (QAPs): Koopmans-Beckmann's QAP or\nLawler's QAP. In our paper, we provide a unifying view for these two problems\nby introducing new rules for array operations in Hilbert spaces. Consequently,\nLawler's QAP can be considered as the Koopmans-Beckmann's alignment between two\narrays in reproducing kernel Hilbert spaces (RKHS), making it possible to\nefficiently solve the problem without computing a huge affinity matrix.\nFurthermore, we develop the entropy-regularized Frank-Wolfe (EnFW) algorithm\nfor optimizing QAPs, which has the same convergence rate as the original FW\nalgorithm while dramatically reducing the computational burden for each outer\niteration. We conduct extensive experiments to evaluate our approach, and show\nthat our algorithm significantly outperforms the state-of-the-art in both\nmatching accuracy and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:46:25 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Zhen", ""], ["Xiang", "Yijian", ""], ["Wu", "Lingfei", ""], ["Xue", "Bing", ""], ["Nehorai", "Arye", ""]]}, {"id": "1911.11121", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian En-Hsu Yen, Siyu Huo, Liang Zhao, Kun Xu, Liang Ma,\n  Shouling Ji and Charu Aggarwal", "title": "Efficient Global String Kernel with Random Features: Beyond Counting\n  Substructures", "comments": "KDD'19 Oral Paper, Data and Code link available in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of large-scale sequential data has been one of the most crucial\ntasks in areas such as bioinformatics, text, and audio mining. Existing string\nkernels, however, either (i) rely on local features of short substructures in\nthe string, which hardly capture long discriminative patterns, (ii) sum over\ntoo many substructures, such as all possible subsequences, which leads to\ndiagonal dominance of the kernel matrix, or (iii) rely on non-positive-definite\nsimilarity measures derived from the edit distance. Furthermore, while there\nhave been works addressing the computational challenge with respect to the\nlength of string, most of them still experience quadratic complexity in terms\nof the number of training samples when used in a kernel-based classifier. In\nthis paper, we present a new class of global string kernels that aims to (i)\ndiscover global properties hidden in the strings through global alignments,\n(ii) maintain positive-definiteness of the kernel, without introducing a\ndiagonal dominant kernel matrix, and (iii) have a training cost linear with\nrespect to not only the length of the string but also the number of training\nstring samples. To this end, the proposed kernels are explicitly defined\nthrough a series of different random feature maps, each corresponding to a\ndistribution of random strings. We show that kernels defined this way are\nalways positive-definite, and exhibit computational benefits as they always\nproduce \\emph{Random String Embeddings (RSE)} that can be directly used in any\nlinear classification models. Our extensive experiments on nine benchmark\ndatasets corroborate that RSE achieves better or comparable accuracy in\ncomparison to state-of-the-art baselines, especially with the strings of longer\nlengths. In addition, we empirically show that RSE scales linearly with the\nincrease of the number and the length of string.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:47:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian En-Hsu", ""], ["Huo", "Siyu", ""], ["Zhao", "Liang", ""], ["Xu", "Kun", ""], ["Ma", "Liang", ""], ["Ji", "Shouling", ""], ["Aggarwal", "Charu", ""]]}, {"id": "1911.11122", "submitter": "Nuri Mert Vural", "authors": "N. Mert Vural, Hakan Gokcesu, Kaan Gokcesu and Suleyman S. Kozat", "title": "Minimax Optimal Algorithms for Adversarial Bandit Problem with Multiple\n  Plays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the adversarial bandit problem with multiple plays under\nsemi-bandit feedback. We introduce a highly efficient algorithm that\nasymptotically achieves the performance of the best switching $m$-arm strategy\nwith minimax optimal regret bounds. To construct our algorithm, we introduce a\nnew expert advice algorithm for the multiple-play setting. By using our expert\nadvice algorithm, we additionally improve the best-known high-probability bound\nfor the multi-play setting by $O(\\sqrt{m})$. Our results are guaranteed to hold\nin an individual sequence manner since we have no statistical assumption on the\nbandit arm gains. Through an extensive set of experiments involving synthetic\nand real data, we demonstrate significant performance gains achieved by the\nproposed algorithm with respect to the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:47:44 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Vural", "N. Mert", ""], ["Gokcesu", "Hakan", ""], ["Gokcesu", "Kaan", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1911.11134", "submitter": "Utku Evci", "authors": "Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, Erich Elsen", "title": "Rigging the Lottery: Making All Tickets Winners", "comments": "Published in Proceedings of the 37th International Conference on\n  Machine Learning. Code can be found in github.com/google-research/rigl", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (2020) 471-481", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications require sparse neural networks due to space or inference\ntime restrictions. There is a large body of work on training dense networks to\nyield sparse networks for inference, but this limits the size of the largest\ntrainable sparse model to that of the largest trainable dense model. In this\npaper we introduce a method to train sparse neural networks with a fixed\nparameter count and a fixed computational cost throughout training, without\nsacrificing accuracy relative to existing dense-to-sparse training methods. Our\nmethod updates the topology of the sparse network during training by using\nparameter magnitudes and infrequent gradient calculations. We show that this\napproach requires fewer floating-point operations (FLOPs) to achieve a given\nlevel of accuracy compared to prior techniques. We demonstrate state-of-the-art\nsparse training results on a variety of networks and datasets, including\nResNet-50, MobileNets on Imagenet-2012, and RNNs on WikiText-103. Finally, we\nprovide some insights into why allowing the topology to change during the\noptimization can overcome local minima encountered when the topology remains\nstatic. Code used in our work can be found in github.com/google-research/rigl.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 18:58:53 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 20:13:36 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 14:12:42 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Evci", "Utku", ""], ["Gale", "Trevor", ""], ["Menick", "Jacob", ""], ["Castro", "Pablo Samuel", ""], ["Elsen", "Erich", ""]]}, {"id": "1911.11167", "submitter": "Laixi Shi", "authors": "Laixi Shi and Yuejie Chi", "title": "Manifold Gradient Descent Solves Multi-Channel Sparse Blind\n  Deconvolution Provably and Efficiently", "comments": "accepted by IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-channel sparse blind deconvolution, or convolutional sparse coding,\nrefers to the problem of learning an unknown filter by observing its circulant\nconvolutions with multiple input signals that are sparse. This problem finds\nnumerous applications in signal processing, computer vision, and inverse\nproblems. However, it is challenging to learn the filter efficiently due to the\nbilinear structure of the observations with the respect to the unknown filter\nand inputs, as well as the sparsity constraint. In this paper, we propose a\nnovel approach based on nonconvex optimization over the sphere manifold by\nminimizing a smooth surrogate of the sparsity-promoting loss function. It is\ndemonstrated that manifold gradient descent with random initializations will\nprovably recover the filter, up to scaling and shift ambiguity, as soon as the\nnumber of observations is sufficiently large under an appropriate random data\nmodel. Numerical experiments are provided to illustrate the performance of the\nproposed method with comparisons to existing ones.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:04:07 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 22:12:17 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 02:41:56 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Shi", "Laixi", ""], ["Chi", "Yuejie", ""]]}, {"id": "1911.11174", "submitter": "David Burth Kurka", "authors": "David Burth Kurka, Deniz G\\\"und\\\"uz", "title": "DeepJSCC-f: Deep Joint Source-Channel Coding of Images with Feedback", "comments": "IEEE Journal on Selected Areas in Information Theory (JSAIT), to\n  appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.IV eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider wireless transmission of images in the presence of channel output\nfeedback. From a Shannon theoretic perspective feedback does not improve the\nasymptotic end-to-end performance, and separate source coding followed by\ncapacity-achieving channel coding, which ignores the feedback signal, achieves\nthe optimal performance. It is well known that separation is not optimal in the\npractical finite blocklength regime; however, there are no known practical\njoint source-channel coding (JSCC) schemes that can exploit the feedback signal\nand surpass the performance of separation-based schemes. Inspired by the recent\nsuccess of deep learning methods for JSCC, we investigate how noiseless or\nnoisy channel output feedback can be incorporated into the transmission system\nto improve the reconstruction quality at the receiver. We introduce an\nautoencoder-based JSCC scheme, which we call DeepJSCC-f, that exploits the\nchannel output feedback, and provides considerable improvements in terms of the\nend-to-end reconstruction quality for fixed-length transmission, or in terms of\nthe average delay for variable-length transmission. To the best of our\nknowledge, this is the first practical JSCC scheme that can fully exploit\nchannel output feedback, demonstrating yet another setting in which modern\nmachine learning techniques can enable the design of new and efficient\ncommunication methods that surpass the performance of traditional structured\ncoding-based designs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:13:53 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:27:34 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Kurka", "David Burth", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "1911.11177", "submitter": "Yair Movshovitz-Attias", "authors": "Elad Eban, Yair Movshovitz-Attias, Hao Wu, Mark Sandler, Andrew Poon,\n  Yerlan Idelbayev, Miguel A. Carreira-Perpinan", "title": "Structured Multi-Hashing for Model Compression", "comments": "Elad and Yair contributed equally to the paper. They jointly proposed\n  the idea of structured-multi-hashing. Elad: Wrote most of the code and ran\n  most of the experiments Yair: Main contributor to the manuscript Hao: Coding\n  and experiments Yerlan: Coding and experiments Miguel: advised Yerlan about\n  optimization and model compression Mark:experiments Andrew: experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of deep neural networks (DNNs), state-of-the-art models\nare too large to deploy on low-resource devices or common server configurations\nin which multiple models are held in memory. Model compression methods address\nthis limitation by reducing the memory footprint, latency, or energy\nconsumption of a model with minimal impact on accuracy. We focus on the task of\nreducing the number of learnable variables in the model. In this work we\ncombine ideas from weight hashing and dimensionality reductions resulting in a\nsimple and powerful structured multi-hashing method based on matrix products\nthat allows direct control of model size of any deep network and is trained\nend-to-end. We demonstrate the strength of our approach by compressing models\nfrom the ResNet, EfficientNet, and MobileNet architecture families. Our method\nallows us to drastically decrease the number of variables while maintaining\nhigh accuracy. For instance, by applying our approach to EfficentNet-B4 (16M\nparameters) we reduce it to to the size of B0 (5M parameters), while gaining\nover 3% in accuracy over B0 baseline. On the commonly used benchmark CIFAR10 we\nreduce the ResNet32 model by 75% with no loss in quality, and are able to do a\n10x compression while still achieving above 90% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:21:25 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Eban", "Elad", ""], ["Movshovitz-Attias", "Yair", ""], ["Wu", "Hao", ""], ["Sandler", "Mark", ""], ["Poon", "Andrew", ""], ["Idelbayev", "Yerlan", ""], ["Carreira-Perpinan", "Miguel A.", ""]]}, {"id": "1911.11185", "submitter": "Xiaojian Ma", "authors": "Mark Edmonds, Xiaojian Ma, Siyuan Qi, Yixin Zhu, Hongjing Lu,\n  Song-Chun Zhu", "title": "Theory-based Causal Transfer: Integrating Instance-level Induction and\n  Abstract-level Structure Learning", "comments": "Accepted to AAAI 2020 as an oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning transferable knowledge across similar but different settings is a\nfundamental component of generalized intelligence. In this paper, we approach\nthe transfer learning challenge from a causal theory perspective. Our agent is\nendowed with two basic yet general theories for transfer learning: (i) a task\nshares a common abstract structure that is invariant across domains, and (ii)\nthe behavior of specific features of the environment remain constant across\ndomains. We adopt a Bayesian perspective of causal theory induction and use\nthese theories to transfer knowledge between environments. Given these general\ntheories, the goal is to train an agent by interactively exploring the problem\nspace to (i) discover, form, and transfer useful abstract and structural\nknowledge, and (ii) induce useful knowledge from the instance-level attributes\nobserved in the environment. A hierarchy of Bayesian structures is used to\nmodel abstract-level structural causal knowledge, and an instance-level\nassociative learning scheme learns which specific objects can be used to induce\nstate changes through interaction. This model-learning scheme is then\nintegrated with a model-based planner to achieve a task in the OpenLock\nenvironment, a virtual ``escape room'' with a complex hierarchy that requires\nagents to reason about an abstract, generalized causal structure. We compare\nperformances against a set of predominate model-free reinforcement learning(RL)\nalgorithms. RL agents showed poor ability transferring learned knowledge across\ndifferent trials. Whereas the proposed model revealed similar performance\ntrends as human learners, and more importantly, demonstrated transfer behavior\nacross trials and learning situations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:36:28 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Edmonds", "Mark", ""], ["Ma", "Xiaojian", ""], ["Qi", "Siyuan", ""], ["Zhu", "Yixin", ""], ["Lu", "Hongjing", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1911.11195", "submitter": "Azadeh Mozafari", "authors": "Azadeh Sadat Mozafari, Hugo Siqueira Gomes, Christian Gagne", "title": "A Novel Unsupervised Post-Processing Calibration Method for DNNS with\n  Robustness to Domain Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uncertainty estimation is critical in real-world decision making\napplications, especially when distributional shift between the training and\ntest data are prevalent. Many calibration methods in the literature have been\nproposed to improve the predictive uncertainty of DNNs which are generally not\nwell-calibrated. However, none of them is specifically designed to work\nproperly under domain shift condition. In this paper, we propose Unsupervised\nTemperature Scaling (UTS) as a robust calibration method to domain shift. It\nexploits unlabeled test samples instead of the training one to adjust the\nuncertainty prediction of deep models towards the test distribution. UTS\nutilizes a novel loss function, weighted NLL, which allows unsupervised\ncalibration. We evaluate UTS on a wide range of model-datasets to show the\npossibility of calibration without labels and demonstrate the robustness of UTS\ncompared to other methods (e.g., TS, MC-dropout, SVI, ensembles) in shifted\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:59:40 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Mozafari", "Azadeh Sadat", ""], ["Gomes", "Hugo Siqueira", ""], ["Gagne", "Christian", ""]]}, {"id": "1911.11219", "submitter": "Chang Xiao", "authors": "Chang Xiao and Changxi Zheng", "title": "One Man's Trash is Another Man's Treasure: Resisting Adversarial\n  Examples by Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern image classification systems are often built on deep neural networks,\nwhich suffer from adversarial examples--images with deliberately crafted,\nimperceptible noise to mislead the network's classification. To defend against\nadversarial examples, a plausible idea is to obfuscate the network's gradient\nwith respect to the input image. This general idea has inspired a long line of\ndefense methods. Yet, almost all of them have proven vulnerable. We revisit\nthis seemingly flawed idea from a radically different perspective. We embrace\nthe omnipresence of adversarial examples and the numerical procedure of\ncrafting them, and turn this harmful attacking process into a useful defense\nmechanism. Our defense method is conceptually simple: before feeding an input\nimage for classification, transform it by finding an adversarial example on a\npre-trained external model. We evaluate our method against a wide range of\npossible attacks. On both CIFAR-10 and Tiny ImageNet datasets, our method is\nsignificantly more robust than state-of-the-art methods. Particularly, in\ncomparison to adversarial training, our method offers lower training cost as\nwell as stronger robustness.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:33:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 21:10:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xiao", "Chang", ""], ["Zheng", "Changxi", ""]]}, {"id": "1911.11250", "submitter": "Tobias Schlosser", "authors": "Tobias Schlosser, Frederik Beuth, Michael Friedrich, and Danny Kowerko", "title": "A Novel Visual Fault Detection and Classification System for\n  Semiconductor Manufacturing Using Stacked Hybrid Convolutional Neural\n  Networks", "comments": "Accepted for: 2019 IEEE 24th International Conference on Emerging\n  Technologies and Factory Automation (ETFA); the latest versions of this\n  contribution cover minor typo corrections", "journal-ref": null, "doi": "10.1109/ETFA.2019.8869311", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated visual inspection in the semiconductor industry aims to detect and\nclassify manufacturing defects utilizing modern image processing techniques.\nWhile an earliest possible detection of defect patterns allows quality control\nand automation of manufacturing chains, manufacturers benefit from an increased\nyield and reduced manufacturing costs. Since classical image processing systems\nare limited in their ability to detect novel defect patterns, and machine\nlearning approaches often involve a tremendous amount of computational effort,\nthis contribution introduces a novel deep neural network based hybrid approach.\nUnlike classical deep neural networks, a multi-stage system allows the\ndetection and classification of the finest structures in pixel size within\nhigh-resolution imagery. Consisting of stacked hybrid convolutional neural\nnetworks (SH-CNN) and inspired by current approaches of visual attention, the\nrealized system draws the focus over the level of detail from its structures to\nmore task-relevant areas of interest. The results of our test environment show\nthat the SH-CNN outperforms current approaches of learning-based automated\nvisual inspection, whereas a distinction depending on the level of detail\nenables the elimination of defect patterns in earlier stages of the\nmanufacturing process.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:58:28 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 16:48:41 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 20:00:12 GMT"}, {"version": "v4", "created": "Fri, 1 Jan 2021 23:30:21 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 23:22:01 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Schlosser", "Tobias", ""], ["Beuth", "Frederik", ""], ["Friedrich", "Michael", ""], ["Kowerko", "Danny", ""]]}, {"id": "1911.11251", "submitter": "Tobias Schlosser", "authors": "Tobias Schlosser, Michael Friedrich, and Danny Kowerko", "title": "Hexagonal Image Processing in the Context of Machine Learning:\n  Conception of a Biologically Inspired Hexagonal Deep Learning Framework", "comments": "Accepted for: 2019 18th IEEE International Conference on Machine\n  Learning and Applications (ICMLA); the latest versions of this contribution\n  cover minor typo corrections", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00300", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the human visual perception system, hexagonal image processing in\nthe context of machine learning deals with the development of image processing\nsystems that combine the advantages of evolutionary motivated structures based\non biological models. While conventional state-of-the-art image processing\nsystems of recording and output devices almost exclusively utilize square\narranged methods, their hexagonal counterparts offer a number of key advantages\nthat can benefit both researchers and users. This contribution serves as a\ngeneral application-oriented approach the synthesis of the therefore designed\nhexagonal image processing framework, called Hexnet, the processing steps of\nhexagonal image transformation, and dependent methods. The results of our\ncreated test environment show that the realized framework surpasses current\napproaches of hexagonal image processing systems, while hexagonal artificial\nneural networks can benefit from the implemented hexagonal architecture. As\nhexagonal lattice format based deep neural networks, also called H-DNN, can be\ncompared to their square counterparts by transforming classical square lattice\nbased data sets into their hexagonal representation, they can also result in a\nreduction of trainable parameters as well as result in increased training and\ntest rates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:58:31 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 16:48:44 GMT"}, {"version": "v3", "created": "Sun, 26 Jan 2020 20:00:15 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 13:50:32 GMT"}, {"version": "v5", "created": "Wed, 25 Mar 2020 22:59:06 GMT"}, {"version": "v6", "created": "Fri, 1 Jan 2021 23:30:21 GMT"}, {"version": "v7", "created": "Thu, 18 Mar 2021 23:21:56 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Schlosser", "Tobias", ""], ["Friedrich", "Michael", ""], ["Kowerko", "Danny", ""]]}, {"id": "1911.11253", "submitter": "Cassidy Laidlaw", "authors": "Cassidy Laidlaw and Soheil Feizi", "title": "Playing it Safe: Adversarial Robustness with an Abstain Option", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore adversarial robustness in the setting in which it is acceptable\nfor a classifier to abstain---that is, output no class---on adversarial\nexamples. Adversarial examples are small perturbations of normal inputs to a\nclassifier that cause the classifier to give incorrect output; they present\nsecurity and safety challenges for machine learning systems. In many\nsafety-critical applications, it is less costly for a classifier to abstain on\nadversarial examples than to give incorrect output for them. We first introduce\na novel objective function for adversarial robustness with an abstain option\nwhich characterizes an explicit tradeoff between robustness and accuracy. We\nthen present a simple baseline in which an adversarially-trained classifier\nabstains on all inputs within a certain distance of the decision boundary,\nwhich we theoretically and experimentally evaluate. Finally, we propose\nCombined Abstention Robustness Learning (CARL), a method for jointly learning a\nclassifier and the region of the input space on which it should abstain. We\nexplore different variations of the PGD and DeepFool adversarial attacks on\nCARL in the abstain setting. Evaluating against these attacks, we demonstrate\nthat training with CARL results in a more accurate, robust, and efficient\nclassifier than the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:59:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Laidlaw", "Cassidy", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.11255", "submitter": "Rafael Henrique Santos Rocha", "authors": "Ruy Luiz Milidi\\'u and Rafael Henrique Santos Rocha", "title": "Cumulative Sum Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Ordinal Regression is to find a rule that ranks items from a\ngiven set. Several learning algorithms to solve this prediction problem build\nan ensemble of binary classifiers. Ranking by Projecting uses interdependent\nbinary perceptrons. These perceptrons share the same direction vector, but use\ndifferent bias values. Similar approaches use independent direction vectors and\nbiases. To combine the binary predictions, most of them adopt a simple counting\nheuristics. Here, we introduce a novel cumulative sum scoring function to\ncombine the binary predictions. The proposed score value aggregates the\nstrength of each one of the relevant binary classifications on how large is the\nitem's rank. We show that our modeling casts ordinal regression as a Structured\nPerceptron problem. As a consequence, we simplify its formulation and\ndescription, which results in two simple online learning algorithms. The second\nalgorithm is a Passive-Aggressive version of the first algorithm. We show that\nunder some rank separability condition both algorithms converge. Furthermore,\nwe provide mistake bounds for each one of the two online algorithms. For the\nPassive-Aggressive version, we assume the knowledge of a separation margin,\nwhat significantly improves the corresponding mistake bound. Additionally, we\nshow that Ranking by Projecting is a special case of our prediction algorithm.\nFrom a neural network architecture point of view, our empirical findings\nsuggest a layer of cusum units for ordinal regression, instead of the usual\nsoftmax layer of multiclass problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 22:04:19 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Milidi\u00fa", "Ruy Luiz", ""], ["Rocha", "Rafael Henrique Santos", ""]]}, {"id": "1911.11260", "submitter": "Risto Vuorio", "authors": "John Holler, Risto Vuorio, Zhiwei Qin, Xiaocheng Tang, Yan Jiao,\n  Tiancheng Jin, Satinder Singh, Chenxi Wang and Jieping Ye", "title": "Deep Reinforcement Learning for Multi-Driver Vehicle Dispatching and\n  Repositioning Problem", "comments": "ICDM 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order dispatching and driver repositioning (also known as fleet management)\nin the face of spatially and temporally varying supply and demand are central\nto a ride-sharing platform marketplace. Hand-crafting heuristic solutions that\naccount for the dynamics in these resource allocation problems is difficult,\nand may be better handled by an end-to-end machine learning method. Previous\nworks have explored machine learning methods to the problem from a high-level\nperspective, where the learning method is responsible for either repositioning\nthe drivers or dispatching orders, and as a further simplification, the drivers\nare considered independent agents maximizing their own reward functions. In\nthis paper we present a deep reinforcement learning approach for tackling the\nfull fleet management and dispatching problems. In addition to treating the\ndrivers as individual agents, we consider the problem from a system-centric\nperspective, where a central fleet management agent is responsible for\ndecision-making for all drivers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 22:28:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Holler", "John", ""], ["Vuorio", "Risto", ""], ["Qin", "Zhiwei", ""], ["Tang", "Xiaocheng", ""], ["Jiao", "Yan", ""], ["Jin", "Tiancheng", ""], ["Singh", "Satinder", ""], ["Wang", "Chenxi", ""], ["Ye", "Jieping", ""]]}, {"id": "1911.11284", "submitter": "Ehsan Aghaei", "authors": "Ehsan Aghaei, Gursel Serpen", "title": "Host-based anomaly detection using Eigentraces feature extraction and\n  one-class classification on system call trace data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a methodology for host-based anomaly detection using a\nsemi-supervised algorithm namely one-class classifier combined with a PCA-based\nfeature extraction technique called Eigentraces on system call trace data. The\none-class classification is based on generating a set of artificial data using\na reference distribution and combining the target class probability function\nwith artificial class density function to estimate the target class density\nfunction through the Bayes formulation. The benchmark dataset, ADFA-LD, is\nemployed for the simulation study. ADFA-LD dataset contains thousands of system\ncall traces collected during various normal and attack processes for the Linux\noperating system environment. In order to pre-process and to extract features,\nwindowing on the system call trace data followed by the principal component\nanalysis which is named as Eigentraces is implemented. The target class\nprobability function is modeled separately by Radial Basis Function neural\nnetwork and Random Forest machine learners for performance comparison purposes.\nThe simulation study showed that the proposed intrusion detection system offers\nhigh performance for detecting anomalies and normal activities with respect to\na set of well-accepted metrics including detection rate, accuracy, and missed\nand false alarm rates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:55:00 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Aghaei", "Ehsan", ""], ["Serpen", "Gursel", ""]]}, {"id": "1911.11285", "submitter": "Pierre Richemond", "authors": "Pierre H. Richemond, Arinbj\\\"orn Kolbeinsson, Yike Guo", "title": "Biologically inspired architectures for sample-efficient deep\n  reinforcement learning", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning requires a heavy price in terms of sample\nefficiency and overparameterization in the neural networks used for function\napproximation. In this work, we use tensor factorization in order to learn more\ncompact representation for reinforcement learning policies. We show empirically\nthat in the low-data regime, it is possible to learn online policies with 2 to\n10 times less total coefficients, with little to no loss of performance. We\nalso leverage progress in second order optimization, and use the theory of\nwavelet scattering to further reduce the number of learned coefficients, by\nforegoing learning the topmost convolutional layer filters altogether. We\nevaluate our results on the Atari suite against recent baseline algorithms that\nrepresent the state-of-the-art in data efficiency, and get comparable results\nwith an order of magnitude gain in weight parsimony.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:59:22 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Guo", "Yike", ""]]}, {"id": "1911.11308", "submitter": "Runzhong Wang", "authors": "Runzhong Wang, Junchi Yan and Xiaokang Yang", "title": "Neural Graph Matching Network: Learning Lawler's Quadratic Assignment\n  Problem with Extension to Hypergraph and Multiple-graph Matching", "comments": "Accepted by TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching involves combinatorial optimization based on edge-to-edge\naffinity matrix, which can be generally formulated as Lawler's Quadratic\nAssignment Problem (QAP). This paper presents a QAP network directly learning\nwith the affinity matrix (equivalently the association graph) whereby the\nmatching problem is translated into a constrained vertex classification task.\nThe association graph is learned by an embedding network for vertex\nclassification, followed by Sinkhorn normalization and a cross-entropy loss for\nend-to-end learning. We further improve the embedding model on association\ngraph by introducing Sinkhorn based matching-aware constraint, as well as dummy\nnodes to deal with unequal sizes of graphs. To our best knowledge, this is one\nof the first network to directly learn with the general Lawler's QAP. In\ncontrast, recent deep matching methods focus on the learning of node/edge\nfeatures in two graphs respectively. We also show how to extend our network to\nhypergraph matching, and matching of multiple graphs. Experimental results on\nboth synthetic graphs and real-world images show its effectiveness. For pure\nQAP tasks on synthetic data and QAPLIB benchmark, our method can perform\ncompetitively and even surpass state-of-the-art graph matching and QAP solvers\nwith notable less time cost. We provide a project homepage at\nhttp://thinklab.sjtu.edu.cn/project/NGM/index.html.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 02:06:57 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 17:16:22 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 17:18:34 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Wang", "Runzhong", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""]]}, {"id": "1911.11322", "submitter": "Han Shi", "authors": "Han Shi, Haozheng Fan, James T. Kwok", "title": "Effective Decoding in Graph Auto-Encoder using Triadic Closure", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (variational) graph auto-encoder and its variants have been popularly\nused for representation learning on graph-structured data. While the encoder is\noften a powerful graph convolutional network, the decoder reconstructs the\ngraph structure by only considering two nodes at a time, thus ignoring possible\ninteractions among edges. On the other hand, structured prediction, which\nconsiders the whole graph simultaneously, is computationally expensive. In this\npaper, we utilize the well-known triadic closure property which is exhibited in\nmany real-world networks. We propose the triad decoder, which considers and\npredicts the three edges involved in a local triad together. The triad decoder\ncan be readily used in any graph-based auto-encoder. In particular, we\nincorporate this to the (variational) graph auto-encoder. Experiments on link\nprediction, node clustering and graph generation show that the use of triads\nleads to more accurate prediction, clustering and better preservation of the\ngraph characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 03:56:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shi", "Han", ""], ["Fan", "Haozheng", ""], ["Kwok", "James T.", ""]]}, {"id": "1911.11337", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang, Shuai Li, Weiwen Liu", "title": "Contextual Combinatorial Conservative Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multi-armed bandits (MAB) asks to make sequential decisions\nwhile balancing between exploitation and exploration, and have been\nsuccessfully applied to a wide range of practical scenarios. Various algorithms\nhave been designed to achieve a high reward in a long term. However, its\nshort-term performance might be rather low, which is injurious in risk\nsensitive applications. Building on previous work of conservative bandits, we\nbring up a framework of contextual combinatorial conservative bandits. An\nalgorithm is presented and a regret bound of $\\tilde O(d^2+d\\sqrt{T})$ is\nproven, where $d$ is the dimension of the feature vectors, and $T$ is the total\nnumber of time steps. We further provide an algorithm as well as regret\nanalysis for the case when the conservative reward is unknown. Experiments are\nconducted, and the results validate the effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 04:42:53 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhang", "Xiaojin", ""], ["Li", "Shuai", ""], ["Liu", "Weiwen", ""]]}, {"id": "1911.11343", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Fatemeh Afghah, Abolfazl Razi, Sajad Mousavi,\n  Jonathan Ashdown, Kurt Turk", "title": "An Autonomous Spectrum Management Scheme for Unmanned Aerial Vehicle\n  Networks in Disaster Relief Operations", "comments": "14 pages, 14 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of spectrum shortage in an unmanned aerial\nvehicle (UAV) network during critical missions such as wildfire monitoring,\nsearch and rescue, and disaster monitoring. Such applications involve a high\ndemand for high-throughput data transmissions such as real-time video-, image-,\nand voice- streaming where the assigned spectrum to the UAV network may not be\nadequate to provide the desired Quality of Service (QoS). In these scenarios,\nthe aerial network can borrow an additional spectrum from the available\nterrestrial networks in the trade of a relaying service for them. We propose a\nspectrum sharing model in which the UAVs are grouped into two classes of\nrelaying UAVs that service the spectrum owner and the sensing UAVs that perform\nthe disaster relief mission using the obtained spectrum. The operation of the\nUAV network is managed by a hierarchical mechanism in which a central\ncontroller assigns the tasks of the UAVs based on their resources and determine\ntheir operation region based on the level of priority of impacted areas and\nthen the UAVs autonomously fine-tune their position using a model-free\nreinforcement learning algorithm to maximize the individual throughput and\nprolong their lifetime. We analyze the performance and the convergence for the\nproposed method analytically and with extensive simulations in different\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:09:39 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Afghah", "Fatemeh", ""], ["Razi", "Abolfazl", ""], ["Mousavi", "Sajad", ""], ["Ashdown", "Jonathan", ""], ["Turk", "Kurt", ""]]}, {"id": "1911.11345", "submitter": "Abhishek Chakrabortty", "authors": "Abhishek Chakrabortty, Jiarui Lu, T. Tony Cai and Hongzhe Li", "title": "High Dimensional M-Estimation with Missing Outcomes: A Semi-Parametric\n  Framework", "comments": "34 pages, 4 tables; (Supplement: 58 pages, 10 tables);", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high dimensional $M$-estimation in settings where the response\n$Y$ is possibly missing at random and the covariates $\\mathbf{X} \\in\n\\mathbb{R}^p$ can be high dimensional compared to the sample size $n$. The\nparameter of interest $\\boldsymbol{\\theta}_0 \\in \\mathbb{R}^d$ is defined as\nthe minimizer of the risk of a convex loss, under a fully non-parametric model,\nand $\\boldsymbol{\\theta}_0$ itself is high dimensional which is a key\ndistinction from existing works. Standard high dimensional regression and\nseries estimation with possibly misspecified models and missing $Y$ are\nincluded as special cases, as well as their counterparts in causal inference\nusing 'potential outcomes'.\n  Assuming $\\boldsymbol{\\theta}_0$ is $s$-sparse ($s \\ll n$), we propose an\n$L_1$-regularized debiased and doubly robust (DDR) estimator of\n$\\boldsymbol{\\theta}_0$ based on a high dimensional adaptation of the\ntraditional double robust (DR) estimator's construction. Under mild tail\nassumptions and arbitrarily chosen (working) models for the propensity score\n(PS) and the outcome regression (OR) estimators, satisfying only some\nhigh-level conditions, we establish finite sample performance bounds for the\nDDR estimator showing its (optimal) $L_2$ error rate to be $\\sqrt{s (\\log d)/\nn}$ when both models are correct, and its consistency and DR properties when\nonly one of them is correct. Further, when both the models are correct, we\npropose a desparsified version of our DDR estimator that satisfies an\nasymptotic linear expansion and facilitates inference on low dimensional\ncomponents of $\\boldsymbol{\\theta}_0$. Finally, we discuss various of choices\nof high dimensional parametric/semi-parametric working models for the PS and OR\nestimators. All results are validated via detailed simulations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:11:44 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Chakrabortty", "Abhishek", ""], ["Lu", "Jiarui", ""], ["Cai", "T. Tony", ""], ["Li", "Hongzhe", ""]]}, {"id": "1911.11357", "submitter": "Samaneh Azadi", "authors": "Samaneh Azadi, Michael Tschannen, Eric Tzeng, Sylvain Gelly, Trevor\n  Darrell, Mario Lucic", "title": "Semantic Bottleneck Scene Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupling the high-fidelity generation capabilities of label-conditional image\nsynthesis methods with the flexibility of unconditional generative models, we\npropose a semantic bottleneck GAN model for unconditional synthesis of complex\nscenes. We assume pixel-wise segmentation labels are available during training\nand use them to learn the scene structure. During inference, our model first\nsynthesizes a realistic segmentation layout from scratch, then synthesizes a\nrealistic scene conditioned on that layout. For the former, we use an\nunconditional progressive segmentation generation network that captures the\ndistribution of realistic semantic scene layouts. For the latter, we use a\nconditional segmentation-to-image synthesis network that captures the\ndistribution of photo-realistic images conditioned on the semantic layout. When\ntrained end-to-end, the resulting model outperforms state-of-the-art generative\nmodels in unsupervised image synthesis on two challenging domains in terms of\nthe Frechet Inception Distance and user-study evaluations. Moreover, we\ndemonstrate the generated segmentation maps can be used as additional training\ndata to strongly improve recent segmentation-to-image synthesis networks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:01:09 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Azadi", "Samaneh", ""], ["Tschannen", "Michael", ""], ["Tzeng", "Eric", ""], ["Gelly", "Sylvain", ""], ["Darrell", "Trevor", ""], ["Lucic", "Mario", ""]]}, {"id": "1911.11361", "submitter": "Yifan Wu", "authors": "Yifan Wu, George Tucker, Ofir Nachum", "title": "Behavior Regularized Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL) research, it is common to assume access to\ndirect online interactions with the environment. However in many real-world\napplications, access to the environment is limited to a fixed offline dataset\nof logged experience. In such settings, standard RL algorithms have been shown\nto diverge or otherwise yield poor performance. Accordingly, recent work has\nsuggested a number of remedies to these issues. In this work, we introduce a\ngeneral framework, behavior regularized actor critic (BRAC), to empirically\nevaluate recently proposed methods as well as a number of simple baselines\nacross a variety of offline continuous control tasks. Surprisingly, we find\nthat many of the technical complexities introduced in recent methods are\nunnecessary to achieve strong performance. Additional ablations provide\ninsights into which design choices matter most in the offline RL setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:11:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Wu", "Yifan", ""], ["Tucker", "George", ""], ["Nachum", "Ofir", ""]]}, {"id": "1911.11363", "submitter": "Da Yu", "authors": "Da Yu, Huishuai Zhang, Wei Chen, Tie-Yan Liu, Jian Yin", "title": "Gradient Perturbation is Underrated for Differentially Private Convex\n  Optimization", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2020; 7 pages, 2 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient perturbation, widely used for differentially private optimization,\ninjects noise at every iterative update to guarantee differential privacy.\nPrevious work first determines the noise level that can satisfy the privacy\nrequirement and then analyzes the utility of noisy gradient updates as in the\nnon-private case. In contrast, we explore how privacy noise affects\noptimization property. We show that for differentially private convex\noptimization, the utility guarantee of differentially private (stochastic)\ngradient descent is determined by an \\emph{expected curvature} rather than the\nminimum curvature. The \\emph{expected curvature}, which represents the average\ncurvature over the optimization path, is usually much larger than the minimum\ncurvature. By using the \\emph{expected curvature}, we show that gradient\nperturbation can achieve a significantly improved utility guarantee that can\ntheoretically justify the advantage of gradient perturbation over other\nperturbation methods. Finally, our extensive experiments suggest that gradient\nperturbation with the advanced composition method indeed outperforms other\nperturbation approaches by a large margin, matching our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:18:02 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 09:44:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yu", "Da", ""], ["Zhang", "Huishuai", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""], ["Yin", "Jian", ""]]}, {"id": "1911.11374", "submitter": "Jianwen Xie", "authors": "Jianwen Xie, Ruiqi Gao, Erik Nijkamp, Song-Chun Zhu, Ying Nian Wu", "title": "Representation Learning: A Statistical Perspective", "comments": null, "journal-ref": "Annual Review of Statistics and Its Application 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of data is an important problem in statistics and\nmachine learning. While the origin of learning representations can be traced\nback to factor analysis and multidimensional scaling in statistics, it has\nbecome a central theme in deep learning with important applications in computer\nvision and computational neuroscience. In this article, we review recent\nadvances in learning representations from a statistical perspective. In\nparticular, we review the following two themes: (a) unsupervised learning of\nvector representations and (b) learning of both vector and matrix\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:21:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Xie", "Jianwen", ""], ["Gao", "Ruiqi", ""], ["Nijkamp", "Erik", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1911.11378", "submitter": "Manraj Singh Grover", "authors": "Osaid Rehman Nasir, Shailesh Kumar Jha, Manraj Singh Grover, Yi Yu,\n  Ajit Kumar, Rajiv Ratn Shah", "title": "Text2FaceGAN: Face Generation from Fine Grained Textual Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful generative adversarial networks (GAN) have been developed to\nautomatically synthesize realistic images from text. However, most existing\ntasks are limited to generating simple images such as flowers from captions. In\nthis work, we extend this problem to the less addressed domain of face\ngeneration from fine-grained textual descriptions of face, e.g., \"A person has\ncurly hair, oval face, and mustache\". We are motivated by the potential of\nautomated face generation to impact and assist critical tasks such as criminal\nface reconstruction. Since current datasets for the task are either very small\nor do not contain captions, we generate captions for images in the CelebA\ndataset by creating an algorithm to automatically convert a list of attributes\nto a set of captions. We then model the highly multi-modal problem of text to\nface generation as learning the conditional distribution of faces (conditioned\non text) in same latent space. We utilize the current state-of-the-art GAN\n(DC-GAN with GAN-CLS loss) for learning conditional multi-modality. The\npresence of more fine-grained details and variable length of the captions makes\nthe problem easier for a user but more difficult to handle compared to the\nother text-to-image tasks. We flipped the labels for real and fake images and\nadded noise in discriminator. Generated images for diverse textual descriptions\nshow promising results. In the end, we show how the widely used inceptions\nscore is not a good metric to evaluate the performance of generative models\nused for synthesizing faces from text.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:37:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nasir", "Osaid Rehman", ""], ["Jha", "Shailesh Kumar", ""], ["Grover", "Manraj Singh", ""], ["Yu", "Yi", ""], ["Kumar", "Ajit", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1911.11380", "submitter": "Mathis Bode", "authors": "Mathis Bode, Michael Gauding, Zeyu Lian, Dominik Denker, Marco\n  Davidovic, Konstantin Kleinheinz, Jenia Jitsev, Heinz Pitsch", "title": "Using Physics-Informed Super-Resolution Generative Adversarial Networks\n  for Subgrid Modeling in Turbulent Reactive Flows", "comments": "Submitted to Combustion Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turbulence is still one of the main challenges for accurately predicting\nreactive flows. Therefore, the development of new turbulence closures which can\nbe applied to combustion problems is essential. Data-driven modeling has become\nvery popular in many fields over the last years as large, often extensively\nlabeled, datasets became available and training of large neural networks became\npossible on GPUs speeding up the learning process tremendously. However, the\nsuccessful application of deep neural networks in fluid dynamics, for example\nfor subgrid modeling in the context of large-eddy simulations (LESs), is still\nchallenging. Reasons for this are the large amount of degrees of freedom in\nrealistic flows, the high requirements with respect to accuracy and error\nrobustness, as well as open questions, such as the generalization capability of\ntrained neural networks in such high-dimensional, physics-constrained\nscenarios. This work presents a novel subgrid modeling approach based on a\ngenerative adversarial network (GAN), which is trained with unsupervised deep\nlearning (DL) using adversarial and physics-informed losses. A two-step\ntraining method is used to improve the generalization capability, especially\nextrapolation, of the network. The novel approach gives good results in a\npriori as well as a posteriori tests with decaying turbulence including\nturbulent mixing. The applicability of the network in complex combustion\nscenarios is furthermore discussed by employing it to a reactive LES of the\nSpray A case defined by the Engine Combustion Network (ECN).\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:40:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bode", "Mathis", ""], ["Gauding", "Michael", ""], ["Lian", "Zeyu", ""], ["Denker", "Dominik", ""], ["Davidovic", "Marco", ""], ["Kleinheinz", "Konstantin", ""], ["Jitsev", "Jenia", ""], ["Pitsch", "Heinz", ""]]}, {"id": "1911.11396", "submitter": "Guoxian Yu", "authors": "Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta, Xiangliang Zhang", "title": "Multi-View Multiple Clusterings using Deep Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering aims at integrating complementary information from\nmultiple heterogeneous views to improve clustering results. Existing multi-view\nclustering solutions can only output a single clustering of the data. Due to\ntheir multiplicity, multi-view data, can have different groupings that are\nreasonable and interesting from different perspectives. However, how to find\nmultiple, meaningful, and diverse clustering results from multi-view data is\nstill a rarely studied and challenging topic in multi-view clustering and\nmultiple clusterings. In this paper, we introduce a deep matrix factorization\nbased solution (DMClusts) to discover multiple clusterings. DMClusts gradually\nfactorizes multi-view data matrices into representational subspaces\nlayer-by-layer and generates one clustering in each layer. To enforce the\ndiversity between generated clusterings, it minimizes a new redundancy\nquantification term derived from the proximity between samples in these\nsubspaces. We further introduce an iterative optimization procedure to\nsimultaneously seek multiple clusterings with quality and diversity.\nExperimental results on benchmark datasets confirm that DMClusts outperforms\nstate-of-the-art multiple clustering solutions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:31:09 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Wei", "Shaowei", ""], ["Wang", "Jun", ""], ["Yu", "Guoxian", ""], ["Carlotta", "", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1911.11430", "submitter": "Yanbei Liu", "authors": "Yanbei Liu, Xiao Wang, Shu Wu and Zhitao Xiao", "title": "Independence Promoted Graph Disentangled Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of disentangled representation learning with\nindependent latent factors in graph convolutional networks (GCNs). The current\nmethods usually learn node representation by describing its neighborhood as a\nperceptual whole in a holistic manner while ignoring the entanglement of the\nlatent factors. However, a real-world graph is formed by the complex\ninteraction of many latent factors (e.g., the same hobby, education or work in\nsocial network). While little effort has been made toward exploring the\ndisentangled representation in GCNs. In this paper, we propose a novel\nIndependence Promoted Graph Disentangled Networks (IPGDN) to learn disentangled\nnode representation while enhancing the independence among node\nrepresentations. In particular, we firstly present disentangled representation\nlearning by neighborhood routing mechanism, and then employ the Hilbert-Schmidt\nIndependence Criterion (HSIC) to enforce independence between the latent\nrepresentations, which is effectively integrated into a graph convolutional\nframework as a regularizer at the output layer. Experimental studies on\nreal-world graphs validate our model and demonstrate that our algorithms\noutperform the state-of-the-arts by a wide margin in different network\napplications, including semi-supervised graph classification, graph clustering\nand graph visualization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:01:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Liu", "Yanbei", ""], ["Wang", "Xiao", ""], ["Wu", "Shu", ""], ["Xiao", "Zhitao", ""]]}, {"id": "1911.11433", "submitter": "Anush Sankaran", "authors": "Ameya Prabhu, Riddhiman Dasgupta, Anush Sankaran, Srikanth\n  Tamilselvam, Senthil Mani", "title": "\"You might also like this model\": Data Driven Approach for Recommending\n  Deep Learning Models for Unknown Image Datasets", "comments": "NeurIPS 2019, New in ML Group", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an unknown (new) classification dataset, choosing an appropriate deep\nlearning architecture is often a recursive, time-taking, and laborious process.\nIn this research, we propose a novel technique to recommend a suitable\narchitecture from a repository of known models. Further, we predict the\nperformance accuracy of the recommended architecture on the given unknown\ndataset, without the need for training the model. We propose a model encoder\napproach to learn a fixed length representation of deep learning architectures\nalong with its hyperparameters, in an unsupervised fashion. We manually curate\na repository of image datasets with corresponding known deep learning models\nand show that the predicted accuracy is a good estimator of the actual\naccuracy. We discuss the implications of the proposed approach for three\nbenchmark images datasets and also the challenges in using the approach for\ntext modality. To further increase the reproducibility of the proposed\napproach, the entire implementation is made publicly available along with the\ntrained models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:01:35 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:45:57 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Prabhu", "Ameya", ""], ["Dasgupta", "Riddhiman", ""], ["Sankaran", "Anush", ""], ["Tamilselvam", "Srikanth", ""], ["Mani", "Senthil", ""]]}, {"id": "1911.11481", "submitter": "Alina Dubatovka", "authors": "Alina Dubatovka, Efi Kokiopoulou, Luciano Sbaiz, Andrea Gesmundo,\n  Gabor Bartok, Jesse Berent", "title": "Ranking architectures using meta-learning", "comments": "NeurIPS 2019 Meta-Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has recently attracted lots of research efforts as\nit promises to automate the manual design of neural networks. However, it\nrequires a large amount of computing resources and in order to alleviate this,\na performance prediction network has been recently proposed that enables\nefficient architecture search by forecasting the performance of candidate\narchitectures, instead of relying on actual model training. The performance\npredictor is task-aware taking as input not only the candidate architecture but\nalso task meta-features and it has been designed to collectively learn from\nseveral tasks. In this work, we introduce a pairwise ranking loss for training\na network able to rank candidate architectures for a new unseen task\nconditioning on its task meta-features. We present experimental results,\nshowing that the ranking network is more effective in architecture search than\nthe previously proposed performance predictor.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:04:51 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Dubatovka", "Alina", ""], ["Kokiopoulou", "Efi", ""], ["Sbaiz", "Luciano", ""], ["Gesmundo", "Andrea", ""], ["Bartok", "Gabor", ""], ["Berent", "Jesse", ""]]}, {"id": "1911.11486", "submitter": "Yue Wang", "authors": "Yue Wang, Chenwei Zhang, Shen Wang, Philip S. Yu, Lu Bai, Lixin Cui,\n  Guandong Xu", "title": "Generative Temporal Link Prediction via Self-tokenized Sequence Modeling", "comments": "accepted by World Wide Web Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize networks with evolving structures as temporal networks and\npropose a generative link prediction model, Generative Link Sequence Modeling\n(GLSM), to predict future links for temporal networks. GLSM captures the\ntemporal link formation patterns from the observed links with a sequence\nmodeling framework and has the ability to generate the emerging links by\ninferring from the probability distribution on the potential future links. To\navoid overfitting caused by treating each link as a unique token, we propose a\nself-tokenization mechanism to transform each raw link in the network to an\nabstract aggregation token automatically. The self-tokenization is seamlessly\nintegrated into the sequence modeling framework, which allows the proposed GLSM\nmodel to have the generalization capability to discover link formation patterns\nbeyond raw link sequences. We compare GLSM with the existing state-of-art\nmethods on five real-world datasets. The experimental results demonstrate that\nGLSM obtains future positive links effectively in a generative fashion while\nachieving the best performance (2-10\\% improvements on AUC) among other\nalternatives.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:14:01 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 13:17:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Yue", ""], ["Zhang", "Chenwei", ""], ["Wang", "Shen", ""], ["Yu", "Philip S.", ""], ["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Xu", "Guandong", ""]]}, {"id": "1911.11496", "submitter": "Tom Hanika", "authors": "Dominik D\\\"urrschnabel and Tom Hanika and Maximilian Stubbemann", "title": "FCA2VEC: Embedding Techniques for Formal Concept Analysis", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding large and high dimensional data into low dimensional vector spaces\nis a necessary task to computationally cope with contemporary data sets.\nSuperseding latent semantic analysis recent approaches like word2vec or\nnode2vec are well established tools in this realm. In the present paper we add\nto this line of research by introducing fca2vec, a family of embedding\ntechniques for formal concept analysis (FCA). Our investigation contributes to\ntwo distinct lines of research. First, we enable the application of FCA notions\nto large data sets. In particular, we demonstrate how the cover relation of a\nconcept lattice can be retrieved from a computational feasible embedding.\nSecondly, we show an enhancement for the classical node2vec approach in low\ndimension. For both directions the overall constraint of FCA of explainable\nresults is preserved. We evaluate our novel procedures by computing fca2vec on\ndifferent data sets like, wiki44 (a dense part of the Wikidata knowledge\ngraph), the Mushroom data set and a publication network derived from the FCA\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:36:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Hanika", "Tom", ""], ["Stubbemann", "Maximilian", ""]]}, {"id": "1911.11506", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "Word-Class Embeddings for Multiclass Text Classification", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word embeddings encode general word semantics and lexical\nregularities of natural language, and have proven useful across many NLP tasks,\nincluding word sense disambiguation, machine translation, and sentiment\nanalysis, to name a few. In supervised tasks such as multiclass text\nclassification (the focus of this article) it seems appealing to enhance word\nrepresentations with ad-hoc embeddings that encode task-specific information.\nWe propose (supervised) word-class embeddings (WCEs), and show that, when\nconcatenated to (unsupervised) pre-trained word embeddings, they substantially\nfacilitate the training of deep-learning models in multiclass classification by\ntopic. We show empirical evidence that WCEs yield a consistent improvement in\nmulticlass classification accuracy, using four popular neural architectures and\nsix widely used and publicly available datasets for multiclass text\nclassification. Our code that implements WCEs is publicly available at\nhttps://github.com/AlexMoreo/word-class-embeddings\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:11:00 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1911.11525", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Michael Mrejen, Lior Wolf, Haim Suchowski", "title": "Spectra2pix: Generating Nanostructure Images from Spectra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of the nanostructures that are used in the field of nano-photonics\nhas remained complex, very often relying on the intuition and expertise of the\ndesigner, ultimately limiting the reach and penetration of this groundbreaking\napproach. Recently, there has been an increasing number of studies suggesting\nto apply Machine Learning techniques for the design of nanostructures. Most of\nthese studies engage Deep Learning techniques, which entails training a Deep\nNeural Network (DNN) to approximate the highly non-linear function of the\nunderlying physical process between spectra and nanostructures. At the end of\nthe training, the DNN allows an on-demand design of nanostructures, i.e. the\nmodel can infer nanostructure geometries for desired spectra. In this work, we\nintroduce spectra2pix, which is a model DNN trained to generate 2D images of\nthe designed nanostructures. Our model architecture is not limited to a closed\nset of nanostructure shapes, and can be trained for the design of any geometry.\nWe show, for the first time, a successful generalization ability by designing a\ncompletely unseen sub-family of geometries. This generalization capability\nhighlights the importance of our model architecture, and allows higher\napplicability for real-world design problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:35:45 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Malkiel", "Itzik", ""], ["Mrejen", "Michael", ""], ["Wolf", "Lior", ""], ["Suchowski", "Haim", ""]]}, {"id": "1911.11536", "submitter": "Christian Lang", "authors": "Christian Lang, Florian Steinborn, Oliver Steffens, Elmar W. Lang", "title": "Electricity Load Forecasting -- An Evaluation of Simple 1D-CNN Network\n  Structures", "comments": "Presented at the ITISE 2019 in Granada", "journal-ref": "Proceedings of Papers - ITISE 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a convolutional neural network (CNN) which can be used\nfor forecasting electricity load profiles 36 hours into the future. In contrast\nto well established CNN architectures, the input data is one-dimensional. A\nparameter scanning of network parameters is conducted in order to gain\ninformation about the influence of the kernel size, number of filters, and\ndense size. The results show that a good forecast quality can already be\nachieved with basic CNN architectures.The method works not only for smooth sum\nloads of many hundred consumers, but also for the load of apartment buildings.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:57:45 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lang", "Christian", ""], ["Steinborn", "Florian", ""], ["Steffens", "Oliver", ""], ["Lang", "Elmar W.", ""]]}, {"id": "1911.11542", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, and Bo Wahlberg", "title": "Recursive Prediction of Graph Signals with Incoming Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel and linear regression have been recently explored in the prediction of\ngraph signals as the output, given arbitrary input signals that are agnostic to\nthe graph. In many real-world problems, the graph expands over time as new\nnodes get introduced. Keeping this premise in mind, we propose a method to\nrecursively obtain the optimal prediction or regression coefficients for the\nrecently propose Linear Regression over Graphs (LRG), as the graph expands with\nincoming nodes. This comes as a natural consequence of the structure C(W)= of\nthe regression problem, and obviates the need to solve a new regression problem\neach time a new node is added. Experiments with real-world graph signals show\nthat our approach results in good prediction performance which tends to be\nclose to that obtained from knowing the entire graph apriori.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:07:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["Wahlberg", "Bo", ""]]}, {"id": "1911.11552", "submitter": "Heeyoul Choi", "authors": "Hyeokmin Gwon, Chungjun Lee, Rakun Keum, Heeyoul Choi", "title": "Network Intrusion Detection based on LSTM and Feature Embedding", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing number of network devices and services have led to increasing demand\nfor protective measures as hackers launch attacks to paralyze or steal\ninformation from victim systems. Intrusion Detection System (IDS) is one of the\nessential elements of network perimeter security which detects the attacks by\ninspecting network traffic packets or operating system logs. While existing\nworks demonstrated effectiveness of various machine learning techniques, only\nfew of them utilized the time-series information of network traffic data. Also,\ncategorical information has not been included in neural network based\napproaches. In this paper, we propose network intrusion detection models based\non sequential information using long short-term memory (LSTM) network and\ncategorical information using the embedding technique. We have experimented the\nmodels with UNSW-NB15, which is a comprehensive network traffic dataset. The\nexperiment results confirm that the proposed method improve the performance,\nobserving binary classification accuracy of 99.72\\%.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:15:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gwon", "Hyeokmin", ""], ["Lee", "Chungjun", ""], ["Keum", "Rakun", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1911.11553", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, H{\\aa}kan Hjalmarsson, Bo Wahlberg", "title": "Learning sparse linear dynamic networks in a hyper-parameter free\n  setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of estimating the topology and dynamics of sparse linear\ndynamic networks in a hyperparameter-free setting. We propose a method to\nestimate the network dynamics in a computationally efficient and parameter\ntuning-free iterative framework known as SPICE (Sparse Iterative Covariance\nEstimation). The estimated dynamics directly reveal the underlying topology.\nOur approach does not assume that the network is undirected and is applicable\neven with varying noise levels across the modules of the network. We also do\nnot assume any explicit prior knowledge on the network dynamics. Numerical\nexperiments with realistic dynamic networks illustrate the usefulness of our\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:16:41 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Hjalmarsson", "H\u00e5kan", ""], ["Wahlberg", "Bo", ""]]}, {"id": "1911.11554", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Guangzhi Wang, Shanghang Zhang, Yang Gu, Yaxian Li,\n  Zhichao Song, Pengfei Xu, Runbo Hu, Hua Chai, Kurt Keutzer", "title": "Multi-source Distilling Domain Adaptation", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks suffer from performance decay when there is domain shift\nbetween the labeled source domain and unlabeled target domain, which motivates\nthe research on domain adaptation (DA). Conventional DA methods usually assume\nthat the labeled data is sampled from a single source distribution. However, in\npractice, labeled data may be collected from multiple sources, while naive\napplication of the single-source DA algorithms may lead to suboptimal\nsolutions. In this paper, we propose a novel multi-source distilling domain\nadaptation (MDDA) network, which not only considers the different distances\namong multiple sources and the target, but also investigates the different\nsimilarities of the source samples to the target ones. Specifically, the\nproposed MDDA includes four stages: (1) pre-train the source classifiers\nseparately using the training data from each source; (2) adversarially map the\ntarget into the feature space of each source respectively by minimizing the\nempirical Wasserstein distance between source and target; (3) select the source\ntraining samples that are closer to the target to fine-tune the source\nclassifiers; and (4) classify each encoded target feature by corresponding\nsource classifier, and aggregate different predictions using respective domain\nweight, which corresponds to the discrepancy between each source and target.\nExtensive experiments are conducted on public DA benchmarks, and the results\ndemonstrate that the proposed MDDA significantly outperforms the\nstate-of-the-art approaches. Our source code is released at:\nhttps://github.com/daoyuan98/MDDA.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 19:30:15 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 18:21:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Zhao", "Sicheng", ""], ["Wang", "Guangzhi", ""], ["Zhang", "Shanghang", ""], ["Gu", "Yang", ""], ["Li", "Yaxian", ""], ["Song", "Zhichao", ""], ["Xu", "Pengfei", ""], ["Hu", "Runbo", ""], ["Chai", "Hua", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1911.11558", "submitter": "Shouman Das", "authors": "Rupam Acharyya, Shouman Das, Ankani Chattoraj, Md. Iftekhar Tanveer", "title": "FairyTED: A Fair Rating Predictor for TED Talk Data", "comments": "9 pages, 4 figures, 3 tables. Accepted as a conference paper to be\n  presented at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent trend of applying machine learning in every aspect of human\nlife, it is important to incorporate fairness into the core of the predictive\nalgorithms. We address the problem of predicting the quality of public speeches\nwhile being fair with respect to sensitive attributes of the speakers, e.g.\ngender and race. We use the TED talks as an input repository of public speeches\nbecause it consists of speakers from a diverse community and has a wide\noutreach. Utilizing the theories of Causal Models, Counterfactual Fairness and\nstate-of-the-art neural language models, we propose a mathematical framework\nfor fair prediction of the public speaking quality. We employ grounded\nassumptions to construct a causal model capturing how different attributes\naffect public speaking quality. This causal model contributes in generating\ncounterfactual data to train a fair predictive model. Our framework is general\nenough to utilize any assumption within the causal model. Experimental results\nshow that while prediction accuracy is comparable to recent work on this\ndataset, our predictions are counterfactually fair with respect to a novel\nmetric when compared to true data labels. The FairyTED setup not only allows\norganizers to make informed and diverse selection of speakers from the\nunobserved counterfactual possibilities but it also ensures that viewers and\nnew users are not influenced by unfair and unbalanced ratings from arbitrary\nvisitors to the www.ted.com website when deciding to view a talk.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:55:52 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Acharyya", "Rupam", ""], ["Das", "Shouman", ""], ["Chattoraj", "Ankani", ""], ["Tanveer", "Md. Iftekhar", ""]]}, {"id": "1911.11561", "submitter": "Yue Bai", "authors": "Yue Bai, Lichen Wang, Zhiqiang Tao, Sheng Li, Yun Fu", "title": "Correlative Channel-Aware Fusion for Multi-View Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view time series classification (MVTSC) aims to improve the performance\nby fusing the distinctive temporal information from multiple views. Existing\nmethods mainly focus on fusing multi-view information at an early stage, e.g.,\nby learning a common feature subspace among multiple views. However, these\nearly fusion methods may not fully exploit the unique temporal patterns of each\nview in complicated time series. Moreover, the label correlations of multiple\nviews, which are critical to boost-ing, are usually under-explored for the\nMVTSC problem. To address the aforementioned issues, we propose a Correlative\nChannel-Aware Fusion (C2AF) network. First, C2AF extracts comprehensive and\nrobust temporal patterns by a two-stream structured encoder for each view, and\ncaptures the intra-view and inter-view label correlations with a graph-based\ncorrelation matrix. Second, a channel-aware learnable fusion mechanism is\nimplemented through convolutional neural networks to further explore the global\ncorrelative patterns. These two steps are trained end-to-end in the proposed\nC2AF network. Extensive experimental results on three real-world datasets\ndemonstrate the superiority of our approach over the state-of-the-art methods.\nA detailed ablation study is also provided to show the effectiveness of each\nmodel component.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:22:57 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 23:05:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bai", "Yue", ""], ["Wang", "Lichen", ""], ["Tao", "Zhiqiang", ""], ["Li", "Sheng", ""], ["Fu", "Yun", ""]]}, {"id": "1911.11562", "submitter": "Subhajit Goswami", "authors": "Sabyasachi Chatterjee and Subhajit Goswami", "title": "Adaptive Estimation of Multivariate Piecewise Polynomials and Bounded\n  Variation Functions by Optimal Decision Trees", "comments": "56 pages, 5 figures. The current version has been accepted for\n  publication in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proposed by Donoho (1997), Dyadic CART is a nonparametric regression method\nwhich computes a globally optimal dyadic decision tree and fits piecewise\nconstant functions in two dimensions. In this article we define and study\nDyadic CART and a closely related estimator, namely Optimal Regression Tree\n(ORT), in the context of estimating piecewise smooth functions in general\ndimensions in the fixed design setup. More precisely, these optimal decision\ntree estimators fit piecewise polynomials of any given degree. Like Dyadic CART\nin two dimensions, we reason that these estimators can also be computed in\npolynomial time in the sample size $N$ via dynamic programming. We prove oracle\ninequalities for the finite sample risk of Dyadic CART and ORT which imply\ntight risk bounds for several function classes of interest. Firstly, they imply\nthat the finite sample risk of ORT of order $r \\geq 0$ is always bounded by $C\nk \\frac{\\log N}{N}$ whenever the regression function is piecewise polynomial of\ndegree $r$ on some reasonably regular axis aligned rectangular partition of the\ndomain with at most $k$ rectangles. Beyond the univariate case, such guarantees\nare scarcely available in the literature for computationally efficient\nestimators. Secondly, our oracle inequalities uncover minimax rate optimality\nand adaptivity of the Dyadic CART estimator for function spaces with bounded\nvariation. We consider two function spaces of recent interest where\nmultivariate total variation denoising and univariate trend filtering are the\nstate of the art methods. We show that Dyadic CART enjoys certain advantages\nover these estimators while still maintaining all their known guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:23:03 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 21:46:48 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 20:13:02 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chatterjee", "Sabyasachi", ""], ["Goswami", "Subhajit", ""]]}, {"id": "1911.11581", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang", "title": "Histogram Transform Ensembles for Density Estimation", "comments": "arXiv admin note: text overlap with arXiv:1905.03729", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an algorithm named histogram transform ensembles (HTE) density\nestimator whose effectiveness is supported by both solid theoretical analysis\nand significant experimental performance. On the theoretical side, by\ndecomposing the error term into approximation error and estimation error, we\nare able to conduct the following analysis: First of all, we establish the\nuniversal consistency under $L_1(\\mu)$-norm. Secondly, under the assumption\nthat the underlying density function resides in the H\\\"{o}lder space\n$C^{0,\\alpha}$, we prove almost optimal convergence rates for both single and\nensemble density estimators under $L_1(\\mu)$-norm and $L_{\\infty}(\\mu)$-norm\nfor different tail distributions, whereas in contrast, for its subspace\n$C^{1,\\alpha}$ consisting of smoother functions, almost optimal convergence\nrates can only be established for the ensembles and the lower bound of the\nsingle estimators illustrates the benefits of ensembles over single density\nestimators. In the experiments, we first carry out simulations to illustrate\nthat histogram transform ensembles surpass single histogram transforms, which\noffers powerful evidence to support the theoretical results in the space\n$C^{1,\\alpha}$. Moreover, to further exert the experimental performances, we\npropose an adaptive version of HTE and study the parameters by generating\nseveral synthetic datasets with diversities in dimensions and distributions.\nLast but not least, real data experiments with other state-of-the-art density\nestimators demonstrate the accuracy of the adaptive HTE algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 17:24:12 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Hang", "Hanyuan", ""]]}, {"id": "1911.11592", "submitter": "Harsh Singh", "authors": "Harsh Jot Singh and Abdelhakim Senhaji Hafid", "title": "Transaction Confirmation Time Prediction in Ethereum Blockchain Using\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain offers a decentralized, immutable, transparent system of records.\nIt offers a peer-to-peer network of nodes with no centralised governing entity\nmaking it unhackable and therefore, more secure than the traditional\npaper-based or centralised system of records like banks etc. While there are\ncertain advantages to the paper-based recording approach, it does not work well\nwith digital relationships where the data is in constant flux. Unlike\ntraditional channels, governed by centralized entities, blockchain offers its\nusers a certain level of anonymity by providing capabilities to interact\nwithout disclosing their personal identities and allows them to build trust\nwithout a third-party governing entity. Due to the aforementioned\ncharacteristics of blockchain, more and more users around the globe are\ninclined towards making a digital transaction via blockchain than via\nrudimentary channels. Therefore, there is a dire need for us to gain insight on\nhow these transactions are processed by the blockchain and how much time it may\ntake for a peer to confirm a transaction and add it to the blockchain network.\nThis paper presents a novel approach that would allow one to estimate the time,\nin block time or otherwise, it would take for a mining node to accept and\nconfirm a transaction to a block using machine learning. The paper also aims to\ncompare the predictive accuracy of two machine learning regression models-\nRandom Forest Regressor and Multilayer Perceptron against previously proposed\nstatistical regression model under a set evaluation criterion. The objective is\nto determine whether machine learning offers a more accurate predictive model\nthan conventional statistical models. The proposed model results in improved\naccuracy in prediction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:20:27 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Singh", "Harsh Jot", ""], ["Hafid", "Abdelhakim Senhaji", ""]]}, {"id": "1911.11607", "submitter": "Weijie J. Su", "authors": "Zhiqi Bu and Jinshuo Dong and Qi Long and Weijie J. Su", "title": "Deep Learning with Gaussian Differential Privacy", "comments": "To appear in Harvard Data Science Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are often trained on datasets that contain sensitive\ninformation such as individuals' shopping transactions, personal contacts, and\nmedical records. An increasingly important line of work therefore has sought to\ntrain neural networks subject to privacy constraints that are specified by\ndifferential privacy or its divergence-based relaxations. These privacy\ndefinitions, however, have weaknesses in handling certain important primitives\n(composition and subsampling), thereby giving loose or complicated privacy\nanalyses of training neural networks. In this paper, we consider a recently\nproposed privacy definition termed \\textit{$f$-differential privacy} [18] for a\nrefined privacy analysis of training neural networks. Leveraging the appealing\nproperties of $f$-differential privacy in handling composition and subsampling,\nthis paper derives analytically tractable expressions for the privacy\nguarantees of both stochastic gradient descent and Adam used in training deep\nneural networks, without the need of developing sophisticated techniques as [3]\ndid. Our results demonstrate that the $f$-differential privacy framework allows\nfor a new privacy analysis that improves on the prior analysis~[3], which in\nturn suggests tuning certain parameters of neural networks for a better\nprediction accuracy without violating the privacy budget. These theoretically\nderived improvements are confirmed by our experiments in a range of tasks in\nimage classification, text classification, and recommender systems. Python code\nto calculate the privacy cost for these experiments is publicly available in\nthe \\texttt{TensorFlow Privacy} library.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:08:58 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 03:11:37 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 16:09:13 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bu", "Zhiqi", ""], ["Dong", "Jinshuo", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "1911.11610", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Yan Han, Ahmed H Tewfik", "title": "Improving EEG based Continuous Speech Recognition", "comments": "On preparation for submission to EUSIPCO 2020. arXiv admin note: text\n  overlap with arXiv:1911.04261, arXiv:1906.08871", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce various techniques to improve the performance of\nelectroencephalography (EEG) features based continuous speech recognition (CSR)\nsystems. A connectionist temporal classification (CTC) based automatic speech\nrecognition (ASR) system was implemented for performing recognition. We\nintroduce techniques to initialize the weights of the recurrent layers in the\nencoder of the CTC model with more meaningful weights rather than with random\nweights and we make use of an external language model to improve the beam\nsearch during decoding time.\n  We finally study the problem of predicting articulatory features from EEG\nfeatures in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 16:00:49 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 04:16:39 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 08:37:50 GMT"}, {"version": "v4", "created": "Sun, 15 Dec 2019 06:36:00 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 20:44:05 GMT"}, {"version": "v6", "created": "Tue, 24 Dec 2019 04:52:49 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Han", "Yan", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1911.11622", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer and Mitchell McLaren", "title": "A discriminative condition-aware backend for speaker verification", "comments": null, "journal-ref": "Proceedings of ICASSP 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scoring approach for speaker verification that mimics the\nstandard PLDA-based backend process used in most current speaker verification\nsystems. However, unlike the standard backends, all parameters of the model are\njointly trained to optimize the binary cross-entropy for the speaker\nverification task. We further integrate the calibration stage inside the model,\nmaking the parameters of this stage depend on metadata vectors that represent\nthe conditions of the signals. We show that the proposed backend has excellent\nout-of-the-box calibration performance on most of our test sets, making it an\nideal approach for cases in which the test conditions are not known and\ndevelopment data is not available for training a domain-specific calibration\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:14:22 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ferrer", "Luciana", ""], ["McLaren", "Mitchell", ""]]}, {"id": "1911.11652", "submitter": "Alberto Torres-Barr\\'an", "authors": "Alberto Redondo, Alberto Torres-Barr\\'an, David R\\'ios Insua, Jordi\n  Domingo", "title": "Assessing Supply Chain Cyber Risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk assessment is a major challenge for supply chain managers, as it\npotentially affects business factors such as service costs, supplier\ncompetition and customer expectations. The increasing interconnectivity between\norganisations has put into focus methods for supply chain cyber risk\nmanagement. We introduce a general approach to support such activity taking\ninto account various techniques of attacking an organisation and its suppliers,\nas well as the impacts of such attacks. Since data is lacking in many respects,\nwe use structured expert judgment methods to facilitate its implementation. We\ncouple a family of forecasting models to enrich risk monitoring. The approach\nmay be used to set up risk alarms, negotiate service level agreements, rank\nsuppliers and identify insurance needs, among other management possibilities.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:49:08 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Redondo", "Alberto", ""], ["Torres-Barr\u00e1n", "Alberto", ""], ["Insua", "David R\u00edos", ""], ["Domingo", "Jordi", ""]]}, {"id": "1911.11658", "submitter": "Victor Kristof", "authors": "Victor Kristof, Valentin Quelquejay-Lecl\\`ere, Robin Zbinden, Lucas\n  Maystre, Matthias Grossglauser, Patrick Thiran", "title": "A User Study of Perceived Carbon Footprint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical model to understand people's perception of their\ncarbon footprint. Driven by the observation that few people think of CO2 impact\nin absolute terms, we design a system to probe people's perception from simple\npairwise comparisons of the relative carbon footprint of their actions. The\nformulation of the model enables us to take an active-learning approach to\nselecting the pairs of actions that are maximally informative about the model\nparameters. We define a set of 18 actions and collect a dataset of 2183\ncomparisons from 176 users on a university campus. The early results reveal\npromising directions to improve climate communication and enhance climate\nmitigation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:56:46 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 14:56:02 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kristof", "Victor", ""], ["Quelquejay-Lecl\u00e8re", "Valentin", ""], ["Zbinden", "Robin", ""], ["Maystre", "Lucas", ""], ["Grossglauser", "Matthias", ""], ["Thiran", "Patrick", ""]]}, {"id": "1911.11663", "submitter": "James Ritchie", "authors": "James A. Ritchie, Iain Murray", "title": "Scalable Extreme Deconvolution", "comments": "Appearing at the Second Workshop on Machine Learning and the Physical\n  Sciences (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Extreme Deconvolution method fits a probability density to a dataset\nwhere each observation has Gaussian noise added with a known sample-specific\ncovariance, originally intended for use with astronomical datasets. The\nexisting fitting method is batch EM, which would not normally be applied to\nlarge datasets such as the Gaia catalog containing noisy observations of a\nbillion stars. We propose two minibatch variants of extreme deconvolution,\nbased on an online variation of the EM algorithm, and direct gradient-based\noptimisation of the log-likelihood, both of which can run on GPUs. We\ndemonstrate that these methods provide faster fitting, whilst being able to\nscale to much larger models for use with larger datasets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:02:58 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ritchie", "James A.", ""], ["Murray", "Iain", ""]]}, {"id": "1911.11668", "submitter": "Travis LaCroix", "authors": "Travis LaCroix", "title": "Biology and Compositionality: Empirical Considerations for\n  Emergent-Communication Protocols", "comments": "Accepted for NeurIPS 2019 workshop Emergent Communication: Towards\n  Natural Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in artificial systems by using biological\nsystems as a guide. However, there is often little interaction between\ncomputational models for emergent communication and biological models of the\nemergence of language. Many researchers in language origins and emergent\ncommunication take compositionality as their primary target for explaining how\nsimple communication systems can become more like natural language. However,\nthere is reason to think that compositionality is the wrong target on the\nbiological side, and so too the wrong target on the machine-learning side. As\nsuch, the purpose of this paper is to explore this claim. This has theoretical\nimplications for language origins research more generally, but the focus here\nwill be the implications for research on emergent communication in computer\nscience and machine learning---specifically regarding the types of programmes\nthat might be expected to work and those which will not. I further suggest an\nalternative approach for future research which focuses on reflexivity, rather\nthan compositionality, as a target for explaining how simple communication\nsystems may become more like natural language. I end by providing some\nreference to the language origins literature that may be of some use to\nresearchers in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:07:44 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 19:36:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["LaCroix", "Travis", ""]]}, {"id": "1911.11679", "submitter": "Olivier Sigaud", "authors": "Guillaume Matheron and Nicolas Perrin and Olivier Sigaud", "title": "The problem with DDPG: understanding failures in deterministic\n  environments with sparse rewards", "comments": "19 pages, submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In environments with continuous state and action spaces, state-of-the-art\nactor-critic reinforcement learning algorithms can solve very complex problems,\nyet can also fail in environments that seem trivial, but the reason for such\nfailures is still poorly understood. In this paper, we contribute a formal\nexplanation of these failures in the particular case of sparse reward and\ndeterministic environments. First, using a very elementary control problem, we\nillustrate that the learning process can get stuck into a fixed point\ncorresponding to a poor solution. Then, generalizing from the studied example,\nwe provide a detailed analysis of the underlying mechanisms which results in a\nnew understanding of one of the convergence regimes of these algorithms. The\nresulting perspective casts a new light on already existing solutions to the\nissues we have highlighted, and suggests other potential approaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:28:09 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Matheron", "Guillaume", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "1911.11691", "submitter": "Siavash Golkar", "authors": "Siavash Golkar", "title": "Emergent Structures and Lifetime Structure Evolution in Artificial\n  Neural Networks", "comments": "Proceedings of NeurIPS workshop on Real Neurons & Hidden Units. 5\n  Pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the flexibility of biological neural networks whose connectivity\nstructure changes significantly during their lifetime, we introduce the\nUnstructured Recursive Network (URN) and demonstrate that it can exhibit\nsimilar flexibility during training via gradient descent. We show empirically\nthat many of the different neural network structures commonly used in practice\ntoday (including fully connected, locally connected and residual networks of\ndifferent depths and widths) can emerge dynamically from the same URN. These\ndifferent structures can be derived using gradient descent on a single general\nloss function where the structure of the data and the relative strengths of\nvarious regulator terms determine the structure of the emergent network. We\nshow that this loss function and the regulators arise naturally when\nconsidering the symmetries of the network as well as the geometric properties\nof the input data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:51:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Golkar", "Siavash", ""]]}, {"id": "1911.11702", "submitter": "Miguel Fabian Romero Rondon", "authors": "Miguel Fabian Romero Rondon, Lucile Sassatelli, Ramon Aparicio Pardo,\n  Frederic Precioso", "title": "Revisiting Deep Architectures for Head Motion Prediction in 360{\\deg}\n  Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider predicting the user's head motion in 360-degree videos, with 2\nmodalities only: the past user's positions and the video content (not knowing\nother users' traces). We make two main contributions. First, we re-examine\nexisting deep-learning approaches for this problem and identify hidden flaws\nfrom a thorough root-cause analysis. Second, from the results of this analysis,\nwe design a new proposal establishing state-of-the-art performance. First,\nre-assessing the existing methods that use both modalities, we obtain the\nsurprising result that they all perform worse than baselines using the user's\ntrajectory only. A root-cause analysis of the metrics, datasets and neural\narchitectures shows in particular that (i) the content can inform the\nprediction for horizons longer than 2 to 3 sec. (existing methods consider\nshorter horizons), and that (ii) to compete with the baselines, it is necessary\nto have a recurrent unit dedicated to process the positions, but this is not\nsufficient. Second, from a re-examination of the problem supported with the\nconcept of Structural-RNN, we design a new deep neural architecture, named\nTRACK. TRACK achieves state-of-the-art performance on all considered datasets\nand prediction horizons, outperforming competitors by up to 20 percent on\nfocus-type videos and horizons 2-5 seconds. The entire framework (codes and\ndatasets) is online and received an ACM reproducibility badge.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:13:00 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 14:07:32 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 16:13:35 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Rondon", "Miguel Fabian Romero", ""], ["Sassatelli", "Lucile", ""], ["Pardo", "Ramon Aparicio", ""], ["Precioso", "Frederic", ""]]}, {"id": "1911.11725", "submitter": "Nino Arsov", "authors": "Nino Arsov, Goran Velinov, Aleksandar S. Dimovski, Bojana Koteska,\n  Dragan Sahpaski, Margina Kon-Popovska", "title": "Prediction of Horizontal Data Partitioning Through Query Execution Cost\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The excessively increased volume of data in modern data management systems\ndemands an improved system performance, frequently provided by data\ndistribution, system scalability and performance optimization techniques.\nOptimized horizontal data partitioning has a significant influence of\ndistributed data management systems. An optimally partitioned schema found in\nthe early phase of logical database design without loading of real data in the\nsystem and its adaptation to changes of business environment are very important\nfor a successful implementation, system scalability and performance\nimprovement. In this paper we present a novel approach for finding an optimal\nhorizontally partitioned schema that manifests a minimal total execution cost\nof a given database workload. Our approach is based on a formal model that\nenables abstraction of the predicates in the workload queries, and are\nsubsequently used to define all relational fragments. This approach has\npredictive features acquired by simulation of horizontal partitioning, without\nloading any data into the partitions, but instead, altering the statistics in\nthe database catalogs. We define an optimization problem and employ a genetic\nalgorithm (GA) to find an approximately optimal horizontally partitioned\nschema. The solutions to the optimization problem are evaluated using\nPostgreSQL's query optimizer. The initial experimental evaluation of our\napproach confirms its efficiency and correctness, and the numbers imply that\nthe approach is effective in reducing the workload execution cost.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:02:58 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Velinov", "Goran", ""], ["Dimovski", "Aleksandar S.", ""], ["Koteska", "Bojana", ""], ["Sahpaski", "Dragan", ""], ["Kon-Popovska", "Margina", ""]]}, {"id": "1911.11726", "submitter": "Nino Arsov", "authors": "Nino Arsov and Georgina Mirceva", "title": "Network Embedding: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are one of the most powerful structures for modeling problems in the\nreal world. Downstream machine learning tasks defined on networks have the\npotential to solve a variety of problems. With link prediction, for instance,\none can predict whether two persons will become friends on a social network.\nMany machine learning algorithms, however, require that each input example is a\nreal vector. Network embedding encompasses various methods for unsupervised,\nand sometimes supervised, learning of feature representations of nodes and\nlinks in a network. Typically, embedding methods are based on the assumption\nthat the similarity between nodes in the network should be reflected in the\nlearned feature representations. In this paper, we review significant\ncontributions to network embedding in the last decade. In particular, we look\nat four methods: Spectral Clustering, DeepWalk, Large-scale Information Network\nEmbedding (LINE), and node2vec. We describe each method and list its advantages\nand shortcomings. In addition, we give examples of real-world machine learning\nproblems on networks in which the embedding is critical in order to maximize\nthe predictive performance of the machine learning task. Finally, we take a\nlook at research trends and state-of-the art methods in the research on network\nembedding.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:03:08 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Mirceva", "Georgina", ""]]}, {"id": "1911.11728", "submitter": "Sahil Bhatia", "authors": "Sahil Bhatia, Saswat Padhi, Nagarajan Natarajan, Rahul Sharma, Prateek\n  Jain", "title": "On Scaling Data-Driven Loop Invariant Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated synthesis of inductive invariants is an important problem in\nsoftware verification. Once all the invariants have been specified, software\nverification reduces to checking of verification conditions. Although static\nanalyses to infer invariants have been studied for over forty years, recent\nyears have seen a flurry of data-driven invariant inference techniques which\nguess invariants from examples instead of analyzing program text. However,\nthese techniques have been demonstrated to scale only to programs with a small\nnumber of variables. In this paper, we study these scalability issues and\naddress them in our tool oasis that improves the scale of data-driven invariant\ninference and outperforms state-of-the-art systems on benchmarks from the\ninvariant inference track of the Syntax Guided Synthesis competition.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:05:46 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:34:27 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Bhatia", "Sahil", ""], ["Padhi", "Saswat", ""], ["Natarajan", "Nagarajan", ""], ["Sharma", "Rahul", ""], ["Jain", "Prateek", ""]]}, {"id": "1911.11737", "submitter": "John Thickstun", "authors": "Harsh Verma, John Thickstun", "title": "Convolutional Composer Classification", "comments": "8 pages, published at ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates end-to-end learnable models for attributing composers\nto musical scores. We introduce several pooled, convolutional architectures for\nthis task and draw connections between our approach and classical learning\napproaches based on global and n-gram features. We evaluate models on a corpus\nof 2,500 scores from the KernScores collection, authored by a variety of\ncomposers spanning the Renaissance era to the early 20th century. This corpus\nhas substantial overlap with the corpora used in several previous, smaller\nstudies; we compare our results on subsets of the corpus to these previous\nworks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:17:14 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Verma", "Harsh", ""], ["Thickstun", "John", ""]]}, {"id": "1911.11743", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa", "authors": "Vinoj Jayasundara, Hirunima Jayasekara, Tharaka Samarasinghe, Kasun T.\n  Hemachandra", "title": "Device-Free User Authentication, Activity Classification and Tracking\n  using Passive Wi-Fi Sensing: A Deep Learning Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy issues related to video camera feeds have led to a growing need for\nsuitable alternatives that provide functionalities such as user authentication,\nactivity classification and tracking in a noninvasive manner. Existing\ninfrastructure makes Wi-Fi a possible candidate, yet, utilizing traditional\nsignal processing methods to extract information necessary to fully\ncharacterize an event by sensing weak ambient Wi-Fi signals is deemed to be\nchallenging. This paper introduces a novel end to-end deep learning framework\nthat simultaneously predicts the identity, activity and the location of a user\nto create user profiles similar to the information provided through a video\ncamera. The system is fully autonomous and requires zero user intervention\nunlike systems that require user-initiated initialization, or a user held\ntransmitting device to facilitate the prediction. The system can also predict\nthe trajectory of the user by predicting the location of a user over\nconsecutive time steps. The performance of the system is evaluated through\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:27:50 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jayasundara", "Vinoj", ""], ["Jayasekara", "Hirunima", ""], ["Samarasinghe", "Tharaka", ""], ["Hemachandra", "Kasun T.", ""]]}, {"id": "1911.11750", "submitter": "Nino Arsov", "authors": "Nino Arsov, Milan Dukovski, Blagoja Evkoski, Stefan Cvetkovski", "title": "A Measure of Similarity in Textual Data Using Spearman's Rank\n  Correlation Coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, many diverse advances have occurred in the field of\ninformation extraction from data. Information extraction in its simplest form\ntakes place in computing environments, where structured data can be extracted\nthrough a series of queries. The continuous expansion of quantities of data\nhave therefore provided an opportunity for knowledge extraction (KE) from a\ntextual document (TD). A typical problem of this kind is the extraction of\ncommon characteristics and knowledge from a group of TDs, with the possibility\nto group such similar TDs in a process known as clustering. In this paper we\npresent a technique for such KE among a group of TDs related to the common\ncharacteristics and meaning of their content. Our technique is based on the\nSpearman's Rank Correlation Coefficient (SRCC), for which the conducted\nexperiments have proven to be comprehensive measure to achieve a high-quality\nKE.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:38:59 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Dukovski", "Milan", ""], ["Evkoski", "Blagoja", ""], ["Cvetkovski", "Stefan", ""]]}, {"id": "1911.11756", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Semi-Supervised Learning for Text Classification by Layer Partitioning", "comments": "ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent neural semi-supervised learning algorithms rely on adding small\nperturbation to either the input vectors or their representations. These\nmethods have been successful on computer vision tasks as the images form a\ncontinuous manifold, but are not appropriate for discrete input such as\nsentence. To adapt these methods to text input, we propose to decompose a\nneural network $M$ into two components $F$ and $U$ so that $M = U\\circ F$. The\nlayers in $F$ are then frozen and only the layers in $U$ will be updated during\nmost time of the training. In this way, $F$ serves as a feature extractor that\nmaps the input to high-level representation and adds systematical noise using\ndropout. We can then train $U$ using any state-of-the-art SSL algorithms such\nas $\\Pi$-model, temporal ensembling, mean teacher, etc. Furthermore, this\ngradually unfreezing schedule also prevents a pretrained model from\ncatastrophic forgetting. The experimental results demonstrate that our approach\nprovides improvements when compared to state of the art methods especially on\nshort texts.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:47:48 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1911.11772", "submitter": "Ali Basirat", "authors": "Ali Basirat", "title": "Shifted Randomized Singular Value Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the randomized singular value decomposition (SVD) algorithm\n\\citep{Halko2011finding} to estimate the SVD of a shifted data matrix without\nexplicitly constructing the matrix in the memory. With no loss in the accuracy\nof the original algorithm, the extended algorithm provides for a more efficient\nway of matrix factorization. The algorithm facilitates the low-rank\napproximation and principal component analysis (PCA) of off-center data\nmatrices. When applied to different types of data matrices, our experimental\nresults confirm the advantages of the extensions made to the original\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:38:42 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 12:12:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Basirat", "Ali", ""]]}, {"id": "1911.11774", "submitter": "Chencheng Cai", "authors": "Chencheng Cai and Rong Chen and Han Xiao", "title": "Matrix Completion using Kronecker Product Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matrix completion problem is to recover the missing entries in a partially\nobserved matrix. Most of the existing matrix completion methods assume a low\nrank structure of the underlying complete matrix. In this paper, we introduce\nan alternative and more general form of the underlying complete matrix, which\nassumes a low Kronecker rank instead of a low regular rank, but includes the\nlatter as a special case. The extra flexibility allows for a much more\nparsimonious representation of the underlying matrix, but also raises the\nchallenge of determining the proper Kronecker product configuration to be used.\nWe find that the configuration can be identified using the mean squared error\ncriterion as well as a modified cross-validation criterion. We establish the\nconsistency of this procedure under suitable conditions on the signal-to-noise\nratio. A aggregation procedure is also proposed to deal with special missing\npatterns and complex underlying structures. Both numerical and empirical\nstudies are carried out to demonstrate the performance of the new method.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:48:31 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 03:04:00 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 18:18:31 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Cai", "Chencheng", ""], ["Chen", "Rong", ""], ["Xiao", "Han", ""]]}, {"id": "1911.11775", "submitter": "Omar Peracha", "authors": "Omar Peracha", "title": "Improving Polyphonic Music Models with Feature-Rich Encoding", "comments": "Proceedings of the 21st International Society for Music Information\n  Retrieval Conference, ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores sequential modelling of polyphonic music with deep neural\nnetworks. While recent breakthroughs have focussed on network architecture, we\ndemonstrate that the representation of the sequence can make an equally\nsignificant contribution to the performance of the model as measured by\nvalidation set loss. By extracting salient features inherent to the training\ndataset, the model can either be conditioned on these features or trained to\npredict said features as extra components of the sequences being modelled. We\nshow that training a neural network to predict a seemingly more complex\nsequence, with extra features included in the series being modelled, can\nimprove overall model performance significantly. We first introduce TonicNet, a\nGRU-based model trained to initially predict the chord at a given time-step\nbefore then predicting the notes of each voice at that time-step, in contrast\nwith the typical approach of predicting only the notes. We then evaluate\nTonicNet on the canonical JSB Chorales dataset and obtain state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:38:30 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:54:24 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 22:18:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Peracha", "Omar", ""]]}, {"id": "1911.11776", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Tatsuya Harada", "title": "Noise Robust Generative Adversarial Networks", "comments": "Accepted to CVPR 2020. Project page:\n  https://takuhirok.github.io/NR-GAN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are neural networks that learn data\ndistributions through adversarial training. In intensive studies, recent GANs\nhave shown promising results for reproducing training images. However, in spite\nof noise, they reproduce images with fidelity. As an alternative, we propose a\nnovel family of GANs called noise robust GANs (NR-GANs), which can learn a\nclean image generator even when training images are noisy. In particular,\nNR-GANs can solve this problem without having complete noise information (e.g.,\nthe noise distribution type, noise amount, or signal-noise relationship). To\nachieve this, we introduce a noise generator and train it along with a clean\nimage generator. However, without any constraints, there is no incentive to\ngenerate an image and noise separately. Therefore, we propose distribution and\ntransformation constraints that encourage the noise generator to capture only\nthe noise-specific components. In particular, considering such constraints\nunder different assumptions, we devise two variants of NR-GANs for\nsignal-independent noise and three variants of NR-GANs for signal-dependent\nnoise. On three benchmark datasets, we demonstrate the effectiveness of NR-GANs\nin noise robust image generation. Furthermore, we show the applicability of\nNR-GANs in image denoising. Our code is available at\nhttps://github.com/takuhirok/NR-GAN/.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:42:54 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 16:54:37 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1911.11791", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Purang Abolmaesumi, Sidney Fels", "title": "A Preliminary Study of Disentanglement With Insights on the Inadequacy\n  of Metrics", "comments": "Disentanglement Challenge - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled encoding is an important step towards a better representation\nlearning. However, despite the numerous efforts, there still is no clear winner\nthat captures the independent features of the data in an unsupervised fashion.\nIn this work we empirically evaluate the performance of six unsupervised\ndisentanglement approaches on the mpi3d toy dataset curated and released for\nthe NeurIPS 2019 Disentanglement Challenge. The methods investigated in this\nwork are Beta-VAE, Factor-VAE, DIP-I-VAE, DIP-II-VAE, Info-VAE, and Beta-TCVAE.\nThe capacities of all models were progressively increased throughout the\ntraining and the hyper-parameters were kept intact across experiments. The\nmethods were evaluated based on five disentanglement metrics, namely, DCI,\nFactor-VAE, IRS, MIG, and SAP-Score. Within the limitations of this study, the\nBeta-TCVAE approach was found to outperform its alternatives with respect to\nthe normalized sum of metrics. However, a qualitative study of the encoded\nlatents reveal that there is not a consistent correlation between the reported\nmetrics and the disentanglement potential of the model.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:01:03 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Abdi", "Amir H.", ""], ["Abolmaesumi", "Purang", ""], ["Fels", "Sidney", ""]]}, {"id": "1911.11800", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa", "authors": "Hirunima Jayasekara, Vinoj Jayasundara, Jathushan Rajasegaran, Sandaru\n  Jayasekara, Suranga Seneviratne, Ranga Rodrigo", "title": "TimeCaps: Learning From Time Series Data with Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks excel in understanding spatial relationships in 2D data for\nvision related tasks. Even though they are not designed to capture 1D temporal\nrelationships, with TimeCaps we demonstrate that given the ability, capsule\nnetworks excel in understanding temporal relationships. To this end, we\ngenerate capsules along the temporal and channel dimensions creating two\ntemporal feature detectors which learn contrasting relationships. TimeCaps\nsurpasses the state-of-the-art results by achieving 96.21% accuracy on\nidentifying 13 Electrocardiogram (ECG) signal beat categories, while achieving\non-par results on identifying 30 classes of short audio commands. Further, the\ninstantiation parameters inherently learnt by the capsule networks allow us to\ncompletely parameterize 1D signals which opens various possibilities in signal\nprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:28:57 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 16:58:10 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 12:01:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jayasekara", "Hirunima", ""], ["Jayasundara", "Vinoj", ""], ["Rajasegaran", "Jathushan", ""], ["Jayasekara", "Sandaru", ""], ["Seneviratne", "Suranga", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "1911.11807", "submitter": "Florian Hartmann", "authors": "Florian Hartmann, Sunah Suh, Arkadiusz Komarzewski, Tim D. Smith,\n  Ilana Segall", "title": "Federated Learning for Ranking Browser History Suggestions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a new subfield of machine learning that allows fitting\nmodels without collecting the training data itself. Instead of sharing data,\nusers collaboratively train a model by only sending weight updates to a server.\nTo improve the ranking of suggestions in the Firefox URL bar, we make use of\nFederated Learning to train a model on user interactions in a\nprivacy-preserving way. This trained model replaces a handcrafted heuristic,\nand our results show that users now type over half a character less to find\nwhat they are looking for. To be able to deploy our system to real users\nwithout degrading their experience during training, we design the optimization\nprocess to be robust. To this end, we use a variant of Rprop for optimization,\nand implement additional safeguards. By using a numerical gradient\napproximation technique, our system is able to optimize anything in Firefox\nthat is currently based on handcrafted heuristics. Our paper shows that\nFederated Learning can be used successfully to train models in\nprivacy-respecting ways.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:45:28 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hartmann", "Florian", ""], ["Suh", "Sunah", ""], ["Komarzewski", "Arkadiusz", ""], ["Smith", "Tim D.", ""], ["Segall", "Ilana", ""]]}, {"id": "1911.11819", "submitter": "David Zhao", "authors": "David Zhao, Alessandro Rinaldo, Christopher Brookins", "title": "Cryptocurrency Price Prediction and Trading Strategies Using Support\n  Vector Machines", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few assets in financial history have been as notoriously volatile as\ncryptocurrencies. While the long term outlook for this asset class remains\nunclear, we are successful in making short term price predictions for several\nmajor crypto assets. Using historical data from July 2015 to November 2019, we\ndevelop a large number of technical indicators to capture patterns in the\ncryptocurrency market. We then test various classification methods to forecast\nshort-term future price movements based on these indicators. On both PPV and\nNPV metrics, our classifiers do well in identifying up and down market moves\nover the next 1 hour. Beyond evaluating classification accuracy, we also\ndevelop a strategy for translating 1-hour-ahead class predictions into trading\ndecisions, along with a backtester that simulates trading in a realistic\nenvironment. We find that support vector machines yield the most profitable\ntrading strategies, which outperform the market on average for Bitcoin,\nEthereum and Litecoin over the past 22 months, since January 2018.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 20:26:46 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 22:58:25 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhao", "David", ""], ["Rinaldo", "Alessandro", ""], ["Brookins", "Christopher", ""]]}, {"id": "1911.11853", "submitter": "Antonio Ramires", "authors": "Ant\\'onio Ramires, Pritish Chandna, Xavier Favory, Emilia G\\'omez,\n  Xavier Serra", "title": "Neural Percussive Synthesis Parameterised by High-Level Timbral Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep neural network-based methodology for synthesising\npercussive sounds with control over high-level timbral characteristics of the\nsounds. This approach allows for intuitive control of a synthesizer, enabling\nthe user to shape sounds without extensive knowledge of signal processing. We\nuse a feedforward convolutional neural network-based architecture, which is\nable to map input parameters to the corresponding waveform. We propose two\ndatasets to evaluate our approach on both a restrictive context, and in one\ncovering a broader spectrum of sounds. The timbral features used as parameters\nare taken from recent literature in signal processing. We also use these\nfeatures for evaluation and validation of the presented model, to ensure that\nchanging the input parameters produces a congruent waveform with the desired\ncharacteristics. Finally, we evaluate the quality of the output sound using a\nsubjective listening test. We provide sound examples and the system's source\ncode for reproducibility.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:26:51 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 10:34:14 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ramires", "Ant\u00f3nio", ""], ["Chandna", "Pritish", ""], ["Favory", "Xavier", ""], ["G\u00f3mez", "Emilia", ""], ["Serra", "Xavier", ""]]}, {"id": "1911.11855", "submitter": "Badong Chen", "authors": "Badong Chen, Zhuang Li, Yingsong Li, Pengju Ren", "title": "Asymmetric Correntropy for Robust Adaptive Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, correntropy has been seccessfully applied to robust adaptive\nfiltering to eliminate adverse effects of impulsive noises or outliers.\nCorrentropy is generally defined as the expectation of a Gaussian kernel\nbetween two random variables. This definition is reasonable when the error\nbetween the two random variables is symmetrically distributed around zero. For\nthe case of asymmetric error distribution, the symmetric Gaussian kernel is\nhowever inappropriate and cannot adapt to the error distribution well. To\naddress this problem, in this letter we propose a new variant of correntropy,\nnamed asymmetric correntropy, which uses an asymmetric Gaussian model as the\nkernel function. In addition, a robust adaptive filtering algorithm based on\nasymmetric correntropy is developed and its steadystate convergence performance\nis analyzed. Simulations are provided to confirm the theoretical results and\ngood performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:02:40 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Badong", ""], ["Li", "Zhuang", ""], ["Li", "Yingsong", ""], ["Ren", "Pengju", ""]]}, {"id": "1911.11856", "submitter": "Jonathan Kuck", "authors": "Jonathan Kuck and Tri Dao and Hamid Rezatofighi and Ashish Sabharwal\n  and Stefano Ermon", "title": "Approximating the Permanent by Sampling from Adaptive Partitions", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the permanent of a non-negative matrix is a core problem with\npractical applications ranging from target tracking to statistical\nthermodynamics. However, this problem is also #P-complete, which leaves little\nhope for finding an exact solution that can be computed efficiently. While the\nproblem admits a fully polynomial randomized approximation scheme, this method\nhas seen little use because it is both inefficient in practice and difficult to\nimplement. We present AdaPart, a simple and efficient method for drawing exact\nsamples from an unnormalized distribution. Using AdaPart, we show how to\nconstruct tight bounds on the permanent which hold with high probability, with\nguaranteed polynomial runtime for dense matrices. We find that AdaPart can\nprovide empirical speedups exceeding 25x over prior sampling methods on\nmatrices that are challenging for variational based approaches. Finally, in the\ncontext of multi-target tracking, exact sampling from the distribution defined\nby the matrix permanent allows us to use the optimal proposal distribution\nduring particle filtering. Using AdaPart, we show that this leads to improved\ntracking performance using an order of magnitude fewer samples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 22:05:28 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Kuck", "Jonathan", ""], ["Dao", "Tri", ""], ["Rezatofighi", "Hamid", ""], ["Sabharwal", "Ashish", ""], ["Ermon", "Stefano", ""]]}, {"id": "1911.11881", "submitter": "Yifei Fan", "authors": "Chao Tang, Yifei Fan, Anthony Yezzi", "title": "An Adaptive View of Adversarial Robustness from Test-time Smoothing\n  Defense", "comments": "NeurIPS-2019 Workshop on Safety and Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The safety and robustness of learning-based decision-making systems are under\nthreats from adversarial examples, as imperceptible perturbations can mislead\nneural networks to completely different outputs. In this paper, we present an\nadaptive view of the issue via evaluating various test-time smoothing defense\nagainst white-box untargeted adversarial examples. Through controlled\nexperiments with pretrained ResNet-152 on ImageNet, we first illustrate the\nnon-monotonic relation between adversarial attacks and smoothing defenses. Then\nat the dataset level, we observe large variance among samples and show that it\nis easy to inflate accuracy (even to 100%) or build large-scale (i.e., with\nsize ~10^4) subsets on which a designated method outperforms others by a large\nmargin. Finally at the sample level, as different adversarial examples require\ndifferent degrees of defense, the potential advantages of iterative methods are\nalso discussed. We hope this paper reveal useful behaviors of test-time\ndefenses, which could help improve the evaluation process for adversarial\nrobustness in the future.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 23:45:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tang", "Chao", ""], ["Fan", "Yifei", ""], ["Yezzi", "Anthony", ""]]}, {"id": "1911.11888", "submitter": "Hugh Chen", "authors": "Hugh Chen and Scott Lundberg and Su-In Lee", "title": "Explaining Models by Propagating Shapley Values of Local Components", "comments": "4 pages and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, making the best possible predictions with complex models\n(e.g., neural networks, ensembles/stacks of different models) can impact\npatient welfare. In order to make these complex models explainable, we present\nDeepSHAP for mixed model types, a framework for layer wise propagation of\nShapley values that builds upon DeepLIFT (an existing approach for explaining\nneural networks). We show that in addition to being able to explain neural\nnetworks, this new framework naturally enables attributions for stacks of mixed\nmodels (e.g., neural network feature extractor into a tree model) as well as\nattributions of the loss. Finally, we theoretically justify a method for\nobtaining attributions with respect to a background distribution (under a\nShapley value framework).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:13:08 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Hugh", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "1911.11901", "submitter": "Joseph Gatto", "authors": "Joseph Gatto, Ravi Lanka, Yumi Iwashita, Adrian Stoica", "title": "Single Sample Feature Importance: An Interpretable Algorithm for\n  Low-Level Feature Analysis", "comments": "The research was carried out at the Jet Propulsion Laboratory,\n  California Institute of Technology, under a contract with the National\n  Aeronautics and Space Administration. The work of Joseph Gatto was sponsored\n  by the JPL Summer Internship Program and the National Aeronautics and Space\n  Administration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Have you ever wondered how your feature space is impacting the prediction of\na specific sample in your dataset? In this paper, we introduce Single Sample\nFeature Importance (SSFI), which is an interpretable feature importance\nalgorithm that allows for the identification of the most important features\nthat contribute to the prediction of a single sample. When a dataset can be\nlearned by a Random Forest classifier or regressor, SSFI shows how the Random\nForest's prediction path can be utilized for low-level feature importance\ncalculation. SSFI results in a relative ranking of features, highlighting those\nwith the greatest impact on a data point's prediction. We demonstrate these\nresults both numerically and visually on four different datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:58:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Gatto", "Joseph", ""], ["Lanka", "Ravi", ""], ["Iwashita", "Yumi", ""], ["Stoica", "Adrian", ""]]}, {"id": "1911.11908", "submitter": "Gan Sun", "authors": "Gan Sun, Yang Cong, Qianqian Wang, Jun Li, Yun Fu", "title": "Lifelong Spectral Clustering", "comments": "9 pages,7 figures", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, spectral clustering (SC) has become one of the most\neffective clustering algorithms. However, most previous studies focus on\nspectral clustering tasks with a fixed task set, which cannot incorporate with\na new spectral clustering task without accessing to previously learned tasks.\nIn this paper, we aim to explore the problem of spectral clustering in a\nlifelong machine learning framework, i.e., Lifelong Spectral Clustering (L2SC).\nIts goal is to efficiently learn a model for a new spectral clustering task by\nselectively transferring previously accumulated experience from knowledge\nlibrary. Specifically, the knowledge library of L2SC contains two components:\n1) orthogonal basis library: capturing latent cluster centers among the\nclusters in each pair of tasks; 2) feature embedding library: embedding the\nfeature manifold information shared among multiple related tasks. As a new\nspectral clustering task arrives, L2SC firstly transfers knowledge from both\nbasis library and feature library to obtain encoding matrix, and further\nredefines the library base over time to maximize performance across all the\nclustering tasks. Meanwhile, a general online update formulation is derived to\nalternatively update the basis library and feature library. Finally, the\nempirical experiments on several real-world benchmark datasets demonstrate that\nour L2SC model can effectively improve the clustering performance when\ncomparing with other state-of-the-art spectral clustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 01:37:18 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 04:03:02 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sun", "Gan", ""], ["Cong", "Yang", ""], ["Wang", "Qianqian", ""], ["Li", "Jun", ""], ["Fu", "Yun", ""]]}, {"id": "1911.11928", "submitter": "Yang Yu", "authors": "Rong-Jun Qin, Jing-Cheng Pang, Yang Yu", "title": "Improving Fictitious Play Reinforcement Learning with Expanding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fictitious play with reinforcement learning is a general and effective\nframework for zero-sum games. However, using the current deep neural network\nmodels, the implementation of fictitious play faces crucial challenges. Neural\nnetwork model training employs gradient descent approaches to update all\nconnection weights, and thus is easy to forget the old opponents after training\nto beat the new opponents. Existing approaches often maintain a pool of\nhistorical policy models to avoid the forgetting. However, learning to beat a\npool in stochastic games, i.e., a wide distribution over policy models, is\neither sample-consuming or insufficient to exploit all models with limited\namount of samples. In this paper, we propose a learning process with neural\nfictitious play to alleviate the above issues. We train a single model as our\npolicy model, which consists of sub-models and a selector. Everytime facing a\nnew opponent, the model is expanded by adding a new sub-model, where only the\nnew sub-model is updated instead of the whole model. At the same time, the\nselector is also updated to mix up the new sub-model with the previous ones at\nthe state-level, so that the model is maintained as a behavior strategy instead\nof a wide distribution over policy models. Experiments on Kuhn poker, a\ngrid-world Treasure Hunting game, and Mini-RTS environments show that the\nproposed approach alleviates the forgetting problem, and consequently improves\nthe learning efficiency and the robustness of neural fictitious play.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:14:37 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 04:54:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Qin", "Rong-Jun", ""], ["Pang", "Jing-Cheng", ""], ["Yu", "Yang", ""]]}, {"id": "1911.11932", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov, Vijay Gadepally, Karen M. Gettings, Michel A. Kinsy", "title": "Survey of Attacks and Defenses on Edge-Deployed Neural Networks", "comments": null, "journal-ref": "In the 2019 IEEE High Performance Extreme Computing Conference\n  (HPEC), 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) workloads are quickly moving from datacenters onto\nedge devices, for latency, privacy, or energy reasons. While datacenter\nnetworks can be protected using conventional cybersecurity measures, edge\nneural networks bring a host of new security challenges. Unlike classic IoT\napplications, edge neural networks are typically very compute and memory\nintensive, their execution is data-independent, and they are robust to noise\nand faults. Neural network models may be very expensive to develop, and can\npotentially reveal information about the private data they were trained on,\nrequiring special care in distribution. The hidden states and outputs of the\nnetwork can also be used in reconstructing user inputs, potentially violating\nusers' privacy. Furthermore, neural networks are vulnerable to adversarial\nattacks, which may cause misclassifications and violate the integrity of the\noutput. These properties add challenges when securing edge-deployed DNNs,\nrequiring new considerations, threat models, priorities, and approaches in\nsecurely and privately deploying DNNs to the edge. In this work, we cover the\nlandscape of attacks on, and defenses, of neural networks deployed in edge\ndevices and provide a taxonomy of attacks and defenses targeting edge DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:31:04 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Isakov", "Mihailo", ""], ["Gadepally", "Vijay", ""], ["Gettings", "Karen M.", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1911.11943", "submitter": "Choi Sungik", "authors": "Sungik Choi, Sae-Young Chung", "title": "Novelty Detection Via Blurring", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional out-of-distribution (OOD) detection schemes based on variational\nautoencoder or Random Network Distillation (RND) have been observed to assign\nlower uncertainty to the OOD than the target distribution. In this work, we\ndiscover that such conventional novelty detection schemes are also vulnerable\nto the blurred images. Based on the observation, we construct a novel RND-based\nOOD detector, SVD-RND, that utilizes blurred images during training. Our\ndetector is simple, efficient at test time, and outperforms baseline OOD\ndetectors in various domains. Further results show that SVD-RND learns better\ntarget distribution representation than the baseline RND algorithm. Finally,\nSVD-RND combined with geometric transform achieves near-perfect detection\naccuracy on the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:10:18 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:36:13 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 06:39:00 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Choi", "Sungik", ""], ["Chung", "Sae-Young", ""]]}, {"id": "1911.11950", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Santu Rana, Svetha Venkatesh", "title": "Trading Convergence Rate with Computational Budget in High Dimensional\n  Bayesian Optimization", "comments": "Our accepted paper (with Supplementary Material) at AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i03.5623", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling Bayesian optimisation (BO) to high-dimensional search spaces is a\nactive and open research problems particularly when no assumptions are made on\nfunction structure. The main reason is that at each iteration, BO requires to\nfind global maximisation of acquisition function, which itself is a non-convex\noptimization problem in the original search space. With growing dimensions, the\ncomputational budget for this maximisation gets increasingly short leading to\ninaccurate solution of the maximisation. This inaccuracy adversely affects both\nthe convergence and the efficiency of BO. We propose a novel approach where the\nacquisition function only requires maximisation on a discrete set of low\ndimensional subspaces embedded in the original high-dimensional search space.\nOur method is free of any low dimensional structure assumption on the function\nunlike many recent high-dimensional BO methods. Optimising acquisition function\nin low dimensional subspaces allows our method to obtain accurate solutions\nwithin limited computational budget. We show that in spite of this convenience,\nour algorithm remains convergent. In particular, cumulative regret of our\nalgorithm only grows sub-linearly with the number of iterations. More\nimportantly, as evident from our regret bounds, our algorithm provides a way to\ntrade the convergence rate with the number of subspaces used in the\noptimisation. Finally, when the number of subspaces is \"sufficiently large\",\nour algorithm's cumulative regret is at most\n$\\mathcal{O}^{*}(\\sqrt{T\\gamma_T})$ as opposed to\n$\\mathcal{O}^{*}(\\sqrt{DT\\gamma_T})$ for the GP-UCB of Srinivas et al. (2012),\nreducing a crucial factor $\\sqrt{D}$ where $D$ being the dimensional number of\ninput space.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:49:12 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 07:19:24 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1911.11952", "submitter": "Siamak Shakeri", "authors": "Siamak Shakeri, Abhinav Sethy", "title": "Label Dependent Deep Variational Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating paraphrases that are lexically similar but semantically different\nis a challenging task. Paraphrases of this form can be used to augment data\nsets for various NLP tasks such as machine reading comprehension and question\nanswering with non-trivial negative examples. In this article, we propose a\ndeep variational model to generate paraphrases conditioned on a label that\nspecifies whether the paraphrases are semantically related or not. We also\npresent new training recipes and KL regularization techniques that improve the\nperformance of variational paraphrasing models. Our proposed model demonstrates\npromising results in enhancing the generative power of the model by employing\nlabel-dependent generation on paraphrasing datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:54:14 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1911.11976", "submitter": "Faisal Hussain", "authors": "Faisal Hussain, Muhammad Basit Umair, Muhammad Ehatisham-ul-Haq, Ivan\n  Miguel Pires, T\\^ania Valente, Nuno M.Garcia and Nuno Pombo", "title": "An Efficient Machine Learning-based Elderly Fall Detection Algorithm", "comments": "6 pages, SENSORDEVICES 2018, the Ninth International Conference on\n  Sensor Device Technologies and Applications, Venice, Italy, 16-20 September\n  2018", "journal-ref": null, "doi": null, "report-no": "ISBN: 978-1-61208-660-6", "categories": "cs.LG cs.CY eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Falling is a commonly occurring mishap with elderly people, which may cause\nserious injuries. Thus, rapid fall detection is very important in order to\nmitigate the severe effects of fall among the elderly people. Many fall\nmonitoring systems based on the accelerometer have been proposed for the fall\ndetection. However, many of them mistakenly identify the daily life activities\nas fall or fall as daily life activity. To this aim, an efficient machine\nlearning-based fall detection algorithm has been proposed in this paper. The\nproposed algorithm detects fall with efficient sensitivity, specificity, and\naccuracy as compared to the state-of-the-art techniques. A publicly available\ndataset with a very simple and computationally efficient set of features is\nused to accurately detect the fall incident. The proposed algorithm reports and\naccuracy of 99.98% with the Support Vector Machine(SVM) classifier.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:26:10 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hussain", "Faisal", ""], ["Umair", "Muhammad Basit", ""], ["Ehatisham-ul-Haq", "Muhammad", ""], ["Pires", "Ivan Miguel", ""], ["Valente", "T\u00e2nia", ""], ["Garcia", "Nuno M.", ""], ["Pombo", "Nuno", ""]]}, {"id": "1911.11983", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Raymond K. W. Wong, Chinmay Hegde", "title": "Benefits of Jointly Training Autoencoders: An Improved Neural Tangent\n  Kernel Analysis", "comments": "Added Sections 3.2 and 3.4 on inductive biases. Fixed an error in\n  deriving the neural tangent kernel in Section 3.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A remarkable recent discovery in machine learning has been that deep neural\nnetworks can achieve impressive performance (in terms of both lower training\nerror and higher generalization capacity) in the regime where they are\nmassively over-parameterized. Consequently, over the past year, the community\nhas devoted growing interest in analyzing optimization and generalization\nproperties of over-parameterized networks, and several breakthrough works have\nled to important theoretical progress. However, the majority of existing work\nonly applies to supervised learning scenarios and hence are limited to settings\nsuch as classification and regression. In contrast, the role of\nover-parameterization in the unsupervised setting has gained far less\nattention. In this paper, we study the gradient dynamics of two-layer\nover-parameterized autoencoders with ReLU activation. We make very few\nassumptions about the given training dataset (other than mild non-degeneracy\nconditions). Starting from a randomly initialized autoencoder network, we\nrigorously prove the linear convergence of gradient descent in two learning\nregimes, namely: (i) the weakly-trained regime where only the encoder is\ntrained, and (ii) the jointly-trained regime where both the encoder and the\ndecoder are trained. Our results indicate the considerable benefits of joint\ntraining over weak training for finding global optima, achieving a dramatic\ndecrease in the required level of over-parameterization. We also analyze the\ncase of weight-tied autoencoders (which is a commonly used architectural choice\nin practical settings) and prove that in the over-parameterized setting,\ntraining such networks from randomly initialized points leads to certain\nunexpected degeneracies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:45:36 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:47:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Wong", "Raymond K. W.", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1911.11984", "submitter": "Chengyuan Deng", "authors": "Chen Wang, Chengyuan Deng, Vladimir Ivanov", "title": "SAG-VAE: End-to-end Joint Inference of Data Representations and Feature\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Variational Autoencoders (VAEs) are powerful in data representation\ninference, but it cannot learn relations between features with its vanilla form\nand common variations. The ability to capture relations within data can provide\nthe much needed inductive bias necessary for building more robust Machine\nLearning algorithms with more interpretable results. In this paper, inspired by\nrecent advances in relational learning using Graph Neural Networks, we propose\nthe Self-Attention Graph Variational AutoEncoder (SAG-VAE) network which can\nsimultaneously learn feature relations and data representations in an\nend-to-end manner. SAG-VAE is trained by jointly inferring the posterior\ndistribution of two types of latent variables, which denote the data\nrepresentation and a shared graph structure, respectively. Furthermore, we\nintroduce a novel self-attention graph network that improves the generative\ncapabilities of SAG-VAE by parameterizing the generative distribution allowing\nSAG-VAE to generate new data via graph convolution, while still trainable via\nbackpropagation. A learnable relational graph representation enhances SAG-VAE's\nrobustness to perturbation and noise, while also providing deeper intuition\ninto model performance. Experiments based on graphs show that SAG-VAE is\ncapable of approximately retrieving edges and links between nodes based\nentirely on feature observations. Finally, results on image data illustrate\nthat SAG-VAE is fairly robust against perturbations in image reconstruction and\nsampling.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:48:08 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:22:34 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 11:37:41 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""], ["Ivanov", "Vladimir", ""]]}, {"id": "1911.11988", "submitter": "Craig Atkinson", "authors": "Craig Atkinson, Brendan McCane, Lech Szymanski, Anthony Robins", "title": "GRIm-RePR: Prioritising Generating Important Features for\n  Pseudo-Rehearsal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-rehearsal allows neural networks to learn a sequence of tasks without\nforgetting how to perform in earlier tasks. Preventing forgetting is achieved\nby introducing a generative network which can produce data from previously seen\ntasks so that it can be rehearsed along side learning the new task. This has\nbeen found to be effective in both supervised and reinforcement learning. Our\ncurrent work aims to further prevent forgetting by encouraging the generator to\naccurately generate features important for task retention. More specifically,\nthe generator is improved by introducing a second discriminator into the\nGenerative Adversarial Network which learns to classify between real and fake\nitems from the intermediate activation patterns that they produce when fed\nthrough a continual learning agent. Using Atari 2600 games, we experimentally\nfind that improving the generator can considerably reduce catastrophic\nforgetting compared to the standard pseudo-rehearsal methods used in deep\nreinforcement learning. Furthermore, we propose normalising the Q-values taught\nto the long-term system as we observe this substantially reduces catastrophic\nforgetting by minimising the interference between tasks' reward functions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 07:06:03 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Atkinson", "Craig", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Robins", "Anthony", ""]]}, {"id": "1911.11992", "submitter": "Isao Ishikawa", "authors": "Masahiro Ikeda, Isao Ishikawa, Yoshihiro Sawano", "title": "Composition operators on reproducing kernel Hilbert spaces with analytic\n  positive definite functions", "comments": "We fix several typos. We add a result in the case of a tensor product\n  of even functions on the real line in Section 4.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA math.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we specify what functions induce the bounded composition\noperators on a reproducing kernel Hilbert space (RKHS) associated with an\nanalytic positive definite function defined on $\\mathbf{R}^d$. We prove that\nonly affine transforms can do so in a pretty large class of RKHS. Our result\ncovers not only the Paley-Wiener space on the real line, studied in previous\nworks, but also much more general RKHSs corresponding to analytic positive\ndefinite functions where existing methods do not work. Our method only relies\non an intrinsic properties of the RKHSs, and we establish a connection between\nthe behavior of composition operators and the asymptotic properties of the\ngreatest zeros of orthogonal polynomials on a weighted $L^2$-spaces on the real\nline. We also investigate the compactness of the composition operators and show\nthat any bounded composition operators cannot be compact in our situation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 07:15:59 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 12:09:40 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 16:08:52 GMT"}, {"version": "v4", "created": "Tue, 9 Mar 2021 05:40:04 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Ikeda", "Masahiro", ""], ["Ishikawa", "Isao", ""], ["Sawano", "Yoshihiro", ""]]}, {"id": "1911.11997", "submitter": "Haoyi Xiong", "authors": "Zhi Fengy, Haoyi Xiong, Chuanyuan Song, Sijia Yang, Baoxin Zhao,\n  Licheng Wang, Zeyu Chen, Shengwen Yang, Liping Liu, Jun Huan", "title": "SecureGBM: Secure Multi-Party Gradient Boosting", "comments": "The first two authors contributed equally to the manuscript. The\n  paper has been accepted for publication in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated machine learning systems have been widely used to facilitate the\njoint data analytics across the distributed datasets owned by the different\nparties that do not trust each others. In this paper, we proposed a novel\nGradient Boosting Machines (GBM) framework SecureGBM built-up with a\nmulti-party computation model based on semi-homomorphic encryption, where every\ninvolved party can jointly obtain a shared Gradient Boosting machines model\nwhile protecting their own data from the potential privacy leakage and\ninferential identification. More specific, our work focused on a specific\n\"dual--party\" secure learning scenario based on two parties -- both party own\nan unique view (i.e., attributes or features) to the sample group of samples\nwhile only one party owns the labels. In such scenario, feature and label data\nare not allowed to share with others. To achieve the above goal, we firstly\nextent -- LightGBM -- a well known implementation of tree-based GBM through\ncovering its key operations for training and inference with SEAL homomorphic\nencryption schemes. However, the performance of such re-implementation is\nsignificantly bottle-necked by the explosive inflation of the communication\npayloads, based on ciphertexts subject to the increasing length of plaintexts.\nIn this way, we then proposed to use stochastic approximation techniques to\nreduced the communication payloads while accelerating the overall training\nprocedure in a statistical manner. Our experiments using the real-world data\nshowed that SecureGBM can well secure the communication and computation of\nLightGBM training and inference procedures for the both parties while only\nlosing less than 3% AUC, using the same number of iterations for gradient\nboosting, on a wide range of benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 07:42:07 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Fengy", "Zhi", ""], ["Xiong", "Haoyi", ""], ["Song", "Chuanyuan", ""], ["Yang", "Sijia", ""], ["Zhao", "Baoxin", ""], ["Wang", "Licheng", ""], ["Chen", "Zeyu", ""], ["Yang", "Shengwen", ""], ["Liu", "Liping", ""], ["Huan", "Jun", ""]]}, {"id": "1911.12008", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, James Large and Matthew Middlehurst", "title": "A tale of two toolkits, report the second: bake off redux. Chapter 1.\n  dictionary based classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification (TSC) is the problem of learning labels from time\ndependent data. One class of algorithms is derived from a bag of words\napproach. A window is run along a series, the subseries is shortened and\ndiscretised to form a word, then features are formed from the histogram of\nfrequency of occurrence of words. We call this type of approach to TSC\ndictionary based classification. We compare four dictionary based algorithms in\nthe context of a wider project to update the great time series classification\nbakeoff, a comparative study published in 2017. We experimentally characterise\nthe algorithms in terms of predictive performance, time complexity and space\ncomplexity. We find that we can improve on the previous best in terms of\naccuracy, but this comes at the cost of time and space. Alternatively, the same\nperformance can be achieved with far less cost. We review the relative merits\nof the four algorithms before suggesting a path to possible improvement.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:05:48 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Bagnall", "Anthony", ""], ["Large", "James", ""], ["Middlehurst", "Matthew", ""]]}, {"id": "1911.12093", "submitter": "Ling Chen", "authors": "Weiqi Chen, Ling Chen, Yu Xie, Wei Cao, Yusong Gao, Xiaojie Feng", "title": "Multi-Range Attentive Bicomponent Graph Convolutional Network for\n  Traffic Forecasting", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting is of great importance to transportation management and\npublic safety, and very challenging due to the complicated spatial-temporal\ndependency and essential uncertainty brought about by the road network and\ntraffic conditions. Latest studies mainly focus on modeling the spatial\ndependency by utilizing graph convolutional networks (GCNs) throughout a fixed\nweighted graph. However, edges, i.e., the correlations between pair-wise nodes,\nare much more complicated and interact with each other. In this paper, we\npropose the Multi-Range Attentive Bicomponent GCN (MRA-BGCN), a novel deep\nlearning model for traffic forecasting. We first build the node-wise graph\naccording to the road network distance and the edge-wise graph according to\nvarious edge interaction patterns. Then, we implement the interactions of both\nnodes and edges using bicomponent graph convolution. The multi-range attention\nmechanism is introduced to aggregate information in different neighborhood\nranges and automatically learn the importance of different ranges. Extensive\nexperiments on two real-world road network traffic datasets, METR-LA and\nPEMS-BAY, show that our MRA-BGCN achieves the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:48:11 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Weiqi", ""], ["Chen", "Ling", ""], ["Xie", "Yu", ""], ["Cao", "Wei", ""], ["Gao", "Yusong", ""], ["Feng", "Xiaojie", ""]]}, {"id": "1911.12104", "submitter": "Jie Yang", "authors": "Jie Yang, Yu-Kai Wang, Xin Yao, Chin-Teng Lin", "title": "Adaptive Initialization Method for K-means Algorithm", "comments": "22 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The K-means algorithm is a widely used clustering algorithm that offers\nsimplicity and efficiency. However, the traditional K-means algorithm uses the\nrandom method to determine the initial cluster centers, which make clustering\nresults prone to local optima and then result in worse clustering performance.\nMany initialization methods have been proposed, but none of them can\ndynamically adapt to datasets with various characteristics. In our previous\nresearch, an initialization method for K-means based on hybrid distance was\nproposed, and this algorithm can adapt to datasets with different\ncharacteristics. However, it has the following drawbacks: (a) When calculating\ndensity, the threshold cannot be uniquely determined, resulting in unstable\nresults. (b) Heavily depending on adjusting the parameter, the parameter must\nbe adjusted five times to obtain better clustering results. (c) The time\ncomplexity of the algorithm is quadratic, which is difficult to apply to large\ndatasets. In the current paper, we proposed an adaptive initialization method\nfor the K-means algorithm (AIMK) to improve our previous work. AIMK can not\nonly adapt to datasets with various characteristics but also obtain better\nclustering results within two interactions. In addition, we then leverage\nrandom sampling in AIMK, which is named as AIMK-RS, to reduce the time\ncomplexity. AIMK-RS is easily applied to large and high-dimensional datasets.\nWe compared AIMK and AIMK-RS with 10 different algorithms on 16 normal and six\nextra-large datasets. The experimental results show that AIMK and AIMK-RS\noutperform the current initialization methods and several well-known clustering\nalgorithms. Furthermore, AIMK-RS can significantly reduce the complexity of\napplying it to extra-large datasets with high dimensions. The time complexity\nof AIMK-RS is O(n).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 12:27:00 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yang", "Jie", ""], ["Wang", "Yu-Kai", ""], ["Yao", "Xin", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1911.12122", "submitter": "Dmitry Baranchuk", "authors": "Dmitry Baranchuk, Artem Babenko", "title": "Towards Similarity Graphs Constructed by Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity graphs are an active research direction for the nearest neighbor\nsearch (NNS) problem. New algorithms for similarity graph construction are\ncontinuously being proposed and analyzed by both theoreticians and\npractitioners. However, existing construction algorithms are mostly based on\nheuristics and do not explicitly maximize the target performance measure, i.e.,\nsearch recall. Therefore, at the moment it is not clear whether the performance\nof similarity graphs has plateaued or more effective graphs can be constructed\nwith more theoretically grounded methods. In this paper, we introduce a new\nprincipled algorithm, based on adjacency matrix optimization, which explicitly\nmaximizes search efficiency. Namely, we propose a probabilistic model of a\nsimilarity graph defined in terms of its edge probabilities and show how to\nlearn these probabilities from data as a reinforcement learning task. As\nconfirmed by experiments, the proposed construction method can be used to\nrefine the state-of-the-art similarity graphs, achieving higher recall rates\nfor the same number of distance computations. Furthermore, we analyze the\nlearned graphs and reveal the structural properties that are responsible for\nmore efficient search.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:08:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:59:16 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Baranchuk", "Dmitry", ""], ["Babenko", "Artem", ""]]}, {"id": "1911.12126", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Tianbao Zhou and Bo Zhang and Jixiang Li", "title": "Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture\n  Search", "comments": "Accepted to ECCV 2020, camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Architecture Search (DARTS) is now a widely disseminated\nweight-sharing neural architecture search method. However, it suffers from\nwell-known performance collapse due to an inevitable aggregation of skip\nconnections. In this paper, we first disclose that its root cause lies in an\nunfair advantage in exclusive competition. Through experiments, we show that if\neither of two conditions is broken, the collapse disappears. Thereby, we\npresent a novel approach called Fair DARTS where the exclusive competition is\nrelaxed to be collaborative. Specifically, we let each operation's\narchitectural weight be independent of others. Yet there is still an important\nissue of discretization discrepancy. We then propose a zero-one loss to push\narchitectural weights towards zero or one, which approximates an expected\nmulti-hot solution. Our experiments are performed on two mainstream search\nspaces, and we derive new state-of-the-art results on CIFAR-10 and ImageNet.\nOur code is available on https://github.com/xiaomi-automl/fairdarts .\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:10:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 11:31:52 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 02:37:59 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 01:16:52 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhou", "Tianbao", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""]]}, {"id": "1911.12135", "submitter": "Tomasz Rutkowski", "authors": "Tomasz M. Rutkowski, Masato S. Abe, Marcin Koculak, Mihoko\n  Otake-Matsuura", "title": "Cognitive Assessment Estimation from Behavioral Responses in Emotional\n  Faces Evaluation Task -- AI Regression Approach for Dementia Onset Prediction\n  in Aging Societies", "comments": "4 pages, 2 figures, accepted for a presentation at AI for Social Good\n  workshop at NeurIPS (2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a practical health-theme machine learning (ML) application\nconcerning `AI for social good' domain for `Producing Good Outcomes' track. In\nparticular, the solution is concerning the problem of a potential elderly adult\ndementia onset prediction in aging societies. The paper discusses our attempt\nand encouraging preliminary study results of behavioral responses analysis in a\nworking memory-based emotional evaluation experiment. We focus on the\ndevelopment of digital biomarkers for dementia progress detection and\nmonitoring. We present a behavioral data collection concept for a subsequent\nAI-based application together with a range of regression encouraging results of\nMontreal Cognitive Assessment (MoCA) scores in the leave-one-subject-out\ncross-validation setup. The regressor input variables include experimental\nsubject's emotional valence and arousal recognition responses, as well as\nreaction times, together with self-reported education levels and ages, obtained\nfrom a group of twenty older adults taking part in the reported data collection\nproject. The presented results showcase the potential social benefits of\nartificial intelligence application for elderly and establish a step forward to\ndevelop ML approaches, for the subsequent application of simple behavioral\nobjective testing for dementia onset diagnostics replacing subjective MoCA.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 05:47:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Rutkowski", "Tomasz M.", ""], ["Abe", "Masato S.", ""], ["Koculak", "Marcin", ""], ["Otake-Matsuura", "Mihoko", ""]]}, {"id": "1911.12143", "submitter": "Takahiro Yabe", "authors": "Takahiro Yabe, Kota Tsubouchi, Toru Shimizu, Yoshihide Sekimoto,\n  Satish V. Ukkusuri", "title": "City2City: Translating Place Representations across Cities", "comments": "A short 4-page version of this work was accepted in ACM SIGSPATIAL\n  Conference 2019. This is the full version with details. In Proceedings of the\n  27th ACM SIGSPATIAL International Conference on Advances in Geographic\n  Information Systems. ACM", "journal-ref": null, "doi": "10.1145/3347146.3359063", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large mobility datasets collected from various sources have allowed us to\nobserve, analyze, predict and solve a wide range of important urban challenges.\nIn particular, studies have generated place representations (or embeddings)\nfrom mobility patterns in a similar manner to word embeddings to better\nunderstand the functionality of different places within a city. However,\nstudies have been limited to generating such representations of cities in an\nindividual manner and has lacked an inter-city perspective, which has made it\ndifficult to transfer the insights gained from the place representations across\ndifferent cities. In this study, we attempt to bridge this research gap by\ntreating \\textit{cities} and \\textit{languages} analogously. We apply methods\ndeveloped for unsupervised machine language translation tasks to translate\nplace representations across different cities. Real world mobility data\ncollected from mobile phone users in 2 cities in Japan are used to test our\nplace representation translation methods. Translated place representations are\nvalidated using landuse data, and results show that our methods were able to\naccurately translate place representations from one city to another.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:57:43 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yabe", "Takahiro", ""], ["Tsubouchi", "Kota", ""], ["Shimizu", "Toru", ""], ["Sekimoto", "Yoshihide", ""], ["Ukkusuri", "Satish V.", ""]]}, {"id": "1911.12161", "submitter": "David Zimmerer", "authors": "David Zimmerer, Jens Petersen, Klaus Maier-Hein", "title": "High- and Low-level image component decomposition using VAEs for\n  improved reconstruction and anomaly detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoders have often been used for unsupervised pretraining,\nfeature extraction and out-of-distribution and anomaly detection in the medical\nfield. However, VAEs often lack the ability to produce sharp images and learn\nhigh-level features. We propose to alleviate these issues by adding a new\nbranch to conditional hierarchical VAEs. This enforces a division between\nhigher-level and lower-level features. Despite the additional computational\noverhead compared to a normal VAE it results in sharper and better\nreconstructions and can capture the data distribution similarly well (indicated\nby a similar or slightly better OoD detection performance).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:08:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zimmerer", "David", ""], ["Petersen", "Jens", ""], ["Maier-Hein", "Klaus", ""]]}, {"id": "1911.12178", "submitter": "Karan Singh", "authors": "Elad Hazan, Sham M. Kakade, Karan Singh", "title": "The Nonstochastic Control Problem", "comments": "To appear at Algorithmic Learning Theory (ALT) 2020; small revisions\n  from the last ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling an unknown linear dynamical system in\nthe presence of (nonstochastic) adversarial perturbations and adversarial\nconvex loss functions. In contrast to classical control, the a priori\ndetermination of an optimal controller here is hindered by the latter's\ndependence on the yet unknown perturbations and costs. Instead, we measure\nregret against an optimal linear policy in hindsight, and give the first\nefficient algorithm that guarantees a sublinear regret bound, scaling as\nT^{2/3}, in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:29:50 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 08:08:10 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Hazan", "Elad", ""], ["Kakade", "Sham M.", ""], ["Singh", "Karan", ""]]}, {"id": "1911.12205", "submitter": "Junyi Gao", "authors": "Liantao Ma, Junyi Gao, Yasha Wang, Chaohe Zhang, Jiangtao Wang, Wenjie\n  Ruan, Wen Tang, Xin Gao, Xinyu Ma", "title": "AdaCare: Explainable Clinical Health Status Representation Learning via\n  Scale-Adaptive Feature Extraction and Recalibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based health status representation learning and clinical\nprediction have raised much research interest in recent years. Existing models\nhave shown superior performance, but there are still several major issues that\nhave not been fully taken into consideration. First, the historical variation\npattern of the biomarker in diverse time scales plays a vital role in\nindicating the health status, but it has not been explicitly extracted by\nexisting works. Second, key factors that strongly indicate the health risk are\ndifferent among patients. It is still challenging to adaptively make use of the\nfeatures for patients in diverse conditions. Third, using prediction models as\nthe black box will limit the reliability in clinical practice. However, none of\nthe existing works can provide satisfying interpretability and meanwhile\nachieve high prediction performance. In this work, we develop a general health\nstatus representation learning model, named AdaCare. It can capture the long\nand short-term variations of biomarkers as clinical features to depict the\nhealth status in multiple time scales. It also models the correlation between\nclinical features to enhance the ones which strongly indicate the health status\nand thus can maintain a state-of-the-art performance in terms of prediction\naccuracy while providing qualitative interpretability. We conduct a health risk\nprediction experiment on two real-world datasets. Experiment results indicate\nthat AdaCare outperforms state-of-the-art approaches and provides effective\ninterpretability, which is verifiable by clinical experts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:02:26 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ma", "Liantao", ""], ["Gao", "Junyi", ""], ["Wang", "Yasha", ""], ["Zhang", "Chaohe", ""], ["Wang", "Jiangtao", ""], ["Ruan", "Wenjie", ""], ["Tang", "Wen", ""], ["Gao", "Xin", ""], ["Ma", "Xinyu", ""]]}, {"id": "1911.12216", "submitter": "Junyi Gao", "authors": "Liantao Ma, Chaohe Zhang, Yasha Wang, Wenjie Ruan, Jiantao Wang, Wen\n  Tang, Xinyu Ma, Xin Gao, Junyi Gao", "title": "ConCare: Personalized Clinical Feature Embedding via Capturing the\n  Healthcare Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the patient's clinical outcome from the historical electronic\nmedical records (EMR) is a fundamental research problem in medical informatics.\nMost deep learning-based solutions for EMR analysis concentrate on learning the\nclinical visit embedding and exploring the relations between visits. Although\nthose works have shown superior performances in healthcare prediction, they\nfail to explore the personal characteristics during the clinical visits\nthoroughly. Moreover, existing works usually assume that the more recent record\nweights more in the prediction, but this assumption is not suitable for all\nconditions. In this paper, we propose ConCare to handle the irregular EMR data\nand extract feature interrelationship to perform individualized healthcare\nprediction. Our solution can embed the feature sequences separately by modeling\nthe time-aware distribution. ConCare further improves the multi-head\nself-attention via the cross-head decorrelation, so that the inter-dependencies\namong dynamic features and static baseline information can be effectively\ncaptured to form the personal health context. Experimental results on two\nreal-world EMR datasets demonstrate the effectiveness of ConCare. The medical\nfindings extracted by ConCare are also empirically confirmed by human experts\nand medical literature.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:19:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ma", "Liantao", ""], ["Zhang", "Chaohe", ""], ["Wang", "Yasha", ""], ["Ruan", "Wenjie", ""], ["Wang", "Jiantao", ""], ["Tang", "Wen", ""], ["Ma", "Xinyu", ""], ["Gao", "Xin", ""], ["Gao", "Junyi", ""]]}, {"id": "1911.12224", "submitter": "Bianca Iancu", "authors": "Bianca Iancu, Gabriele Mazzola, Kyriakos Psarakis, Panagiotis Soilis", "title": "Multi-label Classification for Automatic Tag Prediction in the Context\n  of Programming Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the best ways for developers to test and improve their skills in a fun\nand challenging way are programming challenges, offered by a plethora of\nwebsites. For the inexperienced ones, some of the problems might appear too\nchallenging, requiring some suggestions to implement a solution. On the other\nhand, tagging problems can be a tedious task for problem creators. In this\npaper, we focus on automating the task of tagging a programming challenge\ndescription using machine and deep learning methods. We observe that the deep\nlearning methods implemented outperform well-known IR approaches such as\ntf-idf, thus providing a starting point for further research on the task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:35:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Iancu", "Bianca", ""], ["Mazzola", "Gabriele", ""], ["Psarakis", "Kyriakos", ""], ["Soilis", "Panagiotis", ""]]}, {"id": "1911.12247", "submitter": "Thomas Kipf", "authors": "Thomas Kipf, Elise van der Pol, Max Welling", "title": "Contrastive Learning of Structured World Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A structured understanding of our world in terms of objects, relations, and\nhierarchies is an important component of human cognition. Learning such a\nstructured world model from raw sensory data remains a challenge. As a step\ntowards this goal, we introduce Contrastively-trained Structured World Models\n(C-SWMs). C-SWMs utilize a contrastive approach for representation learning in\nenvironments with compositional structure. We structure each state embedding as\na set of object representations and their relations, modeled by a graph neural\nnetwork. This allows objects to be discovered from raw pixel observations\nwithout direct supervision as part of the learning process. We evaluate C-SWMs\non compositional environments involving multiple interacting objects that can\nbe manipulated independently by an agent, simple Atari games, and a\nmulti-object physics simulation. Our experiments demonstrate that C-SWMs can\novercome limitations of models based on pixel reconstruction and outperform\ntypical representatives of this model class in highly structured environments,\nwhile learning interpretable object-based representations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:10:04 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 13:38:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kipf", "Thomas", ""], ["van der Pol", "Elise", ""], ["Welling", "Max", ""]]}, {"id": "1911.12250", "submitter": "Edouard Leurent", "authors": "Edouard Leurent, Jean Mercat", "title": "Social Attention for Autonomous Decision-Making in Dense Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of learning architectures for behavioural planning in a\ndense traffic setting. Such architectures should deal with a varying number of\nnearby vehicles, be invariant to the ordering chosen to describe them, while\nstaying accurate and compact. We observe that the two most popular\nrepresentations in the literature do not fit these criteria, and perform badly\non an complex negotiation task. We propose an attention-based architecture that\nsatisfies all these properties and explicitly accounts for the existing\ninteractions between the traffic participants. We show that this architecture\nleads to significant performance gains, and is able to capture interactions\npatterns that can be visualised and qualitatively interpreted. Videos and code\nare available at https://eleurent.github.io/social-attention/.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:14:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Leurent", "Edouard", ""], ["Mercat", "Jean", ""]]}, {"id": "1911.12258", "submitter": "Nuri Mert Vural", "authors": "Nuri Mert Vural, Fatih Ilhan and Suleyman S. Kozat", "title": "Stability of the Decoupled Extended Kalman Filter Learning Algorithm in\n  LSTM-Based Online Learning", "comments": "This paper was an early draft of the presented results. We have\n  written and published another paper (arXiv:1911.12258) where we have improved\n  on the material in this paper. The published paper covers most of the\n  material presented in this paper as well. Therefore, we remove this paper\n  from Arxiv and refer the interested readers to arXiv:1911.12258", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the convergence and stability properties of the decoupled\nextended Kalman filter learning algorithm (DEKF) within the long-short term\nmemory network (LSTM) based online learning framework. For this purpose, we\nmodel DEKF as a perturbed extended Kalman filter and derive sufficient\nconditions for its stability during LSTM training. We show that if the\nperturbations -- introduced due to decoupling -- stay bounded, DEKF learns LSTM\nparameters with similar convergence and stability properties of the global\nextended Kalman filter learning algorithm. We verify our results with several\nnumerical simulations and compare DEKF with other LSTM training methods. In our\nsimulations, we also observe that the well-known hyper-parameter selection\napproaches used for DEKF in the literature satisfy our conditions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:34:31 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 08:28:41 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 16:06:22 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 15:32:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vural", "Nuri Mert", ""], ["Ilhan", "Fatih", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1911.12287", "submitter": "Giannis Daras", "authors": "Giannis Daras, Augustus Odena, Han Zhang, Alexandros G. Dimakis", "title": "Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for\n  Generative Models", "comments": "Added TFRC, tensorflow-gan acknowledgements. Changed \"Ablation Study\"\n  to \"Ablation Studies\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new local sparse attention layer that preserves\ntwo-dimensional geometry and locality. We show that by just replacing the dense\nattention layer of SAGAN with our construction, we obtain very significant FID,\nInception score and pure visual improvements. FID score is improved from\n$18.65$ to $15.94$ on ImageNet, keeping all other parameters the same. The\nsparse attention patterns that we propose for our new layer are designed using\na novel information theoretic criterion that uses information flow graphs. We\nalso present a novel way to invert Generative Adversarial Networks with\nattention. Our method extracts from the attention layer of the discriminator a\nsaliency map, which we use to construct a new loss function for the inversion.\nThis allows us to visualize the newly introduced attention heads and show that\nthey indeed capture interesting aspects of two-dimensional geometry of real\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:03:16 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 18:30:38 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Daras", "Giannis", ""], ["Odena", "Augustus", ""], ["Zhang", "Han", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1911.12321", "submitter": "Ali Eshragh", "authors": "Ali Eshragh, Fred Roosta, Asef Nazari, Michael W. Mahoney", "title": "LSAR: Efficient Leverage Score Sampling Algorithm for the Analysis of\n  Big Time Series Data", "comments": "38 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply methods from randomized numerical linear algebra (RandNLA) to\ndevelop improved algorithms for the analysis of large-scale time series data.\nWe first develop a new fast algorithm to estimate the leverage scores of an\nautoregressive (AR) model in big data regimes. We show that the accuracy of\napproximations lies within $(1+\\mathcal{O}(\\varepsilon))$ of the true leverage\nscores with high probability. These theoretical results are subsequently\nexploited to develop an efficient algorithm, called LSAR, for fitting an\nappropriate AR model to big time series data. Our proposed algorithm is\nguaranteed, with high probability, to find the maximum likelihood estimates of\nthe parameters of the underlying true AR model and has a worst case running\ntime that significantly improves those of the state-of-the-art alternatives in\nbig data regimes. Empirical results on large-scale synthetic as well as real\ndata highly support the theoretical results and reveal the efficacy of this new\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:57:12 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 21:36:05 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Eshragh", "Ali", ""], ["Roosta", "Fred", ""], ["Nazari", "Asef", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1911.12322", "submitter": "Avital Shafran", "authors": "Avital Shafran, Gil Segev, Shmuel Peleg, Yedid Hoshen", "title": "Crypto-Oriented Neural Architecture Design", "comments": "Full version (shorter version published in ICASSP'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks revolutionize many applications, significant privacy\nconflicts between model users and providers emerge. The cryptography community\ndeveloped a variety of techniques for secure computation to address such\nprivacy issues. As generic techniques for secure computation are typically\nprohibitively ineffective, many efforts focus on optimizing their underlying\ncryptographic tools. Differently, we propose to optimize the initial design of\ncrypto-oriented neural architectures and provide a novel Partial Activation\nlayer. The proposed layer is much faster for secure computation. Evaluating our\nmethod on three state-of-the-art architectures (SqueezeNet, ShuffleNetV2, and\nMobileNetV2) demonstrates significant improvement to the efficiency of secure\ninference on common evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:57:42 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 17:48:31 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 06:42:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Shafran", "Avital", ""], ["Segev", "Gil", ""], ["Peleg", "Shmuel", ""], ["Hoshen", "Yedid", ""]]}, {"id": "1911.12360", "submitter": "Quanquan Gu", "authors": "Zixiang Chen and Yuan Cao and Difan Zou and Quanquan Gu", "title": "How Much Over-parameterization Is Sufficient to Learn Deep ReLU\n  Networks?", "comments": "26 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of research on deep learning focuses on the extremely\nover-parameterized setting, and shows that when the network width is larger\nthan a high degree polynomial of the training sample size $n$ and the inverse\nof the target error $\\epsilon^{-1}$, deep neural networks learned by\n(stochastic) gradient descent enjoy nice optimization and generalization\nguarantees. Very recently, it is shown that under certain margin assumptions on\nthe training data, a polylogarithmic width condition suffices for two-layer\nReLU networks to converge and generalize (Ji and Telgarsky, 2019). However,\nwhether deep neural networks can be learned with such a mild\nover-parameterization is still an open question. In this work, we answer this\nquestion affirmatively and establish sharper learning guarantees for deep ReLU\nnetworks trained by (stochastic) gradient descent. In specific, under certain\nassumptions made in previous work, our optimization and generalization\nguarantees hold with network width polylogarithmic in $n$ and $\\epsilon^{-1}$.\nOur results push the study of over-parameterized deep neural networks towards\nmore practical settings.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:59:50 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 05:22:34 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 17:41:21 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Zixiang", ""], ["Cao", "Yuan", ""], ["Zou", "Difan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1911.12410", "submitter": "Shahin Khobahi", "authors": "Shahin Khobahi, Mojtaba Soltanalian", "title": "Model-Aware Deep Architectures for One-Bit Compressive Variational\n  Autoencoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG eess.IV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized mathematical models play a central role in understanding and\ndesign of complex information systems. However, they often cannot take into\naccount the intricate interactions innate to such systems. On the contrary,\npurely data-driven approaches do not need explicit mathematical models for data\ngeneration and have a wider applicability at the cost of interpretability. In\nthis paper, we consider the design of a one-bit compressive variational\nautoencoder, and propose a novel hybrid model-based and data-driven methodology\nthat allows us not only to design the sensing matrix and the quantization\nthresholds for one-bit data acquisition, but also allows for learning the\nlatent-parameters of iterative optimization algorithms specifically designed\nfor the problem of one-bit sparse signal recovery. In addition, the proposed\nmethod has the ability to adaptively learn the proper quantization thresholds,\npaving the way for amplitude recovery in one-bit compressive sensing. Our\nresults demonstrate a significant improvement compared to state-of-the-art\nmodel-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 20:38:16 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Khobahi", "Shahin", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "1911.12426", "submitter": "Adam Sandler", "authors": "Adam Sandler, Diego Klabjan, Yuan Luo", "title": "Conditional Hierarchical Bayesian Tucker Decomposition", "comments": "20 pages, added model evaluation and log-likelihood sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research focuses on studying and developing methods for reducing the\ndimensionality of large datasets, common in biomedical applications. A major\nproblem when learning information about patients based on genetic sequencing\ndata is that there are often more feature variables (genetic data) than\nobservations (patients). This makes direct supervised learning difficult. One\nway of reducing the feature space is to use latent Dirichlet allocation in\norder to group genetic variants in an unsupervised manner. Latent Dirichlet\nallocation is a common model in natural language processing, which describes a\ndocument as a mixture of topics, each with a probability of generating certain\nwords. This can be generalized as a Bayesian tensor decomposition to account\nfor multiple feature variables. While we made some progress improving and\nmodifying these methods, our significant contributions are with hierarchical\ntopic modeling. We developed distinct methods of incorporating hierarchical\ntopic modeling, based on nested Chinese restaurant processes and Pachinko\nAllocation Machine, into Bayesian tensor decompositions. We apply these models\nto predict whether or not patients have autism spectrum disorder based on\ngenetic sequencing data. We examine a dataset from National Database for Autism\nResearch consisting of paired siblings -- one with autism, and the other\nwithout -- and counts of their genetic variants. Additionally, we linked the\ngenes with their Reactome biological pathways. We combine this information into\na tensor of patients, counts of their genetic variants, and the membership of\nthese genes in pathways. Once we decompose this tensor, we use logistic\nregression on the reduced features in order to predict if patients have autism.\nWe also perform a similar analysis of a dataset of patients with one of four\ncommon types of cancer (breast, lung, prostate, and colorectal).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:22:04 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 04:18:25 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Sandler", "Adam", ""], ["Klabjan", "Diego", ""], ["Luo", "Yuan", ""]]}, {"id": "1911.12436", "submitter": "Oskar Triebe", "authors": "Oskar Triebe, Nikolay Laptev, Ram Rajagopal", "title": "AR-Net: A simple Auto-Regressive Neural Network for time-series", "comments": "Building a bridge between traditional statistical time-series models\n  and deep-learning models. Main Topics: Time-Series, Auto-Regression, Neural\n  Networks, Sparsity, Long-Range Dependencies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new framework for time-series modeling that\ncombines the best of traditional statistical models and neural networks. We\nfocus on time-series with long-range dependencies, needed for monitoring fine\ngranularity data (e.g. minutes, seconds, milliseconds), prevalent in\noperational use-cases.\n  Traditional models, such as auto-regression fitted with least squares\n(Classic-AR) can model time-series with a concise and interpretable model. When\ndealing with long-range dependencies, Classic-AR models can become intractably\nslow to fit for large data. Recently, sequence-to-sequence models, such as\nRecurrent Neural Networks, which were originally intended for natural language\nprocessing, have become popular for time-series. However, they can be overly\ncomplex for typical time-series data and lack interpretability.\n  A scalable and interpretable model is needed to bridge the statistical and\ndeep learning-based approaches. As a first step towards this goal, we propose\nmodelling AR-process dynamics using a feed-forward neural network approach,\ntermed AR-Net. We show that AR-Net is as interpretable as Classic-AR but also\nscales to long-range dependencies.\n  Our results lead to three major conclusions: First, AR-Net learns identical\nAR-coefficients as Classic-AR, thus being equally interpretable. Second, the\ncomputational complexity with respect to the order of the AR process, is linear\nfor AR-Net as compared to a quadratic for Classic-AR. This makes it possible to\nmodel long-range dependencies within fine granularity data. Third, by\nintroducing regularization, AR-Net automatically selects and learns sparse\nAR-coefficients. This eliminates the need to know the exact order of the\nAR-process and allows to learn sparse weights for a model with long-range\ndependencies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:47:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Triebe", "Oskar", ""], ["Laptev", "Nikolay", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1911.12441", "submitter": "Trent Kyono", "authors": "Trent Kyono and Mihaela van der Schaar", "title": "Improving Model Robustness Using Causal Knowledge", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, researchers in fields, such as the natural and social sciences,\nhave been verifying causal relationships and investigating hypotheses that are\nnow well-established or understood as truth. These causal mechanisms are\nproperties of the natural world, and thus are invariant conditions regardless\nof the collection domain or environment. We show in this paper how prior\nknowledge in the form of a causal graph can be utilized to guide model\nselection, i.e., to identify from a set of trained networks the models that are\nthe most robust and invariant to unseen domains. Our method incorporates prior\nknowledge (which can be incomplete) as a Structural Causal Model (SCM) and\ncalculates a score based on the likelihood of the SCM given the target\npredictions of a candidate model and the provided input variables. We show on\nboth publicly available and synthetic datasets that our method is able to\nidentify more robust models in terms of generalizability to unseen\nout-of-distribution test examples and domains where covariates have shifted.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:57:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kyono", "Trent", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1911.12443", "submitter": "Aniket Pramanik", "authors": "Aniket Pramanik, Hemant Aggarwal and Mathews Jacob", "title": "Calibrationless Parallel MRI using Model based Deep Learning (C-MODL)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fast model based deep learning approach for calibrationless\nparallel MRI reconstruction. The proposed scheme is a non-linear generalization\nof structured low rank (SLR) methods that self learn linear annihilation\nfilters from the same subject. It pre-learns non-linear annihilation relations\nin the Fourier domain from exemplar data. The pre-learning strategy\nsignificantly reduces the computational complexity, making the proposed scheme\nthree orders of magnitude faster than SLR schemes. The proposed framework also\nallows the use of a complementary spatial domain prior; the hybrid\nregularization scheme offers improved performance over calibrated image domain\nMoDL approach. The calibrationless strategy minimizes potential mismatches\nbetween calibration data and the main scan, while eliminating the need for a\nfully sampled calibration region.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 22:04:54 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 13:45:49 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Pramanik", "Aniket", ""], ["Aggarwal", "Hemant", ""], ["Jacob", "Mathews", ""]]}, {"id": "1911.12446", "submitter": "Samuel Bosch", "authors": "Samuel Bosch, Alexander Sanchez de la Cerda, Mohsen Imani, Tajana\n  Simunic Rosing and Giovanni De Micheli", "title": "QubitHD: A Stochastic Acceleration Method for HD Computing-Based Machine\n  Learning", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Machine Learning algorithms based on Brain-inspired Hyperdimensional (HD)\ncomputing imitate cognition by exploiting statistical properties of\nhigh-dimensional vector spaces. It is a promising solution for achieving high\nenergy-efficiency in different machine learning tasks, such as classification,\nsemi-supervised learning and clustering. A weakness of existing HD\ncomputing-based ML algorithms is the fact that they have to be binarized for\nachieving very high energy-efficiency. At the same time, binarized models reach\nlower classification accuracies. To solve the problem of the trade-off between\nenergy-efficiency and classification accuracy, we propose the QubitHD\nalgorithm. It stochastically binarizes HD-based algorithms, while maintaining\ncomparable classification accuracies to their non-binarized counterparts. The\nFPGA implementation of QubitHD provides a 65% improvement in terms of\nenergy-efficiency, and a 95% improvement in terms of the training time, as\ncompared to state-of-the-art HD-based ML algorithms. It also outperforms\nstate-of-the-art low-cost classifiers (like Binarized Neural Networks) in terms\nof speed and energy-efficiency by an order of magnitude during training and\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 22:20:00 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 13:12:54 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bosch", "Samuel", ""], ["de la Cerda", "Alexander Sanchez", ""], ["Imani", "Mohsen", ""], ["Rosing", "Tajana Simunic", ""], ["De Micheli", "Giovanni", ""]]}, {"id": "1911.12463", "submitter": "Ke Sun", "authors": "Ke Sun and Frank Nielsen", "title": "Information-Geometric Set Embeddings (IGSE): From Sets to Probability\n  Distributions", "comments": "To be presented at Sets & Partitions (NeurIPS 2019 workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter introduces an abstract learning problem called the \"set\nembedding\": The objective is to map sets into probability distributions so as\nto lose less information. We relate set union and intersection operations with\ncorresponding interpolations of probability distributions. We also demonstrate\na preliminary solution with experimental results on toy set embedding examples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 23:38:17 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 23:03:00 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Sun", "Ke", ""], ["Nielsen", "Frank", ""]]}, {"id": "1911.12466", "submitter": "Ali Javed", "authors": "Ali Javed, Scott D. Hamshaw, Donna M. Rizzo, and Byung Suk Lee", "title": "Analysis of Hydrological and Suspended Sediment Events from Mad River\n  Watershed using Multivariate Time Series Clustering", "comments": "Corrected typo in title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydrological storm events are a primary driver for transporting water quality\nconstituents such as turbidity, suspended sediments and nutrients. Analyzing\nthe concentration (C) of these water quality constituents in response to\nincreased streamflow discharge (Q), particularly when monitored at high\ntemporal resolution during a hydrological event, helps to characterize the\ndynamics and flux of such constituents. A conventional approach to storm event\nanalysis is to reduce the C-Q time series to two-dimensional (2-D) hysteresis\nloops and analyze these 2-D patterns. While effective and informative to some\nextent, this hysteresis loop approach has limitations because projecting the\nC-Q time series onto a 2-D plane obscures detail (e.g., temporal variation)\nassociated with the C-Q relationships. In this paper, we address this issue\nusing a multivariate time series clustering approach. Clustering is applied to\nsequences of river discharge and suspended sediment data (acquired through\nturbidity-based monitoring) from six watersheds located in the Lake Champlain\nBasin in the northeastern United States. While clusters of the hydrological\nstorm events using the multivariate time series approach were found to be\ncorrelated to 2-D hysteresis loop classifications and watershed locations, the\nclusters differed from the 2-D hysteresis classifications. Additionally, using\navailable meteorological data associated with storm events, we examine the\ncharacteristics of computational clusters of storm events in the study\nwatersheds and identify the features driving the clustering approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 00:04:21 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:15:35 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Javed", "Ali", ""], ["Hamshaw", "Scott D.", ""], ["Rizzo", "Donna M.", ""], ["Lee", "Byung Suk", ""]]}, {"id": "1911.12473", "submitter": "Dang Nguyen", "authors": "Dang Nguyen, Sunil Gupta, Santu Rana, Alistair Shilton, Svetha\n  Venkatesh", "title": "Bayesian Optimization for Categorical and Category-Specific Continuous\n  Inputs", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world functions are defined over both categorical and\ncategory-specific continuous variables and thus cannot be optimized by\ntraditional Bayesian optimization (BO) methods. To optimize such functions, we\npropose a new method that formulates the problem as a multi-armed bandit\nproblem, wherein each category corresponds to an arm with its reward\ndistribution centered around the optimum of the objective function in\ncontinuous variables. Our goal is to identify the best arm and the maximizer of\nthe corresponding continuous function simultaneously. Our algorithm uses a\nThompson sampling scheme that helps connecting both multi-arm bandit and BO in\na unified framework. We extend our method to batch BO to allow parallel\noptimization when multiple resources are available. We theoretically analyze\nour method for convergence and prove sub-linear regret bounds. We perform a\nvariety of experiments: optimization of several benchmark functions,\nhyper-parameter tuning of a neural network, and automatic selection of the best\nmachine learning model along with its optimal hyper-parameters (a.k.a automated\nmachine learning). Comparisons with other methods demonstrate the effectiveness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:05:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nguyen", "Dang", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Shilton", "Alistair", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1911.12474", "submitter": "Mouloud Belbahri", "authors": "Mouloud Belbahri, Alejandro Murua, Olivier Gandouet, Vahid Partovi Nia", "title": "Qini-based Uplift Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift models provide a solution to the problem of isolating the marketing\neffect of a campaign. For customer churn reduction, uplift models are used to\nidentify the customers who are likely to respond positively to a retention\nactivity only if targeted, and to avoid wasting resources on customers that are\nvery likely to switch to another company. We introduce a Qini-based uplift\nregression model to analyze a large insurance company's retention marketing\ncampaign. Our approach is based on logistic regression models. We show that a\nQini-optimized uplift model acts as a regularizing factor for uplift, much as a\npenalized likelihood model does for regression. This results in interpretable\nparsimonious models with few relevant xplanatory variables. Our results show\nthat performing Qini-based parameters estimation significantly improves the\nuplift models performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:09:42 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 18:29:18 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Belbahri", "Mouloud", ""], ["Murua", "Alejandro", ""], ["Gandouet", "Olivier", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1911.12476", "submitter": "Shaoli Huang", "authors": "Mingjiang Liang, Shaoli Huang, Shirui Pan, Mingming Gong and Wei Liu", "title": "Learning Multi-level Weight-centric Features for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning is currently enjoying a considerable resurgence of\ninterest, aided by the recent advance of deep learning. Contemporary approaches\nbased on weight-generation scheme delivers a straightforward and flexible\nsolution to the problem. However, they did not fully consider both the\nrepresentation power for unseen categories and weight generation capacity in\nfeature learning, making it a significant performance bottleneck. This paper\nproposes a multi-level weight-centric feature learning to give full play to\nfeature extractor's dual roles in few-shot learning. Our proposed method\nconsists of two essential techniques: a weight-centric training strategy to\nimprove the features' prototype-ability and a multi-level feature incorporating\na mid- and relation-level information. The former increases the feasibility of\nconstructing a discriminative decision boundary based on a few samples.\nSimultaneously, the latter helps improve the transferability for characterizing\nnovel classes and preserve classification capability for base classes. We\nextensively evaluate our approach to low-shot classification benchmarks.\nExperiments demonstrate our proposed method significantly outperforms its\ncounterparts in both standard and generalized settings and using different\nnetwork backbones.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:22:59 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 05:58:52 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Liang", "Mingjiang", ""], ["Huang", "Shaoli", ""], ["Pan", "Shirui", ""], ["Gong", "Mingming", ""], ["Liu", "Wei", ""]]}, {"id": "1911.12481", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan", "title": "Product Knowledge Graph Embedding for E-commerce", "comments": null, "journal-ref": null, "doi": "10.1145/3336191.3371778", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new product knowledge graph (PKG) embedding\napproach for learning the intrinsic product relations as product knowledge for\ne-commerce. We define the key entities and summarize the pivotal product\nrelations that are critical for general e-commerce applications including\nmarketing, advertisement, search ranking and recommendation. We first provide a\ncomprehensive comparison between PKG and ordinary knowledge graph (KG) and then\nillustrate why KG embedding methods are not suitable for PKG learning. We\nconstruct a self-attention-enhanced distributed representation learning model\nfor learning PKG embeddings from raw customer activity data in an end-to-end\nfashion. We design an effective multi-task learning schema to fully leverage\nthe multi-modal e-commerce data. The Poincare embedding is also employed to\nhandle complex entity structures. We use a real-world dataset from\ngrocery.walmart.com to evaluate the performances on knowledge completion,\nsearch ranking and recommendation. The proposed approach compares favourably to\nbaselines in knowledge completion and downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:53:47 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "1911.12486", "submitter": "Xueya Zhang", "authors": "Xueya Zhang and Tong Zhang and Wenting Zhao and Zhen Cui and Jian Yang", "title": "Dual-Attention Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have shown the powerful ability in text\nstructure representation and effectively facilitate the task of text\nclassification. However, challenges still exist in adapting GCN on learning\ndiscriminative features from texts due to the main issue of graph variants\nincurred by the textual complexity and diversity. In this paper, we propose a\ndual-attention GCN to model the structural information of various texts as well\nas tackle the graph-invariant problem through embedding two types of attention\nmechanisms, i.e. the connection-attention and hop-attention, into the classic\nGCN. To encode various connection patterns between neighbour words,\nconnection-attention adaptively imposes different weights specified to\nneighbourhoods of each word, which captures the short-term dependencies. On the\nother hand, the hop-attention applies scaled coefficients to different scopes\nduring the graph diffusion process to make the model learn more about the\ndistribution of context, which captures long-term semantics in an adaptive way.\nExtensive experiments are conducted on five widely used datasets to evaluate\nour dual-attention GCN, and the achieved state-of-the-art performance verifies\nthe effectiveness of dual-attention mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:14:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Xueya", ""], ["Zhang", "Tong", ""], ["Zhao", "Wenting", ""], ["Cui", "Zhen", ""], ["Yang", "Jian", ""]]}, {"id": "1911.12505", "submitter": "Agelos Kratimenos", "authors": "Agelos Kratimenos, Kleanthis Avramidis, Christos Garoufis, Athanasia\n  Zlatintsi, Petros Maragos", "title": "Augmentation Methods on Monophonic Audio for Instrument Classification\n  in Polyphonic Music", "comments": null, "journal-ref": null, "doi": "10.23919/Eusipco47968.2020.9287745", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrument classification is one of the fields in Music Information Retrieval\n(MIR) that has attracted a lot of research interest. However, the majority of\nthat is dealing with monophonic music, while efforts on polyphonic material\nmainly focus on predominant instrument recognition. In this paper, we propose\nan approach for instrument classification in polyphonic music from purely\nmonophonic data, that involves performing data augmentation by mixing different\naudio segments. A variety of data augmentation techniques focusing on different\nsonic aspects, such as overlaying audio segments of the same genre, as well as\npitch and tempo-based synchronization, are explored. We utilize Convolutional\nNeural Networks for the classification task, comparing shallow to deep network\narchitectures. We further investigate the usage of a combination of the above\nclassifiers, each trained on a single augmented dataset. An ensemble of\nVGG-like classifiers, trained on non-augmented, pitch-synchronized,\ntempo-synchronized and genre-similar excerpts, respectively, yields the best\nresults, achieving slightly above 80% in terms of label ranking average\nprecision (LRAP) in the IRMAS test set.ruments in over 2300 testing tracks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:12:22 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 02:19:47 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kratimenos", "Agelos", ""], ["Avramidis", "Kleanthis", ""], ["Garoufis", "Christos", ""], ["Zlatintsi", "Athanasia", ""], ["Maragos", "Petros", ""]]}, {"id": "1911.12528", "submitter": "Istvan Fehervari", "authors": "Istvan Fehervari, Avinash Ravichandran, Srikar Appalaraju", "title": "Unbiased Evaluation of Deep Metric Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning (DML) is a popular approach for images retrieval,\nsolving verification (same or not) problems and addressing open set\nclassification. Arguably, the most common DML approach is with triplet loss,\ndespite significant advances in the area of DML. Triplet loss suffers from\nseveral issues such as collapse of the embeddings, high sensitivity to sampling\nschemes and more importantly a lack of performance when compared to more modern\nmethods. We attribute this adoption to a lack of fair comparisons between\nvarious methods and the difficulty in adopting them for novel problem\nstatements. In this paper, we perform an unbiased comparison of the most\npopular DML baseline methods under same conditions and more importantly, not\nobfuscating any hyper parameter tuning or adjustment needed to favor a\nparticular method. We find, that under equal conditions several older methods\nperform significantly better than previously believed. In fact, our unified\nimplementation of 12 recently introduced DML algorithms achieve state-of-the\nart performance on CUB200, CAR196, and Stanford Online products datasets which\nestablishes a new set of baselines for future DML research. The codebase and\nall tuned hyperparameters will be open-sourced for reproducibility and to serve\nas a source of benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 04:54:14 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fehervari", "Istvan", ""], ["Ravichandran", "Avinash", ""], ["Appalaraju", "Srikar", ""]]}, {"id": "1911.12540", "submitter": "Ehsan Hoseinzade", "authors": "Ehsan Hoseinzade, Saman Haratizadeh, Arash Khoeini", "title": "U-CNNpred: A Universal CNN-based Predictor for Stock Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of financial market prediction systems depends heavily on the\nquality of features it is using. While researchers have used various techniques\nfor enhancing the stock specific features, less attention has been paid to\nextracting features that represent general mechanism of financial markets. In\nthis paper, we investigate the importance of extracting such general features\nin stock market prediction domain and show how it can improve the performance\nof financial market prediction. We present a framework called U-CNNpred, that\nuses a CNN-based structure. A base model is trained in a specially designed\nlayer-wise training procedure over a pool of historical data from many\nfinancial markets, in order to extract the common patterns from different\nmarkets. Our experiments, in which we have used hundreds of stocks in S\\&P 500\nas well as 14 famous indices around the world, show that this model can\noutperform baseline algorithms when predicting the directional movement of the\nmarkets for which it has been trained for. We also show that the base model can\nbe fine-tuned for predicting new markets and achieve a better performance\ncompared to the state of the art baseline algorithms that focus on constructing\nmarket-specific models from scratch.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:50:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hoseinzade", "Ehsan", ""], ["Haratizadeh", "Saman", ""], ["Khoeini", "Arash", ""]]}, {"id": "1911.12560", "submitter": "Jierui Lin", "authors": "Jierui Lin, Min Du, Jian Liu", "title": "Free-riders in Federated Learning: Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a recently proposed paradigm that enables multiple\nclients to collaboratively train a joint model. It allows clients to train\nmodels locally, and leverages the parameter server to generate a global model\nby aggregating the locally submitted gradient updates at each round. Although\nthe incentive model for federated learning has not been fully developed, it is\nsupposed that participants are able to get rewards or the privilege to use the\nfinal global model, as a compensation for taking efforts to train the model.\nTherefore, a client who does not have any local data has the incentive to\nconstruct local gradient updates in order to deceive for rewards. In this\npaper, we are the first to propose the notion of free rider attacks, to explore\npossible ways that an attacker may construct gradient updates, without any\nlocal training data. Furthermore, we explore possible defenses that could\ndetect the proposed attacks, and propose a new high dimensional detection\nmethod called STD-DAGMM, which particularly works well for anomaly detection of\nmodel parameters. We extend the attacks and defenses to consider more free\nriders as well as differential privacy, which sheds light on and calls for\nfuture research in this field.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:13:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Jierui", ""], ["Du", "Min", ""], ["Liu", "Jian", ""]]}, {"id": "1911.12568", "submitter": "Ramya Korlakai Vinayak", "authors": "Ramya Korlakai Vinayak, Weihao Kong, Sham M. Kakade", "title": "Optimal Estimation of Change in a Population of Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paired estimation of change in parameters of interest over a population plays\na central role in several application domains including those in the social\nsciences, epidemiology, medicine and biology. In these domains, the size of the\npopulation under study is often very large, however, the number of observations\navailable per individual in the population is very small (\\emph{sparse\nobservations}) which makes the problem challenging. Consider the setting with\n$N$ independent individuals, each with unknown parameters $(p_i, q_i)$ drawn\nfrom some unknown distribution on $[0, 1]^2$. We observe $X_i \\sim\n\\text{Bin}(t, p_i)$ before an event and $Y_i \\sim \\text{Bin}(t, q_i)$ after the\nevent. Provided these paired observations, $\\{(X_i, Y_i) \\}_{i=1}^N$, our goal\nis to accurately estimate the \\emph{distribution of the change in parameters},\n$\\delta_i := q_i - p_i$, over the population and properties of interest like\nthe \\emph{$\\ell_1$-magnitude of the change} with sparse observations ($t\\ll\nN$). We provide \\emph{information theoretic lower bounds} on the error in\nestimating the distribution of change and the $\\ell_1$-magnitude of change.\nFurthermore, we show that the following two step procedure achieves the optimal\nerror bounds: first, estimate the full joint distribution of the paired\nparameters using the maximum likelihood estimator (MLE) and then estimate the\ndistribution of change and the $\\ell_1$-magnitude of change using the joint\nMLE. Notably, and perhaps surprisingly, these error bounds are of the same\norder as the minimax optimal error bounds for learning the \\emph{full} joint\ndistribution itself (in Wasserstein-1 distance); in other words, estimating the\nmagnitude of the change of parameters over the population is, in a minimax\nsense, as difficult as estimating the full joint distribution itself.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:43:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Vinayak", "Ramya Korlakai", ""], ["Kong", "Weihao", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1911.12574", "submitter": "Jie Wang", "authors": "Qi Zhou, Houqiang Li, Jie Wang", "title": "Deep Model-Based Reinforcement Learning via Estimated Uncertainty and\n  Conservative Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning algorithms tend to achieve higher sample\nefficiency than model-free methods. However, due to the inevitable errors of\nlearned models, model-based methods struggle to achieve the same asymptotic\nperformance as model-free methods.\n  In this paper, We propose a Policy Optimization method with Model-Based\nUncertainty (POMBU)---a novel model-based approach---that can effectively\nimprove the asymptotic performance using the uncertainty in Q-values. We derive\nan upper bound of the uncertainty, based on which we can approximate the\nuncertainty accurately and efficiently for model-based methods. We further\npropose an uncertainty-aware policy optimization algorithm that optimizes the\npolicy conservatively to encourage performance improvement with high\nprobability. This can significantly alleviate the overfitting of policy to\ninaccurate models.\n  Experiments show POMBU can outperform existing state-of-the-art policy\noptimization algorithms in terms of sample efficiency and asymptotic\nperformance. Moreover, the experiments demonstrate the excellent robustness of\nPOMBU compared to previous model-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:56:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhou", "Qi", ""], ["Li", "Houqiang", ""], ["Wang", "Jie", ""]]}, {"id": "1911.12580", "submitter": "Zheyan Shen", "authors": "Zheyan Shen, Peng Cui, Tong Zhang, Kun Kuang", "title": "Stable Learning via Sample Reweighting", "comments": "Accepted as poster paper at AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning linear prediction models with model\nmisspecification bias. In such case, the collinearity among input variables may\ninflate the error of parameter estimation, resulting in instability of\nprediction results when training and test distributions do not match. In this\npaper we theoretically analyze this fundamental problem and propose a sample\nreweighting method that reduces collinearity among input variables. Our method\ncan be seen as a pretreatment of data to improve the condition of design\nmatrix, and it can then be combined with any standard learning method for\nparameter estimation and variable selection. Empirical studies on both\nsimulation and real datasets demonstrate the effectiveness of our method in\nterms of more stable performance across different distributed data.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:12:24 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "Zheyan", ""], ["Cui", "Peng", ""], ["Zhang", "Tong", ""], ["Kuang", "Kun", ""]]}, {"id": "1911.12587", "submitter": "Julia Stoyanovich", "authors": "Sebastian Schelter, Yuxuan He, Jatin Khilnani, Julia Stoyanovich", "title": "FairPrep: Promoting Data to a First-Class Citizen in Studies on\n  Fairness-Enhancing Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of incorporating ethics and legal compliance into\nmachine-assisted decision-making is broadly recognized. Further, several lines\nof recent work have argued that critical opportunities for improving data\nquality and representativeness, controlling for bias, and allowing humans to\noversee and impact computational processes are missed if we do not consider the\nlifecycle stages upstream from model training and deployment. Yet, very little\nhas been done to date to provide system-level support to data scientists who\nwish to develop and deploy responsible machine learning methods. We aim to fill\nthis gap and present FairPrep, a design and evaluation framework for\nfairness-enhancing interventions.\n  FairPrep is based on a developer-centered design, and helps data scientists\nfollow best practices in software engineering and machine learning. As part of\nour contribution, we identify shortcomings in existing empirical studies for\nanalyzing fairness-enhancing interventions. We then show how FairPrep can be\nused to measure the impact of sound best practices, such as hyperparameter\ntuning and feature scaling. In particular, our results suggest that the high\nvariability of the outcomes of fairness-enhancing interventions observed in\nprevious studies is often an artifact of a lack of hyperparameter tuning.\nFurther, we show that the choice of a data cleaning method can impact the\neffectiveness of fairness-enhancing interventions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:28:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Schelter", "Sebastian", ""], ["He", "Yuxuan", ""], ["Khilnani", "Jatin", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1911.12595", "submitter": "Yawei Zhao", "authors": "Yawei Zhao, Qian Zhao, Xingxing Zhang, En Zhu, Xinwang Liu, Jianping\n  Yin", "title": "Understand Dynamic Regret with Switching Cost for Online Decision Making", "comments": "Accepted by ACM Transactions on Intelligent Systems and Technology\n  (TIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a metric to measure the performance of an online method, dynamic regret\nwith switching cost has drawn much attention for online decision making\nproblems. Although the sublinear regret has been provided in many previous\nresearches, we still have little knowledge about the relation between the\ndynamic regret and the switching cost. In the paper, we investigate the\nrelation for two classic online settings: Online Algorithms (OA) and Online\nConvex Optimization (OCO). We provide a new theoretical analysis framework,\nwhich shows an interesting observation, that is, the relation between the\nswitching cost and the dynamic regret is different for settings of OA and OCO.\nSpecifically, the switching cost has significant impact on the dynamic regret\nin the setting of OA. But, it does not have an impact on the dynamic regret in\nthe setting of OCO. Furthermore, we provide a lower bound of regret for the\nsetting of OCO, which is same with the lower bound in the case of no switching\ncost. It shows that the switching cost does not change the difficulty of online\ndecision making problems in the setting of OCO.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:46:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhao", "Yawei", ""], ["Zhao", "Qian", ""], ["Zhang", "Xingxing", ""], ["Zhu", "En", ""], ["Liu", "Xinwang", ""], ["Yin", "Jianping", ""]]}, {"id": "1911.12603", "submitter": "Guanhua Zheng", "authors": "Guanhua Zheng, Jitao Sang, Houqiang Li, Jian Yu, and Changsheng Xu", "title": "A Generalization Theory based on Independent and Task-Identically\n  Distributed Assumption", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing generalization theories analyze the generalization performance\nmainly based on the model complexity and training process. The ignorance of the\ntask properties, which results from the widely used IID assumption, makes these\ntheories fail to interpret many generalization phenomena or guide practical\nlearning tasks. In this paper, we propose a new Independent and\nTask-Identically Distributed (ITID) assumption, to consider the task properties\ninto the data generating process. The derived generalization bound based on the\nITID assumption identifies the significance of hypothesis invariance in\nguaranteeing generalization performance. Based on the new bound, we introduce a\npractical invariance enhancement algorithm from the perspective of modifying\ndata distributions. Finally, we verify the algorithm and theorems in the\ncontext of image classification task on both toy and real-world datasets. The\nexperimental results demonstrate the reasonableness of the ITID assumption and\nthe effectiveness of new generalization theory in improving practical\ngeneralization performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:06:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zheng", "Guanhua", ""], ["Sang", "Jitao", ""], ["Li", "Houqiang", ""], ["Yu", "Jian", ""], ["Xu", "Changsheng", ""]]}, {"id": "1911.12607", "submitter": "Ole-Christoffer Granmo", "authors": "Adrian Phoulady, Ole-Christoffer Granmo, Saeed Rahimi Gorji, Hady\n  Ahmady Phoulady", "title": "The Weighted Tsetlin Machine: Compressed Representations with Weighted\n  Clauses", "comments": "Accepted at the Ninth International Workshop on Statistical\n  Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is an interpretable mechanism for pattern\nrecognition that constructs conjunctive clauses from data. The clauses capture\nfrequent patterns with high discriminating power, providing increasing\nexpression power with each additional clause. However, the resulting accuracy\ngain comes at the cost of linear growth in computation time and memory usage.\nIn this paper, we present the Weighted Tsetlin Machine (WTM), which reduces\ncomputation time and memory usage by weighting the clauses. Real-valued\nweighting allows one clause to replace multiple, and supports fine-tuning the\nimpact of each clause. Our novel scheme simultaneously learns both the\ncomposition of the clauses and their weights. Furthermore, we increase training\nefficiency by replacing $k$ Bernoulli trials of success probability $p$ with a\nuniform sample of average size $p k$, the size drawn from a binomial\ndistribution. In our empirical evaluation, the WTM achieved the same accuracy\nas the TM on MNIST, IMDb, and Connect-4, requiring only $1/4$, $1/3$, and\n$1/50$ of the clauses, respectively. With the same number of clauses, the WTM\noutperformed the TM, obtaining peak test accuracies of respectively $98.63\\%$,\n$90.37\\%$, and $87.91\\%$. Finally, our novel sampling scheme reduced sample\ngeneration time by a factor of $7$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:23:09 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 08:00:42 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 07:50:16 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 17:51:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Phoulady", "Adrian", ""], ["Granmo", "Ole-Christoffer", ""], ["Gorji", "Saeed Rahimi", ""], ["Phoulady", "Hady Ahmady", ""]]}, {"id": "1911.12665", "submitter": "Jie Wang", "authors": "Taoxing Pan, Jun Liu, Jie Wang", "title": "D-SPIDER-SFO: A Decentralized Optimization Algorithm with Faster\n  Convergence Rate for Nonconvex Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization algorithms have attracted intensive interests\nrecently, as it has a balanced communication pattern, especially when solving\nlarge-scale machine learning problems. Stochastic Path Integrated Differential\nEstimator Stochastic First-Order method (SPIDER-SFO) nearly achieves the\nalgorithmic lower bound in certain regimes for nonconvex problems. However,\nwhether we can find a decentralized algorithm which achieves a similar\nconvergence rate to SPIDER-SFO is still unclear. To tackle this problem, we\npropose a decentralized variant of SPIDER-SFO, called decentralized SPIDER-SFO\n(D-SPIDER-SFO). We show that D-SPIDER-SFO achieves a similar gradient\ncomputation cost---that is, $\\mathcal{O}(\\epsilon^{-3})$ for finding an\n$\\epsilon$-approximate first-order stationary point---to its centralized\ncounterpart. To the best of our knowledge, D-SPIDER-SFO achieves the\nstate-of-the-art performance for solving nonconvex optimization problems on\ndecentralized networks in terms of the computational cost. Experiments on\ndifferent network configurations demonstrate the efficiency of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:15:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pan", "Taoxing", ""], ["Liu", "Jun", ""], ["Wang", "Jie", ""]]}, {"id": "1911.12675", "submitter": "Xu Shen", "authors": "Xu Shen, Xinmei Tian, Tongliang Liu, Fang Xu and Dacheng Tao", "title": "Continuous Dropout", "comments": "Accepted by TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout has been proven to be an effective algorithm for training robust deep\nnetworks because of its ability to prevent overfitting by avoiding the\nco-adaptation of feature detectors. Current explanations of dropout include\nbagging, naive Bayes, regularization, and sex in evolution. According to the\nactivation patterns of neurons in the human brain, when faced with different\nsituations, the firing rates of neurons are random and continuous, not binary\nas current dropout does. Inspired by this phenomenon, we extend the traditional\nbinary dropout to continuous dropout. On the one hand, continuous dropout is\nconsiderably closer to the activation characteristics of neurons in the human\nbrain than traditional binary dropout. On the other hand, we demonstrate that\ncontinuous dropout has the property of avoiding the co-adaptation of feature\ndetectors, which suggests that we can extract more independent feature\ndetectors for model averaging in the test stage. We introduce the proposed\ncontinuous dropout to a feedforward neural network and comprehensively compare\nit with binary dropout, adaptive dropout, and DropConnect on MNIST, CIFAR-10,\nSVHN, NORB, and ILSVRC-12. Thorough experiments demonstrate that our method\nperforms better in preventing the co-adaptation of feature detectors and\nimproves test performance. The code is available at:\nhttps://github.com/jasonustc/caffe-multigpu/tree/dropout.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:37:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "Xu", ""], ["Tian", "Xinmei", ""], ["Liu", "Tongliang", ""], ["Xu", "Fang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1911.12682", "submitter": "Xu Shen", "authors": "Xu Shen, Xinmei Tian, Shaoyan Sun, Dacheng Tao", "title": "Patch Reordering: a Novel Way to Achieve Rotation and Translation\n  Invariance in Convolutional Neural Networks", "comments": "Accepted AAAI17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have demonstrated state-of-the-art\nperformance on many visual recognition tasks. However, the combination of\nconvolution and pooling operations only shows invariance to small local\nlocation changes in meaningful objects in input. Sometimes, such networks are\ntrained using data augmentation to encode this invariance into the parameters,\nwhich restricts the capacity of the model to learn the content of these\nobjects. A more efficient use of the parameter budget is to encode rotation or\ntranslation invariance into the model architecture, which relieves the model\nfrom the need to learn them. To enable the model to focus on learning the\ncontent of objects other than their locations, we propose to conduct patch\nranking of the feature maps before feeding them into the next layer. When patch\nranking is combined with convolution and pooling operations, we obtain\nconsistent representations despite the location of meaningful objects in input.\nWe show that the patch ranking module improves the performance of the CNN on\nmany benchmark tasks, including MNIST digit recognition, large-scale image\nrecognition, and image retrieval. The code is available at\nhttps://github.com//jasonustc/caffe-multigpu/tree/TICNN .\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:49:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "Xu", ""], ["Tian", "Xinmei", ""], ["Sun", "Shaoyan", ""], ["Tao", "Dacheng", ""]]}, {"id": "1911.12689", "submitter": "Adriano Barra Dr.", "authors": "Elena Agliari, Francesco Alemanno, Adriano Barra, Martino Centonze,\n  Alberto Fachechi", "title": "Neural networks with redundant representation: detecting the\n  undetectable", "comments": null, "journal-ref": "Phys. Rev. Lett. 124, 028301 (2020)", "doi": "10.1103/PhysRevLett.124.028301", "report-no": "Roma01.Math", "categories": "cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a three-layer Sejnowski machine and show that features learnt via\ncontrastive divergence have a dual representation as patterns in a dense\nassociative memory of order P=4. The latter is known to be able to\nHebbian-store an amount of patterns scaling as N^{P-1}, where N denotes the\nnumber of constituting binary neurons interacting P-wisely. We also prove that,\nby keeping the dense associative network far from the saturation regime\n(namely, allowing for a number of patterns scaling only linearly with N, while\nP>2) such a system is able to perform pattern recognition far below the\nstandard signal-to-noise threshold. In particular, a network with P=4 is able\nto retrieve information whose intensity is O(1) even in the presence of a noise\nO(\\sqrt{N}) in the large N limit. This striking skill stems from a redundancy\nrepresentation of patterns -- which is afforded given the (relatively) low-load\ninformation storage -- and it contributes to explain the impressive abilities\nin pattern recognition exhibited by new-generation neural networks. The whole\ntheory is developed rigorously, at the replica symmetric level of\napproximation, and corroborated by signal-to-noise analysis and Monte Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:00:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Agliari", "Elena", ""], ["Alemanno", "Francesco", ""], ["Barra", "Adriano", ""], ["Centonze", "Martino", ""], ["Fachechi", "Alberto", ""]]}, {"id": "1911.12732", "submitter": "Jun Jin", "authors": "Jun Jin, Chao Ying, Zhou Yu", "title": "Distributed estimation of principal support vector machines for\n  sufficient dimension reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principal support vector machines method (Li et al., 2011) is a powerful\ntool for sufficient dimension reduction that replaces original predictors with\ntheir low-dimensional linear combinations without loss of information. However,\nthe computational burden of the principal support vector machines method\nconstrains its use for massive data. To address this issue, we in this paper\npropose two distributed estimation algorithms for fast implementation when the\nsample size is large. Both the two distributed sufficient dimension reduction\nestimators enjoy the same statistical efficiency as merging all the data\ntogether, which provides rigorous statistical guarantees for their application\nto large scale datasets. The two distributed algorithms are further adapt to\nprincipal weighted support vector machines (Shin et al., 2016) for sufficient\ndimension reduction in binary classification. The statistical accuracy and\ncomputational complexity of our proposed methods are examined through\ncomprehensive simulation studies and a real data application with more than\n600000 samples.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 14:42:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jin", "Jun", ""], ["Ying", "Chao", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.12740", "submitter": "Sunav Choudhary", "authors": "Ramit Pahwa, Manoj Ghuhan Arivazhagan, Ankur Garg, Siddarth\n  Krishnamoorthy, Rohit Saxena, Sunav Choudhary", "title": "Data-Driven Compression of Convolutional Neural Networks", "comments": "17 pages, 10 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deploying trained convolutional neural networks (CNNs) to mobile devices is a\nchallenging task because of the simultaneous requirements of the deployed model\nto be fast, lightweight and accurate. Designing and training a CNN architecture\nthat does well on all three metrics is highly non-trivial and can be very\ntime-consuming if done by hand. One way to solve this problem is to compress\nthe trained CNN models before deploying to mobile devices. This work asks and\nanswers three questions on compressing CNN models automatically: a) How to\ncontrol the trade-off between speed, memory and accuracy during model\ncompression? b) In practice, a deployed model may not see all classes and/or\nmay not need to produce all class labels. Can this fact be used to improve the\ntrade-off? c) How to scale the compression algorithm to execute within a\nreasonable amount of time for many deployments? The paper demonstrates that a\nmodel compression algorithm utilizing reinforcement learning with architecture\nsearch and knowledge distillation can answer these questions in the\naffirmative. Experimental results are provided for current state-of-the-art CNN\nmodel families for image feature extraction like VGG and ResNet with CIFAR\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:03:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pahwa", "Ramit", ""], ["Arivazhagan", "Manoj Ghuhan", ""], ["Garg", "Ankur", ""], ["Krishnamoorthy", "Siddarth", ""], ["Saxena", "Rohit", ""], ["Choudhary", "Sunav", ""]]}, {"id": "1911.12760", "submitter": "Vatsal Aggarwal", "authors": "Vatsal Aggarwal, Marius Cotescu, Nishant Prateek, Jaime\n  Lorenzo-Trueba, and Roberto Barra-Chicote", "title": "Using VAEs and Normalizing Flows for One-shot Text-To-Speech Synthesis\n  of Expressive Speech", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Text-to-Speech method to create an unseen expressive style using\none utterance of expressive speech of around one second. Specifically, we\nenhance the disentanglement capabilities of a state-of-the-art\nsequence-to-sequence based system with a Variational AutoEncoder (VAE) and a\nHouseholder Flow. The proposed system provides a 22% KL-divergence reduction\nwhile jointly improving perceptual metrics over state-of-the-art. At synthesis\ntime we use one example of expressive style as a reference input to the encoder\nfor generating any text in the desired style. Perceptual MUSHRA evaluations\nshow that we can create a voice with a 9% relative naturalness improvement over\nstandard Neural Text-to-Speech, while also improving the perceived emotional\nintensity (59 compared to the 55 of neutral speech).\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:57:14 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 13:56:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Aggarwal", "Vatsal", ""], ["Cotescu", "Marius", ""], ["Prateek", "Nishant", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Barra-Chicote", "Roberto", ""]]}, {"id": "1911.12774", "submitter": "Harry Clifford MSci DPhil", "authors": "Adnan Akbar, Geoffroy Dubourg-Felonneau, Andrey Solovyev, John W\n  Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Effective Sub-clonal Cancer Representation to Predict Tumor Evolution", "comments": "Learning Meaningful Representations of Life Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of cancer treatments end in failure due to Intra-Tumor\nHeterogeneity (ITH). ITH in cancer is represented by clonal evolution where\ndifferent sub-clones compete with each other for resources under conditions of\nDarwinian natural selection. Predicting the growth of these sub-clones within a\ntumour is among the key challenges of modern cancer research. Predicting tumor\nbehavior enables the creation of risk profiles for patients and the\noptimisation of their treatment by therapeutically targeting sub-clones more\nlikely to grow. Current research efforts in this space are focused on\nmathematical modelling of population genetics to quantify the selective\nadvantage of sub-clones, thus enabling predictions of which sub-clones are more\nlikely to grow. These tumor evolution models are based on assumptions which are\nnot valid for real-world tumor micro-environment. Furthermore, these models are\noften fit on a single instance of a tumor, and hence prediction models cannot\nbe validated. This paper presents an alternative approach for predicting cancer\nevolution using a data-driven machine learning method. Our proposed method is\nbased on the intuition that if we can capture the true characteristics of\nsub-clones within a tumor and represent it in the form of features, a\nsophisticated machine learning algorithm can be trained to predict its\nbehavior. The work presented here provides a novel approach to predicting\ncancer evolution, utilizing a data-driver approach. We strongly believe that\nthe accumulation of data from microbiologists, oncologists and machine learning\nresearchers could be used to encapsulate the true essence of tumor sub-clones,\nand can play a vital role in selecting the best cancer treatments for patients.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:23:33 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Akbar", "Adnan", ""], ["Dubourg-Felonneau", "Geoffroy", ""], ["Solovyev", "Andrey", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1911.12780", "submitter": "Colin Paterson", "authors": "Colin Paterson, Radu Calinescu and Chiara Picardi", "title": "Detection and Mitigation of Rare Subclasses in Deep Neural Network\n  Classifiers", "comments": "8 pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regions of high-dimensional input spaces that are underrepresented in\ntraining datasets reduce machine-learnt classifier performance, and may lead to\ncorner cases and unwanted bias for classifiers used in decision making systems.\nWhen these regions belong to otherwise well-represented classes, their presence\nand negative impact are very hard to identify. We propose an approach for the\ndetection and mitigation of such rare subclasses in deep neural network\nclassifiers. The new approach is underpinned by an easy-to-compute commonality\nmetric that supports the detection of rare subclasses, and comprises methods\nfor reducing the impact of these subclasses during both model training and\nmodel exploitation. We demonstrate our approach using two well-known datasets,\nMNIST's handwritten digits and Kaggle's cats/dogs, identifying rare subclasses\nand producing models which compensate for subclass rarity. In addition we\ndemonstrate how our run-time approach increases the ability of users to\nidentify samples likely to be misclassified at run-time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:41:35 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 15:06:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Paterson", "Colin", ""], ["Calinescu", "Radu", ""], ["Picardi", "Chiara", ""]]}, {"id": "1911.12809", "submitter": "George De Ath", "authors": "George De Ath, Richard M. Everson, Alma A. M. Rahat and Jonathan E.\n  Fieldsend", "title": "Greed is Good: Exploration and Exploitation Trade-offs in Bayesian\n  Optimisation", "comments": "Published in ACM Transactions on Evolutionary Learning and\n  Optimization (TELO). 22 pages (main paper) + 27 pages (supplementary\n  material)", "journal-ref": null, "doi": "10.1145/3425501", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of acquisition functions for Bayesian optimisation to locate\nthe global optimum of continuous functions is investigated in terms of the\nPareto front between exploration and exploitation. We show that Expected\nImprovement (EI) and the Upper Confidence Bound (UCB) always select solutions\nto be expensively evaluated on the Pareto front, but Probability of Improvement\nis not guaranteed to do so and Weighted Expected Improvement does so only for a\nrestricted range of weights.\n  We introduce two novel $\\epsilon$-greedy acquisition functions. Extensive\nempirical evaluation of these together with random search, purely exploratory,\nand purely exploitative search on 10 benchmark problems in 1 to 10 dimensions\nshows that $\\epsilon$-greedy algorithms are generally at least as effective as\nconventional acquisition functions (e.g., EI and UCB), particularly with a\nlimited budget. In higher dimensions $\\epsilon$-greedy approaches are shown to\nhave improved performance over conventional approaches. These results are borne\nout on a real world computational fluid dynamics optimisation problem and a\nrobotics active learning problem. Our analysis and experiments suggest that the\nmost effective strategy, particularly in higher dimensions, is to be mostly\ngreedy, occasionally selecting a random exploratory solution.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 17:52:06 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 12:58:19 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard M.", ""], ["Rahat", "Alma A. M.", ""], ["Fieldsend", "Jonathan E.", ""]]}, {"id": "1911.12842", "submitter": "Bhishma Dedhia", "authors": "Sarthak Consul, Bhishma Dedhia, Kumar Ashutosh and Parthasarathi\n  Khirwadkar", "title": "Analysis of Lower Bounds for Simple Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy iteration is a family of algorithms that are used to find an optimal\npolicy for a given Markov Decision Problem (MDP). Simple Policy iteration (SPI)\nis a type of policy iteration where the strategy is to change the policy at\nexactly one improvable state at every step. Melekopoglou and Condon [1990]\nshowed an exponential lower bound on the number of iterations taken by SPI for\na 2 action MDP. The results have not been generalized to $k-$action MDP since.\nIn this paper, we revisit the algorithm and the analysis done by Melekopoglou\nand Condon. We generalize the previous result and prove a novel exponential\nlower bound on the number of iterations taken by policy iteration for\n$N-$state, $k-$action MDPs. We construct a family of MDPs and give an\nindex-based switching rule that yields a strong lower bound of\n$\\mathcal{O}\\big((3+k)2^{N/2-3}\\big)$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:45:16 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Consul", "Sarthak", ""], ["Dedhia", "Bhishma", ""], ["Ashutosh", "Kumar", ""], ["Khirwadkar", "Parthasarathi", ""]]}, {"id": "1911.12848", "submitter": "Sonali Rajesh Shah", "authors": "Sonali Rajesh Shah (1) and Abhishek Kaushik (1) ((1) Dublin Business\n  School)", "title": "Sentiment Analysis On Indian Indigenous Languages: A Review On\n  Multilingual Opinion Mining", "comments": null, "journal-ref": null, "doi": "10.20944/preprints201911.0338.v1", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increase in the use of smartphones has laid to the use of the internet and\nsocial media platforms. The most commonly used social media platforms are\nTwitter, Facebook, WhatsApp and Instagram. People are sharing their personal\nexperiences, reviews, feedbacks on the web. The information which is available\non the web is unstructured and enormous. Hence, there is a huge scope of\nresearch on understanding the sentiment of the data available on the web.\nSentiment Analysis (SA) can be carried out on the reviews, feedbacks,\ndiscussions available on the web. There has been extensive research carried out\non SA in the English language, but data on the web also contains different\nother languages which should be analyzed. This paper aims to analyze, review\nand discuss the approaches, algorithms, challenges faced by the researchers\nwhile carrying out the SA on Indigenous languages.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:00:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shah", "Sonali Rajesh", ""], ["Kaushik", "Abhishek", ""]]}, {"id": "1911.12864", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Sushant Kumar, Evren Korpeoglu, Kannan Achan", "title": "Self-attention with Functional Time Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential modelling with self-attention has achieved cutting edge\nperformances in natural language processing. With advantages in model\nflexibility, computation complexity and interpretability, self-attention is\ngradually becoming a key component in event sequence models. However, like most\nother sequence models, self-attention does not account for the time span\nbetween events and thus captures sequential signals rather than temporal\npatterns. Without relying on recurrent network structures, self-attention\nrecognizes event orderings via positional encoding. To bridge the gap between\nmodelling time-independent and time-dependent event sequence, we introduce a\nfunctional feature map that embeds time span into high-dimensional spaces. By\nconstructing the associated translation-invariant time kernel function, we\nreveal the functional forms of the feature map under classic functional\nfunction analysis results, namely Bochner's Theorem and Mercer's Theorem. We\npropose several models to learn the functional time representation and the\ninteractions with event representation. These methods are evaluated on\nreal-world datasets under various continuous-time event sequence prediction\ntasks. The experiments reveal that the proposed methods compare favorably to\nbaseline models while also capturing useful time-event interactions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 21:04:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Kumar", "Sushant", ""], ["Korpeoglu", "Evren", ""], ["Achan", "Kannan", ""]]}, {"id": "1911.12868", "submitter": "Michael Smith", "authors": "Michael T. Smith, Joel Ssematimba, Mauricio A. Alvarez, Engineer\n  Bainomugisha", "title": "Machine Learning for a Low-cost Air Pollution Network", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection in economically constrained countries often necessitates\nusing approximate and biased measurements due to the low-cost of the sensors\nused. This leads to potentially invalid predictions and poor policies or\ndecision making. This is especially an issue if methods from resource-rich\nregions are applied without handling these additional constraints. In this\npaper we show, through the use of an air pollution network example, how using\nprobabilistic machine learning can mitigate some of the technical constraints.\nSpecifically we experiment with modelling the calibration for individual\nsensors as either distributions or Gaussian processes over time, and discuss\nthe wider issues around the decision process.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 21:32:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Smith", "Michael T.", ""], ["Ssematimba", "Joel", ""], ["Alvarez", "Mauricio A.", ""], ["Bainomugisha", "Engineer", ""]]}, {"id": "1911.12890", "submitter": "Masato Shirasaki", "authors": "Masato Shirasaki, Kana Moriwaki, Taira Oogi, Naoki Yoshida, Shiro\n  Ikeda, Takahiro Nishimichi", "title": "Noise reduction for weak lensing mass mapping: An application of\n  generative adversarial networks to Subaru Hyper Suprime-Cam first-year data", "comments": "16 pages, 17 figures, 1 table. Accepted for publication in MNRAS", "journal-ref": null, "doi": null, "report-no": "YITP-19-111", "categories": "astro-ph.CO astro-ph.IM physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep-learning approach based on generative adversarial networks\n(GANs) to reduce noise in weak lensing mass maps under realistic conditions. We\napply image-to-image translation using conditional GANs to the mass map\nobtained from the first-year data of Subaru Hyper Suprime-Cam (HSC) survey. We\ntrain the conditional GANs by using 25000 mock HSC catalogues that directly\nincorporate a variety of observational effects. We study the non-Gaussian\ninformation in denoised maps using one-point probability distribution functions\n(PDFs) and also perform matching analysis for positive peaks and massive\nclusters. An ensemble learning technique with our GANs is successfully applied\nto reproduce the PDFs of the lensing convergence. About $60\\%$ of the peaks in\nthe denoised maps with height greater than $5\\sigma$ have counterparts of\nmassive clusters within a separation of 6 arcmin. We show that PDFs in the\ndenoised maps are not compromised by details of multiplicative biases and\nphotometric redshift distributions, nor by shape measurement errors, and that\nthe PDFs show stronger cosmological dependence compared to the noisy\ncounterpart. We apply our denoising method to a part of the first-year HSC data\nto show that the observed mass distribution is statistically consistent with\nthe prediction from the standard $\\Lambda$CDM model.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 22:54:23 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 04:12:36 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Shirasaki", "Masato", ""], ["Moriwaki", "Kana", ""], ["Oogi", "Taira", ""], ["Yoshida", "Naoki", ""], ["Ikeda", "Shiro", ""], ["Nishimichi", "Takahiro", ""]]}, {"id": "1911.12896", "submitter": "Michael Kamp", "authors": "Michael Kamp, Mario Boley, Michael Mock, Daniel Keren, Assaf Schuster,\n  Izchak Sharfman", "title": "Adaptive Communication Bounds for Distributed Online Learning", "comments": null, "journal-ref": "Proceedings of the 7th NIPS Workshop on Optimization for Machine\n  Learning, 2014", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider distributed online learning protocols that control the exchange\nof information between local learners in a round-based learning scenario. The\nlearning performance of such a protocol is intuitively optimal if approximately\nthe same loss is incurred as in a hypothetical serial setting. If a protocol\naccomplishes this, it is inherently impossible to achieve a strong\ncommunication bound at the same time. In the worst case, every input is\nessential for the learning performance, even for the serial setting, and thus\nneeds to be exchanged between the local learners. However, it is reasonable to\ndemand a bound that scales well with the hardness of the serialized prediction\nproblem, as measured by the loss received by a serial online learning\nalgorithm. We provide formal criteria based on this intuition and show that\nthey hold for a simplified version of a previously published protocol.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 23:12:34 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kamp", "Michael", ""], ["Boley", "Mario", ""], ["Mock", "Michael", ""], ["Keren", "Daniel", ""], ["Schuster", "Assaf", ""], ["Sharfman", "Izchak", ""]]}, {"id": "1911.12899", "submitter": "Michael Kamp", "authors": "Michael Kamp, Sebastian Bothe, Mario Boley, Michael Mock", "title": "Communication-Efficient Distributed Online Learning with Kernels", "comments": null, "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2016", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an efficient distributed online learning protocol for low-latency\nreal-time services. It extends a previously presented protocol to kernelized\nonline learners that represent their models by a support vector expansion.\nWhile such learners often achieve higher predictive performance than their\nlinear counterparts, communicating the support vector expansions becomes\ninefficient for large numbers of support vectors. The proposed extension allows\nfor a larger class of online learning algorithms---including those alleviating\nthe problem above through model compression. In addition, we characterize the\nquality of the proposed protocol by introducing a novel criterion that requires\nthe communication to be bounded by the loss suffered.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 23:22:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kamp", "Michael", ""], ["Bothe", "Sebastian", ""], ["Boley", "Mario", ""], ["Mock", "Michael", ""]]}, {"id": "1911.12919", "submitter": "Duc Le", "authors": "Van-Duc Le, Tien-Cuong Bui, Sang Kyun Cha", "title": "Spatiotemporal deep learning model for citywide air pollution\n  interpolation and prediction", "comments": "Accepted at BigComp2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, air pollution is one of the most concerns for big cities.\nPredicting air quality for any regions and at any time is a critical\nrequirement of urban citizens. However, air pollution prediction for the whole\ncity is a challenging problem. The reason is, there are many spatiotemporal\nfactors affecting air pollution throughout the city. Collecting as many of them\ncould help us to forecast air pollution better. In this research, we present\nmany spatiotemporal datasets collected over Seoul city in Korea, which is\ncurrently much suffered by air pollution problem as well. These datasets\ninclude air pollution data, meteorological data, traffic volume, average\ndriving speed, and air pollution indexes of external areas which are known to\nimpact Seoul's air pollution. To the best of our knowledge, traffic volume and\naverage driving speed data are two new datasets in air pollution research. In\naddition, recent research in air pollution has tried to build models to\ninterpolate and predict air pollution in the city. Nevertheless, they mostly\nfocused on predicting air quality in discrete locations or used hand-crafted\nspatial and temporal features. In this paper, we propose the usage of\nConvolutional Long Short-Term Memory (ConvLSTM) model \\cite{b16}, a combination\nof Convolutional Neural Networks and Long Short-Term Memory, which\nautomatically manipulates both the spatial and temporal features of the data.\nSpecially, we introduce how to transform the air pollution data into sequences\nof images which leverages the using of ConvLSTM model to interpolate and\npredict air quality for the entire city at the same time. We prove that our\napproach is suitable for spatiotemporal air pollution problems and also\noutperforms other related research.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 01:40:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Le", "Van-Duc", ""], ["Bui", "Tien-Cuong", ""], ["Cha", "Sang Kyun", ""]]}, {"id": "1911.12922", "submitter": "Georgios Smyrnis", "authors": "Georgios Smyrnis, Petros Maragos", "title": "Tropical Polynomial Division and Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the process of Tropical Polynomial Division, a\ngeometric method which seeks to emulate the division of regular polynomials,\nwhen applied to those of the max-plus semiring. This is done via the\napproximation of the Newton Polytope of the dividend polynomial by that of the\ndivisor. This process is afterwards generalized and applied in the context of\nneural networks with ReLU activations. In particular, we make use of the\nintuition it provides, in order to minimize a two-layer fully connected\nnetwork, trained for a binary classification problem. This method is later\nevaluated on a variety of experiments, demonstrating its capability to\napproximate a network, with minimal loss in performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:10:23 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Smyrnis", "Georgios", ""], ["Maragos", "Petros", ""]]}, {"id": "1911.12927", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Fred Roosta, Marcus Gallagher", "title": "Richer priors for infinitely wide multi-layer perceptrons", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the distribution over functions induced through a\nzero-mean iid prior distribution over the parameters of a multi-layer\nperceptron (MLP) converges to a Gaussian process (GP), under mild conditions.\nWe extend this result firstly to independent priors with general zero or\nnon-zero means, and secondly to a family of partially exchangeable priors which\ngeneralise iid priors. We discuss how the second prior arises naturally when\nconsidering an equivalence class of functions in an MLP and through training\nprocesses such as stochastic gradient descent.\n  The model resulting from partially exchangeable priors is a GP, with an\nadditional level of inference in the sense that the prior and posterior\npredictive distributions require marginalisation over hyperparameters. We\nderive the kernels of the limiting GP in deep MLPs, and show empirically that\nthese kernels avoid certain pathologies present in previously studied priors.\nWe empirically evaluate our claims of convergence by measuring the maximum mean\ndiscrepancy between finite width models and limiting models. We compare the\nperformance of our new limiting model to some previously discussed models on\nsynthetic regression problems. We observe increasing ill-conditioning of the\nmarginal likelihood and hyper-posterior as the depth of the model increases,\ndrawing parallels with finite width networks which require notoriously involved\noptimisation tricks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:34:35 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Tsuchida", "Russell", ""], ["Roosta", "Fred", ""], ["Gallagher", "Marcus", ""]]}, {"id": "1911.12965", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang and Beilun Wang", "title": "Sparse and Low-Rank Tensor Regression via Parallel Proximal Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in various scientific fields having demand of\npredicting relationship between higher-order (tensor) feature and univariate\nresponse, we propose a \\underline{S}parse and \\underline{L}ow-rank\n\\underline{T}ensor \\underline{R}egression model (SLTR). This model enforces\nsparsity and low-rankness of the tensor coefficient by directly applying\n$\\ell_1$ norm and tensor nuclear norm on it respectively, such that (1) the\nstructural information of tensor is preserved and (2) the data interpretation\nis convenient. To make the solving procedure scalable and efficient, SLTR makes\nuse of the proximal gradient method to optimize two norm regularizers, which\ncan be easily implemented parallelly. Additionally, a tighter convergence rate\nis proved over three-order tensor data. We evaluate SLTR on several simulated\ndatasets and one fMRI dataset. Experiment results show that, compared with\nprevious models, SLTR is able to obtain a solution no worse than others with\nmuch less time cost.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 06:25:36 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Wang", "Beilun", ""]]}, {"id": "1911.12976", "submitter": "Melkior Ornik", "authors": "Melkior Ornik and Ufuk Topcu", "title": "Learning and Planning for Time-Varying MDPs Using Maximum Likelihood\n  Estimation", "comments": "To be published in Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a formal approach to online learning and planning for\nagents operating in a priori unknown, time-varying environments. The proposed\nmethod computes the maximally likely model of the environment, given the\nobservations about the environment made by an agent earlier in the system run\nand assuming knowledge of a bound on the maximal rate of change of system\ndynamics. Such an approach generalizes the estimation method commonly used in\nlearning algorithms for unknown Markov decision processes with time-invariant\ntransition probabilities, but is also able to quickly and correctly identify\nthe system dynamics following a change. Based on the proposed method, we\ngeneralize the exploration bonuses used in learning for time-invariant Markov\ndecision processes by introducing a notion of uncertainty in a learned\ntime-varying model, and develop a control policy for time-varying Markov\ndecision processes based on the exploitation and exploration trade-off. We\ndemonstrate the proposed methods on four numerical examples: a patrolling task\nwith a change in system dynamics, a two-state MDP with periodically changing\noutcomes of actions, a wind flow estimation task, and a multi-armed bandit\nproblem with periodically changing probabilities of different rewards.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:02:14 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 17:13:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ornik", "Melkior", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1911.13018", "submitter": "Antonio Quintero-Rincon", "authors": "Antonio Quintero-Rinc\\'on, Catalina Carenzo, Joaqu\\'in Ems, Lourdes\n  Hirschson, Valeria Muro, Carlos D'Giano", "title": "Spike-and-wave epileptiform discharge pattern detection based on\n  Kendall's Tau-b coefficient", "comments": "8 pages, 3 figures. RESEARCH LETTERS/SHORT REPORTS", "journal-ref": "Applied Medical Informatics 41 (1), 1-8, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is an important public health issue. An appropriate epileptiform\ndischarge pattern detection of this neurological disease is a typical problem\nin biomedical engineering. In this paper, a new method is proposed for\nspike-and-wave discharge pattern detection based on Kendall's Tau-b\ncoefficient. The proposed approach is demonstrated on a real dataset containing\nspike-and-wave discharge signals, where our performance is evaluated in terms\nof high Specificity, rule in (SpPIn) with 94% for patient-specific\nspike-and-wave discharge detection and 83% for a general spike-and-wave\ndischarge detection.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:41:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Quintero-Rinc\u00f3n", "Antonio", ""], ["Carenzo", "Catalina", ""], ["Ems", "Joaqu\u00edn", ""], ["Hirschson", "Lourdes", ""], ["Muro", "Valeria", ""], ["D'Giano", "Carlos", ""]]}, {"id": "1911.13019", "submitter": "Minsoo Kang", "authors": "Minsoo Kang, Jonghwan Mun, Bohyung Han", "title": "Towards Oracle Knowledge Distillation with Neural Architecture Search", "comments": "accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework of knowledge distillation that is capable of\nlearning powerful and efficient student models from ensemble teacher networks.\nOur approach addresses the inherent model capacity issue between teacher and\nstudent and aims to maximize benefit from teacher models during distillation by\nreducing their capacity gap. Specifically, we employ a neural architecture\nsearch technique to augment useful structures and operations, where the\nsearched network is appropriate for knowledge distillation towards student\nmodels and free from sacrificing its performance by fixing the network\ncapacity. We also introduce an oracle knowledge distillation loss to facilitate\nmodel search and distillation using an ensemble-based teacher model, where a\nstudent network is learned to imitate oracle performance of the teacher. We\nperform extensive experiments on the image classification datasets---CIFAR-100\nand TinyImageNet---using various networks. We also show that searching for a\nnew student model is effective in both accuracy and memory size and that the\nsearched models often outperform their teacher models thanks to neural\narchitecture search with oracle knowledge distillation.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:42:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kang", "Minsoo", ""], ["Mun", "Jonghwan", ""], ["Han", "Bohyung", ""]]}, {"id": "1911.13036", "submitter": "Luc Giffon", "authors": "Luc Giffon (QARMA, LIS), St\\'ephane Ayache (QARMA, LIS), Thierry\n  Arti\\`eres (QARMA, ECM, LIS), Hachem Kadri (QARMA, LIS)", "title": "Deep Networks with Adaptive Nystr\\\"om Approximation", "comments": null, "journal-ref": "IJCNN 2019 - International Joint Conference on Neural Networks,\n  Jul 2019, Budapest, Hungary", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has focused on combining kernel methods and deep learning to\nexploit the best of the two approaches. Here, we introduce a new architecture\nof neural networks in which we replace the top dense layers of standard\nconvolutional architectures with an approximation of a kernel function by\nrelying on the Nystr{\\\"o}m approximation. Our approach is easy and highly\nflexible. It is compatible with any kernel function and it allows exploiting\nmultiple kernels. We show that our architecture has the same performance than\nstandard architecture on datasets like SVHN and CIFAR100. One benefit of the\nmethod lies in its limited number of learnable parameters which makes it\nparticularly suited for small training set sizes, e.g. from 5 to 20 samples per\nclass.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:26:59 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Giffon", "Luc", "", "QARMA, LIS"], ["Ayache", "St\u00e9phane", "", "QARMA, LIS"], ["Arti\u00e8res", "Thierry", "", "QARMA, ECM, LIS"], ["Kadri", "Hachem", "", "QARMA, LIS"]]}, {"id": "1911.13042", "submitter": "Claudio Gambella", "authors": "Julien Monteil, Anton Dekusar, Claudio Gambella, Yassine Lassoued,\n  Martin Mevissen", "title": "On model selection for scalable time series forecasting in transport\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transport literature is dense regarding short-term traffic predictions,\nup to the scale of 1 hour, yet less dense for long-term traffic predictions.\nThe transport literature is also sparse when it comes to city-scale traffic\npredictions, mainly because of low data availability. In this work, we report\nan effort to investigate whether deep learning models can be useful for the\nlong-term large-scale traffic prediction task, while focusing on the\nscalability of the models. We investigate a city-scale traffic dataset with 14\nweeks of speed observations collected every 15 minutes over 1098 segments in\nthe hypercenter of Los Angeles, California. We look at a variety of\nstate-of-the-art machine learning and deep learning predictors for link-based\npredictions, and investigate how such predictors can scale up to larger areas\nwith clustering, and graph convolutional approaches. We discuss that modelling\ntemporal and spatial features into deep learning predictors can be helpful for\nlong-term predictions, while simpler, not deep learning-based predictors,\nachieve very satisfactory performance for link-based and short-term\nforecasting. The trade-off is discussed not only in terms of prediction\naccuracy vs prediction horizon but also in terms of training time and model\nsizing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:36:49 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:01:31 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 16:52:51 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Monteil", "Julien", ""], ["Dekusar", "Anton", ""], ["Gambella", "Claudio", ""], ["Lassoued", "Yassine", ""], ["Mevissen", "Martin", ""]]}, {"id": "1911.13044", "submitter": "Todor Davchev", "authors": "Todor Davchev, Michael Burke, Subramanian Ramamoorthy", "title": "Learning Structured Representations of Spatial and Interactive Dynamics\n  for Trajectory Prediction in Crowded Scenes", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters 2021", "doi": "10.1109/LRA.2020.3047778", "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context plays a significant role in the generation of motion for dynamic\nagents in interactive environments. This work proposes a modular method that\nutilises a learned model of the environment for motion prediction. This\nmodularity explicitly allows for unsupervised adaptation of trajectory\nprediction models to unseen environments and new tasks by relying on unlabelled\nimage data only. We model both the spatial and dynamic aspects of a given\nenvironment alongside the per agent motions. This results in more informed\nmotion prediction and allows for performance comparable to the\nstate-of-the-art. We highlight the model's prediction capability using a\nbenchmark pedestrian prediction problem and a robot manipulation task and show\nthat we can transfer the predictor across these tasks in a completely\nunsupervised way. The proposed approach allows for robust and label efficient\nforward modelling, and relaxes the need for full model re-training in new\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:42:10 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 10:56:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 11:34:06 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 09:29:35 GMT"}, {"version": "v5", "created": "Sun, 16 Aug 2020 18:47:40 GMT"}, {"version": "v6", "created": "Sat, 2 Jan 2021 13:24:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Davchev", "Todor", ""], ["Burke", "Michael", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1911.13060", "submitter": "Jan M\\\"uller", "authors": "Jan M\\\"uller, Reinhard Klein, Michael Weinmann", "title": "Orthogonal Wasserstein GANs", "comments": "Correction of the formatting of the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein-GANs have been introduced to address the deficiencies of\ngenerative adversarial networks (GANs) regarding the problems of vanishing\ngradients and mode collapse during the training, leading to improved\nconvergence behaviour and improved image quality. However, Wasserstein-GANs\nrequire the discriminator to be Lipschitz continuous. In current\nstate-of-the-art Wasserstein-GANs this constraint is enforced via gradient norm\nregularization. In this paper, we demonstrate that this regularization does not\nencourage a broad distribution of spectral-values in the discriminator weights,\nhence resulting in less fidelity in the learned distribution. We therefore\ninvestigate the possibility of substituting this Lipschitz constraint with an\northogonality constraint on the weight matrices. We compare three different\nweight orthogonalization techniques with regards to their convergence\nproperties, their ability to ensure the Lipschitz condition and the achieved\nquality of the learned distribution. In addition, we provide a comparison to\nWasserstein-GANs trained with current state-of-the-art methods, where we\ndemonstrate the potential of solely using orthogonality-based regularization.\nIn this context, we propose an improved training procedure for Wasserstein-GANs\nwhich utilizes orthogonalization to further increase its generalization\ncapability. Finally, we provide a novel metric to evaluate the generalization\ncapabilities of the discriminators of different Wasserstein-GANs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:20:12 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 00:36:08 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["M\u00fcller", "Jan", ""], ["Klein", "Reinhard", ""], ["Weinmann", "Michael", ""]]}, {"id": "1911.13061", "submitter": "Duncan Watson-Parris", "authors": "Duncan Watson-Parris, Samuel Sutherland, Matthew Christensen, Anthony\n  Caterini, Dino Sejdinovic, Philip Stier", "title": "Detecting anthropogenic cloud perturbations with deep learning", "comments": "Awarded Best Paper and Spotlight Oral at Climate Change: How Can AI\n  Help? (Workshop) at International Conference on Machine Learning (ICML), Long\n  Beach, California, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most pressing questions in climate science is that of the effect\nof anthropogenic aerosol on the Earth's energy balance. Aerosols provide the\n`seeds' on which cloud droplets form, and changes in the amount of aerosol\navailable to a cloud can change its brightness and other physical properties\nsuch as optical thickness and spatial extent. Clouds play a critical role in\nmoderating global temperatures and small perturbations can lead to significant\namounts of cooling or warming. Uncertainty in this effect is so large it is not\ncurrently known if it is negligible, or provides a large enough cooling to\nlargely negate present-day warming by CO2. This work uses deep convolutional\nneural networks to look for two particular perturbations in clouds due to\nanthropogenic aerosol and assess their properties and prevalence, providing\nvaluable insights into their climatic effects.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:22:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Watson-Parris", "Duncan", ""], ["Sutherland", "Samuel", ""], ["Christensen", "Matthew", ""], ["Caterini", "Anthony", ""], ["Sejdinovic", "Dino", ""], ["Stier", "Philip", ""]]}, {"id": "1911.13068", "submitter": "Beibin Li", "authors": "Beibin Li, Nicholas Nuechterlein, Erin Barney, Caitlin Hudac, Pamela\n  Ventola, Linda Shapiro, Frederick Shic", "title": "Sparsely Grouped Input Variables for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In genomic analysis, biomarker discovery, image recognition, and other\nsystems involving machine learning, input variables can often be organized into\ndifferent groups by their source or semantic category. Eliminating some groups\nof variables can expedite the process of data acquisition and avoid\nover-fitting. Researchers have used the group lasso to ensure group sparsity in\nlinear models and have extended it to create compact neural networks in\nmeta-learning. Different from previous studies, we use multi-layer non-linear\nneural networks to find sparse groups for input variables. We propose a new\nloss function to regularize parameters for grouped input variables, design a\nnew optimization algorithm for this loss function, and test these methods in\nthree real-world settings. We achieve group sparsity for three datasets,\nmaintaining satisfying results while excluding one nucleotide position from an\nRNA splicing experiment, excluding 89.9% of stimuli from an eye-tracking\nexperiment, and excluding 60% of image rows from an experiment on the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:45:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Beibin", ""], ["Nuechterlein", "Nicholas", ""], ["Barney", "Erin", ""], ["Hudac", "Caitlin", ""], ["Ventola", "Pamela", ""], ["Shapiro", "Linda", ""], ["Shic", "Frederick", ""]]}, {"id": "1911.13096", "submitter": "Rujing Yao", "authors": "Rujing Yao, Linlin Hou, Yingchun Ye, Ou Wu, Ji Zhang, Jian Wu", "title": "Method and Dataset Mining in Scientific Papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literature analysis facilitates researchers better understanding the\ndevelopment of science and technology. The conventional literature analysis\nfocuses on the topics, authors, abstracts, keywords, references, etc., and\nrarely pays attention to the content of papers. In the field of machine\nlearning, the involved methods (M) and datasets (D) are key information in\npapers. The extraction and mining of M and D are useful for discipline analysis\nand algorithm recommendation. In this paper, we propose a novel entity\nrecognition model, called MDER, and constructe datasets from the papers of the\nPAKDD conferences (2009-2019). Some preliminary experiments are conducted to\nassess the extraction performance and the mining results are visualized.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:19:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yao", "Rujing", ""], ["Hou", "Linlin", ""], ["Ye", "Yingchun", ""], ["Wu", "Ou", ""], ["Zhang", "Ji", ""], ["Wu", "Jian", ""]]}, {"id": "1911.13122", "submitter": "Solenne Gaucher", "authors": "Solenne Gaucher (LMO), Olga Klopp (CREST), Genevi\\`eve Robin (ENPC,\n  MATHERIALS)", "title": "Outliers Detection in Networks with Missing Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outliers arise in networks due to different reasons such as fraudulent\nbehavior of malicious users or default in measurement instruments and can\nsignificantly impair network analyses. In addition, real-life networks are\nlikely to be incompletely observed, with missing links due to individual\nnon-response or machine failures. Identifying outliers in the presence of\nmissing links is therefore a crucial problem in network analysis. In this work,\nwe introduce a new algorithm to detect outliers in a network that\nsimultaneously predicts the missing links. The proposed method is statistically\nsound: we prove that, under fairly general assumptions, our algorithm exactly\ndetects the outliers, and achieves the best known error for the prediction of\nmissing links with polynomial computation cost. It is also computationally\nefficient: we prove sub-linear convergence of our algorithm. We provide a\nsimulation study which demonstrates the good behavior of the algorithm in terms\nof outliers detection and prediction of the missing links. We also illustrate\nthe method with an application in epidemiology, and with the analysis of a\npolitical Twitter network. The method is freely available as an R package on\nthe Comprehensive R Archive Network.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:33:00 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 14:19:55 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Gaucher", "Solenne", "", "LMO"], ["Klopp", "Olga", "", "CREST"], ["Robin", "Genevi\u00e8ve", "", "ENPC,\n  MATHERIALS"]]}, {"id": "1911.13136", "submitter": "Hector Rodriguez-Deniz", "authors": "Hector Rodriguez-Deniz, Mattias Villani and Augusto Voltes-Dorta", "title": "A Multilayered Block Network Model to Forecast Large Dynamic\n  Transportation Graphs: an Application to US Air Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic transportation networks have been analyzed for years by means of\nstatic graph-based indicators in order to study the temporal evolution of\nrelevant network components, and to reveal complex dependencies that would not\nbe easily detected by a direct inspection of the data. This paper presents a\nstate-of-the-art latent network model to forecast multilayer dynamic graphs\nthat are increasingly common in transportation and proposes a community-based\nextension to reduce the computational burden. Flexible time series analysis is\nobtained by modeling the probability of edges between vertices through latent\nGaussian processes. The models and Bayesian inference are illustrated on a\nsample of 10-year data from four major airlines within the US air\ntransportation system. Results show how the estimated latent parameters from\nthe models are related to the airline's connectivity dynamics, and their\nability to project the multilayer graph into the future for out-of-sample full\nnetwork forecasts, while stochastic blockmodeling allows for the identification\nof relevant communities. Reliable network predictions would allow policy-makers\nto better understand the dynamics of the transport system, and help in their\nplanning on e.g. route development, or the deployment of new regulations.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:03:05 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 07:07:09 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 12:44:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Rodriguez-Deniz", "Hector", ""], ["Villani", "Mattias", ""], ["Voltes-Dorta", "Augusto", ""]]}, {"id": "1911.13152", "submitter": "Daniel Furelos-Blanco", "authors": "Daniel Furelos-Blanco, Mark Law, Alessandra Russo, Krysia Broda and\n  Anders Jonsson", "title": "Induction of Subgoal Automata for Reinforcement Learning", "comments": "Preprint accepted for publication to the 34th AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present ISA, a novel approach for learning and exploiting\nsubgoals in reinforcement learning (RL). Our method relies on inducing an\nautomaton whose transitions are subgoals expressed as propositional formulas\nover a set of observable events. A state-of-the-art inductive logic programming\nsystem is used to learn the automaton from observation traces perceived by the\nRL agent. The reinforcement learning and automaton learning processes are\ninterleaved: a new refined automaton is learned whenever the RL agent generates\na trace not recognized by the current automaton. We evaluate ISA in several\ngridworld problems and show that it performs similarly to a method for which\nautomata are given in advance. We also show that the learned automata can be\nexploited to speed up convergence through reward shaping and transfer learning\nacross multiple tasks. Finally, we analyze the running time and the number of\ntraces that ISA needs to learn an automata, and the impact that the number of\nobservable events has on the learner's performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:28:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Furelos-Blanco", "Daniel", ""], ["Law", "Mark", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""], ["Jonsson", "Anders", ""]]}, {"id": "1911.13159", "submitter": "Leo Feng", "authors": "Leo Feng, Luisa Zintgraf, Bei Peng, Shimon Whiteson", "title": "VIABLE: Fast Adaptation via Backpropagating Learned Loss", "comments": "Published at the 3rd Workshop on Meta-Learning at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot learning, typically, the loss function which is applied at test\ntime is the one we are ultimately interested in minimising, such as the\nmean-squared-error loss for a regression problem. However, given that we have\nfew samples at test time, we argue that the loss function that we are\ninterested in minimising is not necessarily the loss function most suitable for\ncomputing gradients in a few-shot setting. We propose VIABLE, a generic\nmeta-learning extension that builds on existing meta-gradient-based methods by\nlearning a differentiable loss function, replacing the pre-defined inner-loop\nloss function in performing task-specific updates. We show that learning a loss\nfunction capable of leveraging relational information between samples reduces\nunderfitting, and significantly improves performance and sample efficiency on a\nsimple regression task. Furthermore, we show VIABLE is scalable by evaluating\non the Mini-Imagenet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:47:09 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Feng", "Leo", ""], ["Zintgraf", "Luisa", ""], ["Peng", "Bei", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1911.13162", "submitter": "Alexander Preuhs", "authors": "Alexander Preuhs, Michael Manhart, Philipp Roser, Bernhard Stimpel,\n  Christopher Syben, Marios Psychogios, Markus Kowarschik, Andreas Maier", "title": "Deep autofocus with cone-beam CT consistency constraint", "comments": "Accepted at BVM 2020, review score under Top-6 of the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality reconstruction with interventional C-arm cone-beam computed\ntomography (CBCT) requires exact geometry information. If the geometry\ninformation is corrupted, e. g., by unexpected patient or system movement, the\nmeasured signal is misplaced in the backprojection operation. With prolonged\nacquisition times of interventional C-arm CBCT the likelihood of rigid patient\nmotion increases. To adapt the backprojection operation accordingly, a motion\nestimation strategy is necessary. Recently, a novel learning-based approach was\nproposed, capable of compensating motions within the acquisition plane. We\nextend this method by a CBCT consistency constraint, which was proven to be\nefficient for motions perpendicular to the acquisition plane. By the\nsynergistic combination of these two measures, in and out-plane motion is well\ndetectable, achieving an average artifact suppression of 93 [percent]. This\noutperforms the entropy-based state-of-the-art autofocus measure which achieves\non average an artifact suppression of 54 [percent].\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:54:38 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 12:17:44 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 21:43:50 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Preuhs", "Alexander", ""], ["Manhart", "Michael", ""], ["Roser", "Philipp", ""], ["Stimpel", "Bernhard", ""], ["Syben", "Christopher", ""], ["Psychogios", "Marios", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1911.13173", "submitter": "Brendan Ruff", "authors": "Brendan Ruff and Taylor Beck and Joscha Bach", "title": "Mean Shift Rejection: Training Deep Neural Networks Without Minibatch\n  Statistics or Normalization", "comments": "under review at ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks are known to be unstable during training\nat high learning rate unless normalization techniques are employed. Normalizing\nweights or activations allows the use of higher learning rates, resulting in\nfaster convergence and higher test accuracy. Batch normalization requires\nminibatch statistics that approximate the dataset statistics but this incurs\nadditional compute and memory costs and causes a communication bottleneck for\ndistributed training. Weight normalization and initialization-only schemes do\nnot achieve comparable test accuracy.\n  We introduce a new understanding of the cause of training instability and\nprovide a technique that is independent of normalization and minibatch\nstatistics. Our approach treats training instability as a spatial common mode\nsignal which is suppressed by placing the model on a channel-wise zero-mean\nisocline that is maintained throughout training. Firstly, we apply channel-wise\nzero-mean initialization of filter kernels with overall unity kernel magnitude.\nAt each training step we modify the gradients of spatial kernels so that their\nweighted channel-wise mean is subtracted in order to maintain the common mode\nrejection condition. This prevents the onset of mean shift. This new technique\nallows direct training of the test graph so that training and test models are\nidentical. We also demonstrate that injecting random noise throughout the\nnetwork during training improves generalization. This is based on the idea\nthat, as a side effect, batch normalization performs deep data augmentation by\ninjecting minibatch noise due to the weakness of the dataset approximation.\n  Our technique achieves higher accuracy compared to batch normalization and\nfor the first time shows that minibatches and normalization are unnecessary for\nstate-of-the-art training.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:19:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ruff", "Brendan", ""], ["Beck", "Taylor", ""], ["Bach", "Joscha", ""]]}, {"id": "1911.13175", "submitter": "Sean Moran", "authors": "Sean Moran, Steven McDonagh, Gregory Slabaugh", "title": "CURL: Neural Curve Layers for Global Image Enhancement", "comments": "Accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to adjust global image properties such as colour,\nsaturation, and luminance using human-interpretable image enhancement curves,\ninspired by the Photoshop curves tool. Our method, dubbed neural CURve Layers\n(CURL), is designed as a multi-colour space neural retouching block trained\njointly in three different colour spaces (HSV, CIELab, RGB) guided by a novel\nmulti-colour space loss. The curves are fully differentiable and are trained\nend-to-end for different computer vision problems including photo enhancement\n(RGB-to-RGB) and as part of the image signal processing pipeline for image\nformation (RAW-to-RGB). To demonstrate the effectiveness of CURL we combine\nthis global image transformation block with a pixel-level (local) image\nmulti-scale encoder-decoder backbone network. In an extensive experimental\nevaluation we show that CURL produces state-of-the-art image quality versus\nrecently proposed deep learning approaches in both objective and perceptual\nmetrics, setting new state-of-the-art performance on multiple public datasets.\nOur code is publicly available at: https://github.com/sjmoran/CURL.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:20:05 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 16:18:59 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:50:27 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 07:42:56 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Moran", "Sean", ""], ["McDonagh", "Steven", ""], ["Slabaugh", "Gregory", ""]]}, {"id": "1911.13178", "submitter": "Andreas Kamilaris", "authors": "Jesper Provoost, Luc Wismans, Sander Van der Drift, Andreas Kamilaris\n  and Maurice Van Keulen", "title": "Short Term Prediction of Parking Area states Using Real Time Data and\n  Machine Learning Techniques", "comments": "Proc. of Transportation Research Board 2020 Annual Meeting,\n  Washington D.C., USA, January 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public road authorities and private mobility service providers need\ninformation derived from the current and predicted traffic states to act upon\nthe daily urban system and its spatial and temporal dynamics. In this research,\na real-time parking area state (occupancy, in- and outflux) prediction model\n(up to 60 minutes ahead) has been developed using publicly available historic\nand real time data sources. Based on a case study in a real-life scenario in\nthe city of Arnhem, a Neural Network-based approach outperforms a Random\nForest-based one on all assessed performance measures, although the differences\nare small. Both are outperforming a naive seasonal random walk model. Although\nthe performance degrades with increasing prediction horizon, the model shows a\nperformance gain of over 150% at a prediction horizon of 60 minutes compared\nwith the naive model. Furthermore, it is shown that predicting the in- and\noutflux is a far more difficult task (i.e. performance gains of 30%) which\nneeds more training data, not based exclusively on occupancy rate. However, the\nperformance of predicting in- and outflux is less sensitive to the prediction\nhorizon. In addition, it is shown that real-time information of current\noccupancy rate is the independent variable with the highest contribution to the\nperformance, although time, traffic flow and weather variables also deliver a\nsignificant contribution. During real-time deployment, the model performs three\ntimes better than the naive model on average. As a result, it can provide\nvaluable information for proactive traffic management as well as mobility\nservice providers.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:23:41 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Provoost", "Jesper", ""], ["Wismans", "Luc", ""], ["Van der Drift", "Sander", ""], ["Kamilaris", "Andreas", ""], ["Van Keulen", "Maurice", ""]]}, {"id": "1911.13211", "submitter": "Adeline Fermanian", "authors": "Adeline Fermanian", "title": "Embedding and learning with signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential and temporal data arise in many fields of research, such as\nquantitative finance, medicine, or computer vision. A novel approach for\nsequential learning, called the signature method and rooted in rough path\ntheory, is considered. Its basic principle is to represent multidimensional\npaths by a graded feature set of their iterated integrals, called the\nsignature. This approach relies critically on an embedding principle, which\nconsists in representing discretely sampled data as paths, i.e., functions from\n$[0,1]$ to $\\mathbb{R}^d$. After a survey of machine learning methodologies for\nsignatures, the influence of embeddings on prediction accuracy is investigated\nwith an in-depth study of three recent and challenging datasets. It is shown\nthat a specific embedding, called lead-lag, is systematically the strongest\nperformer across all datasets and algorithms considered. Moreover, an empirical\nstudy reveals that computing signatures over the whole path domain does not\nlead to a loss of local information. It is concluded that, with a good\nembedding, combining signatures with other simple algorithms achieves results\ncompetitive with state-of-the-art, domain-specific approaches.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 17:16:49 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:13:27 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 11:40:26 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Fermanian", "Adeline", ""]]}, {"id": "1911.13213", "submitter": "Ali Oskooei", "authors": "Ali Oskooei, Sophie Mai Chau, Jonas Weiss, Arvind Sridhar, Mar\\'ia\n  Rodr\\'iguez Mart\\'inez and Bruno Michel", "title": "DeStress: Deep Learning for Unsupervised Identification of Mental Stress\n  in Firefighters from Heart-rate Variability (HRV) Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we perform a study of various unsupervised methods to identify\nmental stress in firefighter trainees based on unlabeled heart rate variability\ndata. We collect RR interval time series data from nearly 100 firefighter\ntrainees that participated in a drill. We explore and compare three methods in\norder to perform unsupervised stress detection: 1) traditional K-Means\nclustering with engineered time and frequency domain features 2) convolutional\nautoencoders and 3) long short-term memory (LSTM) autoencoders, both trained on\nthe raw RRI measurements combined with DBSCAN clustering and\nK-Nearest-Neighbors classification. We demonstrate that K-Means combined with\nengineered features is unable to capture meaningful structure within the data.\nOn the other hand, convolutional and LSTM autoencoders tend to extract varying\nstructure from the data pointing to different clusters with different sizes of\nclusters. We attempt at identifying the true stressed and normal clusters using\nthe HRV markers of mental stress reported in the literature. We demonstrate\nthat the clusters produced by the convolutional autoencoders consistently and\nsuccessfully stratify stressed versus normal samples, as validated by several\nestablished physiological stress markers such as RMSSD, Max-HR, Mean-HR and\nLF-HF ratio.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:59:09 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Oskooei", "Ali", ""], ["Chau", "Sophie Mai", ""], ["Weiss", "Jonas", ""], ["Sridhar", "Arvind", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""], ["Michel", "Bruno", ""]]}, {"id": "1911.13220", "submitter": "Daniel Mas Montserrat", "authors": "Daniel Mas Montserrat, Carlos Bustamante, Alexander Ioannidis", "title": "Class-Conditional VAE-GAN for Local-Ancestry Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local ancestry inference (LAI) allows identification of the ancestry of all\nchromosomal segments in admixed individuals, and it is a critical step in the\nanalysis of human genomes with applications from pharmacogenomics and precision\nmedicine to genome-wide association studies. In recent years, many LAI\ntechniques have been developed in both industry and academic research. However,\nthese methods require large training data sets of human genomic sequences from\nthe ancestries of interest. Such reference data sets are usually limited,\nproprietary, protected by privacy restrictions, or otherwise not accessible to\nthe public. Techniques to generate training samples that resemble real haploid\nsequences from ancestries of interest can be useful tools in such scenarios,\nsince a generalized model can often be shared, but the unique human sample\nsequences cannot. In this work we present a class-conditional VAE-GAN to\ngenerate new human genomic sequences that can be used to train local ancestry\ninference (LAI) algorithms. We evaluate the quality of our generated data by\ncomparing the performance of a state-of-the-art LAI method when trained with\ngenerated versus real data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:06:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Montserrat", "Daniel Mas", ""], ["Bustamante", "Carlos", ""], ["Ioannidis", "Alexander", ""]]}, {"id": "1911.13237", "submitter": "Tianyuan Zhang", "authors": "Tianyuan Zhang, Bichen Wu, Xin Wang, Joseph Gonzalez, Kurt Keutzer", "title": "Domain-Aware Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with more parameters and FLOPs have higher capacity and\ngeneralize better to diverse domains. But to be deployed on edge devices, the\nmodel's complexity has to be constrained due to limited compute resource. In\nthis work, we propose a method to improve the model capacity without increasing\ninference-time complexity. Our method is based on an assumption of data\nlocality: for an edge device, within a short period of time, the input data to\nthe device are sampled from a single domain with relatively low diversity.\nTherefore, it is possible to utilize a specialized, low-complexity model to\nachieve good performance in that input domain. To leverage this, we propose\nDomain-aware Dynamic Network (DDN), which is a high-capacity dynamic network in\nwhich each layer contains multiple weights. During inference, based on the\ninput domain, DDN dynamically combines those weights into one single weight\nthat specializes in the given domain. This way, DDN can keep the inference-time\ncomplexity low but still maintain a high capacity. Experiments show that\nwithout increasing the parameters, FLOPs, and actual latency, DDN achieves up\nto 2.6\\% higher AP50 than a static network on the BDD100K object-detection\nbenchmark.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:00:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Tianyuan", ""], ["Wu", "Bichen", ""], ["Wang", "Xin", ""], ["Gonzalez", "Joseph", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1911.13238", "submitter": "Jinle Zhu", "authors": "Jinle Zhu, Qiang Li, Li Hu, Hongyang Chen and Nirwan Ansari", "title": "Machine Learning-based Signal Detection for PMH Signals in\n  Load-modulated MIMO System", "comments": "with example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase Modulation on the Hypersphere (PMH) is a power efficient modulation\nscheme for the \\textit{load-modulated} multiple-input multiple-output (MIMO)\ntransmitters with central power amplifiers (CPA). However, it is difficult to\nobtain the precise channel state information (CSI), and the traditional optimal\nmaximum likelihood (ML) detection scheme incurs high complexity which increases\nexponentially with the number of antennas and the number of bits carried per\nantenna in the PMH modulation. To detect the PMH signals without knowing the\nprior CSI, we first propose a signal detection scheme, termed as the\nhypersphere clustering scheme based on the expectation maximization (EM)\nalgorithm with maximum likelihood detection (HEM-ML). By leveraging machine\nlearning, the proposed detection scheme can accurately obtain information of\nthe channel from a few of the received symbols with little resource cost and\nachieve comparable detection results as that of the optimal ML detector. To\nfurther reduce the computational complexity in the ML detection in HEM-ML, we\nalso propose the second signal detection scheme, termed as the hypersphere\nclustering scheme based on the EM algorithm with KD-tree detection (HEM-KD).\nThe CSI obtained from the EM algorithm is used to build a spatial KD-tree\nreceiver codebook and the signal detection problem can be transformed into a\nnearest neighbor search (NNS) problem. The detection complexity of HEM-KD is\nsignificantly reduced without any detection performance loss as compared to\nHEM-ML. Extensive simulation results verify the effectiveness of our proposed\ndetection schemes.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 07:57:15 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhu", "Jinle", ""], ["Li", "Qiang", ""], ["Hu", "Li", ""], ["Chen", "Hongyang", ""], ["Ansari", "Nirwan", ""]]}, {"id": "1911.13252", "submitter": "Julia El Zini", "authors": "Julia El Zini, Yara Rizk and Mariette Awad", "title": "An Optimized and Energy-Efficient Parallel Implementation of\n  Non-Iteratively Trained Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNN) have been successfully applied to various\nsequential decision-making tasks, natural language processing applications, and\ntime-series predictions. Such networks are usually trained through\nback-propagation through time (BPTT) which is prohibitively expensive,\nespecially when the length of the time dependencies and the number of hidden\nneurons increase. To reduce the training time, extreme learning machines (ELMs)\nhave been recently applied to RNN training, reaching a 99\\% speedup on some\napplications. Due to its non-iterative nature, ELM training, when parallelized,\nhas the potential to reach higher speedups than BPTT.\n  In this work, we present \\opt, an optimized parallel RNN training algorithm\nbased on ELM that takes advantage of the GPU shared memory and of parallel QR\nfactorization algorithms to efficiently reach optimal solutions. The\ntheoretical analysis of the proposed algorithm is presented on six RNN\narchitectures, including LSTM and GRU, and its performance is empirically\ntested on ten time-series prediction applications. \\opt~is shown to reach up to\n845 times speedup over its sequential counterpart and to require up to 20x less\ntime to train than parallel BPTT.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:30:53 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zini", "Julia El", ""], ["Rizk", "Yara", ""], ["Awad", "Mariette", ""]]}, {"id": "1911.13254", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (FAIR, SIERRA, PSL), Nicolas Usunier (FAIR),\n  L\\'eon Bottou (FAIR), Francis Bach (DI-ENS, PSL, SIERRA)", "title": "Music Source Separation in the Waveform Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source separation for music is the task of isolating contributions, or stems,\nfrom different instruments recorded individually and arranged together to form\na song. Such components include voice, bass, drums and any other\naccompaniments.Contrarily to many audio synthesis tasks where the best\nperformances are achieved by models that directly generate the waveform, the\nstate-of-the-art in source separation for music is to compute masks on the\nmagnitude spectrum. In this paper, we compare two waveform domain\narchitectures. We first adapt Conv-Tasnet, initially developed for speech\nsource separation,to the task of music source separation. While Conv-Tasnet\nbeats many existing spectrogram-domain methods, it suffersfrom significant\nartifacts, as shown by human evaluations. We propose instead Demucs, a novel\nwaveform-to-waveform model,with a U-Net structure and bidirectional\nLSTM.Experiments on the MusDB dataset show that, with proper data augmentation,\nDemucs beats allexisting state-of-the-art architectures, including Conv-Tasnet,\nwith 6.3 SDR on average, (and up to 6.8 with 150 extra training songs, even\nsurpassing the IRM oracle for the bass source).Using recent development in\nmodel quantization, Demucs can be compressed down to 120MBwithout any loss of\naccuracy.We also provide human evaluations, showing that Demucs benefit from a\nlarge advantagein terms of the naturalness of the audio. However, it suffers\nfrom some bleeding,especially between the vocals and other source.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:50:45 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 14:37:48 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "FAIR, SIERRA, PSL"], ["Usunier", "Nicolas", "", "FAIR"], ["Bottou", "L\u00e9on", "", "FAIR"], ["Bach", "Francis", "", "DI-ENS, PSL, SIERRA"]]}, {"id": "1911.13259", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Yasmeen Kussad, Dominic Kirkham, John W\n  Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Flatsomatic: A Method for Compression of Somatic Mutation Profiles in\n  Cancer", "comments": "Learning Meaningful Representations of Life Workshop at NeurIPS 2019.\n  arXiv admin note: substantial text overlap with arXiv:1911.09008", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present Flatsomatic - a Variational Auto Encoder (VAE)\noptimized to compress somatic mutations that allow for unbiased data\ncompression whilst maintaining the signal. We compared two different neural\nnetwork architectures for the VAE: Multilayer Perceptron (MLP) and\nbidirectional LSTM. The somatic profiles we used to train our models consisted\nof 8,062 Pan-Cancer patients from The Cancer Genome Atlas and 989 cell lines\nfrom the COSMIC cell line project. The profiles for each patient were\nrepresented by the genomic loci where somatic mutations occurred and, to reduce\nsparsity, the locations with a frequency <5 were removed. We enhanced the VAE\nperformance by changing its evidence lower bound, and devised an F1-score based\nloss showing that it helps the VAE learn better than with binary cross-entropy.\nWe also employed beta-VAE to weight the variational regularisation term in the\nloss function and showed the best performance through a preliminary function to\nincrease the weight of the regularisation term with each epoch. We assessed the\nreconstruction ability of the VAE using the micro F1-score metric and showed\nthat our best performing model was a 2-layer deep MLP VAE. Our analysis also\nshowed that the size of the latent space did not have a significant effect on\nthe VAE learning ability. We compared the Flatsomatic embeddings created to a\nlower dimension version of the data from principal component analysis, showing\nsuperior performance of Flatsomatic, and performed K-means clustering on both\ndatasets to draw comparisons to known cancer types of each profile. Finally, we\npresent results that confirm that the Flatsomatic representations of 64\ndimensions maintain the same predictive power as the original 8,298 dimensions\nvector, through prediction of drug response.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:29:34 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Kussad", "Yasmeen", ""], ["Kirkham", "Dominic", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1911.13268", "submitter": "Xue Chen", "authors": "Pranjal Awasthi, Vaggos Chatziafratis, Xue Chen, Aravindan\n  Vijayaraghavan", "title": "Adversarially Robust Low Dimensional Representations", "comments": "68 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems are vulnerable to small perturbations made to\nthe input either at test time or at training time. This has received much\nrecent interest on the empirical front due to several applications where\nreliability and security are critical, and the emergence of paradigms such as\nlow precision machine learning. However our theoretical understanding of the\ndesign of adversarially robust algorithms for the above settings is limited.\n  In this work we focus on Principal Component Analysis (PCA), a ubiquitous\nalgorithmic primitive in machine learning. We formulate a natural robust\nvariant of PCA, where the goal is to find a low dimensional subspace to\nrepresent the given data with minimum projection error, and that is in addition\nrobust to small perturbations measured in $\\ell_q$ norm (say $q=\\infty$).\nUnlike PCA which is solvable in polynomial time, our formulation is\ncomputationally intractable to optimize as it captures the well-studied sparse\nPCA objective as a special case. We show various algorithmic and statistical\nresults including:\n  - Polynomial time algorithm that is constant factor competitive in the\nworst-case, with respect to the best subspace both in terms of the projection\nerror and the robustness criterion. We also show that our algorithmic\ntechniques can be made robust to corruptions in the training data as well, in\naddition to yielding representations that are robust at test time.\n  - We prove that our formulation (and algorithms) also enjoy significant\nstatistical benefits in terms of sample complexity over standard PCA on account\nof a ``regularization effect'', that is formalized using the well-studied\nspiked covariance model.\n  - We illustrate the broad applicability of our algorithmic techniques in\naddressing robustness to adversarial perturbations, both at training-time and\ntest-time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:06:29 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 03:46:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Chatziafratis", "Vaggos", ""], ["Chen", "Xue", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1911.13270", "submitter": "Andrew Gambardella", "authors": "Andrew Gambardella, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Philip H. S. Torr", "title": "Transflow Learning: Repurposing Flow Models Without Retraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that deep generative models have a rich latent space, and\nthat it is possible to smoothly manipulate their outputs by traversing this\nlatent space. Recently, architectures have emerged that allow for more complex\nmanipulations, such as making an image look as though it were from a different\nclass, or painted in a certain style. These methods typically require large\namounts of training in order to learn a single class of manipulations. We\npresent Transflow Learning, a method for transforming a pre-trained generative\nmodel so that its outputs more closely resemble data that we provide\nafterwards. In contrast to previous methods, Transflow Learning does not\nrequire any training at all, and instead warps the probability distribution\nfrom which we sample latent vectors using Bayesian inference. Transflow\nLearning can be used to solve a wide variety of tasks, such as neural style\ntransfer and few-shot classification.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:14:53 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 14:09:04 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Gambardella", "Andrew", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1911.13288", "submitter": "Murat Ozbayoglu", "authors": "Omer Berat Sezer, Mehmet Ugur Gudelek, Ahmet Murat Ozbayoglu", "title": "Financial Time Series Forecasting with Deep Learning : A Systematic\n  Literature Review: 2005-2019", "comments": "13 figures, 13 tables, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time series forecasting is, without a doubt, the top choice of\ncomputational intelligence for finance researchers from both academia and\nfinancial industry due to its broad implementation areas and substantial\nimpact. Machine Learning (ML) researchers came up with various models and a\nvast number of studies have been published accordingly. As such, a significant\namount of surveys exist covering ML for financial time series forecasting\nstudies. Lately, Deep Learning (DL) models started appearing within the field,\nwith results that significantly outperform traditional ML counterparts. Even\nthough there is a growing interest in developing models for financial time\nseries forecasting research, there is a lack of review papers that were solely\nfocused on DL for finance. Hence, our motivation in this paper is to provide a\ncomprehensive literature review on DL studies for financial time series\nforecasting implementations. We not only categorized the studies according to\ntheir intended forecasting implementation areas, such as index, forex,\ncommodity forecasting, but also grouped them based on their DL model choices,\nsuch as Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs),\nLong-Short Term Memory (LSTM). We also tried to envision the future for the\nfield by highlighting the possible setbacks and opportunities, so the\ninterested researchers can benefit.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:43:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sezer", "Omer Berat", ""], ["Gudelek", "Mehmet Ugur", ""], ["Ozbayoglu", "Ahmet Murat", ""]]}, {"id": "1911.13300", "submitter": "Indranil SenGupta", "authors": "Indranil SenGupta, William Nganje, Erik Hanson", "title": "Refinements of Barndorff-Nielsen and Shephard model: an analysis of\n  crude oil price with machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly used stochastic model for derivative and commodity market analysis\nis the Barndorff-Nielsen and Shephard (BN-S) model. Though this model is very\nefficient and analytically tractable, it suffers from the absence of long range\ndependence and many other issues. For this paper, the analysis is restricted to\ncrude oil price dynamics. A simple way of improving the BN-S model with the\nimplementation of various machine learning algorithms is proposed. This refined\nBN-S model is more efficient and has fewer parameters than other models which\nare used in practice as improvements of the BN-S model. The procedure and the\nmodel show the application of data science for extracting a \"deterministic\ncomponent\" out of processes that are usually considered to be completely\nstochastic. Empirical applications validate the efficacy of the proposed model\nfor long range dependence.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:57:09 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:41:25 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 15:04:01 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["SenGupta", "Indranil", ""], ["Nganje", "William", ""], ["Hanson", "Erik", ""]]}]